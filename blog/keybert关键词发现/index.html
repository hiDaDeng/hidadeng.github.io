<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>KeyBERT | 关键词发现 | 大邓和他的PYTHON</title>
<meta name="keywords" content="文本向量化, 文本相似性计算, 文本分析, BERT, 余弦相似度, KeyBERT, python" />
<meta name="description" content="使用 BERT 嵌入 和 简单余弦相似度 来查找文档中与文档本身最相似的短语，自动挖掘文本中的关键词">
<meta name="author" content="大邓">
<link rel="canonical" href="/blog/keybert%E5%85%B3%E9%94%AE%E8%AF%8D%E5%8F%91%E7%8E%B0/" />
<meta name="baidu-site-verification" content="code-xTk1LSyjvt" />
<meta name="360-site-verification" content="dc00b42cd1d4e0fcaa5edfd27394f9cd" />
<meta name="sogou-site-verification" content="3HDeo612Pl" />
<link crossorigin="anonymous" href="/assets/css/stylesheet.min.css" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/assets/js/highlight.min.js" onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="apple-touch-icon" href="/apple-touch-icon.png">
<link rel="mask-icon" href="/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<meta name="generator" content="Hugo 0.89.4" />
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:title" content="KeyBERT | 关键词发现" />
<meta property="og:description" content="使用 BERT 嵌入 和 简单余弦相似度 来查找文档中与文档本身最相似的短语，自动挖掘文本中的关键词" />
<meta property="og:type" content="article" />
<meta property="og:url" content="/blog/keybert%E5%85%B3%E9%94%AE%E8%AF%8D%E5%8F%91%E7%8E%B0/" />
<meta property="og:image" content="/images/blog/keybert.png" /><meta property="article:section" content="blog" />
<meta property="article:published_time" content="2021-10-27T16:40:10&#43;06:00" />
<meta property="article:modified_time" content="2021-10-27T16:40:10&#43;06:00" />

<meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:image" content="/images/blog/keybert.png" />
<meta name="twitter:title" content="KeyBERT | 关键词发现"/>
<meta name="twitter:description" content="使用 BERT 嵌入 和 简单余弦相似度 来查找文档中与文档本身最相似的短语，自动挖掘文本中的关键词"/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Blogs",
      "item": "/blog/"
    }
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "KeyBERT | 关键词发现",
      "item": "/blog/keybert%E5%85%B3%E9%94%AE%E8%AF%8D%E5%8F%91%E7%8E%B0/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "KeyBERT | 关键词发现",
  "name": "KeyBERT | 关键词发现",
  "description": "使用 BERT 嵌入 和 简单余弦相似度 来查找文档中与文档本身最相似的短语，自动挖掘文本中的关键词",
  "keywords": [
    "文本向量化", "文本相似性计算", "文本分析", "BERT", "余弦相似度", "KeyBERT", "python"
  ],
  "articleBody": " 点击上方图片购买课程   尽管已经有很多方法可用于关键字生成（例如，Rake、YAKE!、TF-IDF 等），但我想创建一个非常基本但功能强大的方法来提取关键字和关键短语。这就是 KeyBERT 的用武之地！它使用 BERT 嵌入 和 简单余弦相似度 来查找文档中与文档本身最相似的短语。\nKeyBERT步骤\n 首先使用 BERT 提取文档嵌入以获得文档级向量表示。 随后，为 N-gram 词/短语提取词向量。 然后，我们使用余弦相似度来找到与文档最相似的单词/短语。 最后可以将最相似的词识别为最能描述整个文档的词。  安装 !pip3 install keybert==0.5.0 \n初始化模型 KeyBERT库需要安装配置spacy语言模型\n具体参考公众号：大邓和他的Python 2021-10-29 的推文 查看spacy配置方法\n初始化模型\nfrom keybert import KeyBERT import spacy import jieba zh_model = spacy.load(\"zh_core_web_sm\") bertModel = KeyBERT(model=zh_model) \n准备数据 中文测试数据需要先分词，而后构造成类英文的语言结构(用空格间隔的文本)\n# 测试数据 doc = \"\"\"时值10月25日抗美援朝纪念日，《长津湖》片方发布了“纪念中国人民志愿军抗美援朝出国作战71周年特别短片”，再次向伟大的志愿军致敬！ 电影《长津湖》全情全景地还原了71年前抗美援朝战场上那场史诗战役，志愿军奋不顾身的英勇精神令观众感叹：“岁月峥嵘英雄不灭，丹心铁骨军魂永存！”影片上映以来票房屡创新高，目前突破53亿元，暂列中国影史票房总榜第三名。 值得一提的是，这部影片的很多主创或有军人的血脉，或有当兵的经历，或者家人是军人。提起这些他们也充满自豪，影片总监制黄建新称：“当兵以后会有一种特别能坚持的劲儿。”饰演雷公的胡军透露：“我父亲曾经参加过抗美援朝，还得了一个三等功。”影片历史顾问王树增表示：“我当了五十多年的兵，我的老部队就是上甘岭上下来的，那些老兵都是我的偶像。” “身先士卒卫华夏家国，血战无畏护山河无恙。”片中饰演七连连长伍千里的吴京感叹：“要永远记住这些先烈们，他们给我们带来今天的和平。感谢他们的付出，才让我们有今天的幸福生活。”饰演新兵伍万里的易烊千玺表示：“战争的残酷、碾压式的伤害，其实我们现在的年轻人几乎很难能体会到，希望大家看完电影后能明白，是那些先辈们的牺牲奉献，换来了我们的现在。” 影片对战争群像的恢弘呈现，对个体命运的深切关怀，令许多观众无法控制自己的眼泪，观众称：“当看到影片中的惊险战斗场面，看到英雄们壮怀激烈的拼杀，为国捐躯的英勇无畏和无悔付出，我明白了为什么说今天的幸福生活来之不易。”（记者 王金跃） \"\"\" doc = ' '.join(jieba.lcut(doc)) # 关键词提取 keywords = bertModel.extract_keywords(doc, keyphrase_ngram_range=(1, 1), stop_words=None, top_n=10) keywords [('铁骨', 0.5028), ('纪念日', 0.495), ('丹心', 0.4894), ('战役', 0.4869), ('影史', 0.473), ('父亲', 0.4576), ('票房', 0.4571), ('偶像', 0.4497), ('精神', 0.4436), ('家国', 0.4373)]  常用extract_keywords参数 bertModel.extract_keywords(docs, keyphrase_ngram_range, stop_words, top_n)\n docs 文档字符串（空格间隔词语的字符串） keyphrase_ngram_range 设置ngram，默认(1, 1) stop_words 停用词列表 top_n 显示前n个关键词，默认5 highlight 可视化标亮关键词，默认False use_maxsum: 默认False;是否使用Max Sum Similarity作为关键词提取标准， use_mmr: 默认False;是否使用Maximal Marginal Relevance (MMR) 作为关键词提取标准 diversity 如果use_mmr=True，可以设置该参数。参数取值范围从0到1  对于keyphrase_ngram_range参数，\n (1, 1) 只单个词， 如\"抗美援朝\", “纪念日\"是孤立的两个词 (2, 2) 考虑词组， 如出现有意义的词组 “抗美援朝 纪念日” (1, 2) 同时考虑以上两者情况  # 关键词提取 keywords = bertModel.extract_keywords(doc, keyphrase_ngram_range=(2, 2), stop_words=None, diversity=0.7, top_n=10) keywords [('影片 总监制', 0.5412), ('丹心 铁骨', 0.5339), ('抗美援朝 纪念日', 0.5295), ('长津湖 片方', 0.5252), ('志愿军 致敬', 0.5207), ('老兵 偶像', 0.5192), ('票房 创新', 0.5108), ('军人 血脉', 0.5084), ('家国 血战', 0.4946), ('家人 军人', 0.4885)]  #可视化 keywords = bertModel.extract_keywords(doc, keyphrase_ngram_range=(2, 2), stop_words=None, highlight=True, top_n=10)   # 关键词提取 keywords = bertModel.extract_keywords(doc, keyphrase_ngram_range=(2, 2), stop_words=None, use_mmr=True, diversity=0.05, top_n=10) keywords [('影片 总监制', 0.5412), ('长津湖 片方', 0.5252), ('抗美援朝 纪念日', 0.5295), ('丹心 铁骨', 0.5339), ('志愿军 致敬', 0.5207), ('老兵 偶像', 0.5192), ('票房 创新', 0.5108), ('军人 血脉', 0.5084), ('家国 血战', 0.4946), ('家人 军人', 0.4885)]  英文KeyBERT 同样需要配置spacy，参考公众号：大邓和他的Python 2021-10-29 的推文 查看spacy配置方法\nfrom keybert import KeyBERT import spacy en_model = spacy.load(\"en_core_web_sm\") doc = \"\"\" Supervised learning is the machine learning task of learning a function that maps an input to an output based on example input-output pairs. It infers a function from labeled training data consisting of a set of training examples. In supervised learning, each example is a pair consisting of an input object (typically a vector) and a desired output value (also called the supervisory signal). A supervised learning algorithm analyzes the training data and produces an inferred function, which can be used for mapping new examples. An optimal scenario will allow for the algorithm to correctly determine the class labels for unseen instances. This requires the learning algorithm to generalize from the training data to unseen situations in a 'reasonable' way (see inductive bias). \"\"\" kw_model = KeyBERT() keywords = kw_model.extract_keywords(doc, keyphrase_ngram_range=(1, 2)) keywords Run\n[('supervised learning', 0.6779), ('supervised', 0.6676), ('signal supervised', 0.6152), ('examples supervised', 0.6112), ('labeled training', 0.6013)]  代码下载 https://github.com/hidadeng/DaDengAndHisPython/tree/master/20211030KeyBERT关键词提取\n",
  "wordCount" : "393",
  "inLanguage": "en",
  "image":"/images/blog/keybert.png","datePublished": "2021-10-27T16:40:10+06:00",
  "dateModified": "2021-10-27T16:40:10+06:00",
  "author":{
    "@type": "Person",
    "name": "大邓"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "/blog/keybert%E5%85%B3%E9%94%AE%E8%AF%8D%E5%8F%91%E7%8E%B0/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "大邓和他的PYTHON",
    "logo": {
      "@type": "ImageObject",
      "url": "/favicon.ico"
    }
  }
}
</script>
<script async src="https://www.googletagmanager.com/gtag/js?id=G-SFGQCREQ9X"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-SFGQCREQ9X');
</script>

</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="/" accesskey="h" title="大邓和他的PYTHON (Alt + H)" target="_blank">大邓和他的PYTHON</a>
            <span class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </span>
        </div>
        <ul id="menu">
            <li>
                <a href="/blog" title="博文" target="_blank">
                    <span>博文</span>
                </a>
            </li>
            <li>
                <a href="/search/" title="搜索" target="_blank">
                    <span>搜索</span>
                </a>
            </li>
            <li>
                <a href="/tags/" title="标签" target="_blank">
                    <span>标签</span>
                </a>
            </li>
            <li>
                <a href="mailto:thunderhit@qq.com" title="联系" target="_blank">
                    <span>联系</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">


<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js" integrity="sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js" integrity="sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa" crossorigin="anonymous"
onload="renderMathInElement(document.body);"></script>


<article class="post-single">
  <header class="post-header">
    
    <div class="breadcrumbs"><a href="/" target="_blank">Home</a>&nbsp;»&nbsp;<a href="/blog/" target="_blank">Blogs</a></div>
    <h1 class="post-title">
      KeyBERT | 关键词发现
    </h1>
    <div class="post-meta"><span title='2021-10-27 16:40:10 +0600 +0600'>2021-10-27</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;大邓

</div>

    <div>
      <br>
      <ul class="post-tags">
        <li><a href="/tags/python/" target='_blank'>Python</a></li>
        <li><a href="/tags/%E7%AC%AC%E4%B8%89%E6%96%B9%E5%8C%85/" target='_blank'>第三方包</a></li>
        <li><a href="/tags/%E6%96%87%E6%9C%AC%E5%88%86%E6%9E%90/" target='_blank'>文本分析</a></li>
        <li><a href="/tags/bert/" target='_blank'>Bert</a></li>
      </ul>
    </div>
  </header> 
<figure class="entry-cover"><a href="/images/blog/keybert.png" target="_blank"
            rel="noopener noreferrer"><img loading="lazy" src="/images/blog/keybert.png" alt=""></a>
        
</figure><div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#%e5%ae%89%e8%a3%85" aria-label="安装">安装</a></li>
                <li>
                    <a href="#%e5%88%9d%e5%a7%8b%e5%8c%96%e6%a8%a1%e5%9e%8b" aria-label="初始化模型">初始化模型</a></li>
                <li>
                    <a href="#%e5%87%86%e5%a4%87%e6%95%b0%e6%8d%ae" aria-label="准备数据">准备数据</a></li>
                <li>
                    <a href="#%e5%b8%b8%e7%94%a8extract_keywords%e5%8f%82%e6%95%b0" aria-label="常用extract_keywords参数">常用extract_keywords参数</a></li>
                <li>
                    <a href="#%e8%8b%b1%e6%96%87keybert" aria-label="英文KeyBERT">英文KeyBERT</a></li>
                <li>
                    <a href="#%e4%bb%a3%e7%a0%81%e4%b8%8b%e8%bd%bd" aria-label="代码下载">代码下载</a>
                </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><div style="text-align: center;">
<figure >
    <a href="https://m.qlchat.com/wechat/page/channel-intro?channelId=2000015158133596">
        <img src="/images/bg/management_data_mining_with_python_course.png" width="90%" />
    </a>
    <figcaption><small><i>点击上方图片购买课程</i></small></figcaption>
</figure>
</div>
<br>
<p>尽管已经有很多方法可用于关键字生成（例如，Rake、YAKE!、TF-IDF 等），但我想创建一个非常基本但功能强大的方法来提取关键字和关键短语。这就是 KeyBERT 的用武之地！它使用 <strong>BERT 嵌入</strong> 和 <strong>简单余弦相似度</strong> 来查找文档中与文档本身最相似的短语。</p>
<p>KeyBERT步骤</p>
<ol>
<li>首先使用 BERT 提取文档嵌入以获得<strong>文档级向量表示</strong>。</li>
<li>随后，为 N-gram 词/短语提取<strong>词向量</strong>。</li>
<li>然后，我们使用余弦相似度来找到与文档最相似的单词/短语。</li>
<li>最后可以将最相似的词识别为最能描述整个文档的词。</li>
</ol>
<br>
<h2 id="安装">安装<a hidden class="anchor" aria-hidden="true" href="#安装">#</a></h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="err">!</span><span class="n">pip3</span> <span class="n">install</span> <span class="n">keybert</span><span class="o">==</span><span class="mf">0.5.0</span>
</code></pre></div><br>
<h2 id="初始化模型">初始化模型<a hidden class="anchor" aria-hidden="true" href="#初始化模型">#</a></h2>
<p>KeyBERT库需要安装配置spacy语言模型</p>
<p>具体参考<strong>公众号：大邓和他的Python</strong> 2021-10-29 的推文 查看spacy配置方法</p>
<p>初始化模型</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">keybert</span> <span class="kn">import</span> <span class="n">KeyBERT</span>
<span class="kn">import</span> <span class="nn">spacy</span>
<span class="kn">import</span> <span class="nn">jieba</span>


<span class="n">zh_model</span> <span class="o">=</span> <span class="n">spacy</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&#34;zh_core_web_sm&#34;</span><span class="p">)</span>
<span class="n">bertModel</span> <span class="o">=</span> <span class="n">KeyBERT</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">zh_model</span><span class="p">)</span>
</code></pre></div><br>
<h2 id="准备数据">准备数据<a hidden class="anchor" aria-hidden="true" href="#准备数据">#</a></h2>
<p>中文测试数据需要先分词，而后构造成类英文的语言结构(用空格间隔的文本)</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1"># 测试数据</span>
<span class="n">doc</span> <span class="o">=</span>  <span class="s2">&#34;&#34;&#34;时值10月25日抗美援朝纪念日，《长津湖》片方发布了“纪念中国人民志愿军抗美援朝出国作战71周年特别短片”，再次向伟大的志愿军致敬！
</span><span class="s2">　　电影《长津湖》全情全景地还原了71年前抗美援朝战场上那场史诗战役，志愿军奋不顾身的英勇精神令观众感叹：“岁月峥嵘英雄不灭，丹心铁骨军魂永存！”影片上映以来票房屡创新高，目前突破53亿元，暂列中国影史票房总榜第三名。
</span><span class="s2">　　值得一提的是，这部影片的很多主创或有军人的血脉，或有当兵的经历，或者家人是军人。提起这些他们也充满自豪，影片总监制黄建新称：“当兵以后会有一种特别能坚持的劲儿。”饰演雷公的胡军透露：“我父亲曾经参加过抗美援朝，还得了一个三等功。”影片历史顾问王树增表示：“我当了五十多年的兵，我的老部队就是上甘岭上下来的，那些老兵都是我的偶像。”
</span><span class="s2">　　“身先士卒卫华夏家国，血战无畏护山河无恙。”片中饰演七连连长伍千里的吴京感叹：“要永远记住这些先烈们，他们给我们带来今天的和平。感谢他们的付出，才让我们有今天的幸福生活。”饰演新兵伍万里的易烊千玺表示：“战争的残酷、碾压式的伤害，其实我们现在的年轻人几乎很难能体会到，希望大家看完电影后能明白，是那些先辈们的牺牲奉献，换来了我们的现在。”
</span><span class="s2">　　影片对战争群像的恢弘呈现，对个体命运的深切关怀，令许多观众无法控制自己的眼泪，观众称：“当看到影片中的惊险战斗场面，看到英雄们壮怀激烈的拼杀，为国捐躯的英勇无畏和无悔付出，我明白了为什么说今天的幸福生活来之不易。”（记者 王金跃）
</span><span class="s2">        &#34;&#34;&#34;</span>


<span class="n">doc</span> <span class="o">=</span> <span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">jieba</span><span class="o">.</span><span class="n">lcut</span><span class="p">(</span><span class="n">doc</span><span class="p">))</span>


<span class="c1"># 关键词提取</span>
<span class="n">keywords</span> <span class="o">=</span> <span class="n">bertModel</span><span class="o">.</span><span class="n">extract_keywords</span><span class="p">(</span><span class="n">doc</span><span class="p">,</span> 
                                      <span class="n">keyphrase_ngram_range</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
                                      <span class="n">stop_words</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                                      <span class="n">top_n</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">keywords</span>
</code></pre></div><pre><code>[('铁骨', 0.5028),
 ('纪念日', 0.495),
 ('丹心', 0.4894),
 ('战役', 0.4869),
 ('影史', 0.473),
 ('父亲', 0.4576),
 ('票房', 0.4571),
 ('偶像', 0.4497),
 ('精神', 0.4436),
 ('家国', 0.4373)]
</code></pre>
<br>
<h2 id="常用extract_keywords参数">常用extract_keywords参数<a hidden class="anchor" aria-hidden="true" href="#常用extract_keywords参数">#</a></h2>
<p><strong>bertModel.extract_keywords(docs, keyphrase_ngram_range, stop_words, top_n)</strong></p>
<ul>
<li><strong>docs</strong> 文档字符串（空格间隔词语的字符串）</li>
<li><strong>keyphrase_ngram_range</strong> 设置ngram，默认(1, 1)</li>
<li><strong>stop_words</strong> 停用词列表</li>
<li><strong>top_n</strong> 显示前n个关键词，默认5</li>
<li><strong>highlight</strong> 可视化标亮关键词，默认False</li>
<li>use_maxsum: 默认False;是否使用Max Sum Similarity作为关键词提取标准，</li>
<li>use_mmr: 默认False;是否使用Maximal Marginal Relevance (MMR) 作为关键词提取标准</li>
<li>diversity 如果use_mmr=True，可以设置该参数。参数取值范围从0到1</li>
</ul>
<br>
<p>对于<strong>keyphrase_ngram_range</strong>参数，</p>
<ul>
<li>(1, 1) 只单个词， 如&quot;抗美援朝&quot;, &ldquo;纪念日&quot;是孤立的两个词</li>
<li>(2, 2) 考虑词组， 如出现有意义的词组 &ldquo;抗美援朝 纪念日&rdquo;</li>
<li>(1, 2) 同时考虑以上两者情况</li>
</ul>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1"># 关键词提取</span>
<span class="n">keywords</span> <span class="o">=</span> <span class="n">bertModel</span><span class="o">.</span><span class="n">extract_keywords</span><span class="p">(</span><span class="n">doc</span><span class="p">,</span> 
                                      <span class="n">keyphrase_ngram_range</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
                                      <span class="n">stop_words</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                                      <span class="n">diversity</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> 
                                      <span class="n">top_n</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">keywords</span>
</code></pre></div><pre><code>[('影片 总监制', 0.5412),
 ('丹心 铁骨', 0.5339),
 ('抗美援朝 纪念日', 0.5295),
 ('长津湖 片方', 0.5252),
 ('志愿军 致敬', 0.5207),
 ('老兵 偶像', 0.5192),
 ('票房 创新', 0.5108),
 ('军人 血脉', 0.5084),
 ('家国 血战', 0.4946),
 ('家人 军人', 0.4885)]
</code></pre>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#可视化</span>
<span class="n">keywords</span> <span class="o">=</span> <span class="n">bertModel</span><span class="o">.</span><span class="n">extract_keywords</span><span class="p">(</span><span class="n">doc</span><span class="p">,</span> 
                                      <span class="n">keyphrase_ngram_range</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
                                      <span class="n">stop_words</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                                      <span class="n">highlight</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                      <span class="n">top_n</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</code></pre></div>
<figure >
    
        <img src="img/highlight.png" width="800" />
    
    
</figure>

<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1"># 关键词提取</span>
<span class="n">keywords</span> <span class="o">=</span> <span class="n">bertModel</span><span class="o">.</span><span class="n">extract_keywords</span><span class="p">(</span><span class="n">doc</span><span class="p">,</span> 
                                      <span class="n">keyphrase_ngram_range</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
                                      <span class="n">stop_words</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                                      <span class="n">use_mmr</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">diversity</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span> 
                                      <span class="n">top_n</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

<span class="n">keywords</span>
</code></pre></div><pre><code>[('影片 总监制', 0.5412),
 ('长津湖 片方', 0.5252),
 ('抗美援朝 纪念日', 0.5295),
 ('丹心 铁骨', 0.5339),
 ('志愿军 致敬', 0.5207),
 ('老兵 偶像', 0.5192),
 ('票房 创新', 0.5108),
 ('军人 血脉', 0.5084),
 ('家国 血战', 0.4946),
 ('家人 军人', 0.4885)]
</code></pre>
<br>
<h2 id="英文keybert">英文KeyBERT<a hidden class="anchor" aria-hidden="true" href="#英文keybert">#</a></h2>
<p>同样需要配置spacy，参考<strong>公众号：大邓和他的Python</strong> 2021-10-29 的推文 查看spacy配置方法</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">keybert</span> <span class="kn">import</span> <span class="n">KeyBERT</span>
<span class="kn">import</span> <span class="nn">spacy</span>

<span class="n">en_model</span> <span class="o">=</span> <span class="n">spacy</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&#34;en_core_web_sm&#34;</span><span class="p">)</span>

<span class="n">doc</span> <span class="o">=</span> <span class="s2">&#34;&#34;&#34;
</span><span class="s2">         Supervised learning is the machine learning task of learning a function that
</span><span class="s2">         maps an input to an output based on example input-output pairs. It infers a
</span><span class="s2">         function from labeled training data consisting of a set of training examples.
</span><span class="s2">         In supervised learning, each example is a pair consisting of an input object
</span><span class="s2">         (typically a vector) and a desired output value (also called the supervisory signal). 
</span><span class="s2">         A supervised learning algorithm analyzes the training data and produces an inferred function, 
</span><span class="s2">         which can be used for mapping new examples. An optimal scenario will allow for the 
</span><span class="s2">         algorithm to correctly determine the class labels for unseen instances. This requires 
</span><span class="s2">         the learning algorithm to generalize from the training data to unseen situations in a 
</span><span class="s2">         &#39;reasonable&#39; way (see inductive bias).
</span><span class="s2">      &#34;&#34;&#34;</span>
<span class="n">kw_model</span> <span class="o">=</span> <span class="n">KeyBERT</span><span class="p">()</span>
<span class="n">keywords</span> <span class="o">=</span> <span class="n">kw_model</span><span class="o">.</span><span class="n">extract_keywords</span><span class="p">(</span><span class="n">doc</span><span class="p">,</span> <span class="n">keyphrase_ngram_range</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="n">keywords</span>
</code></pre></div><p>Run</p>
<pre><code>[('supervised learning', 0.6779),
 ('supervised', 0.6676),
 ('signal supervised', 0.6152),
 ('examples supervised', 0.6112),
 ('labeled training', 0.6013)]
</code></pre>
<br>
<h2 id="代码下载">代码下载<a hidden class="anchor" aria-hidden="true" href="#代码下载">#</a></h2>
<p><a href="https://github.com/hidadeng/DaDengAndHisPython/tree/master/20211030KeyBERT%E5%85%B3%E9%94%AE%E8%AF%8D%E6%8F%90%E5%8F%96">https://github.com/hidadeng/DaDengAndHisPython/tree/master/20211030KeyBERT关键词提取</a></p>


  </div>

  <footer class="post-footer">

  </footer><script src="https://utteranc.es/client.js"
        repo="hiDaDeng/hidadeng.github.io"
        issue-term="pathname"
        theme="preferred-color-scheme"
        crossorigin="anonymous"
        async>
</script>

</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2022 <a href="/">大邓和他的PYTHON</a></span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerText = 'copy';

        function copyingDone() {
            copybutton.innerText = 'copied!';
            setTimeout(() => {
                copybutton.innerText = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
