<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>实验 | 使用本地大模型预测在线评论情感类别和分值 | 大邓和他的PYTHON</title>
<meta name="keywords" content="Python, large language model, 大语言模型, 情感分析, sentiment analysis, ollama, deepseek, qwen" />
<meta name="description" content="情感分析是分析文本以确定消息的情绪基调是积极、消极还是中性的过程。通过情感分析，我们可以了解文本是否表现出快乐、悲伤、愤怒等情绪。主要的计算方法有语义词典法、机器学习法、混合方法、其他方法。 随着chatGPT这类大语言模型的出现， 它们增强了文本理解能力，使我们能够更精准的把握文本中的语义和情绪，也因此大型语言模型 (LLM) 一出场就有实现情感分析功能。Sentiment analysis is the process of analyzing text to determine whether the emotional tone of a message is positive, negative, or neutral. Through sentiment analysis, we can understand whether the text expresses emotions such as happiness, sadness, anger, etc. The main computational methods are semantic dictionary method, machine learning method, hybrid method, and other methods. With the emergence of large language models such as chatGPT, they enhance text understanding capabilities, allowing us to more accurately grasp the semantics and emotions in the text. Therefore, large language models (LLMs) have implemented sentiment analysis functions as soon as they appeared.">
<meta name="author" content="大邓">
<link rel="canonical" href="/blog/2024-08-06-using-the-ollama-local-large-model-to-predict-the-sentiment-category-of-online-comments/" />
<meta name="baidu-site-verification" content="codeva-TJUe6nOmGr" />
<meta name="sogou-site-verification" content="dZHPIorOhK" />
<meta name="sogou-site-verification" content="dZHPIorOhK" />
<meta name="google-site-verification" content="0cmjnyICPwXY_UmLHzs6RRUBIFxxqieMsgTGT_kVctk" />
<meta name="yandex-verification" content="5e672f12d3e2cacd" />
<link crossorigin="anonymous" href="/assets/css/stylesheet.min.css" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/assets/js/highlight.min.js" onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="apple-touch-icon" href="/apple-touch-icon.png">
<link rel="mask-icon" href="/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<meta name="generator" content="Hugo 0.89.4" />
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:title" content="实验 | 使用本地大模型预测在线评论情感类别和分值" />
<meta property="og:description" content="情感分析是分析文本以确定消息的情绪基调是积极、消极还是中性的过程。通过情感分析，我们可以了解文本是否表现出快乐、悲伤、愤怒等情绪。主要的计算方法有语义词典法、机器学习法、混合方法、其他方法。 随着chatGPT这类大语言模型的出现， 它们增强了文本理解能力，使我们能够更精准的把握文本中的语义和情绪，也因此大型语言模型 (LLM) 一出场就有实现情感分析功能。Sentiment analysis is the process of analyzing text to determine whether the emotional tone of a message is positive, negative, or neutral. Through sentiment analysis, we can understand whether the text expresses emotions such as happiness, sadness, anger, etc. The main computational methods are semantic dictionary method, machine learning method, hybrid method, and other methods. With the emergence of large language models such as chatGPT, they enhance text understanding capabilities, allowing us to more accurately grasp the semantics and emotions in the text. Therefore, large language models (LLMs) have implemented sentiment analysis functions as soon as they appeared." />
<meta property="og:type" content="article" />
<meta property="og:url" content="/blog/2024-08-06-using-the-ollama-local-large-model-to-predict-the-sentiment-category-of-online-comments/" />
<meta property="og:image" content="/images/blog/sentiment-analysis-with-llms.jpeg" /><meta property="article:section" content="blog" />
<meta property="article:published_time" content="2025-02-07T00:00:00&#43;00:00" />
<meta property="article:modified_time" content="2025-02-07T00:00:00&#43;00:00" />

<meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:image" content="/images/blog/sentiment-analysis-with-llms.jpeg" />
<meta name="twitter:title" content="实验 | 使用本地大模型预测在线评论情感类别和分值"/>
<meta name="twitter:description" content="情感分析是分析文本以确定消息的情绪基调是积极、消极还是中性的过程。通过情感分析，我们可以了解文本是否表现出快乐、悲伤、愤怒等情绪。主要的计算方法有语义词典法、机器学习法、混合方法、其他方法。 随着chatGPT这类大语言模型的出现， 它们增强了文本理解能力，使我们能够更精准的把握文本中的语义和情绪，也因此大型语言模型 (LLM) 一出场就有实现情感分析功能。Sentiment analysis is the process of analyzing text to determine whether the emotional tone of a message is positive, negative, or neutral. Through sentiment analysis, we can understand whether the text expresses emotions such as happiness, sadness, anger, etc. The main computational methods are semantic dictionary method, machine learning method, hybrid method, and other methods. With the emergence of large language models such as chatGPT, they enhance text understanding capabilities, allowing us to more accurately grasp the semantics and emotions in the text. Therefore, large language models (LLMs) have implemented sentiment analysis functions as soon as they appeared."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Blogs",
      "item": "/blog/"
    }
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "实验 | 使用本地大模型预测在线评论情感类别和分值",
      "item": "/blog/2024-08-06-using-the-ollama-local-large-model-to-predict-the-sentiment-category-of-online-comments/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "实验 | 使用本地大模型预测在线评论情感类别和分值",
  "name": "实验 | 使用本地大模型预测在线评论情感类别和分值",
  "description": "情感分析是分析文本以确定消息的情绪基调是积极、消极还是中性的过程。通过情感分析，我们可以了解文本是否表现出快乐、悲伤、愤怒等情绪。主要的计算方法有语义词典法、机器学习法、混合方法、其他方法。 随着chatGPT这类大语言模型的出现， 它们增强了文本理解能力，使我们能够更精准的把握文本中的语义和情绪，也因此大型语言模型 (LLM) 一出场就有实现情感分析功能。Sentiment analysis is the process of analyzing text to determine whether the emotional tone of a message is positive, negative, or neutral. Through sentiment analysis, we can understand whether the text expresses emotions such as happiness, sadness, anger, etc. The main computational methods are semantic dictionary method, machine learning method, hybrid method, and other methods. With the emergence of large language models such as chatGPT, they enhance text understanding capabilities, allowing us to more accurately grasp the semantics and emotions in the text. Therefore, large language models (LLMs) have implemented sentiment analysis functions as soon as they appeared.",
  "keywords": [
    "Python", "large language model", "大语言模型", "情感分析", "sentiment analysis", "ollama", "deepseek", "qwen"
  ],
  "articleBody": "情感分析是分析文本以确定消息的情绪基调是积极、消极还是中性的过程。通过情感分析，我们可以了解文本是否表现出快乐、悲伤、愤怒等情绪。主要的计算方法有语义词典法、机器学习法、混合方法、其他方法。 随着chatGPT这类大语言模型的出现， 它们增强了文本理解能力，使我们能够更精准的把握文本中的语义和情绪，也因此大型语言模型 (LLM) 一出场就有实现情感分析功能。\n一、任务描述 大邓准备了200条外卖评论数据(下图蓝色框)， 已进行标注, 其中负面110条，正面90条。\n现在想设计一个Prompt， 使用中文大模型对 review 文本进行情感类别(pos/neg)的预测(红色框)， 最终会计算大模型预测的准确率。\n先提前剧透一下， 模型预测的准确率87.5%。这种准确率，用到经管社科研究中， 应该没啥问题。\n\n二、传统模式 VS 大语言模型 大语言模型 (LLM) 因其在理解和生成人类语言方面的熟练程度而在情绪分析方面表现出色。通过对各种数据和算法进行训练，LLM 可以检测文本中的细微差别，从而增强其在社交媒体、新闻文章和客户评论等平台上掌握人们情绪和观点的能力。它们捕捉上下文和情感线索的能力提高了情绪分析的准确性和深度。\n情感分析领域，传统模式与大语言模型 (LLM) 的比较\n 传统的内容分析方法可能难以准确捕捉细微的情绪。 LLM 使用深度学习和迁移学习等先进技术，擅长理解不同的语言表达。 LLM 在跨文本源（包括社交媒体帖子和新闻文章）的情感分析方面具有卓越的准确性和效率。  \n三、Ollama Ollama是一款开源应用程序，可让您使用 MacOS、Linux 和 Windows 上的命令行界面在本地运行、创建和共享大型语言模型。\nOllama 可以直接从其库中访问各种 LLM，只需一个命令即可下载。下载后，只需执行一个命令即可开始使用。这对于工作量围绕终端窗口的用户非常有帮助。Ollama的安装、配置、使用的详细教程可阅读 教程 | 如何使用 Ollama 下载 \u0026 使用本地大语言模型\n3.1 安装模型 假设电脑中已安装了Ollama软件，\n qwen： 阿里的通义千问大模型， 主要适用于中文场景， 英文也可。 llama：Meta发布的LLama大模型，主要适用于英文场景， 中文也可。 deepseek： 幻方量化的DeepSeek模型，适用于中英文场景。  本文实验对象为中文内容(中文外卖在线评论）， 之前我尝试过deepseek感觉运行速度较慢， 本文选择 qwen (最新的模型是qwen2.5), 我们尝试一次性安装多个模型， 测试运行速度和任务完成的准确率。\nollama run qwen2.5:0.5b ollama run qwen2.5:1.5b ollama run qwen2.5:3b ollama run qwen2.5:7b \n3.2 安装python包 打开电脑命令行cmd(mac是terminal), 网络是连网状态，执行安装命令\npip3 install ollama pip3 install instructor \n3.3 启动ollama服务 在电脑中找到软件Ollama， 双击打开，即可开启Ollama服务。\n\n四、实验 4.1 代码结构 project - code.ipynb #代码 - data.csv #在线评论数据 - qwen2.5-0.5b-result.csv #qwen2.5:0.5b预测结果 - qwen2.5-1.5b-result.csv #qwen2.5:1.5预测结果 - qwen2.5-3b-result.csv #qwen2.5:3b预测结果 - qwen2.5-7b-result.csv #qwen2.5:7b预测结果 - async-qwen2.5-7b-result.csv #qwen2.5:7b异步代码预测结果 \n4.2 读取数据 data.csv 内存储着200条外卖评论，均已标注(label字段，其中1为正面， 0为负面)\nimport pandas as pd df = pd.read_csv('data.csv') df 字段的数据类型\ndf.dtypes Run\nlabel int64 review object dtype: object \nlabel数值的分布\ndf.label.value_counts() Run\nlabel 0 110 1 90 Name: count, dtype: int64 \n4.3 设计提示Promp 需要根据单词，生成单词、音标、语义、例句、历史文化、相关单词等信息， 提示如下，\nPROMPT_TEXT = \"根据评论内容，返回文本的情感类别(pos、neg、neo)和对应的情感得分(取值范围0~1)\"\" 注意: PROMPT_TEXT会影响模型表现， 大邓设计的非常粗糙， 建议大家可以设计DIY自己PROMPT_TEXT。\n4.4 小实验 使用参考推文 实验 | 如何使 Ollama 结构化输出 JSON 样式的结果 ，可确保情感分析的结果为指定格式。\n%%time from openai import OpenAI from pydantic import BaseModel from typing import List import os import instructor #结构化输出 class Sentiment(BaseModel): senti_label: str senti_score: float #Prompt提示 PROMPT_TEXT = \"根据评论内容，返回文本的情感类别(pos、neg、neo)和对应的情感得分(取值范围0~1)\" #实验数据 COMMENT_CONTENT = '11点14订餐，13点20饭才到，2个小时才把我的午饭送到，而且还是打了2次客服电话，1次投诉电话才给送来，要是不打电话都不知道几点能吃上午饭？' client = instructor.from_openai( OpenAI( base_url=\"http://localhost:11434/v1\", api_key=\"NA\", # required, but unused ), mode = instructor.Mode.JSON, ) resp = client.chat.completions.create( model = \"qwen2.5:7b\", messages=[ {\"role\": \"system\", \"content\": PROMPT_TEXT}, #提示PROMP {\"role\": \"user\", \"content\": COMMENT_CONTENT} #评论文本 ], response_model = Sentiment, max_retries = 3 ) print(resp.model_dump_json(indent=2)) Run\n{ \"senti_label\": \"neg\", \"senti_score\": -0.65 } CPU times: user 44.4 ms, sys: 6.46 ms, total: 50.8 ms Wall time: 1 s 运行一条评论耗时 1 s， 该评论为 负面neg, 情感分 -0.65。\n五、 完整代码 由于大模型速度非常缓慢，一次提问耗时几秒， 如果大规模使用大模型对数据进行数据标注， 速度慢的令人抓狂。 这时候写代码就有同步代码和异步代码之分。\n 同步代码 按照顺序执行，每个任务必须等待前一个任务完成后才能开始。适用于处理少量数据或不需要高并发性能的情况。 异步代码 允许并发执行多个任务，适合处理大量数据时提高效率。使用asyncio库来实现异步操作。  本章节是情感分析实验代码的收官章节， 设计了 同步代码 和 异步代码 两个版本， 并在本章末进行了任务耗时(速度)对比。\n5.1 同步代码 %%time import pandas as pd from tqdm import tqdm from openai import OpenAI from pydantic import BaseModel from typing import List import os import instructor #结构化输出 class Sentiment(BaseModel): senti_label: str senti_score: float #Prompt提示 PROMPT_TEXT = \"根据评论内容，返回文本的情感类别(pos、neg)和情感得分(取值范围 -1~1)\" client = instructor.from_openai( OpenAI( base_url=\"http://localhost:11434/v1\", api_key=\"NA\", # required, but unused ), mode = instructor.Mode.JSON, ) labels = [] scores = [] #读取数据 df = pd.read_csv('data.csv') for review in tqdm(df['review']): try: resp = client.chat.completions.create( model = 'qwen2.5:7b', #选择模型。 0.5b、1.5b、3b、7b等 messages=[ {\"role\": \"system\", \"content\": PROMPT_TEXT}, #提示 {\"role\": \"user\", \"content\": review} #评论文本 ], response_model = Sentiment, max_retries = 3 ) labels.append(resp.senti_label) scores.append(resp.senti_score) except: labels.append('NA') scores.append('NA') df['SentiLabel'] = labels df['SentiScore'] = scores #保存结果 df.to_csv('qwen2.5-7b-result.csv', index=False) df 5.2 异步代码 相比 5.1普通代码 ， 异步代码运行速度更快。\nimport pandas as pd from tqdm.asyncio import tqdm_asyncio # 使用AsyncOpenAI代替OpenAI以支持异步操作 from openai import AsyncOpenAI from pydantic import BaseModel from typing import List import numpy as np import os import instructor import asyncio # 结构化输出 class Sentiment(BaseModel): senti_label: str senti_score: float # Prompt提示 PROMPT_TEXT = \"根据评论内容，返回文本的情感类别(pos、neg)和情感得分(取值范围 -1~1)\" client = instructor.from_openai( AsyncOpenAI( base_url=\"http://localhost:11434/v1\", api_key=\"NA\", # required, but unused ), mode=instructor.Mode.JSON, ) async def analyze_review(review): try: resp = await client.chat.completions.create( model='qwen2.5:7b', # 选择模型。 3b、7b等 messages=[ {\"role\": \"system\", \"content\": PROMPT_TEXT}, # 提示 {\"role\": \"user\", \"content\": review} # 评论文本 ], response_model=Sentiment, max_retries=3 # 最大(失败）的重试次数。 ) return resp.senti_label, resp.senti_score except Exception as e: print(f\"Error processing review: {e}\") return 'NA', np.nan async def main(): # 读取数据 df = pd.read_csv('data.csv') tasks = [analyze_review(review) for review in df['review']] results = await tqdm_asyncio.gather(*tasks) labels, scores = zip(*results) df['SentiLabel'] = labels df['SentiScore'] = scores # 保存结果 df.to_csv('async-qwen2.5-7b-result.csv', index=False) # 检查是否已经在运行的事件循环中 try: asyncio.get_running_loop() # 如果在交互模式下运行，直接调度main()而不使用asyncio.run asyncio.create_task(main()) except RuntimeError: # 如果没有正在运行的事件循环，使用asyncio.run(main()) asyncio.run(main()) \n5.3 速度对比 以qwen2.5:7b为例， 对本文 data.csv 在线评论数据进行情感分析，\n 普通代码 运行耗时 160 秒 异步代码 运行耗时 90 秒  \n六、评价模型 本文分别对0.5b、1.5b、3b、7b进行实验， 记录了200条外卖评论的任务耗时(以同步代码为例）和准确率， 结果如下\n| 模型 | 模型参数 | 任务耗时(秒) | 准确率 | | ----- | ------ | -------- | ----- | |qwen2.5| 0.5b | 260s | 1.5% | |qwen2.5| 1.5b | 48.5s | 58.5% | |qwen2.5| 3b | 140s | 86% | |qwen2.5| 7b | 160s | 87.5% | 综合任务耗时和准确率， 建议使用 qwen2.5:3b 和 qwen2.5:7b 。如果电脑性能很好，直接上 qwen2.5:7b 甚至更大参数的模型。\nTips:准确率计算方法 假设label为1时， SentiLabel 为pos(或label为0时， SentiLabel为neg)， 大模型判断正确。反之，判断失误。\nexpression = \"(label == 1) \u0026 (sentiment == 'pos') | (label == 0) \u0026 (sentiment == 'neg')\" correct_ratio = len(df.query(expression))/ len(df) print(f'准确率: {correct_ratio*100}%') Run\n准确率: 86% \n七、获取代码 点击下载本文代码\n\n相关内容  文献 | GPT 是多语言心理文本分析的有效工具 教程 | 如何使用 Ollama 下载 \u0026 使用本地大语言模型 实验 | 如何使 Ollama 结构化输出 JSON 样式的结果 推荐 | 文本分析库cntext2.x使用手册 实验 | 使用本地大模型从文本中提取结构化信息 实验 | 使用Ollama本地大模型DIY制作单词书教案PDF 实验 | 使用 Crewai 和 Ollama 构建智能体(AI Agent)帮我撰写博客文章  \n精选内容  LIST | 可供社科(经管)领域使用的数据集汇总 LIST | 社科(经管)数据挖掘文献资料汇总 网络爬虫 | 使用scrapegraph-ai(大模型方案)自动采集网页数据 推荐 | 文本分析库cntext2.x使用手册 付费视频课 | Python实证指标构建与文本分析 实验 | 使用本地大模型从文本中提取结构化信息   ",
  "wordCount" : "719",
  "inLanguage": "en",
  "image":"/images/blog/sentiment-analysis-with-llms.jpeg","datePublished": "2025-02-07T00:00:00Z",
  "dateModified": "2025-02-07T00:00:00Z",
  "author":{
    "@type": "Person",
    "name": "大邓"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "/blog/2024-08-06-using-the-ollama-local-large-model-to-predict-the-sentiment-category-of-online-comments/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "大邓和他的PYTHON",
    "logo": {
      "@type": "ImageObject",
      "url": "/favicon.ico"
    }
  }
}
</script>
<script async src="https://www.googletagmanager.com/gtag/js?id=G-SFGQCREQ9X"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-SFGQCREQ9X');
</script>



<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC" rel="stylesheet">
<link href="https://fonts.googleapis.com/css2?family=PT+Serif" rel="stylesheet">
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="/" accesskey="h" title="大邓和他的PYTHON (Alt + H)" target="_blank">大邓和他的PYTHON</a>
            <span class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </span>
        </div>
        <ul id="menu">
            <li>
                <a href="/about/" title="关于" target="_blank">
                    <span>关于</span>
                </a>
            </li>
            <li>
                <a href="/archives/" title="归档" target="_blank">
                    <span>归档</span>
                </a>
            </li>
            <li>
                <a href="/search/" title="搜索" target="_blank">
                    <span>搜索</span>
                </a>
            </li>
            <li>
                <a href="/tags/" title="标签" target="_blank">
                    <span>标签</span>
                </a>
            </li>
            <li>
                <a href="/blog/management_python_course/" title="课程" target="_blank">
                    <span>课程</span>
                </a>
            </li>
            <li>
                <a href="/blog/the_text_analysis_list_about_ms/" title="文献" target="_blank">
                    <span>文献</span>
                </a>
            </li>
            <li>
                <a href="/blog/datasets_available_for_management_science/" title="数据" target="_blank">
                    <span>数据</span>
                </a>
            </li>
            <li>
                <a href="/blog/2024-04-27-cntext2x-usage-tutorial/" title="cntext2.x" target="_blank">
                    <span>cntext2.x</span>
                </a>
            </li>
            <li>
                <a href="/index.xml" title="RSS" target="_blank">
                    <span>RSS</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">


<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js" integrity="sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js" integrity="sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa" crossorigin="anonymous"
onload="renderMathInElement(document.body);"></script>




<article class="post-single">
  <header class="post-header">
    
    <div class="breadcrumbs"><a href="/" target="_blank">Home</a>&nbsp;»&nbsp;<a href="/blog/" target="_blank">Blogs</a></div>
    <h1 class="post-title">
      实验 | 使用本地大模型预测在线评论情感类别和分值
    </h1>
    <div class="post-meta"><span title='2025-02-07 00:00:00 +0000 UTC'>2025-02-07</span>&nbsp;·&nbsp;4 min&nbsp;·&nbsp;大邓

</div>
  </header> 
<figure class="entry-cover"><a href="/images/blog/sentiment-analysis-with-llms.jpeg" target="_blank"
            rel="noopener noreferrer"><img loading="lazy" src="/images/blog/sentiment-analysis-with-llms.jpeg" alt=""></a>
        
</figure>
<div class="share-buttons">
    <a target="_blank" rel="noopener noreferrer" aria-label="share 实验 | 使用本地大模型预测在线评论情感类别和分值 on twitter"
        href="https://twitter.com/intent/tweet/?text=%e5%ae%9e%e9%aa%8c%20%7c%20%e4%bd%bf%e7%94%a8%e6%9c%ac%e5%9c%b0%e5%a4%a7%e6%a8%a1%e5%9e%8b%e9%a2%84%e6%b5%8b%e5%9c%a8%e7%ba%bf%e8%af%84%e8%ae%ba%e6%83%85%e6%84%9f%e7%b1%bb%e5%88%ab%e5%92%8c%e5%88%86%e5%80%bc&amp;url=%2fblog%2f2024-08-06-using-the-ollama-local-large-model-to-predict-the-sentiment-category-of-online-comments%2f&amp;hashtags=LLM%2c%e6%96%87%e6%9c%ac%e5%88%86%e6%9e%90">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-253.927,424.544c135.939,0 210.268,-112.643 210.268,-210.268c0,-3.218 0,-6.437 -0.153,-9.502c14.406,-10.421 26.973,-23.448 36.935,-38.314c-13.18,5.824 -27.433,9.809 -42.452,11.648c15.326,-9.196 26.973,-23.602 32.49,-40.92c-14.252,8.429 -30.038,14.56 -46.896,17.931c-13.487,-14.406 -32.644,-23.295 -53.946,-23.295c-40.767,0 -73.87,33.104 -73.87,73.87c0,5.824 0.613,11.494 1.992,16.858c-61.456,-3.065 -115.862,-32.49 -152.337,-77.241c-6.284,10.881 -9.962,23.601 -9.962,37.088c0,25.594 13.027,48.276 32.95,61.456c-12.107,-0.307 -23.448,-3.678 -33.41,-9.196l0,0.92c0,35.862 25.441,65.594 59.311,72.49c-6.13,1.686 -12.72,2.606 -19.464,2.606c-4.751,0 -9.348,-0.46 -13.946,-1.38c9.349,29.426 36.628,50.728 68.965,51.341c-25.287,19.771 -57.164,31.571 -91.8,31.571c-5.977,0 -11.801,-0.306 -17.625,-1.073c32.337,21.15 71.264,33.41 112.95,33.41Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share 实验 | 使用本地大模型预测在线评论情感类别和分值 on linkedin"
        href="https://www.linkedin.com/shareArticle?mini=true&amp;url=%2fblog%2f2024-08-06-using-the-ollama-local-large-model-to-predict-the-sentiment-category-of-online-comments%2f&amp;title=%e5%ae%9e%e9%aa%8c%20%7c%20%e4%bd%bf%e7%94%a8%e6%9c%ac%e5%9c%b0%e5%a4%a7%e6%a8%a1%e5%9e%8b%e9%a2%84%e6%b5%8b%e5%9c%a8%e7%ba%bf%e8%af%84%e8%ae%ba%e6%83%85%e6%84%9f%e7%b1%bb%e5%88%ab%e5%92%8c%e5%88%86%e5%80%bc&amp;summary=%e5%ae%9e%e9%aa%8c%20%7c%20%e4%bd%bf%e7%94%a8%e6%9c%ac%e5%9c%b0%e5%a4%a7%e6%a8%a1%e5%9e%8b%e9%a2%84%e6%b5%8b%e5%9c%a8%e7%ba%bf%e8%af%84%e8%ae%ba%e6%83%85%e6%84%9f%e7%b1%bb%e5%88%ab%e5%92%8c%e5%88%86%e5%80%bc&amp;source=%2fblog%2f2024-08-06-using-the-ollama-local-large-model-to-predict-the-sentiment-category-of-online-comments%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share 实验 | 使用本地大模型预测在线评论情感类别和分值 on reddit"
        href="https://reddit.com/submit?url=%2fblog%2f2024-08-06-using-the-ollama-local-large-model-to-predict-the-sentiment-category-of-online-comments%2f&title=%e5%ae%9e%e9%aa%8c%20%7c%20%e4%bd%bf%e7%94%a8%e6%9c%ac%e5%9c%b0%e5%a4%a7%e6%a8%a1%e5%9e%8b%e9%a2%84%e6%b5%8b%e5%9c%a8%e7%ba%bf%e8%af%84%e8%ae%ba%e6%83%85%e6%84%9f%e7%b1%bb%e5%88%ab%e5%92%8c%e5%88%86%e5%80%bc">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share 实验 | 使用本地大模型预测在线评论情感类别和分值 on facebook"
        href="https://facebook.com/sharer/sharer.php?u=%2fblog%2f2024-08-06-using-the-ollama-local-large-model-to-predict-the-sentiment-category-of-online-comments%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share 实验 | 使用本地大模型预测在线评论情感类别和分值 on whatsapp"
        href="https://api.whatsapp.com/send?text=%e5%ae%9e%e9%aa%8c%20%7c%20%e4%bd%bf%e7%94%a8%e6%9c%ac%e5%9c%b0%e5%a4%a7%e6%a8%a1%e5%9e%8b%e9%a2%84%e6%b5%8b%e5%9c%a8%e7%ba%bf%e8%af%84%e8%ae%ba%e6%83%85%e6%84%9f%e7%b1%bb%e5%88%ab%e5%92%8c%e5%88%86%e5%80%bc%20-%20%2fblog%2f2024-08-06-using-the-ollama-local-large-model-to-predict-the-sentiment-category-of-online-comments%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share 实验 | 使用本地大模型预测在线评论情感类别和分值 on telegram"
        href="https://telegram.me/share/url?text=%e5%ae%9e%e9%aa%8c%20%7c%20%e4%bd%bf%e7%94%a8%e6%9c%ac%e5%9c%b0%e5%a4%a7%e6%a8%a1%e5%9e%8b%e9%a2%84%e6%b5%8b%e5%9c%a8%e7%ba%bf%e8%af%84%e8%ae%ba%e6%83%85%e6%84%9f%e7%b1%bb%e5%88%ab%e5%92%8c%e5%88%86%e5%80%bc&amp;url=%2fblog%2f2024-08-06-using-the-ollama-local-large-model-to-predict-the-sentiment-category-of-online-comments%2f">
        <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28">
            <path
                d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
        </svg>
    </a>
    
</div>
<aside id="toc-container" class="toc-container wide">
    <div class="toc">
        <details  open>
            <summary accesskey="c" title="(Alt + C)">
                <span class="details">Table of Contents</span>
            </summary>

            <div class="inner"><ul>
                    <li>
                        <a href="#%e4%b8%80%e4%bb%bb%e5%8a%a1%e6%8f%8f%e8%bf%b0" aria-label="一、任务描述">一、任务描述</a></li>
                    <li>
                        <a href="#%e4%ba%8c%e4%bc%a0%e7%bb%9f%e6%a8%a1%e5%bc%8f-vs-%e5%a4%a7%e8%af%ad%e8%a8%80%e6%a8%a1%e5%9e%8b" aria-label="二、传统模式 VS 大语言模型">二、传统模式 VS 大语言模型</a></li>
                    <li>
                        <a href="#%e4%b8%89ollama" aria-label="三、Ollama">三、Ollama</a><ul>
                            
                    <li>
                        <a href="#31-%e5%ae%89%e8%a3%85%e6%a8%a1%e5%9e%8b" aria-label="3.1 安装模型">3.1 安装模型</a></li>
                    <li>
                        <a href="#32-%e5%ae%89%e8%a3%85python%e5%8c%85" aria-label="3.2 安装python包">3.2 安装python包</a></li>
                    <li>
                        <a href="#33-%e5%90%af%e5%8a%a8ollama%e6%9c%8d%e5%8a%a1" aria-label="3.3 启动ollama服务">3.3 启动ollama服务</a></li></ul>
                    </li>
                    <li>
                        <a href="#%e5%9b%9b%e5%ae%9e%e9%aa%8c" aria-label="四、实验">四、实验</a><ul>
                            
                    <li>
                        <a href="#41-%e4%bb%a3%e7%a0%81%e7%bb%93%e6%9e%84" aria-label="4.1 代码结构">4.1 代码结构</a></li>
                    <li>
                        <a href="#42-%e8%af%bb%e5%8f%96%e6%95%b0%e6%8d%ae" aria-label="4.2 读取数据">4.2 读取数据</a></li>
                    <li>
                        <a href="#43-%e8%ae%be%e8%ae%a1%e6%8f%90%e7%a4%bapromp" aria-label="4.3 设计提示Promp">4.3 设计提示Promp</a></li>
                    <li>
                        <a href="#44-%e5%b0%8f%e5%ae%9e%e9%aa%8c" aria-label="4.4 小实验">4.4 小实验</a></li></ul>
                    </li>
                    <li>
                        <a href="#%e4%ba%94-%e5%ae%8c%e6%95%b4%e4%bb%a3%e7%a0%81" aria-label="五、 完整代码">五、 完整代码</a><ul>
                            
                    <li>
                        <a href="#51-%e5%90%8c%e6%ad%a5%e4%bb%a3%e7%a0%81" aria-label="5.1 同步代码">5.1 同步代码</a></li>
                    <li>
                        <a href="#52-%e5%bc%82%e6%ad%a5%e4%bb%a3%e7%a0%81" aria-label="5.2 异步代码">5.2 异步代码</a></li>
                    <li>
                        <a href="#53-%e9%80%9f%e5%ba%a6%e5%af%b9%e6%af%94" aria-label="5.3 速度对比">5.3 速度对比</a></li></ul>
                    </li>
                    <li>
                        <a href="#%e5%85%ad%e8%af%84%e4%bb%b7%e6%a8%a1%e5%9e%8b" aria-label="六、评价模型">六、评价模型</a><ul>
                            
                    <li>
                        <a href="#tips%e5%87%86%e7%a1%ae%e7%8e%87%e8%ae%a1%e7%ae%97%e6%96%b9%e6%b3%95" aria-label="Tips:准确率计算方法">Tips:准确率计算方法</a></li></ul>
                    </li>
                    <li>
                        <a href="#%e4%b8%83%e8%8e%b7%e5%8f%96%e4%bb%a3%e7%a0%81" aria-label="七、获取代码">七、获取代码</a></li>
                    <li>
                        <a href="#%e7%9b%b8%e5%85%b3%e5%86%85%e5%ae%b9" aria-label="相关内容">相关内容</a></li>
                    <li>
                        <a href="#%e7%b2%be%e9%80%89%e5%86%85%e5%ae%b9" aria-label="精选内容">精选内容</a>
                    </li>
                </ul>
            </div>
        </details>
    </div>
</aside>
<script>
    let activeElement;
    let elements;
    window.addEventListener('DOMContentLoaded', function (event) {
        checkTocPosition();

        elements = document.querySelectorAll('h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]');
         
         activeElement = elements[0];
         const id = encodeURI(activeElement.getAttribute('id')).toLowerCase();
         document.querySelector(`.inner ul li a[href="#${id}"]`).classList.add('active');
     }, false);

    window.addEventListener('resize', function(event) {
        checkTocPosition();
    }, false);

    window.addEventListener('scroll', () => {
        
        activeElement = Array.from(elements).find((element) => {
            if ((getOffsetTop(element) - window.pageYOffset) > 0 && 
                (getOffsetTop(element) - window.pageYOffset) < window.innerHeight/2) {
                return element;
            }
        }) || activeElement

        elements.forEach(element => {
             const id = encodeURI(element.getAttribute('id')).toLowerCase();
             if (element === activeElement){
                 document.querySelector(`.inner ul li a[href="#${id}"]`).classList.add('active');
             } else {
                 document.querySelector(`.inner ul li a[href="#${id}"]`).classList.remove('active');
             }
         })
     }, false);

    const main = parseInt(getComputedStyle(document.body).getPropertyValue('--article-width'), 10);
    const toc = parseInt(getComputedStyle(document.body).getPropertyValue('--toc-width'), 10);
    const gap = parseInt(getComputedStyle(document.body).getPropertyValue('--gap'), 10);

    function checkTocPosition() {
        const width = document.body.scrollWidth;

        if (width - main - (toc * 2) - (gap * 4) > 0) {
            document.getElementById("toc-container").classList.add("wide");
        } else {
            document.getElementById("toc-container").classList.remove("wide");
        }
    }

    function getOffsetTop(element) {
        if (!element.getClientRects().length) {
            return 0;
        }
        let rect = element.getBoundingClientRect();
        let win = element.ownerDocument.defaultView;
        return rect.top + win.pageYOffset;   
    }
</script>



  <div style="margin-top:2em;padding:0 0.5em;font-size:.875rem">
    <hr>
    <div style="padding-bottom:1em;">
        <p>本文作者：大邓
        <p>本文标题：实验 | 使用本地大模型预测在线评论情感类别和分值
        <p>本文链接：https://textdata.cn/blog/2024-08-06-using-the-ollama-local-large-model-to-predict-the-sentiment-category-of-online-comments/
        <p>版权声明：<a href="https://creativecommons.org/licenses/by-nc/4.0/" target="_blank">署名-非商业性使用-相同方式共享 4.0 国际</a></p>
    </div>
    <hr>
  </div>


  <br>



  
  <div class="post-content"><p>情感分析是分析文本以确定消息的情绪基调是积极、消极还是中性的过程。通过情感分析，我们可以了解文本是否表现出快乐、悲伤、愤怒等情绪。主要的计算方法有语义词典法、机器学习法、混合方法、其他方法。 随着chatGPT这类大语言模型的出现， 它们增强了文本理解能力，使我们能够更精准的把握文本中的语义和情绪，也因此大型语言模型 (LLM) 一出场就有实现情感分析功能。</p>
<p><img loading="lazy" src="img/Sentiment-Analysis-methods.png" alt=""  />
</p>
<h2 id="一任务描述">一、任务描述<a hidden class="anchor" aria-hidden="true" href="#一任务描述">#</a></h2>
<p>大邓准备了200条外卖评论数据(下图蓝色框)， 已进行标注, 其中负面110条，正面90条。</p>
<p>现在想设计一个Prompt， 使用中文大模型对 <em><strong>review</strong></em> 文本进行情感类别(pos/neg)的预测(红色框)， 最终会计算大模型预测的准确率。</p>
<p><img loading="lazy" src="img/00-purpose.png" alt=""  />
</p>
<p>先提前剧透一下， 模型预测的准确率87.5%。这种准确率，用到经管社科研究中， 应该没啥问题。</p>
<p><br><br></p>
<h2 id="二传统模式-vs-大语言模型">二、传统模式 VS 大语言模型<a hidden class="anchor" aria-hidden="true" href="#二传统模式-vs-大语言模型">#</a></h2>
<p>大语言模型 (LLM) 因其在理解和生成人类语言方面的熟练程度而在情绪分析方面表现出色。通过对各种数据和算法进行训练，LLM 可以检测文本中的细微差别，从而增强其在社交媒体、新闻文章和客户评论等平台上掌握人们情绪和观点的能力。它们捕捉上下文和情感线索的能力提高了情绪分析的准确性和深度。</p>
<p>情感分析领域，传统模式与大语言模型 (LLM) 的比较</p>
<ul>
<li>传统的内容分析方法可能难以准确捕捉细微的情绪。</li>
<li>LLM 使用深度学习和迁移学习等先进技术，擅长理解不同的语言表达。</li>
<li>LLM 在跨文本源（包括社交媒体帖子和新闻文章）的情感分析方面具有卓越的准确性和效率。</li>
</ul>
<p><br><br></p>
<h2 id="三ollama">三、Ollama<a hidden class="anchor" aria-hidden="true" href="#三ollama">#</a></h2>
<p><a href="https://ollama.ai/"><strong>Ollama</strong></a>是一款开源应用程序，可让您使用 MacOS、Linux 和 Windows 上的命令行界面在本地运行、创建和共享大型语言模型。</p>
<p>Ollama 可以直接从其库中访问各种 LLM，只需一个命令即可下载。下载后，只需执行一个命令即可开始使用。这对于工作量围绕终端窗口的用户非常有帮助。Ollama的安装、配置、使用的详细教程可阅读  <a href="https://textdata.cn/blog/2024-06-14-how-to-download-large-language-model-with-ollama/"><strong>教程 | 如何使用 Ollama 下载 &amp; 使用本地大语言模型</strong></a></p>
<br>
<h3 id="31-安装模型">3.1 安装模型<a hidden class="anchor" aria-hidden="true" href="#31-安装模型">#</a></h3>
<p>假设电脑中已安装了Ollama软件，</p>
<ul>
<li><em><strong>qwen</strong></em>： 阿里的通义千问大模型， 主要适用于中文场景， 英文也可。</li>
<li><em><strong>llama</strong></em>：Meta发布的LLama大模型，主要适用于英文场景， 中文也可。</li>
<li><em><strong>deepseek</strong></em>： 幻方量化的DeepSeek模型，适用于中英文场景。</li>
</ul>
<p><img loading="lazy" src="img/00-qwen.png" alt=""  />
</p>
<p>本文实验对象为中文内容(中文外卖在线评论）， 之前我尝试过deepseek感觉运行速度较慢， 本文选择 <em><strong>qwen</strong></em> (最新的模型是qwen2.5), <em><strong>我们尝试一次性安装多个模型， 测试运行速度和任务完成的准确率</strong></em>。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">ollama</span> <span class="n">run</span> <span class="n">qwen2</span><span class="mf">.5</span><span class="p">:</span><span class="mf">0.5</span><span class="n">b</span>
<span class="n">ollama</span> <span class="n">run</span> <span class="n">qwen2</span><span class="mf">.5</span><span class="p">:</span><span class="mf">1.5</span><span class="n">b</span>
<span class="n">ollama</span> <span class="n">run</span> <span class="n">qwen2</span><span class="mf">.5</span><span class="p">:</span><span class="mi">3</span><span class="n">b</span>
<span class="n">ollama</span> <span class="n">run</span> <span class="n">qwen2</span><span class="mf">.5</span><span class="p">:</span><span class="mi">7</span><span class="n">b</span>
</code></pre></div><br>
<h3 id="32-安装python包">3.2 安装python包<a hidden class="anchor" aria-hidden="true" href="#32-安装python包">#</a></h3>
<p>打开电脑命令行cmd(mac是terminal),  网络是连网状态，执行安装命令</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">pip3 install ollama
pip3 install instructor
</code></pre></div><br>
<h3 id="33-启动ollama服务">3.3 启动ollama服务<a hidden class="anchor" aria-hidden="true" href="#33-启动ollama服务">#</a></h3>
<p>在电脑中找到软件Ollama， 双击打开，即可开启Ollama服务。</p>
<p><br><br></p>
<h2 id="四实验">四、实验<a hidden class="anchor" aria-hidden="true" href="#四实验">#</a></h2>
<h3 id="41-代码结构">4.1 代码结构<a hidden class="anchor" aria-hidden="true" href="#41-代码结构">#</a></h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">project
  - code.ipynb                   #代码
  - data.csv                     #在线评论数据
  - qwen2.5-0.5b-result.csv      #qwen2.5:0.5b预测结果
  - qwen2.5-1.5b-result.csv      #qwen2.5:1.5预测结果
  - qwen2.5-3b-result.csv        #qwen2.5:3b预测结果
  - qwen2.5-7b-result.csv        #qwen2.5:7b预测结果
  - async-qwen2.5-7b-result.csv  #qwen2.5:7b异步代码预测结果
</code></pre></div><br>
<h3 id="42-读取数据">4.2 读取数据<a hidden class="anchor" aria-hidden="true" href="#42-读取数据">#</a></h3>
<p><em><strong>data.csv</strong></em> 内存储着200条外卖评论，均已标注(label字段，其中1为正面， 0为负面)</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;data.csv&#39;</span><span class="p">)</span>
<span class="n">df</span>
</code></pre></div><p><img loading="lazy" src="img/06-df.png" alt=""  />
</p>
<br>
<p>字段的数据类型</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df</span><span class="o">.</span><span class="n">dtypes</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">label</span>         <span class="n">int64</span>
<span class="n">review</span>       <span class="nb">object</span>
<span class="n">dtype</span><span class="p">:</span> <span class="nb">object</span>
</code></pre></div><br>
<p>label数值的分布</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df</span><span class="o">.</span><span class="n">label</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">label
0    110
1     90
Name: count, dtype: int64
</code></pre></div><br>
<h3 id="43-设计提示promp">4.3 设计提示Promp<a hidden class="anchor" aria-hidden="true" href="#43-设计提示promp">#</a></h3>
<p>需要根据单词，生成单词、音标、语义、例句、历史文化、相关单词等信息， 提示如下，</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">PROMPT_TEXT = &#34;根据评论内容，返回文本的情感类别(pos、neg、neo)和对应的情感得分(取值范围0~1)&#34;&#34;
</code></pre></div><p><strong>注意: PROMPT_TEXT会影响模型表现， 大邓设计的非常粗糙， 建议大家可以设计DIY自己PROMPT_TEXT</strong>。</p>
<br>
<h3 id="44-小实验">4.4 小实验<a hidden class="anchor" aria-hidden="true" href="#44-小实验">#</a></h3>
<p>使用参考推文 <a href="https://textdata.cn/blog/2024-08-07-structured-outputs-with-ollama/">实验 | 如何使 Ollama 结构化输出 JSON 样式的结果</a> ，可确保情感分析的结果为指定格式。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="o">%%</span><span class="n">time</span>
<span class="kn">from</span> <span class="nn">openai</span> <span class="kn">import</span> <span class="n">OpenAI</span>
<span class="kn">from</span> <span class="nn">pydantic</span> <span class="kn">import</span> <span class="n">BaseModel</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">List</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">instructor</span>

<span class="c1">#结构化输出</span>
<span class="k">class</span> <span class="nc">Sentiment</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>
    <span class="n">senti_label</span><span class="p">:</span> <span class="nb">str</span>
    <span class="n">senti_score</span><span class="p">:</span> <span class="nb">float</span>


<span class="c1">#Prompt提示</span>
<span class="n">PROMPT_TEXT</span> <span class="o">=</span> <span class="s2">&#34;根据评论内容，返回文本的情感类别(pos、neg、neo)和对应的情感得分(取值范围0~1)&#34;</span>

<span class="c1">#实验数据</span>
<span class="n">COMMENT_CONTENT</span> <span class="o">=</span> <span class="s1">&#39;11点14订餐，13点20饭才到，2个小时才把我的午饭送到，而且还是打了2次客服电话，1次投诉电话才给送来，要是不打电话都不知道几点能吃上午饭？&#39;</span>


<span class="n">client</span> <span class="o">=</span> <span class="n">instructor</span><span class="o">.</span><span class="n">from_openai</span><span class="p">(</span>
    <span class="n">OpenAI</span><span class="p">(</span>
        <span class="n">base_url</span><span class="o">=</span><span class="s2">&#34;http://localhost:11434/v1&#34;</span><span class="p">,</span>
        <span class="n">api_key</span><span class="o">=</span><span class="s2">&#34;NA&#34;</span><span class="p">,</span>  <span class="c1"># required, but unused</span>
    <span class="p">),</span>
    <span class="n">mode</span> <span class="o">=</span> <span class="n">instructor</span><span class="o">.</span><span class="n">Mode</span><span class="o">.</span><span class="n">JSON</span><span class="p">,</span>
<span class="p">)</span>


<span class="n">resp</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">chat</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
    <span class="n">model</span> <span class="o">=</span> <span class="s2">&#34;qwen2.5:7b&#34;</span><span class="p">,</span>
    <span class="n">messages</span><span class="o">=</span><span class="p">[</span>
        <span class="p">{</span><span class="s2">&#34;role&#34;</span><span class="p">:</span> <span class="s2">&#34;system&#34;</span><span class="p">,</span> <span class="s2">&#34;content&#34;</span><span class="p">:</span> <span class="n">PROMPT_TEXT</span><span class="p">},</span> <span class="c1">#提示PROMP</span>
        <span class="p">{</span><span class="s2">&#34;role&#34;</span><span class="p">:</span> <span class="s2">&#34;user&#34;</span><span class="p">,</span> <span class="s2">&#34;content&#34;</span><span class="p">:</span> <span class="n">COMMENT_CONTENT</span><span class="p">}</span> <span class="c1">#评论文本</span>
    <span class="p">],</span>
    <span class="n">response_model</span> <span class="o">=</span> <span class="n">Sentiment</span><span class="p">,</span>
    <span class="n">max_retries</span> <span class="o">=</span> <span class="mi">3</span>
<span class="p">)</span>


<span class="nb">print</span><span class="p">(</span><span class="n">resp</span><span class="o">.</span><span class="n">model_dump_json</span><span class="p">(</span><span class="n">indent</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">{
  &#34;senti_label&#34;: &#34;neg&#34;,
  &#34;senti_score&#34;: -0.65
}
CPU times: user 44.4 ms, sys: 6.46 ms, total: 50.8 ms
Wall time: 1 s
</code></pre></div><p>运行一条评论耗时 1 s， 该评论为 <em><strong>负面neg</strong></em>,  情感分 <em><strong>-0.65</strong></em>。</p>
<br>
<br>
<h2 id="五-完整代码">五、 完整代码<a hidden class="anchor" aria-hidden="true" href="#五-完整代码">#</a></h2>
<p>由于大模型速度非常缓慢，一次提问耗时几秒， 如果大规模使用大模型对数据进行数据标注， 速度慢的令人抓狂。 这时候写代码就有同步代码和异步代码之分。</p>
<ul>
<li><strong>同步代码</strong> 按照顺序执行，每个任务必须等待前一个任务完成后才能开始。适用于处理少量数据或不需要高并发性能的情况。</li>
<li><strong>异步代码</strong> 允许并发执行多个任务，适合处理大量数据时提高效率。使用<code>asyncio</code>库来实现异步操作。</li>
</ul>
<p>本章节是情感分析实验代码的收官章节， 设计了 <strong>同步代码</strong> 和 <strong>异步代码</strong> 两个版本， 并在本章末进行了任务耗时(速度)对比。</p>
<h3 id="51-同步代码">5.1 同步代码<a hidden class="anchor" aria-hidden="true" href="#51-同步代码">#</a></h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="o">%%</span><span class="n">time</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>
<span class="kn">from</span> <span class="nn">openai</span> <span class="kn">import</span> <span class="n">OpenAI</span>
<span class="kn">from</span> <span class="nn">pydantic</span> <span class="kn">import</span> <span class="n">BaseModel</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">List</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">instructor</span>

 

<span class="c1">#结构化输出</span>
<span class="k">class</span> <span class="nc">Sentiment</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>
    <span class="n">senti_label</span><span class="p">:</span> <span class="nb">str</span>
    <span class="n">senti_score</span><span class="p">:</span> <span class="nb">float</span>
    

<span class="c1">#Prompt提示</span>
<span class="n">PROMPT_TEXT</span> <span class="o">=</span> <span class="s2">&#34;根据评论内容，返回文本的情感类别(pos、neg)和情感得分(取值范围 -1~1)&#34;</span> 

<span class="n">client</span> <span class="o">=</span> <span class="n">instructor</span><span class="o">.</span><span class="n">from_openai</span><span class="p">(</span>
    <span class="n">OpenAI</span><span class="p">(</span>
        <span class="n">base_url</span><span class="o">=</span><span class="s2">&#34;http://localhost:11434/v1&#34;</span><span class="p">,</span>
        <span class="n">api_key</span><span class="o">=</span><span class="s2">&#34;NA&#34;</span><span class="p">,</span>  <span class="c1"># required, but unused</span>
    <span class="p">),</span>
    <span class="n">mode</span> <span class="o">=</span> <span class="n">instructor</span><span class="o">.</span><span class="n">Mode</span><span class="o">.</span><span class="n">JSON</span><span class="p">,</span>
<span class="p">)</span>


<span class="n">labels</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">scores</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1">#读取数据</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;data.csv&#39;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">review</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;review&#39;</span><span class="p">]):</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">resp</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">chat</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
        <span class="n">model</span> <span class="o">=</span> <span class="s1">&#39;qwen2.5:7b&#39;</span><span class="p">,</span>  <span class="c1">#选择模型。 0.5b、1.5b、3b、7b等</span>
        <span class="n">messages</span><span class="o">=</span><span class="p">[</span>
            <span class="p">{</span><span class="s2">&#34;role&#34;</span><span class="p">:</span> <span class="s2">&#34;system&#34;</span><span class="p">,</span> <span class="s2">&#34;content&#34;</span><span class="p">:</span> <span class="n">PROMPT_TEXT</span><span class="p">},</span>  <span class="c1">#提示</span>
            <span class="p">{</span><span class="s2">&#34;role&#34;</span><span class="p">:</span> <span class="s2">&#34;user&#34;</span><span class="p">,</span> <span class="s2">&#34;content&#34;</span><span class="p">:</span> <span class="n">review</span><span class="p">}</span>   <span class="c1">#评论文本</span>
        <span class="p">],</span>
        <span class="n">response_model</span> <span class="o">=</span> <span class="n">Sentiment</span><span class="p">,</span>
        <span class="n">max_retries</span> <span class="o">=</span> <span class="mi">3</span>
    <span class="p">)</span>
        
        <span class="n">labels</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">resp</span><span class="o">.</span><span class="n">senti_label</span><span class="p">)</span>
        <span class="n">scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">resp</span><span class="o">.</span><span class="n">senti_score</span><span class="p">)</span>
    <span class="k">except</span><span class="p">:</span>
        <span class="n">labels</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">&#39;NA&#39;</span><span class="p">)</span>
        <span class="n">scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">&#39;NA&#39;</span><span class="p">)</span>
        
        
    
    
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;SentiLabel&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">labels</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;SentiScore&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">scores</span>
<span class="c1">#保存结果</span>
<span class="n">df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;qwen2.5-7b-result.csv&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">df</span>
</code></pre></div><p><img loading="lazy" src="img/07-df.png" alt=""  />
</p>
<br>
<h3 id="52-异步代码">5.2 异步代码<a hidden class="anchor" aria-hidden="true" href="#52-异步代码">#</a></h3>
<p>相比 <em><strong>5.1普通代码</strong></em> ， 异步代码运行速度更快。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">tqdm.asyncio</span> <span class="kn">import</span> <span class="n">tqdm_asyncio</span>
<span class="c1"># 使用AsyncOpenAI代替OpenAI以支持异步操作</span>
<span class="kn">from</span> <span class="nn">openai</span> <span class="kn">import</span> <span class="n">AsyncOpenAI</span>
<span class="kn">from</span> <span class="nn">pydantic</span> <span class="kn">import</span> <span class="n">BaseModel</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">List</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">instructor</span>
<span class="kn">import</span> <span class="nn">asyncio</span>

<span class="c1"># 结构化输出</span>
<span class="k">class</span> <span class="nc">Sentiment</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>
    <span class="n">senti_label</span><span class="p">:</span> <span class="nb">str</span>
    <span class="n">senti_score</span><span class="p">:</span> <span class="nb">float</span>

<span class="c1"># Prompt提示</span>
<span class="n">PROMPT_TEXT</span> <span class="o">=</span> <span class="s2">&#34;根据评论内容，返回文本的情感类别(pos、neg)和情感得分(取值范围 -1~1)&#34;</span>

<span class="n">client</span> <span class="o">=</span> <span class="n">instructor</span><span class="o">.</span><span class="n">from_openai</span><span class="p">(</span>
    <span class="n">AsyncOpenAI</span><span class="p">(</span>
        <span class="n">base_url</span><span class="o">=</span><span class="s2">&#34;http://localhost:11434/v1&#34;</span><span class="p">,</span>
        <span class="n">api_key</span><span class="o">=</span><span class="s2">&#34;NA&#34;</span><span class="p">,</span>  <span class="c1"># required, but unused</span>
    <span class="p">),</span>
    <span class="n">mode</span><span class="o">=</span><span class="n">instructor</span><span class="o">.</span><span class="n">Mode</span><span class="o">.</span><span class="n">JSON</span><span class="p">,</span>
<span class="p">)</span>

<span class="k">async</span> <span class="k">def</span> <span class="nf">analyze_review</span><span class="p">(</span><span class="n">review</span><span class="p">):</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">resp</span> <span class="o">=</span> <span class="k">await</span> <span class="n">client</span><span class="o">.</span><span class="n">chat</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
            <span class="n">model</span><span class="o">=</span><span class="s1">&#39;qwen2.5:7b&#39;</span><span class="p">,</span>  <span class="c1"># 选择模型。 3b、7b等</span>
            <span class="n">messages</span><span class="o">=</span><span class="p">[</span>
                <span class="p">{</span><span class="s2">&#34;role&#34;</span><span class="p">:</span> <span class="s2">&#34;system&#34;</span><span class="p">,</span> <span class="s2">&#34;content&#34;</span><span class="p">:</span> <span class="n">PROMPT_TEXT</span><span class="p">},</span>  <span class="c1"># 提示</span>
                <span class="p">{</span><span class="s2">&#34;role&#34;</span><span class="p">:</span> <span class="s2">&#34;user&#34;</span><span class="p">,</span> <span class="s2">&#34;content&#34;</span><span class="p">:</span> <span class="n">review</span><span class="p">}</span>  <span class="c1"># 评论文本</span>
            <span class="p">],</span>
            <span class="n">response_model</span><span class="o">=</span><span class="n">Sentiment</span><span class="p">,</span>
            <span class="n">max_retries</span><span class="o">=</span><span class="mi">3</span>  <span class="c1"># 最大(失败）的重试次数。</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">resp</span><span class="o">.</span><span class="n">senti_label</span><span class="p">,</span> <span class="n">resp</span><span class="o">.</span><span class="n">senti_score</span>
    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;Error processing review: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
        <span class="k">return</span> <span class="s1">&#39;NA&#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>

<span class="k">async</span> <span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="c1"># 读取数据</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;data.csv&#39;</span><span class="p">)</span>
    <span class="n">tasks</span> <span class="o">=</span> <span class="p">[</span><span class="n">analyze_review</span><span class="p">(</span><span class="n">review</span><span class="p">)</span> <span class="k">for</span> <span class="n">review</span> <span class="ow">in</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;review&#39;</span><span class="p">]]</span>
    <span class="n">results</span> <span class="o">=</span> <span class="k">await</span> <span class="n">tqdm_asyncio</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="o">*</span><span class="n">tasks</span><span class="p">)</span>
    
    <span class="n">labels</span><span class="p">,</span> <span class="n">scores</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">results</span><span class="p">)</span>
    <span class="n">df</span><span class="p">[</span><span class="s1">&#39;SentiLabel&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">labels</span>
    <span class="n">df</span><span class="p">[</span><span class="s1">&#39;SentiScore&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">scores</span>
    
    <span class="c1"># 保存结果</span>
    <span class="n">df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;async-qwen2.5-7b-result.csv&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># 检查是否已经在运行的事件循环中</span>
<span class="k">try</span><span class="p">:</span>
    <span class="n">asyncio</span><span class="o">.</span><span class="n">get_running_loop</span><span class="p">()</span>
    <span class="c1"># 如果在交互模式下运行，直接调度main()而不使用asyncio.run</span>
    <span class="n">asyncio</span><span class="o">.</span><span class="n">create_task</span><span class="p">(</span><span class="n">main</span><span class="p">())</span>
<span class="k">except</span> <span class="ne">RuntimeError</span><span class="p">:</span>
    <span class="c1"># 如果没有正在运行的事件循环，使用asyncio.run(main())</span>
    <span class="n">asyncio</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">main</span><span class="p">())</span>
</code></pre></div><br>
<h3 id="53-速度对比">5.3 速度对比<a hidden class="anchor" aria-hidden="true" href="#53-速度对比">#</a></h3>
<p>以<em><strong>qwen2.5:7b</strong></em>为例， 对本文 <em><strong>data.csv</strong></em> 在线评论数据进行情感分析，</p>
<ul>
<li><strong>普通代码</strong> 运行耗时 <strong>160</strong> 秒</li>
<li><strong>异步代码</strong> 运行耗时 <strong>90</strong> 秒</li>
</ul>
<br>
<p><br><br></p>
<h2 id="六评价模型">六、评价模型<a hidden class="anchor" aria-hidden="true" href="#六评价模型">#</a></h2>
<p>本文分别对0.5b、1.5b、3b、7b进行实验， 记录了200条外卖评论的任务耗时(以同步代码为例）和准确率， 结果如下</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">|  模型  | 模型参数 | 任务耗时(秒) | 准确率 |
| ----- | ------  |  --------  | ----- |
|qwen2.5|   0.5b  |     260s   | 1.5%  |
|qwen2.5|   1.5b  |    48.5s   | 58.5% |
|qwen2.5|    3b   |     140s   |  86%  |
|qwen2.5|    7b   |     160s   |  87.5% |
</code></pre></div><p>综合任务耗时和准确率， 建议使用 <em><strong>qwen2.5:3b</strong></em> 和 <em><strong>qwen2.5:7b</strong></em> 。如果电脑性能很好，直接上  <em><strong>qwen2.5:7b</strong></em>  甚至更大参数的模型。</p>
<h3 id="tips准确率计算方法">Tips:准确率计算方法<a hidden class="anchor" aria-hidden="true" href="#tips准确率计算方法">#</a></h3>
<p>假设label为1时， <em><strong>SentiLabel</strong></em> 为pos(或label为0时， SentiLabel为neg)， 大模型判断正确。反之，判断失误。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">expression</span> <span class="o">=</span> <span class="s2">&#34;(label == 1) &amp; (sentiment == &#39;pos&#39;) | (label == 0) &amp; (sentiment == &#39;neg&#39;)&#34;</span>
<span class="n">correct_ratio</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="n">expression</span><span class="p">))</span><span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;准确率: </span><span class="si">{</span><span class="n">correct_ratio</span><span class="o">*</span><span class="mi">100</span><span class="si">}</span><span class="s1">%&#39;</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">准确率: 86%
</code></pre></div><p><br><br></p>
<h2 id="七获取代码">七、获取代码<a hidden class="anchor" aria-hidden="true" href="#七获取代码">#</a></h2>
<p><a href="project.zip"><strong>点击下载本文代码</strong></a></p>
<p><br><br></p>
<h2 id="相关内容">相关内容<a hidden class="anchor" aria-hidden="true" href="#相关内容">#</a></h2>
<ul>
<li><a href="https://textdata.cn/blog/2025-02-17-gpt-is-an-effective-tool-for-multilingual-psychological-text-analysis/"><strong>文献 | GPT 是多语言心理文本分析的有效工具</strong></a></li>
<li><a href="https://textdata.cn/blog/2024-06-14-how-to-download-large-language-model-with-ollama/"><strong>教程 | 如何使用 Ollama 下载 &amp; 使用本地大语言模型</strong></a></li>
<li><a href="https://textdata.cn/blog/2024-08-07-structured-outputs-with-ollama/"><strong>实验 | 如何使 Ollama 结构化输出 JSON 样式的结果</strong></a></li>
<li><a href="https://textdata.cn/blog/2024-04-27-cntext2x-usage-tutorial/"><strong>推荐 | 文本分析库cntext2.x使用手册</strong></a></li>
<li><a href="https://textdata.cn/blog/2024-06-14-using-large-language-model-to-extract-structure-data-from-raw-text/"><strong>实验 | 使用本地大模型从文本中提取结构化信息</strong></a></li>
<li><a href="https://textdata.cn/blog/2024-07-10-using-large-language-model-to-build-diy-dictionary/">实验 | 使用Ollama本地大模型DIY制作单词书教案PDF</a></li>
<li><a href="https://textdata.cn/blog/2024-08-05-create-a-blog-writer-multi-agent-system-using-crewai-and-ollama/">实验 | 使用 Crewai 和 Ollama 构建智能体(AI Agent)帮我撰写博客文章</a></li>
</ul>
<p><br><br></p>
<h2 id="精选内容">精选内容<a hidden class="anchor" aria-hidden="true" href="#精选内容">#</a></h2>
<ul>
<li><a href="https://textdata.cn/blog/datasets_available_for_management_science/">LIST | 可供社科(经管)领域使用的数据集汇总</a></li>
<li><a href="https://textdata.cn/blog/the_text_analysis_list_about_ms/">LIST | 社科(经管)数据挖掘文献资料汇总</a></li>
<li><a href="https://textdata.cn/blog/2024-06-16-scrapegraph-ai/">网络爬虫 | 使用scrapegraph-ai(大模型方案)自动采集网页数据</a></li>
<li><a href="https://textdata.cn/blog/2024-04-27-cntext2x-usage-tutorial/">推荐 | 文本分析库cntext2.x使用手册</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
<li><a href="https://textdata.cn/blog/2024-06-14-using-large-language-model-to-extract-structure-data-from-raw-text/">实验 | 使用本地大模型从文本中提取结构化信息</a>
<br>
<br></li>
</ul>


  </div>


  <br>

  <div style="text-align: center;">
    <figure >
        <a href="https://textdata.cn/blog/management_python_course/">
            <img src="/images/bg/management_data_mining_with_python_course2.png" width="100%" />
        </a>
        <figcaption><small><i>点击了解课程详情</i></small></figcaption>
    </figure>
  </div>

  <br>


  <div style="margin-top:2em;padding:0 0.5em;font-size:.875rem">
    <hr>
    <div style="padding-bottom:1em;">
        <p>本文作者：大邓
        <p>本文标题：实验 | 使用本地大模型预测在线评论情感类别和分值
        <p>本文链接：https://textdata.cn/blog/2024-08-06-using-the-ollama-local-large-model-to-predict-the-sentiment-category-of-online-comments/
        <p>版权声明：<a href="https://creativecommons.org/licenses/by-nc/4.0/" target="_blank">「署名-非商业性使用-相同方式共享 4.0 国际」</a></p>
    </div>
    <hr>
  </div>






  <footer class="post-footer">
      <ul class="post-tags">
        <b>Tags:  &nbsp;</b>
        <li><a href="/tags/llm/" target='_blank'>LLM</a></li>
        <li><a href="/tags/%E6%96%87%E6%9C%AC%E5%88%86%E6%9E%90/" target='_blank'>文本分析</a></li>
      </ul>


<div class="share-buttons">
    <a target="_blank" rel="noopener noreferrer" aria-label="share 实验 | 使用本地大模型预测在线评论情感类别和分值 on twitter"
        href="https://twitter.com/intent/tweet/?text=%e5%ae%9e%e9%aa%8c%20%7c%20%e4%bd%bf%e7%94%a8%e6%9c%ac%e5%9c%b0%e5%a4%a7%e6%a8%a1%e5%9e%8b%e9%a2%84%e6%b5%8b%e5%9c%a8%e7%ba%bf%e8%af%84%e8%ae%ba%e6%83%85%e6%84%9f%e7%b1%bb%e5%88%ab%e5%92%8c%e5%88%86%e5%80%bc&amp;url=%2fblog%2f2024-08-06-using-the-ollama-local-large-model-to-predict-the-sentiment-category-of-online-comments%2f&amp;hashtags=LLM%2c%e6%96%87%e6%9c%ac%e5%88%86%e6%9e%90">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-253.927,424.544c135.939,0 210.268,-112.643 210.268,-210.268c0,-3.218 0,-6.437 -0.153,-9.502c14.406,-10.421 26.973,-23.448 36.935,-38.314c-13.18,5.824 -27.433,9.809 -42.452,11.648c15.326,-9.196 26.973,-23.602 32.49,-40.92c-14.252,8.429 -30.038,14.56 -46.896,17.931c-13.487,-14.406 -32.644,-23.295 -53.946,-23.295c-40.767,0 -73.87,33.104 -73.87,73.87c0,5.824 0.613,11.494 1.992,16.858c-61.456,-3.065 -115.862,-32.49 -152.337,-77.241c-6.284,10.881 -9.962,23.601 -9.962,37.088c0,25.594 13.027,48.276 32.95,61.456c-12.107,-0.307 -23.448,-3.678 -33.41,-9.196l0,0.92c0,35.862 25.441,65.594 59.311,72.49c-6.13,1.686 -12.72,2.606 -19.464,2.606c-4.751,0 -9.348,-0.46 -13.946,-1.38c9.349,29.426 36.628,50.728 68.965,51.341c-25.287,19.771 -57.164,31.571 -91.8,31.571c-5.977,0 -11.801,-0.306 -17.625,-1.073c32.337,21.15 71.264,33.41 112.95,33.41Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share 实验 | 使用本地大模型预测在线评论情感类别和分值 on linkedin"
        href="https://www.linkedin.com/shareArticle?mini=true&amp;url=%2fblog%2f2024-08-06-using-the-ollama-local-large-model-to-predict-the-sentiment-category-of-online-comments%2f&amp;title=%e5%ae%9e%e9%aa%8c%20%7c%20%e4%bd%bf%e7%94%a8%e6%9c%ac%e5%9c%b0%e5%a4%a7%e6%a8%a1%e5%9e%8b%e9%a2%84%e6%b5%8b%e5%9c%a8%e7%ba%bf%e8%af%84%e8%ae%ba%e6%83%85%e6%84%9f%e7%b1%bb%e5%88%ab%e5%92%8c%e5%88%86%e5%80%bc&amp;summary=%e5%ae%9e%e9%aa%8c%20%7c%20%e4%bd%bf%e7%94%a8%e6%9c%ac%e5%9c%b0%e5%a4%a7%e6%a8%a1%e5%9e%8b%e9%a2%84%e6%b5%8b%e5%9c%a8%e7%ba%bf%e8%af%84%e8%ae%ba%e6%83%85%e6%84%9f%e7%b1%bb%e5%88%ab%e5%92%8c%e5%88%86%e5%80%bc&amp;source=%2fblog%2f2024-08-06-using-the-ollama-local-large-model-to-predict-the-sentiment-category-of-online-comments%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share 实验 | 使用本地大模型预测在线评论情感类别和分值 on reddit"
        href="https://reddit.com/submit?url=%2fblog%2f2024-08-06-using-the-ollama-local-large-model-to-predict-the-sentiment-category-of-online-comments%2f&title=%e5%ae%9e%e9%aa%8c%20%7c%20%e4%bd%bf%e7%94%a8%e6%9c%ac%e5%9c%b0%e5%a4%a7%e6%a8%a1%e5%9e%8b%e9%a2%84%e6%b5%8b%e5%9c%a8%e7%ba%bf%e8%af%84%e8%ae%ba%e6%83%85%e6%84%9f%e7%b1%bb%e5%88%ab%e5%92%8c%e5%88%86%e5%80%bc">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share 实验 | 使用本地大模型预测在线评论情感类别和分值 on facebook"
        href="https://facebook.com/sharer/sharer.php?u=%2fblog%2f2024-08-06-using-the-ollama-local-large-model-to-predict-the-sentiment-category-of-online-comments%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share 实验 | 使用本地大模型预测在线评论情感类别和分值 on whatsapp"
        href="https://api.whatsapp.com/send?text=%e5%ae%9e%e9%aa%8c%20%7c%20%e4%bd%bf%e7%94%a8%e6%9c%ac%e5%9c%b0%e5%a4%a7%e6%a8%a1%e5%9e%8b%e9%a2%84%e6%b5%8b%e5%9c%a8%e7%ba%bf%e8%af%84%e8%ae%ba%e6%83%85%e6%84%9f%e7%b1%bb%e5%88%ab%e5%92%8c%e5%88%86%e5%80%bc%20-%20%2fblog%2f2024-08-06-using-the-ollama-local-large-model-to-predict-the-sentiment-category-of-online-comments%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share 实验 | 使用本地大模型预测在线评论情感类别和分值 on telegram"
        href="https://telegram.me/share/url?text=%e5%ae%9e%e9%aa%8c%20%7c%20%e4%bd%bf%e7%94%a8%e6%9c%ac%e5%9c%b0%e5%a4%a7%e6%a8%a1%e5%9e%8b%e9%a2%84%e6%b5%8b%e5%9c%a8%e7%ba%bf%e8%af%84%e8%ae%ba%e6%83%85%e6%84%9f%e7%b1%bb%e5%88%ab%e5%92%8c%e5%88%86%e5%80%bc&amp;url=%2fblog%2f2024-08-06-using-the-ollama-local-large-model-to-predict-the-sentiment-category-of-online-comments%2f">
        <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28">
            <path
                d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
        </svg>
    </a>
    
</div>




  </footer><script src="https://utteranc.es/client.js"
        repo="hiDaDeng/hidadeng.github.io"
        issue-term="pathname"
        theme="preferred-color-scheme"
        crossorigin="anonymous"
        async>
</script>

  
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2025 <a href="/">大邓和他的PYTHON</a></span>
</footer>
<a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerText = 'Copy';

        function copyingDone() {
            copybutton.innerText = 'Copied!';
            setTimeout(() => {
                copybutton.innerText = 'Copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>


    
    
</body>

</html>
