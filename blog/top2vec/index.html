<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Top2Vec|主题建模和语义搜索库 | 大邓和他的PYTHON</title>
<meta name="keywords" content="词向量, 文本分析, 第三方包" />
<meta name="description" content="越来越多的美国年轻人拍一段自己的短视频，放在 TikTok 上面求职，请求看到的人转发">
<meta name="author" content="大邓">
<link rel="canonical" href="/blog/top2vec/" />
<link crossorigin="anonymous" href="/assets/css/stylesheet.min.css" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/assets/js/highlight.min.js" onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="apple-touch-icon" href="/apple-touch-icon.png">
<link rel="mask-icon" href="/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<meta name="generator" content="Hugo 0.89.4" />
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:title" content="Top2Vec|主题建模和语义搜索库" />
<meta property="og:description" content="越来越多的美国年轻人拍一段自己的短视频，放在 TikTok 上面求职，请求看到的人转发" />
<meta property="og:type" content="article" />
<meta property="og:url" content="/blog/top2vec/" />
<meta property="og:image" content="/images/blog/top2vec.png" /><meta property="article:section" content="blog" />
<meta property="article:published_time" content="2021-12-13T10:43:10&#43;06:00" />
<meta property="article:modified_time" content="2021-12-13T10:43:10&#43;06:00" />

<meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:image" content="/images/blog/top2vec.png" />
<meta name="twitter:title" content="Top2Vec|主题建模和语义搜索库"/>
<meta name="twitter:description" content="越来越多的美国年轻人拍一段自己的短视频，放在 TikTok 上面求职，请求看到的人转发"/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Blogs",
      "item": "/blog/"
    }
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Top2Vec|主题建模和语义搜索库",
      "item": "/blog/top2vec/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Top2Vec|主题建模和语义搜索库",
  "name": "Top2Vec|主题建模和语义搜索库",
  "description": "越来越多的美国年轻人拍一段自己的短视频，放在 TikTok 上面求职，请求看到的人转发",
  "keywords": [
    "词向量", "文本分析", "第三方包"
  ],
  "articleBody": "Top2Vec 是一种用于主题建模和语义搜索的算法。**我个人从理解代码和使用代码难度来看， 对于Python小白，BERTopic更适合直接用预训练词向量，而Top2Vec更适合对小规模数据训练词向量后做主题建模。**它自动检测文本中存在的主题并生成联合嵌入的主题、文档和词向量。训练 Top2Vec 模型后，您可以：\n 获取检测到的主题数。 获取话题。 获取主题大小。 获取分层主题。 按关键字搜索主题。 按主题搜索文档。 按关键字搜索文档。 找出相似的词。 查找类似的文档。 使用 RESTful-Top2Vec 公开模型 有关其工作原理的更多详细信息，请参阅论文。  亮点\n 自动查找主题数。 不需要停用词列表。 不需要词干/词形还原。 适用于短文本。 创建联合嵌入的主题、文档和词向量。 内置搜索功能。  它是如何工作的？\n该算法做出的假设是，许多语义相似的文档都表明了一个潜在的主题。\n第一步是创建文档和词向量的联合嵌入。一旦文档和单词被嵌入到一个向量空间中，算法的目标就是找到密集的文档集群，然后确定哪些单词将这些文档吸引到一起。每个密集区域是一个主题，将文档吸引到密集区域的词就是主题词。\n!pip3 install top2vec \n1. 导入数据 使用某灾难数据集，这里是存在标注的标签，但是我们假设不用label的，仅作为评判Top2vec运行效果的标准。点击cnews.csv下载\nfrom IPython.display import display from cntext import STOPWORDS_zh from top2vec import Top2Vec import pandas as pd import jieba df = pd.read_csv('cnews.csv') df.head()   df.label.value_counts() 时政 120 科技 106 时尚 106 财经 105 家居 103 教育 97 娱乐 96 体育 95 房产 87 游戏 85 Name: label, dtype: int64  2. 清洗数据 一般而言，作中文文本分析，需要把中文分词构造成类西方语言(空格间隔词语的文本)风格。在此期间，顺便将停用词剔除。其实在用top2vec时，不剔除停用词影响也不大。\ndef clean_text(text): words = jieba.lcut(text) words = [w for w in words if w not in STOPWORDS_zh] return ' '.join(words) df['cleantext'] = df.text.apply(clean_text) df.head()   3. 训练模型 Top2vec有一下四个常用参数\nTop2vec(documents, min_count, speed, workers)\n documents: 文档列表 min_count: 词语最少出现次数。低于min_count的词不加入模型中 speed: 训练速度，参数默认\"learn\"  “fast-learn” 速度最快，训练效果最差 “learn” 速度，训练效果中等 “deep-learn” 速度最慢，训练效果最佳   workers: 并行运行数，该值最大取值为电脑CPU的核数。  model = Top2Vec(documents=df['cleantext'].to_list(), min_count=10, speed=\"deep-learn\", workers=8) 2021-12-14 20:21:10,318 - top2vec - INFO - Pre-processing documents for training 2021-12-14 20:21:10,871 - top2vec - INFO - Creating joint document/word embedding 2021-12-14 20:25:06,082 - top2vec - INFO - Creating lower dimension embedding of documents 2021-12-14 20:25:14,645 - top2vec - INFO - Finding dense areas of documents 2021-12-14 20:25:14,683 - top2vec - INFO - Finding topics  # 话题个数 model.get_num_topics() 11  # 各话题数量 topic_sizes, topic_nums = model.get_topic_sizes() {\"topic_sizes\":topic_sizes, \"topic_ids\":topic_nums} {'topic_sizes': array([116, 108, 105, 104, 100, 97, 95, 94, 89, 74, 18]), 'topic_ids': array([ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10])}  4. get_topics 用pyecharts词云图显示话题信息， 为了简化代码，将该功能封装为函数\ndef gen_wordcloud(topic_words, word_scores, topic_id): \"\"\" topic_words: 主题词列表 word_scores: 主题特征词的权重得分(词语表征主题的能力) topic_id: 主题id \"\"\" import pyecharts.options as opts from pyecharts.charts import WordCloud from IPython.display import display data = [(word, str(weight)) for word, weight in zip(topic_words, word_scores)] wc = WordCloud() wc.add(series_name=\"\", data_pair=data, word_size_range=[6, 88]) wc.set_global_opts( title_opts=opts.TitleOpts(title=\"Topic_{topic_id}\".format(topic_id=topic_id), title_textstyle_opts=opts.TextStyleOpts(font_size=23)), tooltip_opts=opts.TooltipOpts(is_show=True)) display(wc.render_notebook()) topic_wordss, word_scoress, topic_ids = model.get_topics(11) for topic_words, word_scores, topic_id in zip(topic_wordss, word_scoress, topic_ids): gen_wordcloud(topic_words, word_scores, topic_id)         5. get_documents_topics get_documents_topics(doc_ids, num_topics=1)\n doc_ids: 待查询文档id列表 num_topics: 返回某文档可能归属话题的个数    # 查第一条文档的 model.get_documents_topics(doc_ids=[0], num_topics=1) (array([9]), array([0.13393445], dtype=float32), array([['留学', '学生', '申请', '签证', '大学', '学费', '本科', '名校', '留学生', '加拿大', '课程', '申请者', '院校', '学校', '移民', '英国', '高等教育', '教育', '录取', '高中生', '出国', '人数', '高中', '学位', '就读', '生活费', '家长', '澳大利亚', '申请人', '预科', '美国', '该国', '新政', '招生', '文凭', '学士学位', '公立', '私立', '攻读', '高校', '绿卡', '升学', '学历', '雅思', '入学', '资助', '移民部', '技术移民', '万至', '学期']], dtype=' 6. search_topics 根据关键词搜索话题，查某词是否属于某话题，属于该主题的概率 search_topics(keywords, num_topics, keywords_neg=None)\n keywords: 关键词列表 num_topics: 返回话题个数，按照语义相似度从高到低排序 keywords_neg: 反义词列表  def gen_wordcloud2(query_word, topic_words, word_scores, topic_id, topic_probability): \"\"\" query_word: 待查询词 topic_words: 主题词列表 word_scores: 主题特征词的权重得分(词语表征主题的能力) topic_id: 主题id topic_probability: 主题概率 \"\"\" import pyecharts.options as opts from pyecharts.charts import WordCloud from IPython.display import display data = [(word, str(weight)) for word, weight in zip(topic_words, word_scores)] wc = WordCloud() wc.add(series_name=\"\", data_pair=data, word_size_range=[6, 88]) title = \"\"\"Word{query_word}\\nTopic_{topic_id}\\nProbability:{probability:.2f}\"\"\".format(query_word=query_word, topic_id=topic_id, probability=topic_probability) wc.set_global_opts( title_opts=opts.TitleOpts(title=title, title_textstyle_opts=opts.TextStyleOpts(font_size=18)), tooltip_opts=opts.TooltipOpts(is_show=True)) display(wc.render_notebook()) query_word = \"电影\" topic_wordss, word_scoress, topic_scores, topic_ids = model.search_topics(keywords=[query_word], num_topics=4) for topic_words, word_scores, topic_score, topic_id in zip(topic_wordss, word_scoress, topic_scores, topic_ids): if topic_score0.5: gen_wordcloud2(query_word=query_word, topic_words=topic_words, word_scores=word_scores, topic_id=topic_id, topic_probability=topic_score)   7. query_topics 根据一段文本寻找最符合该文本的话题 query_topics(query, num_topics)\n query: 查询文本，注意是用空格间隔词语的文本 num_topics: 返回的话题数  返回话题特征词列表， 话题特征词权重， 话题概率， 话题id\nquerytext = '刘晓庆 55 岁 近日 颁奖礼 刘晓庆 一袭 宝蓝色 超低 胸 V 领 长裙 亮相 轻薄 蕾丝 奢华 皮草 艳丽 色彩 翠绿' topic_words, word_scores, topic_scores, topic_ids = model.query_topics(query=querytext, num_topics=2) print('可能归属的话题有: ', topic_ids) print('归属于该话题的概率', topic_scores) 可能归属的话题有: [1 4] 归属于该话题的概率 [0.3688392 0.21418373]  8. search_documents_by_keywords 根据关键词，筛选文档\nsearch_documents_by_keywords(keywords, num_docs, keywords_neg=None, return_documents=True)\n#文档， 语义相关性， 文档id docs, scores, doc_ids = model.search_documents_by_keywords(keywords=['搭配'], num_docs=3, keywords_neg=None, return_documents=True) for doc, score, doc_id in zip(docs, scores, doc_ids): print(f\"Document: {doc_id}, Semantic similarity: {score}\") print(doc) print('----------') print() Document: 870, Semantic similarity: 0.46936729550361633 组图 看达人 演绎 豹纹 军装 风 导语 懂得 潮流 总是 知道 适合 今冬 流行 亮点 太 军装 豹纹 类似 民族风情 想要 知道 搭配 快 看看 时尚 达 穿 军绿色 宽松 款 大衣 不失 俏皮 味道 高腰 设计 短裙 有效 提升 腰线 衬托出 修长 美腿 豹纹 今年 冬季 抢眼 搭配 元素 加上 驼色 针织衫 灰色 围巾 暖 棕色 手 挎包 整体 色调 统一 迷人 棕色 蓝色 结合能 眼前一亮 简洁 款式 依然 突显 独特 品味 宽松 针织 外套 衬托出 优美 身形 搭配 同样 沉闷 黑色 包包 性感 丝袜 装扮 依然 透露 出 迷人 气息 立领 衬衫 加上 深黄 高腰 裤 摩登 感 十足 随意 披上 外套 更显 慵懒 个性 法式 风情 ---------- Document: 450, Semantic similarity: 0.46842482686042786 街 拍 爱 招摇过市 毛茸茸 ( 组图 ) 导语 皮草 每个 冬天 可能 丢弃 每个 需要 温暖 早些 相比 人造皮 草比 真皮 草 风头 更劲 时尚 环保 大牌 秀 场上 超模 一个个 穿着 人造皮 草 “ 招摇过市 ” 之后 街头 潮人 没有 理由 拒绝 外形 酷酷 这件 气场 皮草 单品 配合默契 摇滚 风 配饰 搭配 黑色 皮草 长 背心 更显 利落 酷酷 黑色 皮草 搭配 蓝色 衬衣 不同 感觉 加上 下半身 底裤 时髦 包包 颜色 提亮 整身 装扮 抹胸 式 皮草 特点 高贵典雅 适合 搭配 连衣裙 装饰 增添 时尚 美感 复古 圆点 连衣裙 搭配 宽松 棕色 皮草 衣 名媛 感觉 典雅 淑女 短款 黑色 皮草 搭配 贴身 仔裤 搭配 长靴 潇洒 帅气 茸茸 帽子 增添 不少 甜美 感 ---------- Document: 665, Semantic similarity: 0.45364660024642944 组图 韩国 明星 街 拍 各显 本色 魅力 导语 很多 迷 韩剧 剧中 女星 逐渐 变成 家喻户晓 红人 韩 剧中 靓丽 女星 示范 想 靓丽 成为 众人 瞩目 焦点 摆脱 荧幕 光环 现实 中是 李孝利 韩国 有人 气 女歌手 走红 速度 之快 成为 影视 歌 多方面 艺人 街 拍图 成为 众相 追捧 对象 身 装扮 休闲 个性 典型 风格 棒球帽 字母 T恤 简单 活力 下身 裙裤 透露 出 少女 气息 搭配 毛线 靴 青春 气息 迎面而来 想 卫衣 穿 出 时尚 感 学学 拼接 色 卫衣 搭配 牛仔 短裤 帅气 亮面 底裤 更显 腿部 线条 打造 野性 装扮 一件 豹纹 外套 搞定 下身 搭配 短裤 短裙 露出 性感美 腿 挎 一个 ----------  9. search_documents_by_topic 根据指定的topic_id， 显示该主题前num_docs个文档，显示的文档是根据概率从高到低降序显示\n#查看topic4的前5条文档 topic_id = 4 documents, document_scores, document_ids = model.search_documents_by_topic(topic_num=topic_id, num_docs=5) for doc, score, doc_id in zip(documents, document_scores, document_ids): print(f\"Document: {doc_id}, Semantic similarity: {score}\") print(\"-----------\") print(doc) print(\"-----------\") print() Document: 91, Semantic similarity: 0.4055505692958832 ----------- 遍地 狼烟 场面 恢弘 打造 精良 狙击枪 战 类型 片 新浪 娱乐 讯 电影 遍地 狼烟 12 2 上映 该片 何润东 ( 微博 ) 宋佳 ( 微博 ) 梁家辉 何晟铭 ( 微博 ) 主演 展现 狙击手 不为人知 一面 何润东 日前 透露 拍摄 该片 苦练 身材 希望 电影 能够 看起来 “ 够 爷们 ” 狙击 题材 枪战 片 遍地 狼烟 取材 狙击手 创作 初衷 导演 胡 大为 表示 “ 狙击手 生活 远远 不像 想像 简单 辛苦 危险 曾经 一位 狙击手 朋友 等待 目标 潜伏 树上 达 一周 久 枪法 百发百中 之外 狙击手 需要 经受 常人 难以忍受 痛苦 ” 希望 借由 遍地 狼烟 狙击手 不为人知 一面 呈现 观众 面前 何润东 ” ----------- Document: 392, Semantic similarity: 0.38211899995803833 ----------- 组图 大S 新片 腿 夹 色诱 古天乐 动作 搞笑 情色 新浪 娱乐 讯 大S 古天乐 结戏缘 电影 大内 密探 灵灵狗 饰演 夫妻 使出 浑身解数 色诱 古天乐 露出 性感 香肩 双脚 夹紧 画面 相当 搞笑 剧中 打斗 戏 不断 牺牲 形象 引诱 大S 挑战 笑 非常 紧张 平常 懂 搔首弄姿 如今 勾引 古天乐 不知 尴尬 ----------- Document: 265, Semantic similarity: 0.376071572303772 ----------- 危险 关系 开机 章子怡 荐 张柏芝 演 坏女孩 ( 图 ) 章子怡 推荐 张柏芝 周 冬雨 ( 微博 ) 这部 法国 经典小说 蓝本 电影 改编 多次 许秦豪 介绍 吸引 执导 该片 原因 改编 剧本 复杂 人物 关系 “ 故事 背景 选在 1930 年代 上海 里面 有人 爱情 游戏 有人 爱情 生命 关系 发展 吸引 ” 戏中 人物 到底 复杂 原来 三位 主演 饰演 女孩 坏女孩 花花公子 角色 章子怡 介绍 剧本 爱 杜芬玉 纯情 女孩 “ 剧本 感动 爱情故事 选择 女孩 修养 经历 特别 爱情 路上 坎坷 一次 心灵 挑战 到时候 知道 选 ” 制片人 陈伟明 现场 透露 原来 章子怡 推荐 张柏芝 出演 莫 婕妤 “ 坏女孩 ” 角色 对此 章子怡 坦陈 希望 演员 出演 这部 电影 推荐 过周 冬雨 演 “ 贝贝 ” “ 推荐 柏芝 是因为 合适 制片人 投资人 沟通 商量 毕竟 希望 希望 这是 一部 聚集 演员 国际化 影片 想 推荐 周 冬雨 演贝贝 角色 听说 上学 ” 张柏芝 称 爱情 “ 危险 ” 发布会 身穿 黑色 ----------- Document: 729, Semantic similarity: 0.37136194109916687 ----------- 陈小春 缺席 宝马 狂想曲 活动 熊乃谨 谈 感情 戏 新浪 娱乐 讯 10 21 电影 宝马 狂想曲 合肥 举行 观众 见面会 男主角 陈小春 ( 微博 ) 缺席 活动 女主角 熊乃谨 表示 之前 刚刚 伴娘 身份 出席 陈小春 应 采儿 ( 微博 ) 婚礼 朋友 老公 演起 感情 戏 不得不 拍 一段 闺蜜 报告 熊乃谨 好友 老公 谈恋爱 宝马 狂想曲 一部 黑色幽默 题材 电影 该片 陈小春 婚后 出演 首部 作品 饰演 极度 热爱 宝马 忠实 fans 黄德斌 梁家仁 李健仁 饰演 贼匪 团伙 进行 几度 精彩 抢夺 宝马 ----------- Document: 562, Semantic similarity: 0.36686939001083374 ----------- 黄百鸣 称用 张柏芝 值得 新片 吴君如 擦肩 ( 组图 ) 新浪 娱乐 讯 肥妈 玛利亚 担任 主席 公司 收购 10 28 香港 举行 签约 仪式 到场 嘉宾 包括 狄波拉 老公 徐小明 夫妇 黄百鸣 王晶 夏韶声 亢帅克 肥妈 表示 公司 包括 mv 制作 经理人 公司 饮食 频道 之后 开拍 一套 青春 歌舞片 并会 联络 巨星 参与 演出 支持 下一代 黄百鸣 请来 张柏芝 拍摄 贺岁片 柏芝 产后 复出 头炮 表示 这部 戏 下周 开拍 柏芝 状态 甚勇 是否 柏芝 五千万 片酬 黄百鸣 表示 合理 觉得 值得 开拍 贺岁片 少 吴君如 解释 之前 误会 君如 怀孕 接 甘国 亮 新片 TUNGSTAR / 文并 图 -----------  documents, document_scores, document_ids = model.search_documents_by_keywords(keywords=[\"搭配\", \"高跟鞋\"], num_docs=5) for doc, score, doc_id in zip(documents, document_scores, document_ids): print(f\"Document: {doc_id}, Semantic similarity: {score}\") print(\"-----------\") print(doc) print(\"-----------\") print() Document: 727, Semantic similarity: 0.5883481502532959 ----------- 组图 冷气 办公室 连衣裙 配小 坎肩 美国 设计师 Diane Von Furstenberg 曾经 感觉 女人 穿 连衣裙 女人 找到 一件 适合 dream dress 重要 无需 费神 搭配 单穿 连身 优雅 飞扬 裙摆 似乎 告诉 女 连衣裙 玩起 High Fashion 变脸 游戏 DKNY 绿色 连衣裙 新品 未 定价 H \u0026 M 黑色 外套 新品 未 定价 Agatha 配件 新品 未 定价 C . Banner 高跟鞋 新品 未 定价 低 V 领 连衣裙 秀出 属于 性感 更好 展现出 颈部 线条 搭配 修身 剪裁 西装 短款 皮手套 极具 欧美 明星 范儿 细 高跟鞋 更好 突出 双腿 长度 整体 显得 轻盈 不少 On \u0026 on 米色 连衣裙 新品 未 定价 Asobio 针织 外套 RMB 449 Kookai 金色 腰带 Jc ----------- Document: 435, Semantic similarity: 0.5440454483032227 ----------- 组图 秋冬 优雅 妖娆 女星 爱 裸 色系 导语 裸色 优雅 代名词 女星 近来 誓 裸色 进行 到底 无论是 徐若 ? 性感 乐基儿 气质 搭配 各色 礼服 赏心悦目 娇俏 款式 更是 大饱眼福 徐若 ? 飘逸 丝带 立刻 彰显 天王 嫂 贵妇 气质 袁咏仪 翻领 西装 气质 非凡 裸色 短款 紧身 西装 皮质 面料 彰显 个性 夹带 一点 蕾丝 装饰 女性 柔美 油然而生 搭配 碎花 蛋糕 裙 气质 非凡 ----------- Document: 870, Semantic similarity: 0.523485541343689 ----------- 组图 看达人 演绎 豹纹 军装 风 导语 懂得 潮流 总是 知道 适合 今冬 流行 亮点 太 军装 豹纹 类似 民族风情 想要 知道 搭配 快 看看 时尚 达 穿 军绿色 宽松 款 大衣 不失 俏皮 味道 高腰 设计 短裙 有效 提升 腰线 衬托出 修长 美腿 豹纹 今年 冬季 抢眼 搭配 元素 加上 驼色 针织衫 灰色 围巾 暖 棕色 手 挎包 整体 色调 统一 迷人 棕色 蓝色 结合能 眼前一亮 简洁 款式 依然 突显 ----------- Document: 522, Semantic similarity: 0.4756317138671875 ----------- 女星 争当 蓝色妖姬 \u0026 nbsp ; 英国 气质 女演员 瑞切尔 ・ 薇 兹 时尚 点评 英国 气质 女演员 瑞切尔 · 薇 兹 ( Rachel Weisz ) 美貌 非常 头脑 修身 印花 连衣裙 搭配 抢眼 棕红色 短 夹克 非常 好看 搭配 黑色 罗马 feel 高跟鞋 特别 有潮味 时尚 点评 身材 不算 瘦 女星 Lea Michele 搭配 起来 非常 特色 一味 地瘦 风格 满是 褶皱 裙子 非常 修身 亮眼 颜色 非常 ----------- Document: 707, Semantic similarity: 0.47334203124046326 ----------- 组图 黑丝 短裙 上阵 5 旬 女星 胜过 90 红星 导语 气温 越来越低 女星 不畏 严寒 纷纷 穿着 短裙 透视装 出席 活动 一番 比拼 不难 发现 气质 年轻 难得 厉害 一起 看看 刘晓庆 55 岁 近日 颁奖礼 刘晓庆 一袭 宝蓝色 超低 胸 V 领 长裙 亮相 轻薄 蕾丝 奢华 皮草 艳丽 色彩 翠绿 首饰 配上 短小 精炼 波波 头 瞬间 减龄 15 岁 张曼玉 46 岁 一向 气质 型 美女 著称 反倒 少 繁琐 修饰 刻意 打扮 超级 简单 Lanvin for H \u0026 M 斜肩 礼裙 搭配 一双 皮质 手套 -----------  10. get_topic_hierarchy 对话题进行分类，需要\n 先执行model.hierarchical_topic_reduction 再执行model.get_topic_hierarchy。  # 将话题分为2类 model.hierarchical_topic_reduction(num_topics=2) model.get_topic_hierarchy() [[6, 4, 1, 3, 8, 5], [7, 2, 10, 9, 0]]  11. similar_words 查找相似词， 该方法其实也可以用于扩充词典。\nsimilar_words(keywords, num_words, keywords_neg=None)\n keywords: 待查询关键词列表 num_words: 返回相似词个数 keywords_neg: 指定反义词列表  # 查找【增进】的最相似的10个词 model.similar_words(keywords=[\"增进\"], num_words=10, keywords_neg=None) (array(['两国关系', '王刚', '友好', '会见', '两国', '东盟', '温家宝', '中美', '伙伴', '双方'], dtype=' 12. save 训练不易， 记得保存模型。\nmodel.save('随便起个名字.pkl') ",
  "wordCount" : "2080",
  "inLanguage": "en",
  "image":"/images/blog/top2vec.png","datePublished": "2021-12-13T10:43:10+06:00",
  "dateModified": "2021-12-13T10:43:10+06:00",
  "author":{
    "@type": "Person",
    "name": "大邓"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "/blog/top2vec/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "大邓和他的PYTHON",
    "logo": {
      "@type": "ImageObject",
      "url": "/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="/" accesskey="h" title="大邓和他的PYTHON (Alt + H)">大邓和他的PYTHON</a>
            <span class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </span>
        </div>
        <ul id="menu">
            <li>
                <a href="/blog" title="博文">
                    <span>博文</span>
                </a>
            </li>
            <li>
                <a href="/search/" title="搜索">
                    <span>搜索</span>
                </a>
            </li>
            <li>
                <a href="/tags/" title="标签">
                    <span>标签</span>
                </a>
            </li>
            <li>
                <a href="/categories/" title="类目">
                    <span>类目</span>
                </a>
            </li>
            <li>
                <a href="mailto:thunderhit@qq.com" title="联系">
                    <span>联系</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <div class="breadcrumbs"><a href="/">Home</a>&nbsp;»&nbsp;<a href="/blog/">Blogs</a></div>
    <h1 class="post-title">
      Top2Vec|主题建模和语义搜索库
    </h1>
    <div class="post-description">
      越来越多的美国年轻人拍一段自己的短视频，放在 TikTok 上面求职，请求看到的人转发
    </div>
    <div class="post-meta"><span title='2021-12-13 10:43:10 +0600 +0600'>2021-12-13</span>&nbsp;·&nbsp;10 min&nbsp;·&nbsp;大邓

</div>
  </header> 
<figure class="entry-cover"><a href="/images/blog/top2vec.png" target="_blank"
            rel="noopener noreferrer"><img loading="lazy" src="/images/blog/top2vec.png" alt=""></a>
        
</figure><div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#1-%e5%af%bc%e5%85%a5%e6%95%b0%e6%8d%ae" aria-label="1. 导入数据">1. 导入数据</a></li>
                <li>
                    <a href="#2-%e6%b8%85%e6%b4%97%e6%95%b0%e6%8d%ae" aria-label="2. 清洗数据">2. 清洗数据</a></li>
                <li>
                    <a href="#3-%e8%ae%ad%e7%bb%83%e6%a8%a1%e5%9e%8b" aria-label="3. 训练模型">3. 训练模型</a></li>
                <li>
                    <a href="#4-get_topics" aria-label="4. get_topics">4. get_topics</a></li>
                <li>
                    <a href="#5-get_documents_topics" aria-label="5. get_documents_topics">5. get_documents_topics</a></li>
                <li>
                    <a href="#6-search_topics" aria-label="6. search_topics">6. search_topics</a></li>
                <li>
                    <a href="#7-query_topics" aria-label="7. query_topics">7. query_topics</a></li>
                <li>
                    <a href="#8-search_documents_by_keywords" aria-label="8. search_documents_by_keywords">8. search_documents_by_keywords</a></li>
                <li>
                    <a href="#9-search_documents_by_topic" aria-label="9. search_documents_by_topic">9. search_documents_by_topic</a></li>
                <li>
                    <a href="#10-get_topic_hierarchy" aria-label="10. get_topic_hierarchy">10. get_topic_hierarchy</a></li>
                <li>
                    <a href="#11-similar_words" aria-label="11. similar_words">11. similar_words</a></li>
                <li>
                    <a href="#12-save" aria-label="12. save">12. save</a>
                </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><p>Top2Vec 是一种用于主题建模和语义搜索的算法。**我个人从理解代码和使用代码难度来看， 对于Python小白，BERTopic更适合直接用预训练词向量，而Top2Vec更适合对小规模数据训练词向量后做主题建模。**它自动检测文本中存在的主题并生成联合嵌入的主题、文档和词向量。训练 Top2Vec 模型后，您可以：</p>
<ul>
<li>获取检测到的主题数。</li>
<li>获取话题。</li>
<li>获取主题大小。</li>
<li>获取分层主题。</li>
<li>按关键字搜索主题。</li>
<li>按主题搜索文档。</li>
<li>按关键字搜索文档。</li>
<li>找出相似的词。</li>
<li>查找类似的文档。</li>
<li>使用 RESTful-Top2Vec 公开模型</li>
<li>有关其工作原理的更多详细信息，请参阅论文。</li>
</ul>
<p><strong>亮点</strong></p>
<ul>
<li>自动查找主题数。</li>
<li>不需要停用词列表。</li>
<li>不需要词干/词形还原。</li>
<li>适用于短文本。</li>
<li>创建联合嵌入的主题、文档和词向量。</li>
<li>内置搜索功能。</li>
</ul>
<p><strong>它是如何工作的？</strong></p>
<p>该算法做出的假设是，许多语义相似的文档都表明了一个潜在的主题。</p>
<p>第一步是创建文档和词向量的联合嵌入。一旦文档和单词被嵌入到一个向量空间中，算法的目标就是找到密集的文档集群，然后确定哪些单词将这些文档吸引到一起。每个密集区域是一个主题，将文档吸引到密集区域的词就是主题词。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="err">!</span><span class="n">pip3</span> <span class="n">install</span> <span class="n">top2vec</span>
</code></pre></div><br>
<h2 id="1-导入数据">1. 导入数据<a hidden class="anchor" aria-hidden="true" href="#1-导入数据">#</a></h2>
<p>使用某灾难数据集，这里是存在标注的标签，但是我们假设不用label的，仅作为评判Top2vec运行效果的标准。<a href="cnews.csv">点击cnews.csv下载</a></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">display</span>
<span class="kn">from</span> <span class="nn">cntext</span> <span class="kn">import</span> <span class="n">STOPWORDS_zh</span>
<span class="kn">from</span> <span class="nn">top2vec</span> <span class="kn">import</span> <span class="n">Top2Vec</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">jieba</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;cnews.csv&#39;</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><figure>
    <img loading="lazy" src="img/df.png" width="800"/> 
</figure>

<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df</span><span class="o">.</span><span class="n">label</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</code></pre></div><pre><code>时政    120
科技    106
时尚    106
财经    105
家居    103
教育     97
娱乐     96
体育     95
房产     87
游戏     85
Name: label, dtype: int64
</code></pre>
<br>
<h2 id="2-清洗数据">2. 清洗数据<a hidden class="anchor" aria-hidden="true" href="#2-清洗数据">#</a></h2>
<p>一般而言，作中文文本分析，需要把中文分词构造成类西方语言(空格间隔词语的文本)风格。在此期间，顺便将停用词剔除。其实在用top2vec时，不剔除停用词影响也不大。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">clean_text</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="n">words</span> <span class="o">=</span> <span class="n">jieba</span><span class="o">.</span><span class="n">lcut</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
    <span class="n">words</span> <span class="o">=</span> <span class="p">[</span><span class="n">w</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">words</span> <span class="k">if</span> <span class="n">w</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">STOPWORDS_zh</span><span class="p">]</span>
    <span class="k">return</span> <span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">words</span><span class="p">)</span>


<span class="n">df</span><span class="p">[</span><span class="s1">&#39;cleantext&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">text</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">clean_text</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><figure>
    <img loading="lazy" src="img/df2.png" width="800"/> 
</figure>

<br>
<h2 id="3-训练模型">3. 训练模型<a hidden class="anchor" aria-hidden="true" href="#3-训练模型">#</a></h2>
<p>Top2vec有一下四个常用参数</p>
<p><strong>Top2vec(documents, min_count, speed, workers)</strong></p>
<ul>
<li>documents: 文档列表</li>
<li>min_count: 词语最少出现次数。低于min_count的词不加入模型中</li>
<li>speed: 训练速度，参数默认&quot;learn&quot;
<ul>
<li>&ldquo;fast-learn&rdquo;  速度最快，训练效果最差</li>
<li>&ldquo;learn&rdquo;       速度，训练效果中等</li>
<li>&ldquo;deep-learn&rdquo;  速度最慢，训练效果最佳</li>
</ul>
</li>
<li>workers: 并行运行数，该值最大取值为电脑CPU的核数。</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">model</span> <span class="o">=</span> <span class="n">Top2Vec</span><span class="p">(</span><span class="n">documents</span><span class="o">=</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;cleantext&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">to_list</span><span class="p">(),</span> 
                <span class="n">min_count</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                <span class="n">speed</span><span class="o">=</span><span class="s2">&#34;deep-learn&#34;</span><span class="p">,</span>  
                <span class="n">workers</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
</code></pre></div><pre><code>2021-12-14 20:21:10,318 - top2vec - INFO - Pre-processing documents for training
2021-12-14 20:21:10,871 - top2vec - INFO - Creating joint document/word embedding
2021-12-14 20:25:06,082 - top2vec - INFO - Creating lower dimension embedding of documents
2021-12-14 20:25:14,645 - top2vec - INFO - Finding dense areas of documents
2021-12-14 20:25:14,683 - top2vec - INFO - Finding topics
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1"># 话题个数</span>
<span class="n">model</span><span class="o">.</span><span class="n">get_num_topics</span><span class="p">()</span>
</code></pre></div><pre><code>11
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1"># 各话题数量</span>
<span class="n">topic_sizes</span><span class="p">,</span> <span class="n">topic_nums</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">get_topic_sizes</span><span class="p">()</span>

<span class="p">{</span><span class="s2">&#34;topic_sizes&#34;</span><span class="p">:</span><span class="n">topic_sizes</span><span class="p">,</span> 
 <span class="s2">&#34;topic_ids&#34;</span><span class="p">:</span><span class="n">topic_nums</span><span class="p">}</span>
</code></pre></div><pre><code>{'topic_sizes': array([116, 108, 105, 104, 100,  97,  95,  94,  89,  74,  18]),
 'topic_ids': array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10])}
</code></pre>
<br>
<h2 id="4-get_topics">4. get_topics<a hidden class="anchor" aria-hidden="true" href="#4-get_topics">#</a></h2>
<p>用pyecharts词云图显示<strong>话题信息</strong>， 为了简化代码，将该功能封装为函数</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">gen_wordcloud</span><span class="p">(</span><span class="n">topic_words</span><span class="p">,</span> <span class="n">word_scores</span><span class="p">,</span> <span class="n">topic_id</span><span class="p">):</span>
    <span class="s2">&#34;&#34;&#34;
</span><span class="s2">    topic_words: 主题词列表
</span><span class="s2">    word_scores: 主题特征词的权重得分(词语表征主题的能力)
</span><span class="s2">    topic_id: 主题id
</span><span class="s2">    &#34;&#34;&#34;</span>
    <span class="kn">import</span> <span class="nn">pyecharts.options</span> <span class="k">as</span> <span class="nn">opts</span>
    <span class="kn">from</span> <span class="nn">pyecharts.charts</span> <span class="kn">import</span> <span class="n">WordCloud</span>
    <span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">display</span>
    
    <span class="n">data</span> <span class="o">=</span> <span class="p">[(</span><span class="n">word</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">weight</span><span class="p">))</span> <span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">weight</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">topic_words</span><span class="p">,</span> <span class="n">word_scores</span><span class="p">)]</span>

    <span class="n">wc</span> <span class="o">=</span> <span class="n">WordCloud</span><span class="p">()</span>
    <span class="n">wc</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">series_name</span><span class="o">=</span><span class="s2">&#34;&#34;</span><span class="p">,</span> <span class="n">data_pair</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">word_size_range</span><span class="o">=</span><span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">88</span><span class="p">])</span>
    <span class="n">wc</span><span class="o">.</span><span class="n">set_global_opts</span><span class="p">(</span>
        <span class="n">title_opts</span><span class="o">=</span><span class="n">opts</span><span class="o">.</span><span class="n">TitleOpts</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s2">&#34;Topic_</span><span class="si">{topic_id}</span><span class="s2">&#34;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">topic_id</span><span class="o">=</span><span class="n">topic_id</span><span class="p">),</span> 
                                  <span class="n">title_textstyle_opts</span><span class="o">=</span><span class="n">opts</span><span class="o">.</span><span class="n">TextStyleOpts</span><span class="p">(</span><span class="n">font_size</span><span class="o">=</span><span class="mi">23</span><span class="p">)),</span>
        <span class="n">tooltip_opts</span><span class="o">=</span><span class="n">opts</span><span class="o">.</span><span class="n">TooltipOpts</span><span class="p">(</span><span class="n">is_show</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>

    <span class="n">display</span><span class="p">(</span><span class="n">wc</span><span class="o">.</span><span class="n">render_notebook</span><span class="p">())</span>
</code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">topic_wordss</span><span class="p">,</span> <span class="n">word_scoress</span><span class="p">,</span> <span class="n">topic_ids</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">get_topics</span><span class="p">(</span><span class="mi">11</span><span class="p">)</span>

<span class="k">for</span> <span class="n">topic_words</span><span class="p">,</span> <span class="n">word_scores</span><span class="p">,</span> <span class="n">topic_id</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">topic_wordss</span><span class="p">,</span> <span class="n">word_scoress</span><span class="p">,</span> <span class="n">topic_ids</span><span class="p">):</span>
    <span class="n">gen_wordcloud</span><span class="p">(</span><span class="n">topic_words</span><span class="p">,</span> <span class="n">word_scores</span><span class="p">,</span> <span class="n">topic_id</span><span class="p">)</span>
</code></pre></div><p><figure>
    <img loading="lazy" src="img/vis1.png" width="800"/> 
</figure>

<figure>
    <img loading="lazy" src="img/vis2.png" width="800"/> 
</figure>

<figure>
    <img loading="lazy" src="img/vis3.png" width="800"/> 
</figure>

<figure>
    <img loading="lazy" src="img/vis4.png" width="800"/> 
</figure>
</p>
<br>
<h2 id="5-get_documents_topics">5. get_documents_topics<a hidden class="anchor" aria-hidden="true" href="#5-get_documents_topics">#</a></h2>
<p>get_documents_topics(doc_ids, num_topics=1)</p>
<ul>
<li>doc_ids: 待查询文档id列表</li>
<li>num_topics: 返回某文档可能归属话题的个数</li>
</ul>
<figure>
    <img loading="lazy" src="img/df.png" width="800"/> 
</figure>

<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1"># 查第一条文档的</span>
<span class="n">model</span><span class="o">.</span><span class="n">get_documents_topics</span><span class="p">(</span><span class="n">doc_ids</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">num_topics</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div><pre><code>(array([9]),
 array([0.13393445], dtype=float32),
 array([['留学', '学生', '申请', '签证', '大学', '学费', '本科', '名校', '留学生', '加拿大', '课程', '申请者', '院校', '学校', '移民', '英国', '高等教育', '教育', '录取', '高中生',
         '出国', '人数', '高中', '学位', '就读', '生活费', '家长', '澳大利亚', '申请人', '预科',
         '美国', '该国', '新政', '招生', '文凭', '学士学位', '公立', '私立', '攻读', '高校',
         '绿卡', '升学', '学历', '雅思', '入学', '资助', '移民部', '技术移民', '万至', '学期']],
       dtype='&lt;U9'),
 array([[0.6926953 , 0.6242467 , 0.5911637 , 0.5618203 , 0.54714125,
         0.54360884, 0.5397957 , 0.5385162 , 0.53832144, 0.5268167 ,
         0.5255044 , 0.52232724, 0.52129036, 0.5149227 , 0.49912092,
         0.46216848, 0.46023563, 0.45987687, 0.45913237, 0.45762828,
         0.45715228, 0.45121962, 0.45040804, 0.44802257, 0.44495288,
         0.44481775, 0.44124833, 0.43432242, 0.43391675, 0.43311685,
         0.4321192 , 0.4318304 , 0.43135592, 0.42906424, 0.42849895,
         0.42731148, 0.42642018, 0.420944  , 0.417553  , 0.41722208,
         0.41120926, 0.4068325 , 0.40628856, 0.4049462 , 0.40243787,
         0.40150112, 0.39927092, 0.3964286 , 0.3903596 , 0.38602734]],
       dtype=float32))
</code></pre>
<br>
<h2 id="6-search_topics">6. search_topics<a hidden class="anchor" aria-hidden="true" href="#6-search_topics">#</a></h2>
<p>根据关键词搜索话题，查某词是否属于某话题，属于该主题的概率
search_topics(keywords, num_topics, keywords_neg=None)</p>
<ul>
<li>keywords: 关键词列表</li>
<li>num_topics: 返回话题个数，按照语义相似度从高到低排序</li>
<li>keywords_neg: 反义词列表</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">gen_wordcloud2</span><span class="p">(</span><span class="n">query_word</span><span class="p">,</span> <span class="n">topic_words</span><span class="p">,</span> <span class="n">word_scores</span><span class="p">,</span> <span class="n">topic_id</span><span class="p">,</span> <span class="n">topic_probability</span><span class="p">):</span>
    <span class="s2">&#34;&#34;&#34;
</span><span class="s2">    query_word: 待查询词
</span><span class="s2">    topic_words: 主题词列表
</span><span class="s2">    word_scores: 主题特征词的权重得分(词语表征主题的能力)
</span><span class="s2">    topic_id: 主题id
</span><span class="s2">    topic_probability: 主题概率
</span><span class="s2">    &#34;&#34;&#34;</span>
    <span class="kn">import</span> <span class="nn">pyecharts.options</span> <span class="k">as</span> <span class="nn">opts</span>
    <span class="kn">from</span> <span class="nn">pyecharts.charts</span> <span class="kn">import</span> <span class="n">WordCloud</span>
    <span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">display</span>
    
    <span class="n">data</span> <span class="o">=</span> <span class="p">[(</span><span class="n">word</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">weight</span><span class="p">))</span> <span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">weight</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">topic_words</span><span class="p">,</span> <span class="n">word_scores</span><span class="p">)]</span>

    <span class="n">wc</span> <span class="o">=</span> <span class="n">WordCloud</span><span class="p">()</span>
    <span class="n">wc</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">series_name</span><span class="o">=</span><span class="s2">&#34;&#34;</span><span class="p">,</span> <span class="n">data_pair</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">word_size_range</span><span class="o">=</span><span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">88</span><span class="p">])</span>
    <span class="n">title</span> <span class="o">=</span> <span class="s2">&#34;&#34;&#34;Word</span><span class="si">{query_word}</span><span class="se">\n</span><span class="s2">Topic_</span><span class="si">{topic_id}</span><span class="se">\n</span><span class="s2">Probability:</span><span class="si">{probability:.2f}</span><span class="s2">&#34;&#34;&#34;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">query_word</span><span class="o">=</span><span class="n">query_word</span><span class="p">,</span>
                                                              <span class="n">topic_id</span><span class="o">=</span><span class="n">topic_id</span><span class="p">,</span> 
                                                              <span class="n">probability</span><span class="o">=</span><span class="n">topic_probability</span><span class="p">)</span>
    <span class="n">wc</span><span class="o">.</span><span class="n">set_global_opts</span><span class="p">(</span>
        <span class="n">title_opts</span><span class="o">=</span><span class="n">opts</span><span class="o">.</span><span class="n">TitleOpts</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="n">title</span><span class="p">,</span> 
                                  <span class="n">title_textstyle_opts</span><span class="o">=</span><span class="n">opts</span><span class="o">.</span><span class="n">TextStyleOpts</span><span class="p">(</span><span class="n">font_size</span><span class="o">=</span><span class="mi">18</span><span class="p">)),</span>
        <span class="n">tooltip_opts</span><span class="o">=</span><span class="n">opts</span><span class="o">.</span><span class="n">TooltipOpts</span><span class="p">(</span><span class="n">is_show</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>

    <span class="n">display</span><span class="p">(</span><span class="n">wc</span><span class="o">.</span><span class="n">render_notebook</span><span class="p">())</span>
</code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">query_word</span> <span class="o">=</span> <span class="s2">&#34;电影&#34;</span>
<span class="n">topic_wordss</span><span class="p">,</span> <span class="n">word_scoress</span><span class="p">,</span> <span class="n">topic_scores</span><span class="p">,</span> <span class="n">topic_ids</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">search_topics</span><span class="p">(</span><span class="n">keywords</span><span class="o">=</span><span class="p">[</span><span class="n">query_word</span><span class="p">],</span> <span class="n">num_topics</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="k">for</span> <span class="n">topic_words</span><span class="p">,</span> <span class="n">word_scores</span><span class="p">,</span> <span class="n">topic_score</span><span class="p">,</span> <span class="n">topic_id</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">topic_wordss</span><span class="p">,</span> <span class="n">word_scoress</span><span class="p">,</span> <span class="n">topic_scores</span><span class="p">,</span> <span class="n">topic_ids</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">topic_score</span><span class="o">&gt;</span><span class="mf">0.5</span><span class="p">:</span>
        <span class="n">gen_wordcloud2</span><span class="p">(</span><span class="n">query_word</span><span class="o">=</span><span class="n">query_word</span><span class="p">,</span> 
                       <span class="n">topic_words</span><span class="o">=</span><span class="n">topic_words</span><span class="p">,</span> 
                       <span class="n">word_scores</span><span class="o">=</span><span class="n">word_scores</span><span class="p">,</span> 
                       <span class="n">topic_id</span><span class="o">=</span><span class="n">topic_id</span><span class="p">,</span> <span class="n">topic_probability</span><span class="o">=</span><span class="n">topic_score</span><span class="p">)</span>
</code></pre></div><figure>
    <img loading="lazy" src="img/vis5.png" width="800"/> 
</figure>

<br>
<h2 id="7-query_topics">7. query_topics<a hidden class="anchor" aria-hidden="true" href="#7-query_topics">#</a></h2>
<p>根据一段文本寻找最符合该文本的话题
query_topics(query, num_topics)</p>
<ul>
<li>query: 查询文本，注意是用空格间隔词语的文本</li>
<li>num_topics: 返回的话题数</li>
</ul>
<p>返回话题特征词列表， 话题特征词权重， 话题概率， 话题id</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">querytext</span> <span class="o">=</span> <span class="s1">&#39;刘晓庆 55 岁 近日 颁奖礼 刘晓庆 一袭 宝蓝色 超低 胸 V 领 长裙 亮相 轻薄 蕾丝 奢华 皮草 艳丽 色彩 翠绿&#39;</span>
<span class="n">topic_words</span><span class="p">,</span> <span class="n">word_scores</span><span class="p">,</span> <span class="n">topic_scores</span><span class="p">,</span> <span class="n">topic_ids</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">query_topics</span><span class="p">(</span><span class="n">query</span><span class="o">=</span><span class="n">querytext</span><span class="p">,</span> 
                                                                       <span class="n">num_topics</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;可能归属的话题有: &#39;</span><span class="p">,</span> <span class="n">topic_ids</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;归属于该话题的概率&#39;</span><span class="p">,</span> <span class="n">topic_scores</span><span class="p">)</span>
</code></pre></div><pre><code>可能归属的话题有:  [1 4]
归属于该话题的概率 [0.3688392  0.21418373]
</code></pre>
<br>
<h2 id="8-search_documents_by_keywords">8. search_documents_by_keywords<a hidden class="anchor" aria-hidden="true" href="#8-search_documents_by_keywords">#</a></h2>
<p>根据关键词，筛选文档</p>
<p>search_documents_by_keywords(keywords,
num_docs,
keywords_neg=None,
return_documents=True)</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#文档， 语义相关性， 文档id</span>
<span class="n">docs</span><span class="p">,</span> <span class="n">scores</span><span class="p">,</span> <span class="n">doc_ids</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">search_documents_by_keywords</span><span class="p">(</span><span class="n">keywords</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;搭配&#39;</span><span class="p">],</span> 
                                                         <span class="n">num_docs</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> 
                                                         <span class="n">keywords_neg</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> 
                                                         <span class="n">return_documents</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">for</span> <span class="n">doc</span><span class="p">,</span> <span class="n">score</span><span class="p">,</span> <span class="n">doc_id</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">docs</span><span class="p">,</span> <span class="n">scores</span><span class="p">,</span> <span class="n">doc_ids</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;Document: </span><span class="si">{</span><span class="n">doc_id</span><span class="si">}</span><span class="s2">, Semantic similarity: </span><span class="si">{</span><span class="n">score</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">doc</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;----------&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">()</span>
</code></pre></div><pre><code>Document: 870, Semantic similarity: 0.46936729550361633
组图 看达人 演绎 豹纹 军装 风 导语 懂得 潮流 总是 知道 适合 今冬 流行 亮点 太 军装 豹纹 类似 民族风情 想要 知道 搭配 快 看看 时尚 达 穿 军绿色 宽松 款 大衣 不失 俏皮 味道 高腰 设计 短裙 有效 提升 腰线 衬托出 修长 美腿 豹纹 今年 冬季 抢眼 搭配 元素 加上 驼色 针织衫 灰色 围巾 暖 棕色 手 挎包 整体 色调 统一 迷人 棕色 蓝色 结合能 眼前一亮 简洁 款式 依然 突显 独特 品味 宽松 针织 外套 衬托出 优美 身形 搭配 同样 沉闷 黑色 包包 性感 丝袜 装扮 依然 透露 出 迷人 气息 立领 衬衫 加上 深黄 高腰 裤 摩登 感 十足 随意 披上 外套 更显 慵懒 个性 法式 风情
----------

Document: 450, Semantic similarity: 0.46842482686042786
街 拍 爱 招摇过市 毛茸茸 ( 组图 ) 导语 皮草 每个 冬天 可能 丢弃 每个 需要 温暖 早些 相比 人造皮 草比 真皮 草 风头 更劲 时尚 环保 大牌 秀 场上 超模 一个个 穿着 人造皮 草 “ 招摇过市 ” 之后 街头 潮人 没有 理由 拒绝 外形 酷酷 这件 气场 皮草 单品 配合默契 摇滚 风 配饰 搭配 黑色 皮草 长 背心 更显 利落 酷酷 黑色 皮草 搭配 蓝色 衬衣 不同 感觉 加上 下半身 底裤 时髦 包包 颜色 提亮 整身 装扮 抹胸 式 皮草 特点 高贵典雅 适合 搭配 连衣裙 装饰 增添 时尚 美感 复古 圆点 连衣裙 搭配 宽松 棕色 皮草 衣 名媛 感觉 典雅 淑女 短款 黑色 皮草 搭配 贴身 仔裤 搭配 长靴 潇洒 帅气 茸茸 帽子 增添 不少 甜美 感
----------

Document: 665, Semantic similarity: 0.45364660024642944
组图 韩国 明星 街 拍 各显 本色 魅力 导语 很多 迷 韩剧 剧中 女星 逐渐 变成 家喻户晓 红人 韩 剧中 靓丽 女星 示范 想 靓丽 成为 众人 瞩目 焦点 摆脱 荧幕 光环 现实 中是 李孝利 韩国 有人 气 女歌手 走红 速度 之快 成为 影视 歌 多方面 艺人 街 拍图 成为 众相 追捧 对象 身 装扮 休闲 个性 典型 风格 棒球帽 字母 T恤 简单 活力 下身 裙裤 透露 出 少女 气息 搭配 毛线 靴 青春 气息 迎面而来 想 卫衣 穿 出 时尚 感 学学 拼接 色 卫衣 搭配 牛仔 短裤 帅气 亮面 底裤 更显 腿部 线条 打造 野性 装扮 一件 豹纹 外套 搞定 下身 搭配 短裤 短裙 露出 性感美 腿 挎 一个 
----------
</code></pre>
<br>
<h2 id="9-search_documents_by_topic">9. search_documents_by_topic<a hidden class="anchor" aria-hidden="true" href="#9-search_documents_by_topic">#</a></h2>
<p>根据指定的topic_id， 显示该主题前num_docs个文档，显示的文档是根据概率从高到低降序显示</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#查看topic4的前5条文档</span>
<span class="n">topic_id</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">documents</span><span class="p">,</span> <span class="n">document_scores</span><span class="p">,</span> <span class="n">document_ids</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">search_documents_by_topic</span><span class="p">(</span><span class="n">topic_num</span><span class="o">=</span><span class="n">topic_id</span><span class="p">,</span> <span class="n">num_docs</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="k">for</span> <span class="n">doc</span><span class="p">,</span> <span class="n">score</span><span class="p">,</span> <span class="n">doc_id</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">documents</span><span class="p">,</span> <span class="n">document_scores</span><span class="p">,</span> <span class="n">document_ids</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;Document: </span><span class="si">{</span><span class="n">doc_id</span><span class="si">}</span><span class="s2">, Semantic similarity: </span><span class="si">{</span><span class="n">score</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&#34;-----------&#34;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">doc</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&#34;-----------&#34;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">()</span>
</code></pre></div><pre><code>Document: 91, Semantic similarity: 0.4055505692958832
-----------
遍地 狼烟 场面 恢弘   打造 精良 狙击枪 战 类型 片 新浪 娱乐 讯   电影 遍地 狼烟 12 2 上映 该片 何润东 ( 微博 ) 宋佳 ( 微博 ) 梁家辉 何晟铭 ( 微博 ) 主演 展现 狙击手 不为人知 一面 何润东 日前 透露 拍摄 该片 苦练 身材 希望 电影 能够 看起来 “ 够 爷们 ” 狙击 题材 枪战 片 遍地 狼烟 取材 狙击手 创作 初衷 导演 胡 大为 表示 “ 狙击手 生活 远远 不像 想像 简单 辛苦 危险 曾经 一位 狙击手 朋友 等待 目标 潜伏 树上 达 一周 久 枪法 百发百中 之外 狙击手 需要 经受 常人 难以忍受 痛苦 ” 希望 借由 遍地 狼烟 狙击手 不为人知 一面 呈现 观众 面前 何润东  ”
-----------

Document: 392, Semantic similarity: 0.38211899995803833
-----------
组图 大S 新片 腿 夹 色诱 古天乐   动作 搞笑 情色 新浪 娱乐 讯   大S 古天乐 结戏缘 电影 大内 密探 灵灵狗 饰演 夫妻 使出 浑身解数 色诱 古天乐 露出 性感 香肩 双脚 夹紧 画面 相当 搞笑 剧中 打斗 戏 不断 牺牲 形象 引诱 大S 挑战 笑 非常 紧张 平常 懂 搔首弄姿 如今 勾引 古天乐 不知 尴尬
-----------

Document: 265, Semantic similarity: 0.376071572303772
-----------
危险 关系 开机   章子怡 荐 张柏芝 演 坏女孩 ( 图 ) 章子怡 推荐 张柏芝 周 冬雨 ( 微博 ) 这部 法国 经典小说 蓝本 电影 改编 多次 许秦豪 介绍 吸引 执导 该片 原因 改编 剧本 复杂 人物 关系 “ 故事 背景 选在 1930 年代 上海 里面 有人 爱情 游戏 有人 爱情 生命 关系 发展 吸引 ” 戏中 人物 到底 复杂 原来 三位 主演 饰演 女孩 坏女孩 花花公子 角色 章子怡 介绍 剧本 爱 杜芬玉 纯情 女孩 “ 剧本 感动 爱情故事 选择 女孩 修养 经历 特别 爱情 路上 坎坷 一次 心灵 挑战 到时候 知道 选 ” 制片人 陈伟明 现场 透露 原来 章子怡 推荐 张柏芝 出演 莫 婕妤 “ 坏女孩 ” 角色 对此 章子怡 坦陈 希望 演员 出演 这部 电影 推荐 过周 冬雨 演 “ 贝贝 ” “ 推荐 柏芝 是因为 合适 制片人 投资人 沟通 商量 毕竟 希望 希望 这是 一部 聚集 演员 国际化 影片 想 推荐 周 冬雨 演贝贝 角色 听说 上学 ” 张柏芝 称 爱情 “ 危险 ” 发布会 身穿 黑色 
-----------

Document: 729, Semantic similarity: 0.37136194109916687
-----------
陈小春 缺席 宝马 狂想曲 活动   熊乃谨 谈 感情 戏 新浪 娱乐 讯   10 21 电影 宝马 狂想曲 合肥 举行 观众 见面会 男主角 陈小春 ( 微博 ) 缺席 活动 女主角 熊乃谨 表示 之前 刚刚 伴娘 身份 出席 陈小春 应 采儿 ( 微博 ) 婚礼 朋友 老公 演起 感情 戏 不得不 拍 一段 闺蜜 报告 熊乃谨 好友 老公 谈恋爱 宝马 狂想曲 一部 黑色幽默 题材 电影 该片 陈小春 婚后 出演 首部 作品 饰演 极度 热爱 宝马 忠实 fans 黄德斌 梁家仁 李健仁 饰演 贼匪 团伙 进行 几度 精彩 抢夺 宝马
-----------

Document: 562, Semantic similarity: 0.36686939001083374
-----------
黄百鸣 称用 张柏芝 值得   新片 吴君如 擦肩 ( 组图 ) 新浪 娱乐 讯   肥妈 玛利亚 担任 主席 公司 收购 10 28 香港 举行 签约 仪式 到场 嘉宾 包括 狄波拉 老公 徐小明 夫妇 黄百鸣 王晶 夏韶声 亢帅克 肥妈 表示 公司 包括 mv 制作 经理人 公司 饮食 频道 之后 开拍 一套 青春 歌舞片 并会 联络 巨星 参与 演出 支持 下一代 黄百鸣 请来 张柏芝 拍摄 贺岁片 柏芝 产后 复出 头炮 表示 这部 戏 下周 开拍 柏芝 状态 甚勇 是否 柏芝 五千万 片酬 黄百鸣 表示 合理 觉得 值得 开拍 贺岁片 少 吴君如 解释 之前 误会 君如 怀孕 接 甘国 亮 新片 TUNGSTAR / 文并 图
-----------
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">documents</span><span class="p">,</span> <span class="n">document_scores</span><span class="p">,</span> <span class="n">document_ids</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">search_documents_by_keywords</span><span class="p">(</span><span class="n">keywords</span><span class="o">=</span><span class="p">[</span><span class="s2">&#34;搭配&#34;</span><span class="p">,</span> <span class="s2">&#34;高跟鞋&#34;</span><span class="p">],</span> <span class="n">num_docs</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="k">for</span> <span class="n">doc</span><span class="p">,</span> <span class="n">score</span><span class="p">,</span> <span class="n">doc_id</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">documents</span><span class="p">,</span> <span class="n">document_scores</span><span class="p">,</span> <span class="n">document_ids</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;Document: </span><span class="si">{</span><span class="n">doc_id</span><span class="si">}</span><span class="s2">, Semantic similarity: </span><span class="si">{</span><span class="n">score</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&#34;-----------&#34;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">doc</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&#34;-----------&#34;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">()</span>
</code></pre></div><pre><code>Document: 727, Semantic similarity: 0.5883481502532959
-----------
组图 冷气 办公室   连衣裙 配小 坎肩 美国 设计师 Diane   Von   Furstenberg 曾经 感觉 女人 穿 连衣裙 女人 找到 一件 适合 dream   dress 重要 无需 费神 搭配 单穿 连身 优雅 飞扬 裙摆 似乎 告诉 女 连衣裙 玩起 High   Fashion 变脸 游戏 DKNY 绿色 连衣裙   新品 未 定价 H &amp; M 黑色 外套   新品 未 定价 Agatha 配件 新品 未 定价 C . Banner 高跟鞋   新品 未 定价 低 V 领 连衣裙 秀出 属于 性感 更好 展现出 颈部 线条 搭配 修身 剪裁 西装 短款 皮手套 极具 欧美 明星 范儿 细 高跟鞋 更好 突出 双腿 长度 整体 显得 轻盈 不少 On &amp; on 米色 连衣裙   新品 未 定价 Asobio 针织 外套   RMB   449 Kookai 金色 腰带 Jc  
-----------

Document: 435, Semantic similarity: 0.5440454483032227
-----------
组图 秋冬 优雅 妖娆   女星 爱 裸 色系 导语 裸色 优雅 代名词 女星 近来 誓 裸色 进行 到底 无论是 徐若 ? 性感 乐基儿 气质 搭配 各色 礼服 赏心悦目 娇俏 款式 更是 大饱眼福 徐若 ? 飘逸 丝带    立刻 彰显 天王 嫂 贵妇 气质 袁咏仪 翻领 西装   气质 非凡 裸色 短款 紧身 西装 皮质 面料 彰显 个性 夹带 一点 蕾丝 装饰 女性 柔美 油然而生 搭配 碎花 蛋糕 裙 气质 非凡
-----------

Document: 870, Semantic similarity: 0.523485541343689
-----------
组图 看达人 演绎 豹纹 军装 风 导语 懂得 潮流 总是 知道 适合 今冬 流行 亮点 太 军装 豹纹 类似 民族风情 想要 知道 搭配 快 看看 时尚 达 穿 军绿色 宽松 款 大衣 不失 俏皮 味道 高腰 设计 短裙 有效 提升 腰线 衬托出 修长 美腿 豹纹 今年 冬季 抢眼 搭配 元素 加上 驼色 针织衫 灰色 围巾 暖 棕色 手 挎包 整体 色调 统一 迷人 棕色 蓝色 结合能 眼前一亮 简洁 款式 依然 突显 
-----------

Document: 522, Semantic similarity: 0.4756317138671875
-----------
女星 争当 蓝色妖姬 &amp; nbsp ; 英国 气质 女演员 瑞切尔 ・ 薇 兹 时尚 点评 英国 气质 女演员 瑞切尔 · 薇 兹 ( Rachel   Weisz )   美貌 非常 头脑 修身 印花 连衣裙 搭配 抢眼 棕红色 短 夹克 非常 好看 搭配 黑色 罗马 feel 高跟鞋 特别 有潮味 时尚 点评 身材 不算 瘦 女星 Lea   Michele 搭配 起来 非常 特色 一味 地瘦 风格 满是 褶皱 裙子 非常 修身 亮眼 颜色 非常
-----------

Document: 707, Semantic similarity: 0.47334203124046326
-----------
组图 黑丝 短裙 上阵   5 旬 女星 胜过 90 红星 导语 气温 越来越低 女星 不畏 严寒 纷纷 穿着 短裙 透视装 出席 活动 一番 比拼 不难 发现 气质 年轻 难得 厉害 一起 看看 刘晓庆 55 岁 近日 颁奖礼 刘晓庆 一袭 宝蓝色 超低 胸 V 领 长裙 亮相 轻薄 蕾丝 奢华 皮草 艳丽 色彩 翠绿 首饰 配上 短小 精炼 波波 头 瞬间 减龄 15 岁 张曼玉 46 岁 一向 气质 型 美女 著称 反倒 少 繁琐 修饰 刻意 打扮 超级 简单 Lanvin   for   H &amp; M 斜肩 礼裙 搭配 一双 皮质 手套 
-----------
</code></pre>
<br>
<h2 id="10-get_topic_hierarchy">10. get_topic_hierarchy<a hidden class="anchor" aria-hidden="true" href="#10-get_topic_hierarchy">#</a></h2>
<p>对话题进行分类，需要</p>
<ol>
<li>先执行model.hierarchical_topic_reduction</li>
<li>再执行model.get_topic_hierarchy。</li>
</ol>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1"># 将话题分为2类</span>
<span class="n">model</span><span class="o">.</span><span class="n">hierarchical_topic_reduction</span><span class="p">(</span><span class="n">num_topics</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">get_topic_hierarchy</span><span class="p">()</span>
</code></pre></div><pre><code>[[6, 4, 1, 3, 8, 5], [7, 2, 10, 9, 0]]
</code></pre>
<br>
<h2 id="11-similar_words">11. similar_words<a hidden class="anchor" aria-hidden="true" href="#11-similar_words">#</a></h2>
<p>查找相似词， 该方法其实也可以用于扩充词典。</p>
<p>similar_words(keywords, num_words, keywords_neg=None)</p>
<ul>
<li>keywords: 待查询关键词列表</li>
<li>num_words: 返回相似词个数</li>
<li>keywords_neg: 指定反义词列表</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1"># 查找【增进】的最相似的10个词</span>
<span class="n">model</span><span class="o">.</span><span class="n">similar_words</span><span class="p">(</span><span class="n">keywords</span><span class="o">=</span><span class="p">[</span><span class="s2">&#34;增进&#34;</span><span class="p">],</span> 
                    <span class="n">num_words</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> 
                    <span class="n">keywords_neg</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</code></pre></div><pre><code>(array(['两国关系', '王刚', '友好', '会见', '两国', '东盟', '温家宝', '中美', '伙伴', '双方'],
       dtype='&lt;U4'),
 array([0.5130112 , 0.50116096, 0.47922852, 0.46926211, 0.46253758,
        0.4395747 , 0.43768376, 0.42893141, 0.41960889, 0.41416299]))
</code></pre>
<br>
<h2 id="12-save">12. save<a hidden class="anchor" aria-hidden="true" href="#12-save">#</a></h2>
<p>训练不易， 记得保存模型。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;随便起个名字.pkl&#39;</span><span class="p">)</span>
</code></pre></div>

  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="/tags/%E8%AF%8D%E5%90%91%E9%87%8F/">词向量</a></li>
      <li><a href="/tags/%E6%96%87%E6%9C%AC%E5%88%86%E6%9E%90/">文本分析</a></li>
      <li><a href="/tags/%E7%AC%AC%E4%B8%89%E6%96%B9%E5%8C%85/">第三方包</a></li>
    </ul>

  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2021 <a href="/">大邓和他的PYTHON</a></span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerText = 'copy';

        function copyingDone() {
            copybutton.innerText = 'copied!';
            setTimeout(() => {
                copybutton.innerText = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
