atomicnumber;group;period;symbol;elementname;groupname;color;url;excerpt
1;1;1;Bit;字符\n编码;数据源;#3182bd;https://hidadeng.github.io;文本由字符组成，但文件由字节组成。 这些字节根据某种编码（又名字符集，如gbk、utf-8、ascii）表示字符。 通过选择正确的编码来修复或加载您的数据。
2;1;2;Typ;手工\n敲字;数据源;#6baed6;https://hidadeng.github.io;写程序先小后大，先局部小范围测试，后大规模应用。当在测试代码或演示时，使用您自己的文本会让您更有信心。
3;1;3;Str;导入\n结构\n数据;数据源;#6baed6;https://hidadeng.github.io;结构化数据意味着即用型数据，但您必须解释它的格式样式。
4;1;4;Cor;生成\n语料;数据源;#6baed6;https://hidadeng.github.io;语料库是一种语言资源，由一组结构化的文档和附加信息组成。 它结合了预处理文档及其元数据，这些元数据可能是其他 NLP 任务的输出。
5;1;5;Api;接口\n导入;数据源;#6baed6;https://hidadeng.github.io;API 用作不同应用程序之间的接口。 请求者自动获得对数据的访问权，其好处是源不必知道其他系统是如何工作的。
6;1;6;Scr;网络\n爬虫;数据源;#6baed6;https://hidadeng.github.io;缺少语料库或 API 要求您从网络上抓取文本数据或文件。 请克服 IP 阻塞、cookie 墙、请求标头和 js 网站的挑战。
7;1;7;Ext;文本提取\nOCR扫码;数据源;#6baed6;https://hidadeng.github.io;当您拥有输出格式（PDF 或图像）并且需要将其简化为文本数据的源格式时，提取文本并将其转换为定性数据是一项挑战。
8;2;2;Man;人工\n标注;训练集;#9ecae1;https://hidadeng.github.io;没有人愿意做标注数据的体力劳动。 每个人都想用已标注过的训练数据构建语言模型。
9;2;3;Ann;机器\n标注;训练集;#9ecae1;https://hidadeng.github.io;使用标注工具对原始文本数据进行标注，注意不同类别数据量要保证数据平衡。
10;2;4;Pro;训练\n数据;训练集;#9ecae1;https://hidadeng.github.io;好的数据要包含基本事实， 但请注意数据集是否符合您的目的。
11;2;5;Cro;众包;训练集;#9ecae1;https://hidadeng.github.io;构建训练数据是一项劳动密集型任务。 研究者仔细考究数据的定义，比如需要哪些标注(类别)、如何识别文本的类别，然后通过外包给远程工作人员来扩大规模。
12;2;6;Aug;数据\n增强;训练集;#9ecae1;https://hidadeng.github.io;考虑到效率问题，如可以，尽量先考虑通过现有数据生成需要的数据，而不是去找全新数据。
13;2;7;Rul;规则\n生成\n新数据;训练集;#9ecae1;https://hidadeng.github.io;定义用于标记训练数据的函数的算法规则，通过运行代码构建训练数据集。
14;3;3;Tok;分词;词语解析;#fd8d3c;https://hidadeng.github.io;许多 NLP 任务使用密集的矩阵计算，使用的是token(单词 id)替代单词字符串。 将本文分为多个token
15;3;4;Voc;构建\n词汇表;词语解析;#fd8d3c;https://hidadeng.github.io;构建词汇表(词语与词语id对应关系)，后续的文本数据处理都会基于词汇表，将文本批量转为不同长度的token列表
16;3;5;Mor;词形\n标注器;词语解析;#fd8d3c;https://hidadeng.github.io;处理时考虑词语形态，如is、was、are、am都可以统一到be这个词里
17;3;6;Pos;词性\n标注器;词语解析;#fd8d3c;https://hidadeng.github.io;处理时考虑词性，如名词、动词
18;3;7;Dep;依存\n解析器;词语解析;#fd8d3c;https://hidadeng.github.io;依赖解析器从句子中提取依赖图。 在图中，语法结构，如主语和宾语，以及由依赖标签表示的单词之间的关系。
19;4;3;Ste;词干化;词语处理;#fd8d3c;https://hidadeng.github.io;词干提取指的是一种粗略的启发式过程，它切断单词的结尾，希望具有相同含义的单词成为具有相同句法的单词。如products可以整理为product
20;4;4;Lem;词根化;词语处理;#fd8d3c;https://hidadeng.github.io;词形还原Lemmatization通常是指将单词正确地重写为其基本形式（引理）。如had、has还原为have。
21;4;5;Nrm;标准化;词语处理;#fd8d3c;https://hidadeng.github.io;标准化，除了 Stemming 或 Lemmatizing 之外，仍然可能需要编辑单词的字符。
22;4;6;Spl;拼写\n检查;词语处理;#fd8d3c;https://hidadeng.github.io;拼写检查
23;4;7;Neg;否定\n识别;词语处理;#fd8d3c;https://hidadeng.github.io;忽略否定的含义会翻转文本的极性。
24;5;3;Ngr;N-grams;词组&实体;#fdae6b;https://hidadeng.github.io;使用N-gram 会出现概率很高的常见多词表达，例如二连词(Bi-gram)下“red”、“wine”是一个词组“red wine”。
25;5;4;Phr;基于规则\n短语匹配器;词组&实体;#fdae6b;https://hidadeng.github.io;基于规则的短语词组匹配器； 如果规则不复杂，可以通过构建规则识别词组。
26;5;5;Chu;依存\n名词块;词组&实体;#fdae6b;https://hidadeng.github.io;依存名词块；一种将句子识别为不同的模块，例如主、谓、宾。
27;5;6;Ner;命名\n实体\n识别;词组&实体;#fdae6b;https://hidadeng.github.io;识别命名实体是将 NER 类别（如人员、位置或组织）
28;5;7;Abr;缩写\n识别器;词组&实体;#fdae6b;https://hidadeng.github.io;缩写识别
29;6;2;Pri;价格\n解析器;实体增强;#fdae6b;https://hidadeng.github.io;从原始文本中提取价格和货币，并将其规范化为标准格式。
30;6;3;Geo;地里编码;实体增强;#fdae6b;https://hidadeng.github.io;从文本解析为地址， 并将地址转换为地理坐标，如纬度和经度。
31;6;4;Tmp;时间解析;实体增强;#fdae6b;https://hidadeng.github.io;查找包含时间指示的字符串，然后从中提取规范化的时间格式。
32;6;5;Nel;命名实体链接;实体增强;#fdae6b;https://hidadeng.github.io;命名实体链接，例如根据Apple，可以有丰富的关系，如Apple-Iphone、Apple-US Company 
33;6;6;Crf;同义指代识别;实体增强;#fdae6b;https://hidadeng.github.io;识别同义指代，同一个主体，在文中会在不同位置以不同词语出现。如Obama、He、President
34;6;7;Anm;文本\n脱敏;实体增强;#fdae6b;https://hidadeng.github.io;文本脱敏，将可挖掘出个人、组织的隐私信息匿名化
35;7;4;Sen;断句;句子段落;#fdd0a2;https://hidadeng.github.io;断句
36;7;5;Par;段落;句子段落;#fdd0a2;https://hidadeng.github.io;段落分割
37;7;6;Grm;语法\n检测;句子段落;#fdd0a2;https://hidadeng.github.io;语法检测，提升句子语法水平。
38;7;7;Rea;可读性\n打分;句子段落;#fdd0a2;https://hidadeng.github.io;文本可读性；通过查看关键字密度、音节数以及文档中句子和单词的平均长度来衡量文本的可读性。
39;8;4;Ded;同义文档剔除;文档;#fdd0a2;https://hidadeng.github.io;剔除同义的文档； 通过嵌入Embedding，将文档向量化，从中找到内容相近的文档，剔除同义词文档。
40;8;5;Raw;文本清洗;文档;#fdd0a2;https://hidadeng.github.io;预处理文本，目标是提高后续 NLP 任务的质量。
41;8;6;Met;元信息\n提取;文档;#fdd0a2;https://hidadeng.github.io;从文件中提取文本应该伴随着元信息的提取。
42;8;7;Lng;语言\n识别;文档;#fdd0a2;https://hidadeng.github.io;语言识别； 在选择模型之前，先识别文本对应的语言种类。
43;9;3;Trn;训练\n模型;模型开发;#31a354;https://hidadeng.github.io;训练语言模型应该从一个简单的baseline开始，并通过更复杂的技术进行改进。
44;9;4;Tst;评估\n模型;模型开发;#31a354;https://hidadeng.github.io;选择正确的指标，评测语言模型训练的好坏。
45;9;5;Exp;解读\n模型;模型开发;#31a354;https://hidadeng.github.io;解读模型，相比于性能，有时候模型的透明度也很重要。
46;9;6;Dpl;部署\n模型;模型开发;#31a354;https://hidadeng.github.io;在DevOps中部署语言模型
47;9;7;Mon;监测\n模型;模型开发;#31a354;https://hidadeng.github.io;为语言模型提供新的反馈，以进一步提高模型性能。
48;10;3;Spa;垃圾邮件识别;文本分类;#74c476;https://hidadeng.github.io;垃圾邮件监测
49;10;4;Sed;情感\n分析;文本分类;#74c476;https://hidadeng.github.io;识别文本中的情感(情绪)
50;10;5;Int;意图\n分类;文本分类;#74c476;https://hidadeng.github.io;了解用户的意图，并给出准确的回应。
51;10;6;Cls;文本分类;文本分类;#74c476;https://hidadeng.github.io;文本分类，根据内容为文本分配标签或类别。 例如情感分类、垃圾邮件分类。
52;10;7;Mlc;多标签\n多类别\n分类;文本分类;#74c476;https://hidadeng.github.io;文本分类的一个子概念是， 多标签多类别文本分类，即一条文档可以同时被标注为多个标签。
53;11;3;Key;关键词\n提取;无监督信号;#74c476;https://hidadeng.github.io;关键词提取。
54;11;4;Esu;中心\n思想;无监督信号;#74c476;https://hidadeng.github.io;类似于关键词提取，从文本中提取出最相关的句子。
55;11;5;Top;主题\n模型;无监督信号;#74c476;https://hidadeng.github.io;通过对数据的理解，将数据按照n个主题对数据进行主题建模，划分为n个主题文档簇。
56;11;6;Tre;趋势\n诊断;无监督信号;#74c476;https://hidadeng.github.io;单词出现频率依时间绘制折线图，洞见趋势。
57;11;7;Out;异类(词)\n诊断;无监督信号;#74c476;https://hidadeng.github.io;查找文本中的异类词(类比理解，统计中的离群点)
58;12;3;Syn;Wordnet\n数据集;相似度;#a1d99b;https://hidadeng.github.io;词语之间的存在同义、近义、上位词、下位词等关系，通过这类关系，构建wordnet-synsets
59;12;4;Dst;距离\n计算;相似度;#a1d99b;https://hidadeng.github.io;通过特定距离算法来测量文档或词语的相似度。
60;12;5;Sim;文档\n相似度;相似度;#a1d99b;https://hidadeng.github.io;将两个文档表示为同维度的两个向量，因此向量可用于度量文档的相似性。
61;12;6;Dis;词语\n向量化;相似度;#a1d99b;https://hidadeng.github.io;将不同词语表示为同维度的不同向量，因此向量可用于度量词语的相似性。
62;12;7;Con;上下文\n词向量;相似度;#a1d99b;https://hidadeng.github.io;使用单词综合表示上下文的情景。
63;13;2;Nex;预测\n词语;文本生成;#a1d99b;https://hidadeng.github.io;根据上下文情况，预测下一个词
64;13;3;Rep;自动\n报告;文本生成;#a1d99b;https://hidadeng.github.io;基于结构化数据编写句子也称为Data2Tect文本生成。
65;13;4;Tra;翻译;文本生成;#a1d99b;https://hidadeng.github.io;机器翻译将文本完美地转换为另一种语言。
66;13;5;Asu;概括\n摘要;文本生成;#a1d99b;https://hidadeng.github.io;抽象摘要系统，通过使用尽可能少的单词生成新的短语来表达文本的内容。
67;13;6;Prp;改述(写);文本生成;#a1d99b;https://hidadeng.github.io;通过使用不同的词并保持语义含义将源文本的含义表达为新文本。感觉可以用于论文降重。
68;13;7;Rnn;RNN\nLSTM;文本生成;#a1d99b;https://hidadeng.github.io;自然语言处理深度神经网络框架RNN、LSTM
69;14;2;Rel;关系\n提取;系统应用;#c7e9c0;https://hidadeng.github.io;从文本中提取语义关系，在实体之间建立联系。
70;14;3;Qan;问答;系统应用;#c7e9c0;https://hidadeng.github.io;回答人类的提出的任何问题，无论提问的格式如何。
71;14;4;Cha;对话\n机器人;系统应用;#c7e9c0;https://hidadeng.github.io;为您的客户角色编写一个自然且令人信服的聊天机器人对话，以满足您客户的需求。
72;14;5;Sem;语义\n搜索\n索引;系统应用;#c7e9c0;https://hidadeng.github.io;除了关键字搜索之外，通过将有关一段文本的语义信息添加到索引，来提高搜索准确性。
73;14;6;Kno;知识库;系统应用;#c7e9c0;https://hidadeng.github.io;发现有关实体（NER、NEL）的事实，建立相关的知识库。
74;14;7;Edi;媒体监测;系统应用;#c7e9c0;https://hidadeng.github.io;大规模内容分析（用于识别、收集和生成信息的），可以监测并了解发声者的诉求，更好的开展相关事务（营销、舆情管理等）
75;15;1;App;交互\n应用\n开发;可视化;#756bb1;https://hidadeng.github.io;制作精美的交互Presentation应用
76;15;2;Ann;POS\n可视化;可视化;#bcbddc;https://hidadeng.github.io;不要只print文本，这样会丢失一些元信息。
77;15;3;Wcl;词云图;可视化;#bcbddc;https://hidadeng.github.io;大多数 Wordclouds 似乎忽略了可视化信息的最佳实践。
78;15;4;Emb;词嵌入\n可视化;可视化;#bcbddc;https://hidadeng.github.io;可视化。词向量，可以物以类聚，词以群分。
79;15;5;Tim;事件\n时间线;可视化;#bcbddc;https://hidadeng.github.io;通过在时间线上按时间顺序绘制事件来增加对文本的洞察力。
80;15;6;Map;地理可视化;可视化;#bcbddc;https://hidadeng.github.io;在地图上绘制地理编码的命名实体。
81;15;7;Gra;关系可视化;可视化;#bcbddc;https://hidadeng.github.io;可视化 命名实体词的图(关系网络)
