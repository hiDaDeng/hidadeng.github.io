<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta property="og:title" content="tomotopy | 速度最快的LDA主题模型">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>tomotopy | 速度最快的LDA主题模型 | 大邓和他的PYTHON</title>
<meta name="keywords" content="经管科研, lda, 文本分析, 文本挖掘, python, text analysis, text mining, social science, computational sociology, management" />
<meta name="description" content="接近C的速度，比市面的sklearn、gensim快十几倍">
<meta name="author" content="大邓">
<link rel="canonical" href="/blog/2023-04-25-tomotopy_is_the_fastest_topic_model/" />
<meta name="baidu-site-verification" content="codeva-q71uASYfGi" />
<meta name="360-site-verification" content="6b9b733ec558a1bb12cee8aa82f2529e" />
<meta name="sogou-site-verification" content="dZHPIorOhK" />
<link crossorigin="anonymous" href="/assets/css/stylesheet.min.css" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/assets/js/highlight.min.js" onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="apple-touch-icon" href="/apple-touch-icon.png">
<link rel="mask-icon" href="/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<meta name="generator" content="Hugo 0.89.4" />
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:title" content="tomotopy | 速度最快的LDA主题模型" />
<meta property="og:description" content="接近C的速度，比市面的sklearn、gensim快十几倍" />
<meta property="og:type" content="article" />
<meta property="og:url" content="/blog/2023-04-25-tomotopy_is_the_fastest_topic_model/" />
<meta property="og:image" content="/images/blog/tomotopy.png" /><meta property="article:section" content="blog" />
<meta property="article:published_time" content="2023-04-25T11:43:10&#43;06:00" />
<meta property="article:modified_time" content="2023-04-25T11:43:10&#43;06:00" />

<meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:image" content="/images/blog/tomotopy.png" />
<meta name="twitter:title" content="tomotopy | 速度最快的LDA主题模型"/>
<meta name="twitter:description" content="接近C的速度，比市面的sklearn、gensim快十几倍"/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Blogs",
      "item": "/blog/"
    }
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "tomotopy | 速度最快的LDA主题模型",
      "item": "/blog/2023-04-25-tomotopy_is_the_fastest_topic_model/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "tomotopy | 速度最快的LDA主题模型",
  "name": "tomotopy | 速度最快的LDA主题模型",
  "description": "接近C的速度，比市面的sklearn、gensim快十几倍",
  "keywords": [
    "经管科研", "lda", "文本分析", "文本挖掘", "python", "text analysis", "text mining", "social science", "computational sociology", "management"
  ],
  "articleBody": "代码下载 tomotopy简介？ tomotopy 是 tomoto（主题建模工具）的 Python 扩展，它是用 C++ 编写的基于 Gibbs 采样的主题模型库。支持的主题模型包括 LDA、DMR、HDP、MG-LDA、PA 和 HPA， 利用现代 CPU 的矢量化来最大化速度。\nhttps://github.com/bab2min/tomotopy\n下图中同样的数据集， tomotopy迭代200次，gensim迭代10次的情况下， tomotopy与gensim耗时对比图，由此可见tomotopy训练主题模型速度之快。 当前版本的 tomotopy 支持的主题模型包括\n 潜在狄利克雷分配（LDAModel） 标记的 LDA（LLDA 模型） 部分标记的 LDA（PLDA 模型） 监督LDA（SLDA模型） Dirichlet 多项回归 (DMRModel) 广义狄利克雷多项回归 (GDMRModel) 分层狄利克雷过程 (HDPModel) 分层LDA（HLDA模型） 多粒 LDA（MGLDA 模型） 弹珠盘分配（PAModel） 分层 PA (HPAModel) 相关主题模型（CTModel） 动态主题模型 (DTModel) 基于伪文档的主题模型（PTModel）。  安装 !pip3 install tomotopy==0.12.2 !pip3 install pyLDAvis==3.3.1 目前，tomotopy 可以利用 AVX2、AVX 或 SSE2 SIMD 指令集来最大程度利用PC的性能。\nimport tomotopy as tp tp.isa Run\n'avx2'  如果 tp.isa 返回 None，则训练过程可能需要很长时间。\n1. 导入数据 准备一个自己很熟悉的数据disaster_news.csv，一共有332条，话题数K=5，（正常情况下K是需要探索的）。\nimport pandas as pd df = pd.read_csv('disaster_news.csv') df.head() 2. 整理数据 分词、去除停用词,\nimport re import jieba stopwords = open('stopwords.txt', encoding='utf-8').read().split('\\n') def segment(text): words = jieba.lcut(text) words = [w for w in words if w not in stopwords] return words test = \"云南永善县级地震已致人伤间民房受损中新网月日电据云南昭通市防震减灾局官方网站消息截至日时云南昭通永善县级地震已造成人受伤其中重伤人轻伤人已全部送医院救治民房受损户间倒塌户间个乡镇所学校不同程度受损目前被损毁电力交通通讯设施已全部抢通修复当地已调拨帐篷顶紧急转移万人月日时分云南昭通永善县发生里氏级地震震源深度公里当地震感强烈此外成都等四川多地也有明显震感\" print(segment(test)) ['云南', '永善县', '级', '地震', '已致', '伤间', '民房', '受损', '中新网', '日电', '云南', '昭通市', '防震', '减灾', '局', '官方网站', '消息', '日时', '云南', '昭通', '永善县', '级', '地震', '造成', '受伤', '重伤', '轻伤', '送', '医院', '救治', '民房', '受损', '户间', '倒塌', '户间', '乡镇', '学校', '不同', '程度', '受损', '目前', '损毁', '电力', '交通', '通讯', '设施', '抢通', '修复', '调拨', '帐篷', '顶', '紧急', '转移', '万人', '时分', '云南', '昭通', '永善县', '发生', '里氏', '级', '地震', '震源', '深度', '公里', '震感', '强烈', '成都', '四川', '多地', '明显', '震感']  df['words'] = df['text'].apply(segment) df.head() 3. 找到最佳K 绘制Coherence曲线是一种常见的方法，用于选择主题数（k）的最佳值。这可以帮助您确定在哪个主题数下主题模型的性能最佳。以下是一般步骤以及如何解释Coherence曲线来找出最佳的k：\n 创建主题模型：首先，您需要使用不同的k值来创建一系列主题模型，每个模型都有不同数量的主题（k）。这可以通过循环遍历k值并训练主题模型来完成。 计算Coherence：对于每个k值，使用tomotopy.coherence.Coherence类计算主题模型的一致性度量（比如C_V、UMass等）。这将为每个k值生成一个一致性得分。 绘制Coherence曲线：将k值（主题数）作为x轴，一致性得分作为y轴，绘制Coherence曲线。得到一个k和一致性得分之间的关系图。 寻找拐点：观察Coherence曲线，通常会看到一条曲线在某个k值附近达到峰值，然后开始下降。这个峰值对应的k值通常被认为是最佳的主题数。这是因为在这个k值下，主题模型的主题在文本中的一致性较高。 选择最佳k：根据Coherence曲线上的峰值，选择最佳的k值作为主题模型的最终主题数。 模型评估：一旦选择了最佳k值，您可以使用该值来训练最终的主题模型，并在任务中进行评估。  Coherence曲线上的峰值通常对应于最佳的主题数，因为在这个点上主题之间的关联度较高。然而，需要谨慎选择，因为有时候峰值可能不明显，或者可能有多个相似的峰值。您可以使用这个方法来帮助确定最佳的主题数，但最终的决策可能还需要结合领域知识和任务需求来做出。\ntomotopy每次运行得到的图形状不一样，为了保证运行结果具有可比性，设置了随机种子seed为1，你也可以根据需要改为自己需要的随机状态(这里有点像炼丹)。经过运行发现k=5比较合适（跑出了我的预判）。\ndef find_k(docs, min_k=1, max_k=20, min_df=2): #min_df 词语最少出现在2个文档中 import matplotlib.pyplot as plt scores = [] for k in range(min_k, max_k): #seed随机种子，保证在大邓这里运行结果与你运行的结果一样 mdl = tp.LDAModel(min_df=min_df, k=k, seed=1) for words in docs: if words: mdl.add_doc(words) mdl.train(20) coh = tp.coherence.Coherence(mdl) scores.append(coh.get_score()) #x = list(range(min_k, max_k - 1)) # 区间最右侧的值。注意：不能大于max_k #print(x) #print() plt.plot(range(min_k, max_k), scores) plt.xlabel(\"number of topics\") plt.ylabel(\"coherence\") plt.show() find_k(docs=df['words'], min_k=1, max_k=10, min_df=2) 4. 训练lda 使用tomotopy的LDA模型， 话题数K=5\nimport tomotopy as tp #初始化LDA mdl = tp.LDAModel(k=5, min_df=2, seed=555) for words in df['words']: #确认words 是 非空词语列表 if words: mdl.add_doc(words=words) #训练 mdl.train() #查看每个topic feature words for k in range(mdl.k): print('Top 10 words of topic #{}'.format(k)) print(mdl.get_topic_words(k, top_n=10)) print('\\n') Run\nTop 10 words of topic #0 [('一辆', 0.02751251682639122), ('事故', 0.021704642102122307), ('记者', 0.018342189490795135), ('死亡', 0.01650812290608883), ('造成', 0.014062701724469662), ('人员', 0.013909862376749516), ('现场', 0.013451346196234226), ('受伤', 0.012687151320278645), ('相撞', 0.011922957375645638), ('货车', 0.011922957375645638)] ​ ​ Top 10 words of topic #1 ​ [('学生', 0.02709135226905346), ('食物中毒', 0.02498047426342964), ('出现', 0.019175563007593155), ('医院', 0.016185153275728226), ('事件', 0.013546556234359741), ('调查', 0.013194743543863297), ('年月日', 0.012842929922044277), ('治疗', 0.012667023576796055), ('症状', 0.011787491850554943), ('名', 0.011259771883487701)] ​ ​ Top 10 words of topic #2 ​ [('现场', 0.018848909065127373), ('发生', 0.01677251048386097), ('医院', 0.015015557408332825), ('起火', 0.014216942712664604), ('原因', 0.012140544131398201), ('目前', 0.012140544131398201), ('救治', 0.01150165218859911), ('进行', 0.011022482998669147), ('名', 0.009425252676010132), ('火势', 0.009265529923141003)] ​ ​ Top 10 words of topic #3 ​ [('发生', 0.03348556533455849), ('爆炸', 0.022389251738786697), ('造成', 0.019663840532302856), ('死亡', 0.01713310182094574), ('受伤', 0.016938429325819016), ('年月日', 0.016354413703083992), ('轿车', 0.012655640952289104), ('警方', 0.012460969388484955), ('袭击', 0.012266295962035656), ('事件', 0.011487606912851334)] ​ ​ Top 10 words of topic #4 ​ [('地震', 0.047826822847127914), ('发生', 0.03555167838931084), ('火灾', 0.03140682727098465), ('时分', 0.020885275676846504), ('级', 0.015783920884132385), ('时间', 0.013870910741388798), ('公里', 0.013711493462324142), ('人员伤亡', 0.013073823414742947), ('记者', 0.013073823414742947), ('震感', 0.012276736088097095)] \n查看话题模型信息\nmdl.summary() Run\nBasicInfo|LDAModel(currentversion:0.12.2)|332docs,29749words|TotalVocabs:8428,UsedVocabs:2984|Entropyofwords:7.10665|Entropyofterm-weightedwords:7.10665|RemovedVocabs:NA|TrainingInfo|Iterations:10,Burn-insteps:0|OptimizationInterval:10|Log-likelihoodperword:-7.79934|InitialParameters|tw:TermWeight.ONE|min_cf:0(minimumcollectionfrequencyofwords)|min_df:2(minimumdocumentfrequencyofwords)|rm_top:0(thenumberoftopwordstoberemoved)|k:5(thenumberoftopicsbetween1~32767)|alpha:[0.1](hyperparameterofDirichletdistributionfordocument-topic,givenasasingle`float`incaseofsymmetricpriorandasalistwithlength`k`of`float`incaseofasymmetricprior.)|eta:0.01(hyperparameterofDirichletdistributionfortopic-word)|seed:555(randomseed)|trainedinversion0.12.2|Parameters|alpha(Dirichletpriorontheper-documenttopicdistributions)|[0.71433650.68525130.750896160.62046770.7040125]|eta(Dirichletpriorontheper-topicworddistribution)|0.01|Topics|#0 (6513) : 一辆 事故 记者 死亡 造成 |#1 (5655) : 学生 食物中毒 出现 医院 事件 |#2 (6231) : 现场 发生 医院 起火 原因 |#3 (5107) : 发生 爆炸 造成 死亡 受伤 |#4 (6243) : 地震 发生 火灾 时分 级 topic解读 根据每个话题top10的特征词，5个话题解读为\n 交通事故| #0 (6513) : 一辆 事故 记者 死亡 造成 食品安全| #1 (5655) : 学生 食物中毒 出现 医院 事件 火灾新闻| #2 (6231) : 现场 发生 医院 起火 原因 恐怖袭击| #3 (5107) : 发生 爆炸 造成 死亡 受伤 地震灾害| #4 (6243) : 地震 发生 火灾 时分 级  5. 可视化 使用pyLDAvis\nimport pyLDAvis import numpy as np import warnings warnings.filterwarnings('ignore', category=Warning) #在notebook显示 pyLDAvis.enable_notebook() #获取pyldavis需要的参数 topic_term_dists = np.stack([mdl.get_topic_word_dist(k) for k in range(mdl.k)]) doc_topic_dists = np.stack([doc.get_topic_dist() for doc in mdl.docs]) doc_topic_dists /= doc_topic_dists.sum(axis=1, keepdims=True) doc_lengths = np.array([len(doc.words) for doc in mdl.docs]) vocab = list(mdl.used_vocabs) term_frequency = mdl.used_vocab_freq prepared_data = pyLDAvis.prepare( topic_term_dists, doc_topic_dists, doc_lengths, vocab, term_frequency, start_index=0, # tomotopy话题id从0开始，pyLDAvis话题id从1开始 sort_topics=False #注意：否则pyLDAvis与tomotopy内的话题无法一一对应。  ) #可视化结果存到html文件中 #pyLDAvis.save_html(prepared_data, 'ldavis.html') #notebook中显示 pyLDAvis.display(prepared_data) 6. 预测 预测某文档的话题\nimport jieba stopwords = open('stopwords.txt', encoding='utf-8').read().split('\\n') #预测 doc = '云南永善县级地震已致伤间民房受损中新网日电云南昭通市防震减灾局官方网站消息日时云南昭通永善县级地震造成受伤重伤轻伤送医院救治民房受损户间倒塌户间乡镇学校不同程度受损目前损毁电力交通通讯设施抢通修复调拨帐篷顶紧急转移万人时分云南昭通永善县发生里氏级地震震源深度公里震感强烈成都四川多地明显震感' words = [w for w in jieba.lcut(doc) if w not in stopwords] #构造tomotopy需要的数据 doc_inst = mdl.make_doc(words=words) topic_dist, ll = mdl.infer(doc_inst) print(\"Topic Distribution for Unseen Docs: \", topic_dist) Topic Distribution for Unseen Docs: [0.11645161 0.10240361 0.5342029 0.03622254 0.21071935]  列表长度为5， 列表第三个数值(topic #2)数值最大，该文本最大的可能性是topic #2\n补充: 指定主题特征词 如果对数据比较了解，已经知道有一些主题，可以把比较明显的词语分配给指定的topic_id。\nmdl = tp.LDAModel(k=5, min_df=2, seed=555) for words in df['words']: if words: mdl.add_doc(words) #把word相撞 分配给topic_0, 权重设置为1， 其他topic权重设置为0.1 #注意这里的range(5) 5是对应的k值 mdl.set_word_prior('相撞', [1.0 if k == 0 else 0.1 for k in range(5)]) #把word地震 分配给topic_1, 权重设置为1， 其他topic权重设置为0.1 mdl.set_word_prior('地震', [1.0 if k == 1 else 0.1 for k in range(5)]) #把word火灾 分配给topic_2, 权重设置为1， 其他topic权重设置为0.1 mdl.set_word_prior('火灾', [1.0 if k == 2 else 0.1 for k in range(5)]) #把word中毒 分配给topic_3, 权重设置为1， 其他topic权重设置为0.1 mdl.set_word_prior('中毒', [1.0 if k == 3 else 0.1 for k in range(5)]) #把word袭击 分配给topic_4, 权重设置为1， 其他topic权重设置为0.1 mdl.set_word_prior('袭击', [1.0 if k == 4 else 0.1 for k in range(5)]) mdl.train() mdl.summary() | LDAModel (current version: 0.12.2) | 332 docs, 29749 words | Total Vocabs: 8428, Used Vocabs: 2984 | Entropy of words: 7.10665 | Entropy of term-weighted words: 7.10665 | Removed Vocabs:  | | Iterations: 10, Burn-in steps: 0 | Optimization Interval: 10 | Log-likelihood per word: -7.72251 | | tw: TermWeight.ONE | min_cf: 0 (minimum collection frequency of words) | min_df: 2 (minimum document frequency of words) | rm_top: 0 (the number of top words to be removed) | k: 5 (the number of topics between 1 ~ 32767) | alpha: [0.1] (hyperparameter of Dirichlet distribution for document-topic, given as a single `float` in case of symmetric prior and as a list with length `k` of `float` in case of asymmetric prior.) | eta: 0.01 (hyperparameter of Dirichlet distribution for topic-word) | seed: 555 (random seed) | trained in version 0.12.2 |  | alpha (Dirichlet prior on the per-document topic distributions) | [0.7106193 0.60264444 0.5734784 0.71375024 0.6234263 ] | eta (Dirichlet prior on the per-topic word distribution) | 0.01 |  | #0 (6599) : 一辆 事故 死亡 发生 造成 | #1 (6087) : 地震 发生 级 公里 年月日 | #2 (5892) : 火灾 发生 现场 大火 起火 | #3 (6402) : 医院 学生 食物中毒 出现 名 | #4 (4769) : 事件 发生 袭击 人员 工作 |  广而告之  长期征稿 长期招募小伙伴 付费视频课 | Python实证指标构建与文本分析  ",
  "wordCount" : "992",
  "inLanguage": "en",
  "image":"/images/blog/tomotopy.png","datePublished": "2023-04-25T11:43:10+06:00",
  "dateModified": "2023-04-25T11:43:10+06:00",
  "author":{
    "@type": "Person",
    "name": "大邓"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "/blog/2023-04-25-tomotopy_is_the_fastest_topic_model/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "大邓和他的PYTHON",
    "logo": {
      "@type": "ImageObject",
      "url": "/favicon.ico"
    }
  }
}
</script>
<script async src="https://www.googletagmanager.com/gtag/js?id=G-SFGQCREQ9X"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-SFGQCREQ9X');
</script>



<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC" rel="stylesheet">
<link href="https://fonts.googleapis.com/css2?family=PT+Serif" rel="stylesheet">
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="/" accesskey="h" title="大邓和他的PYTHON (Alt + H)" target="_blank">大邓和他的PYTHON</a>
            <span class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </span>
        </div>
        <ul id="menu">
            <li>
                <a href="/about/" title="关于" target="_blank">
                    <span>关于</span>
                </a>
            </li>
            <li>
                <a href="/blog" title="博文" target="_blank">
                    <span>博文</span>
                </a>
            </li>
            <li>
                <a href="/search/" title="搜索" target="_blank">
                    <span>搜索</span>
                </a>
            </li>
            <li>
                <a href="/tags/" title="标签" target="_blank">
                    <span>标签</span>
                </a>
            </li>
            <li>
                <a href="/blog/management_python_course/" title="课程" target="_blank">
                    <span>课程</span>
                </a>
            </li>
            <li>
                <a href="/blog/datasets_available_for_management_science/" title="数据" target="_blank">
                    <span>数据</span>
                </a>
            </li>
            <li>
                <a href="/index.xml" title="RSS" target="_blank">
                    <span>RSS</span>
                </a>
            </li>
            <li>
                <a href="/blog/2024-04-27-cntext2x-usage-tutorial/" title="cntext2.x" target="_blank">
                    <span>cntext2.x</span>
                </a>
            </li>
            <li>
                <a href="/support/" title="打赏" target="_blank">
                    <span>打赏</span>
                </a>
            </li>
            <li>
                <a href="https://github.com/hiDaDeng/hidadeng.github.io/discussions/" title="留言板" target="_blank">
                    <span>留言板</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">


<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js" integrity="sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js" integrity="sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa" crossorigin="anonymous"
onload="renderMathInElement(document.body);"></script>




<article class="post-single">
  <header class="post-header">
    
    <div class="breadcrumbs"><a href="/" target="_blank">Home</a>&nbsp;»&nbsp;<a href="/blog/" target="_blank">Blogs</a></div>
    <h1 class="post-title">
      tomotopy | 速度最快的LDA主题模型
    </h1>
    <div class="post-meta"><span title='2023-04-25 11:43:10 +0600 +0600'>2023-04-25</span>&nbsp;·&nbsp;5 min&nbsp;·&nbsp;大邓

</div>
  </header> 
<figure class="entry-cover"><a href="/images/blog/tomotopy.png" target="_blank"
            rel="noopener noreferrer"><img loading="lazy" src="/images/blog/tomotopy.png" alt=""></a>
        
</figure>
<div class="share-buttons">
    <a target="_blank" rel="noopener noreferrer" aria-label="share tomotopy | 速度最快的LDA主题模型 on twitter"
        href="https://twitter.com/intent/tweet/?text=tomotopy%20%7c%20%e9%80%9f%e5%ba%a6%e6%9c%80%e5%bf%ab%e7%9a%84LDA%e4%b8%bb%e9%a2%98%e6%a8%a1%e5%9e%8b&amp;url=%2fblog%2f2023-04-25-tomotopy_is_the_fastest_topic_model%2f&amp;hashtags=%e5%ad%a6%e6%9c%af%e5%ba%94%e7%94%a8%2c%e6%96%87%e6%9c%ac%e5%88%86%e6%9e%90%2c%e6%95%b0%e6%8d%ae%e5%88%86%e6%9e%90%2c%e7%ac%ac%e4%b8%89%e6%96%b9%e5%8c%85">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-253.927,424.544c135.939,0 210.268,-112.643 210.268,-210.268c0,-3.218 0,-6.437 -0.153,-9.502c14.406,-10.421 26.973,-23.448 36.935,-38.314c-13.18,5.824 -27.433,9.809 -42.452,11.648c15.326,-9.196 26.973,-23.602 32.49,-40.92c-14.252,8.429 -30.038,14.56 -46.896,17.931c-13.487,-14.406 -32.644,-23.295 -53.946,-23.295c-40.767,0 -73.87,33.104 -73.87,73.87c0,5.824 0.613,11.494 1.992,16.858c-61.456,-3.065 -115.862,-32.49 -152.337,-77.241c-6.284,10.881 -9.962,23.601 -9.962,37.088c0,25.594 13.027,48.276 32.95,61.456c-12.107,-0.307 -23.448,-3.678 -33.41,-9.196l0,0.92c0,35.862 25.441,65.594 59.311,72.49c-6.13,1.686 -12.72,2.606 -19.464,2.606c-4.751,0 -9.348,-0.46 -13.946,-1.38c9.349,29.426 36.628,50.728 68.965,51.341c-25.287,19.771 -57.164,31.571 -91.8,31.571c-5.977,0 -11.801,-0.306 -17.625,-1.073c32.337,21.15 71.264,33.41 112.95,33.41Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share tomotopy | 速度最快的LDA主题模型 on linkedin"
        href="https://www.linkedin.com/shareArticle?mini=true&amp;url=%2fblog%2f2023-04-25-tomotopy_is_the_fastest_topic_model%2f&amp;title=tomotopy%20%7c%20%e9%80%9f%e5%ba%a6%e6%9c%80%e5%bf%ab%e7%9a%84LDA%e4%b8%bb%e9%a2%98%e6%a8%a1%e5%9e%8b&amp;summary=tomotopy%20%7c%20%e9%80%9f%e5%ba%a6%e6%9c%80%e5%bf%ab%e7%9a%84LDA%e4%b8%bb%e9%a2%98%e6%a8%a1%e5%9e%8b&amp;source=%2fblog%2f2023-04-25-tomotopy_is_the_fastest_topic_model%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share tomotopy | 速度最快的LDA主题模型 on reddit"
        href="https://reddit.com/submit?url=%2fblog%2f2023-04-25-tomotopy_is_the_fastest_topic_model%2f&title=tomotopy%20%7c%20%e9%80%9f%e5%ba%a6%e6%9c%80%e5%bf%ab%e7%9a%84LDA%e4%b8%bb%e9%a2%98%e6%a8%a1%e5%9e%8b">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share tomotopy | 速度最快的LDA主题模型 on facebook"
        href="https://facebook.com/sharer/sharer.php?u=%2fblog%2f2023-04-25-tomotopy_is_the_fastest_topic_model%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share tomotopy | 速度最快的LDA主题模型 on whatsapp"
        href="https://api.whatsapp.com/send?text=tomotopy%20%7c%20%e9%80%9f%e5%ba%a6%e6%9c%80%e5%bf%ab%e7%9a%84LDA%e4%b8%bb%e9%a2%98%e6%a8%a1%e5%9e%8b%20-%20%2fblog%2f2023-04-25-tomotopy_is_the_fastest_topic_model%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share tomotopy | 速度最快的LDA主题模型 on telegram"
        href="https://telegram.me/share/url?text=tomotopy%20%7c%20%e9%80%9f%e5%ba%a6%e6%9c%80%e5%bf%ab%e7%9a%84LDA%e4%b8%bb%e9%a2%98%e6%a8%a1%e5%9e%8b&amp;url=%2fblog%2f2023-04-25-tomotopy_is_the_fastest_topic_model%2f">
        <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28">
            <path
                d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
        </svg>
    </a>
    
</div>
<aside id="toc-container" class="toc-container wide">
    <div class="toc">
        <details  open>
            <summary accesskey="c" title="(Alt + C)">
                <span class="details">Table of Contents</span>
            </summary>

            <div class="inner"><ul>
                    <li>
                        <a href="#%e4%bb%a3%e7%a0%81%e4%b8%8b%e8%bd%bdtomotopy_codezip" aria-label="代码下载"><a href="tomotopy_code.zip">代码下载</a></a></li>
                    <li>
                        <a href="#tomotopy%e7%ae%80%e4%bb%8b" aria-label="tomotopy简介？">tomotopy简介？</a></li>
                    <li>
                        <a href="#%e5%ae%89%e8%a3%85" aria-label="安装">安装</a></li>
                    <li>
                        <a href="#1-%e5%af%bc%e5%85%a5%e6%95%b0%e6%8d%ae" aria-label="1. 导入数据">1. 导入数据</a></li>
                    <li>
                        <a href="#2-%e6%95%b4%e7%90%86%e6%95%b0%e6%8d%ae" aria-label="2. 整理数据">2. 整理数据</a></li>
                    <li>
                        <a href="#3-%e6%89%be%e5%88%b0%e6%9c%80%e4%bd%b3k" aria-label="3. 找到最佳K">3. 找到最佳K</a></li>
                    <li>
                        <a href="#4-%e8%ae%ad%e7%bb%83lda" aria-label="4. 训练lda">4. 训练lda</a><ul>
                            
                    <li>
                        <a href="#topic%e8%a7%a3%e8%af%bb" aria-label="topic解读">topic解读</a></li></ul>
                    </li>
                    <li>
                        <a href="#5-%e5%8f%af%e8%a7%86%e5%8c%96" aria-label="5. 可视化">5. 可视化</a></li>
                    <li>
                        <a href="#6-%e9%a2%84%e6%b5%8b" aria-label="6. 预测">6. 预测</a></li>
                    <li>
                        <a href="#%e8%a1%a5%e5%85%85-%e6%8c%87%e5%ae%9a%e4%b8%bb%e9%a2%98%e7%89%b9%e5%be%81%e8%af%8d" aria-label="补充: 指定主题特征词">补充: 指定主题特征词</a></li>
                    <li>
                        <a href="#%e5%b9%bf%e8%80%8c%e5%91%8a%e4%b9%8b" aria-label="广而告之">广而告之</a>
                    </li>
                </ul>
            </div>
        </details>
    </div>
</aside>
<script>
    let activeElement;
    let elements;
    window.addEventListener('DOMContentLoaded', function (event) {
        checkTocPosition();

        elements = document.querySelectorAll('h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]');
         
         activeElement = elements[0];
         const id = encodeURI(activeElement.getAttribute('id')).toLowerCase();
         document.querySelector(`.inner ul li a[href="#${id}"]`).classList.add('active');
     }, false);

    window.addEventListener('resize', function(event) {
        checkTocPosition();
    }, false);

    window.addEventListener('scroll', () => {
        
        activeElement = Array.from(elements).find((element) => {
            if ((getOffsetTop(element) - window.pageYOffset) > 0 && 
                (getOffsetTop(element) - window.pageYOffset) < window.innerHeight/2) {
                return element;
            }
        }) || activeElement

        elements.forEach(element => {
             const id = encodeURI(element.getAttribute('id')).toLowerCase();
             if (element === activeElement){
                 document.querySelector(`.inner ul li a[href="#${id}"]`).classList.add('active');
             } else {
                 document.querySelector(`.inner ul li a[href="#${id}"]`).classList.remove('active');
             }
         })
     }, false);

    const main = parseInt(getComputedStyle(document.body).getPropertyValue('--article-width'), 10);
    const toc = parseInt(getComputedStyle(document.body).getPropertyValue('--toc-width'), 10);
    const gap = parseInt(getComputedStyle(document.body).getPropertyValue('--gap'), 10);

    function checkTocPosition() {
        const width = document.body.scrollWidth;

        if (width - main - (toc * 2) - (gap * 4) > 0) {
            document.getElementById("toc-container").classList.add("wide");
        } else {
            document.getElementById("toc-container").classList.remove("wide");
        }
    }

    function getOffsetTop(element) {
        if (!element.getClientRects().length) {
            return 0;
        }
        let rect = element.getBoundingClientRect();
        let win = element.ownerDocument.defaultView;
        return rect.top + win.pageYOffset;   
    }
</script>

  <div class="post-content"><h2 id="代码下载tomotopy_codezip"><a href="tomotopy_code.zip">代码下载</a><a hidden class="anchor" aria-hidden="true" href="#代码下载tomotopy_codezip">#</a></h2>
<br>
<h2 id="tomotopy简介">tomotopy简介？<a hidden class="anchor" aria-hidden="true" href="#tomotopy简介">#</a></h2>
<p>tomotopy 是 tomoto（主题建模工具）的 Python 扩展，它是用 C++ 编写的基于 Gibbs 采样的主题模型库。支持的主题模型包括 LDA、DMR、HDP、MG-LDA、PA 和 HPA， 利用现代 CPU 的矢量化来最大化速度。</p>
<p><a href="https://github.com/bab2min/tomotopy">https://github.com/bab2min/tomotopy</a></p>
<p><strong>下图中同样的数据集， tomotopy迭代200次，gensim迭代10次的情况下， tomotopy与gensim耗时对比图，由此可见tomotopy训练主题模型速度之快。</strong>
<img loading="lazy" src="img/TomotopyVsGensim.png" alt=""  />
</p>
<p>当前版本的 tomotopy 支持的主题模型包括</p>
<ul>
<li>潜在狄利克雷分配（LDAModel）</li>
<li>标记的 LDA（LLDA 模型）</li>
<li>部分标记的 LDA（PLDA 模型）</li>
<li>监督LDA（SLDA模型）</li>
<li>Dirichlet 多项回归 (DMRModel)</li>
<li>广义狄利克雷多项回归 (GDMRModel)</li>
<li>分层狄利克雷过程 (HDPModel)</li>
<li>分层LDA（HLDA模型）</li>
<li>多粒 LDA（MGLDA 模型）</li>
<li>弹珠盘分配（PAModel）</li>
<li>分层 PA (HPAModel)</li>
<li>相关主题模型（CTModel）</li>
<li>动态主题模型 (DTModel)</li>
<li>基于伪文档的主题模型（PTModel）。</li>
</ul>
<br>
<h2 id="安装">安装<a hidden class="anchor" aria-hidden="true" href="#安装">#</a></h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="err">!</span><span class="n">pip3</span> <span class="n">install</span> <span class="n">tomotopy</span><span class="o">==</span><span class="mf">0.12.2</span>
<span class="err">!</span><span class="n">pip3</span> <span class="n">install</span> <span class="n">pyLDAvis</span><span class="o">==</span><span class="mf">3.3.1</span>  
</code></pre></div><p>目前，tomotopy 可以利用 AVX2、AVX 或 SSE2 SIMD 指令集来最大程度利用PC的性能。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">tomotopy</span> <span class="k">as</span> <span class="nn">tp</span>

<span class="n">tp</span><span class="o">.</span><span class="n">isa</span>
</code></pre></div><p>Run</p>
<pre><code>'avx2'
</code></pre>
<p>如果 tp.isa 返回 None，则训练过程可能需要很长时间。</p>
<br>
<h2 id="1-导入数据">1. 导入数据<a hidden class="anchor" aria-hidden="true" href="#1-导入数据">#</a></h2>
<p>准备一个自己很熟悉的数据disaster_news.csv，一共有332条，话题数K=5，（正常情况下K是需要探索的）。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;disaster_news.csv&#39;</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/df1.png" alt=""  />
</p>
<br>
<h2 id="2-整理数据">2. 整理数据<a hidden class="anchor" aria-hidden="true" href="#2-整理数据">#</a></h2>
<p>分词、去除停用词,</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">re</span>
<span class="kn">import</span> <span class="nn">jieba</span>

<span class="n">stopwords</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;stopwords.txt&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">read</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">segment</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="n">words</span> <span class="o">=</span> <span class="n">jieba</span><span class="o">.</span><span class="n">lcut</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
    <span class="n">words</span> <span class="o">=</span> <span class="p">[</span><span class="n">w</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">words</span> <span class="k">if</span> <span class="n">w</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">stopwords</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">words</span>

<span class="n">test</span> <span class="o">=</span> <span class="s2">&#34;云南永善县级地震已致人伤间民房受损中新网月日电据云南昭通市防震减灾局官方网站消息截至日时云南昭通永善县级地震已造成人受伤其中重伤人轻伤人已全部送医院救治民房受损户间倒塌户间个乡镇所学校不同程度受损目前被损毁电力交通通讯设施已全部抢通修复当地已调拨帐篷顶紧急转移万人月日时分云南昭通永善县发生里氏级地震震源深度公里当地震感强烈此外成都等四川多地也有明显震感&#34;</span>
<span class="nb">print</span><span class="p">(</span><span class="n">segment</span><span class="p">(</span><span class="n">test</span><span class="p">))</span>
</code></pre></div><pre><code>['云南', '永善县', '级', '地震', '已致', '伤间', '民房', '受损', '中新网', '日电', '云南', '昭通市', '防震', '减灾', '局', '官方网站', '消息', '日时', '云南', '昭通', '永善县', '级', '地震', '造成', '受伤', '重伤', '轻伤', '送', '医院', '救治', '民房', '受损', '户间', '倒塌', '户间', '乡镇', '学校', '不同', '程度', '受损', '目前', '损毁', '电力', '交通', '通讯', '设施', '抢通', '修复', '调拨', '帐篷', '顶', '紧急', '转移', '万人', '时分', '云南', '昭通', '永善县', '发生', '里氏', '级', '地震', '震源', '深度', '公里', '震感', '强烈', '成都', '四川', '多地', '明显', '震感']
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df</span><span class="p">[</span><span class="s1">&#39;words&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">segment</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/df2.png" alt=""  />
</p>
<br>
<h2 id="3-找到最佳k">3. 找到最佳K<a hidden class="anchor" aria-hidden="true" href="#3-找到最佳k">#</a></h2>
<p>绘制Coherence曲线是一种常见的方法，用于选择主题数（k）的最佳值。这可以帮助您确定在哪个主题数下主题模型的性能最佳。以下是一般步骤以及如何解释Coherence曲线来找出最佳的k：</p>
<ol>
<li>创建主题模型：首先，您需要使用不同的k值来创建一系列主题模型，每个模型都有不同数量的主题（k）。这可以通过循环遍历k值并训练主题模型来完成。</li>
<li>计算Coherence：对于每个k值，使用tomotopy.coherence.Coherence类计算主题模型的一致性度量（比如C_V、UMass等）。这将为每个k值生成一个一致性得分。</li>
<li>绘制Coherence曲线：将k值（主题数）作为x轴，一致性得分作为y轴，绘制Coherence曲线。得到一个k和一致性得分之间的关系图。</li>
<li>寻找拐点：观察Coherence曲线，通常会看到一条曲线在某个k值附近达到峰值，然后开始下降。这个峰值对应的k值通常被认为是最佳的主题数。这是因为在这个k值下，主题模型的主题在文本中的一致性较高。</li>
<li>选择最佳k：根据Coherence曲线上的峰值，选择最佳的k值作为主题模型的最终主题数。</li>
<li>模型评估：一旦选择了最佳k值，您可以使用该值来训练最终的主题模型，并在任务中进行评估。</li>
</ol>
<p>Coherence曲线上的峰值通常对应于最佳的主题数，因为在这个点上主题之间的关联度较高。然而，需要谨慎选择，因为有时候峰值可能不明显，或者可能有多个相似的峰值。您可以使用这个方法来帮助确定最佳的主题数，但最终的决策可能还需要结合领域知识和任务需求来做出。</p>
<p>tomotopy每次运行得到的图形状不一样，为了保证运行结果具有可比性，设置了随机种子seed为1，你也可以根据需要改为自己需要的随机状态(这里有点像炼丹)。经过运行发现k=5比较合适（跑出了我的预判）。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">find_k</span><span class="p">(</span><span class="n">docs</span><span class="p">,</span> <span class="n">min_k</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_k</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">min_df</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
    <span class="c1">#min_df 词语最少出现在2个文档中</span>
    <span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
    <span class="n">scores</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">min_k</span><span class="p">,</span> <span class="n">max_k</span><span class="p">):</span>
        <span class="c1">#seed随机种子，保证在大邓这里运行结果与你运行的结果一样</span>
        <span class="n">mdl</span> <span class="o">=</span> <span class="n">tp</span><span class="o">.</span><span class="n">LDAModel</span><span class="p">(</span><span class="n">min_df</span><span class="o">=</span><span class="n">min_df</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="n">k</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">words</span> <span class="ow">in</span> <span class="n">docs</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">words</span><span class="p">:</span>
                <span class="n">mdl</span><span class="o">.</span><span class="n">add_doc</span><span class="p">(</span><span class="n">words</span><span class="p">)</span>
        <span class="n">mdl</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
        <span class="n">coh</span> <span class="o">=</span> <span class="n">tp</span><span class="o">.</span><span class="n">coherence</span><span class="o">.</span><span class="n">Coherence</span><span class="p">(</span><span class="n">mdl</span><span class="p">)</span>
        <span class="n">scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">coh</span><span class="o">.</span><span class="n">get_score</span><span class="p">())</span>

    <span class="c1">#x = list(range(min_k, max_k - 1))  # 区间最右侧的值。注意：不能大于max_k</span>
    <span class="c1">#print(x)</span>
    <span class="c1">#print()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">min_k</span><span class="p">,</span> <span class="n">max_k</span><span class="p">),</span> <span class="n">scores</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&#34;number of topics&#34;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&#34;coherence&#34;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
    
    
<span class="n">find_k</span><span class="p">(</span><span class="n">docs</span><span class="o">=</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;words&#39;</span><span class="p">],</span> <span class="n">min_k</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_k</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">min_df</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</code></pre></div><p><img loading="lazy" src="img/output_11_0.png" alt="png"  />
</p>
<br>
<h2 id="4-训练lda">4. 训练lda<a hidden class="anchor" aria-hidden="true" href="#4-训练lda">#</a></h2>
<p>使用tomotopy的LDA模型， 话题数K=5</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">tomotopy</span> <span class="k">as</span> <span class="nn">tp</span>

<span class="c1">#初始化LDA</span>
<span class="n">mdl</span> <span class="o">=</span> <span class="n">tp</span><span class="o">.</span><span class="n">LDAModel</span><span class="p">(</span><span class="n">k</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">min_df</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">555</span><span class="p">)</span>
<span class="k">for</span> <span class="n">words</span> <span class="ow">in</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;words&#39;</span><span class="p">]:</span>
    <span class="c1">#确认words 是 非空词语列表</span>
    <span class="k">if</span> <span class="n">words</span><span class="p">:</span>
        <span class="n">mdl</span><span class="o">.</span><span class="n">add_doc</span><span class="p">(</span><span class="n">words</span><span class="o">=</span><span class="n">words</span><span class="p">)</span>

<span class="c1">#训练</span>
<span class="n">mdl</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

<span class="c1">#查看每个topic feature words</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">mdl</span><span class="o">.</span><span class="n">k</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Top 10 words of topic #</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">k</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">mdl</span><span class="o">.</span><span class="n">get_topic_words</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">top_n</span><span class="o">=</span><span class="mi">10</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">    Top 10 words of topic #0
    [(&#39;一辆&#39;, 0.02751251682639122), (&#39;事故&#39;, 0.021704642102122307), (&#39;记者&#39;, 0.018342189490795135), (&#39;死亡&#39;, 0.01650812290608883), (&#39;造成&#39;, 0.014062701724469662), (&#39;人员&#39;, 0.013909862376749516), (&#39;现场&#39;, 0.013451346196234226), (&#39;受伤&#39;, 0.012687151320278645), (&#39;相撞&#39;, 0.011922957375645638), (&#39;货车&#39;, 0.011922957375645638)]


​    
​    Top 10 words of topic #1
​    [(&#39;学生&#39;, 0.02709135226905346), (&#39;食物中毒&#39;, 0.02498047426342964), (&#39;出现&#39;, 0.019175563007593155), (&#39;医院&#39;, 0.016185153275728226), (&#39;事件&#39;, 0.013546556234359741), (&#39;调查&#39;, 0.013194743543863297), (&#39;年月日&#39;, 0.012842929922044277), (&#39;治疗&#39;, 0.012667023576796055), (&#39;症状&#39;, 0.011787491850554943), (&#39;名&#39;, 0.011259771883487701)]


​    
​    Top 10 words of topic #2
​    [(&#39;现场&#39;, 0.018848909065127373), (&#39;发生&#39;, 0.01677251048386097), (&#39;医院&#39;, 0.015015557408332825), (&#39;起火&#39;, 0.014216942712664604), (&#39;原因&#39;, 0.012140544131398201), (&#39;目前&#39;, 0.012140544131398201), (&#39;救治&#39;, 0.01150165218859911), (&#39;进行&#39;, 0.011022482998669147), (&#39;名&#39;, 0.009425252676010132), (&#39;火势&#39;, 0.009265529923141003)]


​    
​    Top 10 words of topic #3
​    [(&#39;发生&#39;, 0.03348556533455849), (&#39;爆炸&#39;, 0.022389251738786697), (&#39;造成&#39;, 0.019663840532302856), (&#39;死亡&#39;, 0.01713310182094574), (&#39;受伤&#39;, 0.016938429325819016), (&#39;年月日&#39;, 0.016354413703083992), (&#39;轿车&#39;, 0.012655640952289104), (&#39;警方&#39;, 0.012460969388484955), (&#39;袭击&#39;, 0.012266295962035656), (&#39;事件&#39;, 0.011487606912851334)]


​    
​    Top 10 words of topic #4
​    [(&#39;地震&#39;, 0.047826822847127914), (&#39;发生&#39;, 0.03555167838931084), (&#39;火灾&#39;, 0.03140682727098465), (&#39;时分&#39;, 0.020885275676846504), (&#39;级&#39;, 0.015783920884132385), (&#39;时间&#39;, 0.013870910741388798), (&#39;公里&#39;, 0.013711493462324142), (&#39;人员伤亡&#39;, 0.013073823414742947), (&#39;记者&#39;, 0.013073823414742947), (&#39;震感&#39;, 0.012276736088097095)]
</code></pre></div><br>
<p>查看话题模型信息</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">mdl</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-mysql" data-lang="mysql"><span class="w">
</span><span class="w">    </span><span class="o">&lt;</span><span class="n">Basic</span><span class="w"> </span><span class="n">Info</span><span class="o">&gt;</span><span class="w">
</span><span class="w">    </span><span class="o">|</span><span class="w"> </span><span class="nf">LDAModel</span><span class="w"> </span><span class="p">(</span><span class="n">current</span><span class="w"> </span><span class="n">version</span><span class="p">:</span><span class="w"> </span><span class="mi">0</span><span class="p">.</span><span class="mi">12</span><span class="p">.</span><span class="mi">2</span><span class="p">)</span><span class="w">
</span><span class="w">    </span><span class="o">|</span><span class="w"> </span><span class="mi">332</span><span class="w"> </span><span class="n">docs</span><span class="p">,</span><span class="w"> </span><span class="mi">29749</span><span class="w"> </span><span class="n">words</span><span class="w">
</span><span class="w">    </span><span class="o">|</span><span class="w"> </span><span class="n">Total</span><span class="w"> </span><span class="n">Vocabs</span><span class="p">:</span><span class="w"> </span><span class="mi">8428</span><span class="p">,</span><span class="w"> </span><span class="n">Used</span><span class="w"> </span><span class="n">Vocabs</span><span class="p">:</span><span class="w"> </span><span class="mi">2984</span><span class="w">
</span><span class="w">    </span><span class="o">|</span><span class="w"> </span><span class="n">Entropy</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">words</span><span class="p">:</span><span class="w"> </span><span class="mi">7</span><span class="p">.</span><span class="mi">10665</span><span class="w">
</span><span class="w">    </span><span class="o">|</span><span class="w"> </span><span class="n">Entropy</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">term</span><span class="o">-</span><span class="n">weighted</span><span class="w"> </span><span class="n">words</span><span class="p">:</span><span class="w"> </span><span class="mi">7</span><span class="p">.</span><span class="mi">10665</span><span class="w">
</span><span class="w">    </span><span class="o">|</span><span class="w"> </span><span class="n">Removed</span><span class="w"> </span><span class="n">Vocabs</span><span class="p">:</span><span class="w"> </span><span class="o">&lt;</span><span class="n">NA</span><span class="o">&gt;</span><span class="w">
</span><span class="w">    </span><span class="o">|</span><span class="w">
</span><span class="w">    </span><span class="o">&lt;</span><span class="n">Training</span><span class="w"> </span><span class="n">Info</span><span class="o">&gt;</span><span class="w">
</span><span class="w">    </span><span class="o">|</span><span class="w"> </span><span class="n">Iterations</span><span class="p">:</span><span class="w"> </span><span class="mi">10</span><span class="p">,</span><span class="w"> </span><span class="n">Burn</span><span class="o">-</span><span class="k">in</span><span class="w"> </span><span class="n">steps</span><span class="p">:</span><span class="w"> </span><span class="mi">0</span><span class="w">
</span><span class="w">    </span><span class="o">|</span><span class="w"> </span><span class="n">Optimization</span><span class="w"> </span><span class="k">Interval</span><span class="p">:</span><span class="w"> </span><span class="mi">10</span><span class="w">
</span><span class="w">    </span><span class="o">|</span><span class="w"> </span><span class="n">Log</span><span class="o">-</span><span class="n">likelihood</span><span class="w"> </span><span class="n">per</span><span class="w"> </span><span class="n">word</span><span class="p">:</span><span class="w"> </span><span class="o">-</span><span class="mi">7</span><span class="p">.</span><span class="mi">79934</span><span class="w">
</span><span class="w">    </span><span class="o">|</span><span class="w">
</span><span class="w">    </span><span class="o">&lt;</span><span class="n">Initial</span><span class="w"> </span><span class="n">Parameters</span><span class="o">&gt;</span><span class="w">
</span><span class="w">    </span><span class="o">|</span><span class="w"> </span><span class="n">tw</span><span class="p">:</span><span class="w"> </span><span class="n">TermWeight</span><span class="p">.</span><span class="n">ONE</span><span class="w">
</span><span class="w">    </span><span class="o">|</span><span class="w"> </span><span class="n">min_cf</span><span class="p">:</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="p">(</span><span class="n">minimum</span><span class="w"> </span><span class="n">collection</span><span class="w"> </span><span class="n">frequency</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">words</span><span class="p">)</span><span class="w">
</span><span class="w">    </span><span class="o">|</span><span class="w"> </span><span class="n">min_df</span><span class="p">:</span><span class="w"> </span><span class="mi">2</span><span class="w"> </span><span class="p">(</span><span class="n">minimum</span><span class="w"> </span><span class="n">document</span><span class="w"> </span><span class="n">frequency</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">words</span><span class="p">)</span><span class="w">
</span><span class="w">    </span><span class="o">|</span><span class="w"> </span><span class="n">rm_top</span><span class="p">:</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="p">(</span><span class="n">the</span><span class="w"> </span><span class="n">number</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">top</span><span class="w"> </span><span class="n">words</span><span class="w"> </span><span class="k">to</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">removed</span><span class="p">)</span><span class="w">
</span><span class="w">    </span><span class="o">|</span><span class="w"> </span><span class="n">k</span><span class="p">:</span><span class="w"> </span><span class="mi">5</span><span class="w"> </span><span class="p">(</span><span class="n">the</span><span class="w"> </span><span class="n">number</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">topics</span><span class="w"> </span><span class="k">between</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="mi">32767</span><span class="p">)</span><span class="w">
</span><span class="w">    </span><span class="o">|</span><span class="w"> </span><span class="n">alpha</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="mi">0</span><span class="p">.</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="p">(</span><span class="n">hyperparameter</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">Dirichlet</span><span class="w"> </span><span class="n">distribution</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">document</span><span class="o">-</span><span class="n">topic</span><span class="p">,</span><span class="w"> </span><span class="n">given</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">single</span><span class="w"> </span><span class="o">`</span><span class="kt">float</span><span class="o">`</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="k">case</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">symmetric</span><span class="w"> </span><span class="n">prior</span><span class="w"> </span><span class="k">and</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">list</span><span class="w"> </span><span class="k">with</span><span class="w"> </span><span class="n">length</span><span class="w"> </span><span class="o">`</span><span class="n">k</span><span class="o">`</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="o">`</span><span class="kt">float</span><span class="o">`</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="k">case</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">asymmetric</span><span class="w"> </span><span class="n">prior</span><span class="p">.)</span><span class="w">
</span><span class="w">    </span><span class="o">|</span><span class="w"> </span><span class="n">eta</span><span class="p">:</span><span class="w"> </span><span class="mi">0</span><span class="p">.</span><span class="mi">01</span><span class="w"> </span><span class="p">(</span><span class="n">hyperparameter</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">Dirichlet</span><span class="w"> </span><span class="n">distribution</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">topic</span><span class="o">-</span><span class="n">word</span><span class="p">)</span><span class="w">
</span><span class="w">    </span><span class="o">|</span><span class="w"> </span><span class="n">seed</span><span class="p">:</span><span class="w"> </span><span class="mi">555</span><span class="w"> </span><span class="p">(</span><span class="n">random</span><span class="w"> </span><span class="n">seed</span><span class="p">)</span><span class="w">
</span><span class="w">    </span><span class="o">|</span><span class="w"> </span><span class="n">trained</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">version</span><span class="w"> </span><span class="mi">0</span><span class="p">.</span><span class="mi">12</span><span class="p">.</span><span class="mi">2</span><span class="w">
</span><span class="w">    </span><span class="o">|</span><span class="w">
</span><span class="w">    </span><span class="o">&lt;</span><span class="n">Parameters</span><span class="o">&gt;</span><span class="w">
</span><span class="w">    </span><span class="o">|</span><span class="w"> </span><span class="nf">alpha</span><span class="w"> </span><span class="p">(</span><span class="n">Dirichlet</span><span class="w"> </span><span class="n">prior</span><span class="w"> </span><span class="k">on</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">per</span><span class="o">-</span><span class="n">document</span><span class="w"> </span><span class="n">topic</span><span class="w"> </span><span class="n">distributions</span><span class="p">)</span><span class="w">
</span><span class="w">    </span><span class="o">|</span><span class="w">  </span><span class="p">[</span><span class="mi">0</span><span class="p">.</span><span class="mi">7143365</span><span class="w">  </span><span class="mi">0</span><span class="p">.</span><span class="mi">6852513</span><span class="w">  </span><span class="mi">0</span><span class="p">.</span><span class="mi">75089616</span><span class="w"> </span><span class="mi">0</span><span class="p">.</span><span class="mi">6204677</span><span class="w">  </span><span class="mi">0</span><span class="p">.</span><span class="mi">7040125</span><span class="w"> </span><span class="p">]</span><span class="w">
</span><span class="w">    </span><span class="o">|</span><span class="w"> </span><span class="nf">eta</span><span class="w"> </span><span class="p">(</span><span class="n">Dirichlet</span><span class="w"> </span><span class="n">prior</span><span class="w"> </span><span class="k">on</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">per</span><span class="o">-</span><span class="n">topic</span><span class="w"> </span><span class="n">word</span><span class="w"> </span><span class="n">distribution</span><span class="p">)</span><span class="w">
</span><span class="w">    </span><span class="o">|</span><span class="w">  </span><span class="mi">0</span><span class="p">.</span><span class="mi">01</span><span class="w">
</span><span class="w">    </span><span class="o">|</span><span class="w">
</span><span class="w">    </span><span class="o">&lt;</span><span class="n">Topics</span><span class="o">&gt;</span><span class="w">
</span><span class="w">    </span><span class="o">|</span><span class="w"> </span><span class="c1">#0 (6513) : 一辆 事故 记者 死亡 造成
</span><span class="c1"></span><span class="w">    </span><span class="o">|</span><span class="w"> </span><span class="c1">#1 (5655) : 学生 食物中毒 出现 医院 事件
</span><span class="c1"></span><span class="w">    </span><span class="o">|</span><span class="w"> </span><span class="c1">#2 (6231) : 现场 发生 医院 起火 原因
</span><span class="c1"></span><span class="w">    </span><span class="o">|</span><span class="w"> </span><span class="c1">#3 (5107) : 发生 爆炸 造成 死亡 受伤
</span><span class="c1"></span><span class="w">    </span><span class="o">|</span><span class="w"> </span><span class="c1">#4 (6243) : 地震 发生 火灾 时分 级
</span></code></pre></div><h3 id="topic解读">topic解读<a hidden class="anchor" aria-hidden="true" href="#topic解读">#</a></h3>
<p>根据每个话题top10的特征词，5个话题解读为</p>
<ul>
<li>交通事故| #0 (6513) : 一辆 事故 记者 死亡 造成</li>
<li>食品安全| #1 (5655) : 学生 食物中毒 出现 医院 事件</li>
<li>火灾新闻| #2 (6231) : 现场 发生 医院 起火 原因</li>
<li>恐怖袭击| #3 (5107) : 发生 爆炸 造成 死亡 受伤</li>
<li>地震灾害| #4 (6243) : 地震 发生 火灾 时分 级</li>
</ul>
<br>
<h2 id="5-可视化">5. 可视化<a hidden class="anchor" aria-hidden="true" href="#5-可视化">#</a></h2>
<p>使用pyLDAvis</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pyLDAvis</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">,</span> <span class="n">category</span><span class="o">=</span><span class="ne">Warning</span><span class="p">)</span>

<span class="c1">#在notebook显示</span>
<span class="n">pyLDAvis</span><span class="o">.</span><span class="n">enable_notebook</span><span class="p">()</span>

<span class="c1">#获取pyldavis需要的参数</span>
<span class="n">topic_term_dists</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">mdl</span><span class="o">.</span><span class="n">get_topic_word_dist</span><span class="p">(</span><span class="n">k</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">mdl</span><span class="o">.</span><span class="n">k</span><span class="p">)])</span>
<span class="n">doc_topic_dists</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">doc</span><span class="o">.</span><span class="n">get_topic_dist</span><span class="p">()</span> <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">mdl</span><span class="o">.</span><span class="n">docs</span><span class="p">])</span>
<span class="n">doc_topic_dists</span> <span class="o">/=</span> <span class="n">doc_topic_dists</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">doc_lengths</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">doc</span><span class="o">.</span><span class="n">words</span><span class="p">)</span> <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">mdl</span><span class="o">.</span><span class="n">docs</span><span class="p">])</span>
<span class="n">vocab</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">mdl</span><span class="o">.</span><span class="n">used_vocabs</span><span class="p">)</span>
<span class="n">term_frequency</span> <span class="o">=</span> <span class="n">mdl</span><span class="o">.</span><span class="n">used_vocab_freq</span>


<span class="n">prepared_data</span> <span class="o">=</span> <span class="n">pyLDAvis</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span>
    <span class="n">topic_term_dists</span><span class="p">,</span> 
    <span class="n">doc_topic_dists</span><span class="p">,</span> 
    <span class="n">doc_lengths</span><span class="p">,</span> 
    <span class="n">vocab</span><span class="p">,</span> 
    <span class="n">term_frequency</span><span class="p">,</span>
    <span class="n">start_index</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="c1"># tomotopy话题id从0开始，pyLDAvis话题id从1开始</span>
    <span class="n">sort_topics</span><span class="o">=</span><span class="kc">False</span> <span class="c1">#注意：否则pyLDAvis与tomotopy内的话题无法一一对应。 </span>
<span class="p">)</span>


<span class="c1">#可视化结果存到html文件中</span>
<span class="c1">#pyLDAvis.save_html(prepared_data, &#39;ldavis.html&#39;)</span>

<span class="c1">#notebook中显示</span>
<span class="n">pyLDAvis</span><span class="o">.</span><span class="n">display</span><span class="p">(</span><span class="n">prepared_data</span><span class="p">)</span>
</code></pre></div><p><img loading="lazy" src="img/ldavis.png" alt=""  />
</p>
<br>
<h2 id="6-预测">6. 预测<a hidden class="anchor" aria-hidden="true" href="#6-预测">#</a></h2>
<p>预测某文档的话题</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">jieba</span>
<span class="n">stopwords</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;stopwords.txt&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">read</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="c1">#预测</span>
<span class="n">doc</span> <span class="o">=</span> <span class="s1">&#39;云南永善县级地震已致伤间民房受损中新网日电云南昭通市防震减灾局官方网站消息日时云南昭通永善县级地震造成受伤重伤轻伤送医院救治民房受损户间倒塌户间乡镇学校不同程度受损目前损毁电力交通通讯设施抢通修复调拨帐篷顶紧急转移万人时分云南昭通永善县发生里氏级地震震源深度公里震感强烈成都四川多地明显震感&#39;</span>
<span class="n">words</span> <span class="o">=</span> <span class="p">[</span><span class="n">w</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">jieba</span><span class="o">.</span><span class="n">lcut</span><span class="p">(</span><span class="n">doc</span><span class="p">)</span> <span class="k">if</span> <span class="n">w</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">stopwords</span><span class="p">]</span>

<span class="c1">#构造tomotopy需要的数据</span>
<span class="n">doc_inst</span> <span class="o">=</span> <span class="n">mdl</span><span class="o">.</span><span class="n">make_doc</span><span class="p">(</span><span class="n">words</span><span class="o">=</span><span class="n">words</span><span class="p">)</span>
<span class="n">topic_dist</span><span class="p">,</span> <span class="n">ll</span> <span class="o">=</span> <span class="n">mdl</span><span class="o">.</span><span class="n">infer</span><span class="p">(</span><span class="n">doc_inst</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&#34;Topic Distribution for Unseen Docs: &#34;</span><span class="p">,</span> <span class="n">topic_dist</span><span class="p">)</span>

</code></pre></div><pre><code>Topic Distribution for Unseen Docs:  [0.11645161 0.10240361 0.5342029  0.03622254 0.21071935]
</code></pre>
<p>列表长度为5， 列表第三个数值(topic #2)数值最大，该文本最大的可能性是topic #2</p>
<br>
<h2 id="补充-指定主题特征词">补充: 指定主题特征词<a hidden class="anchor" aria-hidden="true" href="#补充-指定主题特征词">#</a></h2>
<p>如果对数据比较了解，已经知道有一些主题，可以把比较明显的词语分配给指定的topic_id。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">mdl</span> <span class="o">=</span> <span class="n">tp</span><span class="o">.</span><span class="n">LDAModel</span><span class="p">(</span><span class="n">k</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">min_df</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">555</span><span class="p">)</span>

<span class="k">for</span> <span class="n">words</span> <span class="ow">in</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;words&#39;</span><span class="p">]:</span>
    <span class="k">if</span> <span class="n">words</span><span class="p">:</span>
        <span class="n">mdl</span><span class="o">.</span><span class="n">add_doc</span><span class="p">(</span><span class="n">words</span><span class="p">)</span>

<span class="c1">#把word相撞 分配给topic_0, 权重设置为1， 其他topic权重设置为0.1</span>
<span class="c1">#注意这里的range(5) 5是对应的k值</span>
<span class="n">mdl</span><span class="o">.</span><span class="n">set_word_prior</span><span class="p">(</span><span class="s1">&#39;相撞&#39;</span><span class="p">,</span> <span class="p">[</span><span class="mf">1.0</span> <span class="k">if</span> <span class="n">k</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="mf">0.1</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">)])</span>
<span class="c1">#把word地震 分配给topic_1, 权重设置为1， 其他topic权重设置为0.1</span>
<span class="n">mdl</span><span class="o">.</span><span class="n">set_word_prior</span><span class="p">(</span><span class="s1">&#39;地震&#39;</span><span class="p">,</span> <span class="p">[</span><span class="mf">1.0</span> <span class="k">if</span> <span class="n">k</span> <span class="o">==</span> <span class="mi">1</span> <span class="k">else</span> <span class="mf">0.1</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">)])</span>
<span class="c1">#把word火灾 分配给topic_2, 权重设置为1， 其他topic权重设置为0.1</span>
<span class="n">mdl</span><span class="o">.</span><span class="n">set_word_prior</span><span class="p">(</span><span class="s1">&#39;火灾&#39;</span><span class="p">,</span> <span class="p">[</span><span class="mf">1.0</span> <span class="k">if</span> <span class="n">k</span> <span class="o">==</span> <span class="mi">2</span> <span class="k">else</span> <span class="mf">0.1</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">)])</span>
<span class="c1">#把word中毒 分配给topic_3, 权重设置为1， 其他topic权重设置为0.1</span>
<span class="n">mdl</span><span class="o">.</span><span class="n">set_word_prior</span><span class="p">(</span><span class="s1">&#39;中毒&#39;</span><span class="p">,</span> <span class="p">[</span><span class="mf">1.0</span> <span class="k">if</span> <span class="n">k</span> <span class="o">==</span> <span class="mi">3</span> <span class="k">else</span> <span class="mf">0.1</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">)])</span>
<span class="c1">#把word袭击 分配给topic_4, 权重设置为1， 其他topic权重设置为0.1</span>
<span class="n">mdl</span><span class="o">.</span><span class="n">set_word_prior</span><span class="p">(</span><span class="s1">&#39;袭击&#39;</span><span class="p">,</span> <span class="p">[</span><span class="mf">1.0</span> <span class="k">if</span> <span class="n">k</span> <span class="o">==</span> <span class="mi">4</span> <span class="k">else</span> <span class="mf">0.1</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">)])</span>

<span class="n">mdl</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
<span class="n">mdl</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>  
</code></pre></div><pre><code>&lt;Basic Info&gt;
| LDAModel (current version: 0.12.2)
| 332 docs, 29749 words
| Total Vocabs: 8428, Used Vocabs: 2984
| Entropy of words: 7.10665
| Entropy of term-weighted words: 7.10665
| Removed Vocabs: &lt;NA&gt;
|
&lt;Training Info&gt;
| Iterations: 10, Burn-in steps: 0
| Optimization Interval: 10
| Log-likelihood per word: -7.72251
|
&lt;Initial Parameters&gt;
| tw: TermWeight.ONE
| min_cf: 0 (minimum collection frequency of words)
| min_df: 2 (minimum document frequency of words)
| rm_top: 0 (the number of top words to be removed)
| k: 5 (the number of topics between 1 ~ 32767)
| alpha: [0.1] (hyperparameter of Dirichlet distribution for document-topic, given as a single `float` in case of symmetric prior and as a list with length `k` of `float` in case of asymmetric prior.)
| eta: 0.01 (hyperparameter of Dirichlet distribution for topic-word)
| seed: 555 (random seed)
| trained in version 0.12.2
|
&lt;Parameters&gt;
| alpha (Dirichlet prior on the per-document topic distributions)
|  [0.7106193  0.60264444 0.5734784  0.71375024 0.6234263 ]
| eta (Dirichlet prior on the per-topic word distribution)
|  0.01
|
&lt;Topics&gt;
| #0 (6599) : 一辆 事故 死亡 发生 造成
| #1 (6087) : 地震 发生 级 公里 年月日
| #2 (5892) : 火灾 发生 现场 大火 起火
| #3 (6402) : 医院 学生 食物中毒 出现 名
| #4 (4769) : 事件 发生 袭击 人员 工作
|
</code></pre>
<br>
<br>
<h2 id="广而告之">广而告之<a hidden class="anchor" aria-hidden="true" href="#广而告之">#</a></h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>


  </div>

  <footer class="post-footer">
      <ul class="post-tags">
        <b>Tags:  &nbsp;</b>
        <li><a href="/tags/%E5%AD%A6%E6%9C%AF%E5%BA%94%E7%94%A8/" target='_blank'>学术应用</a></li>
        <li><a href="/tags/%E6%96%87%E6%9C%AC%E5%88%86%E6%9E%90/" target='_blank'>文本分析</a></li>
        <li><a href="/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/" target='_blank'>数据分析</a></li>
        <li><a href="/tags/%E7%AC%AC%E4%B8%89%E6%96%B9%E5%8C%85/" target='_blank'>第三方包</a></li>
      </ul>


<div class="share-buttons">
    <a target="_blank" rel="noopener noreferrer" aria-label="share tomotopy | 速度最快的LDA主题模型 on twitter"
        href="https://twitter.com/intent/tweet/?text=tomotopy%20%7c%20%e9%80%9f%e5%ba%a6%e6%9c%80%e5%bf%ab%e7%9a%84LDA%e4%b8%bb%e9%a2%98%e6%a8%a1%e5%9e%8b&amp;url=%2fblog%2f2023-04-25-tomotopy_is_the_fastest_topic_model%2f&amp;hashtags=%e5%ad%a6%e6%9c%af%e5%ba%94%e7%94%a8%2c%e6%96%87%e6%9c%ac%e5%88%86%e6%9e%90%2c%e6%95%b0%e6%8d%ae%e5%88%86%e6%9e%90%2c%e7%ac%ac%e4%b8%89%e6%96%b9%e5%8c%85">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-253.927,424.544c135.939,0 210.268,-112.643 210.268,-210.268c0,-3.218 0,-6.437 -0.153,-9.502c14.406,-10.421 26.973,-23.448 36.935,-38.314c-13.18,5.824 -27.433,9.809 -42.452,11.648c15.326,-9.196 26.973,-23.602 32.49,-40.92c-14.252,8.429 -30.038,14.56 -46.896,17.931c-13.487,-14.406 -32.644,-23.295 -53.946,-23.295c-40.767,0 -73.87,33.104 -73.87,73.87c0,5.824 0.613,11.494 1.992,16.858c-61.456,-3.065 -115.862,-32.49 -152.337,-77.241c-6.284,10.881 -9.962,23.601 -9.962,37.088c0,25.594 13.027,48.276 32.95,61.456c-12.107,-0.307 -23.448,-3.678 -33.41,-9.196l0,0.92c0,35.862 25.441,65.594 59.311,72.49c-6.13,1.686 -12.72,2.606 -19.464,2.606c-4.751,0 -9.348,-0.46 -13.946,-1.38c9.349,29.426 36.628,50.728 68.965,51.341c-25.287,19.771 -57.164,31.571 -91.8,31.571c-5.977,0 -11.801,-0.306 -17.625,-1.073c32.337,21.15 71.264,33.41 112.95,33.41Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share tomotopy | 速度最快的LDA主题模型 on linkedin"
        href="https://www.linkedin.com/shareArticle?mini=true&amp;url=%2fblog%2f2023-04-25-tomotopy_is_the_fastest_topic_model%2f&amp;title=tomotopy%20%7c%20%e9%80%9f%e5%ba%a6%e6%9c%80%e5%bf%ab%e7%9a%84LDA%e4%b8%bb%e9%a2%98%e6%a8%a1%e5%9e%8b&amp;summary=tomotopy%20%7c%20%e9%80%9f%e5%ba%a6%e6%9c%80%e5%bf%ab%e7%9a%84LDA%e4%b8%bb%e9%a2%98%e6%a8%a1%e5%9e%8b&amp;source=%2fblog%2f2023-04-25-tomotopy_is_the_fastest_topic_model%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share tomotopy | 速度最快的LDA主题模型 on reddit"
        href="https://reddit.com/submit?url=%2fblog%2f2023-04-25-tomotopy_is_the_fastest_topic_model%2f&title=tomotopy%20%7c%20%e9%80%9f%e5%ba%a6%e6%9c%80%e5%bf%ab%e7%9a%84LDA%e4%b8%bb%e9%a2%98%e6%a8%a1%e5%9e%8b">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share tomotopy | 速度最快的LDA主题模型 on facebook"
        href="https://facebook.com/sharer/sharer.php?u=%2fblog%2f2023-04-25-tomotopy_is_the_fastest_topic_model%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share tomotopy | 速度最快的LDA主题模型 on whatsapp"
        href="https://api.whatsapp.com/send?text=tomotopy%20%7c%20%e9%80%9f%e5%ba%a6%e6%9c%80%e5%bf%ab%e7%9a%84LDA%e4%b8%bb%e9%a2%98%e6%a8%a1%e5%9e%8b%20-%20%2fblog%2f2023-04-25-tomotopy_is_the_fastest_topic_model%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share tomotopy | 速度最快的LDA主题模型 on telegram"
        href="https://telegram.me/share/url?text=tomotopy%20%7c%20%e9%80%9f%e5%ba%a6%e6%9c%80%e5%bf%ab%e7%9a%84LDA%e4%b8%bb%e9%a2%98%e6%a8%a1%e5%9e%8b&amp;url=%2fblog%2f2023-04-25-tomotopy_is_the_fastest_topic_model%2f">
        <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28">
            <path
                d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
        </svg>
    </a>
    
</div>




  </footer><script src="https://giscus.app/client.js"
        data-repo="hidadeng/hidadeng.github.io"
        data-repo-id="R_kgDOGcZESg"
        data-category="Announcements"
        data-category-id="DIC_kwDOGcZESs4Cfa2L"
        data-mapping="og:title"
        data-strict="0"
        data-reactions-enabled="1"
        data-emit-metadata="0"
        data-input-position="top"
        data-theme="preferred_color_scheme"
        data-lang="zh-CN"
        data-loading="lazy"
        crossorigin="anonymous"
        async>
</script>

  
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2024 <a href="/">大邓和他的PYTHON</a></span>
</footer>
<a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerText = 'Copy';

        function copyingDone() {
            copybutton.innerText = 'Copied!';
            setTimeout(() => {
                copybutton.innerText = 'Copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>


    
    
</body>

</html>
