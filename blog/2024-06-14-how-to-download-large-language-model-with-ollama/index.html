<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>教程 | 如何使用 Ollama 下载 &amp; 使用本地大语言模型 | 大邓和他的PYTHON</title>
<meta name="keywords" content="Python, large language model, 大语言模型, ollama, deepseek, qwen" />
<meta name="description" content="Ollama是一款开源应用程序，可让您使用 MacOS、Linux 和 Windows 上的命令行界面在本地运行、创建和共享大型语言模型。Ollama 可以直接从其库中访问各种 LLM，只需一个命令即可下载。下载后，只需执行一个命令即可开始使用。这对于工作量围绕终端窗口的用户非常有帮助。如果他们被困在某个地方，他们可以在不切换到另一个浏览器窗口的情况下获得答案。Ollama is an open source application that allows you to run, create, and share large language models locally using a command line interface on MacOS, Linux, and Windows. Ollama can access a variety of LLMs directly from its library and can be downloaded with just one command. Once downloaded, it only takes one command to get started. This is very helpful for users whose workload revolves around a terminal window. If they are stuck somewhere, they can get the answer without switching to another browser window.">
<meta name="author" content="大邓">
<link rel="canonical" href="/blog/2024-06-14-how-to-download-large-language-model-with-ollama/" />
<meta name="baidu-site-verification" content="codeva-TJUe6nOmGr" />
<meta name="360-site-verification" content="6b9b733ec558a1bb12cee8aa82f2529e" />
<meta name="sogou-site-verification" content="dZHPIorOhK" />
<link crossorigin="anonymous" href="/assets/css/stylesheet.min.css" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/assets/js/highlight.min.js" onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="apple-touch-icon" href="/apple-touch-icon.png">
<link rel="mask-icon" href="/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<meta name="generator" content="Hugo 0.89.4" />
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:title" content="教程 | 如何使用 Ollama 下载 &amp; 使用本地大语言模型" />
<meta property="og:description" content="Ollama是一款开源应用程序，可让您使用 MacOS、Linux 和 Windows 上的命令行界面在本地运行、创建和共享大型语言模型。Ollama 可以直接从其库中访问各种 LLM，只需一个命令即可下载。下载后，只需执行一个命令即可开始使用。这对于工作量围绕终端窗口的用户非常有帮助。如果他们被困在某个地方，他们可以在不切换到另一个浏览器窗口的情况下获得答案。Ollama is an open source application that allows you to run, create, and share large language models locally using a command line interface on MacOS, Linux, and Windows. Ollama can access a variety of LLMs directly from its library and can be downloaded with just one command. Once downloaded, it only takes one command to get started. This is very helpful for users whose workload revolves around a terminal window. If they are stuck somewhere, they can get the answer without switching to another browser window." />
<meta property="og:type" content="article" />
<meta property="og:url" content="/blog/2024-06-14-how-to-download-large-language-model-with-ollama/" />
<meta property="og:image" content="/images/blog/Ollama-installation-run-models-customizations.jpg" /><meta property="article:section" content="blog" />
<meta property="article:published_time" content="2025-02-07T00:00:00&#43;00:00" />
<meta property="article:modified_time" content="2025-02-07T00:00:00&#43;00:00" />

<meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:image" content="/images/blog/Ollama-installation-run-models-customizations.jpg" />
<meta name="twitter:title" content="教程 | 如何使用 Ollama 下载 &amp; 使用本地大语言模型"/>
<meta name="twitter:description" content="Ollama是一款开源应用程序，可让您使用 MacOS、Linux 和 Windows 上的命令行界面在本地运行、创建和共享大型语言模型。Ollama 可以直接从其库中访问各种 LLM，只需一个命令即可下载。下载后，只需执行一个命令即可开始使用。这对于工作量围绕终端窗口的用户非常有帮助。如果他们被困在某个地方，他们可以在不切换到另一个浏览器窗口的情况下获得答案。Ollama is an open source application that allows you to run, create, and share large language models locally using a command line interface on MacOS, Linux, and Windows. Ollama can access a variety of LLMs directly from its library and can be downloaded with just one command. Once downloaded, it only takes one command to get started. This is very helpful for users whose workload revolves around a terminal window. If they are stuck somewhere, they can get the answer without switching to another browser window."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Blogs",
      "item": "/blog/"
    }
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "教程 | 如何使用 Ollama 下载 \u0026 使用本地大语言模型",
      "item": "/blog/2024-06-14-how-to-download-large-language-model-with-ollama/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "教程 | 如何使用 Ollama 下载 \u0026 使用本地大语言模型",
  "name": "教程 | 如何使用 Ollama 下载 \u0026 使用本地大语言模型",
  "description": "Ollama是一款开源应用程序，可让您使用 MacOS、Linux 和 Windows 上的命令行界面在本地运行、创建和共享大型语言模型。Ollama 可以直接从其库中访问各种 LLM，只需一个命令即可下载。下载后，只需执行一个命令即可开始使用。这对于工作量围绕终端窗口的用户非常有帮助。如果他们被困在某个地方，他们可以在不切换到另一个浏览器窗口的情况下获得答案。Ollama is an open source application that allows you to run, create, and share large language models locally using a command line interface on MacOS, Linux, and Windows. Ollama can access a variety of LLMs directly from its library and can be downloaded with just one command. Once downloaded, it only takes one command to get started. This is very helpful for users whose workload revolves around a terminal window. If they are stuck somewhere, they can get the answer without switching to another browser window.",
  "keywords": [
    "Python", "large language model", "大语言模型", "ollama", "deepseek", "qwen"
  ],
  "articleBody": "一、Ollama 1.1 Ollama介绍 Ollama是一款开源应用程序，可让您使用 MacOS、Linux 和 Windows 上的命令行界面在本地运行、创建和共享大型语言模型。\nOllama 可以直接从其库中访问各种 LLM，只需一个命令即可下载。下载后，只需执行一个命令即可开始使用。这对于工作量围绕终端窗口的用户非常有帮助。如果他们被困在某个地方，他们可以在不切换到另一个浏览器窗口的情况下获得答案。\n这就是为什么 OLLAMA 是您的工具包中必备的工具：\n 简单 ：OLLAMA 提供简单的设置过程。您无需拥有机器学习博士学位即可启动和运行它。 成本效益 ：在本地运行模型意味着您无需支付云成本。您的钱包会感谢您。 隐私 ：使用 OLLAMA，所有数据处理都在您的本地机器上进行。这对于用户隐私来说是一个巨大的胜利。 多功能性 ：OLLAMA 不只是为 Python 爱好者准备的。它的灵活性使其可以用于各种应用程序，包括 Web 开发。  1.2 安装ollama 点击前往网站 https://ollama.com/ ，下载ollama软件，支持win、Mac、linux\n\n二、Ollama操作 2.1 选择模型 ollama软件目前支持多种大模型， 如阿里的（qwen2.5）、meta的(llama3.3) 等。目前ollama最流行的模型，是国产开源大模型 deepseek r1。本文将安装qwen2.5:0.5b、 qwen2.5:1.5b、 qwen2.5:3b、 qwen2.5:7b、 deepseek-r1:1.5b、deepseek-r1:7b。 并对模型的速度、内容质量进行对比。\nDeepSeek-R1 在后训练阶段大规模使用了强化学习技术，在仅有极少标注数据的情况下，极大提升了模型推理能力。在数学、代码、自然语言推理等任务上，性能比肩 OpenAI o1 正式版。\n2.2 安装模型 一般b前面的数字越小， 运行模型对电脑性能的要求越低。\n打开电脑命令行cmd(mac是terminal), 网络是连网状态，执行模型下载(安装)命令\nollama run deepseek-r1:1.5b ollama run deepseek-r1:7b ollama run qwen2.5:0.5b ollama run qwen2.5:1.5b ollama run qwen2.5:3b ollama run qwen2.5:7b \n2.3 查看已安装模型 在电脑命令行cmd(mac是terminal), 执行命令\nollama list Run\nLast login: Tue Sep 24 19:26:46 on ttys000 da@deng ~ % ollama list NAME ID SIZE MODIFIED qwen2.5:0.5b a8b0c5157701 397 MB 15 minutes ago qwen2.5:1.5b 65ec06548149 986 MB 18 minutes ago qwen2.5:3b 357c53fb659c 1.9 GB 12 minutes ago qwen2.5:7b 845dbda0ea48 4.7 GB 21 seconds ago deepseek-r1:1.5b a42b25d8c10a 1.1 GB 48 minutes ago deepseek-r1:7b 0a8c26691023 4.7 GB 50 minutes ago nomic-embed-text:latest 0a109f422b47 274 MB 9 months ago da@deng ~ % 可以看到，列表中有 deepseek-r1:1.5b ， 说明在大邓的电脑中， 已经成功安装了 deepseek-r1:1.5b 。\n2.4 移除模型 使用 ollama rm 模型名称 移除已安装的某模型。 假设要移除 deepseek-r1:8b， 在电脑命令行cmd(mac是terminal), 执行移除命令\nollama rm deepseek-r1:8b Run\ndeleted 'deepseek-r1:8b' \n2.5 启动ollama服务 在电脑中找到 ollama软件的图标， 双击打开即可开启 Ollama 服务。\n如果觉得点击启动太麻烦，也可使用命令行操作， 打开电脑命令行cmd(mac是terminal), 执行\nollama serve Run\n2025/02/07 16:00:18 routes.go:1259: INFO server config env=\"map[HTTPS_PROXY: HTTP_PROXY: NO_PROXY: OLLAMA_DEBUG:false OLLAMA_FLASH_ATTENTION:false OLLAMA_GPU_OVERHEAD:0 OLLAMA_HOST:http://127.0.0.1:11434 OLLAMA_KEEP_ALIVE:5m0s OLLAMA_KV_CACHE_TYPE: OLLAMA_LLM_LIBRARY: OLLAMA_LOAD_TIMEOUT:5m0s OLLAMA_MAX_LOADED_MODELS:0 OLLAMA_MAX_QUEUE:512 OLLAMA_MODELS:/Users/deng/.ollama/models OLLAMA_MULTIUSER_CACHE:false OLLAMA_NOHISTORY:false OLLAMA_NOPRUNE:false OLLAMA_NUM_PARALLEL:0 OLLAMA_ORIGINS:[http://localhost https://localhost http://localhost:* https://localhost:* http://127.0.0.1 https://127.0.0.1 http://127.0.0.1:* https://127.0.0.1:* http://0.0.0.0 https://0.0.0.0 http://0.0.0.0:* https://0.0.0.0:* app://* file://* tauri://* vscode-webview://*] OLLAMA_SCHED_SPREAD:false http_proxy: https_proxy: no_proxy:]\" time=2025-02-07T16:00:18.551+08:00 level=INFO source=images.go:757 msg=\"total blobs: 11\" time=2025-02-07T16:00:18.551+08:00 level=INFO source=images.go:764 msg=\"total unused blobs removed: 0\" [GIN-debug] [WARNING] Creating an Engine instance with the Logger and Recovery middleware already attached. [GIN-debug] [WARNING] Running in \"debug\" mode. Switch to \"release\" mode in production. - using env:\texport GIN_MODE=release - using code:\tgin.SetMode(gin.ReleaseMode) er.(*Server).GenerateRoutes.func1 (5 handlers) ...... time=2025-02-07T16:00:18.553+08:00 level=INFO source=routes.go:1339 msg=\"Dynamic LLM libraries\" runners=[metal] time=2025-02-07T16:00:18.577+08:00 level=INFO source=types.go:131 msg=\"inference compute\" id=0 library=metal variant=\"\" compute=\"\" driver=0.0 name=\"\" total=\"72.0 GiB\" available=\"72.0 GiB\" cmd(mac是terminal)看到如上的信息，说明命令行本地ollama服务已开启。\n三、在Python中调用Ollama中大模型 在Python中， 有很多第三方库，如langchain、langgraph、ollama， 都能调用Ollama内的模型。 这里以ollama库为例，\n3.1 启动Ollama服务 在电脑中找到 ollama 软件的图标， 双击打开即可开启 Ollama 服务。\n3.2 安装 打开电脑命令行 cmd (mac是terminal), 网络是连网状态，执行安装命令\npip3 install ollama #pip3 install ollama==0.2.1 \n3.3 实验 假设你是X先生的私人助理，负责X先生的形成安排。X先生一周后将去哈尔滨旅游，帮X先生设计一个哈尔滨一日游形成安排。\n3.3.1 qwen2.5:1.5b #%%time #单次运行时间 #%%timeit #多次运行，求得平均运行时间 import ollama #大邓的ollama版本为0.2.1 content = \"你是X先生的私人助理，负责X先生的形成安排。X先生一周后将去哈尔滨旅游，帮X先生设计一个哈尔滨一日游形成安排。\" response = ollama.chat(model = 'qwen2:7b', #选择模型 messages = [{'role': 'user', 'content': content}]) #content2 = \"X先生一周后将去哈尔滨旅游，帮X先生设计一个哈尔滨一日游形成安排。\" #response = ollama.chat(model = 'qwen2:7b', #选择模型 # messages = [ # {'role': 'system', 'content': \"你是X先生的私人助理，负责X先生的形成安排。\"}, # {'role': 'user', 'content': content2} # ] # ) result = response['message']['content'] print(result) Run\n我理解您是Qwen，但我作为AI模型，并没有实际经历、记忆或能力来为任何人策划旅行安排。不过，我可以提供一些建议性的建议帮助您设计这个行程。 1. 交通：根据您的具体位置和出发时间，您可以考虑哈尔滨的机场（哈尔滨太平国际机场）或者火车站的便利性。 2. 确定活动：哈尔滨是冰城，所以可以尝试观看滑冰、滑雪或雪地摩托等冰上活动。另外，您还可以参加冰雪节，体验东北特色的冰灯展览。当然，如果您喜欢风景的话，还可以在松花江畔散步，欣赏沿岸的风景。 3. 餐饮：哈尔滨的特色美食包括狗不理包子和东北锅盔。此外，您可以品尝到鲜美的冻梨和各种风味小吃。 4. 购物：逛一逛哈啤街可以买到冰城特产和纪念品。 以上只是建议性的行程安排，您的实际旅行需要根据您的兴趣爱好、身体状况以及时间来确定。希望这些建议对您有所帮助！ 好的，我将根据您的需求为您制定一份哈尔滨一日游的行程方案： ### 第1天：抵达哈尔滨 - **上午8:00**：从上海或您所在的城市出发前往哈尔滨国际机场。 - **下午2:30**：抵达哈尔滨，下飞机后换乘高速动车（约4小时）到达哈尔滨南站。 - **下午3:30**：到机场附近的酒店办理入住手续，稍作休息准备。 ### 第2天：哈尔滨之旅 #### 上午：城市观光与探索 - **10:00**：前往中央大街。这里以其独特的建筑风格和文化氛围吸引着众多游客。 - **上午11:30**：参观东北虎林园，了解中国最北部的野生动物保护情况。 - **下午2:00**：漫步于圣索菲亚教堂附近的小巷，体验哈尔滨的老城区生活。 - **下午4:00**：在哈啤博物馆内探索哈尔滨啤酒的历史和制作工艺。 #### 下午：文化与美食 - **15:30**：参观哈尔滨冰雕艺术展览，欣赏世界级的冰雪艺术品。 - **下午6:00**：返回市区，享用正宗的东北大餐，比如狗不理包子、哈尔滨锅包肉等特色小吃。 #### 晚上：夜游与体验 - **18:00**：乘坐雪乡索道上山，探索世界最大的冰雪雕塑群。 - **晚上20:30**：回到市区，品尝地道的哈尔滨美食和市井风味小摊。 - **21:30**：结束今天的行程。 ### 第3天：返程 #### 晚间：准备离店 - **15:00**：在酒店享用晚餐，并安排打包食物或行李。 - **16:30**：开始收拾行囊，准备出发离开哈尔滨。可能需要提前半小时抵达机场。 请注意，这个方案是基于一般情况下的旅游规划，实际行程可能会根据您的偏好和具体交通时间有所调整。希望这份行程能为您提供一个美好的哈尔滨旅行体验！ \n3.3.2 deepseek r1:1.5b #%%time #单次运行时间 #%%timeit #多次运行，求得平均运行时间 import ollama #大邓的ollama版本为0.2.1 content = \"你是X先生的私人助理，负责X先生的形成安排。X先生一周后将去哈尔滨旅游，帮X先生设计一个哈尔滨一日游形成安排。\" response = ollama.chat(model = 'deepseek-r1:1.5b', #选择模型 messages = [{'role': 'user', 'content': content}]) #content2 = \"X先生一周后将去哈尔滨旅游，帮X先生设计一个哈尔滨一日游形成安排。\" #response = ollama.chat(model = 'deepseek-r1:1.5b', #选择模型 # messages = [ # {'role': 'system', 'content': \"你是X先生的私人助理，负责X先生的形成安排。\"}, # {'role': 'user', 'content': content2} # ] # ) result = response['message']['content'] print(result) Run\n 好的，用户需要我设计哈尔滨一日游的安排。首先，我得考虑目标客户的需求是什么。是单日游还是多日？用户可能是一个游客，想要既能体验哈尔滨的魅力，又不想太累，所以时间控制在两三个小时比较合适。 接下来，我要确定 Polar Express作为活动的主要交通工具，因为它不仅风景优美，还能带来刺激感，比如乘坐 escalator，这样可以让游客感觉有 motion。然后，其他活动要安排得轻松愉快，比如游船、冰灯 etc.，这些都能让整个行程看起来充实而有变化。 时间安排方面，从12点到下午三点左右比较合适，因为中午的户外活动和下午的购物区可以好好玩一玩。每个时间段都要留足够的时间进行活动，确保行程紧凑且不累赘。 另外，还要注意注意事项，比如天气、门票等，特别是如果用户是儿童的话，得确保安全和适合的主题。最后，提醒用户根据自己的需求调整时间和内容，让行程更加个性化和有创意。  嗯，你已经让我设计了一个详细的哈尔滨一日游安排了！让我们一步步来思考一下： ### 1. 时间框架 假设你计划在上午去游览景点，下午去夜游，晚上进行购物和品尝美食。 ### 2. 活动安排建议： - **早上： Polar Express 呼吸机 ride（快速穿梭公园内）** - 每人乘坐 Polar Express前往公园，体验快速移动的刺激。 - **中午： 游船游湖** - 晚上11点前坐 boat 温泉，感受 Polar Bear 和 fish 的美丽。 - **下午： 傍晚： ice cream 环岛游（Polar Express 区）** - 跑在环城的路上购买冰棒和冰淇淋，享受夜景。 - **晚上： 餐饮** - 中午去餐馆点餐，晚餐去夜市品尝特色小吃。 ### 3. 注意事项： - 如果是儿童游玩，记得注意安全，选择容易摔倒的景点。 - 建议提前预订 Polar Express 的票，避免排队。 希望这个安排能满足你的需求！如果你有其他具体需求或偏好，请告诉我，我可以再调整哦！ \n四、性能评价 qwen2.5 和 deepseek r1 都能很好的完成了旅游规划的任务。 运行速度方面， qwen2.5 远快于 deepseek r1 。本次实验中每个代码均运行7次，最终求得平均耗时\n qwen2.5:0.5b 平均耗时 1.43 s ± 746 ms qwen2.5:1.5b 平均耗时 2.5 s ± 1.18 s qwen2.5: 3b 平均耗时 4.76 s ± 1.77 s qwen2.5: 7b 平均耗时 8.58 s ± 534 ms deepseek r1:1.5b 平均耗时 8.71 s ± 1.66 s deepseek r1:7b 平均耗时 21 s ± 4.39 s  如果追求速度， 同样体量的模型的(以1.5b为例)，目前首选 qwen2.5 （qwen2.5:1.5b）。\n各位可以结合自己任务， 电脑性能， 速度等不同需求， 选择对自己最合适的模型。\n精选内容  LIST | 可供社科(经管)领域使用的数据集汇总 LIST | 社科(经管)数据挖掘文献资料汇总 网络爬虫 | 使用scrapegraph-ai(大模型方案)自动采集网页数据 推荐 | 文本分析库cntext2.x使用手册 付费视频课 | Python实证指标构建与文本分析 实验 | 使用本地大模型从文本中提取结构化信息7  ",
  "wordCount" : "656",
  "inLanguage": "en",
  "image":"/images/blog/Ollama-installation-run-models-customizations.jpg","datePublished": "2025-02-07T00:00:00Z",
  "dateModified": "2025-02-07T00:00:00Z",
  "author":{
    "@type": "Person",
    "name": "大邓"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "/blog/2024-06-14-how-to-download-large-language-model-with-ollama/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "大邓和他的PYTHON",
    "logo": {
      "@type": "ImageObject",
      "url": "/favicon.ico"
    }
  }
}
</script>
<script async src="https://www.googletagmanager.com/gtag/js?id=G-SFGQCREQ9X"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-SFGQCREQ9X');
</script>



<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC" rel="stylesheet">
<link href="https://fonts.googleapis.com/css2?family=PT+Serif" rel="stylesheet">
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="/" accesskey="h" title="大邓和他的PYTHON (Alt + H)" target="_blank">大邓和他的PYTHON</a>
            <span class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </span>
        </div>
        <ul id="menu">
            <li>
                <a href="/about/" title="关于" target="_blank">
                    <span>关于</span>
                </a>
            </li>
            <li>
                <a href="/blog" title="博文" target="_blank">
                    <span>博文</span>
                </a>
            </li>
            <li>
                <a href="/search/" title="搜索" target="_blank">
                    <span>搜索</span>
                </a>
            </li>
            <li>
                <a href="/tags/" title="标签" target="_blank">
                    <span>标签</span>
                </a>
            </li>
            <li>
                <a href="/blog/management_python_course/" title="课程" target="_blank">
                    <span>课程</span>
                </a>
            </li>
            <li>
                <a href="/blog/the_text_analysis_list_about_ms/" title="文献" target="_blank">
                    <span>文献</span>
                </a>
            </li>
            <li>
                <a href="/blog/datasets_available_for_management_science/" title="数据" target="_blank">
                    <span>数据</span>
                </a>
            </li>
            <li>
                <a href="/blog/2024-04-27-cntext2x-usage-tutorial/" title="cntext2.x" target="_blank">
                    <span>cntext2.x</span>
                </a>
            </li>
            <li>
                <a href="/index.xml" title="RSS" target="_blank">
                    <span>RSS</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">


<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js" integrity="sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js" integrity="sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa" crossorigin="anonymous"
onload="renderMathInElement(document.body);"></script>




<article class="post-single">
  <header class="post-header">
    
    <div class="breadcrumbs"><a href="/" target="_blank">Home</a>&nbsp;»&nbsp;<a href="/blog/" target="_blank">Blogs</a></div>
    <h1 class="post-title">
      教程 | 如何使用 Ollama 下载 &amp; 使用本地大语言模型
    </h1>
    <div class="post-meta"><span title='2025-02-07 00:00:00 +0000 UTC'>2025-02-07</span>&nbsp;·&nbsp;4 min&nbsp;·&nbsp;大邓

</div>
  </header> 
<figure class="entry-cover"><a href="/images/blog/Ollama-installation-run-models-customizations.jpg" target="_blank"
            rel="noopener noreferrer"><img loading="lazy" src="/images/blog/Ollama-installation-run-models-customizations.jpg" alt=""></a>
        
</figure>
<div class="share-buttons">
    <a target="_blank" rel="noopener noreferrer" aria-label="share 教程 | 如何使用 Ollama 下载 &amp; 使用本地大语言模型 on twitter"
        href="https://twitter.com/intent/tweet/?text=%e6%95%99%e7%a8%8b%20%7c%20%e5%a6%82%e4%bd%95%e4%bd%bf%e7%94%a8%20Ollama%20%e4%b8%8b%e8%bd%bd%20%26%20%e4%bd%bf%e7%94%a8%e6%9c%ac%e5%9c%b0%e5%a4%a7%e8%af%ad%e8%a8%80%e6%a8%a1%e5%9e%8b&amp;url=%2fblog%2f2024-06-14-how-to-download-large-language-model-with-ollama%2f&amp;hashtags=LLM%2c%e6%96%87%e6%9c%ac%e5%88%86%e6%9e%90">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-253.927,424.544c135.939,0 210.268,-112.643 210.268,-210.268c0,-3.218 0,-6.437 -0.153,-9.502c14.406,-10.421 26.973,-23.448 36.935,-38.314c-13.18,5.824 -27.433,9.809 -42.452,11.648c15.326,-9.196 26.973,-23.602 32.49,-40.92c-14.252,8.429 -30.038,14.56 -46.896,17.931c-13.487,-14.406 -32.644,-23.295 -53.946,-23.295c-40.767,0 -73.87,33.104 -73.87,73.87c0,5.824 0.613,11.494 1.992,16.858c-61.456,-3.065 -115.862,-32.49 -152.337,-77.241c-6.284,10.881 -9.962,23.601 -9.962,37.088c0,25.594 13.027,48.276 32.95,61.456c-12.107,-0.307 -23.448,-3.678 -33.41,-9.196l0,0.92c0,35.862 25.441,65.594 59.311,72.49c-6.13,1.686 -12.72,2.606 -19.464,2.606c-4.751,0 -9.348,-0.46 -13.946,-1.38c9.349,29.426 36.628,50.728 68.965,51.341c-25.287,19.771 -57.164,31.571 -91.8,31.571c-5.977,0 -11.801,-0.306 -17.625,-1.073c32.337,21.15 71.264,33.41 112.95,33.41Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share 教程 | 如何使用 Ollama 下载 &amp; 使用本地大语言模型 on linkedin"
        href="https://www.linkedin.com/shareArticle?mini=true&amp;url=%2fblog%2f2024-06-14-how-to-download-large-language-model-with-ollama%2f&amp;title=%e6%95%99%e7%a8%8b%20%7c%20%e5%a6%82%e4%bd%95%e4%bd%bf%e7%94%a8%20Ollama%20%e4%b8%8b%e8%bd%bd%20%26%20%e4%bd%bf%e7%94%a8%e6%9c%ac%e5%9c%b0%e5%a4%a7%e8%af%ad%e8%a8%80%e6%a8%a1%e5%9e%8b&amp;summary=%e6%95%99%e7%a8%8b%20%7c%20%e5%a6%82%e4%bd%95%e4%bd%bf%e7%94%a8%20Ollama%20%e4%b8%8b%e8%bd%bd%20%26%20%e4%bd%bf%e7%94%a8%e6%9c%ac%e5%9c%b0%e5%a4%a7%e8%af%ad%e8%a8%80%e6%a8%a1%e5%9e%8b&amp;source=%2fblog%2f2024-06-14-how-to-download-large-language-model-with-ollama%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share 教程 | 如何使用 Ollama 下载 &amp; 使用本地大语言模型 on reddit"
        href="https://reddit.com/submit?url=%2fblog%2f2024-06-14-how-to-download-large-language-model-with-ollama%2f&title=%e6%95%99%e7%a8%8b%20%7c%20%e5%a6%82%e4%bd%95%e4%bd%bf%e7%94%a8%20Ollama%20%e4%b8%8b%e8%bd%bd%20%26%20%e4%bd%bf%e7%94%a8%e6%9c%ac%e5%9c%b0%e5%a4%a7%e8%af%ad%e8%a8%80%e6%a8%a1%e5%9e%8b">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share 教程 | 如何使用 Ollama 下载 &amp; 使用本地大语言模型 on facebook"
        href="https://facebook.com/sharer/sharer.php?u=%2fblog%2f2024-06-14-how-to-download-large-language-model-with-ollama%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share 教程 | 如何使用 Ollama 下载 &amp; 使用本地大语言模型 on whatsapp"
        href="https://api.whatsapp.com/send?text=%e6%95%99%e7%a8%8b%20%7c%20%e5%a6%82%e4%bd%95%e4%bd%bf%e7%94%a8%20Ollama%20%e4%b8%8b%e8%bd%bd%20%26%20%e4%bd%bf%e7%94%a8%e6%9c%ac%e5%9c%b0%e5%a4%a7%e8%af%ad%e8%a8%80%e6%a8%a1%e5%9e%8b%20-%20%2fblog%2f2024-06-14-how-to-download-large-language-model-with-ollama%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share 教程 | 如何使用 Ollama 下载 &amp; 使用本地大语言模型 on telegram"
        href="https://telegram.me/share/url?text=%e6%95%99%e7%a8%8b%20%7c%20%e5%a6%82%e4%bd%95%e4%bd%bf%e7%94%a8%20Ollama%20%e4%b8%8b%e8%bd%bd%20%26%20%e4%bd%bf%e7%94%a8%e6%9c%ac%e5%9c%b0%e5%a4%a7%e8%af%ad%e8%a8%80%e6%a8%a1%e5%9e%8b&amp;url=%2fblog%2f2024-06-14-how-to-download-large-language-model-with-ollama%2f">
        <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28">
            <path
                d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
        </svg>
    </a>
    
</div>
<aside id="toc-container" class="toc-container wide">
    <div class="toc">
        <details  open>
            <summary accesskey="c" title="(Alt + C)">
                <span class="details">Table of Contents</span>
            </summary>

            <div class="inner"><ul>
                    <li>
                        <a href="#%e4%b8%80ollama" aria-label="一、Ollama">一、Ollama</a><ul>
                            
                    <li>
                        <a href="#11-ollama%e4%bb%8b%e7%bb%8d" aria-label="1.1 Ollama介绍">1.1 Ollama介绍</a></li>
                    <li>
                        <a href="#12-%e5%ae%89%e8%a3%85ollama" aria-label="1.2 安装ollama">1.2 安装ollama</a></li></ul>
                    </li>
                    <li>
                        <a href="#%e4%ba%8collama%e6%93%8d%e4%bd%9c" aria-label="二、Ollama操作">二、Ollama操作</a><ul>
                            
                    <li>
                        <a href="#21-%e9%80%89%e6%8b%a9%e6%a8%a1%e5%9e%8b" aria-label="2.1 选择模型">2.1 选择模型</a></li>
                    <li>
                        <a href="#22-%e5%ae%89%e8%a3%85%e6%a8%a1%e5%9e%8b" aria-label="2.2 安装模型">2.2 安装模型</a></li>
                    <li>
                        <a href="#23-%e6%9f%a5%e7%9c%8b%e5%b7%b2%e5%ae%89%e8%a3%85%e6%a8%a1%e5%9e%8b" aria-label="2.3 查看已安装模型">2.3 查看已安装模型</a></li>
                    <li>
                        <a href="#24-%e7%a7%bb%e9%99%a4%e6%a8%a1%e5%9e%8b" aria-label="2.4 移除模型">2.4 移除模型</a></li>
                    <li>
                        <a href="#25-%e5%90%af%e5%8a%a8ollama%e6%9c%8d%e5%8a%a1" aria-label="2.5 启动ollama服务">2.5 启动ollama服务</a></li></ul>
                    </li>
                    <li>
                        <a href="#%e4%b8%89%e5%9c%a8python%e4%b8%ad%e8%b0%83%e7%94%a8ollama%e4%b8%ad%e5%a4%a7%e6%a8%a1%e5%9e%8b" aria-label="三、在Python中调用Ollama中大模型">三、在Python中调用Ollama中大模型</a><ul>
                            
                    <li>
                        <a href="#31-%e5%90%af%e5%8a%a8ollama%e6%9c%8d%e5%8a%a1" aria-label="3.1 启动Ollama服务">3.1 启动Ollama服务</a></li>
                    <li>
                        <a href="#32-%e5%ae%89%e8%a3%85" aria-label="3.2 安装">3.2 安装</a></li>
                    <li>
                        <a href="#33-%e5%ae%9e%e9%aa%8c" aria-label="3.3 实验">3.3 实验</a><ul>
                            
                    <li>
                        <a href="#331-qwen2515b" aria-label="3.3.1 qwen2.5:1.5b">3.3.1 qwen2.5:1.5b</a></li>
                    <li>
                        <a href="#332-deepseek-r115b" aria-label="3.3.2 deepseek r1:1.5b">3.3.2 deepseek r1:1.5b</a></li></ul>
                    </li></ul>
                    </li>
                    <li>
                        <a href="#%e5%9b%9b%e6%80%a7%e8%83%bd%e8%af%84%e4%bb%b7" aria-label="四、性能评价">四、性能评价</a></li>
                    <li>
                        <a href="#%e7%b2%be%e9%80%89%e5%86%85%e5%ae%b9" aria-label="精选内容">精选内容</a>
                    </li>
                </ul>
            </div>
        </details>
    </div>
</aside>
<script>
    let activeElement;
    let elements;
    window.addEventListener('DOMContentLoaded', function (event) {
        checkTocPosition();

        elements = document.querySelectorAll('h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]');
         
         activeElement = elements[0];
         const id = encodeURI(activeElement.getAttribute('id')).toLowerCase();
         document.querySelector(`.inner ul li a[href="#${id}"]`).classList.add('active');
     }, false);

    window.addEventListener('resize', function(event) {
        checkTocPosition();
    }, false);

    window.addEventListener('scroll', () => {
        
        activeElement = Array.from(elements).find((element) => {
            if ((getOffsetTop(element) - window.pageYOffset) > 0 && 
                (getOffsetTop(element) - window.pageYOffset) < window.innerHeight/2) {
                return element;
            }
        }) || activeElement

        elements.forEach(element => {
             const id = encodeURI(element.getAttribute('id')).toLowerCase();
             if (element === activeElement){
                 document.querySelector(`.inner ul li a[href="#${id}"]`).classList.add('active');
             } else {
                 document.querySelector(`.inner ul li a[href="#${id}"]`).classList.remove('active');
             }
         })
     }, false);

    const main = parseInt(getComputedStyle(document.body).getPropertyValue('--article-width'), 10);
    const toc = parseInt(getComputedStyle(document.body).getPropertyValue('--toc-width'), 10);
    const gap = parseInt(getComputedStyle(document.body).getPropertyValue('--gap'), 10);

    function checkTocPosition() {
        const width = document.body.scrollWidth;

        if (width - main - (toc * 2) - (gap * 4) > 0) {
            document.getElementById("toc-container").classList.add("wide");
        } else {
            document.getElementById("toc-container").classList.remove("wide");
        }
    }

    function getOffsetTop(element) {
        if (!element.getClientRects().length) {
            return 0;
        }
        let rect = element.getBoundingClientRect();
        let win = element.ownerDocument.defaultView;
        return rect.top + win.pageYOffset;   
    }
</script>

  <div class="post-content"><h2 id="一ollama">一、Ollama<a hidden class="anchor" aria-hidden="true" href="#一ollama">#</a></h2>
<h3 id="11-ollama介绍">1.1 Ollama介绍<a hidden class="anchor" aria-hidden="true" href="#11-ollama介绍">#</a></h3>
<p><a href="https://ollama.ai/"><strong>Ollama</strong></a>是一款开源应用程序，可让您使用 MacOS、Linux 和 Windows 上的命令行界面在本地运行、创建和共享大型语言模型。</p>
<p>Ollama 可以直接从其库中访问各种 LLM，只需一个命令即可下载。下载后，只需执行一个命令即可开始使用。这对于工作量围绕终端窗口的用户非常有帮助。如果他们被困在某个地方，他们可以在不切换到另一个浏览器窗口的情况下获得答案。</p>
<br>
<p>这就是为什么 OLLAMA 是您的工具包中必备的工具：</p>
<ul>
<li><strong>简单</strong> ：OLLAMA 提供简单的设置过程。您无需拥有机器学习博士学位即可启动和运行它。</li>
<li><strong>成本效益</strong> ：在本地运行模型意味着您无需支付云成本。您的钱包会感谢您。</li>
<li><strong>隐私</strong> ：使用 OLLAMA，所有数据处理都在您的本地机器上进行。这对于用户隐私来说是一个巨大的胜利。</li>
<li><strong>多功能性</strong> ：OLLAMA 不只是为 Python 爱好者准备的。它的灵活性使其可以用于各种应用程序，包括 Web 开发。</li>
</ul>
<br>
<h3 id="12-安装ollama">1.2 安装ollama<a hidden class="anchor" aria-hidden="true" href="#12-安装ollama">#</a></h3>
<p>点击前往网站 <a href="https://ollama.com/">https://ollama.com/</a> ，下载ollama软件，支持win、Mac、linux</p>
<p><img loading="lazy" src="img/03-ollama-gui.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="二ollama操作">二、Ollama操作<a hidden class="anchor" aria-hidden="true" href="#二ollama操作">#</a></h2>
<h3 id="21-选择模型">2.1 选择模型<a hidden class="anchor" aria-hidden="true" href="#21-选择模型">#</a></h3>
<p>ollama软件目前支持多种大模型， 如阿里的（<em><strong>qwen2.5</strong></em>）、meta的(llama3.3) 等。目前ollama最流行的模型，是国产开源大模型 <em><strong>deepseek r1</strong></em>。本文将安装<em><strong>qwen2.5:0.5b</strong></em>、 <em><strong>qwen2.5:1.5b</strong></em>、 <em><strong>qwen2.5:3b</strong></em>、 <em><strong>qwen2.5:7b</strong></em>、 <em><strong>deepseek-r1:1.5b</strong></em>、<em><strong>deepseek-r1:7b</strong></em>。 并对模型的速度、内容质量进行对比。</p>
<p><img loading="lazy" src="img/04-ollama-model.png" alt=""  />
</p>
<br>
<p><em><strong>DeepSeek-R1</strong></em> 在后训练阶段大规模使用了强化学习技术，在仅有极少标注数据的情况下，极大提升了模型推理能力。<strong>在数学、代码、自然语言推理等任务上，性能比肩 OpenAI o1 正式版</strong>。</p>
<p><img loading="lazy" src="img/01-deepseekr1-performance.png" alt=""  />
</p>
<br>
<h3 id="22-安装模型">2.2 安装模型<a hidden class="anchor" aria-hidden="true" href="#22-安装模型">#</a></h3>
<p><strong>一般b前面的数字越小， 运行模型对电脑性能的要求越低</strong>。</p>
<p><img loading="lazy" src="img/05-deepseek-r1.png" alt=""  />
</p>
<p><img loading="lazy" src="img/05-qwen2.5.png" alt=""  />
</p>
<br>
<p>打开电脑命令行cmd(mac是terminal),  网络是连网状态，执行模型下载(安装)命令</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">ollama run deepseek-r1:1.5b
ollama run deepseek-r1:7b
ollama run qwen2.5:0.5b
ollama run qwen2.5:1.5b
ollama run qwen2.5:3b
ollama run qwen2.5:7b
</code></pre></div><br>
<h3 id="23-查看已安装模型">2.3 查看已安装模型<a hidden class="anchor" aria-hidden="true" href="#23-查看已安装模型">#</a></h3>
<p>在电脑命令行cmd(mac是terminal),  执行命令</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">ollama list
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">Last login: Tue Sep 24 19:26:46 on ttys000
da@deng ~ % ollama list
NAME                       ID              SIZE      MODIFIED        
qwen2.5:0.5b               a8b0c5157701    397 MB    15 minutes ago 
qwen2.5:1.5b               65ec06548149    986 MB    18 minutes ago  
qwen2.5:3b                 357c53fb659c    1.9 GB    12 minutes ago 
qwen2.5:7b                 845dbda0ea48    4.7 GB    21 seconds ago       
deepseek-r1:1.5b           a42b25d8c10a    1.1 GB    48 minutes ago    
deepseek-r1:7b             0a8c26691023    4.7 GB    50 minutes ago    
nomic-embed-text:latest    0a109f422b47    274 MB    9 months ago 
da@deng ~ % 
</code></pre></div><p>可以看到，列表中有 <em><strong>deepseek-r1:1.5b</strong></em> ， 说明在大邓的电脑中， 已经成功安装了 <em><strong>deepseek-r1:1.5b</strong></em> 。</p>
<br>
<h3 id="24-移除模型">2.4 移除模型<a hidden class="anchor" aria-hidden="true" href="#24-移除模型">#</a></h3>
<p>使用 <code>ollama rm 模型名称</code> 移除已安装的某模型。 假设要移除 <em><strong>deepseek-r1:8b</strong></em>， 在电脑命令行cmd(mac是terminal),  执行移除命令</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">ollama</span> <span class="n">rm</span> <span class="n">deepseek</span><span class="o">-</span><span class="n">r1</span><span class="p">:</span><span class="mi">8</span><span class="n">b</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">deleted &#39;deepseek-r1:8b&#39;
</code></pre></div><br>
<h3 id="25-启动ollama服务">2.5 启动ollama服务<a hidden class="anchor" aria-hidden="true" href="#25-启动ollama服务">#</a></h3>
<p>在电脑中找到 ollama软件的图标， 双击打开即可开启 Ollama 服务。</p>
<p>如果觉得点击启动太麻烦，也可使用命令行操作， 打开电脑命令行cmd(mac是terminal), 执行</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">ollama serve
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">2025/02/07 16:00:18 routes.go:1259: INFO server config env=&#34;map[HTTPS_PROXY: HTTP_PROXY: NO_PROXY: OLLAMA_DEBUG:false OLLAMA_FLASH_ATTENTION:false OLLAMA_GPU_OVERHEAD:0 OLLAMA_HOST:http://127.0.0.1:11434 OLLAMA_KEEP_ALIVE:5m0s OLLAMA_KV_CACHE_TYPE: OLLAMA_LLM_LIBRARY: OLLAMA_LOAD_TIMEOUT:5m0s OLLAMA_MAX_LOADED_MODELS:0 OLLAMA_MAX_QUEUE:512 OLLAMA_MODELS:/Users/deng/.ollama/models OLLAMA_MULTIUSER_CACHE:false OLLAMA_NOHISTORY:false OLLAMA_NOPRUNE:false OLLAMA_NUM_PARALLEL:0 OLLAMA_ORIGINS:[http://localhost https://localhost http://localhost:* https://localhost:* http://127.0.0.1 https://127.0.0.1 http://127.0.0.1:* https://127.0.0.1:* http://0.0.0.0 https://0.0.0.0 http://0.0.0.0:* https://0.0.0.0:* app://* file://* tauri://* vscode-webview://*] OLLAMA_SCHED_SPREAD:false http_proxy: https_proxy: no_proxy:]&#34;
time=2025-02-07T16:00:18.551+08:00 level=INFO source=images.go:757 msg=&#34;total blobs: 11&#34;
time=2025-02-07T16:00:18.551+08:00 level=INFO source=images.go:764 msg=&#34;total unused blobs removed: 0&#34;
[GIN-debug] [WARNING] Creating an Engine instance with the Logger and Recovery middleware already attached.

[GIN-debug] [WARNING] Running in &#34;debug&#34; mode. Switch to &#34;release&#34; mode in production.
 - using env:	export GIN_MODE=release
 - using code:	gin.SetMode(gin.ReleaseMode)
er.(*Server).GenerateRoutes.func1 (5 handlers)
......
time=2025-02-07T16:00:18.553+08:00 level=INFO source=routes.go:1339 msg=&#34;Dynamic LLM libraries&#34; runners=[metal]
time=2025-02-07T16:00:18.577+08:00 level=INFO source=types.go:131 msg=&#34;inference compute&#34; id=0 library=metal variant=&#34;&#34; compute=&#34;&#34; driver=0.0 name=&#34;&#34; total=&#34;72.0 GiB&#34; available=&#34;72.0 GiB&#34;
</code></pre></div><p>cmd(mac是terminal)看到如上的信息，说明命令行本地ollama服务已开启。</p>
<br>
<h2 id="三在python中调用ollama中大模型">三、在Python中调用Ollama中大模型<a hidden class="anchor" aria-hidden="true" href="#三在python中调用ollama中大模型">#</a></h2>
<p>在Python中， 有很多第三方库，如langchain、langgraph、ollama， 都能调用Ollama内的模型。 这里以ollama库为例，</p>
<h3 id="31-启动ollama服务">3.1 启动Ollama服务<a hidden class="anchor" aria-hidden="true" href="#31-启动ollama服务">#</a></h3>
<p>在电脑中找到 <em><strong>ollama</strong></em> 软件的图标， 双击打开即可开启 Ollama 服务。</p>
<br>
<h3 id="32-安装">3.2 安装<a hidden class="anchor" aria-hidden="true" href="#32-安装">#</a></h3>
<p>打开电脑命令行 <em><strong>cmd</strong></em> (mac是terminal),  网络是连网状态，执行安装命令</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">pip3 install ollama
#pip3 install ollama==0.2.1
</code></pre></div><br>
<h3 id="33-实验">3.3 实验<a hidden class="anchor" aria-hidden="true" href="#33-实验">#</a></h3>
<p><em><strong>假设你是X先生的私人助理，负责X先生的形成安排。X先生一周后将去哈尔滨旅游，帮X先生设计一个哈尔滨一日游形成安排</strong></em>。</p>
<h4 id="331-qwen2515b">3.3.1 qwen2.5:1.5b<a hidden class="anchor" aria-hidden="true" href="#331-qwen2515b">#</a></h4>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#%%time #单次运行时间</span>
<span class="c1">#%%timeit #多次运行，求得平均运行时间</span>

<span class="kn">import</span> <span class="nn">ollama</span>
<span class="c1">#大邓的ollama版本为0.2.1</span>


<span class="n">content</span> <span class="o">=</span> <span class="s2">&#34;你是X先生的私人助理，负责X先生的形成安排。X先生一周后将去哈尔滨旅游，帮X先生设计一个哈尔滨一日游形成安排。&#34;</span>
<span class="n">response</span> <span class="o">=</span> <span class="n">ollama</span><span class="o">.</span><span class="n">chat</span><span class="p">(</span><span class="n">model</span> <span class="o">=</span> <span class="s1">&#39;qwen2:7b&#39;</span><span class="p">,</span>   <span class="c1">#选择模型</span>
                       <span class="n">messages</span> <span class="o">=</span> <span class="p">[{</span><span class="s1">&#39;role&#39;</span><span class="p">:</span> <span class="s1">&#39;user&#39;</span><span class="p">,</span> <span class="s1">&#39;content&#39;</span><span class="p">:</span> <span class="n">content</span><span class="p">}])</span>


<span class="c1">#content2 = &#34;X先生一周后将去哈尔滨旅游，帮X先生设计一个哈尔滨一日游形成安排。&#34;</span>
<span class="c1">#response = ollama.chat(model = &#39;qwen2:7b&#39;,  #选择模型</span>
<span class="c1">#                       messages = [</span>
<span class="c1">#                         {&#39;role&#39;: &#39;system&#39;, &#39;content&#39;: &#34;你是X先生的私人助理，负责X先生的形成安排。&#34;},</span>
<span class="c1">#                         {&#39;role&#39;: &#39;user&#39;, &#39;content&#39;: content2}</span>
<span class="c1">#                       ]</span>
<span class="c1">#                      )</span>


<span class="n">result</span> <span class="o">=</span> <span class="n">response</span><span class="p">[</span><span class="s1">&#39;message&#39;</span><span class="p">][</span><span class="s1">&#39;content&#39;</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">我理解您是Qwen，但我作为AI模型，并没有实际经历、记忆或能力来为任何人策划旅行安排。不过，我可以提供一些建议性的建议帮助您设计这个行程。

1. 交通：根据您的具体位置和出发时间，您可以考虑哈尔滨的机场（哈尔滨太平国际机场）或者火车站的便利性。
2. 确定活动：哈尔滨是冰城，所以可以尝试观看滑冰、滑雪或雪地摩托等冰上活动。另外，您还可以参加冰雪节，体验东北特色的冰灯展览。当然，如果您喜欢风景的话，还可以在松花江畔散步，欣赏沿岸的风景。
3. 餐饮：哈尔滨的特色美食包括狗不理包子和东北锅盔。此外，您可以品尝到鲜美的冻梨和各种风味小吃。 
4. 购物：逛一逛哈啤街可以买到冰城特产和纪念品。

以上只是建议性的行程安排，您的实际旅行需要根据您的兴趣爱好、身体状况以及时间来确定。希望这些建议对您有所帮助！
好的，我将根据您的需求为您制定一份哈尔滨一日游的行程方案：

### 第1天：抵达哈尔滨

- **上午8:00**：从上海或您所在的城市出发前往哈尔滨国际机场。
- **下午2:30**：抵达哈尔滨，下飞机后换乘高速动车（约4小时）到达哈尔滨南站。
- **下午3:30**：到机场附近的酒店办理入住手续，稍作休息准备。

### 第2天：哈尔滨之旅

#### 上午：城市观光与探索

- **10:00**：前往中央大街。这里以其独特的建筑风格和文化氛围吸引着众多游客。
- **上午11:30**：参观东北虎林园，了解中国最北部的野生动物保护情况。
- **下午2:00**：漫步于圣索菲亚教堂附近的小巷，体验哈尔滨的老城区生活。
- **下午4:00**：在哈啤博物馆内探索哈尔滨啤酒的历史和制作工艺。

#### 下午：文化与美食

- **15:30**：参观哈尔滨冰雕艺术展览，欣赏世界级的冰雪艺术品。
- **下午6:00**：返回市区，享用正宗的东北大餐，比如狗不理包子、哈尔滨锅包肉等特色小吃。

#### 晚上：夜游与体验

- **18:00**：乘坐雪乡索道上山，探索世界最大的冰雪雕塑群。
- **晚上20:30**：回到市区，品尝地道的哈尔滨美食和市井风味小摊。
- **21:30**：结束今天的行程。

### 第3天：返程

#### 晚间：准备离店

- **15:00**：在酒店享用晚餐，并安排打包食物或行李。
- **16:30**：开始收拾行囊，准备出发离开哈尔滨。可能需要提前半小时抵达机场。

请注意，这个方案是基于一般情况下的旅游规划，实际行程可能会根据您的偏好和具体交通时间有所调整。希望这份行程能为您提供一个美好的哈尔滨旅行体验！
</code></pre></div><br>
<h4 id="332-deepseek-r115b">3.3.2 deepseek r1:1.5b<a hidden class="anchor" aria-hidden="true" href="#332-deepseek-r115b">#</a></h4>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#%%time #单次运行时间</span>
<span class="c1">#%%timeit #多次运行，求得平均运行时间</span>

<span class="kn">import</span> <span class="nn">ollama</span>
<span class="c1">#大邓的ollama版本为0.2.1</span>

<span class="n">content</span> <span class="o">=</span> <span class="s2">&#34;你是X先生的私人助理，负责X先生的形成安排。X先生一周后将去哈尔滨旅游，帮X先生设计一个哈尔滨一日游形成安排。&#34;</span>
<span class="n">response</span> <span class="o">=</span> <span class="n">ollama</span><span class="o">.</span><span class="n">chat</span><span class="p">(</span><span class="n">model</span> <span class="o">=</span> <span class="s1">&#39;deepseek-r1:1.5b&#39;</span><span class="p">,</span>   <span class="c1">#选择模型</span>
                       <span class="n">messages</span> <span class="o">=</span> <span class="p">[{</span><span class="s1">&#39;role&#39;</span><span class="p">:</span> <span class="s1">&#39;user&#39;</span><span class="p">,</span> <span class="s1">&#39;content&#39;</span><span class="p">:</span> <span class="n">content</span><span class="p">}])</span>


<span class="c1">#content2 = &#34;X先生一周后将去哈尔滨旅游，帮X先生设计一个哈尔滨一日游形成安排。&#34;</span>
<span class="c1">#response = ollama.chat(model = &#39;deepseek-r1:1.5b&#39;,  #选择模型</span>
<span class="c1">#                       messages = [</span>
<span class="c1">#                         {&#39;role&#39;: &#39;system&#39;, &#39;content&#39;: &#34;你是X先生的私人助理，负责X先生的形成安排。&#34;},</span>
<span class="c1">#                         {&#39;role&#39;: &#39;user&#39;, &#39;content&#39;: content2}</span>
<span class="c1">#                       ]</span>
<span class="c1">#                      )</span>


<span class="n">result</span> <span class="o">=</span> <span class="n">response</span><span class="p">[</span><span class="s1">&#39;message&#39;</span><span class="p">][</span><span class="s1">&#39;content&#39;</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">&lt;think&gt;
好的，用户需要我设计哈尔滨一日游的安排。首先，我得考虑目标客户的需求是什么。是单日游还是多日？用户可能是一个游客，想要既能体验哈尔滨的魅力，又不想太累，所以时间控制在两三个小时比较合适。

接下来，我要确定 Polar Express作为活动的主要交通工具，因为它不仅风景优美，还能带来刺激感，比如乘坐 escalator，这样可以让游客感觉有 motion。然后，其他活动要安排得轻松愉快，比如游船、冰灯 etc.，这些都能让整个行程看起来充实而有变化。

时间安排方面，从12点到下午三点左右比较合适，因为中午的户外活动和下午的购物区可以好好玩一玩。每个时间段都要留足够的时间进行活动，确保行程紧凑且不累赘。

另外，还要注意注意事项，比如天气、门票等，特别是如果用户是儿童的话，得确保安全和适合的主题。最后，提醒用户根据自己的需求调整时间和内容，让行程更加个性化和有创意。
&lt;/think&gt;

嗯，你已经让我设计了一个详细的哈尔滨一日游安排了！让我们一步步来思考一下：

### 1. 时间框架
假设你计划在上午去游览景点，下午去夜游，晚上进行购物和品尝美食。

### 2. 活动安排建议：
   - **早上： Polar Express 呼吸机 ride（快速穿梭公园内）**
   - 每人乘坐 Polar Express前往公园，体验快速移动的刺激。
   
- **中午： 游船游湖**
   - 晚上11点前坐 boat 温泉，感受 Polar Bear 和 fish 的美丽。

- **下午： 傍晚： ice cream 环岛游（Polar Express 区）**
   - 跑在环城的路上购买冰棒和冰淇淋，享受夜景。

- **晚上： 餐饮**
   - 中午去餐馆点餐，晚餐去夜市品尝特色小吃。

### 3. 注意事项：
- 如果是儿童游玩，记得注意安全，选择容易摔倒的景点。
- 建议提前预订 Polar Express 的票，避免排队。

希望这个安排能满足你的需求！如果你有其他具体需求或偏好，请告诉我，我可以再调整哦！
</code></pre></div><br>
<br>
<h2 id="四性能评价">四、性能评价<a hidden class="anchor" aria-hidden="true" href="#四性能评价">#</a></h2>
<p><em><strong>qwen2.5</strong></em> 和 <em><strong>deepseek r1</strong></em> 都能很好的完成了旅游规划的任务。 运行速度方面， <em><strong>qwen2.5</strong></em> 远快于 <em><strong>deepseek r1</strong></em> 。本次实验中每个代码均运行7次，最终求得平均耗时</p>
<ul>
<li><em><strong>qwen2.5:0.5b</strong></em> 平均耗时 <em><strong>1.43 s ± 746 ms</strong></em></li>
<li><em><strong>qwen2.5:1.5b</strong></em> 平均耗时 <em><strong>2.5 s ± 1.18 s</strong></em></li>
<li><em><strong>qwen2.5: 3b</strong></em> 平均耗时 <em><strong>4.76 s ± 1.77 s</strong></em></li>
<li><em><strong>qwen2.5: 7b</strong></em> 平均耗时 <em><strong>8.58 s ± 534 ms</strong></em></li>
<li><em><strong>deepseek r1:1.5b</strong></em> 平均耗时 <em><strong>8.71 s ± 1.66 s</strong></em></li>
<li><em><strong>deepseek r1:7b</strong></em> 平均耗时 <em><strong>21 s ± 4.39 s</strong></em></li>
</ul>
<p>如果追求速度， 同样体量的模型的(以1.5b为例)，目前首选 <em><strong>qwen2.5</strong></em> （qwen2.5:1.5b）。</p>
<p>各位可以结合自己任务， 电脑性能， 速度等不同需求， 选择对自己最合适的模型。</p>
<br>
<br>
<h2 id="精选内容">精选内容<a hidden class="anchor" aria-hidden="true" href="#精选内容">#</a></h2>
<ul>
<li><a href="https://textdata.cn/blog/datasets_available_for_management_science/">LIST | 可供社科(经管)领域使用的数据集汇总</a></li>
<li><a href="https://textdata.cn/blog/the_text_analysis_list_about_ms/">LIST | 社科(经管)数据挖掘文献资料汇总</a></li>
<li><a href="https://textdata.cn/blog/2024-06-16-scrapegraph-ai/">网络爬虫 | 使用scrapegraph-ai(大模型方案)自动采集网页数据</a></li>
<li><a href="https://textdata.cn/blog/2024-04-27-cntext2x-usage-tutorial/">推荐 | 文本分析库cntext2.x使用手册</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
<li><a href="https://textdata.cn/blog/2025-02-07-using-large-language-model-to-extract-structure-data-from-raw-text/">实验 | 使用本地大模型从文本中提取结构化信息</a>7</li>
</ul>


  </div>

  <footer class="post-footer">
      <ul class="post-tags">
        <b>Tags:  &nbsp;</b>
        <li><a href="/tags/llm/" target='_blank'>LLM</a></li>
        <li><a href="/tags/%E6%96%87%E6%9C%AC%E5%88%86%E6%9E%90/" target='_blank'>文本分析</a></li>
      </ul>


<div class="share-buttons">
    <a target="_blank" rel="noopener noreferrer" aria-label="share 教程 | 如何使用 Ollama 下载 &amp; 使用本地大语言模型 on twitter"
        href="https://twitter.com/intent/tweet/?text=%e6%95%99%e7%a8%8b%20%7c%20%e5%a6%82%e4%bd%95%e4%bd%bf%e7%94%a8%20Ollama%20%e4%b8%8b%e8%bd%bd%20%26%20%e4%bd%bf%e7%94%a8%e6%9c%ac%e5%9c%b0%e5%a4%a7%e8%af%ad%e8%a8%80%e6%a8%a1%e5%9e%8b&amp;url=%2fblog%2f2024-06-14-how-to-download-large-language-model-with-ollama%2f&amp;hashtags=LLM%2c%e6%96%87%e6%9c%ac%e5%88%86%e6%9e%90">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-253.927,424.544c135.939,0 210.268,-112.643 210.268,-210.268c0,-3.218 0,-6.437 -0.153,-9.502c14.406,-10.421 26.973,-23.448 36.935,-38.314c-13.18,5.824 -27.433,9.809 -42.452,11.648c15.326,-9.196 26.973,-23.602 32.49,-40.92c-14.252,8.429 -30.038,14.56 -46.896,17.931c-13.487,-14.406 -32.644,-23.295 -53.946,-23.295c-40.767,0 -73.87,33.104 -73.87,73.87c0,5.824 0.613,11.494 1.992,16.858c-61.456,-3.065 -115.862,-32.49 -152.337,-77.241c-6.284,10.881 -9.962,23.601 -9.962,37.088c0,25.594 13.027,48.276 32.95,61.456c-12.107,-0.307 -23.448,-3.678 -33.41,-9.196l0,0.92c0,35.862 25.441,65.594 59.311,72.49c-6.13,1.686 -12.72,2.606 -19.464,2.606c-4.751,0 -9.348,-0.46 -13.946,-1.38c9.349,29.426 36.628,50.728 68.965,51.341c-25.287,19.771 -57.164,31.571 -91.8,31.571c-5.977,0 -11.801,-0.306 -17.625,-1.073c32.337,21.15 71.264,33.41 112.95,33.41Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share 教程 | 如何使用 Ollama 下载 &amp; 使用本地大语言模型 on linkedin"
        href="https://www.linkedin.com/shareArticle?mini=true&amp;url=%2fblog%2f2024-06-14-how-to-download-large-language-model-with-ollama%2f&amp;title=%e6%95%99%e7%a8%8b%20%7c%20%e5%a6%82%e4%bd%95%e4%bd%bf%e7%94%a8%20Ollama%20%e4%b8%8b%e8%bd%bd%20%26%20%e4%bd%bf%e7%94%a8%e6%9c%ac%e5%9c%b0%e5%a4%a7%e8%af%ad%e8%a8%80%e6%a8%a1%e5%9e%8b&amp;summary=%e6%95%99%e7%a8%8b%20%7c%20%e5%a6%82%e4%bd%95%e4%bd%bf%e7%94%a8%20Ollama%20%e4%b8%8b%e8%bd%bd%20%26%20%e4%bd%bf%e7%94%a8%e6%9c%ac%e5%9c%b0%e5%a4%a7%e8%af%ad%e8%a8%80%e6%a8%a1%e5%9e%8b&amp;source=%2fblog%2f2024-06-14-how-to-download-large-language-model-with-ollama%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share 教程 | 如何使用 Ollama 下载 &amp; 使用本地大语言模型 on reddit"
        href="https://reddit.com/submit?url=%2fblog%2f2024-06-14-how-to-download-large-language-model-with-ollama%2f&title=%e6%95%99%e7%a8%8b%20%7c%20%e5%a6%82%e4%bd%95%e4%bd%bf%e7%94%a8%20Ollama%20%e4%b8%8b%e8%bd%bd%20%26%20%e4%bd%bf%e7%94%a8%e6%9c%ac%e5%9c%b0%e5%a4%a7%e8%af%ad%e8%a8%80%e6%a8%a1%e5%9e%8b">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share 教程 | 如何使用 Ollama 下载 &amp; 使用本地大语言模型 on facebook"
        href="https://facebook.com/sharer/sharer.php?u=%2fblog%2f2024-06-14-how-to-download-large-language-model-with-ollama%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share 教程 | 如何使用 Ollama 下载 &amp; 使用本地大语言模型 on whatsapp"
        href="https://api.whatsapp.com/send?text=%e6%95%99%e7%a8%8b%20%7c%20%e5%a6%82%e4%bd%95%e4%bd%bf%e7%94%a8%20Ollama%20%e4%b8%8b%e8%bd%bd%20%26%20%e4%bd%bf%e7%94%a8%e6%9c%ac%e5%9c%b0%e5%a4%a7%e8%af%ad%e8%a8%80%e6%a8%a1%e5%9e%8b%20-%20%2fblog%2f2024-06-14-how-to-download-large-language-model-with-ollama%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share 教程 | 如何使用 Ollama 下载 &amp; 使用本地大语言模型 on telegram"
        href="https://telegram.me/share/url?text=%e6%95%99%e7%a8%8b%20%7c%20%e5%a6%82%e4%bd%95%e4%bd%bf%e7%94%a8%20Ollama%20%e4%b8%8b%e8%bd%bd%20%26%20%e4%bd%bf%e7%94%a8%e6%9c%ac%e5%9c%b0%e5%a4%a7%e8%af%ad%e8%a8%80%e6%a8%a1%e5%9e%8b&amp;url=%2fblog%2f2024-06-14-how-to-download-large-language-model-with-ollama%2f">
        <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28">
            <path
                d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
        </svg>
    </a>
    
</div>




  </footer><script src="https://utteranc.es/client.js"
        repo="hiDaDeng/hidadeng.github.io"
        issue-term="pathname"
        theme="preferred-color-scheme"
        crossorigin="anonymous"
        async>
</script>

  
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2025 <a href="/">大邓和他的PYTHON</a></span>
</footer>
<a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerText = 'Copy';

        function copyingDone() {
            copybutton.innerText = 'Copied!';
            setTimeout(() => {
                copybutton.innerText = 'Copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>


    
    
</body>

</html>
