<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>æ¨è | æ–‡æœ¬åˆ†æåº“ cntext ä½¿ç”¨æ‰‹å†Œ | å¤§é‚“å’Œä»–çš„PYTHON</title>
<meta name="keywords" content="Python, æ–‡æœ¬åˆ†æ, ç»æµæ”¿ç­–ä¸ç¡®å®šæ€§, è¯­ä¹‰å“ç‰Œè¯„åˆ†, cntext, ä¸­æ–‡æ–‡æœ¬åˆ†æ, chinese text analysis, text mining, æ–‡æœ¬æŒ–æ˜, ç»ç®¡æ–‡æœ¬åˆ†æ" />
<meta name="description" content="ç¤¾ä¼šå­¦ã€ç»æµå­¦ã€ç®¡ç†å­¦ç­‰å­¦ç§‘é¢†åŸŸï¼Œä¸­æ–‡æ–‡æœ¬åˆ†æPythonåº“cntext2xã€‚">
<meta name="author" content="å¤§é‚“">
<link rel="canonical" href="/blog/2024-04-27-cntext2x-usage-tutorial/" />
<meta name="baidu-site-verification" content="codeva-TJUe6nOmGr" />
<meta name="sogou-site-verification" content="dZHPIorOhK" />
<meta name="sogou-site-verification" content="dZHPIorOhK" />
<meta name="google-site-verification" content="0cmjnyICPwXY_UmLHzs6RRUBIFxxqieMsgTGT_kVctk" />
<meta name="yandex-verification" content="5e672f12d3e2cacd" />
<link crossorigin="anonymous" href="/assets/css/stylesheet.min.css" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/assets/js/highlight.min.js" onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="apple-touch-icon" href="/apple-touch-icon.png">
<link rel="mask-icon" href="/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<meta name="generator" content="Hugo 0.89.4" />
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:title" content="æ¨è | æ–‡æœ¬åˆ†æåº“ cntext ä½¿ç”¨æ‰‹å†Œ" />
<meta property="og:description" content="ç¤¾ä¼šå­¦ã€ç»æµå­¦ã€ç®¡ç†å­¦ç­‰å­¦ç§‘é¢†åŸŸï¼Œä¸­æ–‡æ–‡æœ¬åˆ†æPythonåº“cntext2xã€‚" />
<meta property="og:type" content="article" />
<meta property="og:url" content="/blog/2024-04-27-cntext2x-usage-tutorial/" />
<meta property="og:image" content="/images/blog/cntext-2x.png" /><meta property="article:section" content="blog" />
<meta property="article:published_time" content="2025-03-14T00:00:00&#43;00:00" />
<meta property="article:modified_time" content="2025-03-14T00:00:00&#43;00:00" />

<meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:image" content="/images/blog/cntext-2x.png" />
<meta name="twitter:title" content="æ¨è | æ–‡æœ¬åˆ†æåº“ cntext ä½¿ç”¨æ‰‹å†Œ"/>
<meta name="twitter:description" content="ç¤¾ä¼šå­¦ã€ç»æµå­¦ã€ç®¡ç†å­¦ç­‰å­¦ç§‘é¢†åŸŸï¼Œä¸­æ–‡æ–‡æœ¬åˆ†æPythonåº“cntext2xã€‚"/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Blogs",
      "item": "/blog/"
    }
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "æ¨è | æ–‡æœ¬åˆ†æåº“ cntext ä½¿ç”¨æ‰‹å†Œ",
      "item": "/blog/2024-04-27-cntext2x-usage-tutorial/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "æ¨è | æ–‡æœ¬åˆ†æåº“ cntext ä½¿ç”¨æ‰‹å†Œ",
  "name": "æ¨è | æ–‡æœ¬åˆ†æåº“ cntext ä½¿ç”¨æ‰‹å†Œ",
  "description": "ç¤¾ä¼šå­¦ã€ç»æµå­¦ã€ç®¡ç†å­¦ç­‰å­¦ç§‘é¢†åŸŸï¼Œä¸­æ–‡æ–‡æœ¬åˆ†æPythonåº“cntext2xã€‚",
  "keywords": [
    "Python", "æ–‡æœ¬åˆ†æ", "ç»æµæ”¿ç­–ä¸ç¡®å®šæ€§", "è¯­ä¹‰å“ç‰Œè¯„åˆ†", "cntext", "ä¸­æ–‡æ–‡æœ¬åˆ†æ", "chinese text analysis", "text mining", "æ–‡æœ¬æŒ–æ˜", "ç»ç®¡æ–‡æœ¬åˆ†æ"
  ],
  "articleBody": "cntextï¼šé¢å‘ç¤¾ä¼šç§‘å­¦ç ”ç©¶çš„ä¸­æ–‡æ–‡æœ¬åˆ†æå·¥å…·åº“ cntext æ˜¯ä¸“ä¸ºç¤¾ä¼šç§‘å­¦å®è¯ç ”ç©¶è€…è®¾è®¡çš„ä¸­æ–‡æ–‡æœ¬åˆ†æ Python åº“ã€‚å®ƒä¸æ­¢äºè¯é¢‘ç»Ÿè®¡å¼çš„ä¼ ç»Ÿæƒ…æ„Ÿåˆ†æï¼Œè¿˜æ‹¥æœ‰è¯åµŒå…¥è®­ç»ƒã€è¯­ä¹‰æŠ•å½±è®¡ç®—ï¼Œå¯ä»å¤§è§„æ¨¡éç»“æ„åŒ–æ–‡æœ¬ä¸­æµ‹é‡æŠ½è±¡æ„å¿µâ€”â€”å¦‚æ€åº¦ã€è®¤çŸ¥ã€æ–‡åŒ–è§‚å¿µä¸å¿ƒç†çŠ¶æ€ã€‚\nğŸ¯ ä½ èƒ½ç”¨å®ƒåšä»€ä¹ˆ\n  æ„å»ºç»“æ„åŒ–ç ”ç©¶æ•°æ®é›†\n æ±‡æ€»å¤šä¸ªæ–‡æœ¬æ–‡ä»¶ï¼ˆtxt/pdf/docx/csvï¼‰ä¸º DataFrameï¼šct.read_files() æå–ä¸Šå¸‚å…¬å¸å¹´æŠ¥ä¸­çš„â€œç®¡ç†å±‚è®¨è®ºä¸åˆ†æâ€ï¼ˆMD\u0026Aï¼‰ï¼šct.extract_mda() è®¡ç®—æ–‡æœ¬å¯è¯»æ€§æŒ‡æ ‡ï¼ˆå¦‚FleschæŒ‡æ•°ï¼‰ï¼šct.readability()    åŸºç¡€æ–‡æœ¬åˆ†æ(ä¼ ç»Ÿæ–¹æ³•)\n è¯é¢‘ç»Ÿè®¡ä¸å…³é”®è¯æå–ï¼šct.word_count() æƒ…æ„Ÿåˆ†æï¼ˆå¯é€‰hownetã€dutirç­‰å†…ç½®è¯å…¸ï¼‰ï¼šct.sentiment() æ–‡æœ¬ç›¸ä¼¼åº¦è®¡ç®—ï¼ˆä½™å¼¦è·ç¦»ï¼‰ï¼šct.cosine_sim()    æµ‹é‡å†…éšæ€åº¦ä¸æ–‡åŒ–å˜è¿\n ä¸¤è¡Œä»£ç è®­ç»ƒé¢†åŸŸä¸“ç”¨è¯å‘é‡ï¼ˆWord2Vec/GloVeï¼‰ï¼šct.Word2Vec() æ„å»ºæ¦‚å¿µè¯­ä¹‰è½´ï¼ˆå¦‚â€œåˆ›æ–° vs å®ˆæ—§â€ï¼‰ï¼šct.generate_concept_axis() é€šè¿‡è¯­ä¹‰æŠ•å½±é‡åŒ–åˆ»æ¿å°è±¡ã€ç»„ç»‡æ–‡åŒ–åç§»ï¼šct.project_text()    èåˆå¤§æ¨¡å‹è¿›è¡Œç»“æ„åŒ–åˆ†æ\n è°ƒç”¨ LLM å¯¹æ–‡æœ¬è¿›è¡Œè¯­ä¹‰è§£æï¼Œè¿”å›ç»“æ„åŒ–ç»“æœï¼ˆå¦‚æƒ…ç»ªç»´åº¦ã€æ„å›¾åˆ†ç±»ï¼‰ï¼šct.llm()    cntext ä¸è¿½æ±‚é»‘ç®±é¢„æµ‹ï¼Œè€Œè‡´åŠ›äºè®©æ–‡æœ¬æˆä¸ºç†è®ºé©±åŠ¨çš„ç§‘å­¦æµ‹é‡å·¥å…·ã€‚ å¼€æºå…è´¹ï¼Œæ¬¢è¿å­¦ç•ŒåŒä»ä½¿ç”¨ã€éªŒè¯ä¸å…±å»ºã€‚\n\nå®‰è£… cntext pip3 install cntext --upgrade \néœ€è¦æ³¨æ„ï¼Œ cntext ä½¿ç”¨ç¯å¢ƒä¸º Python3.9 ~ 3.12,å¦‚å®‰è£…å¤±è´¥ï¼Œé—®é¢˜å¯èƒ½å‡ºåœ¨ python ç‰ˆæœ¬é—®é¢˜ï¼›\n\nåŠŸèƒ½æ¨¡å— import cntext as ct ct.hello() cntext å« ioã€modelã€statsã€mind äº”ä¸ªæ¨¡å—\n å¯¼å…¥æ•°æ®ç”¨ io è®­ç»ƒæ¨¡å‹æ‰©å±•è¯å…¸ç”¨ model ç»Ÿè®¡è¯é¢‘ã€æƒ…æ„Ÿåˆ†æã€ç›¸ä¼¼åº¦ç­‰ç”¨ stats å¯è§†åŒ–æ¨¡å— plot æ€åº¦è®¤çŸ¥æ–‡åŒ–å˜è¿ç”¨ mind å¤§æ¨¡å‹ LLM  å‡½æ•°éƒ¨åˆ†åŠ ç²—çš„ä¸ºå¸¸ç”¨å‡½æ•°ã€‚\n   æ¨¡å— å‡½æ•° åŠŸèƒ½     io ct.get_cntext_path() æŸ¥çœ‹ cntext å®‰è£…è·¯å¾„   io ct.get_dict_list() æŸ¥çœ‹ cntext å†…ç½®è¯å…¸   io ct.get_files(fformat) æŸ¥çœ‹ç¬¦åˆ fformat è·¯å¾„è§„åˆ™çš„æ‰€æœ‰çš„æ–‡ä»¶   io ct.detect_encoding(file, num_lines=100) è¯Šæ–­ txtã€csv ç¼–ç æ ¼å¼   io ct.read_yaml_dict(yfile) è¯»å–å†…ç½® yaml è¯å…¸   io ct.read_pdf(file) è¯»å– PDF æ–‡ä»¶   io ct.read_docx(file) è¯»å– docx æ–‡ä»¶   io ct.read_file(file, encodings) è¯»å–æ–‡ä»¶   io ct.read_files(fformat, encoding) è¯»å–ç¬¦åˆ fformat è·¯å¾„è§„åˆ™çš„æ‰€æœ‰çš„æ–‡ä»¶ï¼Œè¿”å› df   io ct.extract_mda(text, kws_pattern) æå– A è‚¡å¹´æŠ¥ä¸­çš„ MD\u0026A æ–‡æœ¬å†…å®¹ã€‚å¦‚æœè¿”å›'',åˆ™æå–å¤±è´¥ã€‚   io ct.traditional2simple(text) ç¹ä½“è½¬ç®€ä½“   io ct.clean_text(text, lang=â€˜chineseâ€™) æ ¹æ®æŒ‡å®šè¯­è¨€å¯¹æ–‡æœ¬è¿›è¡Œæ ‡å‡†åŒ–æ¸…æ´—ã€‚   io ct.fix_text(text) å°†ä¸æ­£å¸¸çš„ã€æ··ä¹±ç¼–ç çš„æ–‡æœ¬è½¬åŒ–ä¸ºæ­£å¸¸çš„æ–‡æœ¬ã€‚ä¾‹å¦‚å…¨è§’è½¬åŠè§’   io ct.fix_contractions(text) è‹±æ–‡ç¼©å†™(å«ä¿šè¯­è¡¨è¾¾)å¤„ç†ï¼Œ å¦‚ youâ€™re - you are   model ct.Word2Vec(corpus_file, encoding, lang=â€˜chineseâ€™, â€¦) è®­ç»ƒ Word2Vec   model ct.GloVe(corpus_file, encoding, lang=â€˜chineseâ€™, â€¦) GloVe, åº•å±‚ä½¿ç”¨çš„ Standfordnlp/GloVe   model ct.evaluate_similarity(wv, file=None) ä½¿ç”¨è¿‘ä¹‰æ³•è¯„ä¼°æ¨¡å‹è¡¨ç°ï¼Œé»˜è®¤ä½¿ç”¨å†…ç½®çš„æ•°æ®è¿›è¡Œè¯„ä¼°ã€‚   model ct.evaluate_analogy(wv, file=None) ä½¿ç”¨ç±»æ¯”æ³•è¯„ä¼°æ¨¡å‹è¡¨ç°ï¼Œé»˜è®¤ä½¿ç”¨å†…ç½®çš„æ•°æ®è¿›è¡Œè¯„ä¼°ã€‚   model ct.glove2word2vec(glove_file, word2vec_file) å°† GLoVe æ¨¡å‹.txt æ–‡ä»¶è½¬åŒ–ä¸º Word2Vec æ¨¡å‹.txt æ–‡ä»¶ï¼› ä¸€èˆ¬å¾ˆå°‘ç”¨åˆ°   model ct.load_w2v(wv_path) è¯»å– cntext2.x è®­ç»ƒå‡ºçš„ Word2Vec/GloVe æ¨¡å‹æ–‡ä»¶   model ct.expand_dictionary(wv, seeddict, topn=100) æ‰©å±•è¯å…¸, ç»“æœä¿å­˜åˆ°è·¯å¾„[output/Word2Vec]ä¸­   model ct.SoPmi(corpus_file, seed_file, lang='chinese') å…±ç°æ³•æ‰©å±•è¯å…¸   stats ct.word_count(text, lang='chinese') è¯é¢‘ç»Ÿè®¡   stats readability(text, lang='chinese', syllables=3) æ–‡æœ¬å¯è¯»æ€§   stats ct.sentiment(text, diction, lang=â€˜chineseâ€™) æ— (ç­‰)æƒé‡è¯å…¸çš„æƒ…æ„Ÿåˆ†æ   stats ct.sentiment_by_valence(text, diction, lang='chinese') å¸¦æƒé‡çš„è¯å…¸çš„æƒ…æ„Ÿåˆ†æ   stats ct.word_in_context(text, keywords, window=3, lang=â€˜chineseâ€™) åœ¨ text ä¸­æŸ¥æ‰¾ keywords å‡ºç°çš„ä¸Šä¸‹æ–‡å†…å®¹(çª—å£ window)ï¼Œè¿”å› df   stats ct.epu() ä½¿ç”¨æ–°é—»æ–‡æœ¬æ•°æ®è®¡ç®—ç»æµæ”¿ç­–ä¸ç¡®å®šæ€§ EPUï¼Œè¿”å› df   stats ct.fepu(text, ep_pattern='', u_pattern='') ä½¿ç”¨ md\u0026a æ–‡æœ¬æ•°æ®è®¡ç®—ä¼ä¸šä¸ç¡®å®šæ€§æ„ŸçŸ¥ FEPU   stats ct.semantic_brand_score(text, brands, lang=â€˜chineseâ€™) è¡¡é‡å“ç‰Œï¼ˆä¸ªä½“ã€å…¬å¸ã€å“ç‰Œã€å…³é”®è¯ç­‰ï¼‰çš„é‡è¦æ€§   stats ct.cosine_sim(text1, text2, lang=â€˜chineseâ€™) ä½™å¼¦ç›¸ä¼¼åº¦   stats ct.jaccard_sim(text1, text2, lang='chinese') Jaccard ç›¸ä¼¼åº¦   stats ct.minedit_sim(text1, text2, lang='chinese') æœ€å°ç¼–è¾‘è·ç¦»   stats ct.word_hhi(text) æ–‡æœ¬çš„èµ«èŠ¬è¾¾å°”-èµ«å¸Œæ›¼æŒ‡æ•°   plot ct.matplotlib_chinese() æ”¯æŒ matplotlib ä¸­æ–‡ç»˜å›¾   plot ct.lexical_dispersion_plot1(text, targets_dict, lang, title, figsize) å¯¹æŸä¸€ä¸ªæ–‡æœ¬ textï¼Œ å¯è§†åŒ–ä¸åŒç›®æ ‡ç±»åˆ«è¯ targets_dict åœ¨æ–‡æœ¬ä¸­å‡ºç°ä½ç½®   plot ct.lexical_dispersion_plot2(texts_dict, targets, lang, title, figsize) å¯¹æŸå‡ ä¸ªæ–‡æœ¬ texts_dictï¼Œ å¯è§†åŒ–æŸäº›ç›®æ ‡è¯ targets åœ¨æ–‡æœ¬ä¸­å‡ºç°ç›¸å¯¹ä½ç½®(0~100)   mind ct.generate_concept_axis(wv, poswords, negwords) ç”Ÿæˆæ¦‚å¿µè½´å‘é‡ã€‚   mind tm = ct.Text2Mind(wv)\n å•ä¸ª word2vec å†…æŒ–æ˜æ½œåœ¨çš„æ€åº¦åè§ã€åˆ»æ¿å°è±¡ç­‰ã€‚tm å«å¤šé‡æ–¹æ³•   mind sematic_projection(wv, words, poswords, negwords, return_full=False, cosine=False) æµ‹é‡è¯­ä¹‰æŠ•å½±   mind ct.project_word(wv, a, b, cosine=False) è®¡ç®—è¯è¯­ a åœ¨è¯è¯­ b ä¸Šçš„æŠ•å½±   mind ct.project_text(wv, text, axis, lang='chinese', cosine=False) è®¡ç®—è¯è¯­æ–‡æœ¬textåœ¨æ¦‚å¿µè½´å‘é‡axisä¸Šçš„æŠ•å½±å€¼   mind ct.project_text(wv, text, axis, lang='chinese', cosine=False) è®¡ç®—è¯è¯­æ–‡æœ¬textåœ¨æ¦‚å¿µè½´å‘é‡axisä¸Šçš„æŠ•å½±å€¼   mind ct.sematic_distance(wv, words1, words2) æµ‹é‡è¯­ä¹‰è·ç¦»   mind ct.divergent_association_task(wv, words) æµ‹é‡å‘æ•£æ€ç»´(åˆ›é€ åŠ›)   mind ct.discursive_diversity_score(wv, words) æµ‹é‡è¯­è¨€å·®å¼‚æ€§(è®¤çŸ¥å·®å¼‚æ€§)   mind ct.procrustes_align(base_wv, other_wv) ä¸¤ä¸ª word2vec è¿›è¡Œè¯­ä¹‰å¯¹é½ï¼Œå¯ååº”éšæ—¶é—´çš„ç¤¾ä¼šè¯­ä¹‰å˜è¿   LLM ct.llm(text, prompt, output_format, task, backend, base_url, api_key, model_name, temperature) è°ƒç”¨å¤§æ¨¡å‹æ‰§è¡Œç»“æ„åŒ–æ–‡æœ¬åˆ†æä»»åŠ¡ï¼ˆå¦‚æƒ…æ„Ÿåˆ†æã€å…³é”®è¯æå–ã€åˆ†ç±»ç­‰ï¼‰ã€‚    \nQuickStart import cntext as ct print('å½“å‰cntextç‰ˆæœ¬: ', ct.__version__) help(ct) Run\nå½“å‰cntextç‰ˆæœ¬: 2.1.7 Help on package cntext: NAME cntext PACKAGE CONTENTS io mind model stats llm ... \nä¸€ã€IO æ¨¡å—    æ¨¡å— å‡½æ•° åŠŸèƒ½     io ct.get_dict_list() æŸ¥çœ‹ cntext å†…ç½®è¯å…¸   io ct.read_yaml_dict(yfile) è¯»å–å†…ç½® yaml è¯å…¸   io ct.detect_encoding(file, num_lines=100) è¯Šæ–­ txtã€csv ç¼–ç æ ¼å¼   io ct.get_files(fformat) æŸ¥çœ‹ç¬¦åˆ fformat è·¯å¾„è§„åˆ™çš„æ‰€æœ‰çš„æ–‡ä»¶   io ct.read_yaml_dict(yfile) è¯»å–å†…ç½® yaml è¯å…¸   io ct.read_pdf(file) è¯»å– PDF æ–‡ä»¶   io ct.read_file(file, encoding) è¯»å–æ–‡ä»¶   io ct.read_files(fformat, encoding) è¯»å–ç¬¦åˆ fformat è·¯å¾„è§„åˆ™çš„æ‰€æœ‰çš„æ–‡ä»¶ï¼Œè¿”å› df   io ct.extract_mda(text, kws_pattern) æå– A è‚¡å¹´æŠ¥ä¸­çš„ MD\u0026A æ–‡æœ¬å†…å®¹ã€‚å¦‚æœè¿”å›'',åˆ™æå–å¤±è´¥ã€‚   io ct.traditional2simple(text) ç¹ä½“è½¬ç®€ä½“   io ct.fix_text(text) å°†ä¸æ­£å¸¸çš„ã€æ··ä¹±ç¼–ç çš„æ–‡æœ¬è½¬åŒ–ä¸ºæ­£å¸¸çš„æ–‡æœ¬ã€‚ä¾‹å¦‚å…¨è§’è½¬åŠè§’   io ct.fix_contractions(text) è‹±æ–‡ç¼©å†™(å«ä¿šè¯­è¡¨è¾¾)å¤„ç†ï¼Œ å¦‚ youâ€™re - you are    1.1 get_dict_list() æŸ¥çœ‹ cntext å†…ç½®è¯å…¸\nimport cntext as ct ct.get_dict_list() Run\n['zh_common_NTUSD.yaml', 'zh_common_DUTIR.yaml', 'enzh_common_StopWords.yaml', 'en_valence_Concreteness.yaml', 'en_common_LoughranMcDonald.yaml', 'zh_common_FinanceSenti.yaml', 'zh_common_FLS.yaml', 'zh_common_TsinghuaPraiseDegrade.yaml', 'zh_common_FEPU.yaml', 'en_common_ANEW.yaml', 'en_common_NRC.yaml', 'zh_valence_ChineseEmoBank.yaml', 'zh_valence_SixSemanticDimensionDatabase.yaml', 'zh_common_FinacialFormalUnformal.yaml', 'zh_common_LoughranMcDonald.yaml', 'enzh_common_AdvConj.yaml', 'en_common_SentiWS.yaml', 'zh_common_Digitalization.yaml', 'en_common_LSD2015.yaml', 'zh_common_HowNet.yaml', 'zh_common_EPU.yaml'] 1.2 å†…ç½® yaml è¯å…¸    pkl æ–‡ä»¶ è¯å…¸ è¯­è¨€ åŠŸèƒ½     zh_valence_ChineseEmoBank.yaml ä¸­æ–‡æƒ…æ„Ÿè¯å…¸ï¼Œå«æ•ˆä»·valenceå’Œå”¤é†’åº¦arousalã€‚åœ¨ cntext ä¸­ï¼Œæˆ‘ä»¬åªä½¿ç”¨äº† CVAW è¯è¡¨(å•è¯)ï¼Œå…¶ä»–è¯å…¸å¦‚ CVAP, CVAS, CVAT æ²¡æœ‰çº³å…¥åˆ° ChineseEmoBank.pkl. Chinese æ•ˆä»·valenceå’Œå”¤é†’åº¦arousal   zh_common_DUTIR.yaml å¤§è¿ç†å·¥å¤§å­¦æƒ…æ„Ÿæœ¬ä½“åº“ ä¸­æ–‡ ä¸ƒå¤§ç±»æƒ…ç»ªï¼Œå“€, å¥½, æƒŠ, æƒ§, ä¹, æ€’, æ¶   zh_common_HowNet.yaml çŸ¥ç½‘ Hownet è¯å…¸ ä¸­æ–‡ æ­£é¢è¯ã€è´Ÿé¢è¯   en_common_SentiWS.yaml SentimentWortschatz (SentiWS) å¾·æ–‡ æ­£é¢è¯ã€è´Ÿé¢è¯ï¼›\n   zh_common_FinacialFormalUnformal.yaml é‡‘èé¢†åŸŸæ­£å¼ã€éæ­£å¼ï¼›ç§¯ææ¶ˆæ ä¸­æ–‡ formal-posã€\nformal-negï¼›\nunformal-posã€\nunformal-neg   en_common_ANEW.yaml è‹±è¯­å•è¯çš„æƒ…æ„Ÿè§„èŒƒ Affective Norms for English Words (ANEW) è‹±æ–‡ pleasure, arousal, dominance   en_common_LSD2015.yaml Lexicoder Sentiment Dictionary (2015) è‹±æ–‡ æ­£é¢è¯ã€è´Ÿé¢è¯   en_common_NRC.yaml NRC Word-Emotion Association Lexicon è‹±æ–‡ ç»†ç²’åº¦æƒ…ç»ªè¯ï¼›   zh_valence_SixSemanticDimensionDatabase.yaml é€šç”¨ä¸­è‹±æ–‡å…­ç»´è¯­ä¹‰æƒ…æ„Ÿè¯å…¸, å« 17940 ä¸ªä¸­æ–‡è¯çš„å…­ç»´åº¦è¯åº“ï¼Œ ä¸”æ¯ä¸ªç»´åº¦æœ‰æƒé‡ã€‚ ä¸­æ–‡ visionã€socialnessã€emotionã€timeã€spaceã€motor   enzh_common_AdvConj.yaml å‰¯è¯è¿è¯ ä¸­ã€è‹±    enzh_common_StopWords.yaml ä¸­è‹±æ–‡åœç”¨è¯ ä¸­ã€è‹± åœç”¨è¯   en_valence_Concreteness.yaml è‹±æ–‡å…·ä½“æ€§è¯å…¸ English word \u0026 concreateness score   zh_common_LoughranMcDonald.yaml ä¸­æ–‡ LoughranMcDonald è¯å…¸ ä¸­æ–‡ æ­£é¢ã€è´Ÿé¢è¯   zh_common_Digitalization.yaml ç®¡ç†ä¸–ç•Œ|å´é(2021)æ•°å­—åŒ–è¯å…¸ ä¸­æ–‡ å«äººå·¥æ™ºèƒ½æŠ€æœ¯ã€å¤§æ•°æ®æŠ€æœ¯ã€äº‘è®¡ç®—æŠ€æœ¯ã€åŒºå—é“¾æŠ€æœ¯ã€æ•°å­—æŠ€æœ¯åº”ç”¨ç­‰å…³é”®è¯åˆ—è¡¨ã€‚   en_common_LoughranMcDonald.yaml è‹±æ–‡ LoughranMcDonald è¯å…¸ è‹±æ–‡ é‡‘è LM æƒ…ç»ªè¯å…¸ 2018 å¹´ç‰ˆæœ¬ï¼Œå«ä¸ƒä¸ªè¯è¡¨ï¼Œåˆ†åˆ«æ˜¯ Negative, Positive, Uncertainty, Litigious, StrongModal, WeakModal, Constraining   zh_common_FLS.yaml ä¸šç»©è¯´æ˜ä¼šå‰ç»æ€§è¯å…¸é›† ä¸­æ–‡ å« 174 ä¸ªè¯è¯­   zh_common_RhetoricalNationalism.yaml ä¿®è¾æ°‘æ—ä¸»ä¹‰ ä¸­æ–‡ å«å››ä¸ªç»´åº¦ï¼Œæ°‘æ—è‡ªè±ªæ„Ÿã€æ°‘æ—å¤å…´ã€ä¼ä¸šè§’è‰²ã€æ’å¤–ä¸»ä¹‰ï¼Œæ¯ä¸ªç»´åº¦ 100 ä¸ªè¯ã€‚    1.3 read_dict_yaml() ä½¿ç”¨ cntext è¯»å– .yaml è¯å…¸æ–‡ä»¶ï¼› è¿”å›çš„ä¿¡æ¯åŒ…æ‹¬\n Name è¯å…¸çš„åå­— Desc è¯å…¸çš„å«ä¹‰ã€æ¦‚å¿µè§£é‡Š Refer è¯å…¸æ–‡çŒ®å‡ºå¤„ Category è¯å…¸ Dictionary çš„å…³é”®è¯ Dictionary è¯å…¸, python å­—å…¸æ ¼å¼  import cntext as ct print(ct.read_yaml_dict('zh_common_Digitalization.yaml')) Run\n{'Name': 'ä¸­æ–‡æ•°å­—åŒ–è¯å…¸', 'Desc': 'åŸºäºè¿™ç¯‡è®ºæ–‡ï¼Œæ„å»ºäº†ä¸­æ–‡æ•°å­—åŒ–è¯å…¸ï¼Œå«äººå·¥æ™ºèƒ½æŠ€æœ¯ã€å¤§æ•°æ®æŠ€æœ¯ã€äº‘è®¡ç®—æŠ€æœ¯ã€åŒºå—é“¾æŠ€æœ¯ã€æ•°å­—æŠ€æœ¯åº”ç”¨ç­‰å…³é”®è¯åˆ—è¡¨ã€‚ ', 'Refer': 'å´é,èƒ¡æ…§èŠ·,æ—æ…§å¦,ä»»æ™“æ€¡. ä¼ä¸šæ•°å­—åŒ–è½¬å‹ä¸èµ„æœ¬å¸‚åœºè¡¨ç°â€”â€”æ¥è‡ªè‚¡ç¥¨æµåŠ¨æ€§çš„ç»éªŒè¯æ®[J]. ç®¡ç†ä¸–ç•Œ,2021,37(07):130-144+10.', 'Category': ['Artificial_Intelligence', 'Big_Data', 'Cloud_Computing', 'Block_Chains', 'Usage_of_Digitalization'], 'Dictionary': {'Artificial_Intelligence': ['äººå·¥æ™ºèƒ½', 'å•†ä¸šæ™ºèƒ½', 'å›¾åƒç†è§£', 'æŠ•èµ„å†³ç­–è¾…åŠ©ç³»ç»Ÿ', 'æ™ºèƒ½æ•°æ®åˆ†æ', 'æ™ºèƒ½æœºå™¨äºº', 'æœºå™¨å­¦ä¹ ', 'æ·±åº¦å­¦ä¹ ', 'è¯­ä¹‰æœç´¢', 'ç”Ÿç‰©è¯†åˆ«æŠ€æœ¯', 'äººè„¸è¯†åˆ«', 'è¯­éŸ³è¯†åˆ«', 'èº«ä»½éªŒè¯', 'è‡ªåŠ¨é©¾é©¶', 'è‡ªç„¶è¯­è¨€å¤„ç†'], 'Big_Data': ['å¤§æ•°æ®', 'æ•°æ®æŒ–æ˜', 'æ–‡æœ¬æŒ–æ˜', 'æ•°æ®å¯è§†åŒ–', 'å¼‚æ„æ•°æ®', 'å¾ä¿¡', 'å¢å¼ºç°å®', 'æ··åˆç°å®', 'è™šæ‹Ÿç°å®'], 'Cloud_Computing': ['äº‘è®¡ç®—', 'æµè®¡ç®—', 'å›¾è®¡ç®—', 'å†…å­˜è®¡ç®—', 'å¤šæ–¹å®‰å…¨è®¡ç®—', 'ç±»è„‘è®¡ç®—', 'ç»¿è‰²è®¡ç®—', 'è®¤çŸ¥è®¡ç®—', 'èåˆæ¶æ„', 'äº¿çº§å¹¶å‘', 'EBçº§å­˜å‚¨', 'ç‰©è”ç½‘', 'ä¿¡æ¯ç‰©ç†ç³»ç»Ÿ'], 'Block_Chains': ['åŒºå—é“¾', 'æ•°å­—è´§å¸', 'åˆ†å¸ƒå¼è®¡ç®—', 'å·®åˆ†éšç§æŠ€æœ¯', 'æ™ºèƒ½é‡‘èåˆçº¦'], 'Usage_of_Digitalization': ['ç§»åŠ¨äº’è”ç½‘', 'å·¥ä¸šäº’è”ç½‘', 'ç§»åŠ¨äº’è”', 'äº’è”ç½‘åŒ»ç–—', 'ç”µå­å•†åŠ¡', 'ç§»åŠ¨æ”¯ä»˜', 'ç¬¬ä¸‰æ–¹æ”¯ä»˜', 'NFCæ”¯ä»˜', 'æ™ºèƒ½èƒ½æº', 'B2B', 'B2C', 'C2B', 'C2C', 'O2O', 'ç½‘è”', 'æ™ºèƒ½ç©¿æˆ´', 'æ™ºæ…§å†œä¸š', 'æ™ºèƒ½äº¤é€š', 'æ™ºèƒ½åŒ»ç–—', 'æ™ºèƒ½å®¢æœ', 'æ™ºèƒ½å®¶å±…', 'æ™ºèƒ½æŠ•é¡¾', 'æ™ºèƒ½æ–‡æ—…', 'æ™ºèƒ½ç¯ä¿', 'æ™ºèƒ½ç”µç½‘', 'æ™ºèƒ½è¥é”€', 'æ•°å­—è¥é”€', 'æ— äººé›¶å”®', 'äº’è”ç½‘é‡‘è', 'æ•°å­—é‡‘è', 'Fintech', 'é‡‘èç§‘æŠ€', 'é‡åŒ–é‡‘è', 'å¼€æ”¾é“¶è¡Œ']}} \n1.4 detect_encoding() ct.detect_encoding(file) é€šè¿‡è¯»å–å‰ num_lines æ¥è¯†åˆ« txt/csv æ–‡ä»¶çš„ç¼–ç æ ¼å¼\n file æ–‡ä»¶è·¯å¾„  import cntext as ct #è¯»å–dataæ–‡ä»¶å¤¹ä¸‹çš„ã€ä¸‰ä½“.txtã€‘ #è¯†åˆ«ç¼–ç æ–¹å¼ ct.detect_encoding(file='data/ä¸‰ä½“.txt') Run\nutf-8 \n1.5 get_files(fformat)  fformat fformat æ ¼å¼æ”¯æŒ txt/pdf/docx/xlsx/csv ç­‰ã€‚ *è¡¨ç¤ºé€šé…ç¬¦  æŸ¥çœ‹ç¬¦åˆ fformat è·¯å¾„è§„åˆ™çš„æ‰€æœ‰çš„æ–‡ä»¶ï¼Œ fformat æ ¼å¼æ”¯æŒ txt/pdf/docx/xlsx/csv ç­‰ã€‚ *è¡¨ç¤ºé€šé…ç¬¦\n   fformat æ ¼å¼ è¯†åˆ«çš„æ–‡ä»¶     *.txt åŒ¹é…å½“å‰ä»£ç æ‰€åœ¨è·¯å¾„å†…çš„æ‰€æœ‰ txt   *.pdf åŒ¹é…å½“å‰ä»£ç æ‰€åœ¨è·¯å¾„å†…çš„æ‰€æœ‰ pdf   data/*.txt åŒ¹é…ã€Œæ–‡ä»¶å¤¹ dataã€å†…æ‰€æœ‰çš„ txt   \n     #æŸ¥çœ‹ã€æ–‡ä»¶å¤¹dataã€‘å†…æ‰€æœ‰çš„ txtæ–‡ä»¶ã€‚ ct.get_files(fformat='data/*.txt') Run\n['data/ä¸‰ä½“.txt', 'data/santi.txt', 'data/w2v_corpus.txt', 'data/sopmi_corpus.txt', 'data/brown_corpus.txt', 'data/sopmi_seed_words.txt'] \n1.6 read_pdf è¯»å– PDFï¼Œè¿”å›æ–‡æœ¬å†…å®¹\nct.read_pdf(file)  file PDF æ–‡ä»¶è·¯å¾„  ç‚¹å‡» æ ¼åŠ›ç”µå™¨ 2023.pdf\nimport cntext as ct text = ct.read_pdf('æ ¼åŠ›ç”µå™¨2023.pdf') print(text) Run\nç æµ·æ ¼åŠ›ç”µå™¨è‚¡ä»½æœ‰é™å…¬å¸ 2023å¹´å¹´åº¦æŠ¥å‘Šå…¨æ–‡ ç æµ·æ ¼åŠ›ç”µå™¨è‚¡ä»½æœ‰é™å…¬å¸ 2023å¹´å¹´åº¦æŠ¥å‘Š äºŒã€‡äºŒå››å¹´å››æœˆ ç æµ·æ ¼åŠ›ç”µå™¨è‚¡ä»½æœ‰é™å…¬å¸ 2023å¹´å¹´åº¦æŠ¥å‘Šå…¨æ–‡ ç¬¬ 2 é¡µ å…± 249 é¡µ ç¬¬ä¸€èŠ‚ é‡è¦æç¤ºã€ç›®å½•å’Œé‡Šä¹‰ å…¬å¸è‘£äº‹ä¼šã€ç›‘äº‹ä¼šåŠè‘£äº‹ã€ç›‘äº‹ã€é«˜çº§ç®¡ç†äººå‘˜ä¿è¯å¹´åº¦æŠ¥å‘Šå†…å®¹ çš„çœŸå®ã€å‡†ç¡®ã€å®Œæ•´ï¼Œä¸å­˜åœ¨è™šå‡è®°è½½ã€è¯¯å¯¼æ€§é™ˆè¿°æˆ–é‡å¤§é—æ¼ï¼Œå¹¶æ‰¿æ‹… ä¸ªåˆ«å’Œè¿å¸¦çš„æ³•å¾‹ ...... \n1.7 read_docx è¯»å– docxï¼Œè¿”å›æ–‡æœ¬å†…å®¹\nct.read_docx(file)  file docx æ–‡ä»¶è·¯å¾„  import cntext as ct text = ct.read_docx('test.docx') text Run\nè¿™æ˜¯æ¥è‡ªtest.docxé‡Œå†…å®¹ \n1.8 read_file() ct.read_file(file, encoding='utf-8')  file å¾…è¯»å–çš„æ–‡ä»¶è·¯å¾„ï¼› æ”¯æŒ txtã€pdfã€docxã€xlsxã€xlsï¼Œ è¿”å› DataFrame(å« doc å’Œ file ä¸¤ä¸ªå­—æ®µ)ã€‚ encoding å¾…è¯»å–æ–‡ä»¶çš„ç¼–ç æ–¹å¼  ä»¥ data/ä¸‰ä½“.txt ä¸ºä¾‹\nimport cntext as ct #é»˜è®¤encoding='utf-8' #sdf = ct.read_file(file='data/ä¸‰ä½“.txt') sdf = ct.read_file(file='data/ä¸‰ä½“.txt', encoding='utf-8') sdf 1.9 read_files() ct.read_files(fformat, encoding='utf-8'ï¼‰ æ‰¹é‡è¯»å–ç¬¦åˆ fformat æ ¼å¼çš„æ‰€æœ‰æ–‡ä»¶æ•°æ®ï¼Œè¿”å› DataFrame(å« doc å’Œ file ä¸¤ä¸ªå­—æ®µ)ã€‚\nè¯»å–[æ–‡ä»¶å¤¹ data é‡Œæ‰€æœ‰ txt]\nimport cntext as ct #é»˜è®¤encoding='utf-8' #ddf = ct.read_files(fformat='data/*.txt') ddf = ct.read_files(fformat='data/*.txt', encoding='utf-8') ddf 1.10 extract_mda æå– A è‚¡å¹´æŠ¥ä¸­çš„ MD\u0026A æ–‡æœ¬å†…å®¹ã€‚å¦‚æœè¿”å›'',åˆ™æå–å¤±è´¥ã€‚\nct.extract_mda(text, kws_pattern='')  text ä¸­å›½ A è‚¡å¹´æŠ¥åŸå§‹æ–‡æœ¬ kws_pattern ç®¡ç†å±‚è®¨è®ºä¸åˆ†æç« èŠ‚è¯†åˆ«å…³é”®è¯çš„æ¨¡æ¿ã€‚cntext å†…ç½®çš„ kws_pattern å†…å®¹å¦‚ä¸‹  kws_pattern = 'è‘£äº‹ä¼šæŠ¥å‘Š|è‘£äº‹ä¼šæŠ¥å‘Šä¸ç®¡ç†è®¨è®º|ä¼ä¸šè¿è¥ä¸ç®¡ç†è¯„è¿°|ç»è¥æ€»ç»“ä¸åˆ†æ|ç®¡ç†å±‚è¯„ä¼°ä¸æœªæ¥å±•æœ›|è‘£äº‹å±€æŠ¥å‘Š|ç®¡ç†å±‚è®¨è®ºä¸åˆ†æ|ç»è¥æƒ…å†µè®¨è®ºä¸åˆ†æ|ç»è¥ä¸šç»©åˆ†æ|ä¸šåŠ¡å›é¡¾ä¸å±•æœ›|å…¬å¸ç»è¥åˆ†æ|ç®¡ç†å±‚è¯„è®ºä¸åˆ†æ|æ‰§è¡Œæ‘˜è¦ä¸ä¸šåŠ¡å›é¡¾|ä¸šåŠ¡è¿è¥åˆ†æ' \nimport cntext as ct text = ct.read_pdf('æ ¼åŠ›ç”µå™¨2023.pdf') mda_text = ct.extract_mda(text) print(mda_text) Run\n'ç®¡ç†å±‚è®¨è®ºä¸åˆ†æ \\nä¸€ã€æŠ¥å‘ŠæœŸå†…å…¬å¸æ‰€å¤„è¡Œä¸šæƒ…å†µ \\nï¼ˆä¸€ï¼‰è¡Œä¸šå‘å±•ç°çŠ¶ \\n1.æ¶ˆè´¹é¢†åŸŸ â€”â€”å®¶ç”µè¡Œä¸šç¨³å®šå¢é•¿ï¼Œç©ºè°ƒå¸‚åœºæ¢å¤æ˜æ˜¾ \\n2023å¹´ï¼Œä¸­å›½ç»æµä¿æŒäº†æ•´ä½“æ¢å¤å‘å¥½çš„æ€åŠ¿ï¼Œæ¿€å‘æ¶ˆè´¹æ˜¯ç¨³å¢é•¿çš„é‡ä¸­ä¹‹é‡ã€‚å›½å®¶é¼“åŠ±å’Œæ¨åŠ¨æ¶ˆè´¹å“ä»¥æ—§æ¢\\næ–°ï¼Œä¿ƒè¿›æ¶ˆè´¹ç»æµå¤§å¾ªç¯ï¼ŒåŠ é€Ÿæ›´æ–°éœ€æ±‚é‡Šæ”¾ï¼Œæ¨åŠ¨é«˜èƒ½æ•ˆäº§å“è®¾å¤‡é”€å”®å’Œå‡ºå£å¢é•¿ï¼Œè¿›ä¸€æ­¥æ¿€å‘ç»¿è‰²æ¶ˆè´¹æ½œåŠ›ã€‚ \\n1ï¼‰å®¶ç”µè¡Œä¸šç¨³å®šå¢é•¿ \\n2023å¹´ï¼Œå›½å†…ç»æµæ¢å¤æ˜æ˜¾ï¼Œå®¶ç”µè¡Œä¸šç¨³å®šå¢é•¿ã€‚æ ¹æ®å…¨å›½å®¶ç”¨ç”µå™¨å·¥ä¸šä¿¡æ¯ä¸­å¿ƒå‘å¸ƒçš„ã€Š 2023å¹´ä¸­å›½å®¶ç”µ\\nè¡Œä¸šå¹´åº¦æŠ¥å‘Šã€‹ï¼Œå®¶ç”µè¡Œä¸šå¤–é”€æ˜æ˜¾å¢é•¿ï¼Œå‡ºå£è§„æ¨¡ä¸º 6,174äº¿å…ƒï¼ŒåŒæ¯”å¢é•¿ 9.9%ï¼›å›½å†…å¸‚åœºå®ç°ç¨³æ­¥å¢é•¿ï¼Œé”€å”®\\nè§„æ¨¡ä¸º7' ....... ....... \nä»¥2001 å¹´~2023 ä¼šè®¡å¹´åº¦æŠ¥å‘Šæ•°æ®é›†ä¸ºä¾‹ï¼Œ æŸ¥çœ‹ extract_mda çš„æŠ½å– mda çš„èƒ½åŠ›ã€‚\nimport glob import cntext as ct print('extract_mdaè¯†åˆ«èƒ½åŠ›') for year in range(2001, 2024): num = 0 for file in glob.glob(f'å¹´æŠ¥txt/{year}/*.txt'): mda_text = ct.extract_mda(open(file).read()) if mda_text!='': num = num + 1 volume = len(glob.glob(f'å¹´æŠ¥txt/{year}/*.txt')) ratio = num/volume print(f'{year}: {ratio:.2f}') Run\n2001: 0.24 2002: 0.37 2003: 0.43 2004: 0.70 2005: 0.77 2006: 0.78 2007: 0.79 2008: 0.77 2009: 0.79 2010: 0.82 2011: 0.84 2012: 0.96 2013: 0.95 2014: 0.98 2015: 0.98 2016: 0.99 2017: 0.98 2018: 0.98 2019: 0.99 2020: 0.97 2021: 0.98 2022: 0.99 2023: 0.99 å»ºè®®å„ä½ç”¨æœ€è¿‘ 10 å¹´çš„å¹´æŠ¥æ•°æ®ï¼Œé€šè¿‡ extract_mda æå– mda æ–‡æœ¬ï¼Œæˆ–è€…ç›´æ¥è´­ä¹° [æ•°æ®é›† | 2001-2023 å¹´ A è‚¡ä¸Šå¸‚å…¬å¸å¹´æŠ¥\u0026ç®¡ç†å±‚è®¨è®ºä¸åˆ†æ](æ•°æ®é›† | 2001-2023 å¹´ A è‚¡ä¸Šå¸‚å…¬å¸å¹´æŠ¥\u0026ç®¡ç†å±‚è®¨è®ºä¸åˆ†æ)\n1.11 traditional2simple() ç¹ä½“è½¬ç®€ä½“\nct.traditional2simple(text, mode='t2s')  text å¾…è½¬æ¢çš„æ–‡æœ¬ mode è½¬æ¢æ¨¡å¼ï¼Œ é»˜è®¤ mode=â€˜t2sâ€™ç¹è½¬ç®€; mode è¿˜æ”¯æŒ s2t  import cntext as ct text = 'ç°¡é«”æ¼¢å­—' ct.traditional2simple(text) Run\n'ç®€ä½“æ±‰å­—' \ntext = 'ç®€ä½“æ±‰å­—' ct.traditional2simple(text, mode='s2t') Run\n'ç°¡é«”æ¼¢å­—' \n1.12 fix_text() å°†ä¸æ­£å¸¸çš„ã€æ··ä¹±ç¼–ç çš„æ–‡æœ¬è½¬åŒ–ä¸ºæ­£å¸¸çš„æ–‡æœ¬ã€‚ä¾‹å¦‚å…¨è§’è½¬åŠè§’\nimport cntext as ct raw_text = 'ä»Šæ—¥èµ·å¯ä¸­é‡åˆ°æŠ€æœ¯é—®é¢˜ï¼Œå¯ä»¥æ‹¨æ‰“ç”µè¯ï¼ï¼“ï¼—ï¼‘ï¼ï¼–ï¼–ï¼“ï¼’ï¼‘ï¼™ï¼™ï¼‘ã€ï¼–ï¼–ï¼“ï¼’ï¼‘ï¼™ï¼—ï¼“å’¨è¯¢ã€‚' text = ct.fix_text(raw_text) text Run\nä»Šæ—¥èµ·å¯ä¸­é‡åˆ°æŠ€æœ¯é—®é¢˜ï¼Œå¯ä»¥æ‹¨æ‰“ç”µè¯0371-66321991ã€66321973å’¨è¯¢ã€‚ \n1.13 fix_contractions(text) å°†è‹±æ–‡ç¼©å†™(å«ä¿šè¯­è¡¨è¾¾)è½¬åŒ–ä¸ºå®Œæ•´çš„è¡¨è¾¾ï¼Œå¦‚å¦‚\n- you're - you are - yall - you all - gotta - got to ... \nimport cntext as ct raw_text = \"yall're happy now\" text = ct.fix_contractions(raw_text) text Run\n\"you all are happy now\" \n1.14 clean_text(text) ct.clean_text(text, lang='chinese')  text å¾…å¤„ç†çš„æ–‡æœ¬ lang è¯­è¨€ç±»å‹ï¼Œ é»˜è®¤ lang=â€˜chineseâ€™, æ”¯æŒ\"english\"ã€â€œchineseâ€  import cntext as ct chinese_text = (\"ä»Šå¤©çš„è®­ç»ƒå¾ˆæ£’ï¼è·‘äº†5.6å…¬é‡Œï¼Œå¿ƒç‡ç¨³å®šã€‚\" \"æŸ¥çœ‹ https://example.com/data ğŸ˜Š #å¥èº«æ‰“å¡\") print(\" ä¸­æ–‡æ¸…æ´—\") print(\"åŸå§‹:\", repr(chinese_text)) print(\"æ¸…æ´—:\", repr(ct.clean_text(chinese_text, lang=\"chinese\"))) print() # è‹±æ–‡æµ‹è¯• english_text = (\"Great workout today! Ran 5.6 miles, HR stable. \" \"Check https://example.com/data ğŸ˜Š #Fitness\") print(\" è‹±æ–‡æ¸…æ´—\") print(\"åŸå§‹:\", repr(english_text)) print(\"æ¸…æ´—:\", repr(ct.clean_text(english_text, lang=\"english\"))) Run\n ä¸­æ–‡æ¸…æ´— åŸå§‹: 'ä»Šå¤©çš„è®­ç»ƒå¾ˆæ£’ï¼è·‘äº†5.6å…¬é‡Œï¼Œå¿ƒç‡ç¨³å®šã€‚æŸ¥çœ‹ https://example.com/data ğŸ˜Š #å¥èº«æ‰“å¡' æ¸…æ´—: 'ä»Šå¤©çš„è®­ç»ƒå¾ˆæ£’ï¼è·‘äº†æ•°å­—å…¬é‡Œï¼Œå¿ƒç‡ç¨³å®šã€‚æŸ¥çœ‹ å¥èº«æ‰“å¡'  è‹±æ–‡æ¸…æ´— åŸå§‹: 'Great workout today! Ran 5.6 miles, HR stable. Check https://example.com/data ğŸ˜Š #Fitness' æ¸…æ´—: 'great workout today! ran NUMBER miles, hr stable. check ğŸ˜Š #fitness' \näºŒã€Stats æ¨¡å—    æ¨¡å— å‡½æ•° åŠŸèƒ½     stats ct.word_count(text, lang='chinese') è¯é¢‘ç»Ÿè®¡   stats ct.readability(text, lang='chinese') æ–‡æœ¬å¯è¯»æ€§   stats ct.sentiment(text, diction, lang=â€˜chineseâ€™) æ— (ç­‰)æƒé‡è¯å…¸çš„æƒ…æ„Ÿåˆ†æ   stats ct.sentiment_by_valence(text, diction, lang='chinese') å¸¦æƒé‡çš„è¯å…¸çš„æƒ…æ„Ÿåˆ†æ   stats ct.word_in_context(text, keywords, window=3, lang=â€˜chineseâ€™) åœ¨ text ä¸­æŸ¥æ‰¾ keywords å‡ºç°çš„ä¸Šä¸‹æ–‡å†…å®¹(çª—å£ window)ï¼Œè¿”å› df   stats ct.epu(text, e_pattern, p_pattern, u_pattern) ä½¿ç”¨æ–°é—»æ–‡æœ¬æ•°æ®è®¡ç®—ç»æµæ”¿ç­–ä¸ç¡®å®šæ€§ EPUï¼Œè¿”å› df   stats ct.fepu(text, ep_pattern='â€™, u_pattern='') ä½¿ç”¨ md\u0026a æ–‡æœ¬æ•°æ®è®¡ç®—ä¼ä¸šä¸ç¡®å®šæ€§æ„ŸçŸ¥ FEPU   stats ct.semantic_brand_score(text, brands, lang=â€˜chineseâ€™) è¡¡é‡å“ç‰Œï¼ˆä¸ªä½“ã€å…¬å¸ã€å“ç‰Œã€å…³é”®è¯ç­‰ï¼‰çš„é‡è¦æ€§   stats ct.cosine_sim(text1, text2, lang=â€˜chineseâ€™) ä½™å¼¦ç›¸ä¼¼åº¦   stats ct.jaccard_sim(text1, text2, lang='chinese') Jaccard ç›¸ä¼¼åº¦   stats ct.minedit_sim(text1, text2, lang='chinese') æœ€å°ç¼–è¾‘è·ç¦»   stats ct.word_hhi(text) æ–‡æœ¬çš„èµ«èŠ¬è¾¾å°”-èµ«å¸Œæ›¼æŒ‡æ•°    2.1 word_count() ç»Ÿè®¡è¯é¢‘ï¼Œ è¿”å› Counter(ç±»ä¼¼äº python å­—å…¸) ï¼› æ”¯æŒä¸­è‹±æ–‡\nct.word_count(text, lang='chinese', return_df=False)  text å¾…åˆ†æçš„æ–‡æœ¬å­—ç¬¦ä¸² lang æ–‡æœ¬çš„è¯­è¨€ç±»å‹ï¼Œ ä¸­æ–‡ chineseã€è‹±æ–‡ englishï¼Œé»˜è®¤ä¸­æ–‡ã€‚ return_df è¿”å›ç»“æœæ˜¯å¦ä¸º dataframeï¼Œé»˜è®¤ False  import cntext as ct text = 'è‡´åŠ›äºè‡´åŠ›äºä»¥é›¶æ–‡ç« å¤„ç†è´¹æˆ–è®¢é˜…è´¹å‘å¸ƒä¼˜è´¨ç ”ç©¶è½¯ä»¶ã€‚' #ct.word_count(text, lang='chinese') ct.word_count(text) Run\nCounter({'è‡´åŠ›äº': 2, 'æ–‡ç« ': 1, 'å¤„ç†è´¹': 1, 'è®¢é˜…è´¹': 1, 'å‘å¸ƒ': 1, 'ä¼˜è´¨': 1, 'ç ”ç©¶': 1, 'è½¯ä»¶': 1}) \nct.word_count(text, return_df=True) 2.2 readability() ct.readability(text, lang='chinese', syllables=3, return_series=False) è®¡ç®—æ–‡æœ¬å¯è¯»æ€§å¸¸è§æŒ‡æ ‡ï¼› å« Gunning Fog Indexã€ SMOG Indexã€Coleman Liau Indexã€ Automated Readability Index(ARI)ã€Readability Index(Rix)ï¼› æŒ‡æ ‡è¶Šå¤§ï¼Œå¤æ‚åº¦è¶Šé«˜ï¼Œæ–‡æœ¬çš„å¯è¯»æ€§è¶Šå·®ã€‚\n text å¾…åˆ†æçš„æ–‡æœ¬å­—ç¬¦ä¸² lang æ–‡æœ¬çš„è¯­è¨€ç±»å‹ï¼Œ ä¸­æ–‡ chineseã€è‹±æ–‡ englishï¼Œé»˜è®¤ä¸­æ–‡ã€‚ syllables éŸ³èŠ‚æ•°(æ±‰å­—æ•°)å¤§äºç­‰äº syllables ä¸ºå¤æ‚è¯. é»˜è®¤å€¼ä¸º 3 return_series: è®¡ç®—ç»“æœæ˜¯å¦è¾“å‡ºä¸º pd.Series ç±»å‹ï¼Œé»˜è®¤ä¸º False  Gunning Fog Index = 0.4 * (Total_Words/Total_Sentences + 100 * Complex_Words/Total_Words) SMOG Index = 1.0430 * sqrt(Complex_Words/Total_Sentences) * 30 + 3.1291 Coleman-Liau Index = 0.0588 * (100*Total_Letters/Total_Words) -0.296*(100*Total_Sentences/Total_Words) - 15.8 Automated Readability Index(ARI) = 4.71 * (Total_Characters/Total_Words) + 0.5*(Total_Words/Total_Sentences) - 21.43 Readability Index(RIX) = Complex_Words * (6 + Total_characters) / Total_Sentences \nimport cntext as ct text = 'è‡´åŠ›äºä»¥é›¶æ–‡ç« å¤„ç†è´¹æˆ–è®¢é˜…è´¹å‘å¸ƒä¼˜è´¨ç ”ç©¶è½¯ä»¶ã€‚' ct.readability(text, lang='chinese', syllables=3) Run\n{'fog_index': 120.4, 'flesch_kincaid_grade_level': 20.2, 'smog_index': 57.32, 'coleman_liau_index': 83.96, 'ari': 87.4, 'rix': 87.0} \n2.3 sentiment(text, diction, lang) å¸¸è§çš„æƒ…æ„Ÿåˆ†æé»˜è®¤æƒ…ç»ªè¯æ— (ç­‰)æƒé‡ï¼Œ é€šè¿‡ç»Ÿè®¡è¯è¯­ä¸ªæ•°æ¥ååº”æƒ…æ„Ÿä¿¡æ¯ã€‚\nsentiment(text, diction, lang='chinese', return_series=False)  text å¾…åˆ†æçš„æ–‡æœ¬å­—ç¬¦ä¸² diction æ ¼å¼ä¸º Python å­—å…¸ç±»å‹ã€‚å½¢å¦‚ä¸‹é¢çš„æ¡ˆä¾‹ lang æ–‡æœ¬çš„è¯­è¨€ç±»å‹ï¼Œ ä¸­æ–‡ chineseã€è‹±æ–‡ englishï¼Œé»˜è®¤ä¸­æ–‡ã€‚ return_series è®¡ç®—ç»“æœæ˜¯å¦è¾“å‡ºä¸º pd.Series ç±»å‹ï¼Œé»˜è®¤ä¸º False  import cntext as ct diction = {'pos': ['é«˜å…´', 'å¿«ä¹', 'åˆ†äº«'], 'neg': ['éš¾è¿‡', 'æ‚²ä¼¤'], 'adv': ['å¾ˆ', 'ç‰¹åˆ«']} text = 'æˆ‘ä»Šå¤©å¾—å¥–äº†ï¼Œå¾ˆé«˜å…´ï¼Œæˆ‘è¦å°†å¿«ä¹åˆ†äº«å¤§å®¶ã€‚' ct.sentiment(text=text, diction=diction, lang='chinese') Run\n{'pos_num': 3, 'neg_num': 0, 'adv_num': 1, 'stopword_num': 8, 'word_num': 14, 'sentence_num': 1} \n2.4 sentiment_by_valence() ct.sentiment_by_valence(text, diction, lang='chinese', return_series=False)  text å¾…åˆ†æçš„æ–‡æœ¬å­—ç¬¦ä¸² diction æ ¼å¼ä¸º Python å­—å…¸ç±»å‹ã€‚å½¢å¦‚ä¸‹é¢çš„æ¡ˆä¾‹ lang æ–‡æœ¬çš„è¯­è¨€ç±»å‹ï¼Œ ä¸­æ–‡ chineseã€è‹±æ–‡ englishï¼Œé»˜è®¤ä¸­æ–‡ã€‚ return_series è®¡ç®—ç»“æœæ˜¯å¦è¾“å‡ºä¸º pd.Series ç±»å‹ï¼Œé»˜è®¤ä¸º False  å¸¸è§çš„æƒ…æ„Ÿåˆ†ææ˜¯æ— (ç­‰)æƒé‡, ä½†å®é™…ä¸Šä¸åŒçš„è¯è¯­æ‰€æºå¸¦çš„æƒ…æ„Ÿä¿¡æ¯çš„å¼ºåº¦å·®å¼‚æ˜¯å¾ˆå¤§çš„ã€‚æ®æ­¤å­¦è€…ä»¬å¼€å‘å‡ºå¾ˆå¤šå¸¦æƒé‡çš„è¯å…¸ï¼Œä¾‹å¦‚\n è‹±æ–‡å…·ä½“æ€§è¯å…¸ en_valence_Concreteness.yamlï¼Œ è¯å…¸ä¸­æ¯ä¸ªè¯éƒ½æœ‰ä¸€ä¸ª concreteness å€¼ ä¸­æ–‡å…­ç»´åº¦è¯­ä¹‰è¯å…¸ zh_valence_SixSemanticDimensionDatabase.yaml, æ¯ä¸ªä¸­æ–‡è¯æœ‰å…­ä¸ªå€¼ã€‚  ä»¥å…·ä½“æ€§ä¸ºä¾‹ï¼Œ è¯­è¨€å…·ä½“æ€§ Concretenessæè¿°äº†ä¸€ä¸ªè¯åœ¨å¤šå¤§ç¨‹åº¦ä¸Šæ˜¯æŒ‡ä¸€ä¸ªå®é™…çš„ã€æœ‰å½¢çš„æˆ–â€œçœŸå®çš„â€å®ä½“ï¼Œä»¥ä¸€ç§æ›´å…·ä½“ã€æ›´ç†Ÿæ‚‰ã€æ›´å®¹æ˜“è¢«çœ¼ç›æˆ–å¿ƒçµæ„ŸçŸ¥çš„æ–¹å¼æè¿°å¯¹è±¡å’Œè¡Œä¸ºï¼ˆå³ï¼Œå¯æƒ³è±¡æˆ–ç”ŸåŠ¨ï¼›Brysbaert, Warriner, and Kuperman 2014; Semin and Fiedler 1988)\nimport cntext as ct import pandas as pd concreteness_dict = ct.read_yaml_dict('en_valence_Concreteness.yaml')['Dictionary'] concreteness_dict Run\n{'roadsweeper': {'concreteness': 4.85}, 'traindriver': {'concreteness': 4.54}, 'tush': {'concreteness': 4.45}, 'hairdress': {'concreteness': 3.93}, 'pharmaceutics': {'concreteness': 3.77}, 'hoover': {'concreteness': 3.76}, 'shopkeeping': {'concreteness': 3.18}, 'pushiness': {'concreteness': 2.48}, ...... } å¯èƒ½ **concreteness_dict**ä¸å¤Ÿç›´è§‚ï¼Œ å¦‚æœæ•´ç†è½¬åŒ–ä¸€ä¸‹å¤§æ¦‚ç±»ä¼¼äº\nJCR2021 | è®¡ç®—æ–‡æœ¬çš„è¯­è¨€å…·ä½“æ€§ æ–‡ä¸­æä¾›äº†ä¸€ä¸ªæ¡ˆä¾‹\nreply = \"I'll go look for that\" score=ct.sentiment_by_valence(text=reply, diction=concreteness_dict, lang='english') score Run\n{'concreteness': 9.28, 'word_num': 6} \nemployee_replys = [\"I'll go look for that\", \"I'll go search for that\", \"I'll go search for that top\", \"I'll go search for that t-shirt\", \"I'll go look for that t-shirt in grey\", \"I'll go search for that t-shirt in grey\"] for idx, reply in enumerate(employee_replys): score=ct.sentiment_by_valence(text=reply, diction=concreteness_dict, lang='english') template = \"Concreteness Score: {score:.2f}| Example-{idx}: {exmaple}\" print(template.format(score=score['concreteness'], idx=idx, exmaple=reply)) Run\nConcreteness Score: 9.28 | Example-0: I'll go look for that Concreteness Score: 9.32 | Example-1: I'll go search for that Concreteness Score: 13.25 | Example-2: I'll go search for that top Concreteness Score: 14.25 | Example-3: I'll go search for that t-shirt Concreteness Score: 21.32 | Example-4: I'll go look for that t-shirt in grey Concreteness Score: 21.36 | Example-5: I'll go search for that t-shirt in grey \n2.5 word_in_context() You shall know a word by the company it keeps é€šè¿‡ä¸€ä¸ªå•è¯æ‰€å¤„çš„è¯­å¢ƒï¼Œæˆ‘ä»¬å¯ä»¥äº†è§£è¯¥å•è¯çš„å«ä¹‰ã€‚\nåœ¨ text ä¸­æŸ¥æ‰¾ keywords å‡ºç°çš„ä¸Šä¸‹æ–‡å†…å®¹(çª—å£ window)ï¼Œè¿”å› dfã€‚\nct.word_in_context(text, keywords, window=3, lang='chinese')  text å¾…åˆ†ææ–‡æœ¬ keywords å…³é”®è¯åˆ—è¡¨ window å…³é”®è¯ä¸Šä¸‹æ–‡çª—å£å¤§å° lang æ–‡æœ¬çš„è¯­è¨€ç±»å‹ï¼Œ ä¸­æ–‡ chineseã€è‹±æ–‡ englishï¼Œé»˜è®¤ä¸­æ–‡ã€‚  import cntext as ct #æµ‹è¯•ä»£ç ï¼Œå‡è®¾zh_textæ˜¯å¹´æŠ¥æ–‡æœ¬ï¼Œä»æ‰¾æ‰¾å‡ºä¸ç½‘è¯ç›¸å…³è¯çš„ä¸Šä¸‹æ–‡ zh_text = \"\"\" ã€æ’å…¥ä¸€æ¡è‡ªå®¶å¹¿å‘Šã€‘å¤§é‚“è‡ªå·±å®¶çš„å®¶ï¼Œ å®‰å¹³å¿å¤šéš†ä¸ç½‘åˆ¶å“ï¼Œç”Ÿäº§é”€å”®ä¸é”ˆé’¢è½§èŠ±ç½‘ã€ ç”µç„Šç½‘ã€çŸ³ç¬¼ç½‘ã€åˆ€ç‰‡åˆºç»³ã€å†²å­”ç½‘ç­‰ä¸ç½‘åˆ¶å“ã€‚ è”ç³»äºº é‚“é¢–é™ 0318-7686899 äººç”Ÿè‹¦çŸ­ï¼Œæˆ‘å­¦Python åœ¨ç¤¾ç§‘ä¸­ï¼Œå¯ä»¥ç”¨Pythonåšæ–‡æœ¬åˆ†æ Pythonæ˜¯ä¸€é—¨åŠŸèƒ½å¼ºå¤§çš„ç¼–ç¨‹è¯­è¨€ï¼Œå¹¿æ³›åº”ç”¨åœ¨ç»ç®¡ç¤¾ç§‘é¢†åŸŸã€‚ å¯ä»¥åšç½‘ç»œçˆ¬è™«ã€æ–‡æœ¬åˆ†æã€LDAè¯é¢˜æ¨¡å‹ã€ç›¸ä¼¼åº¦åˆ†æç­‰ã€‚ ä»Šå¹´ç»æµä¸æ™¯æ°”ï¼Œå½¢åŠ¿å¼‚å¸¸ä¸¥å³»ã€‚ ç”±äºç–«æƒ…ä¸æ™¯æ°”ï¼Œé™é»˜ç®¡ç†ï¼Œ äº§å“ç§¯å‹ï¼Œ å…¬å¸ç»è¥å›°éš¾ã€‚ ä¿å°±ä¸šä¿ƒå°±ä¸šï¼Œä»»åŠ¡ååˆ†è‰°å·¨ã€‚ \"\"\" #ã€pythonã€‘ä¸Šä¸‹æ–‡ ct.word_in_context(text = zh_text, keywords = ['python'], window=10, lang='chinese') 2.6 epu() ä»£ç  | ä½¿ç”¨æ–°é—»æ•°æ®æµ‹é‡ç»æµæ”¿ç­–ä¸ç¡®å®šæ€§ EPU\nepu(df, freq='Y', e_pattern='', p_pattern='', u_pattern='')  df æ–°é—»æ•°æ® DataFrameï¼Œ å« text å’Œ date ä¸¤ä¸ªå­—æ®µã€‚ æ¯ä¸€è¡Œä»£è¡¨ä¸€æ¡æ–°é—»è®°å½• freq å­—ç¬¦ä¸²ï¼› ç¡®å®š EPU æŒ‡æ•°çš„æ—¶é—´é¢—ç²’åº¦ï¼› å¦‚å¹´ Y, æœˆ m, æ—¥ d, é»˜è®¤ freq=â€˜Yâ€™ e_pattern å­—ç¬¦ä¸²ï¼›ç»æµç±»è¯å…¸ï¼Œç”¨|é—´éš”è¯è¯­ï¼Œå½¢å¦‚ e_pattern = â€˜ç»æµ|é‡‘èâ€™ p_pattern å­—ç¬¦ä¸²ï¼›æ”¿ç­–è¯å…¸ï¼Œç”¨|é—´éš”è¯è¯­ï¼Œå½¢å¦‚ p_pattern = â€˜æ”¿ç­–|æ²»ç†|è¡Œæ”¿â€™ u_pattern å­—ç¬¦ä¸²ï¼›ä¸ç¡®å®šæ€§è¯å…¸ï¼Œç”¨|é—´éš”è¯è¯­ï¼Œå½¢å¦‚ u_pattern = â€˜é£é™©|å±æœº|éš¾ä»¥é¢„æµ‹â€™  å‡†å¤‡å¦‚ä¸‹å›¾æ ¼å¼çš„æ•°æ® news_df\nimport cntext as ct #çœç•¥ï¼Œè¯»å–æ•°æ®å¾—åˆ° news_df epu_df = ct.epu(df=news_df, freq='m') epu_df 2.7 fepu() ä½¿ç”¨ç®¡ç†å±‚è®¨è®ºä¸åˆ†ææ–‡æœ¬æ•°æ®æµ‹é‡ã€Œä¼ä¸šæ„ŸçŸ¥ä¸ç¡®å®šæ€§ã€(Subjective perception of economic policy uncertainty, FEPU)\nct.fepu(text, ep_pattern, u_pattern)  text ï¼›æŸæ—¶æœŸ t æŸä¼ä¸š i çš„ç®¡ç†å±‚è®¨è®ºä¸åˆ†æ md\u0026a æ–‡æœ¬ ep_pattern å­—ç¬¦ä¸²ï¼›ç»æµæ”¿ç­–ç±»è¯å…¸ï¼Œç”¨|é—´éš”è¯è¯­ï¼Œå½¢å¦‚ ep_pattern = â€˜ç»æµ|é‡‘è|æ”¿ç­–|æ²»ç†|è¡Œæ”¿â€™ u_pattern å­—ç¬¦ä¸²ï¼›ä¸ç¡®å®šæ€§è¯å…¸ï¼Œç”¨|é—´éš”è¯è¯­ï¼Œå½¢å¦‚ u_pattern = â€˜é£é™©|å±æœº|éš¾ä»¥é¢„æµ‹â€™  å‡†å¤‡å¦‚ä¸‹å›¾æ ¼å¼çš„æ•°æ® mda_df\nimport cntext as ct #çœç•¥ï¼Œè¯»å–æ•°æ®å¾—åˆ° mda_df fepu_df = df['ç»è¥è®¨è®ºä¸åˆ†æå†…å®¹'].apply(ct.fepu) res_df = pd.concat([df[['ä¼šè®¡å¹´åº¦', 'è‚¡ç¥¨ä»£ç ']], fepu_df], axis=1) res_df 2.8 semantic_brand_score() æ–‡çŒ®\u0026ä»£ç  | ä½¿ç”¨ Python è®¡ç®—è¯­ä¹‰å“ç‰Œè¯„åˆ†(Semantic Brand Score, SBS) ï¼Œ é€šè¿‡ SBS æ¥è¡¡é‡å“ç‰Œï¼ˆä¸ªä½“ã€å…¬å¸ã€å“ç‰Œã€å…³é”®è¯ç­‰ï¼‰çš„é‡è¦æ€§ã€‚\nct.semantic_brand_score(text, brands, lang='chinese')  text å¾…åˆ†ææ–‡æœ¬ brands è¯è¯­åˆ—è¡¨ï¼› lang è¯­è¨€ç±»å‹ï¼Œâ€œchinese\"æˆ–\"englishâ€ï¼Œé»˜è®¤\"chinese\"  ä»¥ä¸‰ä½“å°è¯´ä¸ºä¾‹ï¼Œé€šè¿‡æµ‹é‡å“ç‰Œè¯­ä¹‰è¯„åˆ† SBS æ¥åæ˜ å°è¯´è§’è‰²çš„é‡è¦æ€§ã€‚\nimport cntext as ct brands = ['æ±ªæ·¼', 'å²å¼º', 'ç½—è¾‘', 'å¶æ–‡æ´', 'ä¼Šæ–‡æ–¯'] #å‡†å¤‡santi_test_text #å°è¯´ç­‰åˆ†20ä»½ï¼Œ è¯»å–ç¬¬ä¸€ä»½å¾—åˆ°santi_test_text sbs_df = ct.semantic_brand_score(text=santi_test_text, brands=brands, lang='chinese') sbs_df å¦‚æœå°†ä¸‰ä½“å°è¯´åˆ†æˆ 20 ä»½ï¼Œ æ¯ä¸€ä»½éƒ½æµ‹ç®—å‡ºæ¯ä¸ªè§’è‰²çš„ SBSï¼Œç»˜åˆ¶å‡ºæŠ˜çº¿å›¾å¦‚ä¸‹å›¾æ‰€ç¤ºã€‚\n2.9 æ–‡æœ¬ç›¸ä¼¼åº¦ ct.cosine_sim(text1, text2, lang='chinese') cosä½™å¼¦ç›¸ä¼¼ ct.jaccard_sim(text1, text2, lang='chinese') jaccardç›¸ä¼¼ ct.minedit_sim(text1, text2, lang='chinese') æœ€å°ç¼–è¾‘è·ç¦»ç›¸ä¼¼åº¦ï¼› ct.simple_sim(text1, text2, lang='chinese') æ›´æ”¹å˜åŠ¨ç®—æ³• ç®—æ³•å®ç°å‚è€ƒè‡ª Cohen, Lauren, Christopher Malloy, and Quoc Nguyen. Lazy prices. No. w25084. National Bureau of Economic Research, 2018.\nimport cntext as ct text1 = 'ç¼–ç¨‹çœŸå¥½ç©ç¼–ç¨‹çœŸå¥½ç©' text2 = 'æ¸¸æˆçœŸå¥½ç©ç¼–ç¨‹çœŸå¥½ç©' print('cosine', ct.cosine_sim(text1, text2, lang='chinese')) print('jaccard', ct.jaccard_sim(text1, text2, lang='chinese')) print('minedit', ct.minedit_sim(text1, text2, lang='chinese')) print('simple', ct.simple_sim(text1, text2, lang='chinese')) Run\ncosine 0.82 jaccard 0.67 minedit 1.00 simple 0.84 \nimport cntext as ct text1 = 'Programming is fun!' text2 = 'Programming is interesting!' print('cosine', ct.cosine_sim(text1, text2, lang='english')) print('jaccard', ct.jaccard_sim(text1, text2, lang='english')) print('minedit', ct.minedit_sim(text1, text2, lang='english')) print('simple', ct.simple_sim(text1, text2, lang='english')) Run\ncosine 0.67 jaccard 0.50 minedit 1.00 simple 0.78 \n2.10 word_hhi æ–‡æœ¬çš„èµ«èŠ¬è¾¾å°”-èµ«å¸Œæ›¼æŒ‡æ•°ã€‚ct.word_hhi(text, lang=â€˜chineseâ€™)\nèµ«èŠ¬è¾¾å°”-èµ«å¸Œæ›¼æŒ‡æ•°(Herfindahl-Hirschman Index)ä½œä¸ºä¸€ç§è¡¡é‡å¸‚åœºé›†ä¸­åº¦çš„ç»æµæŒ‡æ ‡ï¼Œé€šå¸¸ç”¨äºåˆ†æäº§ä¸šæˆ–å¸‚åœºä¸­ä¼ä¸šä»½é¢çš„åˆ†å¸ƒæƒ…å†µã€‚\nå‰äººç±»æ¯”å¸‚åœºé›†ä¸­ç¨‹åº¦ï¼Œç”¨äºæµ‹é‡ä¸“åˆ©è´¨é‡(çŸ¥è¯†å®½åº¦)ã€‚ é‚£æ”¾åœ¨æ–‡æœ¬è¯­è¨€ä¸­ï¼Œæˆ‘ä»¬æ˜¯å¦å¯èƒ½åˆ©ç”¨ HHI æ¥é‡åŒ–æŸä¸ªè¯­æ–™åº“ä¸­ä¸åŒè¯æ±‡çš„ä½¿ç”¨é¢‘ç‡åˆ†å¸ƒï¼Œä»¥æ­¤æ¥åˆ†æä¸ªäººã€ç¾¤ä½“æˆ–æ—¶ä»£çš„è¯­è¨€é£æ ¼ã€è¯æ±‡ä¸°å¯Œåº¦ã€æˆ–æ˜¯è¯­è¨€æ ‡å‡†åŒ–ä¸å˜åŒ–çš„è¶‹åŠ¿ã€‚\n å¦‚æœè¯æ±‡åˆ†å¸ƒéå¸¸å‡åŒ€ï¼Œè¡¨æ˜è¯­è¨€ä½¿ç”¨ä¸­çš„è¯æ±‡å¤šæ ·æ€§é«˜ï¼ŒHHI å€¼å°±ä¼šè¾ƒä½ï¼› åä¹‹ï¼Œå¦‚æœå°‘æ•°è¯æ±‡å æ®äº†å¤§éƒ¨åˆ†æ–‡æœ¬ç©ºé—´ï¼Œè¡¨æ˜è¯æ±‡ä½¿ç”¨é›†ä¸­ï¼ŒHHI å€¼åˆ™è¾ƒé«˜ã€‚  ç»“åˆå…¶ä»–è¯­è¨€å­¦æŒ‡æ ‡ä¸€èµ·ä½¿ç”¨ï¼Œæ¯”å¦‚ TTRï¼ˆType-Token Ratioï¼Œç±»å‹-æ ‡è®°æ¯”ç‡ï¼‰ã€Shannon entropyï¼ˆé¦™å†œç†µï¼‰ç­‰ï¼Œå…±åŒè¯„ä¼°è¯­è¨€è¡¨è¾¾çš„å¤æ‚åº¦å’Œå¤šæ ·æ€§ã€‚ä¸è¿‡ï¼Œè¿™ç±»ç ”ç©¶çš„æ–‡çŒ®ç›¸å¯¹è¾ƒå°‘ï¼Œå› ä¸ºè¯­è¨€å­¦é¢†åŸŸæœ‰è‡ªå·±ä¸€å¥—æˆç†Ÿä¸”ä¸“ä¸šçš„åˆ†æå·¥å…·å’Œæ–¹æ³•ï¼ŒHHI æ›´å¤šåœ°è¢«è§†ä¸ºè·¨å­¦ç§‘åº”ç”¨çš„ä¸€ä¸ªåˆ›æ–°å°è¯•ã€‚\nimport cntext as ct personA = 'è¿™åœºéŸ³ä¹ä¼šå¤ªå—¨äº†' personB = 'è¿™åœºéŸ³ä¹ä¼šè¯´å‡ºæ¥ä»¤ä½ ä¸æ•¢ç›¸ä¿¡ï¼Œä¸»åŠæ–¹ç­–åˆ’æœ‰æ–¹ï¼Œç¾¤ä¼—æ¿€æƒ…æ»¡æ»¡ï¼Œæˆ‘å°è±¡æ·±åˆ»ï¼Œä½“éªŒæ„Ÿæ‹‰æ»¡' print('A-hhi', ct.word_hhi(personA)) print('B-hhi', ct.word_hhi(personB)) print('Aè¯æ±‡å¤šæ ·æ€§', 1 - ct.word_hhi(personA)) print('Bè¯æ±‡å¤šæ ·æ€§', 1 - ct.word_hhi(personB)) Run\nA-hhi 0.20000000000000004 B-hhi 0.07024793388429751 Aè¯æ±‡å¤šæ ·æ€§ 0.7999999999999999 Bè¯æ±‡å¤šæ ·æ€§ 0.9297520661157025 \nä¸‰ã€Plot æ¨¡å—    æ¨¡å— å‡½æ•° åŠŸèƒ½     plot ct.matplotlib_chinese() æ”¯æŒ matplotlib ä¸­æ–‡ç»˜å›¾   plot ct.lexical_dispersion_plot1(text, targets_dict, lang, title, figsize) å¯¹æŸä¸€ä¸ªæ–‡æœ¬ textï¼Œ å¯è§†åŒ–ä¸åŒç›®æ ‡ç±»åˆ«è¯ targets_dict åœ¨æ–‡æœ¬ä¸­å‡ºç°ä½ç½®   plot ct.lexical_dispersion_plot2(texts_dict, targets, lang, title, figsize) å¯¹æŸå‡ ä¸ªæ–‡æœ¬ texts_dictï¼Œ å¯è§†åŒ–æŸäº›ç›®æ ‡è¯ targets åœ¨æ–‡æœ¬ä¸­å‡ºç°ç›¸å¯¹ä½ç½®(0~100)    3.1 matplotlib_chinese() matplotlib é»˜è®¤ä¸æ”¯æŒä¸­æ–‡å¯è§†åŒ–ï¼Œ cntext æ–°å¢è¯¥å‡½æ•°ï¼Œå¯ä»¥è§£å†³ä¸­æ–‡å¯è§†åŒ–é—®é¢˜\nimport cntext as ct plt = ct.matplotlib_chinese() plt.figure(figsize=(7, 4)) plt.plot([1, 2, 3, 4], [1, 4, 9, 16]) plt.title('ä¸­æ–‡å›¾è¡¨', fontsize=10) plt.show() 3.2 lexical_dispersion_plot1() è¯æ±‡åˆ†æ•£å›¾å¯è§†åŒ–ï¼Œ å¯¹æŸä¸€ä¸ªæ–‡æœ¬ textï¼Œ å¯è§†åŒ–ä¸åŒç›®æ ‡ç±»åˆ«è¯ targets_dict åœ¨æ–‡æœ¬ä¸­å‡ºç°ä½ç½®\nct.lexical_dispersion_plot1(text, targets_dict, lang='chinese', figsize=(12, 6), title='ç‰¹å®šè¯æ±‡åœ¨ä¸åŒæ–‡æœ¬æ¥æºçš„ç›¸å¯¹ç¦»æ•£å›¾', prop=True)  text: æ–‡æœ¬æ•°æ® targets_dict: ç›®æ ‡ç±»åˆ«è¯å­—å…¸ï¼› targets_dict={â€˜posâ€™: [â€˜å¼€å¿ƒâ€™, â€˜å¿«ä¹â€™], â€˜negâ€™: [â€˜æ‚²ä¼¤â€™, â€˜éš¾è¿‡â€™]} lang: æ–‡æœ¬æ•°æ® texts_dict çš„è¯­è¨€ç±»å‹ï¼Œé»˜è®¤â€™chinese'. figsize: å›¾çš„é•¿å®½å°ºå¯¸. é»˜è®¤ (8, 5). title : å›¾çš„æ ‡é¢˜ï¼› prop: æ¨ªåæ ‡å­—ç¬¦ä½ç½®æ˜¯å¦ä¸ºç›¸å¯¹ä½ç½®. é»˜è®¤ Trueï¼Œæ¨ªåæ ‡ç´¢å¼•å€¼å–å€¼èŒƒå›´ 0 ~ 100  ç‚¹å‡»ä¸‹è½½ ä¸‰ä½“.txtã€åŸºåœ°.txtä¸¤æœ¬å°è¯´æ–‡ä»¶ã€‚\nimport cntext as ct roles_dict = { \"æ±ªæ·¼\": ['æ±ªæ·¼'], \"å¶æ–‡æ´\": ['å¶æ–‡æ´'], \"ç½—è¾‘\": ['ç½—è¾‘'] } santi_text = open('ä¸‰ä½“.txt', encoding='utf-8').read() ax = ct.lexical_dispersion_plot1(text = santi_text, #æ–‡æœ¬æ•°æ® targets_dict = roles_dict, #è§’è‰² figsize = (10, 4), #å°ºå¯¸å¤§å° lang = 'chinese', #ä¸­æ–‡æ•°æ® title = 'ã€Šä¸‰ä½“ã€‹å°è¯´è§’è‰²å‡ºç°ä½ç½®', #æ ‡é¢˜ prop = True) #ç›¸å¯¹ä½ç½®(æ¨ªåæ ‡è½´å–å€¼èŒƒå›´0-100) ax ct.lexical_dispersion_plot1(text = santi_text, #æ–‡æœ¬æ•°æ® targets_dict = roles_dict, #è§’è‰² figsize = (10, 4), #å°ºå¯¸å¤§å° lang = 'chinese', #ä¸­æ–‡æ•°æ® title = 'ã€Šä¸‰ä½“ã€‹å°è¯´è§’è‰²å‡ºç°ä½ç½®', #æ ‡é¢˜ prop = False) #ç»å¯¹ä½ç½®(æ¨ªåæ ‡è½´å–å€¼èŒƒå›´ä¸å°è¯´æ–‡æœ¬é•¿åº¦æœ‰å…³) import cntext as ct # diyäº†ä¸€ä¸ªå°è¯å…¸ senti_dict = { 'pos': ['å¼€å¿ƒ', 'å¹¸ç¦', 'å¿«ä¹', 'å®‰å®', 'å¸Œæœ›'], 'neg': ['ç´§å¼ ', 'ææƒ§', 'å®³æ€•', 'ç»æœ›'] } santi_text = open('ä¸‰ä½“.txt', encoding='utf-8').read() ax = ct.lexical_dispersion_plot1(text = santi_text, targets_dict = senti_dict, figsize = (10, 2), lang = 'chinese', title = 'ã€Šä¸‰ä½“ã€‹æƒ…ç»ªè¯å‡ºç°ä½ç½®', prop = True) ax 3.3 lexical_dispersion_plot2() è¯æ±‡åˆ†æ•£å›¾å¯è§†åŒ–ï¼Œ å¯¹æŸå‡ ä¸ªæ–‡æœ¬ texts_dictï¼Œ å¯è§†åŒ–æŸäº›ç›®æ ‡è¯ targets åœ¨æ–‡æœ¬ä¸­å‡ºç°ç›¸å¯¹ä½ç½®(0~100)\nct.lexical_dispersion_plot2(texts_dict, targets, lang='chinese', figsize=(12, 6), title='ç‰¹å®šè¯æ±‡åœ¨ä¸åŒæ–‡æœ¬æ¥æºçš„ç›¸å¯¹ç¦»æ•£å›¾')  texts_dict: å¤šä¸ªæ–‡æœ¬çš„å­—å…¸æ•°æ®ã€‚å½¢å¦‚{â€˜source1â€™: â€˜source1 çš„æ–‡æœ¬å†…å®¹â€™, â€˜source2â€™: â€˜source2 çš„æ–‡æœ¬å†…å®¹â€™} targets: ç›®æ ‡è¯åˆ—è¡¨ lang: æ–‡æœ¬æ•°æ® texts_dict çš„è¯­è¨€ç±»å‹ï¼Œé»˜è®¤â€™chinese'. figsize: å›¾çš„é•¿å®½å°ºå¯¸. é»˜è®¤ (8, 5). title : å›¾çš„æ ‡é¢˜ï¼›  targets = ['å¤ªç©º', 'å®‡å®™'] texts_dict = {'ä¸‰ä½“': open('ä¸‰ä½“.txt', encoding='utf-8').read(), 'åŸºåœ°': open('åŸºåœ°.txt', encoding='utf-8').read()} ax = ct.lexical_dispersion_plot2(texts_dict = texts_dict, targets = targets, figsize = (10, 2), title = '\"å¤ªç©º/å®‡å®™\"è¯è¯­å‡ºç°ä½ç½®', lang = 'chinese') ax \nå››ã€Model æ¨¡å— æœ¬éƒ¨åˆ†ä¸»è¦å†…å®¹æ˜¯è¯åµŒå…¥æ¨¡å‹ç›¸å…³æŠ€æœ¯ï¼Œ åŒ…æ‹¬ Word2Vec(GLove)çš„è®­ç»ƒã€è¯»å–ã€æ‰©å±•è¯å…¸ã€‚\n   æ¨¡å— å‡½æ•°(ç±») åŠŸèƒ½     model ct.Word2Vec(corpus_file, encoding, lang, window_size, vector_size,â€¦) è®­ç»ƒ Word2Vec   model ct.GloVe(corpus_file, encoding, lang, window_size, vector_size, â€¦) è®­ç»ƒ GLove æ¨¡å‹ã€‚   model ct.evaluate_similarity(wv, file=None) ä½¿ç”¨è¿‘ä¹‰æ³•è¯„ä¼°æ¨¡å‹è¡¨ç°ï¼Œé»˜è®¤ä½¿ç”¨å†…ç½®çš„æ•°æ®è¿›è¡Œè¯„ä¼°ã€‚   model ct.evaluate_analogy(wv, file=None) ä½¿ç”¨ç±»æ¯”æ³•è¯„ä¼°æ¨¡å‹è¡¨ç°ï¼Œé»˜è®¤ä½¿ç”¨å†…ç½®çš„æ•°æ®è¿›è¡Œè¯„ä¼°ã€‚   model ct.load_w2v(wv_path) è¯»å– cntext2.x è®­ç»ƒå‡ºçš„ Word2Vec/GloVe æ¨¡å‹æ–‡ä»¶   model ct.glove2word2vec(glove_file, word2vec_file) å°† GLoVe æ¨¡å‹.txt æ–‡ä»¶è½¬åŒ–ä¸º Word2Vec æ¨¡å‹.txt æ–‡ä»¶ï¼›æ³¨æ„è¿™é‡Œçš„ GLoVe æ¨¡å‹.txt æ˜¯é€šè¿‡Standfordnlp/GloVe è®­ç»ƒå¾—åˆ°çš„ã€‚   model ct.expand_dictionary(wv, seeddict, topn=100) æ‰©å±•è¯å…¸, ç»“æœä¿å­˜åˆ°è·¯å¾„[output/Word2Vec]ä¸­   model ct.SoPmi(corpus_file, seed_file, lang='chinese') å…±ç°æ³•æ‰©å±•è¯å…¸    4.1 Word2Vec() å¯ç›´æ¥å¯¹åŸå§‹è¯­æ–™ txt æ–‡ä»¶è¿›è¡Œè‡ªåŠ¨ Word2vec è®­ç»ƒã€‚è¯¥å‡½æ•°ä¼šè‡ªåŠ¨å¤„ç†æ–‡æœ¬é¢„å¤„ç†(åˆ†è¯ã€å»åœè¯)ã€å†…å­˜ç®¡ç†ã€å‚æ•°è°ƒæ•´ç­‰é—®é¢˜ï¼Œç¡®ä¿è®­ç»ƒè¿‡ç¨‹é¡ºåˆ©è¿›è¡Œã€‚\nåœ¨ gensim.models.word2vec.Word2Vec åŸºç¡€ä¸Šï¼Œå¢åŠ äº†ä¸­è‹±æ–‡çš„é¢„å¤„ç†ï¼Œ ç®€åŒ–äº†ä»£ç ä½¿ç”¨ã€‚é…ç½®å¥½ cntext2.x ç¯å¢ƒï¼Œ å¯ä»¥åšåˆ°\n   è®­ç»ƒåªç”¨ä¸€è¡Œä»£ç     è¯»å–è°ƒç”¨åªç”¨ä¸€è¡Œä»£ç     ct.Word2Vec(corpus_file, lang='chinese', dict_file=None, stopwords_file=None, vector_size=100, window_size=6, min_count=5, max_iter=5, chunksize=10000, only_binary=True, **kwargs)  corpus_file: è¯­æ–™åº“æ–‡ä»¶çš„è·¯å¾„ã€‚ lang: è¯­è¨€ç±»å‹ï¼Œæ”¯æŒ â€˜chineseâ€™ å’Œ â€˜englishâ€™ï¼Œé»˜è®¤ä¸º â€˜chineseâ€™ã€‚ dict_file: è‡ªå®šä¹‰è¯å…¸ txt æ–‡ä»¶è·¯å¾„ï¼Œé»˜è®¤ä¸º Noneã€‚utf-8 ç¼–ç ã€‚ stopwords_file: åœç”¨è¯æ–‡ä»¶è·¯å¾„ï¼Œé»˜è®¤ä¸º Noneã€‚utf-8 ç¼–ç ã€‚ vector_size: è¯å‘é‡çš„ç»´åº¦ï¼Œé»˜è®¤ä¸º 50ã€‚ window_size: ä¸Šä¸‹æ–‡çª—å£çš„å¤§å°ï¼Œé»˜è®¤ä¸º 6ã€‚ min_count: æœ€å°è¯é¢‘ï¼Œé»˜è®¤ä¸º 10ã€‚ max_iter: æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼Œé»˜è®¤ä¸º 5ã€‚ chunksize: æ¯æ¬¡è¯»å–çš„è¡Œæ•°ã€‚é»˜è®¤ä¸º 10000ã€‚è¶Šå¤§é€Ÿåº¦è¶Šå¿«ã€‚ only_binary : æ˜¯å¦åªä¿å­˜æ¨¡å‹ä¸ºäºŒè¿›åˆ¶æ–‡ä»¶ã€‚é»˜è®¤ä¸º Trueï¼Œ ä¿å­˜ä¸º binã€‚False æ—¶åªä¿å­˜ binã€txtã€‚ kwargs: å…¶ä»– gensim å¯é€‰å‚æ•°ï¼Œå¦‚ negativeã€sampleã€hs ç­‰ã€‚  import cntext as ct w2v = ct.Word2Vec(corpus_file = 'data/ä¸‰ä½“.txt', lang = 'chinese', window_size = 6, vector_size = 50) w2v Run\nMac(Linux) System, Enable Parallel Processing Cache output/ä¸‰ä½“_cache.txt Not Found or Empty, Preprocessing Corpus Reading Preprocessed Corpus from output/ä¸‰ä½“_cache.txt Start Training Word2Vec Word2Vec Training Cost 10 s. Output Saved To: output/Word2Vec/ä¸‰ä½“-Word2Vec.50.6.bin [data/ä¸‰ä½“.txt]ä½“ç§¯ 2.7Mï¼Œ è®­ç»ƒæ—¶é—´ 10sï¼Œ æ¨¡å‹æ–‡ä»¶å­˜å‚¨äº output/Word2Vec/ä¸‰ä½“-Word2Vec.50.6.bin\n4.2 GloVe() ä½¿ç”¨ Stanford GloVe ä»£ç å·¥å…·è®­ç»ƒ GloVe æ¨¡å‹ã€‚è¯¥å‡½æ•°ä¼šè‡ªåŠ¨å¤„ç†æ–‡æœ¬é¢„å¤„ç†ã€å†…å­˜ç®¡ç†ã€å‚æ•°è°ƒæ•´ç­‰é—®é¢˜ï¼Œç¡®ä¿è®­ç»ƒè¿‡ç¨‹é¡ºåˆ©è¿›è¡Œã€‚\nct.GloVe(corpus_file, lang='chinese', dict_file=None, stopwords_file=None, vector_size=100, window_size=15, min_count=5, max_memory=4.0, max_iter=15, x_max=10, only_binary=True, chunksize=10000)  corpus_file: è¾“å…¥è¯­æ–™æ–‡ä»¶è·¯å¾„ï¼ˆæ–‡æœ¬æ ¼å¼ï¼‰ã€‚è¯¥æ–‡ä»¶ä¸ºåˆ†è¯åçš„è¯­æ–™æ–‡ä»¶ã€‚ lang: è¯­æ–™æ–‡ä»¶çš„è¯­è¨€ç±»å‹ï¼Œé»˜è®¤ä¸º â€˜chineseâ€™ã€‚ dict_file: è‡ªå®šä¹‰è¯å…¸ txt æ–‡ä»¶è·¯å¾„ï¼Œé»˜è®¤ä¸º Noneã€‚utf-8 ç¼–ç ã€‚ stopwords_file: åœç”¨è¯æ–‡ä»¶è·¯å¾„ï¼Œé»˜è®¤ä¸º Noneã€‚utf-8 ç¼–ç ã€‚ vector_size: è¯å‘é‡ç»´åº¦ï¼Œé»˜è®¤ 100ã€‚ window_size: ä¸Šä¸‹æ–‡çª—å£å¤§å°ï¼Œé»˜è®¤ 15ã€‚ min_count: å¿½ç•¥å‡ºç°æ¬¡æ•°ä½äºæ­¤å€¼çš„å•è¯ï¼Œé»˜è®¤ 5ã€‚ max_memory: å¯ä¾›ä½¿ç”¨çš„æœ€å¤§å†…å­˜å¤§å°ï¼Œå•ä½ä¸º GBï¼Œé»˜è®¤ 4; è¯¥å‚æ•°è¶Šå¤§ï¼Œè®­ç»ƒè¶Šå¿«ã€‚ max_iter: è®­ç»ƒçš„æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼Œé»˜è®¤ 15ã€‚ x_max: å…±ç°çŸ©é˜µä¸­å…ƒç´ çš„æœ€å¤§è®¡æ•°å€¼ï¼Œé»˜è®¤ 10ã€‚ chunksize: æ¯æ¬¡è¯»å–çš„è¡Œæ•°ã€‚é»˜è®¤ä¸º 10000ã€‚è¶Šå¤§é€Ÿåº¦è¶Šå¿«ã€‚ only_binary : æ˜¯å¦åªä¿å­˜æ¨¡å‹ä¸ºäºŒè¿›åˆ¶æ–‡ä»¶ã€‚é»˜è®¤ä¸º Trueï¼Œ ä¿å­˜ä¸º binã€‚False æ—¶åªä¿å­˜ binã€txtã€‚  ct.GloVe å†…ç½® Stanford GloVeç®—æ³•ï¼Œ è®­ç»ƒé€Ÿåº¦éå¸¸å¿«ã€‚\nimport cntext as ct glove = ct.GloVe(corpus_file='data/ä¸‰ä½“.txt', lang='chinese', vector_size=50, window_size=15) glove Run\nMac(Linux) System, Enable Parallel Processing Cache output/ä¸‰ä½“_cache.txt Not Found or Empty, Preprocessing Corpus Start Training GloVe BUILDING VOCABULARY Using vocabulary of size 6975. COUNTING COOCCURRENCES Merging cooccurrence files: processed 2106999 lines. Using random seed 1743474106 SHUFFLING COOCCURRENCES Merging temp files: processed 2106999 lines. TRAINING MODEL Read 2106999 lines. Using random seed 1743474106 04/01/25 - 10:21.46AM, iter: 001, cost: 0.055981 04/01/25 - 10:21.46AM, iter: 002, cost: 0.050632 ...... 04/01/25 - 10:21.48AM, iter: 014, cost: 0.030047 04/01/25 - 10:21.48AM, iter: 015, cost: 0.029100 GloVe Training Cost 9 s. Output Saved To: output/ä¸‰ä½“-GloVe.50.15.bin è®­ç»ƒç”Ÿæˆçš„ output/GloVe/ä¸‰ä½“-GloVe.50.15.bin å¯ç”¨ ct.load_w2v è¯»å–ï¼Œåœ¨åé¢ä¼šæœ‰å±•ç¤ºã€‚\n4.3 evaluate_similarity() è¯„ä¼°è¯å‘é‡æ¨¡å‹è¯­ä¹‰ç›¸ä¼¼è¡¨ç°ã€‚ ä½¿ç”¨ Spearmanâ€™s Rank Coeficient ä½œä¸ºè¯„ä»·æŒ‡æ ‡ï¼Œ å–å€¼[-1, 1], 1 å®Œå…¨ç›¸å…³ï¼Œ-1 å®Œå…¨è´Ÿç›¸å…³ï¼Œ 0 æ¯«æ— ç›¸å…³æ€§ã€‚\ncntext2.x å†…ç½® 537 æ¡è¿‘ä¹‰å®éªŒæ•°æ®ï¼Œ å¯ç›´æ¥ä½¿ç”¨ã€‚\nct.evaluate_similarity(wv, file=None)  wv è¯­æ–™ txt æ–‡ä»¶è·¯å¾„ file è¯„ä¼°æ•°æ®æ–‡ä»¶ï¼Œtxt æ ¼å¼ï¼Œé»˜è®¤ä½¿ç”¨ cntext å†…ç½®çš„è¯„ä¼°æ•°æ®æ–‡ä»¶ã€‚ txt æ–‡ä»¶æ¯è¡Œä¸¤ä¸ªè¯ä¸€ä¸ªæ•°å­—ï¼Œå¦‚ä¸‹æ‰€ç¤º  è¶³çƒ\tè¶³çƒ\t4.98 è€è™\tè€è™\t4.8888888889 æ’æ˜Ÿ\tæ’æ˜Ÿ\t4.7222222222 å…¥åœºåˆ¸\té—¨ç¥¨\t4.5962962963 ç©ºé—´\tåŒ–å­¦\t0.9222222222 è‚¡ç¥¨\tç”µè¯\t0.92 å›½ç‹\tè½¦\t0.9074074074 ä¸­åˆ\tå­—ç¬¦ä¸²\t0.6 æ”¶éŸ³æœº\tå·¥ä½œ\t0.6 æ•™æˆ\té»„ç“œ\t0.5 è‡ªè¡Œè½¦\té¸Ÿ\t0.5 è›‹ç™½è´¨\tæ–‡ç‰©\t0.15 \nimport cntext as ct # å¯åœ¨ https://cntext.readthedocs.io/zh-cn/latest/embeddings.html ä¸‹è½½è¯¥æ¨¡å‹æ–‡ä»¶ dm_w2v = ct.load_w2v('output/douban-movie-1000w-Word2Vec.200.15.bin') # ä½¿ç”¨å†…ç½®è¯„ä¼°æ–‡ä»¶ ct.evaluate_similarity(wv=dm_w2v) # ä½¿ç”¨è‡ªå®šä¹‰è¯„ä¼°æ–‡ä»¶ # ct.evaluate_similarity(wv=dm_w2v, file='diy_similarity.txt') Run\nè¿‘ä¹‰æµ‹è¯•: similarity.txt /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/cntext/model/evaluate_data/similarity.txt Processing Similarity Test: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 537/537 [00:00\n4.4 evaluate_analogy() ç”¨äºè¯„ä¼°è¯å‘é‡æ¨¡å‹åœ¨ç±»æ¯”æµ‹è¯•ï¼ˆanalogy testï¼‰ä¸­è¡¨ç°çš„å‡½æ•°ã€‚å®ƒé€šè¿‡è¯»å–æŒ‡å®šçš„ç±»æ¯”æµ‹è¯•æ–‡ä»¶ï¼Œè®¡ç®—æ¨¡å‹å¯¹è¯è¯­å…³ç³»é¢„æµ‹çš„å‡†ç¡®æ€§ï¼Œå¹¶è¾“å‡ºæ¯ä¸ªç±»åˆ«çš„å‡†ç¡®ç‡ã€å‘ç°è¯è¯­æ•°é‡ã€æœªå‘ç°è¯è¯­æ•°é‡ä»¥åŠå¹³å‡æ’åç­‰æŒ‡æ ‡ã€‚\n é›…å…¸ä¹‹äºå¸Œè…Šï¼Œä¼¼å¦‚å·´æ ¼è¾¾ä¹‹äºä¼Šæ‹‰å…‹ã€‚ å“ˆå°”æ»¨ä¹‹äºé»‘é¾™æ±Ÿï¼Œä¼¼å¦‚é•¿æ²™ä¹‹äºæ¹–å—ã€‚ å›½ç‹ä¹‹äºç‹åï¼Œä¼¼å¦‚ç”·äººä¹‹äºå¥³äººã€‚  cntext2.x å†…ç½® 1194 æ¡ç±»æ¯”ï¼Œ æ ¼å¼å¦‚ä¸‹\nç±»æ¯”æµ‹è¯•çš„æ ¸å¿ƒæ˜¯è§£å†³å½¢å¦‚ â€œA : B :: C : Dâ€ çš„é—®é¢˜ï¼Œç¿»è¯‘è¿‡æ¥å°±æ˜¯\"A ä¹‹äº Bï¼Œä¼¼å¦‚ C ä¹‹äº D\"ï¼› å³é€šè¿‡ AB ç±»æ¯”å…³ç³»ï¼Œæ‰¾åˆ° C çš„å…³ç³»è¯ Dã€‚è¯¥å‡½æ•°é€šè¿‡è¯å‘é‡æ¨¡å‹çš„ç›¸ä¼¼æ€§æœç´¢åŠŸèƒ½ï¼Œè®¡ç®—é¢„æµ‹ç»“æœä¸çœŸå®ç­”æ¡ˆçš„åŒ¹é…ç¨‹åº¦ã€‚\nct.evaluate_analogy(wv, file=None)  wv è¯­æ–™ txt æ–‡ä»¶è·¯å¾„ file è¯„ä¼°æ•°æ®æ–‡ä»¶ï¼Œtxt æ ¼å¼ï¼Œé»˜è®¤ä½¿ç”¨ cntext å†…ç½®çš„è¯„ä¼°æ•°æ®æ–‡ä»¶ã€‚ txt æ–‡ä»¶æ¯è¡Œä¸¤ä¸ªè¯ä¸€ä¸ªæ•°å­—ï¼Œå¦‚ä¸‹æ‰€ç¤º  è¯„ä¼°æ•°æ® txt æ–‡ä»¶æ ¼å¼ï¼Œå¦‚ä¸‹\n: CapitalOfCountries é›…å…¸ å¸Œè…Š å·´æ ¼è¾¾ ä¼Šæ‹‰å…‹ å“ˆç“¦é‚£ å¤å·´ é©¬å¾·é‡Œ è¥¿ç­ç‰™ æ²³å†… è¶Šå— ä¼¦æ•¦ è‹±å›½ : CityInProvince çŸ³å®¶åº„ æ²³åŒ— å—æ˜Œ æ±Ÿè¥¿ æ²ˆé˜³ è¾½å® å—æ˜Œ æ±Ÿè¥¿ å—äº¬ æ±Ÿè‹ éƒ‘å· æ²³å— : FamilyRelationship ç”·å­© å¥³å­© å…„å¼Ÿ å§å¦¹ ç”·å­© å¥³å­© å›½ç‹ ç‹å çˆ¶äº² æ¯äº² å›½ç‹ ç‹å ä¸ˆå¤« å¦»å­ å”å” é˜¿å§¨ : SocialScience-Concepts ç¤¾ä¼š ç¤¾ä¼šç»“æ„ å®¶åº­ å®¶åº­ç»“æ„ æ–‡åŒ– æ–‡åŒ–ä¼ æ‰¿ è¯­è¨€ è¯­è¨€ä¼ æ‰¿ ç¾¤ä½“ ç¾¤ä½“è¡Œä¸º ç»„ç»‡ ç»„ç»‡è¡Œä¸º \nimport cntext as ct # å¯åœ¨ https://cntext.readthedocs.io/zh-cn/latest/embeddings.html ä¸‹è½½è¯¥æ¨¡å‹æ–‡ä»¶ dm_w2v = ct.load_w2v('output/douban-movie-1000w-Word2Vec.200.15.bin') # ä½¿ç”¨å†…ç½®è¯„ä¼°æ–‡ä»¶ ct.evaluate_analogy(wv=dm_w2v) # ä½¿ç”¨è‡ªå®šä¹‰è¯„ä¼°æ–‡ä»¶ # ct.evaluate_analogy(wv=dm_w2v, file='diy_analogy.txt') Run\nç±»æ¯”æµ‹è¯•: analogy.txt /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/cntext/model/evaluate_data/analogy.txt Processing Analogy Test: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1198/1198 [00:11è±†ç“£ç”µå½±åœ¨ FamilyRelationship è¯„ä¼°ä¸­è¡¨ç°è¾ƒå¥½ï¼Œå¤§æ¦‚ç‡æ˜¯å› ä¸ºç”µå½±ä¸»è¦åæ˜ çš„æ˜¯äººä¸äººä¹‹é—´çš„å…³ç³»ï¼Œè¦†ç›–äº†ç»å¤§å¤šæ•° FamilyRelationship å®¶åº­ç±»æ¯”å…³ç³»ï¼Œæ‰€ä»¥ç±»æ¯”è¡¨ç°å·¨å¥½ï¼Œä½†åœ¨å…¶ä»–æ–¹é¢è¡¨ç°è¾ƒå·®ã€‚\nå¦‚æœæ˜¯ç»´åŸºç™¾ç§‘è¯­æ–™ï¼Œå¯èƒ½åœ¨ CapitalOfCountriesã€CityInProvinceã€SocialScience ä¸­è¡¨ç°è¾ƒå¥½ã€‚\n4.5 SoPmi() ct.SoPmi(corpus_file, seed_file) #äººå·¥æ ‡æ³¨çš„åˆå§‹ç§å­è¯  corpus_file è¯­æ–™ txt æ–‡ä»¶è·¯å¾„ seed_file åˆå§‹ç§å­è¯ txt æ–‡ä»¶è·¯å¾„  å…±ç°æ³•\nimport cntext as ct ct.SoPmi(corpus_file='data/sopmi_corpus.txt', seed_file='data/sopmi_seed.txt') # äººå·¥æ ‡æ³¨çš„åˆå§‹ç§å­è¯ Run\nStep 1/4:...Preprocess Corpus ... Step 2/4:...Collect co-occurrency information ... Step 3/4:...Calculate mutual information ... Step 4/4:...Save candidate words ... Finish! used 19.74 s 4.6 load_w2v() å¯¼å…¥ cntext2.x é¢„è®­ç»ƒçš„ word2vec æ¨¡å‹ .txt æ–‡ä»¶\nct.load_w2v(w2v_path)  w2v_path æ¨¡å‹æ–‡ä»¶è·¯å¾„  è¯»å– output/ä¸‰ä½“.100.6.txt æ¨¡å‹æ–‡ä»¶, è¿”å› gensim.models.word2vec.Word2Vec ç±»å‹ã€‚\nimport cntext as ct santi_w2v = ct.load_w2v(w2v_path='output/ä¸‰ä½“-Word2Vec.50.6.bin') # santi_w2v = ct.load_wv(wv_path='output/ä¸‰ä½“-Word2Vec.50.6.txt') santi_glove = ct.load_w2v(w2v_path='output/ä¸‰ä½“-GloVe.50.15.bin') # santi_glove = ct.load_wv(wv_path='output/ä¸‰ä½“-GloVe.50.15.bin') santi_w2v Run\nLoading output/ä¸‰ä½“-Word2Vec.50.6.bin... Loading output/ä¸‰ä½“-GloVe.50.15.bin... \n4.7 glove2word2vec() å°† GLoVe æ¨¡å‹.txt æ–‡ä»¶è½¬åŒ–ä¸º Word2Vec æ¨¡å‹.txt æ–‡ä»¶ï¼› é™¤éä»ç½‘ç»œä¸‹è½½çš„ GloVe æ¨¡å‹èµ„æºï¼Œ å¦åˆ™ä¸€èˆ¬æƒ…å†µç”¨ä¸åˆ°è¿™ä¸ªå‡½æ•°ã€‚\nct.glove2word2vec(glove_file, word2vec_file)  glove_file: GLoVe æ¨¡å‹.txt æ–‡ä»¶è·¯å¾„ word2vec_file: Word2Vec æ¨¡å‹.txt æ–‡ä»¶è·¯å¾„  æ³¨æ„è¿™é‡Œçš„ GLoVe æ¨¡å‹.txt æ˜¯é€šè¿‡Standfordnlp/GloVe è®­ç»ƒå¾—åˆ°çš„\nimport cntext as ct ct.glove2word2vec(glove_file='data/GloVe.6B.50d.txt', word2vec_file='output/word2vec_format_GloVe.6B.50d.txt') \næ³¨æ„  ct.load_w2v() å¯¼å…¥åå¾—åˆ°çš„æ•°æ®ç±»å‹æ˜¯ gensim.models.keyedvectors.KeyedVectors ã€‚ gensim.models.word2vec.Word2Vec å¯ä»¥è½¬åŒ–ä¸º gensim.models.keyedvectors.KeyedVectors ï¼Œ  4.8 expand_dictionary() ct.expand_dictionary(wv, seeddict, topn=100)  wv é¢„è®­ç»ƒæ¨¡å‹ï¼Œæ•°æ®ç±»å‹ä¸º gensim.models.keyedvectors.KeyedVectorsã€‚ seeddict å‚æ•°ç±»ä¼¼äºç§å­è¯ï¼›æ ¼å¼ä¸º PYTHON å­—å…¸ï¼› topn è¿”å› topn ä¸ªè¯­ä¹‰æœ€æ¥è¿‘ seeddict çš„è¯  æ ¹æ®è®¾ç½®çš„ seeddict, å¯æŒ‰ç±»åˆ«æ‰©å±•å¹¶ç”Ÿæˆå¯¹åº”çš„è¯å…¸ txt æ–‡ä»¶ï¼Œ txt æ–‡ä»¶ä½äº[output]æ–‡ä»¶å¤¹å†…ã€‚\nseeddict = { 'äººç‰©': ['å¶æ–‡æ´', 'å²å¼º', 'ç½—è¾‘'], 'ç‰©ä½“': ['é£èˆ¹', 'è½¦è¾†'] } ct.expand_dictionary(wv=santi_w2v.wv, seeddict=seeddict, topn=10) äº”ã€Mind æ¨¡å— è¯åµŒå…¥ä¸­è•´å«ç€äººç±»çš„è®¤çŸ¥ä¿¡æ¯ï¼Œä»¥å¾€çš„è¯åµŒå…¥å¤§å¤šæ˜¯æ¯”è¾ƒä¸€ä¸ªæ¦‚å¿µä¸­ä¸¤ç»„åä¹‰è¯ä¸æŸå¯¹è±¡çš„è·ç¦»è®¡ç®—è®¤çŸ¥ä¿¡æ¯ã€‚\n  å¤šä¸ªå¯¹è±¡ä¸æŸæ¦‚å¿µçš„è¯­ä¹‰è¿œè¿‘ï¼ŒèŒä¸šä¸æ€§åˆ«ï¼ŒæŸä¸ªèŒä¸šæ˜¯å¦å­˜åœ¨äº²è¿‘ç”·æ€§ï¼Œè€Œæ’æ–¥å¥³æ€§\n  å¤šä¸ªå¯¹è±¡åœ¨æŸæ¦‚å¿µå‘é‡æŠ•å½±çš„å¤§å°ï¼Œ äººç±»è¯­è¨€ä¸­ç•™å­˜ç€å¯¹ä¸åŒåŠ¨ç‰©ä½“ç§¯çš„è®¤çŸ¥è®°å¿†ï¼Œå¦‚å°é¼ å¤§è±¡ã€‚åŠ¨ç‰©è¯åœ¨è¯å‘é‡ç©ºé—´ä¸­æ˜¯å¦èƒ½ç•™å­˜ç€è¿™ç§å¤§å°çš„è®°å¿†\n  æœ¬æ¨¡å—ä¸»è¦æ˜¯åˆ©ç”¨å·²è®­ç»ƒå‡ºçš„ word2vec æ¨¡å‹ï¼ŒæŒ–æ˜æ½œåœ¨çš„æ€åº¦åè§ã€åˆ»æ¿å°è±¡ç­‰ã€‚ è¿™éƒ¨åˆ†éš¾åº¦è¾ƒå¤§ï¼Œ å»ºè®®æœ‰ç²¾åŠ›ä¸”ç”µè„‘æ€§èƒ½å¥½çš„åŒå­¦å¯ä»¥ç”¨ cntext è®­ç»ƒæ¨¡å‹ï¼Œ å†æ¥å®éªŒ Mind æ¨¡å—ã€‚\n   æ¨¡å— å‡½æ•°(ç±») åŠŸèƒ½     mind ct.semantic_centroid(wv, words) è®¡ç®—å¤šä¸ªè¯è¯­çš„è¯­ä¹‰ä¸­å¿ƒå‘é‡   mind ct.generate_concept_axis(wv, poswords, negwords) ç”Ÿæˆæ¦‚å¿µè½´å‘é‡ã€‚   mind sematic_projection(wv, words, poswords, negwords) æµ‹é‡è¯­ä¹‰æŠ•å½±   mind ct.project_word(wv, a, b, cosine=False) åœ¨è¯å‘é‡ç©ºé—´ä¸­ï¼Œ è®¡ç®—è¯è¯­ a åœ¨è¯è¯­ b ä¸Šçš„æŠ•å½±   mind ct.project_text(wv, text, axis, lang='chinese', cosine=False) è®¡ç®—è¯è¯­æ–‡æœ¬textåœ¨æ¦‚å¿µè½´å‘é‡axisä¸Šçš„æŠ•å½±å€¼   mind ct.sematic_distance(wv, words1, words2) æµ‹é‡è¯­ä¹‰è·ç¦»   mind ct.divergent_association_task(wv, words) æµ‹é‡å‘æ•£æ€ç»´(åˆ›é€ åŠ›)   mind ct.discursive_diversity_score(wv, words) æµ‹é‡è¯­è¨€å·®å¼‚æ€§(è®¤çŸ¥å·®å¼‚æ€§)   mind ct.procrustes_align(base_wv, other_wv) ä¸¤ä¸ª word2vec è¿›è¡Œè¯­ä¹‰å¯¹é½ï¼Œå¯ååº”éšæ—¶é—´çš„ç¤¾ä¼šè¯­ä¹‰å˜è¿    5.1 semantic_centroid(wv, words) è®¡ç®—å¤šä¸ªè¯è¯­çš„è¯­ä¹‰ä¸­å¿ƒå‘é‡\nimport cntext as ct # è·å–è¯å‘é‡æ–‡ä»¶ https://cntext.readthedocs.io/zh-cn/latest/embeddings.html w2v = ct.load_w2v('ä¸“åˆ©æ‘˜è¦-Word2Vec.200.15.bin') semantic_centroid(wv=w2v, words=['åˆ›æ–°', 'é¢ è¦†']) Run\narray([ 0.15567462, -0.05117003, -0.18534171, 0.20808656, -0.01133028, 0.10738188, -0.02571066, 0.06051835, 0.00107351, 0.08017981, 0.08914138, 0.01845527, 0.06232869, -0.03851539, -0.17092938, 0.02196799, -0.04136903, 0.11350462, -0.09539546, 0.04907424, 0.01268489, 0.05294977, 0.08449743, -0.02762416, 0.02332745, 0.08865491, -0.06260188, -0.0378293 , 0.04771722, 0.05745243, 0.04417403, -0.04126203, -0.02403288, -0.03834526, 0.08115771, 0.01508994, 0.07678635, 0.01395652, 0.1360324 , 0.03027042, -0.02819572, 0.02339242, 0.11504567, 0.02910597, 0.06149592, 0.01126606, -0.10132807, 0.07762785, -0.01214836, 0.03780747, 0.12758181, -0.03115267, -0.19343086, -0.21930983, 0.05253006, -0.01452067, -0.07067247, -0.04237257, -0.08911953, 0.08573315, 0.02742999, 0.05392318, 0.02916237, 0.04465031, -0.0788566 , -0.07088121, 0.03111146, 0.00387428, -0.04032568, 0.14935694, -0.03880607, 0.07259471, 0.01711774, -0.05551507, 0.01039889, 0.00666137, 0.03313185, 0.03169986, 0.08127907, 0.0239668 , -0.00991806, -0.04201584, 0.01199235, -0.08669737, -0.02087858, -0.03440931, 0.02360864, 0.06623896, -0.01020982, 0.01200165, 0.01059455, 0.13041293, 0.01103112, 0.03814259, -0.01519256, 0.02946554, 0.00593279, 0.08796389, 0.0198915 , -0.0569265 , -0.14622693, 0.07680258, -0.02288322, -0.04959924, 0.03325186, 0.11031196, 0.06893978, 0.04289736, -0.0307357 , -0.09662723, 0.02554002, 0.05394766, 0.047071 , -0.09522557, -0.08160087, -0.01467315, -0.01304489, 0.07513782, 0.04484766, -0.0516454 , 0.00648148, 0.01093231, -0.00303798, -0.06217093, 0.02755075, -0.10749754, -0.05205868, -0.02562402, 0.09068517, 0.05208463, -0.11790312, 0.02881086, -0.02414756, 0.00192055, 0.03881926, -0.05390498, 0.06648378, 0.02055933, -0.07083403, -0.07248309, -0.12991821, 0.0603951 , 0.14131376, -0.01507344, -0.06480791, -0.08994781, -0.03397571, 0.0108852 , -0.02777362, 0.01159309, 0.00121858, -0.0690551 , -0.07747664, 0.03437752, -0.14576062, 0.06320656, -0.10743124, -0.01910913, 0.15803815, -0.03027673, -0.02909171, -0.03350233, -0.0694584 , -0.09807504, -0.09133697, -0.01123043, 0.04894681, -0.01971908, -0.08290677, -0.00336836, 0.09619438, -0.03496556, 0.09733834, -0.0421683 , 0.01408717, 0.03355598, 0.00748263, 0.011903 , -0.12909584, 0.01545653, 0.07656407, 0.09496018, 0.0608537 , 0.00597665, -0.01628997, 0.06285962, -0.16796936, -0.0486528 , 0.01525079, -0.03067709, -0.02952635, -0.02731965, -0.06351878, 0.03577968, 0.0457835 , 0.08370785, -0.03491699, -0.12606403, -0.08686454, -0.04782247]) \n5.2 generate_concept_axis(wv, poswords, negwords) ç”Ÿæˆæ¦‚å¿µè½´å‘é‡ã€‚\n wv ç”Ÿæˆæ¦‚å¿µè½´å‘é‡ã€‚ poswords ç¬¬ä¸€ä¸ªè¯è¯­åˆ—è¡¨ï¼Œè¡¨ç¤ºæ¦‚å¿µæ­£ä¹‰è¯ã€‚ negwords ç¬¬äºŒä¸ªè¯è¯­åˆ—è¡¨ï¼Œè¡¨ç¤ºæ¦‚å¿µåä¹‰è¯ã€‚  éœ€è¦æ³¨æ„ï¼Œ æ¦‚å¿µ 1 ä¸ æ¦‚å¿µ 2 æ˜¯æ€§è´¨(æ–¹å‘)ç›¸åçš„ä¸¤ä¸ªæ¦‚å¿µï¼Œ å¦‚\n æ€§åˆ«(ç”·, å¥³) å°ºå¯¸(å¤§, å°) æ–¹å‘(é«˜, ä½) æ–¹å‘(å‰, å) æ¹¿åº¦(å¹², æ¹¿) è´¢å¯Œ(è´«, å¯Œ)  import cntext as ct # è·å–è¯å‘é‡æ–‡ä»¶ # https://github.com/hiDaDeng/Chinese-Pretrained-Word-Embeddings dm_w2v = ct.load_w2v('douban-movie-1000w-Word2Vec.200.15.bin') gender_axis_vector = ct.generate_concept_axis(wv=dm_w2v, poswords=['ç”·', 'ç”·äºº', 'çˆ¶äº²'], negwords=['å¥³', 'å¥³äºº', 'æ¯äº²']) gender_axis_vector Run\narray([-0.0118976 , 0.03178174, -0.04656127, 0.00613294, -0.03692355, -0.06293361, -0.04739443, 0.01368712, 0.02603469, -0.02268519, -0.09925436, 0.05780286, 0.11218373, 0.07519485, 0.06885784, 0.05505687, -0.04097392, 0.1737831 , 0.05118835, -0.06879821, 0.04762978, 0.02224233, -0.04891564, -0.08712718, -0.01432874, -0.07395219, 0.01229804, 0.06655715, -0.01864985, -0.04864848, 0.00260787, 0.06843776, 0.00472286, 0.03623124, 0.11959086, -0.04683099, -0.11005358, 0.0271024 , -0.05976011, 0.12669185, 0.03592191, -0.01125782, -0.02587771, -0.02719228, 0.0507662 , -0.09198377, 0.09546432, -0.01937146, 0.06106697, -0.0405688 , -0.1311393 , 0.06090249, 0.03515694, 0.01364273, -0.02491697, 0.03379048, -0.06635275, 0.01432849, 0.01212378, -0.0625283 , -0.03481676, -0.0422427 , -0.17145215, -0.06323837, 0.02563147, -0.02371969, 0.01217621, -0.00346871, 0.07024875, 0.08295133, 0.00731711, -0.01932047, 0.02165518, -0.09927654, -0.08531073, 0.01949702, 0.00536061, 0.10426087, -0.02010326, 0.02297032, -0.10657956, 0.1035546 , 0.00569263, -0.0849498 , 0.1098236 , 0.05310893, -0.0802139 , -0.01034231, -0.12204715, 0.01407488, -0.01781198, -0.0134118 , 0.09836894, 0.16098371, 0.00609895, 0.05433145, -0.08940306, 0.00136946, -0.08455469, -0.08432727, 0.04675778, -0.03415223, -0.18552355, -0.05219543, -0.01127822, 0.02059881, -0.08120015, -0.15610164, 0.01439221, 0.01727759, -0.14516874, 0.01783531, -0.13099317, 0.03820422, 0.03033866, -0.01779634, 0.07759558, 0.15866944, 0.00191632, -0.00905253, 0.0312649 , -0.05698524, 0.07270953, -0.00734233, 0.06289094, 0.01014149, -0.0052088 , 0.02478063, -0.0112649 , -0.0930789 , 0.14639418, -0.08183327, -0.08392337, -0.01458992, -0.0163887 , 0.06790476, -0.03252221, 0.08593727, 0.10469338, -0.01363467, 0.00749907, -0.01320484, 0.08405331, 0.0489707 , -0.11343482, -0.10319041, -0.02415894, 0.13382405, -0.01983603, -0.00990637, -0.03335103, 0.11718886, -0.05802442, -0.18935862, -0.07409969, -0.08306517, -0.04423901, 0.11331058, 0.00588326, 0.06339834, 0.04405889, 0.1263905 , -0.007273 , -0.02706875, 0.02325469, -0.13092995, 0.02056245, -0.0442118 , -0.01964739, -0.06501938, 0.02196051, -0.1823353 , 0.04273191, 0.01935809, -0.01464438, -0.02626805, 0.09194217, 0.02489716, 0.05376589, -0.00484252, 0.02822759, 0.06744799, -0.14196248, 0.03016541, -0.05347864, -0.16907257, 0.05094757, 0.0721257 , -0.00421157, 0.03022675, -0.00047884, 0.07792547, -0.00209365, 0.0669208 , 0.02009218, 0.11358768, -0.05002993, 0.01760067, 0.03407429, -0.0893421 ], dtype=float32) \n5.3 sematic_distance() å¤šä¸ªå¯¹è±¡ä¸æŸæ¦‚å¿µçš„è¯­ä¹‰è¿œè¿‘ï¼Œä¾‹å¦‚æˆåŠŸä¸æ€§åˆ«ï¼ŒæˆåŠŸæ˜¯å¦å­˜åœ¨äº²è¿‘ç”·æ€§ï¼Œè€Œæ’æ–¥å¥³æ€§\nct.sematic_distance(wv, words1, words2)  wv æ¨¡å‹æ•°æ®ï¼Œ æ•°æ®ç±»å‹ä¸º gensim.models.keyedvectors.KeyedVectorsã€‚ words1ã€words2 å‡ä¸ºè¯è¯­åˆ—è¡¨  åˆ†åˆ«è®¡ç®— words1 ä¸ words2 è¯­ä¹‰è·ç¦»ï¼Œè¿”å›è·ç¦»å·®å€¼ã€‚ä¾‹å¦‚\nmale_concept = ['male', 'man', 'he', 'him'] female_concept = ['female', 'woman', 'she', 'her'] engineer_concept = ['engineer', 'programming', 'software'] dist(male, engineer) = distance(male_concept, engineer_concept) dist(female, engineer) = distance(female_concept, engineer_concept) å¦‚æœ dist(male, engineer)-dist(female, engineer)ï¼Œè¯´æ˜åœ¨è¯­ä¹‰ç©ºé—´ä¸­ï¼Œengineer_concept æ›´æ¥è¿‘ male_concept ï¼Œæ›´è¿œç¦» female_concept ã€‚\næ¢è¨€ä¹‹ï¼Œåœ¨è¯¥è¯­æ–™ä¸­ï¼Œäººä»¬å¯¹è½¯ä»¶å·¥ç¨‹å¸ˆè¿™ä¸€ç±»å·¥ä½œï¼Œå¯¹å¥³æ€§å­˜åœ¨åˆ»æ¿å°è±¡(åè§)ã€‚\nimport cntext as ct # glove_w2v.6B.100d.txté“¾æ¥: https://pan.baidu.com/s/1MMfQ7M0YCzL9Klp4zrlHBw æå–ç : 72l0 g_wv = ct.load_w2v('data/glove_w2v.6B.100d.txt') engineer = ['program', 'software', 'computer'] man_words = [\"man\", \"he\", \"him\"] woman_words = [\"woman\", \"she\", \"her\"] dist_male_engineer = ct.sematic_distance(male_concept, engineer_concept) dist_female_engineer = ct.sematic_distance(female_concept, engineer_concept) dist_male_engineer - dist_female_engineer Run\n-0.5 dist_male_engineer 5.4 sematic_projection() å¤šä¸ªå¯¹è±¡åœ¨æŸæ¦‚å¿µå‘é‡æŠ•å½±çš„å¤§å°\nct.sematic_projection(wv, words, poswords, negwords, return_full=False, cosine=False)  wv æ¨¡å‹æ•°æ®ï¼Œ æ•°æ®ç±»å‹ä¸º gensim.models.keyedvectors.KeyedVectorsã€‚ wordsã€poswordsã€negwords å‡ä¸ºè¯è¯­åˆ—è¡¨ cosine: æ˜¯å¦ä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦ï¼Œé»˜è®¤ä¸ºFalseï¼Œè¿”å›æŠ•å½±å€¼ï¼›Trueæ—¶è¿”å›ä½™å¼¦ç›¸ä¼¼åº¦ return_full: æ˜¯å¦è¿”å›å®Œæ•´å…ƒç»„åˆ—è¡¨ï¼Œé»˜è®¤ä¸ºTrue  ä¸ºäº†è§£é‡Šè¯å‘é‡æ¨¡å‹çš„è¯­ä¹‰æŠ•å½±ï¼Œæˆ‘ä½¿ç”¨äº† 2022 å¹´ Nature è®ºæ–‡ä¸­çš„å›¾ç‰‡[@Grand2022SemanticPR]ã€‚ å…³äºåŠ¨ç‰©çš„åå­—ï¼Œäººç±»å¯¹åŠ¨ç‰©å¤§å°çš„è®¤çŸ¥ä¿¡æ¯éšè—åœ¨è¯­æ–™åº“æ–‡æœ¬ä¸­ã€‚ é€šè¿‡å°†LARGE WORDS å’ŒSMALL WORDSçš„å«ä¹‰ç”¨ä¸åŒçš„animalsçš„å‘é‡æŠ•å½±ï¼ŒåŠ¨ç‰©åœ¨size å‘é‡ä¸Šçš„æŠ•å½±ï¼ˆå°±åƒä¸‹å›¾ä¸­çš„çº¢çº¿ ) å¾—åˆ°ï¼Œå› æ­¤å¯ä»¥é€šè¿‡è®¡ç®—æ¯”è¾ƒåŠ¨ç‰©çš„å¤§å°ã€‚\næ ¹æ®ä¸¤ç»„åä¹‰è¯ poswords , negwords æ„å»ºä¸€ä¸ªæ¦‚å¿µ(è®¤çŸ¥)å‘é‡, words ä¸­çš„æ¯ä¸ªè¯å‘é‡åœ¨æ¦‚å¿µå‘é‡ä¸­æŠ•å½±ï¼Œå³å¯å¾—åˆ°è®¤çŸ¥ä¿¡æ¯ã€‚\nåˆ†å€¼è¶Šå¤§ï¼Œwords è¶Šä½äº poswords ä¸€ä¾§ã€‚\n Grand, G., Blank, I.A., Pereira, F. and Fedorenko, E., 2022. Semantic projection recovers rich human knowledge of multiple object features from word embeddings. Nature Human Behaviour, pp.1-13.\"\n ä¾‹å¦‚ï¼Œäººç±»çš„è¯­è¨€ä¸­ï¼Œå­˜åœ¨å°ºå¯¸ã€æ€§åˆ«ã€å¹´é¾„ã€æ”¿æ²»ã€é€Ÿåº¦ã€è´¢å¯Œç­‰ä¸åŒçš„æ¦‚å¿µã€‚æ¯ä¸ªæ¦‚å¿µå¯ä»¥ç”±ä¸¤ç»„åä¹‰è¯ç¡®å®šæ¦‚å¿µçš„å‘é‡æ–¹å‘ã€‚\nä»¥å°ºå¯¸ä¸ºä¾‹ï¼ŒåŠ¨ç‰©åœ¨äººç±»è®¤çŸ¥ä¸­å¯èƒ½å­˜åœ¨ä½“ç§¯å°ºå¯¸å¤§å°å·®å¼‚ã€‚\nimport cntext as ct animals = ['mouse', 'cat', 'horse', 'pig', 'whale'] small_words= [\"small\", \"little\", \"tiny\"] large_words = [\"large\", \"big\", \"huge\"] # wiki_wv = ct.load_w2v('wikiçš„word2vecæ¨¡å‹æ–‡ä»¶è·¯å¾„') # wiki_wv # In size conception, mouse is smallest, horse is biggest. # åœ¨å¤§å°æ¦‚å¿µä¸Šï¼Œè€é¼ æœ€å°ï¼Œé©¬æ˜¯æœ€å¤§çš„ã€‚ ct.sematic_projection(wv=wiki_wv, words=animals, poswords=large_words, negwords=small_words, ) Run\n[('mouse', -1.68), ('cat', -0.92), ('pig', -0.46), ('whale', -0.24), ('horse', 0.4)] å…³äºå°ºå¯¸çš„è®¤çŸ¥ï¼Œäººç±»åœ¨æ–‡æœ¬ä¸­éšå«ç€è€é¼ è¾ƒå°ï¼Œé©¬è¾ƒå¤§ã€‚\n5.5 project_word åœ¨å‘é‡ç©ºé—´ä¸­ï¼Œ è®¡ç®—è¯è¯­aåœ¨è¯è¯­bä¸Šçš„æŠ•å½±(ä½™å¼¦ç›¸ä¼¼åº¦)ã€‚é»˜è®¤è¿”å›çš„æ˜¯æŠ•å½±å€¼ã€‚ å¦‚æœ cosine=Trueï¼Œè¿”å›è¯è¯­aä¸è¯è¯­bçš„ä½™å¼¦ç›¸ä¼¼åº¦ã€‚\nproject_word(wv, a, b, cosine=False)  wv è¯­æ–™ txt æ–‡ä»¶è·¯å¾„ a è¯è¯­ a å­—ç¬¦ä¸²æˆ–åˆ—è¡¨ b è¯è¯­å­—ç¬¦ä¸²ã€è¯è¯­åˆ—è¡¨ã€æˆ–æŸæ¦‚å¿µå‘é‡ cosine: æ˜¯å¦ä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦ï¼Œ é»˜è®¤ä¸ºFalseï¼Œè¿”å›aåœ¨bä¸Šçš„æŠ•å½±å€¼ï¼› Trueæ—¶ï¼Œè¿”å›aä¸bçš„ä½™å¼¦ç›¸ä¼¼åº¦ã€‚  b='è‹—æ¡' for a in ['æ€§æ„Ÿ','ç¾ä¸½', 'å¯çˆ±', 'ä¸‘é™‹']: proj = ct.project_word(dm_w2v, a, b) print(f'[{a}]åœ¨[{b}]æŠ•å½±å€¼: {proj}') b='ä¿®é•¿' for a in ['æ€§æ„Ÿ','ç¾ä¸½', 'å¯çˆ±', 'ä¸‘é™‹']: proj = ct.project_word(dm_w2v, a, b) print(f'[{a}]åœ¨[{b}]æŠ•å½±å€¼: {proj}') Run\n[æ€§æ„Ÿ]åœ¨[è‹—æ¡]æŠ•å½±å€¼: 14.172947883605957 [ç¾ä¸½]åœ¨[è‹—æ¡]æŠ•å½±å€¼: 7.0944623947143555 [å¯çˆ±]åœ¨[è‹—æ¡]æŠ•å½±å€¼: 6.935092926025391 [ä¸‘é™‹]åœ¨[è‹—æ¡]æŠ•å½±å€¼: 1.235807180404663 [æ€§æ„Ÿ]åœ¨[ä¿®é•¿]æŠ•å½±å€¼: 14.599699974060059 [ç¾ä¸½]åœ¨[ä¿®é•¿]æŠ•å½±å€¼: 9.360642433166504 [å¯çˆ±]åœ¨[ä¿®é•¿]æŠ•å½±å€¼: 4.740543842315674 [ä¸‘é™‹]åœ¨[ä¿®é•¿]æŠ•å½±å€¼: 4.010622501373291 å¯ä»¥çœ‹åˆ°ï¼Œ åœ¨è±†ç“£ç”µå½±è¯­æ–™ä¸­ï¼Œ åœ¨[è‹—æ¡ã€ä¿®é•¿]ç»´åº¦çš„è®¤çŸ¥ä¸­ï¼Œéƒ½è®¤ä¸º\n [æ€§æ„Ÿ]æ„å‘³ç€èº«ææœ€ç˜¦é•¿ [ç¾ä¸½]æ¬¡ä¹‹ã€[å¯çˆ±]ç•¥æ˜¾ä¸é‚£ä¹ˆä¿®é•¿è‹—æ¡ [ä¸‘é™‹]æ„å‘³ç€åŸºæœ¬ä¸[è‹—æ¡ã€ä¿®é•¿]æ— å…³ï¼Œæ•°å€¼æœ€å°ã€‚  ä¸ºäº†è®©æŠ•å½±å€¼æ›´ç¨³å®šï¼Œå¯ä»¥é€‰æ‹©è¯ç»„ï¼Œç¡®å®š[è‹—æ¡ã€ä¿®é•¿]è¿™ä¸ªæ¦‚å¿µçš„æ¦‚å¿µè½´å‘é‡\nfor a in ['æ€§æ„Ÿ','ç¾ä¸½', 'å¯çˆ±', 'ä¸‘é™‹']: proj = ct.project_word(wv=dm_w2v, a=a, b=['ä¿®é•¿', 'è‹—æ¡']) print(f'[{a}]åœ¨[ä¿®é•¿ï¼Œè‹—æ¡]æŠ•å½±å€¼: {proj}') Run\n[æ€§æ„Ÿ]åœ¨[ä¿®é•¿ï¼Œè‹—æ¡]æŠ•å½±å€¼: 15.807487487792969 [ç¾ä¸½]åœ¨[ä¿®é•¿ï¼Œè‹—æ¡]æŠ•å½±å€¼: 9.040315628051758 [å¯çˆ±]åœ¨[ä¿®é•¿ï¼Œè‹—æ¡]æŠ•å½±å€¼: 6.414511203765869 [ä¸‘é™‹]åœ¨[ä¿®é•¿ï¼Œè‹—æ¡]æŠ•å½±å€¼: 2.882350444793701 \n5.6 project_text() åœ¨å‘é‡ç©ºé—´ä¸­ï¼Œè®¡ç®—æ–‡æœ¬åœ¨æ¦‚å¿µè½´å‘é‡ä¸Šçš„æŠ•å½±å€¼ã€‚\nct.project_text(wv, text, axis, lang='chinese', cosine=False)  wv: è¯­è¨€æ¨¡å‹çš„KeyedVectors text: æ–‡æœ¬å­—ç¬¦ä¸² lang: è¯­è¨€,æœ‰chineseå’Œenglishä¸¤ç§; é»˜è®¤\"chinese\" axis: æ¦‚å¿µå‘é‡ cosine: æŠ•å½±å€¼æ˜¯å¦ä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦ï¼Œ é»˜è®¤ä¸ºFalseï¼Œè¿”å›textåœ¨axisä¸Šçš„æŠ•å½±å€¼ï¼› Trueæ—¶ï¼Œè¿”å›textä¸axisçš„ä½™å¼¦ç›¸ä¼¼åº¦ã€‚  import cntext as ct # 1. è¯»å–è¯åµŒå…¥æ¨¡å‹æ–‡ä»¶ embeddings_model = ct.load_w2v('cntext2xè®­ç»ƒå¾—åˆ°çš„æ¨¡å‹æ–‡ä»¶è·¯å¾„') #dm_w2v = ct.load_w2v('douban-movie-1000w-Word2Vec.200.15.bin') # 2. å®šä¹‰æƒ…ç»ªæ­£è´Ÿè¯è¯­ï¼Œç¡®å®šæƒ…ç»ªæ¦‚å¿µè½´å‘é‡sentiment_axis sentiment_pos = ['å¿«ä¹', 'å¹¸ç¦', 'å–œæ‚¦', 'æ»¡è¶³', 'æ¬£æ…°', 'æ¿€åŠ¨', 'å…´å¥‹', 'æ„Ÿæ©', 'çƒ­çˆ±', 'èµç¾'] sentiment_neg = ['ç—›è‹¦', 'æ‚²ä¼¤', 'éš¾è¿‡', 'å¤±æœ›', 'æ„¤æ€’', 'æ€¨æ¨', 'ç»æœ›', 'ææƒ§', 'ç„¦è™‘', 'å‹æŠ‘'] sentiment_axis = ct.generate_concept_axis(wv = embeddings_model, poswords=sentiment_pos, negwords=sentiment_neg) # 3. åˆ›å»ºå®éªŒæ–‡æœ¬ï¼ˆä»æ­£é¢åˆ°è´Ÿé¢ï¼‰ texts = [ \"ä»Šå¤©é˜³å…‰æ˜åªšï¼Œæˆ‘å’Œå®¶äººä¸€èµ·å‡ºæ¸¸ï¼Œæ„Ÿåˆ°æ— æ¯”å¹¸ç¦å’Œå¿«ä¹ã€‚\", \"å·¥ä½œæœ‰äº†æ–°è¿›å±•ï¼Œå¾—åˆ°äº†é¢†å¯¼çš„è¡¨æ‰¬ï¼Œå†…å¿ƒå……æ»¡æˆå°±æ„Ÿã€‚\", \"è™½ç„¶é‡åˆ°äº†å°æŒ«æŠ˜ï¼Œä½†æˆ‘ä¾ç„¶ä¿æŒä¹è§‚ï¼Œç›¸ä¿¡æ˜å¤©ä¼šæ›´å¥½ã€‚\", \"ç”Ÿæ´»å¹³æ·¡ï¼Œæ²¡ä»€ä¹ˆç‰¹åˆ«çš„äº‹å‘ç”Ÿï¼Œå¿ƒæƒ…ä¸€èˆ¬ã€‚\", \"æœ€è¿‘å‹åŠ›æœ‰ç‚¹å¤§ï¼Œç¡çœ ä¸å¥½ï¼Œæ„Ÿè§‰æœ‰ç‚¹ç„¦è™‘å’Œç–²æƒ«ã€‚\", \"é¡¹ç›®å¤±è´¥äº†ï¼Œè¿˜è¢«é¢†å¯¼æ‰¹è¯„ï¼Œå¿ƒé‡Œéå¸¸éš¾è¿‡å’Œå¤±æœ›ã€‚\", \"äº²äººç¦»ä¸–ï¼Œæˆ‘æ„Ÿåˆ°æåº¦æ‚²ä¼¤å’Œç—›è‹¦ï¼Œä¸–ç•Œä»¿ä½›å¤±å»äº†é¢œè‰²ã€‚\" ] # 4. è®¡ç®—æ¯æ¡æ–‡æœ¬åœ¨æƒ…ç»ªè½´ä¸Šçš„æŠ•å½± print(\"æ–‡æœ¬æƒ…ç»ªæŠ•å½±åˆ†æï¼ˆè¶Šå¤§è¶Šæ­£é¢ï¼‰ï¼š\\n\") results = [] for i, text in enumerate(texts): # ä½¿ç”¨æŠ•å½±å‡½æ•°ï¼ˆè¿”å›åœ¨ axis æ–¹å‘ä¸Šçš„æŠ•å½±å€¼ï¼‰ #project_text(wv, text, axis, lang='chinese', cosine=False) proj_value = ct.project_text(wv=embeddings_model, text=text, axis=sentiment_axis, lang='chinese') results.append((proj_value, text)) print(f\"[{i+1}] æŠ•å½±å€¼: {proj_value:+.4f}| {text}\\n\") # 5. æŒ‰æŠ•å½±å€¼æ’åºï¼ŒæŸ¥çœ‹æƒ…ç»ªå¼ºåº¦æ’åº print(\"\\n\" + \"=\"*60) print(\"æŒ‰æƒ…ç»ªæ­£é¢æ€§æ’åºï¼ˆä»é«˜åˆ°ä½ï¼‰ï¼š\") print(\"=\"*60) for value, text in sorted(results, key=lambda x: x[0], reverse=True): print(f\"{value:+.4f}â†’ {text}\") Run\n[1] æŠ•å½±å€¼: +0.8213 | ä»Šå¤©é˜³å…‰æ˜åªšï¼Œæˆ‘å’Œå®¶äººä¸€èµ·å‡ºæ¸¸ï¼Œæ„Ÿåˆ°æ— æ¯”å¹¸ç¦å’Œå¿«ä¹ã€‚ [2] æŠ•å½±å€¼: +0.5641 | å·¥ä½œæœ‰äº†æ–°è¿›å±•ï¼Œå¾—åˆ°äº†é¢†å¯¼çš„è¡¨æ‰¬ï¼Œå†…å¿ƒå……æ»¡æˆå°±æ„Ÿã€‚ [3] æŠ•å½±å€¼: +0.1205 | è™½ç„¶é‡åˆ°äº†å°æŒ«æŠ˜ï¼Œä½†æˆ‘ä¾ç„¶ä¿æŒä¹è§‚ï¼Œç›¸ä¿¡æ˜å¤©ä¼šæ›´å¥½ã€‚ [4] æŠ•å½±å€¼: -0.0321 | ç”Ÿæ´»å¹³æ·¡ï¼Œæ²¡ä»€ä¹ˆç‰¹åˆ«çš„äº‹å‘ç”Ÿï¼Œå¿ƒæƒ…ä¸€èˆ¬ã€‚ [5] æŠ•å½±å€¼: -0.3178 | æœ€è¿‘å‹åŠ›æœ‰ç‚¹å¤§ï¼Œç¡çœ ä¸å¥½ï¼Œæ„Ÿè§‰æœ‰ç‚¹ç„¦è™‘å’Œç–²æƒ«ã€‚ [6] æŠ•å½±å€¼: -0.6124 | é¡¹ç›®å¤±è´¥äº†ï¼Œè¿˜è¢«é¢†å¯¼æ‰¹è¯„ï¼Œå¿ƒé‡Œéå¸¸éš¾è¿‡å’Œå¤±æœ›ã€‚ [7] æŠ•å½±å€¼: -0.9012 | äº²äººç¦»ä¸–ï¼Œæˆ‘æ„Ÿåˆ°æåº¦æ‚²ä¼¤å’Œç—›è‹¦ï¼Œä¸–ç•Œä»¿ä½›å¤±å»äº†é¢œè‰²ã€‚ \n5.7 divergent_association_task() PNAS | ä½¿ç”¨è¯­ä¹‰è·ç¦»æµ‹é‡ä¸€ä¸ªäººçš„åˆ›æ–°åŠ›(å‘æ•£æ€ç»´)å¾—åˆ†ã€‚ä¸€äº›ç†è®ºè®¤ä¸ºï¼Œæœ‰ åˆ›é€ åŠ› çš„äººèƒ½å¤Ÿäº§ç”Ÿæ›´å¤š å‘æ•£æ€§ çš„æƒ³æ³•ã€‚å¦‚æœè¿™æ˜¯æ­£ç¡®çš„ï¼Œç®€å•åœ°è®©è¢«è¯•å†™ N ä¸ªä¸ç›¸å…³çš„å•è¯ï¼Œç„¶åæµ‹é‡è¿™ N ä¸ªè¯çš„è¯­ä¹‰è·ç¦»ï¼Œ ä½œä¸ºå‘æ•£æ€ç»´çš„å®¢è§‚è¡¡é‡æ ‡å‡†ã€‚\nct.divergent_association_task(wv, words)  wv æ¨¡å‹æ•°æ®ï¼Œ æ•°æ®ç±»å‹ä¸º gensim.models.keyedvectors.KeyedVectorsã€‚ wordsè¯è¯­åˆ—è¡¨  low_words = [\"arm\", \"eyes\", \"feet\", \"hand\", \"head\", \"leg\", \"body\"] average_words = [\"bag\", \"bee\", \"burger\", \"feast\", \"office\", \"shoes\", \"tree\"] high_words = [\"hippo\", \"jumper\", \"machinery\", \"prickle\", \"tickets\", \"tomato\", \"violin\"] # å¯¼å…¥æ¨¡å‹ï¼Œå¾—åˆ°wvã€‚ # wv = ct.load_w2v('wikiçš„word2vecæ¨¡å‹æ–‡ä»¶è·¯å¾„') print(ct.divergent_association_task(wv, low_words)) # 50 print(ct.divergent_association_task(wv, average_words)) # 78 print(ct.divergent_association_task(wv, high_words)) # 95 Run\n50 78 95 \n5.8 discursive_diversity_score() MS2022 | ä½¿ç”¨è¯­è¨€å·®å¼‚æ€§æµ‹é‡å›¢é˜Ÿè®¤çŸ¥å·®å¼‚æ€§\nct.discursive_diversity_score(wv, words)  wv æ¨¡å‹æ•°æ®ï¼Œ æ•°æ®ç±»å‹ä¸º gensim.models.keyedvectors.KeyedVectorsã€‚ **words**è¯è¯­åˆ—è¡¨ è¿”å›ä¸€ä¸ªæ•°å€¼  é«˜ç»©æ•ˆå›¢é˜Ÿæ˜¯é‚£äº›å…·æœ‰è°ƒèŠ‚å…±äº«è®¤çŸ¥ä»¥é€‚åº”ä¸æ–­å˜åŒ–çš„ä»»åŠ¡è¦æ±‚çš„é›†ä½“èƒ½åŠ›çš„å›¢é˜Ÿï¼šåœ¨è¿›è¡Œæ„æ€ä»»åŠ¡æ—¶ï¼Œå®ƒä»¬è¡¨ç°å‡ºæ›´é«˜çš„è¯è¯­å¤šæ ·æ€§ï¼Œåœ¨æ‰§è¡Œåè°ƒä»»åŠ¡æ—¶ï¼Œè¡¨ç°å‡ºè¾ƒä½çš„è¯è¯­å¤šæ ·æ€§ã€‚\n5.8 procrustes_align() è¯¥å‡½æ•°ä¸»è¦ç”¨äºåæ˜ åŒä¸€ç ”ç©¶å¯¹è±¡éšç€æ—¶é—´æ¨è¿›çš„ç¤¾ä¼šæ–‡åŒ–å˜è¿ï¼Œæˆ–è€…åŒä¸€æ—¶é—´èŒƒå›´å†…ä¸¤ä¸ªè¢«ç ”ç©¶ä¸»ä½“é—´çš„å·®å¼‚ã€‚\nct.procrustes_align(base_wv, other_wv, words=None)  base_wv (gensim.models.keyedvectors.KeyedVectors): åŸºå‡†è¯­è¨€æ¨¡å‹ other_wv (gensim.models.keyedvectors.KeyedVectors): å…¶ä»–è¯­è¨€æ¨¡å‹ words (list, optional): æ˜¯å¦æ ¹æ®è¯å…¸ words å¯¹æ¨¡å‹è¿›è¡Œå¯¹é½ï¼Œ å¯¹é½ç»“æŸåçš„æ¨¡å‹ä¸­å«æœ‰çš„è¯ä¸ä¼šè¶…å‡º words çš„èŒƒå›´ï¼› é»˜è®¤ None.  ç”±äºä¸åŒè¯­æ–™è®­ç»ƒçš„ Word2Vec æ¨¡å‹æ— æ³•ç›´æ¥æ¯”è¾ƒï¼Œ éœ€è¦å…ˆé€‰å®šä¸€ä¸ªåŸºå‡†æ¨¡å‹ base_embedï¼Œ ä¹‹åæ ¹æ® base_embed å¯¹å…¶ä»–æ¨¡å‹ other_embed è¿›è¡Œè°ƒæ•´ï¼Œè°ƒæ•´åçš„æ¨¡å‹å°±å¯ä»¥ä½¿ç”¨å‰é¢çš„è¯­ä¹‰è·ç¦»å‡½æ•°æˆ–è€…è¯­ä¹‰æŠ•å½±å‡½æ•°ã€‚ è¿™ä¸€è¿‡ç¨‹ç”¨åˆ°çš„ç®—æ³•å«åš procrustes æ­£äº¤ç®—æ³•ã€‚\nè¿™é‡Œæ¨èä¸€ç¯‡ å¯è§†åŒ– | äººæ°‘æ—¥æŠ¥è¯­æ–™åæ˜ ä¸ƒåå¹´æ–‡åŒ–æ¼”å˜\n\nå…­ã€LLM æ¨¡å— ç›®å‰å¤§æ¨¡å‹æœ¬åœ°åŒ–ä½¿ç”¨è¶Šæ¥è¶Šæ–¹ä¾¿ï¼Œ\n   æ¨¡å— å‡½æ•°(ç±») åŠŸèƒ½     LLM ct.llm(text, prompt, output_format, task, backend, base_url, api_key, model_name, temperature) è°ƒç”¨å¤§æ¨¡å‹æ‰§è¡Œç»“æ„åŒ–æ–‡æœ¬åˆ†æä»»åŠ¡ï¼ˆå¦‚æƒ…æ„Ÿåˆ†æã€å…³é”®è¯æå–ã€åˆ†ç±»ç­‰ï¼‰ã€‚    6.1 ct.llm() ä½¿ç”¨å¤§æ¨¡å‹ï¼ˆæœ¬åœ°æˆ– APIï¼‰è¿›è¡Œæ–‡æœ¬åˆ†æï¼Œä»éç»“æ„åŒ–çš„æ–‡æœ¬æ•°æ®ä¸­è¯†åˆ«æ¨¡å¼ã€æå–å…³é”®ä¿¡æ¯ã€ç†è§£è¯­ä¹‰ï¼Œå¹¶å°†å…¶è½¬åŒ–ä¸ºç»“æ„åŒ–æ•°æ®ä»¥ä¾¿è¿›ä¸€æ­¥åˆ†æå’Œåº”ç”¨ã€‚\nct.llm(text, prompt, output_format, task, backend, base_url, api_key, model_name, temperature)  text: å¾…åˆ†æçš„æ–‡æœ¬å†…å®¹ task: é¢„è®¾ä»»åŠ¡åç§°ï¼Œé»˜è®¤ä¸º â€˜sentimentâ€™ã€‚ prompt: è‡ªå®šä¹‰ç³»ç»Ÿæç¤ºè¯­ output_format: è‡ªå®šä¹‰è¾“å‡ºç»“æ„ï¼Œå¦‚ {â€˜labelâ€™: str, â€˜scoreâ€™: float} backend: å¿«æ·åç«¯åˆ«åï¼š - â€˜ollamaâ€™ â†’ http://127.0.0.1:11434/v1 - â€˜lmstudioâ€™ æˆ– â€˜lmsâ€™ â†’ http://localhost:1234/v1 - None â†’ éœ€é…åˆ base_url ä½¿ç”¨ base_url: è‡ªå®šä¹‰æ¨¡å‹æœåŠ¡åœ°å€ï¼Œä¼˜å…ˆçº§é«˜äº backend ç¤ºä¾‹ï¼š - è¿œç¨‹ï¼šhttps://dashscope.aliyuncs.com/compatible-mode/v1 - å†…ç½‘ï¼šhttp://192.168.1.10:11434/v1 - æœ¬åœ°ï¼šhttp://localhost:1234/v1 api_key: API å¯†é’¥ï¼Œè¿œç¨‹æœåŠ¡å¿…å¡«ï¼Œæœ¬åœ°é€šå¸¸ä¸º â€œEMPTYâ€ model_name: æ¨¡å‹åç§°ï¼ˆéœ€æœåŠ¡ç«¯å·²åŠ è½½ï¼‰ temperature: ç”Ÿæˆæ¸©åº¦ï¼Œ0 è¡¨ç¤ºç¡®å®šæ€§è¾“å‡º  å®éªŒæ•°æ®ä¸ºå¤–å–è¯„è®ºï¼Œ ä»Šå¤©å’±ä»¬åšä¸ªæœ‰éš¾åº¦çš„æ–‡æœ¬åˆ†æä»»åŠ¡ï¼Œä»ä¸åŒç»´åº¦(å‘³é“ã€é€Ÿåº¦ã€æœåŠ¡)å¯¹å¤–å–è¯„è®ºè¿›è¡Œæ‰“åˆ†(-1.0~1.0)ã€‚\nimport cntext as ct PROMPT = 'ä»å£å‘³tasteã€é€Ÿåº¦speedã€æœåŠ¡serviceä¸‰ä¸ªç»´åº¦ï¼Œ å¯¹å¤–å–è¯„è®ºå†…å®¹è¿›è¡Œæ–‡æœ¬åˆ†æï¼Œ åˆ†åˆ«è¿”å›ä¸åŒç»´åº¦çš„åˆ†å€¼(åˆ†å€¼èŒƒå›´-1.0 ~ 1.0)' BASE_URL = 'https://dashscope.aliyuncs.com/compatible-mode/v1' API_KEY = 'ä½ çš„API-KEY' MODEL_NAME = 'qwen-max' #å‘³é“ã€é€Ÿåº¦ã€æœåŠ¡ OUTPUT_FORMAT = {'taste': float, 'speed': float, 'service': float} COMMENT_CONTENT = 'å¤ªéš¾åƒäº†' # ä½¿ç”¨ # result = ct.llm(text=COMMENT_CONTENT, # æˆ– result = ct.llm(text=COMMENT_CONTENT, prompt=PROMPT, base_url=BASE_URL, api_key=API_KEY, model_name=MODEL_NAME, temperature=0, output_format=OUTPUT_FORMAT) result Run\n{'taste': -1.0, 'speed': 0.0, 'service': 0.0} \næ‰¹é‡è¿ç®—\nimport pandas as pd import cntext as ct # æ„é€ å®éªŒæ•°æ® data = ['é€Ÿåº¦éå¸¸å¿«ï¼Œå£å‘³éå¸¸å¥½ï¼Œ æœåŠ¡éå¸¸æ£’ï¼', 'é€é¤æ—¶é—´è¿˜æ˜¯æ¯”è¾ƒä¹…', 'é€å•å¾ˆå¿«ï¼Œèœä¹Ÿä¸é”™èµ', 'å¤ªéš¾åƒäº†'] df = pd.DataFrame(data, columns=['comment']) # åˆ†æå‡½æ•° def llm_analysis(text): result = ct.llm(text=text, prompt= 'ä»å£å‘³tasteã€é€Ÿåº¦speedã€æœåŠ¡serviceä¸‰ä¸ªç»´åº¦ï¼Œ å¯¹å¤–å–è¯„è®ºå†…å®¹è¿›è¡Œæ–‡æœ¬åˆ†æï¼Œ åˆ†åˆ«è¿”å›ä¸åŒç»´åº¦çš„åˆ†å€¼(åˆ†å€¼èŒƒå›´-1.0 ~ 1.0)', base_url='https://dashscope.aliyuncs.com/compatible-mode/v1', api_key='ä½ çš„API-KEY', model_name='qwen-max', output_format={'taste': float, 'speed': float, 'service': float} ) return pd.Series(result) # æ‰¹é‡è¿ç®— df2 = df['comment'].apply(llm_analysis) res_df = pd.concat([df, df2], axis=1) # ä¿å­˜åˆ†æç»“æœ res_df.to_csv('result.csv', index=False) res_df LLM æ›´å¤šè¯¦ç»†å†…å®¹ï¼Œè¯·é˜…è¯» æ•™ç¨‹ | ä½¿ç”¨åœ¨çº¿å¤§æ¨¡å‹å°†æ–‡æœ¬æ•°æ®è½¬åŒ–ä¸ºç»“æ„åŒ–æ•°æ®\n6.2 å†…ç½®prompt cntext\nct.llm.tasks_list() Run\n['sentiment', 'emotion', 'classify', 'intent', 'keywords', 'entities', 'summarize', 'rewrite', 'quality', 'similarity'] \n# è·å–sentimentæ¨¡æ¿ ct.llm.tasks_get('sentiment') Run\n{'prompt': 'åˆ†æè¯„è®ºçš„æƒ…æ„Ÿå€¾å‘ï¼šè¿”å›æƒ…æ„Ÿç±»åˆ« labelï¼ˆpos è¡¨ç¤ºæ­£é¢ï¼Œneg è¡¨ç¤ºè´Ÿé¢ï¼Œneutral è¡¨ç¤ºä¸­æ€§ï¼‰å’Œæƒ…æ„Ÿåˆ†å€¼ scoreï¼ˆå–å€¼èŒƒå›´ -1~1ï¼Œè´Ÿæ•°ä¸ºè´Ÿé¢ï¼‰', 'output_format': {'label': 'str', 'score': 'float'}} \n# ä½¿ç”¨sentimentæç¤ºè¯æ¨¡æ¿ã€‚ # å¯ç”¨OllamaæœåŠ¡ï¼Œè°ƒç”¨qwen2.5:7bæ¨¡å‹ ct.llm(\"æœåŠ¡å¾ˆæ£’ï¼\", task=\"sentiment\", backend=\"ollama\", model_name=\"qwen2.5:7b\") Run\n[cntext2x] âœ… è¿æ¥æ¨¡å‹æœåŠ¡: http://127.0.0.1:11434/v1 {'label': 'pos', 'score': 0.8} \nä½¿ç”¨å£°æ˜ å¦‚åœ¨ç ”ç©¶æˆ–é¡¹ç›®ä¸­ä½¿ç”¨åˆ° cntext ï¼Œè¯·ç®€è¦ä»‹ç» cntext ï¼Œå¹¶é™„åŠ ä½¿ç”¨å£°æ˜å‡ºå¤„ã€‚\napalike Deng, X., \u0026 Nan, P. (2022). cntext: a Python tool for text mining [Computer software]. Zenodo. https://doi.org/10.5281/zenodo.7063523\nSource Code URL: https://github.com/hiDaDeng/cntext\nbibtex @misc{deng2022cntext, author = {Deng, X. and Nan, P.}, title = {cntext: a Python tool for text mining}, year = {2022}, publisher = {Zenodo}, doi = {10.5281/zenodo.7063523}, url = {https://doi.org/10.5281/zenodo.7063523}, howpublished = {[Computer software]}, note = {Source Code URL: \\url{https://github.com/hiDaDeng/cntext}} } \nendnote %0 Generic %A Deng, X. %A Nan, P. %T cntext: a Python tool for text mining %Y [Computer software] %D 2022 %I Zenodo %R 10.5281/zenodo.7063523 %U https://doi.org/10.5281/zenodo.7063523 %Z Source Code URL: https://github.com/hiDaDeng/cntext %@ ",
  "wordCount" : "4908",
  "inLanguage": "en",
  "image":"/images/blog/cntext-2x.png","datePublished": "2025-03-14T00:00:00Z",
  "dateModified": "2025-03-14T00:00:00Z",
  "author":{
    "@type": "Person",
    "name": "å¤§é‚“"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "/blog/2024-04-27-cntext2x-usage-tutorial/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "å¤§é‚“å’Œä»–çš„PYTHON",
    "logo": {
      "@type": "ImageObject",
      "url": "/favicon.ico"
    }
  }
}
</script>
<script async src="https://www.googletagmanager.com/gtag/js?id=G-LEXKZ8MRX7"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-LEXKZ8MRX7');
</script>



<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC" rel="stylesheet">
<link href="https://fonts.googleapis.com/css2?family=PT+Serif" rel="stylesheet">
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="/" accesskey="h" title="å¤§é‚“å’Œä»–çš„PYTHON (Alt + H)" target="_blank">å¤§é‚“å’Œä»–çš„PYTHON</a>
            <span class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </span>
        </div>
        <ul id="menu">
            <li>
                <a href="/about/" title="å…³äº" target="_blank">
                    <span>å…³äº</span>
                </a>
            </li>
            <li>
                <a href="/blog/" title="åšæ–‡" target="_blank">
                    <span>åšæ–‡</span>
                </a>
            </li>
            <li>
                <a href="/search/" title="æœç´¢" target="_blank">
                    <span>æœç´¢</span>
                </a>
            </li>
            <li>
                <a href="/archives/" title="å½’æ¡£" target="_blank">
                    <span>å½’æ¡£</span>
                </a>
            </li>
            <li>
                <a href="/tags/" title="æ ‡ç­¾" target="_blank">
                    <span>æ ‡ç­¾</span>
                </a>
            </li>
            <li>
                <a href="/blog/management_python_course/" title="è¯¾ç¨‹" target="_blank">
                    <span>è¯¾ç¨‹</span>
                </a>
            </li>
            <li>
                <a href="/blog/the_text_analysis_list_about_ms/" title="æ–‡çŒ®" target="_blank">
                    <span>æ–‡çŒ®</span>
                </a>
            </li>
            <li>
                <a href="/blog/datasets_available_for_management_science/" title="æ•°æ®" target="_blank">
                    <span>æ•°æ®</span>
                </a>
            </li>
            <li>
                <a href="/blog/2024-04-27-cntext2x-usage-tutorial/" title="cntext" target="_blank">
                    <span class="active">cntext</span>
                </a>
            </li>
            <li>
                <a href="/index.xml" title="RSS" target="_blank">
                    <span>RSS</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">


<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js" integrity="sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js" integrity="sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa" crossorigin="anonymous"
onload="renderMathInElement(document.body);"></script>




<article class="post-single">
  <header class="post-header">
    
    <div class="breadcrumbs"><a href="/" target="_blank">Home</a>&nbsp;Â»&nbsp;<a href="/blog/" target="_blank">Blogs</a></div>
    <h1 class="post-title">
      æ¨è | æ–‡æœ¬åˆ†æåº“ cntext ä½¿ç”¨æ‰‹å†Œ
    </h1>
    <div class="post-meta"><span title='2025-03-14 00:00:00 +0000 UTC'>2025-03-14</span>&nbsp;Â·&nbsp;24 min&nbsp;Â·&nbsp;å¤§é‚“

</div>
  </header> 
<figure class="entry-cover"><a href="/images/blog/cntext-2x.png" target="_blank"
            rel="noopener noreferrer"><img loading="lazy" src="/images/blog/cntext-2x.png" alt=""></a>
        
</figure>
<div class="share-buttons">
    <a target="_blank" rel="noopener noreferrer" aria-label="share æ¨è | æ–‡æœ¬åˆ†æåº“ cntext ä½¿ç”¨æ‰‹å†Œ on twitter"
        href="https://twitter.com/intent/tweet/?text=%e6%8e%a8%e8%8d%90%20%7c%20%e6%96%87%e6%9c%ac%e5%88%86%e6%9e%90%e5%ba%93%20cntext%20%e4%bd%bf%e7%94%a8%e6%89%8b%e5%86%8c&amp;url=%2fblog%2f2024-04-27-cntext2x-usage-tutorial%2f&amp;hashtags=%e6%96%87%e6%9c%ac%e5%88%86%e6%9e%90%2c%e5%ad%a6%e6%9c%af%e5%ba%94%e7%94%a8%2c%e7%ac%ac%e4%b8%89%e6%96%b9%e5%ba%93">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-253.927,424.544c135.939,0 210.268,-112.643 210.268,-210.268c0,-3.218 0,-6.437 -0.153,-9.502c14.406,-10.421 26.973,-23.448 36.935,-38.314c-13.18,5.824 -27.433,9.809 -42.452,11.648c15.326,-9.196 26.973,-23.602 32.49,-40.92c-14.252,8.429 -30.038,14.56 -46.896,17.931c-13.487,-14.406 -32.644,-23.295 -53.946,-23.295c-40.767,0 -73.87,33.104 -73.87,73.87c0,5.824 0.613,11.494 1.992,16.858c-61.456,-3.065 -115.862,-32.49 -152.337,-77.241c-6.284,10.881 -9.962,23.601 -9.962,37.088c0,25.594 13.027,48.276 32.95,61.456c-12.107,-0.307 -23.448,-3.678 -33.41,-9.196l0,0.92c0,35.862 25.441,65.594 59.311,72.49c-6.13,1.686 -12.72,2.606 -19.464,2.606c-4.751,0 -9.348,-0.46 -13.946,-1.38c9.349,29.426 36.628,50.728 68.965,51.341c-25.287,19.771 -57.164,31.571 -91.8,31.571c-5.977,0 -11.801,-0.306 -17.625,-1.073c32.337,21.15 71.264,33.41 112.95,33.41Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share æ¨è | æ–‡æœ¬åˆ†æåº“ cntext ä½¿ç”¨æ‰‹å†Œ on linkedin"
        href="https://www.linkedin.com/shareArticle?mini=true&amp;url=%2fblog%2f2024-04-27-cntext2x-usage-tutorial%2f&amp;title=%e6%8e%a8%e8%8d%90%20%7c%20%e6%96%87%e6%9c%ac%e5%88%86%e6%9e%90%e5%ba%93%20cntext%20%e4%bd%bf%e7%94%a8%e6%89%8b%e5%86%8c&amp;summary=%e6%8e%a8%e8%8d%90%20%7c%20%e6%96%87%e6%9c%ac%e5%88%86%e6%9e%90%e5%ba%93%20cntext%20%e4%bd%bf%e7%94%a8%e6%89%8b%e5%86%8c&amp;source=%2fblog%2f2024-04-27-cntext2x-usage-tutorial%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share æ¨è | æ–‡æœ¬åˆ†æåº“ cntext ä½¿ç”¨æ‰‹å†Œ on reddit"
        href="https://reddit.com/submit?url=%2fblog%2f2024-04-27-cntext2x-usage-tutorial%2f&title=%e6%8e%a8%e8%8d%90%20%7c%20%e6%96%87%e6%9c%ac%e5%88%86%e6%9e%90%e5%ba%93%20cntext%20%e4%bd%bf%e7%94%a8%e6%89%8b%e5%86%8c">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share æ¨è | æ–‡æœ¬åˆ†æåº“ cntext ä½¿ç”¨æ‰‹å†Œ on facebook"
        href="https://facebook.com/sharer/sharer.php?u=%2fblog%2f2024-04-27-cntext2x-usage-tutorial%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share æ¨è | æ–‡æœ¬åˆ†æåº“ cntext ä½¿ç”¨æ‰‹å†Œ on whatsapp"
        href="https://api.whatsapp.com/send?text=%e6%8e%a8%e8%8d%90%20%7c%20%e6%96%87%e6%9c%ac%e5%88%86%e6%9e%90%e5%ba%93%20cntext%20%e4%bd%bf%e7%94%a8%e6%89%8b%e5%86%8c%20-%20%2fblog%2f2024-04-27-cntext2x-usage-tutorial%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share æ¨è | æ–‡æœ¬åˆ†æåº“ cntext ä½¿ç”¨æ‰‹å†Œ on telegram"
        href="https://telegram.me/share/url?text=%e6%8e%a8%e8%8d%90%20%7c%20%e6%96%87%e6%9c%ac%e5%88%86%e6%9e%90%e5%ba%93%20cntext%20%e4%bd%bf%e7%94%a8%e6%89%8b%e5%86%8c&amp;url=%2fblog%2f2024-04-27-cntext2x-usage-tutorial%2f">
        <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28">
            <path
                d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
        </svg>
    </a>
    
</div>
<aside id="toc-container" class="toc-container wide">
    <div class="toc">
        <details  open>
            <summary accesskey="c" title="(Alt + C)">
                <span class="details">Table of Contents</span>
            </summary>

            <div class="inner"><ul>
                    <li>
                        <a href="#cntext%e9%9d%a2%e5%90%91%e7%a4%be%e4%bc%9a%e7%a7%91%e5%ad%a6%e7%a0%94%e7%a9%b6%e7%9a%84%e4%b8%ad%e6%96%87%e6%96%87%e6%9c%ac%e5%88%86%e6%9e%90%e5%b7%a5%e5%85%b7%e5%ba%93" aria-label="cntextï¼šé¢å‘ç¤¾ä¼šç§‘å­¦ç ”ç©¶çš„ä¸­æ–‡æ–‡æœ¬åˆ†æå·¥å…·åº“">cntextï¼šé¢å‘ç¤¾ä¼šç§‘å­¦ç ”ç©¶çš„ä¸­æ–‡æ–‡æœ¬åˆ†æå·¥å…·åº“</a></li>
                    <li>
                        <a href="#%e5%ae%89%e8%a3%85-cntext" aria-label="å®‰è£… cntext">å®‰è£… cntext</a></li>
                    <li>
                        <a href="#%e5%8a%9f%e8%83%bd%e6%a8%a1%e5%9d%97" aria-label="åŠŸèƒ½æ¨¡å—">åŠŸèƒ½æ¨¡å—</a></li>
                    <li>
                        <a href="#quickstart" aria-label="QuickStart">QuickStart</a></li>
                    <li>
                        <a href="#%e4%b8%80io-%e6%a8%a1%e5%9d%97" aria-label="ä¸€ã€IO æ¨¡å—">ä¸€ã€IO æ¨¡å—</a><ul>
                            
                    <li>
                        <a href="#11-get_dict_list" aria-label="1.1 get_dict_list()">1.1 get_dict_list()</a></li>
                    <li>
                        <a href="#12-%e5%86%85%e7%bd%ae-yaml-%e8%af%8d%e5%85%b8" aria-label="1.2 å†…ç½® yaml è¯å…¸">1.2 å†…ç½® yaml è¯å…¸</a></li>
                    <li>
                        <a href="#13-read_dict_yaml" aria-label="1.3 read_dict_yaml()">1.3 read_dict_yaml()</a></li>
                    <li>
                        <a href="#14-detect_encoding" aria-label="1.4 detect_encoding()">1.4 detect_encoding()</a></li>
                    <li>
                        <a href="#15-get_filesfformat" aria-label="1.5 get_files(fformat)">1.5 get_files(fformat)</a></li>
                    <li>
                        <a href="#16-read_pdf" aria-label="1.6 read_pdf">1.6 read_pdf</a></li>
                    <li>
                        <a href="#17-read_docx" aria-label="1.7 read_docx">1.7 read_docx</a></li>
                    <li>
                        <a href="#18-read_file" aria-label="1.8 read_file()">1.8 read_file()</a></li>
                    <li>
                        <a href="#19-read_files" aria-label="1.9 read_files()">1.9 read_files()</a></li>
                    <li>
                        <a href="#110-extract_mda" aria-label="1.10 extract_mda">1.10 extract_mda</a></li>
                    <li>
                        <a href="#111-traditional2simple" aria-label="1.11 traditional2simple()">1.11 traditional2simple()</a></li>
                    <li>
                        <a href="#112-fix_text" aria-label="1.12 fix_text()">1.12 fix_text()</a></li>
                    <li>
                        <a href="#113-fix_contractionstext" aria-label="1.13 fix_contractions(text)">1.13 fix_contractions(text)</a></li>
                    <li>
                        <a href="#114-clean_texttext" aria-label="1.14 clean_text(text)">1.14 clean_text(text)</a></li></ul>
                    </li>
                    <li>
                        <a href="#%e4%ba%8cstats-%e6%a8%a1%e5%9d%97" aria-label="äºŒã€Stats æ¨¡å—">äºŒã€Stats æ¨¡å—</a><ul>
                            
                    <li>
                        <a href="#21-word_count" aria-label="2.1 word_count()">2.1 word_count()</a></li>
                    <li>
                        <a href="#22-readability" aria-label="2.2 readability()">2.2 readability()</a></li>
                    <li>
                        <a href="#23-sentimenttext-diction-lang" aria-label="2.3 sentiment(text, diction, lang)">2.3 sentiment(text, diction, lang)</a></li>
                    <li>
                        <a href="#24-sentiment_by_valence" aria-label="2.4 sentiment_by_valence()">2.4 sentiment_by_valence()</a></li>
                    <li>
                        <a href="#25-word_in_context" aria-label="2.5 word_in_context()">2.5 word_in_context()</a></li>
                    <li>
                        <a href="#26-epu" aria-label="2.6 epu()">2.6 epu()</a></li>
                    <li>
                        <a href="#27-fepu" aria-label="2.7 fepu()">2.7 fepu()</a></li>
                    <li>
                        <a href="#28-semantic_brand_score" aria-label="2.8 semantic_brand_score()">2.8 semantic_brand_score()</a></li>
                    <li>
                        <a href="#29-%e6%96%87%e6%9c%ac%e7%9b%b8%e4%bc%bc%e5%ba%a6" aria-label="2.9 æ–‡æœ¬ç›¸ä¼¼åº¦">2.9 æ–‡æœ¬ç›¸ä¼¼åº¦</a></li>
                    <li>
                        <a href="#210-word_hhi" aria-label="2.10 word_hhi">2.10 word_hhi</a></li></ul>
                    </li>
                    <li>
                        <a href="#%e4%b8%89plot-%e6%a8%a1%e5%9d%97" aria-label="ä¸‰ã€Plot æ¨¡å—">ä¸‰ã€Plot æ¨¡å—</a><ul>
                            
                    <li>
                        <a href="#31-matplotlib_chinese" aria-label="3.1 matplotlib_chinese()">3.1 matplotlib_chinese()</a></li>
                    <li>
                        <a href="#32-lexical_dispersion_plot1" aria-label="3.2 lexical_dispersion_plot1()">3.2 lexical_dispersion_plot1()</a></li>
                    <li>
                        <a href="#33-lexical_dispersion_plot2" aria-label="3.3 lexical_dispersion_plot2()">3.3 lexical_dispersion_plot2()</a></li></ul>
                    </li>
                    <li>
                        <a href="#%e5%9b%9bmodel-%e6%a8%a1%e5%9d%97" aria-label="å››ã€Model æ¨¡å—">å››ã€Model æ¨¡å—</a><ul>
                            
                    <li>
                        <a href="#41-word2vec" aria-label="4.1 Word2Vec()">4.1 Word2Vec()</a></li>
                    <li>
                        <a href="#42-glove" aria-label="4.2 GloVe()">4.2 GloVe()</a></li>
                    <li>
                        <a href="#43-evaluate_similarity" aria-label="4.3 evaluate_similarity()">4.3 evaluate_similarity()</a></li>
                    <li>
                        <a href="#44-evaluate_analogy" aria-label="4.4 evaluate_analogy()">4.4 evaluate_analogy()</a></li>
                    <li>
                        <a href="#45-sopmi" aria-label="4.5 SoPmi()">4.5 SoPmi()</a></li>
                    <li>
                        <a href="#46-load_w2v" aria-label="4.6 load_w2v()">4.6 load_w2v()</a></li>
                    <li>
                        <a href="#47-glove2word2vec" aria-label="4.7 glove2word2vec()">4.7 glove2word2vec()</a></li>
                    <li>
                        <a href="#%e6%b3%a8%e6%84%8f" aria-label="æ³¨æ„">æ³¨æ„</a></li>
                    <li>
                        <a href="#48-expand_dictionary" aria-label="4.8 expand_dictionary()">4.8 expand_dictionary()</a></li></ul>
                    </li>
                    <li>
                        <a href="#%e4%ba%94mind-%e6%a8%a1%e5%9d%97" aria-label="äº”ã€Mind æ¨¡å—">äº”ã€Mind æ¨¡å—</a><ul>
                            
                    <li>
                        <a href="#51-semantic_centroidwv-words" aria-label="5.1 semantic_centroid(wv, words)">5.1 semantic_centroid(wv, words)</a></li>
                    <li>
                        <a href="#52-generate_concept_axiswv-poswords-negwords" aria-label="5.2 generate_concept_axis(wv, poswords, negwords)">5.2 generate_concept_axis(wv, poswords, negwords)</a></li>
                    <li>
                        <a href="#53-sematic_distance" aria-label="5.3 sematic_distance()">5.3 sematic_distance()</a></li>
                    <li>
                        <a href="#54-sematic_projection" aria-label="5.4 sematic_projection()">5.4 sematic_projection()</a></li>
                    <li>
                        <a href="#55-project_word" aria-label="5.5 project_word">5.5 project_word</a></li>
                    <li>
                        <a href="#56-project_text" aria-label="5.6 project_text()">5.6 project_text()</a></li>
                    <li>
                        <a href="#57-divergent_association_task" aria-label="5.7 divergent_association_task()">5.7 divergent_association_task()</a></li>
                    <li>
                        <a href="#58-discursive_diversity_score" aria-label="5.8 discursive_diversity_score()">5.8 discursive_diversity_score()</a></li>
                    <li>
                        <a href="#58-procrustes_align" aria-label="5.8 procrustes_align()">5.8 procrustes_align()</a></li></ul>
                    </li>
                    <li>
                        <a href="#%e5%85%adllm-%e6%a8%a1%e5%9d%97" aria-label="å…­ã€LLM æ¨¡å—">å…­ã€LLM æ¨¡å—</a><ul>
                            
                    <li>
                        <a href="#61-ctllm" aria-label="6.1 ct.llm()">6.1 ct.llm()</a></li>
                    <li>
                        <a href="#62-%e5%86%85%e7%bd%aeprompt" aria-label="6.2 å†…ç½®prompt">6.2 å†…ç½®prompt</a></li></ul>
                    </li>
                    <li>
                        <a href="#%e4%bd%bf%e7%94%a8%e5%a3%b0%e6%98%8e" aria-label="ä½¿ç”¨å£°æ˜">ä½¿ç”¨å£°æ˜</a><ul>
                            
                    <li>
                        <a href="#apalike" aria-label="apalike">apalike</a></li>
                    <li>
                        <a href="#bibtex" aria-label="bibtex">bibtex</a></li>
                    <li>
                        <a href="#endnote" aria-label="endnote">endnote</a>
                    </li>
                </ul>
                </li>
                </ul>
            </div>
        </details>
    </div>
</aside>
<script>
    let activeElement;
    let elements;
    window.addEventListener('DOMContentLoaded', function (event) {
        checkTocPosition();

        elements = document.querySelectorAll('h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]');
         
         activeElement = elements[0];
         const id = encodeURI(activeElement.getAttribute('id')).toLowerCase();
         document.querySelector(`.inner ul li a[href="#${id}"]`).classList.add('active');
     }, false);

    window.addEventListener('resize', function(event) {
        checkTocPosition();
    }, false);

    window.addEventListener('scroll', () => {
        
        activeElement = Array.from(elements).find((element) => {
            if ((getOffsetTop(element) - window.pageYOffset) > 0 && 
                (getOffsetTop(element) - window.pageYOffset) < window.innerHeight/2) {
                return element;
            }
        }) || activeElement

        elements.forEach(element => {
             const id = encodeURI(element.getAttribute('id')).toLowerCase();
             if (element === activeElement){
                 document.querySelector(`.inner ul li a[href="#${id}"]`).classList.add('active');
             } else {
                 document.querySelector(`.inner ul li a[href="#${id}"]`).classList.remove('active');
             }
         })
     }, false);

    const main = parseInt(getComputedStyle(document.body).getPropertyValue('--article-width'), 10);
    const toc = parseInt(getComputedStyle(document.body).getPropertyValue('--toc-width'), 10);
    const gap = parseInt(getComputedStyle(document.body).getPropertyValue('--gap'), 10);

    function checkTocPosition() {
        const width = document.body.scrollWidth;

        if (width - main - (toc * 2) - (gap * 4) > 0) {
            document.getElementById("toc-container").classList.add("wide");
        } else {
            document.getElementById("toc-container").classList.remove("wide");
        }
    }

    function getOffsetTop(element) {
        if (!element.getClientRects().length) {
            return 0;
        }
        let rect = element.getBoundingClientRect();
        let win = element.ownerDocument.defaultView;
        return rect.top + win.pageYOffset;   
    }
</script>



  <div style="margin-top:2em;padding:0 0.5em;font-size:.875rem">
    <hr>
    <div style="padding-bottom:1em;">
        <p>æœ¬æ–‡ä½œè€…: å¤§é‚“
        <p>æœ¬æ–‡æ ‡é¢˜: æ¨è | æ–‡æœ¬åˆ†æåº“ cntext ä½¿ç”¨æ‰‹å†Œ
        <p>æœ¬æ–‡é“¾æ¥: https://textdata.cn/blog/2024-04-27-cntext2x-usage-tutorial/
        <p>ç‰ˆæƒå£°æ˜: <a href="https://creativecommons.org/licenses/by-nc/4.0/" target="_blank">ç½²å-éå•†ä¸šæ€§ä½¿ç”¨-ç›¸åŒæ–¹å¼å…±äº« 4.0 å›½é™…</a></p>
    </div>
    <hr>
  </div>


  <br>



  
  <div class="post-content"><h2 id="cntexté¢å‘ç¤¾ä¼šç§‘å­¦ç ”ç©¶çš„ä¸­æ–‡æ–‡æœ¬åˆ†æå·¥å…·åº“">cntextï¼šé¢å‘ç¤¾ä¼šç§‘å­¦ç ”ç©¶çš„ä¸­æ–‡æ–‡æœ¬åˆ†æå·¥å…·åº“<a hidden class="anchor" aria-hidden="true" href="#cntexté¢å‘ç¤¾ä¼šç§‘å­¦ç ”ç©¶çš„ä¸­æ–‡æ–‡æœ¬åˆ†æå·¥å…·åº“">#</a></h2>
<p>cntext æ˜¯ä¸“ä¸º<strong>ç¤¾ä¼šç§‘å­¦å®è¯ç ”ç©¶è€…</strong>è®¾è®¡çš„ä¸­æ–‡æ–‡æœ¬åˆ†æ Python åº“ã€‚å®ƒä¸æ­¢äºè¯é¢‘ç»Ÿè®¡å¼çš„ä¼ ç»Ÿæƒ…æ„Ÿåˆ†æï¼Œè¿˜æ‹¥æœ‰è¯åµŒå…¥è®­ç»ƒã€è¯­ä¹‰æŠ•å½±è®¡ç®—ï¼Œ<strong>å¯ä»å¤§è§„æ¨¡éç»“æ„åŒ–æ–‡æœ¬ä¸­æµ‹é‡æŠ½è±¡æ„å¿µ</strong>â€”â€”å¦‚æ€åº¦ã€è®¤çŸ¥ã€æ–‡åŒ–è§‚å¿µä¸å¿ƒç†çŠ¶æ€ã€‚</p>
<p>ğŸ¯ <strong>ä½ èƒ½ç”¨å®ƒåšä»€ä¹ˆ</strong></p>
<ol>
<li>
<p>æ„å»ºç»“æ„åŒ–ç ”ç©¶æ•°æ®é›†</p>
<ul>
<li>æ±‡æ€»å¤šä¸ªæ–‡æœ¬æ–‡ä»¶ï¼ˆtxt/pdf/docx/csvï¼‰ä¸º DataFrameï¼š<code>ct.read_files()</code></li>
<li>æå–ä¸Šå¸‚å…¬å¸å¹´æŠ¥ä¸­çš„â€œç®¡ç†å±‚è®¨è®ºä¸åˆ†æâ€ï¼ˆMD&amp;Aï¼‰ï¼š<code>ct.extract_mda()</code></li>
<li>è®¡ç®—æ–‡æœ¬å¯è¯»æ€§æŒ‡æ ‡ï¼ˆå¦‚FleschæŒ‡æ•°ï¼‰ï¼š<code>ct.readability()</code></li>
</ul>
</li>
<li>
<p><strong>åŸºç¡€æ–‡æœ¬åˆ†æ(ä¼ ç»Ÿæ–¹æ³•)</strong></p>
<ul>
<li>è¯é¢‘ç»Ÿè®¡ä¸å…³é”®è¯æå–ï¼š<code>ct.word_count()</code></li>
<li>æƒ…æ„Ÿåˆ†æï¼ˆå¯é€‰hownetã€dutirç­‰å†…ç½®è¯å…¸ï¼‰ï¼š<code>ct.sentiment()</code></li>
<li>æ–‡æœ¬ç›¸ä¼¼åº¦è®¡ç®—ï¼ˆä½™å¼¦è·ç¦»ï¼‰ï¼š<code>ct.cosine_sim()</code></li>
</ul>
</li>
<li>
<p><strong>æµ‹é‡å†…éšæ€åº¦ä¸æ–‡åŒ–å˜è¿</strong></p>
<ul>
<li>ä¸¤è¡Œä»£ç è®­ç»ƒé¢†åŸŸä¸“ç”¨è¯å‘é‡ï¼ˆWord2Vec/GloVeï¼‰ï¼š<code>ct.Word2Vec()</code></li>
<li>æ„å»ºæ¦‚å¿µè¯­ä¹‰è½´ï¼ˆå¦‚â€œåˆ›æ–° vs å®ˆæ—§â€ï¼‰ï¼š<code>ct.generate_concept_axis()</code></li>
<li>é€šè¿‡è¯­ä¹‰æŠ•å½±é‡åŒ–åˆ»æ¿å°è±¡ã€ç»„ç»‡æ–‡åŒ–åç§»ï¼š<code>ct.project_text()</code></li>
</ul>
</li>
<li>
<p><strong>èåˆå¤§æ¨¡å‹è¿›è¡Œç»“æ„åŒ–åˆ†æ</strong></p>
<ul>
<li>è°ƒç”¨ LLM å¯¹æ–‡æœ¬è¿›è¡Œè¯­ä¹‰è§£æï¼Œè¿”å›ç»“æ„åŒ–ç»“æœï¼ˆå¦‚æƒ…ç»ªç»´åº¦ã€æ„å›¾åˆ†ç±»ï¼‰ï¼š<code>ct.llm()</code></li>
</ul>
</li>
</ol>
<p>cntext ä¸è¿½æ±‚é»‘ç®±é¢„æµ‹ï¼Œè€Œè‡´åŠ›äºè®©æ–‡æœ¬æˆä¸ºç†è®ºé©±åŠ¨çš„ç§‘å­¦æµ‹é‡å·¥å…·ã€‚ å¼€æºå…è´¹ï¼Œæ¬¢è¿å­¦ç•ŒåŒä»ä½¿ç”¨ã€éªŒè¯ä¸å…±å»ºã€‚</p>
<p><br><br></p>
<h2 id="å®‰è£…-cntext">å®‰è£… cntext<a hidden class="anchor" aria-hidden="true" href="#å®‰è£…-cntext">#</a></h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">pip3 install cntext --upgrade
</code></pre></div><br>
<p>éœ€è¦æ³¨æ„ï¼Œ <strong>cntext ä½¿ç”¨ç¯å¢ƒä¸º Python3.9 ~ 3.12</strong>,å¦‚å®‰è£…å¤±è´¥ï¼Œé—®é¢˜å¯èƒ½å‡ºåœ¨ python ç‰ˆæœ¬é—®é¢˜ï¼›</p>
<p><br><br></p>
<h2 id="åŠŸèƒ½æ¨¡å—">åŠŸèƒ½æ¨¡å—<a hidden class="anchor" aria-hidden="true" href="#åŠŸèƒ½æ¨¡å—">#</a></h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>
<span class="n">ct</span><span class="o">.</span><span class="n">hello</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/01-hello.jpg" alt=""  />
</p>
<p>cntext å« ioã€modelã€statsã€mind äº”ä¸ªæ¨¡å—</p>
<ol>
<li>å¯¼å…¥æ•°æ®ç”¨ io</li>
<li>è®­ç»ƒæ¨¡å‹æ‰©å±•è¯å…¸ç”¨ model</li>
<li>ç»Ÿè®¡è¯é¢‘ã€æƒ…æ„Ÿåˆ†æã€ç›¸ä¼¼åº¦ç­‰ç”¨ stats</li>
<li>å¯è§†åŒ–æ¨¡å— plot</li>
<li>æ€åº¦è®¤çŸ¥æ–‡åŒ–å˜è¿ç”¨ mind</li>
<li>å¤§æ¨¡å‹ LLM</li>
</ol>
<p>å‡½æ•°éƒ¨åˆ†åŠ ç²—çš„ä¸ºå¸¸ç”¨å‡½æ•°ã€‚</p>
<table>
<thead>
<tr>
<th>æ¨¡å—</th>
<th>å‡½æ•°</th>
<th>åŠŸèƒ½</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>io</strong></td>
<td><strong><em>ct.get_cntext_path()</em></strong></td>
<td>æŸ¥çœ‹ cntext å®‰è£…è·¯å¾„</td>
</tr>
<tr>
<td><strong>io</strong></td>
<td><strong><em>ct.get_dict_list()</em></strong></td>
<td>æŸ¥çœ‹ cntext å†…ç½®è¯å…¸</td>
</tr>
<tr>
<td><strong>io</strong></td>
<td><code>ct.get_files(fformat)</code></td>
<td>æŸ¥çœ‹ç¬¦åˆ fformat è·¯å¾„è§„åˆ™çš„æ‰€æœ‰çš„æ–‡ä»¶</td>
</tr>
<tr>
<td><strong>io</strong></td>
<td><code>ct.detect_encoding(file, num_lines=100)</code></td>
<td>è¯Šæ–­ txtã€csv ç¼–ç æ ¼å¼</td>
</tr>
<tr>
<td><strong>io</strong></td>
<td><strong><em>ct.read_yaml_dict(yfile)</em></strong></td>
<td>è¯»å–å†…ç½® yaml è¯å…¸</td>
</tr>
<tr>
<td><strong>io</strong></td>
<td><strong><em>ct.read_pdf(file)</em></strong></td>
<td>è¯»å– PDF æ–‡ä»¶</td>
</tr>
<tr>
<td><strong>io</strong></td>
<td><strong><em>ct.read_docx(file)</em></strong></td>
<td>è¯»å– docx æ–‡ä»¶</td>
</tr>
<tr>
<td><strong>io</strong></td>
<td><strong><em>ct.read_file(file, encodings)</em></strong></td>
<td>è¯»å–æ–‡ä»¶</td>
</tr>
<tr>
<td><strong>io</strong></td>
<td><strong><em>ct.read_files(fformat, encoding)</em></strong></td>
<td>è¯»å–ç¬¦åˆ fformat è·¯å¾„è§„åˆ™çš„æ‰€æœ‰çš„æ–‡ä»¶ï¼Œè¿”å› df</td>
</tr>
<tr>
<td><strong>io</strong></td>
<td><strong><em>ct.extract_mda(text, kws_pattern)</em></strong></td>
<td>æå– A è‚¡å¹´æŠ¥ä¸­çš„ MD&amp;A æ–‡æœ¬å†…å®¹ã€‚å¦‚æœè¿”å›'',åˆ™æå–å¤±è´¥ã€‚</td>
</tr>
<tr>
<td><strong>io</strong></td>
<td><strong><em>ct.traditional2simple(text)</em></strong></td>
<td>ç¹ä½“è½¬ç®€ä½“</td>
</tr>
<tr>
<td><strong>io</strong></td>
<td><strong><em>ct.clean_text(text, lang=&lsquo;chinese&rsquo;)</em></strong></td>
<td>æ ¹æ®æŒ‡å®šè¯­è¨€å¯¹æ–‡æœ¬è¿›è¡Œæ ‡å‡†åŒ–æ¸…æ´—ã€‚</td>
</tr>
<tr>
<td><strong>io</strong></td>
<td><strong><em>ct.fix_text(text)</em></strong></td>
<td>å°†ä¸æ­£å¸¸çš„ã€æ··ä¹±ç¼–ç çš„æ–‡æœ¬è½¬åŒ–ä¸ºæ­£å¸¸çš„æ–‡æœ¬ã€‚ä¾‹å¦‚å…¨è§’è½¬åŠè§’</td>
</tr>
<tr>
<td><strong>io</strong></td>
<td><code>ct.fix_contractions(text)</code></td>
<td>è‹±æ–‡ç¼©å†™(å«ä¿šè¯­è¡¨è¾¾)å¤„ç†ï¼Œ å¦‚ you&rsquo;re -&gt; you are</td>
</tr>
<tr>
<td><strong>model</strong></td>
<td><strong><em>ct.Word2Vec(corpus_file, encoding, lang=&lsquo;chinese&rsquo;, &hellip;)</em></strong></td>
<td>è®­ç»ƒ Word2Vec</td>
</tr>
<tr>
<td><strong>model</strong></td>
<td><strong><em>ct.GloVe(corpus_file, encoding, lang=&lsquo;chinese&rsquo;, &hellip;)</em></strong></td>
<td>GloVe, åº•å±‚ä½¿ç”¨çš„ <a href="https://github.com/standfordnlp/GloVe">Standfordnlp/GloVe</a></td>
</tr>
<tr>
<td><strong>model</strong></td>
<td><strong><em>ct.evaluate_similarity(wv, file=None)</em></strong></td>
<td>ä½¿ç”¨è¿‘ä¹‰æ³•è¯„ä¼°æ¨¡å‹è¡¨ç°ï¼Œé»˜è®¤ä½¿ç”¨å†…ç½®çš„æ•°æ®è¿›è¡Œè¯„ä¼°ã€‚</td>
</tr>
<tr>
<td><strong>model</strong></td>
<td><strong><em>ct.evaluate_analogy(wv, file=None)</em></strong></td>
<td>ä½¿ç”¨ç±»æ¯”æ³•è¯„ä¼°æ¨¡å‹è¡¨ç°ï¼Œé»˜è®¤ä½¿ç”¨å†…ç½®çš„æ•°æ®è¿›è¡Œè¯„ä¼°ã€‚</td>
</tr>
<tr>
<td><strong>model</strong></td>
<td><strong><em>ct.glove2word2vec(glove_file, word2vec_file)</em></strong></td>
<td>å°† GLoVe æ¨¡å‹.txt æ–‡ä»¶è½¬åŒ–ä¸º Word2Vec æ¨¡å‹.txt æ–‡ä»¶ï¼› ä¸€èˆ¬å¾ˆå°‘ç”¨åˆ°</td>
</tr>
<tr>
<td><strong>model</strong></td>
<td><strong><em>ct.load_w2v(wv_path)</em></strong></td>
<td>è¯»å– cntext2.x è®­ç»ƒå‡ºçš„ Word2Vec/GloVe æ¨¡å‹æ–‡ä»¶</td>
</tr>
<tr>
<td><strong>model</strong></td>
<td><strong><em>ct.expand_dictionary(wv, seeddict, topn=100)</em></strong></td>
<td>æ‰©å±•è¯å…¸, ç»“æœä¿å­˜åˆ°è·¯å¾„[output/Word2Vec]ä¸­</td>
</tr>
<tr>
<td><strong>model</strong></td>
<td><code>ct.SoPmi(corpus_file, seed_file, lang='chinese')</code></td>
<td>å…±ç°æ³•æ‰©å±•è¯å…¸</td>
</tr>
<tr>
<td><strong>stats</strong></td>
<td><code>ct.word_count(text, lang='chinese')</code></td>
<td>è¯é¢‘ç»Ÿè®¡</td>
</tr>
<tr>
<td><strong>stats</strong></td>
<td><code>readability(text, lang='chinese', syllables=3)</code></td>
<td>æ–‡æœ¬å¯è¯»æ€§</td>
</tr>
<tr>
<td><strong>stats</strong></td>
<td><strong><em>ct.sentiment(text, diction, lang=&lsquo;chinese&rsquo;)</em></strong></td>
<td>æ— (ç­‰)æƒé‡è¯å…¸çš„æƒ…æ„Ÿåˆ†æ</td>
</tr>
<tr>
<td><strong>stats</strong></td>
<td><code>ct.sentiment_by_valence(text, diction, lang='chinese')</code></td>
<td>å¸¦æƒé‡çš„è¯å…¸çš„æƒ…æ„Ÿåˆ†æ</td>
</tr>
<tr>
<td><strong>stats</strong></td>
<td><strong><em>ct.word_in_context(text, keywords, window=3, lang=&lsquo;chinese&rsquo;)</em></strong></td>
<td>åœ¨ text ä¸­æŸ¥æ‰¾ keywords å‡ºç°çš„ä¸Šä¸‹æ–‡å†…å®¹(çª—å£ window)ï¼Œè¿”å› df</td>
</tr>
<tr>
<td><strong>stats</strong></td>
<td><strong><em>ct.epu()</em></strong></td>
<td>ä½¿ç”¨æ–°é—»æ–‡æœ¬æ•°æ®è®¡ç®—ç»æµæ”¿ç­–ä¸ç¡®å®šæ€§ EPUï¼Œè¿”å› df</td>
</tr>
<tr>
<td><strong>stats</strong></td>
<td><strong><em>ct.fepu(text, ep_pattern='', u_pattern='')</em></strong></td>
<td>ä½¿ç”¨ md&amp;a æ–‡æœ¬æ•°æ®è®¡ç®—ä¼ä¸šä¸ç¡®å®šæ€§æ„ŸçŸ¥ FEPU</td>
</tr>
<tr>
<td><strong>stats</strong></td>
<td><strong><em>ct.semantic_brand_score(text, brands, lang=&lsquo;chinese&rsquo;)</em></strong></td>
<td>è¡¡é‡å“ç‰Œï¼ˆä¸ªä½“ã€å…¬å¸ã€å“ç‰Œã€å…³é”®è¯ç­‰ï¼‰çš„é‡è¦æ€§</td>
</tr>
<tr>
<td><strong>stats</strong></td>
<td><strong><em>ct.cosine_sim(text1, text2, lang=&lsquo;chinese&rsquo;)</em></strong></td>
<td>ä½™å¼¦ç›¸ä¼¼åº¦</td>
</tr>
<tr>
<td><strong>stats</strong></td>
<td><code>ct.jaccard_sim(text1, text2, lang='chinese')</code></td>
<td>Jaccard ç›¸ä¼¼åº¦</td>
</tr>
<tr>
<td><strong>stats</strong></td>
<td><code>ct.minedit_sim(text1, text2, lang='chinese')</code></td>
<td>æœ€å°ç¼–è¾‘è·ç¦»</td>
</tr>
<tr>
<td><strong>stats</strong></td>
<td><code>ct.word_hhi(text)</code></td>
<td>æ–‡æœ¬çš„èµ«èŠ¬è¾¾å°”-èµ«å¸Œæ›¼æŒ‡æ•°</td>
</tr>
<tr>
<td><strong><em>plot</em></strong></td>
<td><code>ct.matplotlib_chinese()</code></td>
<td>æ”¯æŒ matplotlib ä¸­æ–‡ç»˜å›¾</td>
</tr>
<tr>
<td><strong>plot</strong></td>
<td><code>ct.lexical_dispersion_plot1(text, targets_dict, lang, title, figsize)</code></td>
<td>å¯¹æŸä¸€ä¸ªæ–‡æœ¬ textï¼Œ å¯è§†åŒ–ä¸åŒç›®æ ‡ç±»åˆ«è¯ targets_dict åœ¨æ–‡æœ¬ä¸­å‡ºç°ä½ç½®</td>
</tr>
<tr>
<td><strong>plot</strong></td>
<td><code>ct.lexical_dispersion_plot2(texts_dict, targets, lang, title, figsize)</code></td>
<td>å¯¹æŸå‡ ä¸ªæ–‡æœ¬ texts_dictï¼Œ å¯è§†åŒ–æŸäº›ç›®æ ‡è¯ targets åœ¨æ–‡æœ¬ä¸­å‡ºç°ç›¸å¯¹ä½ç½®(0~100)</td>
</tr>
<tr>
<td><strong>mind</strong></td>
<td><code>ct.generate_concept_axis(wv, poswords, negwords)</code></td>
<td>ç”Ÿæˆæ¦‚å¿µè½´å‘é‡ã€‚</td>
</tr>
<tr>
<td><strong>mind</strong></td>
<td><strong><em>tm = ct.Text2Mind(wv)</em></strong><br></td>
<td>å•ä¸ª word2vec å†…æŒ–æ˜æ½œåœ¨çš„æ€åº¦åè§ã€åˆ»æ¿å°è±¡ç­‰ã€‚tm å«å¤šé‡æ–¹æ³•</td>
</tr>
<tr>
<td><strong>mind</strong></td>
<td><code>sematic_projection(wv, words, poswords, negwords, return_full=False, cosine=False)</code></td>
<td>æµ‹é‡è¯­ä¹‰æŠ•å½±</td>
</tr>
<tr>
<td><strong>mind</strong></td>
<td><code>ct.project_word(wv, a, b, cosine=False)</code></td>
<td>è®¡ç®—è¯è¯­ a åœ¨è¯è¯­ b ä¸Šçš„æŠ•å½±</td>
</tr>
<tr>
<td><strong>mind</strong></td>
<td><code>ct.project_text(wv, text, axis, lang='chinese', cosine=False)</code></td>
<td>è®¡ç®—è¯è¯­æ–‡æœ¬textåœ¨æ¦‚å¿µè½´å‘é‡axisä¸Šçš„æŠ•å½±å€¼</td>
</tr>
<tr>
<td><strong>mind</strong></td>
<td><code>ct.project_text(wv, text, axis, lang='chinese', cosine=False)</code></td>
<td>è®¡ç®—è¯è¯­æ–‡æœ¬textåœ¨æ¦‚å¿µè½´å‘é‡axisä¸Šçš„æŠ•å½±å€¼</td>
</tr>
<tr>
<td><strong>mind</strong></td>
<td><code>ct.sematic_distance(wv, words1, words2)</code></td>
<td>æµ‹é‡è¯­ä¹‰è·ç¦»</td>
</tr>
<tr>
<td><strong>mind</strong></td>
<td><code>ct.divergent_association_task(wv, words)</code></td>
<td>æµ‹é‡å‘æ•£æ€ç»´(åˆ›é€ åŠ›)</td>
</tr>
<tr>
<td><strong>mind</strong></td>
<td><code>ct.discursive_diversity_score(wv, words)</code></td>
<td>æµ‹é‡è¯­è¨€å·®å¼‚æ€§(è®¤çŸ¥å·®å¼‚æ€§)</td>
</tr>
<tr>
<td><strong>mind</strong></td>
<td><strong>ct.procrustes_align(base_wv, other_wv)</strong></td>
<td>ä¸¤ä¸ª word2vec è¿›è¡Œè¯­ä¹‰å¯¹é½ï¼Œå¯ååº”éšæ—¶é—´çš„ç¤¾ä¼šè¯­ä¹‰å˜è¿</td>
</tr>
<tr>
<td><strong><em>LLM</em></strong></td>
<td><strong>ct.llm(text, prompt, output_format, task, backend, base_url, api_key, model_name, temperature)</strong></td>
<td>è°ƒç”¨å¤§æ¨¡å‹æ‰§è¡Œç»“æ„åŒ–æ–‡æœ¬åˆ†æä»»åŠ¡ï¼ˆå¦‚æƒ…æ„Ÿåˆ†æã€å…³é”®è¯æå–ã€åˆ†ç±»ç­‰ï¼‰ã€‚</td>
</tr>
</tbody>
</table>
<p><br><br></p>
<h2 id="quickstart">QuickStart<a hidden class="anchor" aria-hidden="true" href="#quickstart">#</a></h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;å½“å‰cntextç‰ˆæœ¬: &#39;</span><span class="p">,</span> <span class="n">ct</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span>
<span class="n">help</span><span class="p">(</span><span class="n">ct</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-go" data-lang="go"><span class="nx">å½“å‰cntextç‰ˆæœ¬</span><span class="p">:</span> <span class="mf">2.1.7</span>

<span class="nx">Help</span> <span class="nx">on</span> <span class="kn">package</span> <span class="nx">cntext</span><span class="p">:</span>

<span class="nx">NAME</span>
    <span class="nx">cntext</span>

<span class="nx">PACKAGE</span> <span class="nx">CONTENTS</span>
    <span class="nx">io</span>
    <span class="nx">mind</span>
    <span class="nx">model</span>
    <span class="nx">stats</span>
    <span class="nx">llm</span>
<span class="o">...</span>
</code></pre></div><br>
<br>
<h2 id="ä¸€io-æ¨¡å—">ä¸€ã€IO æ¨¡å—<a hidden class="anchor" aria-hidden="true" href="#ä¸€io-æ¨¡å—">#</a></h2>
<table>
<thead>
<tr>
<th>æ¨¡å—</th>
<th>å‡½æ•°</th>
<th>åŠŸèƒ½</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>io</strong></td>
<td><strong><em>ct.get_dict_list()</em></strong></td>
<td>æŸ¥çœ‹ cntext å†…ç½®è¯å…¸</td>
</tr>
<tr>
<td><strong>io</strong></td>
<td><strong><em>ct.read_yaml_dict(yfile)</em></strong></td>
<td>è¯»å–å†…ç½® yaml è¯å…¸</td>
</tr>
<tr>
<td><strong>io</strong></td>
<td><code>ct.detect_encoding(file, num_lines=100)</code></td>
<td>è¯Šæ–­ txtã€csv ç¼–ç æ ¼å¼</td>
</tr>
<tr>
<td><strong>io</strong></td>
<td><code>ct.get_files(fformat)</code></td>
<td>æŸ¥çœ‹ç¬¦åˆ fformat è·¯å¾„è§„åˆ™çš„æ‰€æœ‰çš„æ–‡ä»¶</td>
</tr>
<tr>
<td><strong>io</strong></td>
<td><strong><em>ct.read_yaml_dict(yfile)</em></strong></td>
<td>è¯»å–å†…ç½® yaml è¯å…¸</td>
</tr>
<tr>
<td><strong>io</strong></td>
<td><strong><em>ct.read_pdf(file)</em></strong></td>
<td>è¯»å– PDF æ–‡ä»¶</td>
</tr>
<tr>
<td><strong>io</strong></td>
<td><strong><em>ct.read_file(file, encoding)</em></strong></td>
<td>è¯»å–æ–‡ä»¶</td>
</tr>
<tr>
<td><strong>io</strong></td>
<td><strong><em>ct.read_files(fformat, encoding)</em></strong></td>
<td>è¯»å–ç¬¦åˆ fformat è·¯å¾„è§„åˆ™çš„æ‰€æœ‰çš„æ–‡ä»¶ï¼Œè¿”å› df</td>
</tr>
<tr>
<td><strong>io</strong></td>
<td><strong><em>ct.extract_mda(text, kws_pattern)</em></strong></td>
<td>æå– A è‚¡å¹´æŠ¥ä¸­çš„ MD&amp;A æ–‡æœ¬å†…å®¹ã€‚å¦‚æœè¿”å›'',åˆ™æå–å¤±è´¥ã€‚</td>
</tr>
<tr>
<td><strong>io</strong></td>
<td><strong><em>ct.traditional2simple(text)</em></strong></td>
<td>ç¹ä½“è½¬ç®€ä½“</td>
</tr>
<tr>
<td><strong>io</strong></td>
<td><strong><em>ct.fix_text(text)</em></strong></td>
<td>å°†ä¸æ­£å¸¸çš„ã€æ··ä¹±ç¼–ç çš„æ–‡æœ¬è½¬åŒ–ä¸ºæ­£å¸¸çš„æ–‡æœ¬ã€‚ä¾‹å¦‚å…¨è§’è½¬åŠè§’</td>
</tr>
<tr>
<td><strong>io</strong></td>
<td><code>ct.fix_contractions(text)</code></td>
<td>è‹±æ–‡ç¼©å†™(å«ä¿šè¯­è¡¨è¾¾)å¤„ç†ï¼Œ å¦‚ you&rsquo;re -&gt; you are</td>
</tr>
</tbody>
</table>
<h3 id="11-get_dict_list">1.1 get_dict_list()<a hidden class="anchor" aria-hidden="true" href="#11-get_dict_list">#</a></h3>
<p>æŸ¥çœ‹ cntext å†…ç½®è¯å…¸</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>

<span class="n">ct</span><span class="o">.</span><span class="n">get_dict_list</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">[&#39;zh_common_NTUSD.yaml&#39;,
 &#39;zh_common_DUTIR.yaml&#39;,
 &#39;enzh_common_StopWords.yaml&#39;,
 &#39;en_valence_Concreteness.yaml&#39;,
 &#39;en_common_LoughranMcDonald.yaml&#39;,
 &#39;zh_common_FinanceSenti.yaml&#39;,
 &#39;zh_common_FLS.yaml&#39;,
 &#39;zh_common_TsinghuaPraiseDegrade.yaml&#39;,
 &#39;zh_common_FEPU.yaml&#39;,
 &#39;en_common_ANEW.yaml&#39;,
 &#39;en_common_NRC.yaml&#39;,
 &#39;zh_valence_ChineseEmoBank.yaml&#39;,
 &#39;zh_valence_SixSemanticDimensionDatabase.yaml&#39;,
 &#39;zh_common_FinacialFormalUnformal.yaml&#39;,
 &#39;zh_common_LoughranMcDonald.yaml&#39;,
 &#39;enzh_common_AdvConj.yaml&#39;,
 &#39;en_common_SentiWS.yaml&#39;,
 &#39;zh_common_Digitalization.yaml&#39;,
 &#39;en_common_LSD2015.yaml&#39;,
 &#39;zh_common_HowNet.yaml&#39;,
 &#39;zh_common_EPU.yaml&#39;]
</code></pre></div><h3 id="12-å†…ç½®-yaml-è¯å…¸">1.2 å†…ç½® yaml è¯å…¸<a hidden class="anchor" aria-hidden="true" href="#12-å†…ç½®-yaml-è¯å…¸">#</a></h3>
<table>
<thead>
<tr>
<th>pkl æ–‡ä»¶</th>
<th>è¯å…¸</th>
<th>è¯­è¨€</th>
<th>åŠŸèƒ½</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong><em>zh_valence_ChineseEmoBank.yaml</em></strong></td>
<td>ä¸­æ–‡æƒ…æ„Ÿè¯å…¸ï¼Œå«<code>æ•ˆä»·valence</code>å’Œ<code>å”¤é†’åº¦arousal</code>ã€‚åœ¨ cntext ä¸­ï¼Œæˆ‘ä»¬åªä½¿ç”¨äº† CVAW è¯è¡¨(å•è¯)ï¼Œå…¶ä»–è¯å…¸å¦‚ CVAP, CVAS, CVAT æ²¡æœ‰çº³å…¥åˆ° ChineseEmoBank.pkl.</td>
<td>Chinese</td>
<td><code>æ•ˆä»·valence</code>å’Œ<code>å”¤é†’åº¦arousal</code></td>
</tr>
<tr>
<td><strong><em>zh_common_DUTIR.yaml</em></strong></td>
<td>å¤§è¿ç†å·¥å¤§å­¦æƒ…æ„Ÿæœ¬ä½“åº“</td>
<td>ä¸­æ–‡</td>
<td>ä¸ƒå¤§ç±»æƒ…ç»ªï¼Œ<code>å“€, å¥½, æƒŠ, æƒ§, ä¹, æ€’, æ¶</code></td>
</tr>
<tr>
<td><strong><em>zh_common_HowNet.yaml</em></strong></td>
<td>çŸ¥ç½‘ Hownet è¯å…¸</td>
<td>ä¸­æ–‡</td>
<td>æ­£é¢è¯ã€è´Ÿé¢è¯</td>
</tr>
<tr>
<td><code>en_common_SentiWS.yaml</code></td>
<td>SentimentWortschatz (SentiWS)</td>
<td>å¾·æ–‡</td>
<td>æ­£é¢è¯ã€è´Ÿé¢è¯ï¼›<br></td>
</tr>
<tr>
<td><strong><em>zh_common_FinacialFormalUnformal.yaml</em></strong></td>
<td>é‡‘èé¢†åŸŸæ­£å¼ã€éæ­£å¼ï¼›ç§¯ææ¶ˆæ</td>
<td>ä¸­æ–‡</td>
<td>formal-posã€<br>formal-negï¼›<br>unformal-posã€<br>unformal-neg</td>
</tr>
<tr>
<td><code>en_common_ANEW.yaml</code></td>
<td>è‹±è¯­å•è¯çš„æƒ…æ„Ÿè§„èŒƒ Affective Norms for English Words (ANEW)</td>
<td>è‹±æ–‡</td>
<td>pleasure, arousal, dominance</td>
</tr>
<tr>
<td><code>en_common_LSD2015.yaml</code></td>
<td>Lexicoder Sentiment Dictionary (2015)</td>
<td>è‹±æ–‡</td>
<td>æ­£é¢è¯ã€è´Ÿé¢è¯</td>
</tr>
<tr>
<td><code>en_common_NRC.yaml</code></td>
<td>NRC Word-Emotion Association Lexicon</td>
<td>è‹±æ–‡</td>
<td>ç»†ç²’åº¦æƒ…ç»ªè¯ï¼›</td>
</tr>
<tr>
<td><strong><em>zh_valence_SixSemanticDimensionDatabase.yaml</em></strong></td>
<td><a href="https://textdata.cn/blog/2023-03-20-nature-six-semantic-dimension-database/"><strong>é€šç”¨ä¸­è‹±æ–‡å…­ç»´è¯­ä¹‰æƒ…æ„Ÿè¯å…¸</strong></a>, å« 17940 ä¸ªä¸­æ–‡è¯çš„å…­ç»´åº¦è¯åº“ï¼Œ ä¸”æ¯ä¸ªç»´åº¦æœ‰æƒé‡ã€‚</td>
<td>ä¸­æ–‡</td>
<td>visionã€socialnessã€emotionã€timeã€spaceã€motor</td>
</tr>
<tr>
<td><code>enzh_common_AdvConj.yaml</code></td>
<td>å‰¯è¯è¿è¯</td>
<td>ä¸­ã€è‹±</td>
<td></td>
</tr>
<tr>
<td><strong><em>enzh_common_StopWords.yaml</em></strong></td>
<td>ä¸­è‹±æ–‡åœç”¨è¯</td>
<td>ä¸­ã€è‹±</td>
<td>åœç”¨è¯</td>
</tr>
<tr>
<td><strong><em>en_valence_Concreteness.yaml</em></strong></td>
<td><a href="https://textdata.cn/blog/jcr_concreteness_computation/">è‹±æ–‡å…·ä½“æ€§è¯å…¸</a></td>
<td>English</td>
<td>word &amp; concreateness score</td>
</tr>
<tr>
<td><strong><em>zh_common_LoughranMcDonald.yaml</em></strong></td>
<td>ä¸­æ–‡ LoughranMcDonald è¯å…¸</td>
<td>ä¸­æ–‡</td>
<td>æ­£é¢ã€è´Ÿé¢è¯</td>
</tr>
<tr>
<td><strong><em>zh_common_Digitalization.yaml</em></strong></td>
<td><a href="https://textdata.cn/blog/2022-11-03-mda-measure-digitalization/">ç®¡ç†ä¸–ç•Œ|å´é(2021)æ•°å­—åŒ–è¯å…¸</a></td>
<td>ä¸­æ–‡</td>
<td>å«äººå·¥æ™ºèƒ½æŠ€æœ¯ã€å¤§æ•°æ®æŠ€æœ¯ã€äº‘è®¡ç®—æŠ€æœ¯ã€åŒºå—é“¾æŠ€æœ¯ã€æ•°å­—æŠ€æœ¯åº”ç”¨ç­‰å…³é”®è¯åˆ—è¡¨ã€‚</td>
</tr>
<tr>
<td><strong><em>en_common_LoughranMcDonald.yaml</em></strong></td>
<td>è‹±æ–‡ LoughranMcDonald è¯å…¸</td>
<td>è‹±æ–‡</td>
<td>é‡‘è LM æƒ…ç»ªè¯å…¸ 2018 å¹´ç‰ˆæœ¬ï¼Œå«ä¸ƒä¸ªè¯è¡¨ï¼Œåˆ†åˆ«æ˜¯ Negative, Positive, Uncertainty, Litigious, StrongModal, WeakModal, Constraining</td>
</tr>
<tr>
<td><strong><em>zh_common_FLS.yaml</em></strong></td>
<td><a href="https://textdata.cn/blog/2023-09-08-earnings-communication-conference-forward-looking-statements-information/"><strong>ä¸šç»©è¯´æ˜ä¼šå‰ç»æ€§è¯å…¸é›†</strong></a></td>
<td>ä¸­æ–‡</td>
<td>å« 174 ä¸ªè¯è¯­</td>
</tr>
<tr>
<td><strong><em>zh_common_RhetoricalNationalism.yaml</em></strong></td>
<td>ä¿®è¾æ°‘æ—ä¸»ä¹‰</td>
<td>ä¸­æ–‡</td>
<td>å«å››ä¸ªç»´åº¦ï¼Œæ°‘æ—è‡ªè±ªæ„Ÿã€æ°‘æ—å¤å…´ã€ä¼ä¸šè§’è‰²ã€æ’å¤–ä¸»ä¹‰ï¼Œæ¯ä¸ªç»´åº¦ 100 ä¸ªè¯ã€‚</td>
</tr>
</tbody>
</table>
<br>
<h3 id="13-read_dict_yaml">1.3 read_dict_yaml()<a hidden class="anchor" aria-hidden="true" href="#13-read_dict_yaml">#</a></h3>
<p>ä½¿ç”¨ cntext è¯»å– <strong><em>.yaml</em></strong> è¯å…¸æ–‡ä»¶ï¼› è¿”å›çš„ä¿¡æ¯åŒ…æ‹¬</p>
<ul>
<li>Name è¯å…¸çš„åå­—</li>
<li>Desc è¯å…¸çš„å«ä¹‰ã€æ¦‚å¿µè§£é‡Š</li>
<li>Refer è¯å…¸æ–‡çŒ®å‡ºå¤„</li>
<li>Category è¯å…¸ Dictionary çš„å…³é”®è¯</li>
<li>Dictionary è¯å…¸, python å­—å…¸æ ¼å¼</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>
<span class="nb">print</span><span class="p">(</span><span class="n">ct</span><span class="o">.</span><span class="n">read_yaml_dict</span><span class="p">(</span><span class="s1">&#39;zh_common_Digitalization.yaml&#39;</span><span class="p">))</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">{&#39;Name&#39;: &#39;ä¸­æ–‡æ•°å­—åŒ–è¯å…¸&#39;,
&#39;Desc&#39;: &#39;åŸºäºè¿™ç¯‡è®ºæ–‡ï¼Œæ„å»ºäº†ä¸­æ–‡æ•°å­—åŒ–è¯å…¸ï¼Œå«äººå·¥æ™ºèƒ½æŠ€æœ¯ã€å¤§æ•°æ®æŠ€æœ¯ã€äº‘è®¡ç®—æŠ€æœ¯ã€åŒºå—é“¾æŠ€æœ¯ã€æ•°å­—æŠ€æœ¯åº”ç”¨ç­‰å…³é”®è¯åˆ—è¡¨ã€‚ &#39;, &#39;Refer&#39;: &#39;å´é,èƒ¡æ…§èŠ·,æ—æ…§å¦,ä»»æ™“æ€¡. ä¼ä¸šæ•°å­—åŒ–è½¬å‹ä¸èµ„æœ¬å¸‚åœºè¡¨ç°â€”â€”æ¥è‡ªè‚¡ç¥¨æµåŠ¨æ€§çš„ç»éªŒè¯æ®[J]. ç®¡ç†ä¸–ç•Œ,2021,37(07):130-144+10.&#39;,
&#39;Category&#39;: [&#39;Artificial_Intelligence&#39;, &#39;Big_Data&#39;, &#39;Cloud_Computing&#39;, &#39;Block_Chains&#39;, &#39;Usage_of_Digitalization&#39;],

&#39;Dictionary&#39;:
    {&#39;Artificial_Intelligence&#39;: [&#39;äººå·¥æ™ºèƒ½&#39;, &#39;å•†ä¸šæ™ºèƒ½&#39;, &#39;å›¾åƒç†è§£&#39;, &#39;æŠ•èµ„å†³ç­–è¾…åŠ©ç³»ç»Ÿ&#39;, &#39;æ™ºèƒ½æ•°æ®åˆ†æ&#39;, &#39;æ™ºèƒ½æœºå™¨äºº&#39;, &#39;æœºå™¨å­¦ä¹ &#39;, &#39;æ·±åº¦å­¦ä¹ &#39;, &#39;è¯­ä¹‰æœç´¢&#39;, &#39;ç”Ÿç‰©è¯†åˆ«æŠ€æœ¯&#39;, &#39;äººè„¸è¯†åˆ«&#39;, &#39;è¯­éŸ³è¯†åˆ«&#39;, &#39;èº«ä»½éªŒè¯&#39;, &#39;è‡ªåŠ¨é©¾é©¶&#39;, &#39;è‡ªç„¶è¯­è¨€å¤„ç†&#39;],
    &#39;Big_Data&#39;: [&#39;å¤§æ•°æ®&#39;, &#39;æ•°æ®æŒ–æ˜&#39;, &#39;æ–‡æœ¬æŒ–æ˜&#39;, &#39;æ•°æ®å¯è§†åŒ–&#39;, &#39;å¼‚æ„æ•°æ®&#39;, &#39;å¾ä¿¡&#39;, &#39;å¢å¼ºç°å®&#39;, &#39;æ··åˆç°å®&#39;, &#39;è™šæ‹Ÿç°å®&#39;],
    &#39;Cloud_Computing&#39;: [&#39;äº‘è®¡ç®—&#39;, &#39;æµè®¡ç®—&#39;, &#39;å›¾è®¡ç®—&#39;, &#39;å†…å­˜è®¡ç®—&#39;, &#39;å¤šæ–¹å®‰å…¨è®¡ç®—&#39;, &#39;ç±»è„‘è®¡ç®—&#39;, &#39;ç»¿è‰²è®¡ç®—&#39;, &#39;è®¤çŸ¥è®¡ç®—&#39;, &#39;èåˆæ¶æ„&#39;, &#39;äº¿çº§å¹¶å‘&#39;, &#39;EBçº§å­˜å‚¨&#39;, &#39;ç‰©è”ç½‘&#39;, &#39;ä¿¡æ¯ç‰©ç†ç³»ç»Ÿ&#39;],
    &#39;Block_Chains&#39;: [&#39;åŒºå—é“¾&#39;, &#39;æ•°å­—è´§å¸&#39;, &#39;åˆ†å¸ƒå¼è®¡ç®—&#39;, &#39;å·®åˆ†éšç§æŠ€æœ¯&#39;, &#39;æ™ºèƒ½é‡‘èåˆçº¦&#39;],
    &#39;Usage_of_Digitalization&#39;: [&#39;ç§»åŠ¨äº’è”ç½‘&#39;, &#39;å·¥ä¸šäº’è”ç½‘&#39;, &#39;ç§»åŠ¨äº’è”&#39;, &#39;äº’è”ç½‘åŒ»ç–—&#39;, &#39;ç”µå­å•†åŠ¡&#39;, &#39;ç§»åŠ¨æ”¯ä»˜&#39;, &#39;ç¬¬ä¸‰æ–¹æ”¯ä»˜&#39;, &#39;NFCæ”¯ä»˜&#39;, &#39;æ™ºèƒ½èƒ½æº&#39;, &#39;B2B&#39;, &#39;B2C&#39;, &#39;C2B&#39;, &#39;C2C&#39;, &#39;O2O&#39;, &#39;ç½‘è”&#39;, &#39;æ™ºèƒ½ç©¿æˆ´&#39;, &#39;æ™ºæ…§å†œä¸š&#39;, &#39;æ™ºèƒ½äº¤é€š&#39;, &#39;æ™ºèƒ½åŒ»ç–—&#39;, &#39;æ™ºèƒ½å®¢æœ&#39;, &#39;æ™ºèƒ½å®¶å±…&#39;, &#39;æ™ºèƒ½æŠ•é¡¾&#39;, &#39;æ™ºèƒ½æ–‡æ—…&#39;, &#39;æ™ºèƒ½ç¯ä¿&#39;, &#39;æ™ºèƒ½ç”µç½‘&#39;, &#39;æ™ºèƒ½è¥é”€&#39;, &#39;æ•°å­—è¥é”€&#39;, &#39;æ— äººé›¶å”®&#39;, &#39;äº’è”ç½‘é‡‘è&#39;, &#39;æ•°å­—é‡‘è&#39;, &#39;Fintech&#39;, &#39;é‡‘èç§‘æŠ€&#39;, &#39;é‡åŒ–é‡‘è&#39;, &#39;å¼€æ”¾é“¶è¡Œ&#39;]}}
</code></pre></div><br>
<h3 id="14-detect_encoding">1.4 detect_encoding()<a hidden class="anchor" aria-hidden="true" href="#14-detect_encoding">#</a></h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">ct.detect_encoding(file)
</code></pre></div><p>é€šè¿‡è¯»å–å‰ num_lines æ¥è¯†åˆ« txt/csv æ–‡ä»¶çš„ç¼–ç æ ¼å¼</p>
<ul>
<li><strong><em>file</em></strong> æ–‡ä»¶è·¯å¾„</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>

<span class="c1">#è¯»å–dataæ–‡ä»¶å¤¹ä¸‹çš„ã€ä¸‰ä½“.txtã€‘</span>
<span class="c1">#è¯†åˆ«ç¼–ç æ–¹å¼</span>
<span class="n">ct</span><span class="o">.</span><span class="n">detect_encoding</span><span class="p">(</span><span class="n">file</span><span class="o">=</span><span class="s1">&#39;data/ä¸‰ä½“.txt&#39;</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">utf-8
</code></pre></div><br>
<h3 id="15-get_filesfformat">1.5 get_files(fformat)<a hidden class="anchor" aria-hidden="true" href="#15-get_filesfformat">#</a></h3>
<ul>
<li><strong>fformat</strong> fformat æ ¼å¼æ”¯æŒ txt/pdf/docx/xlsx/csv ç­‰ã€‚ <code>*</code>è¡¨ç¤ºé€šé…ç¬¦</li>
</ul>
<p>æŸ¥çœ‹ç¬¦åˆ fformat è·¯å¾„è§„åˆ™çš„æ‰€æœ‰çš„æ–‡ä»¶ï¼Œ fformat æ ¼å¼æ”¯æŒ txt/pdf/docx/xlsx/csv ç­‰ã€‚ <code>*</code>è¡¨ç¤ºé€šé…ç¬¦</p>
<table>
<thead>
<tr>
<th>fformat æ ¼å¼</th>
<th>è¯†åˆ«çš„æ–‡ä»¶</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>*.txt</code></td>
<td>åŒ¹é…å½“å‰ä»£ç æ‰€åœ¨è·¯å¾„å†…çš„æ‰€æœ‰ txt</td>
</tr>
<tr>
<td><code>*.pdf</code></td>
<td>åŒ¹é…å½“å‰ä»£ç æ‰€åœ¨è·¯å¾„å†…çš„æ‰€æœ‰ pdf</td>
</tr>
<tr>
<td><code>data/*.txt</code></td>
<td>åŒ¹é…ã€Œæ–‡ä»¶å¤¹ dataã€å†…æ‰€æœ‰çš„ txt</td>
</tr>
<tr>
<td><br></td>
<td></td>
</tr>
</tbody>
</table>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#æŸ¥çœ‹ã€æ–‡ä»¶å¤¹dataã€‘å†…æ‰€æœ‰çš„ txtæ–‡ä»¶ã€‚</span>
<span class="n">ct</span><span class="o">.</span><span class="n">get_files</span><span class="p">(</span><span class="n">fformat</span><span class="o">=</span><span class="s1">&#39;data/*.txt&#39;</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">[&#39;data/ä¸‰ä½“.txt&#39;,
 &#39;data/santi.txt&#39;,
 &#39;data/w2v_corpus.txt&#39;,
 &#39;data/sopmi_corpus.txt&#39;,
 &#39;data/brown_corpus.txt&#39;,
 &#39;data/sopmi_seed_words.txt&#39;]
</code></pre></div><br>
<h3 id="16-read_pdf">1.6 read_pdf<a hidden class="anchor" aria-hidden="true" href="#16-read_pdf">#</a></h3>
<p>è¯»å– PDFï¼Œè¿”å›æ–‡æœ¬å†…å®¹</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">ct</span><span class="o">.</span><span class="n">read_pdf</span><span class="p">(</span><span class="n">file</span><span class="p">)</span>
</code></pre></div><ul>
<li><strong><em>file</em></strong> PDF æ–‡ä»¶è·¯å¾„</li>
</ul>
<p>ç‚¹å‡» <a href="https://textdata.cn/data/%E6%A0%BC%E5%8A%9B%E7%94%B5%E5%99%A82023.pdf"><strong>æ ¼åŠ›ç”µå™¨ 2023.pdf</strong></a></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>

<span class="n">text</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">read_pdf</span><span class="p">(</span><span class="s1">&#39;æ ¼åŠ›ç”µå™¨2023.pdf&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">ç æµ·æ ¼åŠ›ç”µå™¨è‚¡ä»½æœ‰é™å…¬å¸ 2023å¹´å¹´åº¦æŠ¥å‘Šå…¨æ–‡
ç æµ·æ ¼åŠ›ç”µå™¨è‚¡ä»½æœ‰é™å…¬å¸
2023å¹´å¹´åº¦æŠ¥å‘Š


äºŒã€‡äºŒå››å¹´å››æœˆ
ç æµ·æ ¼åŠ›ç”µå™¨è‚¡ä»½æœ‰é™å…¬å¸ 2023å¹´å¹´åº¦æŠ¥å‘Šå…¨æ–‡
 ç¬¬ 2 é¡µ å…± 249 é¡µ ç¬¬ä¸€èŠ‚ é‡è¦æç¤ºã€ç›®å½•å’Œé‡Šä¹‰
å…¬å¸è‘£äº‹ä¼šã€ç›‘äº‹ä¼šåŠè‘£äº‹ã€ç›‘äº‹ã€é«˜çº§ç®¡ç†äººå‘˜ä¿è¯å¹´åº¦æŠ¥å‘Šå†…å®¹
çš„çœŸå®ã€å‡†ç¡®ã€å®Œæ•´ï¼Œä¸å­˜åœ¨è™šå‡è®°è½½ã€è¯¯å¯¼æ€§é™ˆè¿°æˆ–é‡å¤§é—æ¼ï¼Œå¹¶æ‰¿æ‹…
ä¸ªåˆ«å’Œè¿å¸¦çš„æ³•å¾‹
......
</code></pre></div><br>
<h3 id="17-read_docx">1.7 read_docx<a hidden class="anchor" aria-hidden="true" href="#17-read_docx">#</a></h3>
<p>è¯»å– docxï¼Œè¿”å›æ–‡æœ¬å†…å®¹</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">ct</span><span class="o">.</span><span class="n">read_docx</span><span class="p">(</span><span class="n">file</span><span class="p">)</span>
</code></pre></div><ul>
<li><strong><em>file</em></strong> docx æ–‡ä»¶è·¯å¾„</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>

<span class="n">text</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">read_docx</span><span class="p">(</span><span class="s1">&#39;test.docx&#39;</span><span class="p">)</span>
<span class="n">text</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">è¿™æ˜¯æ¥è‡ªtest.docxé‡Œå†…å®¹
</code></pre></div><br>
<h3 id="18-read_file">1.8 read_file()<a hidden class="anchor" aria-hidden="true" href="#18-read_file">#</a></h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">ct.read_file(file, encoding=&#39;utf-8&#39;)
</code></pre></div><ul>
<li><strong>file</strong> å¾…è¯»å–çš„æ–‡ä»¶è·¯å¾„ï¼› æ”¯æŒ txtã€pdfã€docxã€xlsxã€xlsï¼Œ è¿”å› DataFrame(å« doc å’Œ file ä¸¤ä¸ªå­—æ®µ)ã€‚</li>
<li><strong>encoding</strong> å¾…è¯»å–æ–‡ä»¶çš„ç¼–ç æ–¹å¼</li>
</ul>
<p>ä»¥ <code>data/ä¸‰ä½“.txt</code> ä¸ºä¾‹</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>

<span class="c1">#é»˜è®¤encoding=&#39;utf-8&#39;</span>
<span class="c1">#sdf = ct.read_file(file=&#39;data/ä¸‰ä½“.txt&#39;)</span>

<span class="n">sdf</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">read_file</span><span class="p">(</span><span class="n">file</span><span class="o">=</span><span class="s1">&#39;data/ä¸‰ä½“.txt&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span>
<span class="n">sdf</span>
</code></pre></div><p><img loading="lazy" src="img/01-san_ti_df.png" alt=""  />
</p>
<br>
<h3 id="19-read_files">1.9 read_files()<a hidden class="anchor" aria-hidden="true" href="#19-read_files">#</a></h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">ct.read_files(fformat, encoding=&#39;utf-8&#39;ï¼‰
</code></pre></div><p>æ‰¹é‡è¯»å–ç¬¦åˆ fformat æ ¼å¼çš„æ‰€æœ‰æ–‡ä»¶æ•°æ®ï¼Œè¿”å› DataFrame(å« doc å’Œ file ä¸¤ä¸ªå­—æ®µ)ã€‚</p>
<p>è¯»å–[æ–‡ä»¶å¤¹ data é‡Œæ‰€æœ‰ txt]</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>

<span class="c1">#é»˜è®¤encoding=&#39;utf-8&#39;</span>
<span class="c1">#ddf = ct.read_files(fformat=&#39;data/*.txt&#39;)</span>

<span class="n">ddf</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">read_files</span><span class="p">(</span><span class="n">fformat</span><span class="o">=</span><span class="s1">&#39;data/*.txt&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span>
<span class="n">ddf</span>
</code></pre></div><p><img loading="lazy" src="img/02-ddf.png" alt=""  />
</p>
<br>
<h3 id="110-extract_mda">1.10 extract_mda<a hidden class="anchor" aria-hidden="true" href="#110-extract_mda">#</a></h3>
<p>æå– A è‚¡å¹´æŠ¥ä¸­çš„ MD&amp;A æ–‡æœ¬å†…å®¹ã€‚å¦‚æœè¿”å›'',åˆ™æå–å¤±è´¥ã€‚</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">ct.extract_mda(text, kws_pattern=&#39;&#39;)
</code></pre></div><ul>
<li>text ä¸­å›½ A è‚¡å¹´æŠ¥åŸå§‹æ–‡æœ¬</li>
<li>kws_pattern ç®¡ç†å±‚è®¨è®ºä¸åˆ†æç« èŠ‚è¯†åˆ«å…³é”®è¯çš„æ¨¡æ¿ã€‚cntext å†…ç½®çš„ kws_pattern å†…å®¹å¦‚ä¸‹</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">kws_pattern = &#39;è‘£äº‹ä¼šæŠ¥å‘Š|è‘£äº‹ä¼šæŠ¥å‘Šä¸ç®¡ç†è®¨è®º|ä¼ä¸šè¿è¥ä¸ç®¡ç†è¯„è¿°|ç»è¥æ€»ç»“ä¸åˆ†æ|ç®¡ç†å±‚è¯„ä¼°ä¸æœªæ¥å±•æœ›|è‘£äº‹å±€æŠ¥å‘Š|ç®¡ç†å±‚è®¨è®ºä¸åˆ†æ|ç»è¥æƒ…å†µè®¨è®ºä¸åˆ†æ|ç»è¥ä¸šç»©åˆ†æ|ä¸šåŠ¡å›é¡¾ä¸å±•æœ›|å…¬å¸ç»è¥åˆ†æ|ç®¡ç†å±‚è¯„è®ºä¸åˆ†æ|æ‰§è¡Œæ‘˜è¦ä¸ä¸šåŠ¡å›é¡¾|ä¸šåŠ¡è¿è¥åˆ†æ&#39;
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>

<span class="n">text</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">read_pdf</span><span class="p">(</span><span class="s1">&#39;æ ¼åŠ›ç”µå™¨2023.pdf&#39;</span><span class="p">)</span>
<span class="n">mda_text</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">extract_mda</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">mda_text</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">&#39;ç®¡ç†å±‚è®¨è®ºä¸åˆ†æ  \nä¸€ã€æŠ¥å‘ŠæœŸå†…å…¬å¸æ‰€å¤„è¡Œä¸šæƒ…å†µ  \nï¼ˆä¸€ï¼‰è¡Œä¸šå‘å±•ç°çŠ¶  \n1.æ¶ˆè´¹é¢†åŸŸ â€”â€”å®¶ç”µè¡Œä¸šç¨³å®šå¢é•¿ï¼Œç©ºè°ƒå¸‚åœºæ¢å¤æ˜æ˜¾  \n2023å¹´ï¼Œä¸­å›½ç»æµä¿æŒäº†æ•´ä½“æ¢å¤å‘å¥½çš„æ€åŠ¿ï¼Œæ¿€å‘æ¶ˆè´¹æ˜¯ç¨³å¢é•¿çš„é‡ä¸­ä¹‹é‡ã€‚å›½å®¶é¼“åŠ±å’Œæ¨åŠ¨æ¶ˆè´¹å“ä»¥æ—§æ¢\næ–°ï¼Œä¿ƒè¿›æ¶ˆè´¹ç»æµå¤§å¾ªç¯ï¼ŒåŠ é€Ÿæ›´æ–°éœ€æ±‚é‡Šæ”¾ï¼Œæ¨åŠ¨é«˜èƒ½æ•ˆäº§å“è®¾å¤‡é”€å”®å’Œå‡ºå£å¢é•¿ï¼Œè¿›ä¸€æ­¥æ¿€å‘ç»¿è‰²æ¶ˆè´¹æ½œåŠ›ã€‚  \n1ï¼‰å®¶ç”µè¡Œä¸šç¨³å®šå¢é•¿  \n2023å¹´ï¼Œå›½å†…ç»æµæ¢å¤æ˜æ˜¾ï¼Œå®¶ç”µè¡Œä¸šç¨³å®šå¢é•¿ã€‚æ ¹æ®å…¨å›½å®¶ç”¨ç”µå™¨å·¥ä¸šä¿¡æ¯ä¸­å¿ƒå‘å¸ƒçš„ã€Š 2023å¹´ä¸­å›½å®¶ç”µ\nè¡Œä¸šå¹´åº¦æŠ¥å‘Šã€‹ï¼Œå®¶ç”µè¡Œä¸šå¤–é”€æ˜æ˜¾å¢é•¿ï¼Œå‡ºå£è§„æ¨¡ä¸º 6,174äº¿å…ƒï¼ŒåŒæ¯”å¢é•¿ 9.9%ï¼›å›½å†…å¸‚åœºå®ç°ç¨³æ­¥å¢é•¿ï¼Œé”€å”®\nè§„æ¨¡ä¸º7&#39;
.......
.......
</code></pre></div><br>
<p>ä»¥<a href="https://textdata.cn/blog/2023-03-23-china-a-share-market-dataset-mda-from-01-to-21/">2001 å¹´~2023 ä¼šè®¡å¹´åº¦æŠ¥å‘Šæ•°æ®é›†</a>ä¸ºä¾‹ï¼Œ æŸ¥çœ‹ <strong><em>extract_mda</em></strong> çš„æŠ½å– mda çš„èƒ½åŠ›ã€‚</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">glob</span>
<span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;extract_mdaè¯†åˆ«èƒ½åŠ›&#39;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">year</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2001</span><span class="p">,</span> <span class="mi">2024</span><span class="p">):</span>
    <span class="n">num</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">file</span> <span class="ow">in</span> <span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;å¹´æŠ¥txt/</span><span class="si">{</span><span class="n">year</span><span class="si">}</span><span class="s1">/*.txt&#39;</span><span class="p">):</span>
        <span class="n">mda_text</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">extract_mda</span><span class="p">(</span><span class="nb">open</span><span class="p">(</span><span class="n">file</span><span class="p">)</span><span class="o">.</span><span class="n">read</span><span class="p">())</span>
        <span class="k">if</span> <span class="n">mda_text</span><span class="o">!=</span><span class="s1">&#39;&#39;</span><span class="p">:</span>
            <span class="n">num</span> <span class="o">=</span> <span class="n">num</span> <span class="o">+</span> <span class="mi">1</span>

    <span class="n">volume</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;å¹´æŠ¥txt/</span><span class="si">{</span><span class="n">year</span><span class="si">}</span><span class="s1">/*.txt&#39;</span><span class="p">))</span>
    <span class="n">ratio</span> <span class="o">=</span> <span class="n">num</span><span class="o">/</span><span class="n">volume</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">year</span><span class="si">}</span><span class="s1">: </span><span class="si">{</span><span class="n">ratio</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">2001: 0.24
2002: 0.37
2003: 0.43
2004: 0.70
2005: 0.77
2006: 0.78
2007: 0.79
2008: 0.77
2009: 0.79
2010: 0.82
2011: 0.84
2012: 0.96
2013: 0.95
2014: 0.98
2015: 0.98
2016: 0.99
2017: 0.98
2018: 0.98
2019: 0.99
2020: 0.97
2021: 0.98
2022: 0.99
2023: 0.99
</code></pre></div><p>å»ºè®®å„ä½ç”¨æœ€è¿‘ 10 å¹´çš„å¹´æŠ¥æ•°æ®ï¼Œé€šè¿‡ extract_mda æå– mda æ–‡æœ¬ï¼Œæˆ–è€…ç›´æ¥è´­ä¹° [æ•°æ®é›† | 2001-2023 å¹´ A è‚¡ä¸Šå¸‚å…¬å¸å¹´æŠ¥&amp;ç®¡ç†å±‚è®¨è®ºä¸åˆ†æ](æ•°æ®é›† | 2001-2023 å¹´ A è‚¡ä¸Šå¸‚å…¬å¸å¹´æŠ¥&amp;ç®¡ç†å±‚è®¨è®ºä¸åˆ†æ)</p>
<br>
<h3 id="111-traditional2simple">1.11 traditional2simple()<a hidden class="anchor" aria-hidden="true" href="#111-traditional2simple">#</a></h3>
<p>ç¹ä½“è½¬ç®€ä½“</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">ct.traditional2simple(text, mode=&#39;t2s&#39;)
</code></pre></div><ul>
<li><strong><em>text</em></strong> å¾…è½¬æ¢çš„æ–‡æœ¬</li>
<li><strong><em>mode</em></strong> è½¬æ¢æ¨¡å¼ï¼Œ é»˜è®¤ mode=&lsquo;t2s&rsquo;ç¹è½¬ç®€; mode è¿˜æ”¯æŒ s2t</li>
</ul>
 <br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>

<span class="n">text</span> <span class="o">=</span> <span class="s1">&#39;ç°¡é«”æ¼¢å­—&#39;</span>
<span class="n">ct</span><span class="o">.</span><span class="n">traditional2simple</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">&#39;ç®€ä½“æ±‰å­—&#39;
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">text</span> <span class="o">=</span> <span class="s1">&#39;ç®€ä½“æ±‰å­—&#39;</span>
<span class="n">ct</span><span class="o">.</span><span class="n">traditional2simple</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;s2t&#39;</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">&#39;ç°¡é«”æ¼¢å­—&#39;
</code></pre></div><br>
<h3 id="112-fix_text">1.12 fix_text()<a hidden class="anchor" aria-hidden="true" href="#112-fix_text">#</a></h3>
<p>å°†ä¸æ­£å¸¸çš„ã€æ··ä¹±ç¼–ç çš„æ–‡æœ¬è½¬åŒ–ä¸ºæ­£å¸¸çš„æ–‡æœ¬ã€‚ä¾‹å¦‚å…¨è§’è½¬åŠè§’</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>

<span class="n">raw_text</span> <span class="o">=</span> <span class="s1">&#39;ä»Šæ—¥èµ·å¯ä¸­é‡åˆ°æŠ€æœ¯é—®é¢˜ï¼Œå¯ä»¥æ‹¨æ‰“ç”µè¯ï¼ï¼“ï¼—ï¼‘ï¼ï¼–ï¼–ï¼“ï¼’ï¼‘ï¼™ï¼™ï¼‘ã€ï¼–ï¼–ï¼“ï¼’ï¼‘ï¼™ï¼—ï¼“å’¨è¯¢ã€‚&#39;</span>

<span class="n">text</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">fix_text</span><span class="p">(</span><span class="n">raw_text</span><span class="p">)</span>
<span class="n">text</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">ä»Šæ—¥èµ·å¯ä¸­é‡åˆ°æŠ€æœ¯é—®é¢˜ï¼Œå¯ä»¥æ‹¨æ‰“ç”µè¯0371-66321991ã€66321973å’¨è¯¢ã€‚
</code></pre></div><br>
<h3 id="113-fix_contractionstext">1.13 fix_contractions(text)<a hidden class="anchor" aria-hidden="true" href="#113-fix_contractionstext">#</a></h3>
<p>å°†è‹±æ–‡ç¼©å†™(å«ä¿šè¯­è¡¨è¾¾)è½¬åŒ–ä¸ºå®Œæ•´çš„è¡¨è¾¾ï¼Œå¦‚å¦‚</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">- you&#39;re -&gt; you are
- yall  -&gt; you all
- gotta  -&gt; got to
...
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>

<span class="n">raw_text</span> <span class="o">=</span> <span class="s2">&#34;yall&#39;re happy now&#34;</span>

<span class="n">text</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">fix_contractions</span><span class="p">(</span><span class="n">raw_text</span><span class="p">)</span>
<span class="n">text</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">&#34;you all are happy now&#34;
</code></pre></div><br>
<h3 id="114-clean_texttext">1.14 clean_text(text)<a hidden class="anchor" aria-hidden="true" href="#114-clean_texttext">#</a></h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">ct</span><span class="o">.</span><span class="n">clean_text</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">lang</span><span class="o">=</span><span class="s1">&#39;chinese&#39;</span><span class="p">)</span>
</code></pre></div><ul>
<li><strong><em>text</em></strong> å¾…å¤„ç†çš„æ–‡æœ¬</li>
<li><strong><em>lang</em></strong> è¯­è¨€ç±»å‹ï¼Œ é»˜è®¤ lang=&lsquo;chinese&rsquo;, æ”¯æŒ&quot;english&quot;ã€&ldquo;chinese&rdquo;</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>

<span class="n">chinese_text</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&#34;ä»Šå¤©çš„è®­ç»ƒå¾ˆæ£’ï¼è·‘äº†5.6å…¬é‡Œï¼Œå¿ƒç‡ç¨³å®šã€‚&#34;</span>
                <span class="s2">&#34;æŸ¥çœ‹ https://example.com/data ğŸ˜Š #å¥èº«æ‰“å¡&#34;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&#34;&gt;&gt;&gt; ä¸­æ–‡æ¸…æ´—&#34;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&#34;åŸå§‹:&#34;</span><span class="p">,</span> <span class="nb">repr</span><span class="p">(</span><span class="n">chinese_text</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&#34;æ¸…æ´—:&#34;</span><span class="p">,</span> <span class="nb">repr</span><span class="p">(</span><span class="n">ct</span><span class="o">.</span><span class="n">clean_text</span><span class="p">(</span><span class="n">chinese_text</span><span class="p">,</span> <span class="n">lang</span><span class="o">=</span><span class="s2">&#34;chinese&#34;</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">()</span>

    <span class="c1"># è‹±æ–‡æµ‹è¯•</span>
<span class="n">english_text</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&#34;Great workout today! Ran 5.6 miles, HR stable. &#34;</span>
                <span class="s2">&#34;Check https://example.com/data ğŸ˜Š #Fitness&#34;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&#34;&gt;&gt;&gt; è‹±æ–‡æ¸…æ´—&#34;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&#34;åŸå§‹:&#34;</span><span class="p">,</span> <span class="nb">repr</span><span class="p">(</span><span class="n">english_text</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&#34;æ¸…æ´—:&#34;</span><span class="p">,</span> <span class="nb">repr</span><span class="p">(</span><span class="n">ct</span><span class="o">.</span><span class="n">clean_text</span><span class="p">(</span><span class="n">english_text</span><span class="p">,</span> <span class="n">lang</span><span class="o">=</span><span class="s2">&#34;english&#34;</span><span class="p">)))</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">&gt;&gt;&gt; ä¸­æ–‡æ¸…æ´—
åŸå§‹: &#39;ä»Šå¤©çš„è®­ç»ƒå¾ˆæ£’ï¼è·‘äº†5.6å…¬é‡Œï¼Œå¿ƒç‡ç¨³å®šã€‚æŸ¥çœ‹ https://example.com/data ğŸ˜Š #å¥èº«æ‰“å¡&#39;
æ¸…æ´—: &#39;ä»Šå¤©çš„è®­ç»ƒå¾ˆæ£’ï¼è·‘äº†æ•°å­—å…¬é‡Œï¼Œå¿ƒç‡ç¨³å®šã€‚æŸ¥çœ‹   å¥èº«æ‰“å¡&#39;

&gt;&gt;&gt; è‹±æ–‡æ¸…æ´—
åŸå§‹: &#39;Great workout today! Ran 5.6 miles, HR stable. Check https://example.com/data ğŸ˜Š #Fitness&#39;
æ¸…æ´—: &#39;great workout today! ran NUMBER miles, hr stable. check  ğŸ˜Š #fitness&#39;
</code></pre></div><p><br><br></p>
<h2 id="äºŒstats-æ¨¡å—">äºŒã€Stats æ¨¡å—<a hidden class="anchor" aria-hidden="true" href="#äºŒstats-æ¨¡å—">#</a></h2>
<table>
<thead>
<tr>
<th>æ¨¡å—</th>
<th>å‡½æ•°</th>
<th>åŠŸèƒ½</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>stats</strong></td>
<td><code>ct.word_count(text, lang='chinese')</code></td>
<td>è¯é¢‘ç»Ÿè®¡</td>
</tr>
<tr>
<td><strong>stats</strong></td>
<td><code>ct.readability(text, lang='chinese')</code></td>
<td>æ–‡æœ¬å¯è¯»æ€§</td>
</tr>
<tr>
<td><strong>stats</strong></td>
<td><strong><em>ct.sentiment(text, diction, lang=&lsquo;chinese&rsquo;)</em></strong></td>
<td>æ— (ç­‰)æƒé‡è¯å…¸çš„æƒ…æ„Ÿåˆ†æ</td>
</tr>
<tr>
<td><strong>stats</strong></td>
<td><code>ct.sentiment_by_valence(text, diction, lang='chinese')</code></td>
<td>å¸¦æƒé‡çš„è¯å…¸çš„æƒ…æ„Ÿåˆ†æ</td>
</tr>
<tr>
<td><strong>stats</strong></td>
<td><strong><em>ct.word_in_context(text, keywords, window=3, lang=&lsquo;chinese&rsquo;)</em></strong></td>
<td>åœ¨ text ä¸­æŸ¥æ‰¾ keywords å‡ºç°çš„ä¸Šä¸‹æ–‡å†…å®¹(çª—å£ window)ï¼Œè¿”å› df</td>
</tr>
<tr>
<td><strong>stats</strong></td>
<td><strong><em>ct.epu(text, e_pattern, p_pattern, u_pattern)</em></strong></td>
<td>ä½¿ç”¨æ–°é—»æ–‡æœ¬æ•°æ®è®¡ç®—ç»æµæ”¿ç­–ä¸ç¡®å®šæ€§ EPUï¼Œè¿”å› df</td>
</tr>
<tr>
<td><strong>stats</strong></td>
<td><strong><em>ct.fepu(text, ep_pattern='&rsquo;, u_pattern='')</em></strong></td>
<td>ä½¿ç”¨ md&amp;a æ–‡æœ¬æ•°æ®è®¡ç®—ä¼ä¸šä¸ç¡®å®šæ€§æ„ŸçŸ¥ FEPU</td>
</tr>
<tr>
<td><strong>stats</strong></td>
<td><strong><em>ct.semantic_brand_score(text, brands, lang=&lsquo;chinese&rsquo;)</em></strong></td>
<td>è¡¡é‡å“ç‰Œï¼ˆä¸ªä½“ã€å…¬å¸ã€å“ç‰Œã€å…³é”®è¯ç­‰ï¼‰çš„é‡è¦æ€§</td>
</tr>
<tr>
<td><strong>stats</strong></td>
<td><strong><em>ct.cosine_sim(text1, text2, lang=&lsquo;chinese&rsquo;)</em></strong></td>
<td>ä½™å¼¦ç›¸ä¼¼åº¦</td>
</tr>
<tr>
<td><strong>stats</strong></td>
<td><code>ct.jaccard_sim(text1, text2, lang='chinese')</code></td>
<td>Jaccard ç›¸ä¼¼åº¦</td>
</tr>
<tr>
<td><strong>stats</strong></td>
<td><code>ct.minedit_sim(text1, text2, lang='chinese')</code></td>
<td>æœ€å°ç¼–è¾‘è·ç¦»</td>
</tr>
<tr>
<td><strong>stats</strong></td>
<td><code>ct.word_hhi(text)</code></td>
<td>æ–‡æœ¬çš„èµ«èŠ¬è¾¾å°”-èµ«å¸Œæ›¼æŒ‡æ•°</td>
</tr>
</tbody>
</table>
<br>
<h3 id="21-word_count">2.1 word_count()<a hidden class="anchor" aria-hidden="true" href="#21-word_count">#</a></h3>
<p>ç»Ÿè®¡è¯é¢‘ï¼Œ è¿”å› Counter(ç±»ä¼¼äº python å­—å…¸) ï¼› æ”¯æŒä¸­è‹±æ–‡</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">ct.word_count(text, lang=&#39;chinese&#39;, return_df=False)
</code></pre></div><ul>
<li><strong>text</strong> å¾…åˆ†æçš„æ–‡æœ¬å­—ç¬¦ä¸²</li>
<li><strong>lang</strong> æ–‡æœ¬çš„è¯­è¨€ç±»å‹ï¼Œ ä¸­æ–‡ chineseã€è‹±æ–‡ englishï¼Œé»˜è®¤ä¸­æ–‡ã€‚</li>
<li><strong>return_df</strong> è¿”å›ç»“æœæ˜¯å¦ä¸º dataframeï¼Œé»˜è®¤ False</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>

<span class="n">text</span> <span class="o">=</span> <span class="s1">&#39;è‡´åŠ›äºè‡´åŠ›äºä»¥é›¶æ–‡ç« å¤„ç†è´¹æˆ–è®¢é˜…è´¹å‘å¸ƒä¼˜è´¨ç ”ç©¶è½¯ä»¶ã€‚&#39;</span>

<span class="c1">#ct.word_count(text, lang=&#39;chinese&#39;)</span>
<span class="n">ct</span><span class="o">.</span><span class="n">word_count</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">Counter({&#39;è‡´åŠ›äº&#39;: 2,
         &#39;æ–‡ç« &#39;: 1,
         &#39;å¤„ç†è´¹&#39;: 1,
         &#39;è®¢é˜…è´¹&#39;: 1,
         &#39;å‘å¸ƒ&#39;: 1,
         &#39;ä¼˜è´¨&#39;: 1,
         &#39;ç ”ç©¶&#39;: 1,
         &#39;è½¯ä»¶&#39;: 1})
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">ct</span><span class="o">.</span><span class="n">word_count</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">return_df</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</code></pre></div><p><img loading="lazy" src="img/09-term_freq.png" alt=""  />
</p>
<br>
<h3 id="22-readability">2.2 readability()<a hidden class="anchor" aria-hidden="true" href="#22-readability">#</a></h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">ct.readability(text, lang=&#39;chinese&#39;, syllables=3, return_series=False)
</code></pre></div><p>è®¡ç®—æ–‡æœ¬å¯è¯»æ€§å¸¸è§æŒ‡æ ‡ï¼› å« Gunning Fog Indexã€ SMOG Indexã€Coleman Liau Indexã€ Automated Readability Index(ARI)ã€Readability Index(Rix)ï¼› æŒ‡æ ‡è¶Šå¤§ï¼Œå¤æ‚åº¦è¶Šé«˜ï¼Œæ–‡æœ¬çš„å¯è¯»æ€§è¶Šå·®ã€‚</p>
<ul>
<li><strong>text</strong> å¾…åˆ†æçš„æ–‡æœ¬å­—ç¬¦ä¸²</li>
<li><strong>lang</strong> æ–‡æœ¬çš„è¯­è¨€ç±»å‹ï¼Œ ä¸­æ–‡ chineseã€è‹±æ–‡ englishï¼Œé»˜è®¤ä¸­æ–‡ã€‚</li>
<li><strong>syllables</strong> éŸ³èŠ‚æ•°(æ±‰å­—æ•°)å¤§äºç­‰äº syllables ä¸ºå¤æ‚è¯. é»˜è®¤å€¼ä¸º 3</li>
<li><strong>return_series</strong>: è®¡ç®—ç»“æœæ˜¯å¦è¾“å‡ºä¸º pd.Series ç±»å‹ï¼Œé»˜è®¤ä¸º False</li>
</ul>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">Gunning Fog Index = 0.4 * (Total_Words/Total_Sentences + 100 * Complex_Words/Total_Words)
SMOG Index = 1.0430 * sqrt(Complex_Words/Total_Sentences) * 30 + 3.1291
Coleman-Liau Index = 0.0588 * (100*Total_Letters/Total_Words) -0.296*(100*Total_Sentences/Total_Words) - 15.8
Automated Readability Index(ARI) = 4.71 * (Total_Characters/Total_Words) + 0.5*(Total_Words/Total_Sentences) - 21.43
Readability Index(RIX) = Complex_Words * (6 + Total_characters) / Total_Sentences
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>

<span class="n">text</span> <span class="o">=</span> <span class="s1">&#39;è‡´åŠ›äºä»¥é›¶æ–‡ç« å¤„ç†è´¹æˆ–è®¢é˜…è´¹å‘å¸ƒä¼˜è´¨ç ”ç©¶è½¯ä»¶ã€‚&#39;</span>

<span class="n">ct</span><span class="o">.</span><span class="n">readability</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">lang</span><span class="o">=</span><span class="s1">&#39;chinese&#39;</span><span class="p">,</span> <span class="n">syllables</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">{&#39;fog_index&#39;: 120.4,
 &#39;flesch_kincaid_grade_level&#39;: 20.2,
 &#39;smog_index&#39;: 57.32,
 &#39;coleman_liau_index&#39;: 83.96,
 &#39;ari&#39;: 87.4,
 &#39;rix&#39;: 87.0}
</code></pre></div><br>
<h3 id="23-sentimenttext-diction-lang">2.3 sentiment(text, diction, lang)<a hidden class="anchor" aria-hidden="true" href="#23-sentimenttext-diction-lang">#</a></h3>
<p>å¸¸è§çš„æƒ…æ„Ÿåˆ†æé»˜è®¤æƒ…ç»ªè¯æ— (ç­‰)æƒé‡ï¼Œ é€šè¿‡ç»Ÿè®¡è¯è¯­ä¸ªæ•°æ¥ååº”æƒ…æ„Ÿä¿¡æ¯ã€‚</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">sentiment(text, diction, lang=&#39;chinese&#39;, return_series=False)
</code></pre></div><ul>
<li><strong>text</strong> å¾…åˆ†æçš„æ–‡æœ¬å­—ç¬¦ä¸²</li>
<li><strong>diction</strong> æ ¼å¼ä¸º Python å­—å…¸ç±»å‹ã€‚å½¢å¦‚ä¸‹é¢çš„æ¡ˆä¾‹</li>
<li><strong>lang</strong> æ–‡æœ¬çš„è¯­è¨€ç±»å‹ï¼Œ ä¸­æ–‡ chineseã€è‹±æ–‡ englishï¼Œé»˜è®¤ä¸­æ–‡ã€‚</li>
<li><strong>return_series</strong> è®¡ç®—ç»“æœæ˜¯å¦è¾“å‡ºä¸º pd.Series ç±»å‹ï¼Œé»˜è®¤ä¸º False</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>

<span class="n">diction</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;pos&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;é«˜å…´&#39;</span><span class="p">,</span> <span class="s1">&#39;å¿«ä¹&#39;</span><span class="p">,</span> <span class="s1">&#39;åˆ†äº«&#39;</span><span class="p">],</span>
           <span class="s1">&#39;neg&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;éš¾è¿‡&#39;</span><span class="p">,</span> <span class="s1">&#39;æ‚²ä¼¤&#39;</span><span class="p">],</span>
           <span class="s1">&#39;adv&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;å¾ˆ&#39;</span><span class="p">,</span> <span class="s1">&#39;ç‰¹åˆ«&#39;</span><span class="p">]}</span>

<span class="n">text</span> <span class="o">=</span> <span class="s1">&#39;æˆ‘ä»Šå¤©å¾—å¥–äº†ï¼Œå¾ˆé«˜å…´ï¼Œæˆ‘è¦å°†å¿«ä¹åˆ†äº«å¤§å®¶ã€‚&#39;</span>
<span class="n">ct</span><span class="o">.</span><span class="n">sentiment</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="n">text</span><span class="p">,</span>
             <span class="n">diction</span><span class="o">=</span><span class="n">diction</span><span class="p">,</span>
             <span class="n">lang</span><span class="o">=</span><span class="s1">&#39;chinese&#39;</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">{&#39;pos_num&#39;: 3,
 &#39;neg_num&#39;: 0,
 &#39;adv_num&#39;: 1,
 &#39;stopword_num&#39;: 8,
 &#39;word_num&#39;: 14,
 &#39;sentence_num&#39;: 1}
</code></pre></div><br>
<h3 id="24-sentiment_by_valence">2.4 sentiment_by_valence()<a hidden class="anchor" aria-hidden="true" href="#24-sentiment_by_valence">#</a></h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">ct.sentiment_by_valence(text, diction, lang=&#39;chinese&#39;, return_series=False)
</code></pre></div><ul>
<li><strong>text</strong> å¾…åˆ†æçš„æ–‡æœ¬å­—ç¬¦ä¸²</li>
<li><strong>diction</strong> æ ¼å¼ä¸º Python å­—å…¸ç±»å‹ã€‚å½¢å¦‚ä¸‹é¢çš„æ¡ˆä¾‹</li>
<li><strong>lang</strong> æ–‡æœ¬çš„è¯­è¨€ç±»å‹ï¼Œ ä¸­æ–‡ chineseã€è‹±æ–‡ englishï¼Œé»˜è®¤ä¸­æ–‡ã€‚</li>
<li><strong>return_series</strong> è®¡ç®—ç»“æœæ˜¯å¦è¾“å‡ºä¸º pd.Series ç±»å‹ï¼Œé»˜è®¤ä¸º False</li>
</ul>
<p>å¸¸è§çš„æƒ…æ„Ÿåˆ†ææ˜¯æ— (ç­‰)æƒé‡, ä½†å®é™…ä¸Šä¸åŒçš„è¯è¯­æ‰€æºå¸¦çš„æƒ…æ„Ÿä¿¡æ¯çš„å¼ºåº¦å·®å¼‚æ˜¯å¾ˆå¤§çš„ã€‚æ®æ­¤å­¦è€…ä»¬å¼€å‘å‡ºå¾ˆå¤šå¸¦æƒé‡çš„è¯å…¸ï¼Œä¾‹å¦‚</p>
<ul>
<li>è‹±æ–‡å…·ä½“æ€§è¯å…¸ en_valence_Concreteness.yamlï¼Œ è¯å…¸ä¸­æ¯ä¸ªè¯éƒ½æœ‰ä¸€ä¸ª concreteness å€¼</li>
<li>ä¸­æ–‡å…­ç»´åº¦è¯­ä¹‰è¯å…¸ zh_valence_SixSemanticDimensionDatabase.yaml, æ¯ä¸ªä¸­æ–‡è¯æœ‰å…­ä¸ªå€¼ã€‚</li>
</ul>
<p>ä»¥å…·ä½“æ€§ä¸ºä¾‹ï¼Œ <strong>è¯­è¨€å…·ä½“æ€§ Concreteness</strong>æè¿°äº†ä¸€ä¸ªè¯åœ¨å¤šå¤§ç¨‹åº¦ä¸Šæ˜¯æŒ‡ä¸€ä¸ªå®é™…çš„ã€æœ‰å½¢çš„æˆ–â€œçœŸå®çš„â€å®ä½“ï¼Œä»¥ä¸€ç§æ›´å…·ä½“ã€æ›´ç†Ÿæ‚‰ã€æ›´å®¹æ˜“è¢«çœ¼ç›æˆ–å¿ƒçµæ„ŸçŸ¥çš„æ–¹å¼æè¿°å¯¹è±¡å’Œè¡Œä¸ºï¼ˆå³ï¼Œå¯æƒ³è±¡æˆ–ç”ŸåŠ¨ï¼›Brysbaert, Warriner, and Kuperman 2014; Semin and Fiedler 1988)</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">concreteness_dict</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">read_yaml_dict</span><span class="p">(</span><span class="s1">&#39;en_valence_Concreteness.yaml&#39;</span><span class="p">)[</span><span class="s1">&#39;Dictionary&#39;</span><span class="p">]</span>
<span class="n">concreteness_dict</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">{&#39;roadsweeper&#39;: {&#39;concreteness&#39;: 4.85},
 &#39;traindriver&#39;: {&#39;concreteness&#39;: 4.54},
 &#39;tush&#39;: {&#39;concreteness&#39;: 4.45},
 &#39;hairdress&#39;: {&#39;concreteness&#39;: 3.93},
 &#39;pharmaceutics&#39;: {&#39;concreteness&#39;: 3.77},
 &#39;hoover&#39;: {&#39;concreteness&#39;: 3.76},
 &#39;shopkeeping&#39;: {&#39;concreteness&#39;: 3.18},
 &#39;pushiness&#39;: {&#39;concreteness&#39;: 2.48},
 ......
 }
</code></pre></div><p>å¯èƒ½ **<em>concreteness_dict</em>**ä¸å¤Ÿç›´è§‚ï¼Œ å¦‚æœæ•´ç†è½¬åŒ–ä¸€ä¸‹å¤§æ¦‚ç±»ä¼¼äº</p>
<p><img loading="lazy" src="img/11-concreteness_df.png" alt=""  />
</p>
<p><a href="https://textdata.cn/blog/jcr_concreteness_computation/"><strong>JCR2021 | è®¡ç®—æ–‡æœ¬çš„è¯­è¨€å…·ä½“æ€§</strong></a> æ–‡ä¸­æä¾›äº†ä¸€ä¸ªæ¡ˆä¾‹</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">reply</span> <span class="o">=</span> <span class="s2">&#34;I&#39;ll go look for that&#34;</span>

<span class="n">score</span><span class="o">=</span><span class="n">ct</span><span class="o">.</span><span class="n">sentiment_by_valence</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="n">reply</span><span class="p">,</span>
                              <span class="n">diction</span><span class="o">=</span><span class="n">concreteness_dict</span><span class="p">,</span>
                              <span class="n">lang</span><span class="o">=</span><span class="s1">&#39;english&#39;</span><span class="p">)</span>

<span class="n">score</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">{&#39;concreteness&#39;: 9.28,
&#39;word_num&#39;: 6}
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">employee_replys</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&#34;I&#39;ll go look for that&#34;</span><span class="p">,</span>
                   <span class="s2">&#34;I&#39;ll go search for that&#34;</span><span class="p">,</span>
                   <span class="s2">&#34;I&#39;ll go search for that top&#34;</span><span class="p">,</span>
                   <span class="s2">&#34;I&#39;ll go search for that t-shirt&#34;</span><span class="p">,</span>
                   <span class="s2">&#34;I&#39;ll go look for that t-shirt in grey&#34;</span><span class="p">,</span>
                   <span class="s2">&#34;I&#39;ll go search for that t-shirt in grey&#34;</span><span class="p">]</span>

<span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">reply</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">employee_replys</span><span class="p">):</span>
    <span class="n">score</span><span class="o">=</span><span class="n">ct</span><span class="o">.</span><span class="n">sentiment_by_valence</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="n">reply</span><span class="p">,</span>
                                  <span class="n">diction</span><span class="o">=</span><span class="n">concreteness_dict</span><span class="p">,</span>
                                  <span class="n">lang</span><span class="o">=</span><span class="s1">&#39;english&#39;</span><span class="p">)</span>

    <span class="n">template</span> <span class="o">=</span> <span class="s2">&#34;Concreteness Score: </span><span class="si">{score:.2f}</span><span class="s2"> | Example-</span><span class="si">{idx}</span><span class="s2">: </span><span class="si">{exmaple}</span><span class="s2">&#34;</span>

    <span class="nb">print</span><span class="p">(</span><span class="n">template</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">score</span><span class="o">=</span><span class="n">score</span><span class="p">[</span><span class="s1">&#39;concreteness&#39;</span><span class="p">],</span>
                          <span class="n">idx</span><span class="o">=</span><span class="n">idx</span><span class="p">,</span>
                          <span class="n">exmaple</span><span class="o">=</span><span class="n">reply</span><span class="p">))</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">Concreteness Score: 9.28 | Example-0: I&#39;ll go look for that
Concreteness Score: 9.32 | Example-1: I&#39;ll go search for that
Concreteness Score: 13.25 | Example-2: I&#39;ll go search for that top
Concreteness Score: 14.25 | Example-3: I&#39;ll go search for that t-shirt
Concreteness Score: 21.32 | Example-4: I&#39;ll go look for that t-shirt in grey
Concreteness Score: 21.36 | Example-5: I&#39;ll go search for that t-shirt in grey
</code></pre></div><br>
<h3 id="25-word_in_context">2.5 word_in_context()<a hidden class="anchor" aria-hidden="true" href="#25-word_in_context">#</a></h3>
<p>You shall know a word by the company it keeps é€šè¿‡ä¸€ä¸ªå•è¯æ‰€å¤„çš„è¯­å¢ƒï¼Œæˆ‘ä»¬å¯ä»¥äº†è§£è¯¥å•è¯çš„å«ä¹‰ã€‚</p>
<p>åœ¨ text ä¸­æŸ¥æ‰¾ keywords å‡ºç°çš„ä¸Šä¸‹æ–‡å†…å®¹(çª—å£ window)ï¼Œè¿”å› dfã€‚</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">ct.word_in_context(text, keywords, window=3, lang=&#39;chinese&#39;)
</code></pre></div><ul>
<li><strong>text</strong> å¾…åˆ†ææ–‡æœ¬</li>
<li><strong>keywords</strong> å…³é”®è¯åˆ—è¡¨</li>
<li><strong>window</strong> å…³é”®è¯ä¸Šä¸‹æ–‡çª—å£å¤§å°</li>
<li><strong>lang</strong> æ–‡æœ¬çš„è¯­è¨€ç±»å‹ï¼Œ ä¸­æ–‡ chineseã€è‹±æ–‡ englishï¼Œé»˜è®¤ä¸­æ–‡ã€‚</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>

<span class="c1">#æµ‹è¯•ä»£ç ï¼Œå‡è®¾zh_textæ˜¯å¹´æŠ¥æ–‡æœ¬ï¼Œä»æ‰¾æ‰¾å‡ºä¸ç½‘è¯ç›¸å…³è¯çš„ä¸Šä¸‹æ–‡</span>
<span class="n">zh_text</span> <span class="o">=</span> <span class="s2">&#34;&#34;&#34;
</span><span class="s2">ã€æ’å…¥ä¸€æ¡è‡ªå®¶å¹¿å‘Šã€‘å¤§é‚“è‡ªå·±å®¶çš„å®¶ï¼Œ
</span><span class="s2">å®‰å¹³å¿å¤šéš†ä¸ç½‘åˆ¶å“ï¼Œç”Ÿäº§é”€å”®ä¸é”ˆé’¢è½§èŠ±ç½‘ã€
</span><span class="s2">ç”µç„Šç½‘ã€çŸ³ç¬¼ç½‘ã€åˆ€ç‰‡åˆºç»³ã€å†²å­”ç½‘ç­‰ä¸ç½‘åˆ¶å“ã€‚
</span><span class="s2">è”ç³»äºº é‚“é¢–é™ 0318-7686899
</span><span class="s2">
</span><span class="s2">äººç”Ÿè‹¦çŸ­ï¼Œæˆ‘å­¦Python
</span><span class="s2">åœ¨ç¤¾ç§‘ä¸­ï¼Œå¯ä»¥ç”¨Pythonåšæ–‡æœ¬åˆ†æ
</span><span class="s2">Pythonæ˜¯ä¸€é—¨åŠŸèƒ½å¼ºå¤§çš„ç¼–ç¨‹è¯­è¨€ï¼Œå¹¿æ³›åº”ç”¨åœ¨ç»ç®¡ç¤¾ç§‘é¢†åŸŸã€‚
</span><span class="s2">å¯ä»¥åšç½‘ç»œçˆ¬è™«ã€æ–‡æœ¬åˆ†æã€LDAè¯é¢˜æ¨¡å‹ã€ç›¸ä¼¼åº¦åˆ†æç­‰ã€‚
</span><span class="s2">
</span><span class="s2">ä»Šå¹´ç»æµä¸æ™¯æ°”ï¼Œå½¢åŠ¿å¼‚å¸¸ä¸¥å³»ã€‚
</span><span class="s2">ç”±äºç–«æƒ…ä¸æ™¯æ°”ï¼Œé™é»˜ç®¡ç†ï¼Œ äº§å“ç§¯å‹ï¼Œ å…¬å¸ç»è¥å›°éš¾ã€‚
</span><span class="s2">ä¿å°±ä¸šä¿ƒå°±ä¸šï¼Œä»»åŠ¡ååˆ†è‰°å·¨ã€‚
</span><span class="s2">&#34;&#34;&#34;</span>

<span class="c1">#ã€pythonã€‘ä¸Šä¸‹æ–‡</span>
<span class="n">ct</span><span class="o">.</span><span class="n">word_in_context</span><span class="p">(</span><span class="n">text</span> <span class="o">=</span> <span class="n">zh_text</span><span class="p">,</span>
                   <span class="n">keywords</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;python&#39;</span><span class="p">],</span>
                   <span class="n">window</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                   <span class="n">lang</span><span class="o">=</span><span class="s1">&#39;chinese&#39;</span><span class="p">)</span>
</code></pre></div><p><img loading="lazy" src="img/20-word-in-context.png" alt=""  />
</p>
<br>
<h3 id="26-epu">2.6 epu()<a hidden class="anchor" aria-hidden="true" href="#26-epu">#</a></h3>
<p><a href="https://textdata.cn/blog/2023-12-20-measure-china-economic-policy-uncertainty/"><strong>ä»£ç  | ä½¿ç”¨æ–°é—»æ•°æ®æµ‹é‡ç»æµæ”¿ç­–ä¸ç¡®å®šæ€§ EPU</strong></a></p>
<p><img loading="lazy" src="img/13-epu-plot.png" alt=""  />
</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">epu(df, freq=&#39;Y&#39;, e_pattern=&#39;&#39;, p_pattern=&#39;&#39;, u_pattern=&#39;&#39;)
</code></pre></div><ul>
<li><strong>df</strong> æ–°é—»æ•°æ® DataFrameï¼Œ å« text å’Œ date ä¸¤ä¸ªå­—æ®µã€‚ æ¯ä¸€è¡Œä»£è¡¨ä¸€æ¡æ–°é—»è®°å½•</li>
<li><strong>freq</strong> å­—ç¬¦ä¸²ï¼› ç¡®å®š EPU æŒ‡æ•°çš„æ—¶é—´é¢—ç²’åº¦ï¼› å¦‚å¹´ Y, æœˆ m, æ—¥ d, é»˜è®¤ freq=&lsquo;Y&rsquo;</li>
<li><strong>e_pattern</strong> å­—ç¬¦ä¸²ï¼›ç»æµç±»è¯å…¸ï¼Œç”¨<code>|</code>é—´éš”è¯è¯­ï¼Œå½¢å¦‚ <strong>e_pattern = â€˜ç»æµ|é‡‘èâ€™</strong></li>
<li><strong>p_pattern</strong> å­—ç¬¦ä¸²ï¼›æ”¿ç­–è¯å…¸ï¼Œç”¨<code>|</code>é—´éš”è¯è¯­ï¼Œå½¢å¦‚ <strong>p_pattern = â€˜æ”¿ç­–|æ²»ç†|è¡Œæ”¿â€™</strong></li>
<li><strong>u_pattern</strong> å­—ç¬¦ä¸²ï¼›ä¸ç¡®å®šæ€§è¯å…¸ï¼Œç”¨<code>|</code>é—´éš”è¯è¯­ï¼Œå½¢å¦‚ <strong>u_pattern = â€˜é£é™©|å±æœº|éš¾ä»¥é¢„æµ‹â€™</strong></li>
</ul>
<p>å‡†å¤‡å¦‚ä¸‹å›¾æ ¼å¼çš„æ•°æ® <strong><em>news_df</em></strong></p>
<p><img loading="lazy" src="img/12-news-df.png" alt=""  />
</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>

<span class="c1">#çœç•¥ï¼Œè¯»å–æ•°æ®å¾—åˆ° news_df</span>

<span class="n">epu_df</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">epu</span><span class="p">(</span><span class="n">df</span><span class="o">=</span><span class="n">news_df</span><span class="p">,</span> <span class="n">freq</span><span class="o">=</span><span class="s1">&#39;m&#39;</span><span class="p">)</span>
<span class="n">epu_df</span>
</code></pre></div><p><img loading="lazy" src="img/13-epu-df.png" alt=""  />
</p>
<br>
<h3 id="27-fepu">2.7 fepu()<a hidden class="anchor" aria-hidden="true" href="#27-fepu">#</a></h3>
<p><a href="https://textdata.cn/blog/2024-04-25-firm-economic-policy-uncertainty/">ä½¿ç”¨ç®¡ç†å±‚è®¨è®ºä¸åˆ†ææ–‡æœ¬æ•°æ®æµ‹é‡ã€Œä¼ä¸šæ„ŸçŸ¥ä¸ç¡®å®šæ€§ã€(Subjective perception of economic policy uncertainty, FEPU)</a></p>
<p><img loading="lazy" src="img/16-fepu-plot.png" alt=""  />
</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">ct.fepu(text, ep_pattern, u_pattern)
</code></pre></div><ul>
<li><strong><em>text</em></strong> ï¼›æŸæ—¶æœŸ t æŸä¼ä¸š i çš„ç®¡ç†å±‚è®¨è®ºä¸åˆ†æ md&amp;a æ–‡æœ¬</li>
<li><strong><em>ep_pattern</em></strong> å­—ç¬¦ä¸²ï¼›ç»æµæ”¿ç­–ç±»è¯å…¸ï¼Œç”¨<code>|</code>é—´éš”è¯è¯­ï¼Œå½¢å¦‚ <strong>ep_pattern = â€˜ç»æµ|é‡‘è|æ”¿ç­–|æ²»ç†|è¡Œæ”¿â€™</strong></li>
<li><strong><em>u_pattern</em></strong> å­—ç¬¦ä¸²ï¼›ä¸ç¡®å®šæ€§è¯å…¸ï¼Œç”¨<code>|</code>é—´éš”è¯è¯­ï¼Œå½¢å¦‚ <strong>u_pattern = â€˜é£é™©|å±æœº|éš¾ä»¥é¢„æµ‹â€™</strong></li>
</ul>
<p>å‡†å¤‡å¦‚ä¸‹å›¾æ ¼å¼çš„æ•°æ® <strong><em>mda_df</em></strong></p>
<p><img loading="lazy" src="img/14-mdadf.png" alt=""  />
</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>

<span class="c1">#çœç•¥ï¼Œè¯»å–æ•°æ®å¾—åˆ° mda_df</span>

<span class="n">fepu_df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;ç»è¥è®¨è®ºä¸åˆ†æå†…å®¹&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">ct</span><span class="o">.</span><span class="n">fepu</span><span class="p">)</span>
<span class="n">res_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">df</span><span class="p">[[</span><span class="s1">&#39;ä¼šè®¡å¹´åº¦&#39;</span><span class="p">,</span> <span class="s1">&#39;è‚¡ç¥¨ä»£ç &#39;</span><span class="p">]],</span> <span class="n">fepu_df</span><span class="p">],</span>   <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">res_df</span>
</code></pre></div><p><img loading="lazy" src="img/15-fepu.png" alt=""  />
</p>
<br>
<br>
<h3 id="28-semantic_brand_score">2.8 semantic_brand_score()<a hidden class="anchor" aria-hidden="true" href="#28-semantic_brand_score">#</a></h3>
<p><a href="https://textdata.cn/blog/2024-04-12-semantic-brand-score/">æ–‡çŒ®&amp;ä»£ç  | ä½¿ç”¨ Python è®¡ç®—è¯­ä¹‰å“ç‰Œè¯„åˆ†(Semantic Brand Score, SBS)</a> ï¼Œ é€šè¿‡ SBS æ¥è¡¡é‡å“ç‰Œï¼ˆä¸ªä½“ã€å…¬å¸ã€å“ç‰Œã€å…³é”®è¯ç­‰ï¼‰çš„é‡è¦æ€§ã€‚</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">ct.semantic_brand_score(text, brands, lang=&#39;chinese&#39;)
</code></pre></div><ul>
<li><strong><em>text</em></strong> å¾…åˆ†ææ–‡æœ¬</li>
<li><strong><em>brands</em></strong> è¯è¯­åˆ—è¡¨ï¼›</li>
<li><strong><em>lang</em></strong> è¯­è¨€ç±»å‹ï¼Œ&ldquo;chinese&quot;æˆ–&quot;english&rdquo;ï¼Œé»˜è®¤&quot;chinese&quot;</li>
</ul>
<p>ä»¥ä¸‰ä½“å°è¯´ä¸ºä¾‹ï¼Œé€šè¿‡æµ‹é‡å“ç‰Œè¯­ä¹‰è¯„åˆ† SBS æ¥åæ˜ å°è¯´è§’è‰²çš„é‡è¦æ€§ã€‚</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>

<span class="n">brands</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;æ±ªæ·¼&#39;</span><span class="p">,</span> <span class="s1">&#39;å²å¼º&#39;</span><span class="p">,</span> <span class="s1">&#39;ç½—è¾‘&#39;</span><span class="p">,</span> <span class="s1">&#39;å¶æ–‡æ´&#39;</span><span class="p">,</span> <span class="s1">&#39;ä¼Šæ–‡æ–¯&#39;</span><span class="p">]</span>

<span class="c1">#å‡†å¤‡santi_test_text</span>
<span class="c1">#å°è¯´ç­‰åˆ†20ä»½ï¼Œ è¯»å–ç¬¬ä¸€ä»½å¾—åˆ°santi_test_text</span>

<span class="n">sbs_df</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">semantic_brand_score</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="n">santi_test_text</span><span class="p">,</span>
                               <span class="n">brands</span><span class="o">=</span><span class="n">brands</span><span class="p">,</span>
                               <span class="n">lang</span><span class="o">=</span><span class="s1">&#39;chinese&#39;</span><span class="p">)</span>
<span class="n">sbs_df</span>
</code></pre></div><p><img loading="lazy" src="img/19-1st-sbs.png" alt=""  />
</p>
<p>å¦‚æœå°†ä¸‰ä½“å°è¯´åˆ†æˆ 20 ä»½ï¼Œ æ¯ä¸€ä»½éƒ½æµ‹ç®—å‡ºæ¯ä¸ªè§’è‰²çš„ SBSï¼Œç»˜åˆ¶å‡ºæŠ˜çº¿å›¾å¦‚ä¸‹å›¾æ‰€ç¤ºã€‚</p>
<p><img loading="lazy" src="img/18-sbs-plot.png" alt=""  />
</p>
<h3 id="29-æ–‡æœ¬ç›¸ä¼¼åº¦">2.9 æ–‡æœ¬ç›¸ä¼¼åº¦<a hidden class="anchor" aria-hidden="true" href="#29-æ–‡æœ¬ç›¸ä¼¼åº¦">#</a></h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">ct.cosine_sim(text1, text2, lang=&#39;chinese&#39;)   cosä½™å¼¦ç›¸ä¼¼
ct.jaccard_sim(text1, text2, lang=&#39;chinese&#39;)  jaccardç›¸ä¼¼
ct.minedit_sim(text1, text2, lang=&#39;chinese&#39;)  æœ€å°ç¼–è¾‘è·ç¦»ç›¸ä¼¼åº¦ï¼›
ct.simple_sim(text1, text2, lang=&#39;chinese&#39;)   æ›´æ”¹å˜åŠ¨ç®—æ³•
</code></pre></div><p>ç®—æ³•å®ç°å‚è€ƒè‡ª <code>Cohen, Lauren, Christopher Malloy, and Quoc Nguyen. Lazy prices. No. w25084. National Bureau of Economic Research, 2018.</code></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>

<span class="n">text1</span> <span class="o">=</span> <span class="s1">&#39;ç¼–ç¨‹çœŸå¥½ç©ç¼–ç¨‹çœŸå¥½ç©&#39;</span>
<span class="n">text2</span> <span class="o">=</span> <span class="s1">&#39;æ¸¸æˆçœŸå¥½ç©ç¼–ç¨‹çœŸå¥½ç©&#39;</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;cosine&#39;</span><span class="p">,</span> <span class="n">ct</span><span class="o">.</span><span class="n">cosine_sim</span><span class="p">(</span><span class="n">text1</span><span class="p">,</span> <span class="n">text2</span><span class="p">,</span> <span class="n">lang</span><span class="o">=</span><span class="s1">&#39;chinese&#39;</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;jaccard&#39;</span><span class="p">,</span> <span class="n">ct</span><span class="o">.</span><span class="n">jaccard_sim</span><span class="p">(</span><span class="n">text1</span><span class="p">,</span> <span class="n">text2</span><span class="p">,</span> <span class="n">lang</span><span class="o">=</span><span class="s1">&#39;chinese&#39;</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;minedit&#39;</span><span class="p">,</span> <span class="n">ct</span><span class="o">.</span><span class="n">minedit_sim</span><span class="p">(</span><span class="n">text1</span><span class="p">,</span> <span class="n">text2</span><span class="p">,</span> <span class="n">lang</span><span class="o">=</span><span class="s1">&#39;chinese&#39;</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;simple&#39;</span><span class="p">,</span> <span class="n">ct</span><span class="o">.</span><span class="n">simple_sim</span><span class="p">(</span><span class="n">text1</span><span class="p">,</span> <span class="n">text2</span><span class="p">,</span> <span class="n">lang</span><span class="o">=</span><span class="s1">&#39;chinese&#39;</span><span class="p">))</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">cosine  0.82
jaccard 0.67
minedit 1.00
simple 0.84
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>


<span class="n">text1</span> <span class="o">=</span> <span class="s1">&#39;Programming is fun!&#39;</span>
<span class="n">text2</span> <span class="o">=</span> <span class="s1">&#39;Programming is interesting!&#39;</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;cosine&#39;</span><span class="p">,</span> <span class="n">ct</span><span class="o">.</span><span class="n">cosine_sim</span><span class="p">(</span><span class="n">text1</span><span class="p">,</span> <span class="n">text2</span><span class="p">,</span> <span class="n">lang</span><span class="o">=</span><span class="s1">&#39;english&#39;</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;jaccard&#39;</span><span class="p">,</span> <span class="n">ct</span><span class="o">.</span><span class="n">jaccard_sim</span><span class="p">(</span><span class="n">text1</span><span class="p">,</span> <span class="n">text2</span><span class="p">,</span> <span class="n">lang</span><span class="o">=</span><span class="s1">&#39;english&#39;</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;minedit&#39;</span><span class="p">,</span> <span class="n">ct</span><span class="o">.</span><span class="n">minedit_sim</span><span class="p">(</span><span class="n">text1</span><span class="p">,</span> <span class="n">text2</span><span class="p">,</span> <span class="n">lang</span><span class="o">=</span><span class="s1">&#39;english&#39;</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;simple&#39;</span><span class="p">,</span> <span class="n">ct</span><span class="o">.</span><span class="n">simple_sim</span><span class="p">(</span><span class="n">text1</span><span class="p">,</span> <span class="n">text2</span><span class="p">,</span> <span class="n">lang</span><span class="o">=</span><span class="s1">&#39;english&#39;</span><span class="p">))</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">cosine  0.67
jaccard 0.50
minedit 1.00
simple 0.78
</code></pre></div><br>
<h3 id="210-word_hhi">2.10 word_hhi<a hidden class="anchor" aria-hidden="true" href="#210-word_hhi">#</a></h3>
<p>æ–‡æœ¬çš„èµ«èŠ¬è¾¾å°”-èµ«å¸Œæ›¼æŒ‡æ•°ã€‚ct.word_hhi(text, lang=&lsquo;chinese&rsquo;)</p>
<br>
<p><strong>èµ«èŠ¬è¾¾å°”-èµ«å¸Œæ›¼æŒ‡æ•°</strong>(<strong>Herfindahl-Hirschman Index</strong>)ä½œä¸ºä¸€ç§è¡¡é‡å¸‚åœºé›†ä¸­åº¦çš„ç»æµæŒ‡æ ‡ï¼Œé€šå¸¸ç”¨äºåˆ†æäº§ä¸šæˆ–å¸‚åœºä¸­ä¼ä¸šä»½é¢çš„åˆ†å¸ƒæƒ…å†µã€‚</p>
<p><img loading="lazy" src="img/word-hhi-algo.png" alt=""  />
</p>
<p>å‰äººç±»æ¯”å¸‚åœºé›†ä¸­ç¨‹åº¦ï¼Œç”¨äºæµ‹é‡ä¸“åˆ©è´¨é‡(çŸ¥è¯†å®½åº¦)ã€‚ é‚£æ”¾åœ¨æ–‡æœ¬è¯­è¨€ä¸­ï¼Œæˆ‘ä»¬æ˜¯å¦å¯èƒ½åˆ©ç”¨ HHI æ¥é‡åŒ–æŸä¸ªè¯­æ–™åº“ä¸­ä¸åŒè¯æ±‡çš„ä½¿ç”¨é¢‘ç‡åˆ†å¸ƒï¼Œä»¥æ­¤æ¥åˆ†æä¸ªäººã€ç¾¤ä½“æˆ–æ—¶ä»£çš„è¯­è¨€é£æ ¼ã€è¯æ±‡ä¸°å¯Œåº¦ã€æˆ–æ˜¯è¯­è¨€æ ‡å‡†åŒ–ä¸å˜åŒ–çš„è¶‹åŠ¿ã€‚</p>
<ul>
<li>å¦‚æœè¯æ±‡åˆ†å¸ƒéå¸¸å‡åŒ€ï¼Œè¡¨æ˜è¯­è¨€ä½¿ç”¨ä¸­çš„è¯æ±‡å¤šæ ·æ€§é«˜ï¼ŒHHI å€¼å°±ä¼šè¾ƒä½ï¼›</li>
<li>åä¹‹ï¼Œå¦‚æœå°‘æ•°è¯æ±‡å æ®äº†å¤§éƒ¨åˆ†æ–‡æœ¬ç©ºé—´ï¼Œè¡¨æ˜è¯æ±‡ä½¿ç”¨é›†ä¸­ï¼ŒHHI å€¼åˆ™è¾ƒé«˜ã€‚</li>
</ul>
<p>ç»“åˆå…¶ä»–è¯­è¨€å­¦æŒ‡æ ‡ä¸€èµ·ä½¿ç”¨ï¼Œæ¯”å¦‚ TTRï¼ˆType-Token Ratioï¼Œç±»å‹-æ ‡è®°æ¯”ç‡ï¼‰ã€Shannon entropyï¼ˆé¦™å†œç†µï¼‰ç­‰ï¼Œå…±åŒè¯„ä¼°è¯­è¨€è¡¨è¾¾çš„å¤æ‚åº¦å’Œå¤šæ ·æ€§ã€‚ä¸è¿‡ï¼Œè¿™ç±»ç ”ç©¶çš„æ–‡çŒ®ç›¸å¯¹è¾ƒå°‘ï¼Œå› ä¸ºè¯­è¨€å­¦é¢†åŸŸæœ‰è‡ªå·±ä¸€å¥—æˆç†Ÿä¸”ä¸“ä¸šçš„åˆ†æå·¥å…·å’Œæ–¹æ³•ï¼ŒHHI æ›´å¤šåœ°è¢«è§†ä¸ºè·¨å­¦ç§‘åº”ç”¨çš„ä¸€ä¸ªåˆ›æ–°å°è¯•ã€‚</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>

<span class="n">personA</span> <span class="o">=</span> <span class="s1">&#39;è¿™åœºéŸ³ä¹ä¼šå¤ªå—¨äº†&#39;</span>
<span class="n">personB</span> <span class="o">=</span> <span class="s1">&#39;è¿™åœºéŸ³ä¹ä¼šè¯´å‡ºæ¥ä»¤ä½ ä¸æ•¢ç›¸ä¿¡ï¼Œä¸»åŠæ–¹ç­–åˆ’æœ‰æ–¹ï¼Œç¾¤ä¼—æ¿€æƒ…æ»¡æ»¡ï¼Œæˆ‘å°è±¡æ·±åˆ»ï¼Œä½“éªŒæ„Ÿæ‹‰æ»¡&#39;</span>


<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;A-hhi&#39;</span><span class="p">,</span> <span class="n">ct</span><span class="o">.</span><span class="n">word_hhi</span><span class="p">(</span><span class="n">personA</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;B-hhi&#39;</span><span class="p">,</span> <span class="n">ct</span><span class="o">.</span><span class="n">word_hhi</span><span class="p">(</span><span class="n">personB</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Aè¯æ±‡å¤šæ ·æ€§&#39;</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">ct</span><span class="o">.</span><span class="n">word_hhi</span><span class="p">(</span><span class="n">personA</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Bè¯æ±‡å¤šæ ·æ€§&#39;</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">ct</span><span class="o">.</span><span class="n">word_hhi</span><span class="p">(</span><span class="n">personB</span><span class="p">))</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">A-hhi 0.20000000000000004
B-hhi 0.07024793388429751

Aè¯æ±‡å¤šæ ·æ€§ 0.7999999999999999
Bè¯æ±‡å¤šæ ·æ€§ 0.9297520661157025
</code></pre></div><br>
<br>
<h2 id="ä¸‰plot-æ¨¡å—">ä¸‰ã€Plot æ¨¡å—<a hidden class="anchor" aria-hidden="true" href="#ä¸‰plot-æ¨¡å—">#</a></h2>
<table>
<thead>
<tr>
<th>æ¨¡å—</th>
<th>å‡½æ•°</th>
<th>åŠŸèƒ½</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>plot</strong></td>
<td><code>ct.matplotlib_chinese()</code></td>
<td>æ”¯æŒ matplotlib ä¸­æ–‡ç»˜å›¾</td>
</tr>
<tr>
<td><strong>plot</strong></td>
<td><code>ct.lexical_dispersion_plot1(text, targets_dict, lang, title, figsize)</code></td>
<td>å¯¹æŸä¸€ä¸ªæ–‡æœ¬ textï¼Œ å¯è§†åŒ–ä¸åŒç›®æ ‡ç±»åˆ«è¯ targets_dict åœ¨æ–‡æœ¬ä¸­å‡ºç°ä½ç½®</td>
</tr>
<tr>
<td><strong>plot</strong></td>
<td><code>ct.lexical_dispersion_plot2(texts_dict, targets, lang, title, figsize)</code></td>
<td>å¯¹æŸå‡ ä¸ªæ–‡æœ¬ texts_dictï¼Œ å¯è§†åŒ–æŸäº›ç›®æ ‡è¯ targets åœ¨æ–‡æœ¬ä¸­å‡ºç°ç›¸å¯¹ä½ç½®(0~100)</td>
</tr>
</tbody>
</table>
<br>
<h3 id="31-matplotlib_chinese">3.1 matplotlib_chinese()<a hidden class="anchor" aria-hidden="true" href="#31-matplotlib_chinese">#</a></h3>
<p>matplotlib é»˜è®¤ä¸æ”¯æŒä¸­æ–‡å¯è§†åŒ–ï¼Œ cntext æ–°å¢è¯¥å‡½æ•°ï¼Œå¯ä»¥è§£å†³ä¸­æ–‡å¯è§†åŒ–é—®é¢˜</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>

<span class="n">plt</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">matplotlib_chinese</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">16</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;ä¸­æ–‡å›¾è¡¨&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/27-chinese-matplotlib.png" alt=""  />
</p>
<br>
<h3 id="32-lexical_dispersion_plot1">3.2 lexical_dispersion_plot1()<a hidden class="anchor" aria-hidden="true" href="#32-lexical_dispersion_plot1">#</a></h3>
<p>è¯æ±‡åˆ†æ•£å›¾å¯è§†åŒ–ï¼Œ å¯¹æŸä¸€ä¸ªæ–‡æœ¬ textï¼Œ å¯è§†åŒ–ä¸åŒç›®æ ‡ç±»åˆ«è¯ targets_dict åœ¨æ–‡æœ¬ä¸­å‡ºç°ä½ç½®</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">ct</span><span class="o">.</span><span class="n">lexical_dispersion_plot1</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">targets_dict</span><span class="p">,</span> <span class="n">lang</span><span class="o">=</span><span class="s1">&#39;chinese&#39;</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span> <span class="n">title</span><span class="o">=</span><span class="s1">&#39;ç‰¹å®šè¯æ±‡åœ¨ä¸åŒæ–‡æœ¬æ¥æºçš„ç›¸å¯¹ç¦»æ•£å›¾&#39;</span><span class="p">,</span> <span class="n">prop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</code></pre></div><ul>
<li><strong><em>text</em></strong>: æ–‡æœ¬æ•°æ®</li>
<li><strong><em>targets_dict</em></strong>: ç›®æ ‡ç±»åˆ«è¯å­—å…¸ï¼› targets_dict={&lsquo;pos&rsquo;: [&lsquo;å¼€å¿ƒ&rsquo;, &lsquo;å¿«ä¹&rsquo;], &lsquo;neg&rsquo;: [&lsquo;æ‚²ä¼¤&rsquo;, &lsquo;éš¾è¿‡&rsquo;]}</li>
<li><strong><em>lang</em></strong>: æ–‡æœ¬æ•°æ® texts_dict çš„è¯­è¨€ç±»å‹ï¼Œé»˜è®¤&rsquo;chinese'.</li>
<li><strong><em>figsize</em></strong>: å›¾çš„é•¿å®½å°ºå¯¸. é»˜è®¤ (8, 5).</li>
<li><strong><em>title</em></strong> : å›¾çš„æ ‡é¢˜ï¼›</li>
<li><strong><em>prop</em></strong>: æ¨ªåæ ‡å­—ç¬¦ä½ç½®æ˜¯å¦ä¸ºç›¸å¯¹ä½ç½®. é»˜è®¤ Trueï¼Œæ¨ªåæ ‡ç´¢å¼•å€¼å–å€¼èŒƒå›´ 0 ~ 100</li>
</ul>
<br>
<p>ç‚¹å‡»ä¸‹è½½ <a href="https://textdata.cn/data/%E4%B8%89%E4%BD%93.txt"><strong>ä¸‰ä½“.txt</strong></a>ã€<a href="https://textdata.cn/data/%E5%9F%BA%E5%9C%B0.txt"><strong>åŸºåœ°.txt</strong></a>ä¸¤æœ¬å°è¯´æ–‡ä»¶ã€‚</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>

<span class="n">roles_dict</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&#34;æ±ªæ·¼&#34;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;æ±ªæ·¼&#39;</span><span class="p">],</span>
    <span class="s2">&#34;å¶æ–‡æ´&#34;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;å¶æ–‡æ´&#39;</span><span class="p">],</span>
    <span class="s2">&#34;ç½—è¾‘&#34;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;ç½—è¾‘&#39;</span><span class="p">]</span>
<span class="p">}</span>

<span class="n">santi_text</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;ä¸‰ä½“.txt&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">lexical_dispersion_plot1</span><span class="p">(</span><span class="n">text</span> <span class="o">=</span> <span class="n">santi_text</span><span class="p">,</span>  <span class="c1">#æ–‡æœ¬æ•°æ®</span>
                            <span class="n">targets_dict</span> <span class="o">=</span> <span class="n">roles_dict</span><span class="p">,</span> <span class="c1">#è§’è‰²</span>
                            <span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span>  <span class="c1">#å°ºå¯¸å¤§å°</span>
                            <span class="n">lang</span> <span class="o">=</span> <span class="s1">&#39;chinese&#39;</span><span class="p">,</span>  <span class="c1">#ä¸­æ–‡æ•°æ®</span>
                            <span class="n">title</span> <span class="o">=</span> <span class="s1">&#39;ã€Šä¸‰ä½“ã€‹å°è¯´è§’è‰²å‡ºç°ä½ç½®&#39;</span><span class="p">,</span> <span class="c1">#æ ‡é¢˜</span>
                            <span class="n">prop</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>    <span class="c1">#ç›¸å¯¹ä½ç½®(æ¨ªåæ ‡è½´å–å€¼èŒƒå›´0-100)</span>
<span class="n">ax</span>
</code></pre></div><p><img loading="lazy" src="img/23-lexical_dispersion_plot1-relative.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">ct</span><span class="o">.</span><span class="n">lexical_dispersion_plot1</span><span class="p">(</span><span class="n">text</span> <span class="o">=</span> <span class="n">santi_text</span><span class="p">,</span>  <span class="c1">#æ–‡æœ¬æ•°æ®</span>
                            <span class="n">targets_dict</span> <span class="o">=</span> <span class="n">roles_dict</span><span class="p">,</span> <span class="c1">#è§’è‰²</span>
                            <span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span>  <span class="c1">#å°ºå¯¸å¤§å°</span>
                            <span class="n">lang</span> <span class="o">=</span> <span class="s1">&#39;chinese&#39;</span><span class="p">,</span>  <span class="c1">#ä¸­æ–‡æ•°æ®</span>
                            <span class="n">title</span> <span class="o">=</span> <span class="s1">&#39;ã€Šä¸‰ä½“ã€‹å°è¯´è§’è‰²å‡ºç°ä½ç½®&#39;</span><span class="p">,</span> <span class="c1">#æ ‡é¢˜</span>
                            <span class="n">prop</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>    <span class="c1">#ç»å¯¹ä½ç½®(æ¨ªåæ ‡è½´å–å€¼èŒƒå›´ä¸å°è¯´æ–‡æœ¬é•¿åº¦æœ‰å…³)</span>
</code></pre></div><p><img loading="lazy" src="img/24-lexical_dispersion_plot1-absolute.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>

<span class="c1"># diyäº†ä¸€ä¸ªå°è¯å…¸</span>
<span class="n">senti_dict</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;pos&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;å¼€å¿ƒ&#39;</span><span class="p">,</span> <span class="s1">&#39;å¹¸ç¦&#39;</span><span class="p">,</span> <span class="s1">&#39;å¿«ä¹&#39;</span><span class="p">,</span> <span class="s1">&#39;å®‰å®&#39;</span><span class="p">,</span> <span class="s1">&#39;å¸Œæœ›&#39;</span><span class="p">],</span>
    <span class="s1">&#39;neg&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;ç´§å¼ &#39;</span><span class="p">,</span> <span class="s1">&#39;ææƒ§&#39;</span><span class="p">,</span> <span class="s1">&#39;å®³æ€•&#39;</span><span class="p">,</span> <span class="s1">&#39;ç»æœ›&#39;</span><span class="p">]</span>
<span class="p">}</span>

<span class="n">santi_text</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;ä¸‰ä½“.txt&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">lexical_dispersion_plot1</span><span class="p">(</span><span class="n">text</span> <span class="o">=</span> <span class="n">santi_text</span><span class="p">,</span>
                            <span class="n">targets_dict</span> <span class="o">=</span> <span class="n">senti_dict</span><span class="p">,</span>
                            <span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
                            <span class="n">lang</span> <span class="o">=</span> <span class="s1">&#39;chinese&#39;</span><span class="p">,</span>
                            <span class="n">title</span> <span class="o">=</span> <span class="s1">&#39;ã€Šä¸‰ä½“ã€‹æƒ…ç»ªè¯å‡ºç°ä½ç½®&#39;</span><span class="p">,</span>
                            <span class="n">prop</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
<span class="n">ax</span>
</code></pre></div><p><img loading="lazy" src="img/25-santi_sentiment.png" alt=""  />
</p>
<br>
<h3 id="33-lexical_dispersion_plot2">3.3 lexical_dispersion_plot2()<a hidden class="anchor" aria-hidden="true" href="#33-lexical_dispersion_plot2">#</a></h3>
<p>è¯æ±‡åˆ†æ•£å›¾å¯è§†åŒ–ï¼Œ å¯¹æŸå‡ ä¸ªæ–‡æœ¬ texts_dictï¼Œ å¯è§†åŒ–æŸäº›ç›®æ ‡è¯ targets åœ¨æ–‡æœ¬ä¸­å‡ºç°ç›¸å¯¹ä½ç½®(0~100)</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">ct</span><span class="o">.</span><span class="n">lexical_dispersion_plot2</span><span class="p">(</span><span class="n">texts_dict</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">lang</span><span class="o">=</span><span class="s1">&#39;chinese&#39;</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span> <span class="n">title</span><span class="o">=</span><span class="s1">&#39;ç‰¹å®šè¯æ±‡åœ¨ä¸åŒæ–‡æœ¬æ¥æºçš„ç›¸å¯¹ç¦»æ•£å›¾&#39;</span><span class="p">)</span>
</code></pre></div><ul>
<li><strong><em>texts_dict</em></strong>: å¤šä¸ªæ–‡æœ¬çš„å­—å…¸æ•°æ®ã€‚å½¢å¦‚{&lsquo;source1&rsquo;: &lsquo;source1 çš„æ–‡æœ¬å†…å®¹&rsquo;, &lsquo;source2&rsquo;: &lsquo;source2 çš„æ–‡æœ¬å†…å®¹&rsquo;}</li>
<li><strong><em>targets</em></strong>: ç›®æ ‡è¯åˆ—è¡¨</li>
<li><strong><em>lang</em></strong>: æ–‡æœ¬æ•°æ® texts_dict çš„è¯­è¨€ç±»å‹ï¼Œé»˜è®¤&rsquo;chinese'.</li>
<li><strong><em>figsize</em></strong>: å›¾çš„é•¿å®½å°ºå¯¸. é»˜è®¤ (8, 5).</li>
<li><strong><em>title</em></strong> : å›¾çš„æ ‡é¢˜ï¼›</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">targets</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;å¤ªç©º&#39;</span><span class="p">,</span> <span class="s1">&#39;å®‡å®™&#39;</span><span class="p">]</span>

<span class="n">texts_dict</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;ä¸‰ä½“&#39;</span><span class="p">:</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;ä¸‰ä½“.txt&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">read</span><span class="p">(),</span>
              <span class="s1">&#39;åŸºåœ°&#39;</span><span class="p">:</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;åŸºåœ°.txt&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">read</span><span class="p">()}</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">lexical_dispersion_plot2</span><span class="p">(</span><span class="n">texts_dict</span> <span class="o">=</span> <span class="n">texts_dict</span><span class="p">,</span>
                            <span class="n">targets</span> <span class="o">=</span> <span class="n">targets</span><span class="p">,</span>
                            <span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
                            <span class="n">title</span> <span class="o">=</span> <span class="s1">&#39;&#34;å¤ªç©º/å®‡å®™&#34;è¯è¯­å‡ºç°ä½ç½®&#39;</span><span class="p">,</span>
                            <span class="n">lang</span> <span class="o">=</span> <span class="s1">&#39;chinese&#39;</span><span class="p">)</span>
<span class="n">ax</span>
</code></pre></div><p><img loading="lazy" src="img/26-santi_base.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="å››model-æ¨¡å—">å››ã€Model æ¨¡å—<a hidden class="anchor" aria-hidden="true" href="#å››model-æ¨¡å—">#</a></h2>
<p>æœ¬éƒ¨åˆ†ä¸»è¦å†…å®¹æ˜¯è¯åµŒå…¥æ¨¡å‹ç›¸å…³æŠ€æœ¯ï¼Œ åŒ…æ‹¬ Word2Vec(GLove)çš„è®­ç»ƒã€è¯»å–ã€æ‰©å±•è¯å…¸ã€‚</p>
<table>
<thead>
<tr>
<th>æ¨¡å—</th>
<th>å‡½æ•°(ç±»)</th>
<th>åŠŸèƒ½</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>model</strong></td>
<td><strong><em>ct.Word2Vec(corpus_file, encoding, lang, window_size, vector_size,&hellip;)</em></strong></td>
<td>è®­ç»ƒ Word2Vec</td>
</tr>
<tr>
<td><strong>model</strong></td>
<td><strong><em>ct.GloVe(corpus_file, encoding, lang, window_size, vector_size, &hellip;)</em></strong></td>
<td>è®­ç»ƒ GLove æ¨¡å‹ã€‚</td>
</tr>
<tr>
<td><strong>model</strong></td>
<td><strong>ct.evaluate_similarity(wv, file=None)</strong></td>
<td>ä½¿ç”¨è¿‘ä¹‰æ³•è¯„ä¼°æ¨¡å‹è¡¨ç°ï¼Œé»˜è®¤ä½¿ç”¨å†…ç½®çš„æ•°æ®è¿›è¡Œè¯„ä¼°ã€‚</td>
</tr>
<tr>
<td><strong>model</strong></td>
<td><strong>ct.evaluate_analogy(wv, file=None)</strong></td>
<td>ä½¿ç”¨ç±»æ¯”æ³•è¯„ä¼°æ¨¡å‹è¡¨ç°ï¼Œé»˜è®¤ä½¿ç”¨å†…ç½®çš„æ•°æ®è¿›è¡Œè¯„ä¼°ã€‚</td>
</tr>
<tr>
<td><strong>model</strong></td>
<td><strong><em>ct.load_w2v(wv_path)</em></strong></td>
<td>è¯»å– cntext2.x è®­ç»ƒå‡ºçš„ Word2Vec/GloVe æ¨¡å‹æ–‡ä»¶</td>
</tr>
<tr>
<td><strong>model</strong></td>
<td><strong><em>ct.glove2word2vec(glove_file, word2vec_file)</em></strong></td>
<td>å°† GLoVe æ¨¡å‹.txt æ–‡ä»¶è½¬åŒ–ä¸º Word2Vec æ¨¡å‹.txt æ–‡ä»¶ï¼›æ³¨æ„è¿™é‡Œçš„ GLoVe æ¨¡å‹.txt æ˜¯é€šè¿‡<a href="https://github.com/standfordnlp/GloVe">Standfordnlp/GloVe</a> è®­ç»ƒå¾—åˆ°çš„ã€‚</td>
</tr>
<tr>
<td><strong>model</strong></td>
<td><strong><em>ct.expand_dictionary(wv, seeddict, topn=100)</em></strong></td>
<td>æ‰©å±•è¯å…¸, ç»“æœä¿å­˜åˆ°è·¯å¾„[output/Word2Vec]ä¸­</td>
</tr>
<tr>
<td><strong>model</strong></td>
<td><code>ct.SoPmi(corpus_file, seed_file, lang='chinese')</code></td>
<td>å…±ç°æ³•æ‰©å±•è¯å…¸</td>
</tr>
</tbody>
</table>
<h3 id="41-word2vec">4.1 Word2Vec()<a hidden class="anchor" aria-hidden="true" href="#41-word2vec">#</a></h3>
<p>å¯ç›´æ¥å¯¹åŸå§‹è¯­æ–™ txt æ–‡ä»¶è¿›è¡Œè‡ªåŠ¨ Word2vec è®­ç»ƒã€‚è¯¥å‡½æ•°ä¼šè‡ªåŠ¨å¤„ç†æ–‡æœ¬é¢„å¤„ç†(åˆ†è¯ã€å»åœè¯)ã€å†…å­˜ç®¡ç†ã€å‚æ•°è°ƒæ•´ç­‰é—®é¢˜ï¼Œç¡®ä¿è®­ç»ƒè¿‡ç¨‹é¡ºåˆ©è¿›è¡Œã€‚</p>
<p>åœ¨ <strong><em>gensim.models.word2vec.Word2Vec</em></strong> åŸºç¡€ä¸Šï¼Œå¢åŠ äº†ä¸­è‹±æ–‡çš„é¢„å¤„ç†ï¼Œ ç®€åŒ–äº†ä»£ç ä½¿ç”¨ã€‚é…ç½®å¥½ cntext2.x ç¯å¢ƒï¼Œ å¯ä»¥åšåˆ°</p>
<ul>
<li>
<ol>
<li>è®­ç»ƒåªç”¨ä¸€è¡Œä»£ç </li>
</ol>
</li>
<li>
<ol start="2">
<li>è¯»å–è°ƒç”¨åªç”¨ä¸€è¡Œä»£ç </li>
</ol>
</li>
</ul>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">ct.Word2Vec(corpus_file, lang=&#39;chinese&#39;, dict_file=None, stopwords_file=None, vector_size=100, window_size=6, min_count=5, max_iter=5, chunksize=10000, only_binary=True, **kwargs)
</code></pre></div><ul>
<li><strong><em>corpus_file</em></strong>: è¯­æ–™åº“æ–‡ä»¶çš„è·¯å¾„ã€‚</li>
<li><strong><em>lang</em></strong>: è¯­è¨€ç±»å‹ï¼Œæ”¯æŒ &lsquo;chinese&rsquo; å’Œ &lsquo;english&rsquo;ï¼Œé»˜è®¤ä¸º &lsquo;chinese&rsquo;ã€‚</li>
<li><strong><em>dict_file</em></strong>: è‡ªå®šä¹‰è¯å…¸ txt æ–‡ä»¶è·¯å¾„ï¼Œé»˜è®¤ä¸º Noneã€‚utf-8 ç¼–ç ã€‚</li>
<li><strong><em>stopwords_file</em></strong>: åœç”¨è¯æ–‡ä»¶è·¯å¾„ï¼Œé»˜è®¤ä¸º Noneã€‚utf-8 ç¼–ç ã€‚</li>
<li><strong><em>vector_size</em></strong>: è¯å‘é‡çš„ç»´åº¦ï¼Œé»˜è®¤ä¸º 50ã€‚</li>
<li><strong><em>window_size</em></strong>: ä¸Šä¸‹æ–‡çª—å£çš„å¤§å°ï¼Œé»˜è®¤ä¸º 6ã€‚</li>
<li><strong><em>min_count</em></strong>: æœ€å°è¯é¢‘ï¼Œé»˜è®¤ä¸º 10ã€‚</li>
<li><strong><em>max_iter</em></strong>: æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼Œé»˜è®¤ä¸º 5ã€‚</li>
<li><strong><em>chunksize</em></strong>: æ¯æ¬¡è¯»å–çš„è¡Œæ•°ã€‚é»˜è®¤ä¸º 10000ã€‚è¶Šå¤§é€Ÿåº¦è¶Šå¿«ã€‚</li>
<li><strong><em>only_binary</em></strong> : æ˜¯å¦åªä¿å­˜æ¨¡å‹ä¸ºäºŒè¿›åˆ¶æ–‡ä»¶ã€‚é»˜è®¤ä¸º Trueï¼Œ ä¿å­˜ä¸º binã€‚False æ—¶åªä¿å­˜ binã€txtã€‚</li>
<li><strong><em>kwargs</em></strong>: å…¶ä»– gensim å¯é€‰å‚æ•°ï¼Œå¦‚ negativeã€sampleã€hs ç­‰ã€‚</li>
</ul>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>

<span class="n">w2v</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">Word2Vec</span><span class="p">(</span><span class="n">corpus_file</span> <span class="o">=</span> <span class="s1">&#39;data/ä¸‰ä½“.txt&#39;</span><span class="p">,</span>
                  <span class="n">lang</span> <span class="o">=</span> <span class="s1">&#39;chinese&#39;</span><span class="p">,</span>
                  <span class="n">window_size</span> <span class="o">=</span> <span class="mi">6</span><span class="p">,</span>
                  <span class="n">vector_size</span> <span class="o">=</span> <span class="mi">50</span><span class="p">)</span>


<span class="n">w2v</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">Mac(Linux) System, Enable Parallel Processing
Cache output/ä¸‰ä½“_cache.txt Not Found or Empty, Preprocessing Corpus
Reading Preprocessed Corpus from output/ä¸‰ä½“_cache.txt
Start Training Word2Vec
Word2Vec Training Cost 10 s.
Output Saved To: output/Word2Vec/ä¸‰ä½“-Word2Vec.50.6.bin
</code></pre></div><p>[data/ä¸‰ä½“.txt]ä½“ç§¯ 2.7Mï¼Œ è®­ç»ƒæ—¶é—´ 10sï¼Œ æ¨¡å‹æ–‡ä»¶å­˜å‚¨äº <strong><em>output/Word2Vec/ä¸‰ä½“-Word2Vec.50.6.bin</em></strong></p>
<p><img loading="lazy" src="img/03-word2vec.png" alt=""  />
</p>
<br>
<br>
<h3 id="42-glove">4.2 GloVe()<a hidden class="anchor" aria-hidden="true" href="#42-glove">#</a></h3>
<p>ä½¿ç”¨ Stanford GloVe ä»£ç å·¥å…·è®­ç»ƒ GloVe æ¨¡å‹ã€‚è¯¥å‡½æ•°ä¼šè‡ªåŠ¨å¤„ç†æ–‡æœ¬é¢„å¤„ç†ã€å†…å­˜ç®¡ç†ã€å‚æ•°è°ƒæ•´ç­‰é—®é¢˜ï¼Œç¡®ä¿è®­ç»ƒè¿‡ç¨‹é¡ºåˆ©è¿›è¡Œã€‚</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">ct.GloVe(corpus_file, lang=&#39;chinese&#39;, dict_file=None, stopwords_file=None, vector_size=100, window_size=15, min_count=5, max_memory=4.0, max_iter=15, x_max=10, only_binary=True, chunksize=10000)
</code></pre></div><ul>
<li><strong><em>corpus_file</em></strong>: è¾“å…¥è¯­æ–™æ–‡ä»¶è·¯å¾„ï¼ˆæ–‡æœ¬æ ¼å¼ï¼‰ã€‚è¯¥æ–‡ä»¶ä¸ºåˆ†è¯åçš„è¯­æ–™æ–‡ä»¶ã€‚</li>
<li><strong><em>lang</em></strong>: è¯­æ–™æ–‡ä»¶çš„è¯­è¨€ç±»å‹ï¼Œé»˜è®¤ä¸º &lsquo;chinese&rsquo;ã€‚</li>
<li><strong><em>dict_file</em></strong>: è‡ªå®šä¹‰è¯å…¸ txt æ–‡ä»¶è·¯å¾„ï¼Œé»˜è®¤ä¸º Noneã€‚utf-8 ç¼–ç ã€‚</li>
<li><strong><em>stopwords_file</em></strong>: åœç”¨è¯æ–‡ä»¶è·¯å¾„ï¼Œé»˜è®¤ä¸º Noneã€‚utf-8 ç¼–ç ã€‚</li>
<li><strong><em>vector_size</em></strong>: è¯å‘é‡ç»´åº¦ï¼Œé»˜è®¤ 100ã€‚</li>
<li><strong><em>window_size</em></strong>: ä¸Šä¸‹æ–‡çª—å£å¤§å°ï¼Œé»˜è®¤ 15ã€‚</li>
<li><strong><em>min_count</em></strong>: å¿½ç•¥å‡ºç°æ¬¡æ•°ä½äºæ­¤å€¼çš„å•è¯ï¼Œé»˜è®¤ 5ã€‚</li>
<li><strong><em>max_memory</em></strong>: å¯ä¾›ä½¿ç”¨çš„æœ€å¤§å†…å­˜å¤§å°ï¼Œå•ä½ä¸º GBï¼Œé»˜è®¤ 4; è¯¥å‚æ•°è¶Šå¤§ï¼Œè®­ç»ƒè¶Šå¿«ã€‚</li>
<li><strong><em>max_iter</em></strong>: è®­ç»ƒçš„æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼Œé»˜è®¤ 15ã€‚</li>
<li><strong><em>x_max</em></strong>: å…±ç°çŸ©é˜µä¸­å…ƒç´ çš„æœ€å¤§è®¡æ•°å€¼ï¼Œé»˜è®¤ 10ã€‚</li>
<li><strong><em>chunksize</em></strong>: æ¯æ¬¡è¯»å–çš„è¡Œæ•°ã€‚é»˜è®¤ä¸º 10000ã€‚è¶Šå¤§é€Ÿåº¦è¶Šå¿«ã€‚</li>
<li><strong><em>only_binary</em></strong> : æ˜¯å¦åªä¿å­˜æ¨¡å‹ä¸ºäºŒè¿›åˆ¶æ–‡ä»¶ã€‚é»˜è®¤ä¸º Trueï¼Œ ä¿å­˜ä¸º binã€‚False æ—¶åªä¿å­˜ binã€txtã€‚</li>
</ul>
<br>
<p>ct.GloVe å†…ç½® <a href="https://nlp.stanford.edu/projects/glove/">Stanford GloVe</a>ç®—æ³•ï¼Œ è®­ç»ƒé€Ÿåº¦éå¸¸å¿«ã€‚</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>

<span class="n">glove</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">GloVe</span><span class="p">(</span><span class="n">corpus_file</span><span class="o">=</span><span class="s1">&#39;data/ä¸‰ä½“.txt&#39;</span><span class="p">,</span>
                 <span class="n">lang</span><span class="o">=</span><span class="s1">&#39;chinese&#39;</span><span class="p">,</span>
                 <span class="n">vector_size</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
                 <span class="n">window_size</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>

<span class="n">glove</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">Mac(Linux) System, Enable Parallel Processing
Cache output/ä¸‰ä½“_cache.txt Not Found or Empty, Preprocessing Corpus
Start Training GloVe
BUILDING VOCABULARY
Using vocabulary of size 6975.

COUNTING COOCCURRENCES
Merging cooccurrence files: processed 2106999 lines.

Using random seed 1743474106
SHUFFLING COOCCURRENCES
Merging temp files: processed 2106999 lines.

TRAINING MODEL
Read 2106999 lines.
Using random seed 1743474106
04/01/25 - 10:21.46AM, iter: 001, cost: 0.055981
04/01/25 - 10:21.46AM, iter: 002, cost: 0.050632
......
04/01/25 - 10:21.48AM, iter: 014, cost: 0.030047
04/01/25 - 10:21.48AM, iter: 015, cost: 0.029100

GloVe Training Cost 9 s.
Output Saved To: output/ä¸‰ä½“-GloVe.50.15.bin
&lt;gensim.models.keyedvectors.KeyedVectors at 0x331517440&gt;
</code></pre></div><p><img loading="lazy" src="img/05-glove.png" alt=""  />
</p>
<p>è®­ç»ƒç”Ÿæˆçš„ <code>output/GloVe/ä¸‰ä½“-GloVe.50.15.bin</code> å¯ç”¨ <strong><em>ct.load_w2v</em></strong> è¯»å–ï¼Œåœ¨åé¢ä¼šæœ‰å±•ç¤ºã€‚</p>
<br>
<h3 id="43-evaluate_similarity">4.3 evaluate_similarity()<a hidden class="anchor" aria-hidden="true" href="#43-evaluate_similarity">#</a></h3>
<p>è¯„ä¼°è¯å‘é‡æ¨¡å‹è¯­ä¹‰ç›¸ä¼¼è¡¨ç°ã€‚ ä½¿ç”¨ Spearman&rsquo;s Rank Coeficient ä½œä¸ºè¯„ä»·æŒ‡æ ‡ï¼Œ å–å€¼[-1, 1], 1 å®Œå…¨ç›¸å…³ï¼Œ-1 å®Œå…¨è´Ÿç›¸å…³ï¼Œ 0 æ¯«æ— ç›¸å…³æ€§ã€‚</p>
<p>cntext2.x å†…ç½® 537 æ¡è¿‘ä¹‰å®éªŒæ•°æ®ï¼Œ å¯ç›´æ¥ä½¿ç”¨ã€‚</p>
<p><img loading="lazy" src="img/01-similar.png" alt=""  />
</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">ct</span><span class="o">.</span><span class="n">evaluate_similarity</span><span class="p">(</span><span class="n">wv</span><span class="p">,</span> <span class="n">file</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</code></pre></div><ul>
<li><strong>wv</strong> è¯­æ–™ txt æ–‡ä»¶è·¯å¾„</li>
<li><strong>file</strong> è¯„ä¼°æ•°æ®æ–‡ä»¶ï¼Œtxt æ ¼å¼ï¼Œé»˜è®¤ä½¿ç”¨ cntext å†…ç½®çš„è¯„ä¼°æ•°æ®æ–‡ä»¶ã€‚ txt æ–‡ä»¶æ¯è¡Œä¸¤ä¸ªè¯ä¸€ä¸ªæ•°å­—ï¼Œå¦‚ä¸‹æ‰€ç¤º</li>
</ul>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">è¶³çƒ	è¶³çƒ	4.98
è€è™	è€è™	4.8888888889
æ’æ˜Ÿ	æ’æ˜Ÿ	4.7222222222
å…¥åœºåˆ¸	é—¨ç¥¨	4.5962962963
ç©ºé—´	åŒ–å­¦	0.9222222222
è‚¡ç¥¨	ç”µè¯	0.92
å›½ç‹	è½¦	0.9074074074
ä¸­åˆ	å­—ç¬¦ä¸²	0.6
æ”¶éŸ³æœº	å·¥ä½œ	0.6
æ•™æˆ	é»„ç“œ	0.5
è‡ªè¡Œè½¦	é¸Ÿ	0.5
è›‹ç™½è´¨	æ–‡ç‰©	0.15
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>

<span class="c1"># å¯åœ¨ https://cntext.readthedocs.io/zh-cn/latest/embeddings.html ä¸‹è½½è¯¥æ¨¡å‹æ–‡ä»¶</span>
<span class="n">dm_w2v</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">load_w2v</span><span class="p">(</span><span class="s1">&#39;output/douban-movie-1000w-Word2Vec.200.15.bin&#39;</span><span class="p">)</span>

<span class="c1"># ä½¿ç”¨å†…ç½®è¯„ä¼°æ–‡ä»¶</span>
<span class="n">ct</span><span class="o">.</span><span class="n">evaluate_similarity</span><span class="p">(</span><span class="n">wv</span><span class="o">=</span><span class="n">dm_w2v</span><span class="p">)</span>
<span class="c1"># ä½¿ç”¨è‡ªå®šä¹‰è¯„ä¼°æ–‡ä»¶</span>
<span class="c1"># ct.evaluate_similarity(wv=dm_w2v, file=&#39;diy_similarity.txt&#39;)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">è¿‘ä¹‰æµ‹è¯•: similarity.txt
/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/cntext/model/evaluate_data/similarity.txt
Processing Similarity Test: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 537/537 [00:00&lt;00:00, 85604.55it/s]

è¯„ä¼°ç»“æœï¼š
+----------+------------+----------------------------+
| å‘ç°è¯è¯­ | æœªå‘ç°è¯è¯­ | Spearman&#39;s Rank Coeficient |
+----------+------------+----------------------------+
|   459    |     78     |            0.43            |
+----------+------------+----------------------------+
</code></pre></div><br>
<h3 id="44-evaluate_analogy">4.4 evaluate_analogy()<a hidden class="anchor" aria-hidden="true" href="#44-evaluate_analogy">#</a></h3>
<p>ç”¨äºè¯„ä¼°è¯å‘é‡æ¨¡å‹åœ¨ç±»æ¯”æµ‹è¯•ï¼ˆanalogy testï¼‰ä¸­è¡¨ç°çš„å‡½æ•°ã€‚å®ƒé€šè¿‡è¯»å–æŒ‡å®šçš„ç±»æ¯”æµ‹è¯•æ–‡ä»¶ï¼Œè®¡ç®—æ¨¡å‹å¯¹è¯è¯­å…³ç³»é¢„æµ‹çš„å‡†ç¡®æ€§ï¼Œå¹¶è¾“å‡ºæ¯ä¸ªç±»åˆ«çš„å‡†ç¡®ç‡ã€å‘ç°è¯è¯­æ•°é‡ã€æœªå‘ç°è¯è¯­æ•°é‡ä»¥åŠå¹³å‡æ’åç­‰æŒ‡æ ‡ã€‚</p>
<ul>
<li>é›…å…¸ä¹‹äºå¸Œè…Šï¼Œä¼¼å¦‚å·´æ ¼è¾¾ä¹‹äºä¼Šæ‹‰å…‹ã€‚</li>
<li>å“ˆå°”æ»¨ä¹‹äºé»‘é¾™æ±Ÿï¼Œä¼¼å¦‚é•¿æ²™ä¹‹äºæ¹–å—ã€‚</li>
<li>å›½ç‹ä¹‹äºç‹åï¼Œä¼¼å¦‚ç”·äººä¹‹äºå¥³äººã€‚</li>
</ul>
<p><img loading="lazy" src="img/02-analogy-woman.png" alt=""  />
</p>
<p>cntext2.x å†…ç½® 1194 æ¡ç±»æ¯”ï¼Œ æ ¼å¼å¦‚ä¸‹</p>
<p><img loading="lazy" src="img/03-analogy.png" alt=""  />
</p>
<p>ç±»æ¯”æµ‹è¯•çš„æ ¸å¿ƒæ˜¯è§£å†³å½¢å¦‚ &ldquo;A : B :: C : D&rdquo; çš„é—®é¢˜ï¼Œç¿»è¯‘è¿‡æ¥å°±æ˜¯&quot;A ä¹‹äº Bï¼Œä¼¼å¦‚ C ä¹‹äº D&quot;ï¼› å³é€šè¿‡ AB ç±»æ¯”å…³ç³»ï¼Œæ‰¾åˆ° C çš„å…³ç³»è¯ Dã€‚è¯¥å‡½æ•°é€šè¿‡è¯å‘é‡æ¨¡å‹çš„ç›¸ä¼¼æ€§æœç´¢åŠŸèƒ½ï¼Œè®¡ç®—é¢„æµ‹ç»“æœä¸çœŸå®ç­”æ¡ˆçš„åŒ¹é…ç¨‹åº¦ã€‚</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">ct</span><span class="o">.</span><span class="n">evaluate_analogy</span><span class="p">(</span><span class="n">wv</span><span class="p">,</span> <span class="n">file</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</code></pre></div><ul>
<li><strong>wv</strong> è¯­æ–™ txt æ–‡ä»¶è·¯å¾„</li>
<li><strong>file</strong> è¯„ä¼°æ•°æ®æ–‡ä»¶ï¼Œtxt æ ¼å¼ï¼Œé»˜è®¤ä½¿ç”¨ cntext å†…ç½®çš„è¯„ä¼°æ•°æ®æ–‡ä»¶ã€‚ txt æ–‡ä»¶æ¯è¡Œä¸¤ä¸ªè¯ä¸€ä¸ªæ•°å­—ï¼Œå¦‚ä¸‹æ‰€ç¤º</li>
</ul>
<br>
<p>è¯„ä¼°æ•°æ® txt æ–‡ä»¶æ ¼å¼ï¼Œå¦‚ä¸‹</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">: CapitalOfCountries
é›…å…¸ å¸Œè…Š å·´æ ¼è¾¾ ä¼Šæ‹‰å…‹
å“ˆç“¦é‚£ å¤å·´ é©¬å¾·é‡Œ è¥¿ç­ç‰™
æ²³å†… è¶Šå— ä¼¦æ•¦ è‹±å›½
: CityInProvince
çŸ³å®¶åº„ æ²³åŒ— å—æ˜Œ æ±Ÿè¥¿
æ²ˆé˜³ è¾½å® å—æ˜Œ æ±Ÿè¥¿
å—äº¬ æ±Ÿè‹ éƒ‘å· æ²³å—
: FamilyRelationship
ç”·å­© å¥³å­© å…„å¼Ÿ å§å¦¹
ç”·å­© å¥³å­© å›½ç‹ ç‹å
çˆ¶äº² æ¯äº² å›½ç‹ ç‹å
ä¸ˆå¤« å¦»å­ å”å” é˜¿å§¨
: SocialScience-Concepts
ç¤¾ä¼š ç¤¾ä¼šç»“æ„ å®¶åº­ å®¶åº­ç»“æ„
æ–‡åŒ– æ–‡åŒ–ä¼ æ‰¿ è¯­è¨€ è¯­è¨€ä¼ æ‰¿
ç¾¤ä½“ ç¾¤ä½“è¡Œä¸º ç»„ç»‡ ç»„ç»‡è¡Œä¸º
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>

<span class="c1"># å¯åœ¨ https://cntext.readthedocs.io/zh-cn/latest/embeddings.html ä¸‹è½½è¯¥æ¨¡å‹æ–‡ä»¶</span>
<span class="n">dm_w2v</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">load_w2v</span><span class="p">(</span><span class="s1">&#39;output/douban-movie-1000w-Word2Vec.200.15.bin&#39;</span><span class="p">)</span>

<span class="c1"># ä½¿ç”¨å†…ç½®è¯„ä¼°æ–‡ä»¶</span>
<span class="n">ct</span><span class="o">.</span><span class="n">evaluate_analogy</span><span class="p">(</span><span class="n">wv</span><span class="o">=</span><span class="n">dm_w2v</span><span class="p">)</span>
<span class="c1"># ä½¿ç”¨è‡ªå®šä¹‰è¯„ä¼°æ–‡ä»¶</span>
<span class="c1"># ct.evaluate_analogy(wv=dm_w2v, file=&#39;diy_analogy.txt&#39;)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">ç±»æ¯”æµ‹è¯•: analogy.txt
/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/cntext/model/evaluate_data/analogy.txt
Processing Analogy Test: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1198/1198 [00:11&lt;00:00, 103.52it/s]

è¯„ä¼°ç»“æœï¼š
+--------------------+----------+------------+------------+----------+
|      Category      | å‘ç°è¯è¯­ | æœªå‘ç°è¯è¯­ | å‡†ç¡®ç‡ (%) | å¹³å‡æ’å |
+--------------------+----------+------------+------------+----------+
| CapitalOfCountries |   615    |     62     |   39.02    |   2.98   |
|   CityInProvince   |   175    |     0      |   28.57    |   4.74   |
| FamilyRelationship |   272    |     0      |   92.65    |   1.48   |
|   SocialScience    |    8     |     62     |   25.00    |   6.00   |
+--------------------+----------+------------+------------+----------+
</code></pre></div><p>è±†ç“£ç”µå½±åœ¨ FamilyRelationship è¯„ä¼°ä¸­è¡¨ç°è¾ƒå¥½ï¼Œå¤§æ¦‚ç‡æ˜¯å› ä¸ºç”µå½±ä¸»è¦åæ˜ çš„æ˜¯äººä¸äººä¹‹é—´çš„å…³ç³»ï¼Œè¦†ç›–äº†ç»å¤§å¤šæ•° FamilyRelationship å®¶åº­ç±»æ¯”å…³ç³»ï¼Œæ‰€ä»¥ç±»æ¯”è¡¨ç°å·¨å¥½ï¼Œä½†åœ¨å…¶ä»–æ–¹é¢è¡¨ç°è¾ƒå·®ã€‚</p>
<p>å¦‚æœæ˜¯ç»´åŸºç™¾ç§‘è¯­æ–™ï¼Œå¯èƒ½åœ¨ CapitalOfCountriesã€CityInProvinceã€SocialScience ä¸­è¡¨ç°è¾ƒå¥½ã€‚</p>
<br>
<h3 id="45-sopmi">4.5 SoPmi()<a hidden class="anchor" aria-hidden="true" href="#45-sopmi">#</a></h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">ct</span><span class="o">.</span><span class="n">SoPmi</span><span class="p">(</span><span class="n">corpus_file</span><span class="p">,</span> <span class="n">seed_file</span><span class="p">)</span>       <span class="c1">#äººå·¥æ ‡æ³¨çš„åˆå§‹ç§å­è¯</span>
</code></pre></div><ul>
<li><strong>corpus_file</strong> è¯­æ–™ txt æ–‡ä»¶è·¯å¾„</li>
<li><strong>seed_file</strong> åˆå§‹ç§å­è¯ txt æ–‡ä»¶è·¯å¾„</li>
</ul>
<p>å…±ç°æ³•</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>

<span class="n">ct</span><span class="o">.</span><span class="n">SoPmi</span><span class="p">(</span><span class="n">corpus_file</span><span class="o">=</span><span class="s1">&#39;data/sopmi_corpus.txt&#39;</span><span class="p">,</span>
         <span class="n">seed_file</span><span class="o">=</span><span class="s1">&#39;data/sopmi_seed.txt&#39;</span><span class="p">)</span>       <span class="c1"># äººå·¥æ ‡æ³¨çš„åˆå§‹ç§å­è¯</span>

</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">Step 1/4:...Preprocess   Corpus ...
Step 2/4:...Collect co-occurrency information ...
Step 3/4:...Calculate   mutual information ...
Step 4/4:...Save    candidate words ...
Finish! used 19.74 s
</code></pre></div><p><img loading="lazy" src="img/06-sopmi.png" alt=""  />
</p>
<br>
<h3 id="46-load_w2v">4.6 load_w2v()<a hidden class="anchor" aria-hidden="true" href="#46-load_w2v">#</a></h3>
<p>å¯¼å…¥ cntext2.x é¢„è®­ç»ƒçš„ word2vec æ¨¡å‹ .txt æ–‡ä»¶</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">ct</span><span class="o">.</span><span class="n">load_w2v</span><span class="p">(</span><span class="n">w2v_path</span><span class="p">)</span>
</code></pre></div><ul>
<li><strong>w2v_path</strong> æ¨¡å‹æ–‡ä»¶è·¯å¾„</li>
</ul>
<p>è¯»å– <strong><em>output/ä¸‰ä½“.100.6.txt</em></strong> æ¨¡å‹æ–‡ä»¶, è¿”å› <code>gensim.models.word2vec.Word2Vec</code> ç±»å‹ã€‚</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>

<span class="n">santi_w2v</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">load_w2v</span><span class="p">(</span><span class="n">w2v_path</span><span class="o">=</span><span class="s1">&#39;output/ä¸‰ä½“-Word2Vec.50.6.bin&#39;</span><span class="p">)</span>
<span class="c1"># santi_w2v = ct.load_wv(wv_path=&#39;output/ä¸‰ä½“-Word2Vec.50.6.txt&#39;)</span>

<span class="n">santi_glove</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">load_w2v</span><span class="p">(</span><span class="n">w2v_path</span><span class="o">=</span><span class="s1">&#39;output/ä¸‰ä½“-GloVe.50.15.bin&#39;</span><span class="p">)</span>
<span class="c1"># santi_glove = ct.load_wv(wv_path=&#39;output/ä¸‰ä½“-GloVe.50.15.bin&#39;)</span>

<span class="n">santi_w2v</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">Loading output/ä¸‰ä½“-Word2Vec.50.6.bin...
Loading output/ä¸‰ä½“-GloVe.50.15.bin...
&lt;gensim.models.keyedvectors.KeyedVectors at 0x33aa9cf80&gt;
</code></pre></div><br>
<h3 id="47-glove2word2vec">4.7 glove2word2vec()<a hidden class="anchor" aria-hidden="true" href="#47-glove2word2vec">#</a></h3>
<p>å°† GLoVe æ¨¡å‹.txt æ–‡ä»¶è½¬åŒ–ä¸º Word2Vec æ¨¡å‹.txt æ–‡ä»¶ï¼› é™¤éä»ç½‘ç»œä¸‹è½½çš„ GloVe æ¨¡å‹èµ„æºï¼Œ å¦åˆ™ä¸€èˆ¬æƒ…å†µç”¨ä¸åˆ°è¿™ä¸ªå‡½æ•°ã€‚</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">ct</span><span class="o">.</span><span class="n">glove2word2vec</span><span class="p">(</span><span class="n">glove_file</span><span class="p">,</span> <span class="n">word2vec_file</span><span class="p">)</span>
</code></pre></div><ul>
<li><strong><em>glove_file</em></strong>: GLoVe æ¨¡å‹.txt æ–‡ä»¶è·¯å¾„</li>
<li><strong><em>word2vec_file</em></strong>: Word2Vec æ¨¡å‹.txt æ–‡ä»¶è·¯å¾„</li>
</ul>
<br>
<p>æ³¨æ„è¿™é‡Œçš„ GLoVe æ¨¡å‹.txt æ˜¯é€šè¿‡<a href="https://github.com/standfordnlp/GloVe">Standfordnlp/GloVe</a> è®­ç»ƒå¾—åˆ°çš„</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>
<span class="n">ct</span><span class="o">.</span><span class="n">glove2word2vec</span><span class="p">(</span><span class="n">glove_file</span><span class="o">=</span><span class="s1">&#39;data/GloVe.6B.50d.txt&#39;</span><span class="p">,</span>
                  <span class="n">word2vec_file</span><span class="o">=</span><span class="s1">&#39;output/word2vec_format_GloVe.6B.50d.txt&#39;</span><span class="p">)</span>
</code></pre></div><br>
<h3 id="æ³¨æ„">æ³¨æ„<a hidden class="anchor" aria-hidden="true" href="#æ³¨æ„">#</a></h3>
<ul>
<li><strong><em>ct.load_w2v()</em></strong> å¯¼å…¥åå¾—åˆ°çš„æ•°æ®ç±»å‹æ˜¯ <strong><em>gensim.models.keyedvectors.KeyedVectors</em></strong> ã€‚</li>
<li><strong><em>gensim.models.word2vec.Word2Vec</em></strong> å¯ä»¥è½¬åŒ–ä¸º <strong><em>gensim.models.keyedvectors.KeyedVectors</em></strong> ï¼Œ</li>
</ul>
<br>
<h3 id="48-expand_dictionary">4.8 expand_dictionary()<a hidden class="anchor" aria-hidden="true" href="#48-expand_dictionary">#</a></h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">ct.expand_dictionary(wv,  seeddict, topn=100)
</code></pre></div><ul>
<li><strong>wv</strong> é¢„è®­ç»ƒæ¨¡å‹ï¼Œæ•°æ®ç±»å‹ä¸º gensim.models.keyedvectors.KeyedVectorsã€‚</li>
<li><strong>seeddict</strong> å‚æ•°ç±»ä¼¼äºç§å­è¯ï¼›æ ¼å¼ä¸º PYTHON å­—å…¸ï¼›</li>
<li><strong>topn</strong> è¿”å› topn ä¸ªè¯­ä¹‰æœ€æ¥è¿‘ seeddict çš„è¯</li>
</ul>
<p>æ ¹æ®è®¾ç½®çš„ seeddict, å¯æŒ‰ç±»åˆ«æ‰©å±•å¹¶ç”Ÿæˆå¯¹åº”çš„è¯å…¸ txt æ–‡ä»¶ï¼Œ txt æ–‡ä»¶ä½äº[output]æ–‡ä»¶å¤¹å†…ã€‚</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">seeddict</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;äººç‰©&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;å¶æ–‡æ´&#39;</span><span class="p">,</span> <span class="s1">&#39;å²å¼º&#39;</span><span class="p">,</span> <span class="s1">&#39;ç½—è¾‘&#39;</span><span class="p">],</span>
    <span class="s1">&#39;ç‰©ä½“&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;é£èˆ¹&#39;</span><span class="p">,</span> <span class="s1">&#39;è½¦è¾†&#39;</span><span class="p">]</span>
<span class="p">}</span>


<span class="n">ct</span><span class="o">.</span><span class="n">expand_dictionary</span><span class="p">(</span><span class="n">wv</span><span class="o">=</span><span class="n">santi_w2v</span><span class="o">.</span><span class="n">wv</span><span class="p">,</span>
                     <span class="n">seeddict</span><span class="o">=</span><span class="n">seeddict</span><span class="p">,</span>
                     <span class="n">topn</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</code></pre></div><p><img loading="lazy" src="img/04-expand.png" alt=""  />
</p>
<br>
<br>
<h2 id="äº”mind-æ¨¡å—">äº”ã€Mind æ¨¡å—<a hidden class="anchor" aria-hidden="true" href="#äº”mind-æ¨¡å—">#</a></h2>
<p>è¯åµŒå…¥ä¸­è•´å«ç€äººç±»çš„è®¤çŸ¥ä¿¡æ¯ï¼Œä»¥å¾€çš„è¯åµŒå…¥å¤§å¤šæ˜¯æ¯”è¾ƒä¸€ä¸ªæ¦‚å¿µä¸­ä¸¤ç»„åä¹‰è¯ä¸æŸå¯¹è±¡çš„è·ç¦»è®¡ç®—è®¤çŸ¥ä¿¡æ¯ã€‚</p>
<ul>
<li>
<p><strong>å¤šä¸ªå¯¹è±¡ä¸æŸæ¦‚å¿µçš„è¯­ä¹‰è¿œè¿‘</strong>ï¼ŒèŒä¸šä¸æ€§åˆ«ï¼ŒæŸä¸ªèŒä¸šæ˜¯å¦å­˜åœ¨äº²è¿‘ç”·æ€§ï¼Œè€Œæ’æ–¥å¥³æ€§</p>
</li>
<li>
<p>å¤šä¸ªå¯¹è±¡åœ¨æŸæ¦‚å¿µå‘é‡æŠ•å½±çš„å¤§å°ï¼Œ äººç±»è¯­è¨€ä¸­ç•™å­˜ç€å¯¹ä¸åŒåŠ¨ç‰©ä½“ç§¯çš„è®¤çŸ¥è®°å¿†ï¼Œå¦‚å°é¼ å¤§è±¡ã€‚åŠ¨ç‰©è¯åœ¨è¯å‘é‡ç©ºé—´ä¸­æ˜¯å¦èƒ½ç•™å­˜ç€è¿™ç§å¤§å°çš„è®°å¿†</p>
</li>
</ul>
<p>æœ¬æ¨¡å—ä¸»è¦æ˜¯åˆ©ç”¨å·²è®­ç»ƒå‡ºçš„ word2vec æ¨¡å‹ï¼ŒæŒ–æ˜æ½œåœ¨çš„æ€åº¦åè§ã€åˆ»æ¿å°è±¡ç­‰ã€‚ è¿™éƒ¨åˆ†éš¾åº¦è¾ƒå¤§ï¼Œ å»ºè®®æœ‰ç²¾åŠ›ä¸”ç”µè„‘æ€§èƒ½å¥½çš„åŒå­¦å¯ä»¥ç”¨ cntext è®­ç»ƒæ¨¡å‹ï¼Œ å†æ¥å®éªŒ Mind æ¨¡å—ã€‚</p>
<table>
<thead>
<tr>
<th>æ¨¡å—</th>
<th>å‡½æ•°(ç±»)</th>
<th>åŠŸèƒ½</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>mind</strong></td>
<td><code>ct.semantic_centroid(wv, words)</code></td>
<td>è®¡ç®—å¤šä¸ªè¯è¯­çš„è¯­ä¹‰ä¸­å¿ƒå‘é‡</td>
</tr>
<tr>
<td><strong>mind</strong></td>
<td><code>ct.generate_concept_axis(wv, poswords, negwords)</code></td>
<td>ç”Ÿæˆæ¦‚å¿µè½´å‘é‡ã€‚</td>
</tr>
<tr>
<td><strong>mind</strong></td>
<td><code>sematic_projection(wv, words, poswords, negwords)</code></td>
<td>æµ‹é‡è¯­ä¹‰æŠ•å½±</td>
</tr>
<tr>
<td><strong>mind</strong></td>
<td><code>ct.project_word(wv, a, b, cosine=False)</code></td>
<td>åœ¨è¯å‘é‡ç©ºé—´ä¸­ï¼Œ è®¡ç®—è¯è¯­ a åœ¨è¯è¯­ b ä¸Šçš„æŠ•å½±</td>
</tr>
<tr>
<td><strong>mind</strong></td>
<td><code>ct.project_text(wv, text, axis, lang='chinese', cosine=False)</code></td>
<td>è®¡ç®—è¯è¯­æ–‡æœ¬textåœ¨æ¦‚å¿µè½´å‘é‡axisä¸Šçš„æŠ•å½±å€¼</td>
</tr>
<tr>
<td><strong>mind</strong></td>
<td><code>ct.sematic_distance(wv, words1, words2)</code></td>
<td>æµ‹é‡è¯­ä¹‰è·ç¦»</td>
</tr>
<tr>
<td><strong>mind</strong></td>
<td><code>ct.divergent_association_task(wv, words)</code></td>
<td>æµ‹é‡å‘æ•£æ€ç»´(åˆ›é€ åŠ›)</td>
</tr>
<tr>
<td><strong>mind</strong></td>
<td><code>ct.discursive_diversity_score(wv, words)</code></td>
<td>æµ‹é‡è¯­è¨€å·®å¼‚æ€§(è®¤çŸ¥å·®å¼‚æ€§)</td>
</tr>
<tr>
<td><strong>mind</strong></td>
<td><strong>ct.procrustes_align(base_wv, other_wv)</strong></td>
<td>ä¸¤ä¸ª word2vec è¿›è¡Œè¯­ä¹‰å¯¹é½ï¼Œå¯ååº”éšæ—¶é—´çš„ç¤¾ä¼šè¯­ä¹‰å˜è¿</td>
</tr>
</tbody>
</table>
<br>
<h3 id="51-semantic_centroidwv-words">5.1 semantic_centroid(wv, words)<a hidden class="anchor" aria-hidden="true" href="#51-semantic_centroidwv-words">#</a></h3>
<p>è®¡ç®—å¤šä¸ªè¯è¯­çš„è¯­ä¹‰ä¸­å¿ƒå‘é‡</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>

<span class="c1"># è·å–è¯å‘é‡æ–‡ä»¶ https://cntext.readthedocs.io/zh-cn/latest/embeddings.html</span>
<span class="n">w2v</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">load_w2v</span><span class="p">(</span><span class="s1">&#39;ä¸“åˆ©æ‘˜è¦-Word2Vec.200.15.bin&#39;</span><span class="p">)</span>
<span class="n">semantic_centroid</span><span class="p">(</span><span class="n">wv</span><span class="o">=</span><span class="n">w2v</span><span class="p">,</span> <span class="n">words</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;åˆ›æ–°&#39;</span><span class="p">,</span> <span class="s1">&#39;é¢ è¦†&#39;</span><span class="p">])</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">array([ 0.15567462, -0.05117003, -0.18534171,  0.20808656, -0.01133028,
        0.10738188, -0.02571066,  0.06051835,  0.00107351,  0.08017981,
        0.08914138,  0.01845527,  0.06232869, -0.03851539, -0.17092938,
        0.02196799, -0.04136903,  0.11350462, -0.09539546,  0.04907424,
        0.01268489,  0.05294977,  0.08449743, -0.02762416,  0.02332745,
        0.08865491, -0.06260188, -0.0378293 ,  0.04771722,  0.05745243,
        0.04417403, -0.04126203, -0.02403288, -0.03834526,  0.08115771,
        0.01508994,  0.07678635,  0.01395652,  0.1360324 ,  0.03027042,
       -0.02819572,  0.02339242,  0.11504567,  0.02910597,  0.06149592,
        0.01126606, -0.10132807,  0.07762785, -0.01214836,  0.03780747,
        0.12758181, -0.03115267, -0.19343086, -0.21930983,  0.05253006,
       -0.01452067, -0.07067247, -0.04237257, -0.08911953,  0.08573315,
        0.02742999,  0.05392318,  0.02916237,  0.04465031, -0.0788566 ,
       -0.07088121,  0.03111146,  0.00387428, -0.04032568,  0.14935694,
       -0.03880607,  0.07259471,  0.01711774, -0.05551507,  0.01039889,
        0.00666137,  0.03313185,  0.03169986,  0.08127907,  0.0239668 ,
       -0.00991806, -0.04201584,  0.01199235, -0.08669737, -0.02087858,
       -0.03440931,  0.02360864,  0.06623896, -0.01020982,  0.01200165,
        0.01059455,  0.13041293,  0.01103112,  0.03814259, -0.01519256,
        0.02946554,  0.00593279,  0.08796389,  0.0198915 , -0.0569265 ,
       -0.14622693,  0.07680258, -0.02288322, -0.04959924,  0.03325186,
        0.11031196,  0.06893978,  0.04289736, -0.0307357 , -0.09662723,
        0.02554002,  0.05394766,  0.047071  , -0.09522557, -0.08160087,
       -0.01467315, -0.01304489,  0.07513782,  0.04484766, -0.0516454 ,
        0.00648148,  0.01093231, -0.00303798, -0.06217093,  0.02755075,
       -0.10749754, -0.05205868, -0.02562402,  0.09068517,  0.05208463,
       -0.11790312,  0.02881086, -0.02414756,  0.00192055,  0.03881926,
       -0.05390498,  0.06648378,  0.02055933, -0.07083403, -0.07248309,
       -0.12991821,  0.0603951 ,  0.14131376, -0.01507344, -0.06480791,
       -0.08994781, -0.03397571,  0.0108852 , -0.02777362,  0.01159309,
        0.00121858, -0.0690551 , -0.07747664,  0.03437752, -0.14576062,
        0.06320656, -0.10743124, -0.01910913,  0.15803815, -0.03027673,
       -0.02909171, -0.03350233, -0.0694584 , -0.09807504, -0.09133697,
       -0.01123043,  0.04894681, -0.01971908, -0.08290677, -0.00336836,
        0.09619438, -0.03496556,  0.09733834, -0.0421683 ,  0.01408717,
        0.03355598,  0.00748263,  0.011903  , -0.12909584,  0.01545653,
        0.07656407,  0.09496018,  0.0608537 ,  0.00597665, -0.01628997,
        0.06285962, -0.16796936, -0.0486528 ,  0.01525079, -0.03067709,
       -0.02952635, -0.02731965, -0.06351878,  0.03577968,  0.0457835 ,
        0.08370785, -0.03491699, -0.12606403, -0.08686454, -0.04782247])
</code></pre></div><br>
<h3 id="52-generate_concept_axiswv-poswords-negwords">5.2 generate_concept_axis(wv, poswords, negwords)<a hidden class="anchor" aria-hidden="true" href="#52-generate_concept_axiswv-poswords-negwords">#</a></h3>
<p>ç”Ÿæˆæ¦‚å¿µè½´å‘é‡ã€‚</p>
<ul>
<li><strong><em>wv</em></strong> ç”Ÿæˆæ¦‚å¿µè½´å‘é‡ã€‚</li>
<li><strong><em>poswords</em></strong> ç¬¬ä¸€ä¸ªè¯è¯­åˆ—è¡¨ï¼Œè¡¨ç¤ºæ¦‚å¿µæ­£ä¹‰è¯ã€‚</li>
<li><strong><em>negwords</em></strong> ç¬¬äºŒä¸ªè¯è¯­åˆ—è¡¨ï¼Œè¡¨ç¤ºæ¦‚å¿µåä¹‰è¯ã€‚</li>
</ul>
<p>éœ€è¦æ³¨æ„ï¼Œ æ¦‚å¿µ 1 ä¸ æ¦‚å¿µ 2 æ˜¯æ€§è´¨(æ–¹å‘)ç›¸åçš„ä¸¤ä¸ªæ¦‚å¿µï¼Œ å¦‚</p>
<ul>
<li>æ€§åˆ«(ç”·, å¥³)</li>
<li>å°ºå¯¸(å¤§, å°)</li>
<li>æ–¹å‘(é«˜, ä½)</li>
<li>æ–¹å‘(å‰, å)</li>
<li>æ¹¿åº¦(å¹², æ¹¿)</li>
<li>è´¢å¯Œ(è´«, å¯Œ)</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>

<span class="c1"># è·å–è¯å‘é‡æ–‡ä»¶</span>
<span class="c1"># https://github.com/hiDaDeng/Chinese-Pretrained-Word-Embeddings</span>
<span class="n">dm_w2v</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">load_w2v</span><span class="p">(</span><span class="s1">&#39;douban-movie-1000w-Word2Vec.200.15.bin&#39;</span><span class="p">)</span>
<span class="n">gender_axis_vector</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">generate_concept_axis</span><span class="p">(</span><span class="n">wv</span><span class="o">=</span><span class="n">dm_w2v</span><span class="p">,</span>
                                              <span class="n">poswords</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;ç”·&#39;</span><span class="p">,</span> <span class="s1">&#39;ç”·äºº&#39;</span><span class="p">,</span> <span class="s1">&#39;çˆ¶äº²&#39;</span><span class="p">],</span>
                                              <span class="n">negwords</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;å¥³&#39;</span><span class="p">,</span> <span class="s1">&#39;å¥³äºº&#39;</span><span class="p">,</span> <span class="s1">&#39;æ¯äº²&#39;</span><span class="p">])</span>
<span class="n">gender_axis_vector</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">array([-0.0118976 ,  0.03178174, -0.04656127,  0.00613294, -0.03692355,
       -0.06293361, -0.04739443,  0.01368712,  0.02603469, -0.02268519,
       -0.09925436,  0.05780286,  0.11218373,  0.07519485,  0.06885784,
        0.05505687, -0.04097392,  0.1737831 ,  0.05118835, -0.06879821,
        0.04762978,  0.02224233, -0.04891564, -0.08712718, -0.01432874,
       -0.07395219,  0.01229804,  0.06655715, -0.01864985, -0.04864848,
        0.00260787,  0.06843776,  0.00472286,  0.03623124,  0.11959086,
       -0.04683099, -0.11005358,  0.0271024 , -0.05976011,  0.12669185,
        0.03592191, -0.01125782, -0.02587771, -0.02719228,  0.0507662 ,
       -0.09198377,  0.09546432, -0.01937146,  0.06106697, -0.0405688 ,
       -0.1311393 ,  0.06090249,  0.03515694,  0.01364273, -0.02491697,
        0.03379048, -0.06635275,  0.01432849,  0.01212378, -0.0625283 ,
       -0.03481676, -0.0422427 , -0.17145215, -0.06323837,  0.02563147,
       -0.02371969,  0.01217621, -0.00346871,  0.07024875,  0.08295133,
        0.00731711, -0.01932047,  0.02165518, -0.09927654, -0.08531073,
        0.01949702,  0.00536061,  0.10426087, -0.02010326,  0.02297032,
       -0.10657956,  0.1035546 ,  0.00569263, -0.0849498 ,  0.1098236 ,
        0.05310893, -0.0802139 , -0.01034231, -0.12204715,  0.01407488,
       -0.01781198, -0.0134118 ,  0.09836894,  0.16098371,  0.00609895,
        0.05433145, -0.08940306,  0.00136946, -0.08455469, -0.08432727,
        0.04675778, -0.03415223, -0.18552355, -0.05219543, -0.01127822,
        0.02059881, -0.08120015, -0.15610164,  0.01439221,  0.01727759,
       -0.14516874,  0.01783531, -0.13099317,  0.03820422,  0.03033866,
       -0.01779634,  0.07759558,  0.15866944,  0.00191632, -0.00905253,
        0.0312649 , -0.05698524,  0.07270953, -0.00734233,  0.06289094,
        0.01014149, -0.0052088 ,  0.02478063, -0.0112649 , -0.0930789 ,
        0.14639418, -0.08183327, -0.08392337, -0.01458992, -0.0163887 ,
        0.06790476, -0.03252221,  0.08593727,  0.10469338, -0.01363467,
        0.00749907, -0.01320484,  0.08405331,  0.0489707 , -0.11343482,
       -0.10319041, -0.02415894,  0.13382405, -0.01983603, -0.00990637,
       -0.03335103,  0.11718886, -0.05802442, -0.18935862, -0.07409969,
       -0.08306517, -0.04423901,  0.11331058,  0.00588326,  0.06339834,
        0.04405889,  0.1263905 , -0.007273  , -0.02706875,  0.02325469,
       -0.13092995,  0.02056245, -0.0442118 , -0.01964739, -0.06501938,
        0.02196051, -0.1823353 ,  0.04273191,  0.01935809, -0.01464438,
       -0.02626805,  0.09194217,  0.02489716,  0.05376589, -0.00484252,
        0.02822759,  0.06744799, -0.14196248,  0.03016541, -0.05347864,
       -0.16907257,  0.05094757,  0.0721257 , -0.00421157,  0.03022675,
       -0.00047884,  0.07792547, -0.00209365,  0.0669208 ,  0.02009218,
        0.11358768, -0.05002993,  0.01760067,  0.03407429, -0.0893421 ],
      dtype=float32)
</code></pre></div><br>
<h3 id="53-sematic_distance">5.3 sematic_distance()<a hidden class="anchor" aria-hidden="true" href="#53-sematic_distance">#</a></h3>
<p><strong>å¤šä¸ªå¯¹è±¡ä¸æŸæ¦‚å¿µçš„è¯­ä¹‰è¿œè¿‘</strong>ï¼Œä¾‹å¦‚æˆåŠŸä¸æ€§åˆ«ï¼ŒæˆåŠŸæ˜¯å¦å­˜åœ¨äº²è¿‘ç”·æ€§ï¼Œè€Œæ’æ–¥å¥³æ€§</p>
<p><img loading="lazy" src="img/21-music-success-genderbias.png" alt=""  />
</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">ct.sematic_distance(wv, words1, words2)
</code></pre></div><ul>
<li><strong><em>wv</em></strong> æ¨¡å‹æ•°æ®ï¼Œ æ•°æ®ç±»å‹ä¸º gensim.models.keyedvectors.KeyedVectorsã€‚</li>
<li><strong><em>words1</em></strong>ã€<strong>words2</strong> å‡ä¸ºè¯è¯­åˆ—è¡¨</li>
</ul>
<p>åˆ†åˆ«è®¡ç®— <strong><em>words1</em></strong> ä¸ <strong><em>words2</em></strong> è¯­ä¹‰è·ç¦»ï¼Œè¿”å›è·ç¦»å·®å€¼ã€‚ä¾‹å¦‚</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">male_concept = [&#39;male&#39;, &#39;man&#39;, &#39;he&#39;, &#39;him&#39;]
female_concept = [&#39;female&#39;, &#39;woman&#39;, &#39;she&#39;, &#39;her&#39;]
engineer_concept  = [&#39;engineer&#39;,  &#39;programming&#39;,  &#39;software&#39;]

dist(male, engineer) = distance(male_concept,  engineer_concept)
dist(female, engineer) = distance(female_concept,  engineer_concept)
</code></pre></div><p>å¦‚æœ <strong><em>dist(male, engineer)-dist(female, engineer)&lt;0</em></strong>ï¼Œè¯´æ˜åœ¨è¯­ä¹‰ç©ºé—´ä¸­ï¼Œ<strong><em>engineer_concept</em></strong> æ›´æ¥è¿‘ <strong><em>male_concept</em></strong> ï¼Œæ›´è¿œç¦» <strong><em>female_concept</em></strong> ã€‚</p>
<p>æ¢è¨€ä¹‹ï¼Œåœ¨è¯¥è¯­æ–™ä¸­ï¼Œäººä»¬å¯¹è½¯ä»¶å·¥ç¨‹å¸ˆè¿™ä¸€ç±»å·¥ä½œï¼Œå¯¹å¥³æ€§å­˜åœ¨åˆ»æ¿å°è±¡(åè§)ã€‚</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>

<span class="c1"># glove_w2v.6B.100d.txté“¾æ¥: https://pan.baidu.com/s/1MMfQ7M0YCzL9Klp4zrlHBw æå–ç : 72l0</span>
<span class="n">g_wv</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">load_w2v</span><span class="p">(</span><span class="s1">&#39;data/glove_w2v.6B.100d.txt&#39;</span><span class="p">)</span>

<span class="n">engineer</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;program&#39;</span><span class="p">,</span> <span class="s1">&#39;software&#39;</span><span class="p">,</span> <span class="s1">&#39;computer&#39;</span><span class="p">]</span>
<span class="n">man_words</span> <span class="o">=</span>  <span class="p">[</span><span class="s2">&#34;man&#34;</span><span class="p">,</span> <span class="s2">&#34;he&#34;</span><span class="p">,</span> <span class="s2">&#34;him&#34;</span><span class="p">]</span>
<span class="n">woman_words</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&#34;woman&#34;</span><span class="p">,</span> <span class="s2">&#34;she&#34;</span><span class="p">,</span> <span class="s2">&#34;her&#34;</span><span class="p">]</span>

<span class="n">dist_male_engineer</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">sematic_distance</span><span class="p">(</span><span class="n">male_concept</span><span class="p">,</span>  <span class="n">engineer_concept</span><span class="p">)</span>
<span class="n">dist_female_engineer</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">sematic_distance</span><span class="p">(</span><span class="n">female_concept</span><span class="p">,</span>  <span class="n">engineer_concept</span><span class="p">)</span>

<span class="n">dist_male_engineer</span> <span class="o">-</span> <span class="n">dist_female_engineer</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">-0.5
</code></pre></div><p>dist_male_engineer &lt; dist_female_engineerï¼Œåœ¨è¯­ä¹‰ç©ºé—´ä¸­ï¼Œå·¥ç¨‹å¸ˆæ›´æ¥è¿‘äºç”·äººï¼Œè€Œä¸æ˜¯å¥³äººã€‚</p>
<br>
<h3 id="54-sematic_projection">5.4 sematic_projection()<a hidden class="anchor" aria-hidden="true" href="#54-sematic_projection">#</a></h3>
<p>å¤šä¸ªå¯¹è±¡åœ¨æŸæ¦‚å¿µå‘é‡æŠ•å½±çš„å¤§å°</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">ct</span><span class="o">.</span><span class="n">sematic_projection</span><span class="p">(</span><span class="n">wv</span><span class="p">,</span> <span class="n">words</span><span class="p">,</span> <span class="n">poswords</span><span class="p">,</span> <span class="n">negwords</span><span class="p">,</span> <span class="n">return_full</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">cosine</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</code></pre></div><ul>
<li><strong><em>wv</em></strong> æ¨¡å‹æ•°æ®ï¼Œ æ•°æ®ç±»å‹ä¸º gensim.models.keyedvectors.KeyedVectorsã€‚</li>
<li><strong><em>words</em></strong>ã€<strong><em>poswords</em></strong>ã€<strong><em>negwords</em></strong> å‡ä¸ºè¯è¯­åˆ—è¡¨</li>
<li><strong>cosine</strong>: æ˜¯å¦ä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦ï¼Œé»˜è®¤ä¸ºFalseï¼Œè¿”å›æŠ•å½±å€¼ï¼›Trueæ—¶è¿”å›ä½™å¼¦ç›¸ä¼¼åº¦</li>
<li><strong>return_full</strong>: æ˜¯å¦è¿”å›å®Œæ•´å…ƒç»„åˆ—è¡¨ï¼Œé»˜è®¤ä¸ºTrue</li>
</ul>
<br>
<p>ä¸ºäº†è§£é‡Šè¯å‘é‡æ¨¡å‹çš„è¯­ä¹‰æŠ•å½±ï¼Œæˆ‘ä½¿ç”¨äº† 2022 å¹´ Nature è®ºæ–‡ä¸­çš„å›¾ç‰‡[@Grand2022SemanticPR]ã€‚ å…³äºåŠ¨ç‰©çš„åå­—ï¼Œäººç±»å¯¹åŠ¨ç‰©å¤§å°çš„è®¤çŸ¥ä¿¡æ¯éšè—åœ¨è¯­æ–™åº“æ–‡æœ¬ä¸­ã€‚ é€šè¿‡å°†<strong>LARGE WORDS</strong> å’Œ<strong>SMALL WORDS</strong>çš„å«ä¹‰ç”¨ä¸åŒçš„<strong>animals</strong>çš„å‘é‡æŠ•å½±ï¼ŒåŠ¨ç‰©åœ¨<strong>size å‘é‡</strong>ä¸Šçš„æŠ•å½±ï¼ˆå°±åƒä¸‹å›¾ä¸­çš„çº¢çº¿ ) å¾—åˆ°ï¼Œå› æ­¤å¯ä»¥é€šè¿‡è®¡ç®—æ¯”è¾ƒåŠ¨ç‰©çš„å¤§å°ã€‚</p>
<p>æ ¹æ®ä¸¤ç»„åä¹‰è¯ <strong><em>poswords</em></strong> , <strong><em>negwords</em></strong> æ„å»ºä¸€ä¸ªæ¦‚å¿µ(è®¤çŸ¥)å‘é‡, words ä¸­çš„æ¯ä¸ªè¯å‘é‡åœ¨æ¦‚å¿µå‘é‡ä¸­æŠ•å½±ï¼Œå³å¯å¾—åˆ°è®¤çŸ¥ä¿¡æ¯ã€‚</p>
<p>åˆ†å€¼è¶Šå¤§ï¼Œ<strong><em>words</em></strong> è¶Šä½äº <strong><em>poswords</em></strong> ä¸€ä¾§ã€‚</p>
<blockquote>
<p>Grand, G., Blank, I.A., Pereira, F. and Fedorenko, E., 2022. Semantic projection recovers rich human knowledge of multiple object features from word embeddings. <em>Nature Human Behaviour</em>, pp.1-13.&quot;</p>
</blockquote>
<p><img loading="lazy" src="img/22-semantic_projection.png" alt=""  />
</p>
<p>ä¾‹å¦‚ï¼Œäººç±»çš„è¯­è¨€ä¸­ï¼Œå­˜åœ¨å°ºå¯¸ã€æ€§åˆ«ã€å¹´é¾„ã€æ”¿æ²»ã€é€Ÿåº¦ã€è´¢å¯Œç­‰ä¸åŒçš„æ¦‚å¿µã€‚æ¯ä¸ªæ¦‚å¿µå¯ä»¥ç”±ä¸¤ç»„åä¹‰è¯ç¡®å®šæ¦‚å¿µçš„å‘é‡æ–¹å‘ã€‚</p>
<p>ä»¥å°ºå¯¸ä¸ºä¾‹ï¼ŒåŠ¨ç‰©åœ¨äººç±»è®¤çŸ¥ä¸­å¯èƒ½å­˜åœ¨ä½“ç§¯å°ºå¯¸å¤§å°å·®å¼‚ã€‚</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>
<span class="n">animals</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;mouse&#39;</span><span class="p">,</span> <span class="s1">&#39;cat&#39;</span><span class="p">,</span> <span class="s1">&#39;horse&#39;</span><span class="p">,</span>  <span class="s1">&#39;pig&#39;</span><span class="p">,</span> <span class="s1">&#39;whale&#39;</span><span class="p">]</span>
<span class="n">small_words</span><span class="o">=</span> <span class="p">[</span><span class="s2">&#34;small&#34;</span><span class="p">,</span> <span class="s2">&#34;little&#34;</span><span class="p">,</span> <span class="s2">&#34;tiny&#34;</span><span class="p">]</span>
<span class="n">large_words</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&#34;large&#34;</span><span class="p">,</span> <span class="s2">&#34;big&#34;</span><span class="p">,</span> <span class="s2">&#34;huge&#34;</span><span class="p">]</span>

<span class="c1"># wiki_wv = ct.load_w2v(&#39;wikiçš„word2vecæ¨¡å‹æ–‡ä»¶è·¯å¾„&#39;)</span>
<span class="c1"># wiki_wv</span>

<span class="c1"># In size conception, mouse is smallest, horse is biggest.</span>
<span class="c1"># åœ¨å¤§å°æ¦‚å¿µä¸Šï¼Œè€é¼ æœ€å°ï¼Œé©¬æ˜¯æœ€å¤§çš„ã€‚</span>
<span class="n">ct</span><span class="o">.</span><span class="n">sematic_projection</span><span class="p">(</span><span class="n">wv</span><span class="o">=</span><span class="n">wiki_wv</span><span class="p">,</span>
                      <span class="n">words</span><span class="o">=</span><span class="n">animals</span><span class="p">,</span>
                      <span class="n">poswords</span><span class="o">=</span><span class="n">large_words</span><span class="p">,</span>
                      <span class="n">negwords</span><span class="o">=</span><span class="n">small_words</span><span class="p">,</span>
                      <span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">[(&#39;mouse&#39;, -1.68),
 (&#39;cat&#39;, -0.92),
 (&#39;pig&#39;, -0.46),
 (&#39;whale&#39;, -0.24),
 (&#39;horse&#39;, 0.4)]
</code></pre></div><p>å…³äºå°ºå¯¸çš„è®¤çŸ¥ï¼Œäººç±»åœ¨æ–‡æœ¬ä¸­éšå«ç€è€é¼ è¾ƒå°ï¼Œé©¬è¾ƒå¤§ã€‚</p>
<br>
<h3 id="55-project_word">5.5 project_word<a hidden class="anchor" aria-hidden="true" href="#55-project_word">#</a></h3>
<p>åœ¨å‘é‡ç©ºé—´ä¸­ï¼Œ è®¡ç®—è¯è¯­aåœ¨è¯è¯­bä¸Šçš„æŠ•å½±(ä½™å¼¦ç›¸ä¼¼åº¦)ã€‚é»˜è®¤è¿”å›çš„æ˜¯æŠ•å½±å€¼ã€‚
å¦‚æœ cosine=Trueï¼Œè¿”å›è¯è¯­aä¸è¯è¯­bçš„ä½™å¼¦ç›¸ä¼¼åº¦ã€‚</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">project_word</span><span class="p">(</span><span class="n">wv</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">cosine</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</code></pre></div><ul>
<li><strong>wv</strong> è¯­æ–™ txt æ–‡ä»¶è·¯å¾„</li>
<li><strong>a</strong> è¯è¯­ a å­—ç¬¦ä¸²æˆ–åˆ—è¡¨</li>
<li><strong>b</strong> è¯è¯­å­—ç¬¦ä¸²ã€è¯è¯­åˆ—è¡¨ã€æˆ–æŸæ¦‚å¿µå‘é‡</li>
<li><em><strong>cosine</strong></em>: æ˜¯å¦ä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦ï¼Œ é»˜è®¤ä¸ºFalseï¼Œè¿”å›aåœ¨bä¸Šçš„æŠ•å½±å€¼ï¼› Trueæ—¶ï¼Œè¿”å›aä¸bçš„ä½™å¼¦ç›¸ä¼¼åº¦ã€‚</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">b</span><span class="o">=</span><span class="s1">&#39;è‹—æ¡&#39;</span>
<span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;æ€§æ„Ÿ&#39;</span><span class="p">,</span><span class="s1">&#39;ç¾ä¸½&#39;</span><span class="p">,</span> <span class="s1">&#39;å¯çˆ±&#39;</span><span class="p">,</span> <span class="s1">&#39;ä¸‘é™‹&#39;</span><span class="p">]:</span>
    <span class="n">proj</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">project_word</span><span class="p">(</span><span class="n">dm_w2v</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;[</span><span class="si">{</span><span class="n">a</span><span class="si">}</span><span class="s1">]åœ¨[</span><span class="si">{</span><span class="n">b</span><span class="si">}</span><span class="s1">]æŠ•å½±å€¼: </span><span class="si">{</span><span class="n">proj</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>


<span class="n">b</span><span class="o">=</span><span class="s1">&#39;ä¿®é•¿&#39;</span>
<span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;æ€§æ„Ÿ&#39;</span><span class="p">,</span><span class="s1">&#39;ç¾ä¸½&#39;</span><span class="p">,</span> <span class="s1">&#39;å¯çˆ±&#39;</span><span class="p">,</span> <span class="s1">&#39;ä¸‘é™‹&#39;</span><span class="p">]:</span>
    <span class="n">proj</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">project_word</span><span class="p">(</span><span class="n">dm_w2v</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;[</span><span class="si">{</span><span class="n">a</span><span class="si">}</span><span class="s1">]åœ¨[</span><span class="si">{</span><span class="n">b</span><span class="si">}</span><span class="s1">]æŠ•å½±å€¼: </span><span class="si">{</span><span class="n">proj</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">[æ€§æ„Ÿ]åœ¨[è‹—æ¡]æŠ•å½±å€¼: 14.172947883605957
[ç¾ä¸½]åœ¨[è‹—æ¡]æŠ•å½±å€¼: 7.0944623947143555
[å¯çˆ±]åœ¨[è‹—æ¡]æŠ•å½±å€¼: 6.935092926025391
[ä¸‘é™‹]åœ¨[è‹—æ¡]æŠ•å½±å€¼: 1.235807180404663

[æ€§æ„Ÿ]åœ¨[ä¿®é•¿]æŠ•å½±å€¼: 14.599699974060059
[ç¾ä¸½]åœ¨[ä¿®é•¿]æŠ•å½±å€¼: 9.360642433166504
[å¯çˆ±]åœ¨[ä¿®é•¿]æŠ•å½±å€¼: 4.740543842315674
[ä¸‘é™‹]åœ¨[ä¿®é•¿]æŠ•å½±å€¼: 4.010622501373291
</code></pre></div><p>å¯ä»¥çœ‹åˆ°ï¼Œ åœ¨è±†ç“£ç”µå½±è¯­æ–™ä¸­ï¼Œ åœ¨[è‹—æ¡ã€ä¿®é•¿]ç»´åº¦çš„è®¤çŸ¥ä¸­ï¼Œéƒ½è®¤ä¸º</p>
<ul>
<li>[æ€§æ„Ÿ]æ„å‘³ç€èº«ææœ€ç˜¦é•¿</li>
<li>[ç¾ä¸½]æ¬¡ä¹‹ã€[å¯çˆ±]ç•¥æ˜¾ä¸é‚£ä¹ˆä¿®é•¿è‹—æ¡</li>
<li>[ä¸‘é™‹]æ„å‘³ç€åŸºæœ¬ä¸[è‹—æ¡ã€ä¿®é•¿]æ— å…³ï¼Œæ•°å€¼æœ€å°ã€‚</li>
</ul>
<br>
<p>ä¸ºäº†è®©æŠ•å½±å€¼æ›´ç¨³å®šï¼Œå¯ä»¥é€‰æ‹©è¯ç»„ï¼Œç¡®å®š[è‹—æ¡ã€ä¿®é•¿]è¿™ä¸ªæ¦‚å¿µçš„æ¦‚å¿µè½´å‘é‡</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;æ€§æ„Ÿ&#39;</span><span class="p">,</span><span class="s1">&#39;ç¾ä¸½&#39;</span><span class="p">,</span> <span class="s1">&#39;å¯çˆ±&#39;</span><span class="p">,</span> <span class="s1">&#39;ä¸‘é™‹&#39;</span><span class="p">]:</span>
    <span class="n">proj</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">project_word</span><span class="p">(</span><span class="n">wv</span><span class="o">=</span><span class="n">dm_w2v</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;ä¿®é•¿&#39;</span><span class="p">,</span> <span class="s1">&#39;è‹—æ¡&#39;</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;[</span><span class="si">{</span><span class="n">a</span><span class="si">}</span><span class="s1">]åœ¨[ä¿®é•¿ï¼Œè‹—æ¡]æŠ•å½±å€¼: </span><span class="si">{</span><span class="n">proj</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">[æ€§æ„Ÿ]åœ¨[ä¿®é•¿ï¼Œè‹—æ¡]æŠ•å½±å€¼: 15.807487487792969
[ç¾ä¸½]åœ¨[ä¿®é•¿ï¼Œè‹—æ¡]æŠ•å½±å€¼: 9.040315628051758
[å¯çˆ±]åœ¨[ä¿®é•¿ï¼Œè‹—æ¡]æŠ•å½±å€¼: 6.414511203765869
[ä¸‘é™‹]åœ¨[ä¿®é•¿ï¼Œè‹—æ¡]æŠ•å½±å€¼: 2.882350444793701
</code></pre></div><br>
<h3 id="56-project_text">5.6 project_text()<a hidden class="anchor" aria-hidden="true" href="#56-project_text">#</a></h3>
<p>åœ¨å‘é‡ç©ºé—´ä¸­ï¼Œè®¡ç®—æ–‡æœ¬åœ¨æ¦‚å¿µè½´å‘é‡ä¸Šçš„æŠ•å½±å€¼ã€‚</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">ct</span><span class="o">.</span><span class="n">project_text</span><span class="p">(</span><span class="n">wv</span><span class="p">,</span> <span class="n">text</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">lang</span><span class="o">=</span><span class="s1">&#39;chinese&#39;</span><span class="p">,</span> <span class="n">cosine</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</code></pre></div><ul>
<li><strong>wv</strong>: è¯­è¨€æ¨¡å‹çš„KeyedVectors</li>
<li><strong>text</strong>: æ–‡æœ¬å­—ç¬¦ä¸²</li>
<li><strong>lang</strong>:  è¯­è¨€,æœ‰chineseå’Œenglishä¸¤ç§; é»˜è®¤&quot;chinese&quot;</li>
<li><strong>axis</strong>:  æ¦‚å¿µå‘é‡</li>
<li><strong>cosine</strong>: æŠ•å½±å€¼æ˜¯å¦ä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦ï¼Œ é»˜è®¤ä¸ºFalseï¼Œè¿”å›textåœ¨axisä¸Šçš„æŠ•å½±å€¼ï¼› Trueæ—¶ï¼Œè¿”å›textä¸axisçš„ä½™å¼¦ç›¸ä¼¼åº¦ã€‚</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>

<span class="c1"># 1. è¯»å–è¯åµŒå…¥æ¨¡å‹æ–‡ä»¶</span>
<span class="n">embeddings_model</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">load_w2v</span><span class="p">(</span><span class="s1">&#39;cntext2xè®­ç»ƒå¾—åˆ°çš„æ¨¡å‹æ–‡ä»¶è·¯å¾„&#39;</span><span class="p">)</span>
<span class="c1">#dm_w2v = ct.load_w2v(&#39;douban-movie-1000w-Word2Vec.200.15.bin&#39;)</span>

<span class="c1"># 2. å®šä¹‰æƒ…ç»ªæ­£è´Ÿè¯è¯­ï¼Œç¡®å®šæƒ…ç»ªæ¦‚å¿µè½´å‘é‡sentiment_axis</span>
<span class="n">sentiment_pos</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;å¿«ä¹&#39;</span><span class="p">,</span> <span class="s1">&#39;å¹¸ç¦&#39;</span><span class="p">,</span> <span class="s1">&#39;å–œæ‚¦&#39;</span><span class="p">,</span> <span class="s1">&#39;æ»¡è¶³&#39;</span><span class="p">,</span> <span class="s1">&#39;æ¬£æ…°&#39;</span><span class="p">,</span> <span class="s1">&#39;æ¿€åŠ¨&#39;</span><span class="p">,</span> <span class="s1">&#39;å…´å¥‹&#39;</span><span class="p">,</span> <span class="s1">&#39;æ„Ÿæ©&#39;</span><span class="p">,</span> <span class="s1">&#39;çƒ­çˆ±&#39;</span><span class="p">,</span> <span class="s1">&#39;èµç¾&#39;</span><span class="p">]</span>
<span class="n">sentiment_neg</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;ç—›è‹¦&#39;</span><span class="p">,</span> <span class="s1">&#39;æ‚²ä¼¤&#39;</span><span class="p">,</span> <span class="s1">&#39;éš¾è¿‡&#39;</span><span class="p">,</span> <span class="s1">&#39;å¤±æœ›&#39;</span><span class="p">,</span> <span class="s1">&#39;æ„¤æ€’&#39;</span><span class="p">,</span> <span class="s1">&#39;æ€¨æ¨&#39;</span><span class="p">,</span> <span class="s1">&#39;ç»æœ›&#39;</span><span class="p">,</span> <span class="s1">&#39;ææƒ§&#39;</span><span class="p">,</span> <span class="s1">&#39;ç„¦è™‘&#39;</span><span class="p">,</span> <span class="s1">&#39;å‹æŠ‘&#39;</span><span class="p">]</span>
<span class="n">sentiment_axis</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">generate_concept_axis</span><span class="p">(</span><span class="n">wv</span> <span class="o">=</span> <span class="n">embeddings_model</span><span class="p">,</span> 
                                         <span class="n">poswords</span><span class="o">=</span><span class="n">sentiment_pos</span><span class="p">,</span>
                                         <span class="n">negwords</span><span class="o">=</span><span class="n">sentiment_neg</span><span class="p">)</span>
<span class="c1"># 3. åˆ›å»ºå®éªŒæ–‡æœ¬ï¼ˆä»æ­£é¢åˆ°è´Ÿé¢ï¼‰</span>
<span class="n">texts</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&#34;ä»Šå¤©é˜³å…‰æ˜åªšï¼Œæˆ‘å’Œå®¶äººä¸€èµ·å‡ºæ¸¸ï¼Œæ„Ÿåˆ°æ— æ¯”å¹¸ç¦å’Œå¿«ä¹ã€‚&#34;</span><span class="p">,</span>
    <span class="s2">&#34;å·¥ä½œæœ‰äº†æ–°è¿›å±•ï¼Œå¾—åˆ°äº†é¢†å¯¼çš„è¡¨æ‰¬ï¼Œå†…å¿ƒå……æ»¡æˆå°±æ„Ÿã€‚&#34;</span><span class="p">,</span>
    <span class="s2">&#34;è™½ç„¶é‡åˆ°äº†å°æŒ«æŠ˜ï¼Œä½†æˆ‘ä¾ç„¶ä¿æŒä¹è§‚ï¼Œç›¸ä¿¡æ˜å¤©ä¼šæ›´å¥½ã€‚&#34;</span><span class="p">,</span>
    <span class="s2">&#34;ç”Ÿæ´»å¹³æ·¡ï¼Œæ²¡ä»€ä¹ˆç‰¹åˆ«çš„äº‹å‘ç”Ÿï¼Œå¿ƒæƒ…ä¸€èˆ¬ã€‚&#34;</span><span class="p">,</span>
    <span class="s2">&#34;æœ€è¿‘å‹åŠ›æœ‰ç‚¹å¤§ï¼Œç¡çœ ä¸å¥½ï¼Œæ„Ÿè§‰æœ‰ç‚¹ç„¦è™‘å’Œç–²æƒ«ã€‚&#34;</span><span class="p">,</span>
    <span class="s2">&#34;é¡¹ç›®å¤±è´¥äº†ï¼Œè¿˜è¢«é¢†å¯¼æ‰¹è¯„ï¼Œå¿ƒé‡Œéå¸¸éš¾è¿‡å’Œå¤±æœ›ã€‚&#34;</span><span class="p">,</span>
    <span class="s2">&#34;äº²äººç¦»ä¸–ï¼Œæˆ‘æ„Ÿåˆ°æåº¦æ‚²ä¼¤å’Œç—›è‹¦ï¼Œä¸–ç•Œä»¿ä½›å¤±å»äº†é¢œè‰²ã€‚&#34;</span>
<span class="p">]</span>


<span class="c1"># 4. è®¡ç®—æ¯æ¡æ–‡æœ¬åœ¨æƒ…ç»ªè½´ä¸Šçš„æŠ•å½±</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&#34;æ–‡æœ¬æƒ…ç»ªæŠ•å½±åˆ†æï¼ˆè¶Šå¤§è¶Šæ­£é¢ï¼‰ï¼š</span><span class="se">\n</span><span class="s2">&#34;</span><span class="p">)</span>
<span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">text</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">texts</span><span class="p">):</span>
    <span class="c1"># ä½¿ç”¨æŠ•å½±å‡½æ•°ï¼ˆè¿”å›åœ¨ axis æ–¹å‘ä¸Šçš„æŠ•å½±å€¼ï¼‰</span>
    <span class="c1">#project_text(wv, text, axis, lang=&#39;chinese&#39;, cosine=False)</span>
    <span class="n">proj_value</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">project_text</span><span class="p">(</span><span class="n">wv</span><span class="o">=</span><span class="n">embeddings_model</span><span class="p">,</span> 
                                 <span class="n">text</span><span class="o">=</span><span class="n">text</span><span class="p">,</span> 
                                 <span class="n">axis</span><span class="o">=</span><span class="n">sentiment_axis</span><span class="p">,</span> 
                                 <span class="n">lang</span><span class="o">=</span><span class="s1">&#39;chinese&#39;</span><span class="p">)</span>
    <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">proj_value</span><span class="p">,</span> <span class="n">text</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;[</span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">] æŠ•å½±å€¼: </span><span class="si">{</span><span class="n">proj_value</span><span class="si">:</span><span class="s2">+.4f</span><span class="si">}</span><span class="s2"> | </span><span class="si">{</span><span class="n">text</span><span class="si">}</span><span class="se">\n</span><span class="s2">&#34;</span><span class="p">)</span>

<span class="c1"># 5. æŒ‰æŠ•å½±å€¼æ’åºï¼ŒæŸ¥çœ‹æƒ…ç»ªå¼ºåº¦æ’åº</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&#34;</span><span class="se">\n</span><span class="s2">&#34;</span> <span class="o">+</span> <span class="s2">&#34;=&#34;</span><span class="o">*</span><span class="mi">60</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&#34;æŒ‰æƒ…ç»ªæ­£é¢æ€§æ’åºï¼ˆä»é«˜åˆ°ä½ï¼‰ï¼š&#34;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&#34;=&#34;</span><span class="o">*</span><span class="mi">60</span><span class="p">)</span>
<span class="k">for</span> <span class="n">value</span><span class="p">,</span> <span class="n">text</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">results</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;</span><span class="si">{</span><span class="n">value</span><span class="si">:</span><span class="s2">+.4f</span><span class="si">}</span><span class="s2"> â†’ </span><span class="si">{</span><span class="n">text</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">[1] æŠ•å½±å€¼: +0.8213 | ä»Šå¤©é˜³å…‰æ˜åªšï¼Œæˆ‘å’Œå®¶äººä¸€èµ·å‡ºæ¸¸ï¼Œæ„Ÿåˆ°æ— æ¯”å¹¸ç¦å’Œå¿«ä¹ã€‚
[2] æŠ•å½±å€¼: +0.5641 | å·¥ä½œæœ‰äº†æ–°è¿›å±•ï¼Œå¾—åˆ°äº†é¢†å¯¼çš„è¡¨æ‰¬ï¼Œå†…å¿ƒå……æ»¡æˆå°±æ„Ÿã€‚
[3] æŠ•å½±å€¼: +0.1205 | è™½ç„¶é‡åˆ°äº†å°æŒ«æŠ˜ï¼Œä½†æˆ‘ä¾ç„¶ä¿æŒä¹è§‚ï¼Œç›¸ä¿¡æ˜å¤©ä¼šæ›´å¥½ã€‚
[4] æŠ•å½±å€¼: -0.0321 | ç”Ÿæ´»å¹³æ·¡ï¼Œæ²¡ä»€ä¹ˆç‰¹åˆ«çš„äº‹å‘ç”Ÿï¼Œå¿ƒæƒ…ä¸€èˆ¬ã€‚
[5] æŠ•å½±å€¼: -0.3178 | æœ€è¿‘å‹åŠ›æœ‰ç‚¹å¤§ï¼Œç¡çœ ä¸å¥½ï¼Œæ„Ÿè§‰æœ‰ç‚¹ç„¦è™‘å’Œç–²æƒ«ã€‚
[6] æŠ•å½±å€¼: -0.6124 | é¡¹ç›®å¤±è´¥äº†ï¼Œè¿˜è¢«é¢†å¯¼æ‰¹è¯„ï¼Œå¿ƒé‡Œéå¸¸éš¾è¿‡å’Œå¤±æœ›ã€‚
[7] æŠ•å½±å€¼: -0.9012 | äº²äººç¦»ä¸–ï¼Œæˆ‘æ„Ÿåˆ°æåº¦æ‚²ä¼¤å’Œç—›è‹¦ï¼Œä¸–ç•Œä»¿ä½›å¤±å»äº†é¢œè‰²ã€‚
</code></pre></div><br>
<h3 id="57-divergent_association_task">5.7 divergent_association_task()<a hidden class="anchor" aria-hidden="true" href="#57-divergent_association_task">#</a></h3>
<p><a href="https://textdata.cn/blog/2022-11-14-pnas_naming_unrelated_words_predicts_creativity/">PNAS | ä½¿ç”¨è¯­ä¹‰è·ç¦»æµ‹é‡ä¸€ä¸ªäººçš„åˆ›æ–°åŠ›(å‘æ•£æ€ç»´)å¾—åˆ†</a>ã€‚ä¸€äº›ç†è®ºè®¤ä¸ºï¼Œæœ‰ åˆ›é€ åŠ› çš„äººèƒ½å¤Ÿäº§ç”Ÿæ›´å¤š å‘æ•£æ€§ çš„æƒ³æ³•ã€‚å¦‚æœè¿™æ˜¯æ­£ç¡®çš„ï¼Œç®€å•åœ°è®©è¢«è¯•å†™ N ä¸ªä¸ç›¸å…³çš„å•è¯ï¼Œç„¶åæµ‹é‡è¿™ N ä¸ªè¯çš„è¯­ä¹‰è·ç¦»ï¼Œ ä½œä¸ºå‘æ•£æ€ç»´çš„å®¢è§‚è¡¡é‡æ ‡å‡†ã€‚</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">ct.divergent_association_task(wv, words)
</code></pre></div><ul>
<li><strong>wv</strong> æ¨¡å‹æ•°æ®ï¼Œ æ•°æ®ç±»å‹ä¸º gensim.models.keyedvectors.KeyedVectorsã€‚</li>
<li><strong>words</strong>è¯è¯­åˆ—è¡¨</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">low_words = [&#34;arm&#34;, &#34;eyes&#34;, &#34;feet&#34;, &#34;hand&#34;, &#34;head&#34;, &#34;leg&#34;, &#34;body&#34;]
average_words = [&#34;bag&#34;, &#34;bee&#34;, &#34;burger&#34;, &#34;feast&#34;, &#34;office&#34;, &#34;shoes&#34;, &#34;tree&#34;]
high_words = [&#34;hippo&#34;, &#34;jumper&#34;, &#34;machinery&#34;, &#34;prickle&#34;, &#34;tickets&#34;, &#34;tomato&#34;, &#34;violin&#34;]

# å¯¼å…¥æ¨¡å‹ï¼Œå¾—åˆ°wvã€‚
# wv = ct.load_w2v(&#39;wikiçš„word2vecæ¨¡å‹æ–‡ä»¶è·¯å¾„&#39;)


print(ct.divergent_association_task(wv, low_words)) # 50
print(ct.divergent_association_task(wv, average_words)) # 78
print(ct.divergent_association_task(wv, high_words)) # 95
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">50
78
95
</code></pre></div><br>
<h3 id="58-discursive_diversity_score">5.8 discursive_diversity_score()<a hidden class="anchor" aria-hidden="true" href="#58-discursive_diversity_score">#</a></h3>
<p><a href="https://textdata.cn/blog/2023-11-02-measure-cognitive-diversity-through-language-discursive-diversity/">MS2022 | ä½¿ç”¨è¯­è¨€å·®å¼‚æ€§æµ‹é‡å›¢é˜Ÿè®¤çŸ¥å·®å¼‚æ€§</a></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">ct.discursive_diversity_score(wv, words)
</code></pre></div><ul>
<li><strong><em>wv</em></strong> æ¨¡å‹æ•°æ®ï¼Œ æ•°æ®ç±»å‹ä¸º gensim.models.keyedvectors.KeyedVectorsã€‚</li>
<li>**<em>words</em>**è¯è¯­åˆ—è¡¨</li>
<li>è¿”å›ä¸€ä¸ªæ•°å€¼</li>
</ul>
<p><img loading="lazy" src="img/23-low-and-high-examples-of-discursive-diversity.jpeg" alt=""  />
</p>
<p>é«˜ç»©æ•ˆå›¢é˜Ÿæ˜¯é‚£äº›å…·æœ‰è°ƒèŠ‚å…±äº«è®¤çŸ¥ä»¥é€‚åº”ä¸æ–­å˜åŒ–çš„ä»»åŠ¡è¦æ±‚çš„é›†ä½“èƒ½åŠ›çš„å›¢é˜Ÿï¼šåœ¨è¿›è¡Œæ„æ€ä»»åŠ¡æ—¶ï¼Œå®ƒä»¬è¡¨ç°å‡ºæ›´é«˜çš„è¯è¯­å¤šæ ·æ€§ï¼Œåœ¨æ‰§è¡Œåè°ƒä»»åŠ¡æ—¶ï¼Œè¡¨ç°å‡ºè¾ƒä½çš„è¯è¯­å¤šæ ·æ€§ã€‚</p>
<br>
<h3 id="58-procrustes_align">5.8 procrustes_align()<a hidden class="anchor" aria-hidden="true" href="#58-procrustes_align">#</a></h3>
<p>è¯¥å‡½æ•°ä¸»è¦ç”¨äºåæ˜ åŒä¸€ç ”ç©¶å¯¹è±¡éšç€æ—¶é—´æ¨è¿›çš„ç¤¾ä¼šæ–‡åŒ–å˜è¿ï¼Œæˆ–è€…åŒä¸€æ—¶é—´èŒƒå›´å†…ä¸¤ä¸ªè¢«ç ”ç©¶ä¸»ä½“é—´çš„å·®å¼‚ã€‚</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">ct.procrustes_align(base_wv, other_wv, words=None)
</code></pre></div><ul>
<li>base_wv (gensim.models.keyedvectors.KeyedVectors): åŸºå‡†è¯­è¨€æ¨¡å‹</li>
<li>other_wv (gensim.models.keyedvectors.KeyedVectors): å…¶ä»–è¯­è¨€æ¨¡å‹</li>
<li>words (list, optional): æ˜¯å¦æ ¹æ®è¯å…¸ words å¯¹æ¨¡å‹è¿›è¡Œå¯¹é½ï¼Œ å¯¹é½ç»“æŸåçš„æ¨¡å‹ä¸­å«æœ‰çš„è¯ä¸ä¼šè¶…å‡º words çš„èŒƒå›´ï¼› é»˜è®¤ None.</li>
</ul>
<p>ç”±äºä¸åŒè¯­æ–™è®­ç»ƒçš„ Word2Vec æ¨¡å‹æ— æ³•ç›´æ¥æ¯”è¾ƒï¼Œ éœ€è¦å…ˆé€‰å®šä¸€ä¸ªåŸºå‡†æ¨¡å‹ <strong><em>base_embed</em></strong>ï¼Œ ä¹‹åæ ¹æ® <strong><em>base_embed</em></strong> å¯¹å…¶ä»–æ¨¡å‹ <strong><em>other_embed</em></strong> è¿›è¡Œè°ƒæ•´ï¼Œè°ƒæ•´åçš„æ¨¡å‹å°±å¯ä»¥ä½¿ç”¨å‰é¢çš„è¯­ä¹‰è·ç¦»å‡½æ•°æˆ–è€…è¯­ä¹‰æŠ•å½±å‡½æ•°ã€‚ è¿™ä¸€è¿‡ç¨‹ç”¨åˆ°çš„ç®—æ³•å«åš procrustes æ­£äº¤ç®—æ³•ã€‚</p>
<p>è¿™é‡Œæ¨èä¸€ç¯‡ <a href="https://textdata.cn/blog/2023-12-28-visualize-the-culture-change-using-people-daily-dataset/">å¯è§†åŒ– | äººæ°‘æ—¥æŠ¥è¯­æ–™åæ˜ ä¸ƒåå¹´æ–‡åŒ–æ¼”å˜</a></p>
<p><br><br></p>
<h2 id="å…­llm-æ¨¡å—">å…­ã€LLM æ¨¡å—<a hidden class="anchor" aria-hidden="true" href="#å…­llm-æ¨¡å—">#</a></h2>
<p>ç›®å‰å¤§æ¨¡å‹æœ¬åœ°åŒ–ä½¿ç”¨è¶Šæ¥è¶Šæ–¹ä¾¿ï¼Œ</p>
<table>
<thead>
<tr>
<th>æ¨¡å—</th>
<th>å‡½æ•°(ç±»)</th>
<th>åŠŸèƒ½</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong><em>LLM</em></strong></td>
<td><strong>ct.llm(text, prompt, output_format, task, backend, base_url, api_key, model_name, temperature)</strong></td>
<td>è°ƒç”¨å¤§æ¨¡å‹æ‰§è¡Œç»“æ„åŒ–æ–‡æœ¬åˆ†æä»»åŠ¡ï¼ˆå¦‚æƒ…æ„Ÿåˆ†æã€å…³é”®è¯æå–ã€åˆ†ç±»ç­‰ï¼‰ã€‚</td>
</tr>
</tbody>
</table>
<h3 id="61-ctllm">6.1 ct.llm()<a hidden class="anchor" aria-hidden="true" href="#61-ctllm">#</a></h3>
<p>ä½¿ç”¨å¤§æ¨¡å‹ï¼ˆæœ¬åœ°æˆ– APIï¼‰è¿›è¡Œæ–‡æœ¬åˆ†æï¼Œä»éç»“æ„åŒ–çš„æ–‡æœ¬æ•°æ®ä¸­è¯†åˆ«æ¨¡å¼ã€æå–å…³é”®ä¿¡æ¯ã€ç†è§£è¯­ä¹‰ï¼Œå¹¶å°†å…¶è½¬åŒ–ä¸ºç»“æ„åŒ–æ•°æ®ä»¥ä¾¿è¿›ä¸€æ­¥åˆ†æå’Œåº”ç”¨ã€‚</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">ct</span><span class="o">.</span><span class="n">llm</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">prompt</span><span class="p">,</span> <span class="n">output_format</span><span class="p">,</span> <span class="n">task</span><span class="p">,</span> <span class="n">backend</span><span class="p">,</span> <span class="n">base_url</span><span class="p">,</span> <span class="n">api_key</span><span class="p">,</span> <span class="n">model_name</span><span class="p">,</span> <span class="n">temperature</span><span class="p">)</span>
</code></pre></div><ul>
<li><strong>text</strong>: å¾…åˆ†æçš„æ–‡æœ¬å†…å®¹</li>
<li><strong>task</strong>: é¢„è®¾ä»»åŠ¡åç§°ï¼Œé»˜è®¤ä¸º &lsquo;sentiment&rsquo;ã€‚</li>
<li><strong>prompt</strong>: è‡ªå®šä¹‰ç³»ç»Ÿæç¤ºè¯­</li>
<li><strong>output_format</strong>: è‡ªå®šä¹‰è¾“å‡ºç»“æ„ï¼Œå¦‚ {&lsquo;label&rsquo;: str, &lsquo;score&rsquo;: float}</li>
<li><strong>backend</strong>: å¿«æ·åç«¯åˆ«åï¼š
- &lsquo;ollama&rsquo; â†’ http://127.0.0.1:11434/v1
- &lsquo;lmstudio&rsquo; æˆ– &lsquo;lms&rsquo; â†’ http://localhost:1234/v1
- None â†’ éœ€é…åˆ base_url ä½¿ç”¨</li>
<li><strong>base_url</strong>: è‡ªå®šä¹‰æ¨¡å‹æœåŠ¡åœ°å€ï¼Œä¼˜å…ˆçº§é«˜äº backend
ç¤ºä¾‹ï¼š
- è¿œç¨‹ï¼šhttps://dashscope.aliyuncs.com/compatible-mode/v1
- å†…ç½‘ï¼šhttp://192.168.1.10:11434/v1
- æœ¬åœ°ï¼šhttp://localhost:1234/v1</li>
<li><strong>api_key</strong>: API å¯†é’¥ï¼Œè¿œç¨‹æœåŠ¡å¿…å¡«ï¼Œæœ¬åœ°é€šå¸¸ä¸º &ldquo;EMPTY&rdquo;</li>
<li><strong>model_name</strong>: æ¨¡å‹åç§°ï¼ˆéœ€æœåŠ¡ç«¯å·²åŠ è½½ï¼‰</li>
<li><strong>temperature</strong>: ç”Ÿæˆæ¸©åº¦ï¼Œ0 è¡¨ç¤ºç¡®å®šæ€§è¾“å‡º</li>
</ul>
<br>
<p><strong>å®éªŒæ•°æ®ä¸ºå¤–å–è¯„è®ºï¼Œ ä»Šå¤©å’±ä»¬åšä¸ªæœ‰éš¾åº¦çš„æ–‡æœ¬åˆ†æä»»åŠ¡ï¼Œä»ä¸åŒç»´åº¦(å‘³é“ã€é€Ÿåº¦ã€æœåŠ¡)å¯¹å¤–å–è¯„è®ºè¿›è¡Œæ‰“åˆ†(-1.0~1.0)</strong>ã€‚</p>
<p><img loading="lazy" src="img/28-llm-analysis.png" alt=""  />
<br></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>

<span class="n">PROMPT</span> <span class="o">=</span> <span class="s1">&#39;ä»å£å‘³tasteã€é€Ÿåº¦speedã€æœåŠ¡serviceä¸‰ä¸ªç»´åº¦ï¼Œ å¯¹å¤–å–è¯„è®ºå†…å®¹è¿›è¡Œæ–‡æœ¬åˆ†æï¼Œ åˆ†åˆ«è¿”å›ä¸åŒç»´åº¦çš„åˆ†å€¼(åˆ†å€¼èŒƒå›´-1.0 ~ 1.0)&#39;</span>
<span class="n">BASE_URL</span> <span class="o">=</span> <span class="s1">&#39;https://dashscope.aliyuncs.com/compatible-mode/v1&#39;</span>
<span class="n">API_KEY</span> <span class="o">=</span> <span class="s1">&#39;ä½ çš„API-KEY&#39;</span>
<span class="n">MODEL_NAME</span> <span class="o">=</span> <span class="s1">&#39;qwen-max&#39;</span>

<span class="c1">#å‘³é“ã€é€Ÿåº¦ã€æœåŠ¡</span>
<span class="n">OUTPUT_FORMAT</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;taste&#39;</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="s1">&#39;speed&#39;</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="s1">&#39;service&#39;</span><span class="p">:</span> <span class="nb">float</span><span class="p">}</span>

<span class="n">COMMENT_CONTENT</span> <span class="o">=</span> <span class="s1">&#39;å¤ªéš¾åƒäº†&#39;</span>

<span class="c1"># ä½¿ç”¨</span>
<span class="c1"># result = ct.llm(text=COMMENT_CONTENT,</span>
<span class="c1"># æˆ–</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">llm</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="n">COMMENT_CONTENT</span><span class="p">,</span>
                <span class="n">prompt</span><span class="o">=</span><span class="n">PROMPT</span><span class="p">,</span>
                <span class="n">base_url</span><span class="o">=</span><span class="n">BASE_URL</span><span class="p">,</span>
                <span class="n">api_key</span><span class="o">=</span><span class="n">API_KEY</span><span class="p">,</span>
                <span class="n">model_name</span><span class="o">=</span><span class="n">MODEL_NAME</span><span class="p">,</span>
                <span class="n">temperature</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                <span class="n">output_format</span><span class="o">=</span><span class="n">OUTPUT_FORMAT</span><span class="p">)</span>

<span class="n">result</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">{&#39;taste&#39;: -1.0, &#39;speed&#39;: 0.0, &#39;service&#39;: 0.0}
</code></pre></div><br>
<p>æ‰¹é‡è¿ç®—</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>


<span class="c1"># æ„é€ å®éªŒæ•°æ®</span>
<span class="n">data</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;é€Ÿåº¦éå¸¸å¿«ï¼Œå£å‘³éå¸¸å¥½ï¼Œ æœåŠ¡éå¸¸æ£’ï¼&#39;</span><span class="p">,</span>
        <span class="s1">&#39;é€é¤æ—¶é—´è¿˜æ˜¯æ¯”è¾ƒä¹…&#39;</span><span class="p">,</span>
        <span class="s1">&#39;é€å•å¾ˆå¿«ï¼Œèœä¹Ÿä¸é”™èµ&#39;</span><span class="p">,</span>
        <span class="s1">&#39;å¤ªéš¾åƒäº†&#39;</span><span class="p">]</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;comment&#39;</span><span class="p">])</span>


<span class="c1"># åˆ†æå‡½æ•°</span>
<span class="k">def</span> <span class="nf">llm_analysis</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">llm</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="n">text</span><span class="p">,</span>
                    <span class="n">prompt</span><span class="o">=</span> <span class="s1">&#39;ä»å£å‘³tasteã€é€Ÿåº¦speedã€æœåŠ¡serviceä¸‰ä¸ªç»´åº¦ï¼Œ å¯¹å¤–å–è¯„è®ºå†…å®¹è¿›è¡Œæ–‡æœ¬åˆ†æï¼Œ åˆ†åˆ«è¿”å›ä¸åŒç»´åº¦çš„åˆ†å€¼(åˆ†å€¼èŒƒå›´-1.0 ~ 1.0)&#39;</span><span class="p">,</span>
                    <span class="n">base_url</span><span class="o">=</span><span class="s1">&#39;https://dashscope.aliyuncs.com/compatible-mode/v1&#39;</span><span class="p">,</span>
                    <span class="n">api_key</span><span class="o">=</span><span class="s1">&#39;ä½ çš„API-KEY&#39;</span><span class="p">,</span>
                    <span class="n">model_name</span><span class="o">=</span><span class="s1">&#39;qwen-max&#39;</span><span class="p">,</span>
                    <span class="n">output_format</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;taste&#39;</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="s1">&#39;speed&#39;</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="s1">&#39;service&#39;</span><span class="p">:</span> <span class="nb">float</span><span class="p">}</span>
                               <span class="p">)</span>
    <span class="k">return</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>


<span class="c1"># æ‰¹é‡è¿ç®—</span>
<span class="n">df2</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;comment&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">llm_analysis</span><span class="p">)</span>
<span class="n">res_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">df</span><span class="p">,</span> <span class="n">df2</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="c1"># ä¿å­˜åˆ†æç»“æœ</span>
<span class="n">res_df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;result.csv&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">res_df</span>
</code></pre></div><p><img loading="lazy" src="img/28-llm-analysis.png" alt=""  />
</p>
<br>
<p>LLM æ›´å¤šè¯¦ç»†å†…å®¹ï¼Œè¯·é˜…è¯» <a href="https://textdata.cn/blog/2025-02-14-using-online-large-model-api-to-transform-text-data-into-structured-data/"><strong>æ•™ç¨‹ | ä½¿ç”¨åœ¨çº¿å¤§æ¨¡å‹å°†æ–‡æœ¬æ•°æ®è½¬åŒ–ä¸ºç»“æ„åŒ–æ•°æ®</strong></a></p>
<br>
<h3 id="62-å†…ç½®prompt">6.2 å†…ç½®prompt<a hidden class="anchor" aria-hidden="true" href="#62-å†…ç½®prompt">#</a></h3>
<p>cntext</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">ct</span><span class="o">.</span><span class="n">llm</span><span class="o">.</span><span class="n">tasks_list</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">[&#39;sentiment&#39;,
 &#39;emotion&#39;,
 &#39;classify&#39;,
 &#39;intent&#39;,
 &#39;keywords&#39;,
 &#39;entities&#39;,
 &#39;summarize&#39;,
 &#39;rewrite&#39;,
 &#39;quality&#39;,
 &#39;similarity&#39;]
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1"># è·å–sentimentæ¨¡æ¿</span>
<span class="n">ct</span><span class="o">.</span><span class="n">llm</span><span class="o">.</span><span class="n">tasks_get</span><span class="p">(</span><span class="s1">&#39;sentiment&#39;</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">{&#39;prompt&#39;: &#39;åˆ†æè¯„è®ºçš„æƒ…æ„Ÿå€¾å‘ï¼šè¿”å›æƒ…æ„Ÿç±»åˆ« labelï¼ˆpos è¡¨ç¤ºæ­£é¢ï¼Œneg è¡¨ç¤ºè´Ÿé¢ï¼Œneutral è¡¨ç¤ºä¸­æ€§ï¼‰å’Œæƒ…æ„Ÿåˆ†å€¼ scoreï¼ˆå–å€¼èŒƒå›´ -1~1ï¼Œè´Ÿæ•°ä¸ºè´Ÿé¢ï¼‰&#39;,
 &#39;output_format&#39;: {&#39;label&#39;: &#39;str&#39;, &#39;score&#39;: &#39;float&#39;}}
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1"># ä½¿ç”¨sentimentæç¤ºè¯æ¨¡æ¿ã€‚</span>
<span class="c1"># å¯ç”¨OllamaæœåŠ¡ï¼Œè°ƒç”¨qwen2.5:7bæ¨¡å‹</span>
<span class="n">ct</span><span class="o">.</span><span class="n">llm</span><span class="p">(</span><span class="s2">&#34;æœåŠ¡å¾ˆæ£’ï¼&#34;</span><span class="p">,</span> <span class="n">task</span><span class="o">=</span><span class="s2">&#34;sentiment&#34;</span><span class="p">,</span> <span class="n">backend</span><span class="o">=</span><span class="s2">&#34;ollama&#34;</span><span class="p">,</span>  <span class="n">model_name</span><span class="o">=</span><span class="s2">&#34;qwen2.5:7b&#34;</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">[cntext2x] âœ… è¿æ¥æ¨¡å‹æœåŠ¡: http://127.0.0.1:11434/v1
{&#39;label&#39;: &#39;pos&#39;, &#39;score&#39;: 0.8}
</code></pre></div><p><br><br></p>
<h2 id="ä½¿ç”¨å£°æ˜">ä½¿ç”¨å£°æ˜<a hidden class="anchor" aria-hidden="true" href="#ä½¿ç”¨å£°æ˜">#</a></h2>
<p>å¦‚åœ¨ç ”ç©¶æˆ–é¡¹ç›®ä¸­ä½¿ç”¨åˆ° <strong>cntext</strong> ï¼Œè¯·ç®€è¦ä»‹ç» cntext ï¼Œå¹¶é™„åŠ ä½¿ç”¨å£°æ˜å‡ºå¤„ã€‚</p>
<h3 id="apalike">apalike<a hidden class="anchor" aria-hidden="true" href="#apalike">#</a></h3>
<p>Deng, X., &amp; Nan, P. (2022). <strong>cntext: a Python tool for text mining</strong> [Computer software]. Zenodo. <a href="https://doi.org/10.5281/zenodo.7063523">https://doi.org/10.5281/zenodo.7063523</a></p>
<p>Source Code URL: <a href="https://github.com/hiDaDeng/cntext">https://github.com/hiDaDeng/cntext</a></p>
<br>
<h3 id="bibtex">bibtex<a hidden class="anchor" aria-hidden="true" href="#bibtex">#</a></h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">@misc{deng2022cntext,
  author       = {Deng, X. and Nan, P.},
  title        = {cntext: a Python tool for text mining},
  year         = {2022},
  publisher    = {Zenodo},
  doi          = {10.5281/zenodo.7063523},
  url          = {https://doi.org/10.5281/zenodo.7063523},
  howpublished = {[Computer software]},
  note         = {Source Code URL: \url{https://github.com/hiDaDeng/cntext}}
}
</code></pre></div><br>
<h3 id="endnote">endnote<a hidden class="anchor" aria-hidden="true" href="#endnote">#</a></h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">%0 Generic
%A Deng, X.
%A Nan, P.
%T cntext: a Python tool for text mining
%Y [Computer software]
%D 2022
%I Zenodo
%R 10.5281/zenodo.7063523
%U https://doi.org/10.5281/zenodo.7063523
%Z Source Code URL: https://github.com/hiDaDeng/cntext
%@
</code></pre></div>

  </div>


  <br>

  <div style="text-align: center;">
    <figure >
        <a href="https://textdata.cn/blog/management_python_course/">
            <img src="/images/bg/management_data_mining_with_python_course2.png" width="100%" />
        </a>
        <figcaption><small><i>ç‚¹å‡»äº†è§£è¯¾ç¨‹è¯¦æƒ…</i></small></figcaption>
    </figure>
  </div>

  <br>


  <div style="margin-top:2em;padding:0 0.5em;font-size:.875rem">
    <hr>
    <div style="padding-bottom:1em;">
        <p>æœ¬æ–‡ä½œè€…: å¤§é‚“
        <p>æœ¬æ–‡æ ‡é¢˜: æ¨è | æ–‡æœ¬åˆ†æåº“ cntext ä½¿ç”¨æ‰‹å†Œ
        <p>æœ¬æ–‡é“¾æ¥: https://textdata.cn/blog/2024-04-27-cntext2x-usage-tutorial/ 
        <p>ç‰ˆæƒå£°æ˜: <a href="https://creativecommons.org/licenses/by-nc/4.0/" target="_blank">ç½²å-éå•†ä¸šæ€§ä½¿ç”¨-ç›¸åŒæ–¹å¼å…±äº« 4.0 å›½é™…</a></p>
    </div>
    <hr>
  </div>






  <footer class="post-footer">
      <ul class="post-tags">
        <b>Tags:  &nbsp;</b>
        <li><a href="/tags/%E6%96%87%E6%9C%AC%E5%88%86%E6%9E%90/" target='_blank'>æ–‡æœ¬åˆ†æ</a></li>
        <li><a href="/tags/%E5%AD%A6%E6%9C%AF%E5%BA%94%E7%94%A8/" target='_blank'>å­¦æœ¯åº”ç”¨</a></li>
        <li><a href="/tags/%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93/" target='_blank'>ç¬¬ä¸‰æ–¹åº“</a></li>
      </ul>


<div class="share-buttons">
    <a target="_blank" rel="noopener noreferrer" aria-label="share æ¨è | æ–‡æœ¬åˆ†æåº“ cntext ä½¿ç”¨æ‰‹å†Œ on twitter"
        href="https://twitter.com/intent/tweet/?text=%e6%8e%a8%e8%8d%90%20%7c%20%e6%96%87%e6%9c%ac%e5%88%86%e6%9e%90%e5%ba%93%20cntext%20%e4%bd%bf%e7%94%a8%e6%89%8b%e5%86%8c&amp;url=%2fblog%2f2024-04-27-cntext2x-usage-tutorial%2f&amp;hashtags=%e6%96%87%e6%9c%ac%e5%88%86%e6%9e%90%2c%e5%ad%a6%e6%9c%af%e5%ba%94%e7%94%a8%2c%e7%ac%ac%e4%b8%89%e6%96%b9%e5%ba%93">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-253.927,424.544c135.939,0 210.268,-112.643 210.268,-210.268c0,-3.218 0,-6.437 -0.153,-9.502c14.406,-10.421 26.973,-23.448 36.935,-38.314c-13.18,5.824 -27.433,9.809 -42.452,11.648c15.326,-9.196 26.973,-23.602 32.49,-40.92c-14.252,8.429 -30.038,14.56 -46.896,17.931c-13.487,-14.406 -32.644,-23.295 -53.946,-23.295c-40.767,0 -73.87,33.104 -73.87,73.87c0,5.824 0.613,11.494 1.992,16.858c-61.456,-3.065 -115.862,-32.49 -152.337,-77.241c-6.284,10.881 -9.962,23.601 -9.962,37.088c0,25.594 13.027,48.276 32.95,61.456c-12.107,-0.307 -23.448,-3.678 -33.41,-9.196l0,0.92c0,35.862 25.441,65.594 59.311,72.49c-6.13,1.686 -12.72,2.606 -19.464,2.606c-4.751,0 -9.348,-0.46 -13.946,-1.38c9.349,29.426 36.628,50.728 68.965,51.341c-25.287,19.771 -57.164,31.571 -91.8,31.571c-5.977,0 -11.801,-0.306 -17.625,-1.073c32.337,21.15 71.264,33.41 112.95,33.41Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share æ¨è | æ–‡æœ¬åˆ†æåº“ cntext ä½¿ç”¨æ‰‹å†Œ on linkedin"
        href="https://www.linkedin.com/shareArticle?mini=true&amp;url=%2fblog%2f2024-04-27-cntext2x-usage-tutorial%2f&amp;title=%e6%8e%a8%e8%8d%90%20%7c%20%e6%96%87%e6%9c%ac%e5%88%86%e6%9e%90%e5%ba%93%20cntext%20%e4%bd%bf%e7%94%a8%e6%89%8b%e5%86%8c&amp;summary=%e6%8e%a8%e8%8d%90%20%7c%20%e6%96%87%e6%9c%ac%e5%88%86%e6%9e%90%e5%ba%93%20cntext%20%e4%bd%bf%e7%94%a8%e6%89%8b%e5%86%8c&amp;source=%2fblog%2f2024-04-27-cntext2x-usage-tutorial%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share æ¨è | æ–‡æœ¬åˆ†æåº“ cntext ä½¿ç”¨æ‰‹å†Œ on reddit"
        href="https://reddit.com/submit?url=%2fblog%2f2024-04-27-cntext2x-usage-tutorial%2f&title=%e6%8e%a8%e8%8d%90%20%7c%20%e6%96%87%e6%9c%ac%e5%88%86%e6%9e%90%e5%ba%93%20cntext%20%e4%bd%bf%e7%94%a8%e6%89%8b%e5%86%8c">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share æ¨è | æ–‡æœ¬åˆ†æåº“ cntext ä½¿ç”¨æ‰‹å†Œ on facebook"
        href="https://facebook.com/sharer/sharer.php?u=%2fblog%2f2024-04-27-cntext2x-usage-tutorial%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share æ¨è | æ–‡æœ¬åˆ†æåº“ cntext ä½¿ç”¨æ‰‹å†Œ on whatsapp"
        href="https://api.whatsapp.com/send?text=%e6%8e%a8%e8%8d%90%20%7c%20%e6%96%87%e6%9c%ac%e5%88%86%e6%9e%90%e5%ba%93%20cntext%20%e4%bd%bf%e7%94%a8%e6%89%8b%e5%86%8c%20-%20%2fblog%2f2024-04-27-cntext2x-usage-tutorial%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share æ¨è | æ–‡æœ¬åˆ†æåº“ cntext ä½¿ç”¨æ‰‹å†Œ on telegram"
        href="https://telegram.me/share/url?text=%e6%8e%a8%e8%8d%90%20%7c%20%e6%96%87%e6%9c%ac%e5%88%86%e6%9e%90%e5%ba%93%20cntext%20%e4%bd%bf%e7%94%a8%e6%89%8b%e5%86%8c&amp;url=%2fblog%2f2024-04-27-cntext2x-usage-tutorial%2f">
        <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28">
            <path
                d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
        </svg>
    </a>
    
</div>




  </footer><script src="https://utteranc.es/client.js"
        repo="hiDaDeng/hidadeng.github.io"
        issue-term="pathname"
        theme="preferred-color-scheme"
        crossorigin="anonymous"
        async>
</script>

  
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2025 <a href="/">å¤§é‚“å’Œä»–çš„PYTHON</a></span>
</footer>
<a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerText = 'Copy';

        function copyingDone() {
            copybutton.innerText = 'Copied!';
            setTimeout(() => {
                copybutton.innerText = 'Copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>


    
    
</body>

</html>
