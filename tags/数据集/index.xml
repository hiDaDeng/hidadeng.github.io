<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>数据集 on 大邓和他的PYTHON</title>
    <link>/tags/%E6%95%B0%E6%8D%AE%E9%9B%86/</link>
    <description>Recent content in 数据集 on 大邓和他的PYTHON</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh</language>
    <lastBuildDate>Fri, 22 Dec 2023 00:00:00 +0000</lastBuildDate><atom:link href="/tags/%E6%95%B0%E6%8D%AE%E9%9B%86/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>LIST | 可供社科(经管)领域使用的数据集汇总</title>
      <link>https://textdata.cn/blog/datasets_available_for_management_science/</link>
      <pubDate>Wed, 22 Nov 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/datasets_available_for_management_science/</guid>
      <description>可供社科(经管)使用的数据集</description>
      <content:encoded><![CDATA[<p>这篇资源帖按照汇总</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">- 社会
- 企业
- 用户

- 词向量
- 词典
</code></pre></div><p><br><br></p>
<h2 id="社会">社会</h2>
<ul>
<li>
<p><a href="https://textdata.cn/blog/2023-12-14-daily-news-dataset/"><span style="color: red;"><strong>新闻数据集(付费) | 含 人民日报/经济日报/光明日报 等 7 家媒体(2023.12.18)</strong></span></a></p>
</li>
<li>
<p><a href="https://textdata.cn/blog/2023-12-22-renmin-gov-leader-comment-board/"><span style="color: red;"><strong>数据集(付费) | 人民网政府留言板原始文本(2011-2023.12)</strong></span></a></p>
</li>
<li>
<p><a href="https://textdata.cn/blog/2023-12-17-gov-anual-report-dataset/"><strong>数据集(付费) | 国、省、市三级政府工作报告文本(1954-2023)</strong></a></p>
</li>
<li>
<p><a href="https://textdata.cn/blog/2023-02-26-cctv1-xwlb-news-text-dataset/"><strong>数据集(付费) | cctv新闻联播文稿数据集</strong></a></p>
</li>
<li>
<p><a href="https://textdata.cn/blog/2023-05-17-china-200-city-real-estate-policy/">实验数据 | 194城市楼市政策梳理(2010-2022)</a></p>
</li>
<li>
<p><a href="https://textdata.cn/blog/2023-09-03-government-procurement-contract-data/">数据集(付费) | 200w政府采购合同公告明细数据（1996.6-2022.12)</a></p>
</li>
</ul>
<p><br><br></p>
<h2 id="企业">企业</h2>
<ul>
<li><a href="https://textdata.cn/blog/2023-05-07-china-law-judgment-documents-datasets/"><strong>数据集(付费) | 中国裁判文书网(2010-2021.10)</strong></a></li>
<li><a href="https://textdata.cn/blog/2023-12-03-china-mainland-corporate-registration-information/"><strong>数据集(付费) | 2.49亿条中国工商注册企业信息(23.9更新)</strong></a></li>
<li><a href="https://textdata.cn/blog/2023-04-13-3571w-patent-dataset-in-china-mainland/"><strong>数据集(付费) | 3571万条专利申请数据集(1985-2022年)</strong></a></li>
<li><a href="https://textdata.cn/blog/2023-12-07-patent-application-dataset-of-listed-company-in-china-a-market/"><strong>数据集(付费) | 上市公司 208 万条专利数据集 (1991-2022)</strong></a></li>
<li><a href="https://textdata.cn/blog/2023-12-22-patent-transform-exchange-dataset/"><strong>数据集(付费) |  专利转让数据库(1985-2021)</strong></a></li>
<li><a href="https://textdata.cn/blog/2023-03-23-china-a-share-market-dataset-mda-from-01-to-21/"><strong>数据集(付费) | 2001年-2022年A股上市公司年报&amp;管理层讨论与分析</strong></a></li>
<li><a href="https://textdata.cn/blog/2023-04-12-china-poi-datasets/"><strong>数据集(付费) |  3.9G全国POI地点兴趣点数据集</strong></a></li>
<li><a href="https://textdata.cn/blog/2023-03-24-load-w2v-and-expand-your-concpet-dicitonary/"><strong>词向量(付费) | 使用MD&amp;A2001-2022语料训练Word2Vec模型</strong></a></li>
<li><a href="https://textdata.cn/blog/2023-04-17-china-a-market-inquiry-letter-datasets/"><strong>数据集(付费) | 2014年-2021年「问询函」</strong></a></li>
<li><a href="https://textdata.cn/blog/2023-08-11-china-a-market-corporate-social-responsibility-dataste/"><strong>数据集(付费) | 2006年-2022年沪深企业社会责任报告</strong></a></li>
<li><a href="https://textdata.cn/blog/2023-09-08-china-a-share-market-listed-company-earnings-communication-conference/"><strong>数据集(付费) | 84w条业绩说明会问答数据(2005-2023)</strong></a></li>
<li><a href="https://textdata.cn/blog/2022-11-25-senior-manager-resume-dataset/"><strong>数据集(付费) | 90w条中国上市公司高管数据</strong></a></li>
<li><a href="https://textdata.cn/blog/2023-05-17-top-manager-violation/"><strong>数据集(付费) | 上市公司高管违规数据(2008-2022)</strong></a></li>
<li><a href="https://textdata.cn/blog/2023-04-26-entrusted-loan-dataset/">数据集 | 07-21年上市公司「委托贷款公告」</a></li>
<li><a href="https://textdata.cn/blog/coporate_social_responsibility_datasets/">数据集 | 企业社会责任报告数据集</a></li>
<li><a href="https://textdata.cn/blog/2022-11-02-27g-python-27g-a-share-market-prospectus/">27G数据集 | 使用Python对27G招股说明书进行文本分析</a></li>
<li><a href="https://textdata.cn/blog/70g_china_market_anunal_report_datasets/">70G数据集 | 上交所定期报告数据集</a></li>
<li><a href="https://textdata.cn/blog/2022-10-21-2007-2021-a-share-reports-dataset/">14G数据集 | 2007-2021年A股上市公司年度报告（txt文件）</a></li>
<li><a href="https://textdata.cn/blog/2022-12-10-1850w-poi-dataset/">1850万条 | 世界地图POI兴趣点数据集</a></li>
<li><a href="https://textdata.cn/blog/2023-10-18-google-local-data/">数据集 | 谷歌地图美国区域内poi、评论信息等信息</a></li>
</ul>
<p><br><br></p>
<h2 id="用户">用户</h2>
<ul>
<li><a href="https://textdata.cn/blog/2023-11-22-1000w-github-developer-dataset/">数据集 | 1000万 Github 用户数据</a></li>
<li><a href="https://textdata.cn/blog/2023-11-22-open-dataset-gharchive-org/">2T数据集 | 使用GH Archive获取Github社区用户数据</a></li>
<li><a href="https://textdata.cn/blog/yelpdataset_10g/">10G数据集 | YelpDaset酒店管理类数据集</a></li>
<li><a href="https://textdata.cn/blog/2022-12-08-indiegogo-dataset/">1.5G数据集 | 200万条Indiegogo众筹项目信息</a></li>
<li><a href="https://textdata.cn/blog/2022-12-04-kickstarters_dataset/">12G数据集 | 23w条Kickstarter项目信息</a></li>
<li><a href="https://textdata.cn/blog/2023-05-10-100m-bilibili-user-info-dataset/">数据集 | B站/哔哩哔哩 1 亿用户数据</a></li>
<li><a href="https://textdata.cn/blog/2023-03-06-zhihurec-dataset/">数据集 | 80w知乎用户问答数据</a></li>
<li><a href="https://textdata.cn/blog/2023-03-06-bedtime-news-datasets/">数据集 |马前卒工作室 睡前消息文稿汇总</a></li>
</ul>
<p><br><br></p>
<h2 id="词向量">词向量</h2>
<ul>
<li><a href="https://textdata.cn/blog/2023-11-20-word2vec-by-year-by-province/"><strong>词向量(付费) | 使用3751w专利申请数据集按年份(按省份)训练词向量</strong></a></li>
<li><a href="https://textdata.cn/blog/2023-11-10-training-word2vec-model-using-china-3751w-patent-application-dataset/"><strong>词向量(付费) | 使用1985年-2022年专利申请摘要训练word2vec模型</strong></a></li>
<li><a href="https://textdata.cn/blog/2023-03-24-load-w2v-and-expand-your-concpet-dicitonary/"> <strong>词向量(付费) | 使用MD&amp;A2001-2022语料训练Word2Vec模型</strong></a></li>
<li><a href="https://textdata.cn/blog/2023-11-18-show-word-meaning-shift-using-word2vec/">案例分享|  使用裁判文书数据集逐年训练年份词向量</a></li>
<li><a href="https://textdata.cn/blog/embeddings_resource_usage_method/">中文词向量资源汇总 &amp; 使用方法</a></li>
<li><a href="https://textdata.cn/blog/pretained_nlp_models/">NLP资源 | 汽车、金融等9大领域预训练词向量模型下载资源</a></li>
<li><a href="https://textdata.cn/blog/2023-03-08-edgar-w2v-and-corpus/">EDGAR | 25年数据的预训练词向量模型</a></li>
<li><a href="https://textdata.cn/blog/2022-10-16-aligned-word-vectors/">数据集 | 多语言对齐词向量预训练模型</a></li>
</ul>
<p><br><br></p>
<h2 id="词典">词典</h2>
<ul>
<li><a href="https://textdata.cn/blog/2023-04-05-chinese-concreteness-dictionary-from-behavior-research-method/">中文心理词典，含具体性、可成象性等指标</a></li>
<li><a href="https://textdata.cn/blog/2023-03-20-nature-six-semantic-dimension-database/">Nature | 通用中英文六维语义情感词典</a></li>
<li><a href="https://textdata.cn/blog/chinese_semantic_kb/">ChineseSemanticKB | 中文语义常用词典</a></li>
<li><a href="https://textdata.cn/blog/2022-11-07-domainwordsdict-liuhuanyong/">DomainWordsDict | 领域词库构建方法与68领域、916万级专业词库分享</a></li>
<li><a href="https://textdata.cn/blog/2022-11-07-financial-invest-merge/">小规模金融并购、投资事件图谱设计概述与数据构成解析</a></li>
<li><a href="https://textdata.cn/blog/2022-09-27-r-ngramr/">Google Books Ngram Viewer显示英文词汇历史使用趋势</a></li>
<li><a href="https://textdata.cn/blog/2022-11-07-chinese-casual-text-datasets/">十万级 | 多领域因果事件对数据集对外开源</a></li>
</ul>
<p><br><br></p>
<h2 id="最后">最后</h2>
<p>数据集和模型资源比较少，各位如果有新资源，欢迎留言分享或者邮箱thunderhit@qq.com联系我。</p>
<p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><strong>付费视频课程 | Python实证指标构建与文本分析</strong>
<ul>
<li>大邓每年会有4场直播，五一、十一、寒、暑假，如果时间点接近，可考虑报名参与<a href="https://textdata.cn/blog/2022-05-workshop/7-Python.html">直播课</a>。</li>
<li>如果只意性价比，且已迫不及待想学，可以考虑直接报名大邓的<a href="https://textdata.cn/blog/management_python_course">录播课</a>。</li>
<li>如果不想学，也可以考虑外包。更建议找淘宝，如果找我咨询，请先阅读<a href="https://textdata.cn/blog/paid_for_service">有偿说明</a></li>
</ul>
</li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>数据集 |  专利转让数据集(1985-2021)</title>
      <link>https://textdata.cn/blog/2023-12-22-patent-transform-exchange-dataset/</link>
      <pubDate>Fri, 22 Dec 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-12-22-patent-transform-exchange-dataset/</guid>
      <description>数据集 |  专利转让数据库(1985-2021)</description>
      <content:encoded><![CDATA[<p><strong>专利所有权转让</strong> 是指在获得国家知识产权局授权后，将专利权转让给个人或企业等法律行为。转让行为需在国务院专利行政部门登记，并签订书面合同。转让合同的当事人成为新的专利申请权人或专利权人，可行使相应的专利申请权或专利权。<br></p>
<p><br><br></p>
<h2 id="一数据集概况">一、数据集概况</h2>
<p>专利转让数据集概况</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">覆盖年份：1985 ~ 2021
数据来源：国家知识产权局
总记录数: 2669767
文件格式: csv压缩文件
csv文件(数字代表字段数量):
     - 专利转让19.csv.gzip
     - 专利转让33.csv.gzip
     - 专利转让140.csv.gzip
</code></pre></div><p><br><br></p>
<h2 id="二查看数据">二、查看数据</h2>
<p>数据集中有 3 个 csv压缩文件， 文件名中的数字代表csv中含多少个字段。例如 <em><strong>专利转让_19.csv.gzip</strong></em> 表示csv中有19个字段。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">csv文件(数字代表字段数量):
   - 专利转让19.csv.gzip
   - 专利转让33.csv.gzip
   - 专利转让140.csv.gzip
</code></pre></div><br>
<h3 id="21---专利转让19csvgzip">2.1   专利转让19.csv.gzip</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="c1">#csv.gzip压缩文件读取方法</span>
<span class="n">df19</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;专利转让19.csv.gzip&#39;</span><span class="p">,</span> <span class="n">compression</span><span class="o">=</span><span class="s1">&#39;gzip&#39;</span><span class="p">)</span>
<span class="c1">#解压为csv读取方法</span>
<span class="c1">#df19 = pd.read_csv(&#39;专利转让19.csv&#39;)</span>

<span class="n">df19</span><span class="p">[</span><span class="s1">&#39;申请日&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">df19</span><span class="p">[</span><span class="s1">&#39;申请日&#39;</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;专利转让19.csv.gzip&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;记录数: &#39;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">df19</span><span class="p">))</span>
<span class="nb">print</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df19</span><span class="p">[</span><span class="s1">&#39;申请日&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df19</span><span class="p">[</span><span class="s1">&#39;申请日&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>
<span class="nb">print</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df19</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
<span class="nb">print</span><span class="p">()</span>
<span class="n">df19</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">专利转让19.csv.gzip

记录数: 1675553

1985-04-01 00:00:00
2018-11-14 00:00:00

Index([&#39;序号&#39;, &#39;公开（公告）号&#39;, &#39;公开（公告）日&#39;, &#39;申请号&#39;, &#39;申请日&#39;, &#39;申请人&#39;, &#39;申请人省市代码&#39;, &#39;中国申请人地市&#39;,
       &#39;中国申请人区县&#39;, &#39;申请人地址&#39;, &#39;当前专利权人&#39;, &#39;法律状态&#39;, &#39;当前法律状态&#39;, &#39;专利类型&#39;, &#39;主分类号&#39;, &#39;转让人&#39;,
       &#39;受让人&#39;, &#39;转让执行日&#39;, &#39;公开国别&#39;],
      dtype=&#39;object&#39;)
</code></pre></div><p><img loading="lazy" src="img/01-df.png" alt=""  />
</p>
<br>
<h3 id="22-专利转让33csvgzip">2.2 专利转让33.csv.gzip</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">df33</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;专利转让33.csv.gzip&#39;</span><span class="p">,</span> <span class="n">compression</span><span class="o">=</span><span class="s1">&#39;gzip&#39;</span><span class="p">)</span>
<span class="c1">#解压为csv读取方法</span>
<span class="c1">#df33 = pd.read_csv(&#39;专利转让33.csv&#39;)</span>
<span class="n">df33</span><span class="p">[</span><span class="s1">&#39;申请日&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">df33</span><span class="p">[</span><span class="s1">&#39;申请日&#39;</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;专利转让33.csv.gzip&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;记录数: &#39;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">df33</span><span class="p">))</span>
<span class="nb">print</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df33</span><span class="p">[</span><span class="s1">&#39;申请日&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df33</span><span class="p">[</span><span class="s1">&#39;申请日&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>
<span class="nb">print</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df33</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
<span class="nb">print</span><span class="p">()</span>
<span class="n">df33</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">专利转让33.csv.gzip

记录数:  256080

1999-01-07 00:00:00
2019-11-07 00:00:00

Index([&#39;序号&#39;, &#39;标题&#39;, &#39;公开（公告）号&#39;, &#39;公开（公告）日&#39;, &#39;申请号&#39;, &#39;申请日&#39;, &#39;申请人&#39;, &#39;标准化申请人&#39;,
       &#39;标准化当前专利权人&#39;, &#39;申请人国别代码&#39;, &#39;申请人省市代码&#39;, &#39;中国申请人地市&#39;, &#39;中国申请人区县&#39;, &#39;申请人地址&#39;,
       &#39;申请人类型&#39;, &#39;当前专利权人&#39;, &#39;法律状态&#39;, &#39;当前法律状态&#39;, &#39;专利类型&#39;, &#39;发明人&#39;, &#39;代理人&#39;, &#39;代理机构&#39;,
       &#39;审查员&#39;, &#39;主分类号&#39;, &#39;IPC&#39;, &#39;国民经济分类&#39;, &#39;转让人&#39;, &#39;受让人&#39;, &#39;转让执行日&#39;, &#39;原告&#39;, &#39;被告&#39;,
       &#39;第一申请人&#39;, &#39;公开国别&#39;],
      dtype=&#39;object&#39;)
</code></pre></div><p><img loading="lazy" src="img/02-df.png" alt=""  />
</p>
<br>
<h3 id="23-专利转让140csvgzip">2.3 专利转让140.csv.gzip</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="c1">#csv.gzip压缩文件读取方法</span>
<span class="n">df140</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;专利转让140.csv.gzip&#39;</span><span class="p">,</span> <span class="n">compression</span><span class="o">=</span><span class="s1">&#39;gzip&#39;</span><span class="p">)</span>
<span class="c1">#解压为csv读取方法</span>
<span class="c1">#df140 = pd.read_csv(&#39;专利转让140.csv&#39;)</span>


<span class="n">df140</span><span class="p">[</span><span class="s1">&#39;申请日&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">df140</span><span class="p">[</span><span class="s1">&#39;申请日&#39;</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;专利转让140.csv.gzip&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;记录数: &#39;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">df140</span><span class="p">))</span>
<span class="nb">print</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df19</span><span class="p">[</span><span class="s1">&#39;申请日&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df19</span><span class="p">[</span><span class="s1">&#39;申请日&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>
<span class="nb">print</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df19</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
<span class="nb">print</span><span class="p">()</span>
<span class="n">df19</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">专利转让140.csv.gzip

记录数:  1050301

2000-02-24 00:00:00
2021-12-01 00:00:00

Index([&#39;序号&#39;, &#39;公开（公告）号&#39;, &#39;标题 (中文)&#39;, &#39;公开（公告）日&#39;, &#39;受让人类型&#39;, &#39;转让执行日&#39;, &#39;转让次数&#39;, &#39;转让人&#39;,
       &#39;转让人类型&#39;, &#39;受让人&#39;,
       ...
       &#39;优先权号&#39;, &#39;优先权日&#39;, &#39;最早优先权日&#39;, &#39;优先权国别&#39;, &#39;PCT国际申请号&#39;, &#39;PCT国际公布号&#39;, &#39;PCT进入国家阶段日&#39;,
       &#39;母案&#39;, &#39;分案&#39;, &#39;一案双申&#39;],
      dtype=&#39;object&#39;, length=140)
</code></pre></div><p><img loading="lazy" src="img/03-df.png" alt=""  />
</p>
<p><br><br></p>
<h3 id="三相关文献">三、相关文献</h3>
<p>使用专利数据做研究的文献</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">[1]Bellstam, Gustaf, Sanjai Bhagat, and J. Anthony Cookson. &#34;A text-based analysis of corporate innovation.&#34; _Management Science_ 67, no. 7 (2021): 4004-4031.
[2]Arts, Sam, Bruno Cassiman, and Jianan Hou. &#34;Position and Differentiation of Firms in Technology Space.&#34; Management Science (2023).
</code></pre></div><br>
<h2 id="四代码操作">四、代码操作</h2>
<p><a href="https://textdata.cn/blog/2023-04-13-3571w-patent-dataset-in-china-mainland/">数据集 | 3571万条专利申请数据集(1985-2022年)</a></p>
<p><a href="https://textdata.cn/blog/2023-12-07-patent-application-dataset-of-listed-company-in-china-a-market/"><strong>数据集(付费) | 上市公司 208 万条专利数据集 (1991-2022)</strong></a></p>
<p><a href="https://textdata.cn/blog/2023-11-17-how-handle-mega-csv-that-far-exceed-memory/">推荐 | 如何处理远超电脑内存的csv文件</a></p>
<p><br><br></p>
<h2 id="四获取数据">四、获取数据</h2>
<p>内容为付费数据集，100元， 加微信 372335839， 备注「姓名-学校-专业」。</p>
<p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>数据集(付费) | 人民网政府留言板原始文本(2011-2023.12)</title>
      <link>https://textdata.cn/blog/2023-12-22-renmin-gov-leader-comment-board/</link>
      <pubDate>Fri, 22 Dec 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-12-22-renmin-gov-leader-comment-board/</guid>
      <description>&lt;img src=&#34;img/04-dataset.png&#34; style=&#34;zoom:80%;&#34; /&gt;
&lt;br&gt;
&lt;h2 id=&#34;一数据概况&#34;&gt;一、数据概况&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;数据来源: 人民网地方领导留言板

覆盖时间: 2011-01-01 ~ 2023.12.06

记录条数: 3914402

文件格式: xlsx、csv
    
所含字段: 
    -  留言领导
    -  留言标题
    -  省份
    -  市
    -  状态
    -  主题类别
    -  投诉种类
    -  留言人
    -  留言时间
    -  留言内容
    -  回复内容
    -  回复时间
    -  回复机构
    -  办理速度评分
    -  办理态度评分
    -  解决程度评分
    -  用户评价
    -  评价标签
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;该数据集 2000 元， 支持开票； 需要的加微信 372335839&lt;/strong&gt;， 备注 【姓名-学校-专业】&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;img src=&#34;img/2023a.png&#34; style=&#34;zoom:80%;&#34; /&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;img/2023b.png&#34; style=&#34;zoom:80%;&#34; /&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;二查看数据&#34;&gt;二、查看数据&lt;/h2&gt;
&lt;h3 id=&#34;21-读取数据&#34;&gt;2.1 读取数据&lt;/h3&gt;
&lt;p&gt;依次读取&lt;em&gt;&lt;strong&gt;2011-2019.csv.gzip&lt;/strong&gt;&lt;/em&gt; 和  &lt;em&gt;&lt;strong&gt;2020-2023.csv.gzip&lt;/strong&gt;&lt;/em&gt;  两个csv文件， 当然也可   &lt;em&gt;&lt;strong&gt;.csv.gzip&lt;/strong&gt;&lt;/em&gt; 解压得到  &lt;em&gt;&lt;strong&gt;.csv&lt;/strong&gt;&lt;/em&gt; 后再读取。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pandas&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pd&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;df11_19&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read_csv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;2011-2019.csv.gzip&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;compression&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;gzip&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;df11_19&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;head&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/02-df.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;df20_23&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read_csv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;2020-2023.csv.gzip&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;compression&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;gzip&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;df20_23&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;head&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/03-df.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;22-字段&#34;&gt;2.2 字段&lt;/h3&gt;
&lt;p&gt;10多年的时间，网站会变动，写爬虫运行爬虫的人也会变动。为了让大家更丝滑的使用数据，大邓对所有的年份进行了字段矫正和统一， 最后字段只有两大类，&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;2011-2019&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df11_19&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;columns&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\n&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;

&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;2020-2023&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df20_23&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;columns&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;2011-2019
Index([&amp;#39;留言领导&amp;#39;, &amp;#39;留言标题&amp;#39;, &amp;#39;省份&amp;#39;, &amp;#39;市&amp;#39;, &amp;#39;状态&amp;#39;, &amp;#39;主题类别&amp;#39;, &amp;#39;投诉种类&amp;#39;, &amp;#39;留言人&amp;#39;, &amp;#39;留言时间&amp;#39;, &amp;#39;留言内容&amp;#39;,
       &amp;#39;回复内容&amp;#39;, &amp;#39;回复时间&amp;#39;, &amp;#39;留言评价&amp;#39;, &amp;#39;评价时间&amp;#39;],
      dtype=&amp;#39;object&amp;#39;)


2020-2023
Index([&amp;#39;留言领导&amp;#39;, &amp;#39;留言标题&amp;#39;, &amp;#39;省份&amp;#39;, &amp;#39;市&amp;#39;, &amp;#39;状态&amp;#39;, &amp;#39;主题类别&amp;#39;, &amp;#39;投诉种类&amp;#39;, &amp;#39;留言人&amp;#39;, &amp;#39;留言时间&amp;#39;, &amp;#39;留言内容&amp;#39;,
       &amp;#39;回复内容&amp;#39;, &amp;#39;回复时间&amp;#39;, &amp;#39;回复机构&amp;#39;, &amp;#39;办理速度评分&amp;#39;, &amp;#39;办理态度评分&amp;#39;, &amp;#39;解决程度评分&amp;#39;, &amp;#39;用户评价&amp;#39;, &amp;#39;评价标签&amp;#39;],
      dtype=&amp;#39;object&amp;#39;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h3 id=&#34;23-记录数&#34;&gt;2.3 记录数&lt;/h3&gt;
&lt;p&gt;数据集总记录数&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;总记录数: &amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df11_19&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df20_23&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;总记录数: 3914402
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h3 id=&#34;24-年度记录数&#34;&gt;2.4 年度记录数&lt;/h3&gt;
&lt;p&gt;两个 dataframe 中都有 &lt;em&gt;&lt;strong&gt;留言日期&lt;/strong&gt;&lt;/em&gt; ， 我们根据该字段查看每个年份的记录数。首先，要先将该字段转化为 datetime 日期类型。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;data&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;df11_19&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;留言时间&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;to_datetime&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df11_19&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;留言时间&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;df20_23&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;留言时间&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;to_datetime&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df20_23&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;留言时间&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;

&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;year&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;year_df&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;df11_19&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;groupby&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df11_19&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;留言时间&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;year&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;append&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;({&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;year&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;year&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;volume&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;year_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)})&lt;/span&gt;
    &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;year&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39; &amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;year_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;

&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;year&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;year_df&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;df20_23&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;groupby&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df20_23&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;留言时间&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;year&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;append&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;({&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;year&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;year&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;volume&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;year_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)})&lt;/span&gt;
    &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;year&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39; &amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;year_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
    

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;2011   23307
2012   20178
2013   42951
2014   97637
2015   131928
2016   201523
2017   202792
2018   243646
2019   464657
2020   517167
2021   783139
2022   648055
2023   537422
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;plt&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;matplotlib&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;scienceplots&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;platform&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pandas&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pd&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;matplotlib_inline&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;matplotlib_inline&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;backend_inline&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;set_matplotlib_formats&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;png&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;svg&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;jieba&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;warnings&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;warnings&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;filterwarnings&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;ignore&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;plt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;style&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;use&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;([&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;science&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;no-latex&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;cjk-sc-font&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;system&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;platform&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;system&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;# 获取操作系统类型&lt;/span&gt;
&lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;system&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;Windows&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;font&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;family&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;SimHei&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;span class=&#34;k&#34;&gt;elif&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;system&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;Darwin&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;font&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;family&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;Arial Unicode MS&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;span class=&#34;k&#34;&gt;else&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;font&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;family&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;sans-serif&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;matplotlib&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;rc&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;font&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;font&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;# 设置全局字体&lt;/span&gt;
    
&lt;span class=&#34;n&#34;&gt;year_volume_df&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;DataFrame&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;c1&#34;&gt;#year_volume_df[&amp;#39;year&amp;#39;] = pd.to_datetime(year_volume_df[&amp;#39;year&amp;#39;])&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;year_volume_df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;set_index&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;year&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;inplace&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;year_volume_df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;plot&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;bar&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;figsize&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;7&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;plt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;title&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;人民网留言板留言数量(2011 ~ 2023)&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;size&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;15&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;plt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;xticks&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;size&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;rotation&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;plt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;xlabel&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;年份&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;size&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;13&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;plt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ylabel&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;留言数量&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;size&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;13&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/plot.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;需要声明， 采集的数据量与真实数据量肯定会有出入的， 例如爬虫运行的时间点、IP被封、请求失败、文件编码(格式)问题等会遗失一定量的记录量。&lt;/p&gt;
&lt;p&gt;但是大家做Python定量文本分析， 不用担心这个问题。  Python为代表的大规模数据挖掘，只要满足  &lt;strong&gt;Earnings(规模带来的信息增益) &amp;raquo; Loss(数据质量产生的损失)&lt;/strong&gt; ，做文本分析就是可行的，有意义的。 而咱们的数据， 数据规模近 400 万条， 数据质量也是有保证的。&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h3 id=&#34;25-value_counts&#34;&gt;2.5 value_counts&lt;/h3&gt;
&lt;p&gt;查看2011-2019年， 不同留 &lt;em&gt;&lt;strong&gt;主题类别&lt;/strong&gt;&lt;/em&gt;  的记录数&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;c1&#34;&gt;#2011-2019&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;df11_19&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;主题类别&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;value_counts&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;主题类别
城建    474433
交通    180197
其他    177258
三农    116153
环保     94345
教育     90602
政务     69915
治安     63750
就业     47857
医疗     37215
企业     36826
旅游     18675
文娱      9866
金融      6778
征集      4741
求助         3
咨询         2
建言         2
投诉         1
Name: count, dtype: int64
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h3 id=&#34;26-查看是否含某词&#34;&gt;2.6 查看是否含某词&lt;/h3&gt;
&lt;p&gt;查看字段 &lt;em&gt;&lt;strong&gt;留言内容&lt;/strong&gt;&lt;/em&gt;, 是否出现 &lt;em&gt;&lt;strong&gt;扰民|噪音&lt;/strong&gt;&lt;/em&gt; 等词语&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;df11_19&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;留言内容&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fillna&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;str&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;contains&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;扰民|噪音&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;0          False
1          False
2          False
3          False
4          False
           ...  
1428614    False
1428615    False
1428616    False
1428617    False
1428618    False
Name: 留言内容, Length: 1428619, dtype: bool
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;p&gt;噪音的留言记录数&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;df11_19&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;留言内容&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fillna&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;str&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;contains&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;扰民|噪音&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sum&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;57846
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;p&gt;噪音的留言记录占总留言数的比例&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;df11_19&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;留言内容&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fillna&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;str&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;contains&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;扰民|噪音&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sum&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df11_19&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;0.0404908516546399
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;有4%的留言是跟扰民、噪音相关的 。&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;三相关内容&#34;&gt;三、相关内容&lt;/h2&gt;
&lt;p&gt;想用 python 对 csv、xlsx 进行分析， 要学会尽量用 pandas 写代码。 以下是近期 pandas 的一些处理推文免费教程， 感兴趣的可以进去浏览浏览。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://textdata.cn/blog/2023-12-17-how-to-generate-panel-data-from-gov-report-dataset/&#34;&gt;&lt;strong&gt;代码 | 使用地方gov工作报告生成某类概念词频「面板数据」&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://textdata.cn/blog/2023-12-18-how-to-generate-panel-data-from-daily-news-dataset/&#34;&gt;&lt;strong&gt;代码 | 使用「新闻数据」构造概念词提及量「面板数据」&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://textdata.cn/blog/2023-02-26-cctv1-xwlb-news-text-dataset/&#34;&gt;&lt;strong&gt;数据代码| 使用cctv新闻联播文稿构造「面板数据」&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://textdata.cn/blog/2028-12-18-how-to-extract-data-from-patent-application-dataset/&#34;&gt;&lt;strong&gt;代码 | 使用3571w专利申请数据集构造「面板数据」&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://textdata.cn/blog/2023-12-20-measure-china-economic-policy-uncertainty/&#34;&gt;&lt;strong&gt;代码 | 使用「新闻数据」计算 「经济政策不确定性」指数&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;四获取数据&#34;&gt;四、获取数据&lt;/h2&gt;
&lt;p&gt;**该数据集2000元， 支持开票； **&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;需要的加微信 372335839&lt;/strong&gt;， 备注 【姓名-学校-专业】&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;广而告之&#34;&gt;广而告之&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/call_for_paper/&#34;&gt;长期征稿&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/we_need_you/&#34;&gt;长期招募小伙伴&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/management_python_course/&#34;&gt;付费视频课 | Python实证指标构建与文本分析&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
      <content:encoded><![CDATA[<img src="img/04-dataset.png" style="zoom:80%;" />
<br>
<h2 id="一数据概况">一、数据概况</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">数据来源: 人民网地方领导留言板

覆盖时间: 2011-01-01 ~ 2023.12.06

记录条数: 3914402

文件格式: xlsx、csv
    
所含字段: 
    -  留言领导
    -  留言标题
    -  省份
    -  市
    -  状态
    -  主题类别
    -  投诉种类
    -  留言人
    -  留言时间
    -  留言内容
    -  回复内容
    -  回复时间
    -  回复机构
    -  办理速度评分
    -  办理态度评分
    -  解决程度评分
    -  用户评价
    -  评价标签
</code></pre></div><p><strong>该数据集 2000 元， 支持开票； 需要的加微信 372335839</strong>， 备注 【姓名-学校-专业】</p>
<p><br><img src="img/2023a.png" style="zoom:80%;" /><br></p>
<p><img src="img/2023b.png" style="zoom:80%;" /><br></p>
<p><br><br></p>
<h2 id="二查看数据">二、查看数据</h2>
<h3 id="21-读取数据">2.1 读取数据</h3>
<p>依次读取<em><strong>2011-2019.csv.gzip</strong></em> 和  <em><strong>2020-2023.csv.gzip</strong></em>  两个csv文件， 当然也可   <em><strong>.csv.gzip</strong></em> 解压得到  <em><strong>.csv</strong></em> 后再读取。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">df11_19</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;2011-2019.csv.gzip&#39;</span><span class="p">,</span> <span class="n">compression</span><span class="o">=</span><span class="s1">&#39;gzip&#39;</span><span class="p">)</span>

<span class="n">df11_19</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div><p><img loading="lazy" src="img/02-df.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df20_23</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;2020-2023.csv.gzip&#39;</span><span class="p">,</span> <span class="n">compression</span><span class="o">=</span><span class="s1">&#39;gzip&#39;</span><span class="p">)</span>
<span class="n">df20_23</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div><p><img loading="lazy" src="img/03-df.png" alt=""  />
</p>
<br>
<h3 id="22-字段">2.2 字段</h3>
<p>10多年的时间，网站会变动，写爬虫运行爬虫的人也会变动。为了让大家更丝滑的使用数据，大邓对所有的年份进行了字段矫正和统一， 最后字段只有两大类，</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;2011-2019&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df11_19</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;2020-2023&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df20_23</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">2011-2019
Index([&#39;留言领导&#39;, &#39;留言标题&#39;, &#39;省份&#39;, &#39;市&#39;, &#39;状态&#39;, &#39;主题类别&#39;, &#39;投诉种类&#39;, &#39;留言人&#39;, &#39;留言时间&#39;, &#39;留言内容&#39;,
       &#39;回复内容&#39;, &#39;回复时间&#39;, &#39;留言评价&#39;, &#39;评价时间&#39;],
      dtype=&#39;object&#39;)


2020-2023
Index([&#39;留言领导&#39;, &#39;留言标题&#39;, &#39;省份&#39;, &#39;市&#39;, &#39;状态&#39;, &#39;主题类别&#39;, &#39;投诉种类&#39;, &#39;留言人&#39;, &#39;留言时间&#39;, &#39;留言内容&#39;,
       &#39;回复内容&#39;, &#39;回复时间&#39;, &#39;回复机构&#39;, &#39;办理速度评分&#39;, &#39;办理态度评分&#39;, &#39;解决程度评分&#39;, &#39;用户评价&#39;, &#39;评价标签&#39;],
      dtype=&#39;object&#39;)
</code></pre></div><br>
<h3 id="23-记录数">2.3 记录数</h3>
<p>数据集总记录数</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;总记录数: &#39;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">df11_19</span><span class="p">)</span><span class="o">+</span><span class="nb">len</span><span class="p">(</span><span class="n">df20_23</span><span class="p">))</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">总记录数: 3914402
</code></pre></div><br>
<h3 id="24-年度记录数">2.4 年度记录数</h3>
<p>两个 dataframe 中都有 <em><strong>留言日期</strong></em> ， 我们根据该字段查看每个年份的记录数。首先，要先将该字段转化为 datetime 日期类型。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">data</span> <span class="o">=</span> <span class="p">[]</span>

<span class="n">df11_19</span><span class="p">[</span><span class="s1">&#39;留言时间&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">df11_19</span><span class="p">[</span><span class="s1">&#39;留言时间&#39;</span><span class="p">])</span>
<span class="n">df20_23</span><span class="p">[</span><span class="s1">&#39;留言时间&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">df20_23</span><span class="p">[</span><span class="s1">&#39;留言时间&#39;</span><span class="p">])</span>

<span class="k">for</span> <span class="n">year</span><span class="p">,</span> <span class="n">year_df</span> <span class="ow">in</span> <span class="n">df11_19</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">df11_19</span><span class="p">[</span><span class="s1">&#39;留言时间&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">dt</span><span class="o">.</span><span class="n">year</span><span class="p">):</span>
    <span class="n">data</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="s1">&#39;year&#39;</span><span class="p">:</span> <span class="n">year</span><span class="p">,</span> <span class="s1">&#39;volume&#39;</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">year_df</span><span class="p">)})</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">year</span><span class="p">,</span> <span class="s1">&#39; &#39;</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">year_df</span><span class="p">))</span>

<span class="k">for</span> <span class="n">year</span><span class="p">,</span> <span class="n">year_df</span> <span class="ow">in</span> <span class="n">df20_23</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">df20_23</span><span class="p">[</span><span class="s1">&#39;留言时间&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">dt</span><span class="o">.</span><span class="n">year</span><span class="p">):</span>
    <span class="n">data</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="s1">&#39;year&#39;</span><span class="p">:</span> <span class="n">year</span><span class="p">,</span> <span class="s1">&#39;volume&#39;</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">year_df</span><span class="p">)})</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">year</span><span class="p">,</span> <span class="s1">&#39; &#39;</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">year_df</span><span class="p">))</span>
    

</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">2011   23307
2012   20178
2013   42951
2014   97637
2015   131928
2016   201523
2017   202792
2018   243646
2019   464657
2020   517167
2021   783139
2022   648055
2023   537422
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">matplotlib</span>
<span class="kn">import</span> <span class="nn">scienceplots</span>
<span class="kn">import</span> <span class="nn">platform</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib_inline</span>
<span class="n">matplotlib_inline</span><span class="o">.</span><span class="n">backend_inline</span><span class="o">.</span><span class="n">set_matplotlib_formats</span><span class="p">(</span><span class="s1">&#39;png&#39;</span><span class="p">,</span> <span class="s1">&#39;svg&#39;</span><span class="p">)</span>
<span class="kn">import</span> <span class="nn">jieba</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">([</span><span class="s1">&#39;science&#39;</span><span class="p">,</span> <span class="s1">&#39;no-latex&#39;</span><span class="p">,</span> <span class="s1">&#39;cjk-sc-font&#39;</span><span class="p">])</span>
<span class="n">system</span> <span class="o">=</span> <span class="n">platform</span><span class="o">.</span><span class="n">system</span><span class="p">()</span>  <span class="c1"># 获取操作系统类型</span>
<span class="k">if</span> <span class="n">system</span> <span class="o">==</span> <span class="s1">&#39;Windows&#39;</span><span class="p">:</span>
    <span class="n">font</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;family&#39;</span><span class="p">:</span> <span class="s1">&#39;SimHei&#39;</span><span class="p">}</span>
<span class="k">elif</span> <span class="n">system</span> <span class="o">==</span> <span class="s1">&#39;Darwin&#39;</span><span class="p">:</span>
    <span class="n">font</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;family&#39;</span><span class="p">:</span> <span class="s1">&#39;Arial Unicode MS&#39;</span><span class="p">}</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">font</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;family&#39;</span><span class="p">:</span> <span class="s1">&#39;sans-serif&#39;</span><span class="p">}</span>
<span class="n">matplotlib</span><span class="o">.</span><span class="n">rc</span><span class="p">(</span><span class="s1">&#39;font&#39;</span><span class="p">,</span> <span class="o">**</span><span class="n">font</span><span class="p">)</span>  <span class="c1"># 设置全局字体</span>
    
<span class="n">year_volume_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="c1">#year_volume_df[&#39;year&#39;] = pd.to_datetime(year_volume_df[&#39;year&#39;])</span>
<span class="n">year_volume_df</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="s1">&#39;year&#39;</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">year_volume_df</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s1">&#39;bar&#39;</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;人民网留言板留言数量(2011 ~ 2023)&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;年份&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">13</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;留言数量&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">13</span><span class="p">)</span>
</code></pre></div><p><img loading="lazy" src="img/plot.png" alt=""  />
</p>
<p>需要声明， 采集的数据量与真实数据量肯定会有出入的， 例如爬虫运行的时间点、IP被封、请求失败、文件编码(格式)问题等会遗失一定量的记录量。</p>
<p>但是大家做Python定量文本分析， 不用担心这个问题。  Python为代表的大规模数据挖掘，只要满足  <strong>Earnings(规模带来的信息增益) &raquo; Loss(数据质量产生的损失)</strong> ，做文本分析就是可行的，有意义的。 而咱们的数据， 数据规模近 400 万条， 数据质量也是有保证的。</p>
<p><br><br></p>
<h3 id="25-value_counts">2.5 value_counts</h3>
<p>查看2011-2019年， 不同留 <em><strong>主题类别</strong></em>  的记录数</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#2011-2019</span>
<span class="n">df11_19</span><span class="p">[</span><span class="s1">&#39;主题类别&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">主题类别
城建    474433
交通    180197
其他    177258
三农    116153
环保     94345
教育     90602
政务     69915
治安     63750
就业     47857
医疗     37215
企业     36826
旅游     18675
文娱      9866
金融      6778
征集      4741
求助         3
咨询         2
建言         2
投诉         1
Name: count, dtype: int64
</code></pre></div><br>
<h3 id="26-查看是否含某词">2.6 查看是否含某词</h3>
<p>查看字段 <em><strong>留言内容</strong></em>, 是否出现 <em><strong>扰民|噪音</strong></em> 等词语</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df11_19</span><span class="p">[</span><span class="s1">&#39;留言内容&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="s1">&#39;扰民|噪音&#39;</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">0          False
1          False
2          False
3          False
4          False
           ...  
1428614    False
1428615    False
1428616    False
1428617    False
1428618    False
Name: 留言内容, Length: 1428619, dtype: bool
</code></pre></div><br>
<p>噪音的留言记录数</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df11_19</span><span class="p">[</span><span class="s1">&#39;留言内容&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="s1">&#39;扰民|噪音&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">57846
</code></pre></div><br>
<p>噪音的留言记录占总留言数的比例</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df11_19</span><span class="p">[</span><span class="s1">&#39;留言内容&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="s1">&#39;扰民|噪音&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">df11_19</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">0.0404908516546399
</code></pre></div><p>有4%的留言是跟扰民、噪音相关的 。</p>
<p><br><br></p>
<h2 id="三相关内容">三、相关内容</h2>
<p>想用 python 对 csv、xlsx 进行分析， 要学会尽量用 pandas 写代码。 以下是近期 pandas 的一些处理推文免费教程， 感兴趣的可以进去浏览浏览。</p>
<ul>
<li>
<p><a href="https://textdata.cn/blog/2023-12-17-how-to-generate-panel-data-from-gov-report-dataset/"><strong>代码 | 使用地方gov工作报告生成某类概念词频「面板数据」</strong></a></p>
</li>
<li>
<p><a href="https://textdata.cn/blog/2023-12-18-how-to-generate-panel-data-from-daily-news-dataset/"><strong>代码 | 使用「新闻数据」构造概念词提及量「面板数据」</strong></a></p>
</li>
<li>
<p><a href="https://textdata.cn/blog/2023-02-26-cctv1-xwlb-news-text-dataset/"><strong>数据代码| 使用cctv新闻联播文稿构造「面板数据」</strong></a></p>
</li>
<li>
<p><a href="https://textdata.cn/blog/2028-12-18-how-to-extract-data-from-patent-application-dataset/"><strong>代码 | 使用3571w专利申请数据集构造「面板数据」</strong></a></p>
</li>
<li>
<p><a href="https://textdata.cn/blog/2023-12-20-measure-china-economic-policy-uncertainty/"><strong>代码 | 使用「新闻数据」计算 「经济政策不确定性」指数</strong></a></p>
</li>
</ul>
<p><br><br></p>
<h2 id="四获取数据">四、获取数据</h2>
<p>**该数据集2000元， 支持开票； **</p>
<p><strong>需要的加微信 372335839</strong>， 备注 【姓名-学校-专业】</p>
<p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>代码 | 使用3571w专利申请数据集构造面板数据</title>
      <link>https://textdata.cn/blog/2028-12-18-how-to-extract-data-from-patent-application-dataset/</link>
      <pubDate>Mon, 18 Dec 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2028-12-18-how-to-extract-data-from-patent-application-dataset/</guid>
      <description>使用3571w专利申请数据生成面板数据</description>
      <content:encoded><![CDATA[<h2 id="相关代码">相关代码</h2>
<ul>
<li><a href="https://textdata.cn/blog/2023-12-18-how-to-generate-panel-data-from-daily-news-dataset/">代码 | 使用jjrb/rmrb数据构造某类概念词频「面板数据」</a></li>
<li><a href="https://textdata.cn/blog/2023-02-26-cctv1-xwlb-news-text-dataset/">代码 | 使用cctv新闻联播文稿构造面板数据</a></li>
</ul>
<p><br><br></p>
<h2 id="一任务">一、任务</h2>
<p>设计筛选条件，将某类专利(如<strong>人工智能</strong>)申请信息， 按 <strong>省份、年度、专利申请数</strong> 构造面板数据。如下图</p>
<p><img loading="lazy" src="img/02-df.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="二专利数据集">二、专利数据集</h2>
<p><a href="https://textdata.cn/blog/2023-04-13-3571w-patent-dataset-in-china-mainland/">数据集 | 3571万条专利申请数据集(1985-2022年)</a></p>
<br>
<h3 id="21-概况">2.1 概况</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">- 数据集名称：省份版知识产权局专利
- 时间跨度：1985.1-2022.5，专利申请总量3571万
- 数据来源：『国家知识产权局』
- 数据整理: 『公众号:大邓和他的Python』
</code></pre></div><p>3571万专利申请全量数据(<strong>1985.01 ~ 2022.5</strong>)数据，解压后整个文件夹大概 20 G。</p>
<p><img loading="lazy" src="img/screen-datasets2.png" alt=""  />
</p>
<br>
<h3 id="22-获取数据">2.2 获取数据</h3>
<ul>
<li>免费下载 <a href="%E4%B8%93%E5%88%A9%E9%9D%A2%E6%9D%BF%E6%95%B0%E6%8D%AE.ipynb">专利面板数据.ipynb</a></li>
<li>免费下载 <a href="AI_panel.xlsx">AI_panel.xlsx</a></li>
<li>免费下载 <a href="AI_details.xlsx">AI_details.xlsx</a></li>
</ul>
<br>
<p><a href="https://textdata.cn/blog/2023-04-13-3571w-patent-dataset-in-china-mainland/">3571万条专利申请数据集(1985-2022年)</a>
100元，需要的话， 加微信 372335839 ，备注【姓名-学校-专业】</p>
<p><br><br></p>
<h2 id="三实验代码">三、实验代码</h2>
<p>本实验代码文件目录结构</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">  |- 专利面板数据.ipynb
  |- Word2Vec
     |-1000w专利摘要文本.100.6.bin
     |-1000w专利摘要文本.100.6.bin.syn1neg.npy
     |-1000w专利摘要文本.100.6.bin.wv.vectors.npy
  |3571万专利申请全量数据1985-2022年
     |-广东省.csv.gzip
     |-...
     |-西藏自治区.csv.gzip
  |-AI_details.xlsx
  |-AI_panel.xlsx
</code></pre></div><br>
<h3 id="31-人工智能相关词">3.1 人工智能相关词</h3>
<p>使用之前 <a href="https://textdata.cn/blog/2023-11-20-word2vec-by-year-by-province/"><strong>词向量(付费) | 使用3751w专利申请数据集按年份(按省份)训练词向量</strong></a>  来扩展 「大数据」相关关键词。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#2.0.0版cntext，未公开，需要私信372335839</span>
<span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>

<span class="c1">#查看版本</span>
<span class="nb">print</span><span class="p">(</span><span class="n">ct</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span>

<span class="n">w2v_m</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">load_w2v</span><span class="p">(</span><span class="s1">&#39;Word2Vec/1000w专利摘要文本.100.6.bin&#39;</span><span class="p">)</span>
<span class="n">w2v_m</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">2.0.0
Loading word2vec model...
&lt;gensim.models.word2vec.Word2Vec at 0x109a8c810&gt;
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#我能想到的AI技术就这四个词</span>
<span class="n">w2v_m</span><span class="o">.</span><span class="n">wv</span><span class="o">.</span><span class="n">most_similar</span><span class="p">([</span><span class="s1">&#39;人工智能&#39;</span><span class="p">],</span> <span class="n">topn</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">[(&#39;AI&#39;, 0.8372030854225159),
 (&#39;人工智能技术&#39;, 0.7714870572090149),
 (&#39;AI智能&#39;, 0.74532151222229),
 (&#39;智能决策&#39;, 0.7404459714889526),
 (&#39;AI人工智能&#39;, 0.7198485732078552),
 (&#39;云计算&#39;, 0.7136917114257812),
 (&#39;人工智能学习&#39;, 0.7058480381965637),
 (&#39;深度学习&#39;, 0.6903414130210876),
 (&#39;交互式&#39;, 0.6859808564186096),
 (&#39;智慧校园&#39;, 0.6856474876403809),
 (&#39;信息技术&#39;, 0.6841551661491394),
 (&#39;智慧养老&#39;, 0.682081937789917),
 (&#39;智慧旅游&#39;, 0.6777652502059937),
 (&#39;智慧医疗&#39;, 0.6757360100746155),
 (&#39;智能机器人&#39;, 0.6742302179336548),
 (&#39;智慧&#39;, 0.6734717488288879),
 (&#39;人工智能语音&#39;, 0.6727728247642517),
 (&#39;物联网&#39;, 0.66999351978302),
 (&#39;机器学习&#39;, 0.6683002710342407),
 (&#39;健康管理&#39;, 0.6656192541122437),
 (&#39;人工智能AI&#39;, 0.6648072600364685),
 (&#39;AI视觉&#39;, 0.6609936356544495),
 (&#39;智慧社区&#39;, 0.6581154465675354),
 (&#39;自主学习&#39;, 0.6569625735282898),
 (&#39;图像识别&#39;, 0.6551436185836792),
 (&#39;健康管理系统&#39;, 0.6537778377532959),
 (&#39;数据分析系统&#39;, 0.6528143882751465),
 (&#39;教学系统&#39;, 0.6516135334968567),
 (&#39;图形化编程&#39;, 0.6513208150863647),
 (&#39;计算机技术&#39;, 0.6512178182601929)]
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">w2v_m</span><span class="o">.</span><span class="n">wv</span><span class="o">.</span><span class="n">most_similar</span><span class="p">([</span><span class="s1">&#39;人工智能&#39;</span><span class="p">,</span> <span class="s1">&#39;机器学习&#39;</span><span class="p">,</span> <span class="s1">&#39;AI&#39;</span><span class="p">,</span> <span class="s1">&#39;NLP&#39;</span><span class="p">,</span> <span class="s1">&#39;智能机器人&#39;</span><span class="p">],</span> <span class="n">topn</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">[(&#39;人工智能技术&#39;, 0.8236023783683777),
 (&#39;人工智能学习&#39;, 0.7996466159820557),
 (&#39;自然语言理解&#39;, 0.7942413687705994),
 (&#39;深度学习&#39;, 0.7931050658226013),
 (&#39;智能决策&#39;, 0.7848177552223206),
 (&#39;上下文感知&#39;, 0.7765907049179077),
 (&#39;自然语言处理&#39;, 0.7757146954536438),
 (&#39;智能问答&#39;, 0.7602421641349792),
 (&#39;自主学习&#39;, 0.7582942247390747),
 (&#39;问答系统&#39;, 0.7564904093742371),
 (&#39;在线学习&#39;, 0.7510443329811096),
 (&#39;人工智能算法&#39;, 0.7500166296958923),
 (&#39;数据挖掘&#39;, 0.7495553493499756),
 (&#39;AI算法&#39;, 0.7419456839561462),
 (&#39;自我学习&#39;, 0.7414599061012268),
 (&#39;AI模型&#39;, 0.7412964105606079),
 (&#39;人工智能AI&#39;, 0.7401654720306396),
 (&#39;知识推理&#39;, 0.7398316860198975),
 (&#39;语音语义&#39;, 0.7393308877944946),
 (&#39;行为识别&#39;, 0.7342970967292786),
 (&#39;人工智能语音&#39;, 0.7332825660705566),
 (&#39;多任务&#39;, 0.7270201444625854),
 (&#39;神经机器翻译&#39;, 0.7220420837402344),
 (&#39;边云协同&#39;, 0.7219405174255371),
 (&#39;图形化编程&#39;, 0.7205625772476196),
 (&#39;云计算&#39;, 0.7199273109436035),
 (&#39;众包&#39;, 0.7197409272193909),
 (&#39;AI智能&#39;, 0.7154985666275024),
 (&#39;NLU&#39;, 0.7152286767959595),
 (&#39;AI人工智能&#39;, 0.7139929533004761)]
</code></pre></div><br>
<p>通过运行多次查询相似词，不断浓缩，得到人工智能技术相关技术词(不一定全，只是演示)</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">AI_rela_words</span> <span class="o">=</span> <span class="s1">&#39;人工智能|机器学习|AI|NLP|智能问答|智能问答|神经机器翻译|NLU|增量学习&#39;</span>
</code></pre></div><br>
<h3 id="32-读取专利数据">3.2 读取专利数据</h3>
<p>尝试读取一个文件
写代码先局部后整体，先小后大。 能在局部小文件做实验成功，就可以for循环推广到所有的文件。这里我们选择 <em><strong>内蒙古自治区.csv.gzip</strong></em></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;3571万专利申请全量数据1985-2022年/内蒙古自治区.csv.gzip&#39;</span><span class="p">,</span> <span class="n">compression</span><span class="o">=</span><span class="s1">&#39;gzip&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">))</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div><p><img loading="lazy" src="img/01-df.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#含有的字段</span>
<span class="n">df</span><span class="o">.</span><span class="n">columns</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">Index([&#39;专利公开号&#39;, &#39;专利名称&#39;, &#39;专利类型&#39;, &#39;专利摘要&#39;, &#39;申请人&#39;, &#39;专利申请号&#39;, &#39;申请日&#39;, &#39;申请公布日&#39;,
       &#39;授权公布号&#39;, &#39;授权公布日&#39;, &#39;申请地址&#39;, &#39;主权项&#39;, &#39;发明人&#39;, &#39;分类号&#39;, &#39;主分类号&#39;, &#39;代理机构&#39;, &#39;分案原申请号&#39;,
       &#39;优先权&#39;, &#39;国际申请&#39;, &#39;国际公布&#39;, &#39;代理人&#39;, &#39;省份或国家代码&#39;, &#39;法律状态&#39;, &#39;专利领域&#39;, &#39;专利学科&#39;,
       &#39;多次公布&#39;],
      dtype=&#39;object&#39;)
</code></pre></div><br>
<h3 id="33-筛选专利">3.3 筛选专利</h3>
<p>使用逻辑条件把 <em><strong>专利名称</strong></em> 和 <em><strong>专利摘要</strong></em> 中含 <em><strong>人工智能</strong></em> 相关概念词的申请记录筛选出来。 注意， 筛选条件的严格程度根据自己需要调整，这里使用的最严格的条件，即 人工智能词同时出现在专利名称和专利摘要，才将该专利识别为人工智能专利。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">AI_rela_words</span> <span class="o">=</span> <span class="s1">&#39;人工智能|机器学习|AI|NLP|智能问答|智能问答|神经机器翻译|NLU|增量学习&#39;</span>

<span class="n">mask1</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;专利名称&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="n">AI_rela_words</span><span class="p">)</span>
<span class="n">mask2</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;专利摘要&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="n">AI_rela_words</span><span class="p">)</span>

<span class="c1">#内容太多， 选择需要的字段进行展示</span>
<span class="n">selected_fields</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;专利名称&#39;</span><span class="p">,</span> <span class="s1">&#39;专利摘要&#39;</span><span class="p">,</span> <span class="s1">&#39;专利类型&#39;</span><span class="p">,</span> <span class="s1">&#39;申请日&#39;</span><span class="p">,</span> <span class="s1">&#39;专利学科&#39;</span><span class="p">,</span> <span class="s1">&#39;专利领域&#39;</span><span class="p">]</span>
<span class="c1">#专利</span>
<span class="n">ai_df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">mask1</span> <span class="o">&amp;</span> <span class="n">mask2</span><span class="p">][</span><span class="n">selected_fields</span><span class="p">]</span>
<span class="n">ai_df</span>
</code></pre></div><p><img loading="lazy" src="img/03-df.png" alt=""  />
</p>
<br>
<p>筛选结果基本上都是人工智能相关专利技术。</p>
<br>
<h3 id="34-专利类型分布">3.4 专利类型分布</h3>
<p>内蒙古自治区， 人工智能相关专利的类型分布</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">ai_df</span><span class="p">[</span><span class="s1">&#39;专利类型&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">专利类型
发明公开    52
实用新型    18
外观设计     5
发明授权     4
Name: count, dtype: int64
</code></pre></div><br>
<h3 id="35-年度申请量">3.5 年度申请量</h3>
<p>计算内蒙古自治区，人工智能相关专利年度申请量。 根据申请日， 先生成year字段</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">ai_df</span><span class="p">[</span><span class="s1">&#39;year&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">ai_df</span><span class="p">[</span><span class="s2">&#34;申请日&#34;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">d</span><span class="p">:</span><span class="n">d</span><span class="p">[:</span><span class="mi">4</span><span class="p">])</span>

<span class="k">for</span> <span class="n">year</span><span class="p">,</span> <span class="n">ai_year_df</span> <span class="ow">in</span> <span class="n">ai_df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;year&#39;</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">year</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">ai_year_df</span><span class="p">))</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">2015 2
2016 3
2017 4
2018 7
2019 8
2020 28
2021 24
2022 3
</code></pre></div><br>
<h3 id="36-获取年度各种专利类型的数量">3.6 获取年度各种专利类型的数量</h3>
<p>计算内蒙古自治区，人工智能领域各类型专利的年度申请量</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="k">for</span> <span class="n">year</span><span class="p">,</span> <span class="n">ai_year_df</span> <span class="ow">in</span> <span class="n">ai_df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;year&#39;</span><span class="p">):</span>
    <span class="n">data</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
    <span class="n">data</span><span class="p">[</span><span class="s1">&#39;年度&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">year</span>
    <span class="n">data</span><span class="p">[</span><span class="s1">&#39;实用新型&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">ai_year_df</span><span class="p">[</span><span class="s1">&#39;专利类型&#39;</span><span class="p">]</span><span class="o">==</span><span class="s1">&#39;实用新型&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
    <span class="n">data</span><span class="p">[</span><span class="s1">&#39;发明公开&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">ai_year_df</span><span class="p">[</span><span class="s1">&#39;专利类型&#39;</span><span class="p">]</span><span class="o">==</span><span class="s1">&#39;发明公开&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
    <span class="n">data</span><span class="p">[</span><span class="s1">&#39;外观设计&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">ai_year_df</span><span class="p">[</span><span class="s1">&#39;专利类型&#39;</span><span class="p">]</span><span class="o">==</span><span class="s1">&#39;外观设计&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
    <span class="n">data</span><span class="p">[</span><span class="s1">&#39;发明授权&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">ai_year_df</span><span class="p">[</span><span class="s1">&#39;专利类型&#39;</span><span class="p">]</span><span class="o">==</span><span class="s1">&#39;发明授权&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
    <span class="n">data</span><span class="p">[</span><span class="s1">&#39;省份&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;内蒙古自治区&#39;</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">{&#39;年度&#39;: &#39;2015&#39;, &#39;实用新型&#39;: 0, &#39;发明公开&#39;: 0, &#39;外观设计&#39;: 2, &#39;发明授权&#39;: 0, &#39;省份&#39;: &#39;内蒙古自治区&#39;}
{&#39;年度&#39;: &#39;2016&#39;, &#39;实用新型&#39;: 1, &#39;发明公开&#39;: 0, &#39;外观设计&#39;: 2, &#39;发明授权&#39;: 0, &#39;省份&#39;: &#39;内蒙古自治区&#39;}
{&#39;年度&#39;: &#39;2017&#39;, &#39;实用新型&#39;: 3, &#39;发明公开&#39;: 1, &#39;外观设计&#39;: 0, &#39;发明授权&#39;: 0, &#39;省份&#39;: &#39;内蒙古自治区&#39;}
{&#39;年度&#39;: &#39;2018&#39;, &#39;实用新型&#39;: 1, &#39;发明公开&#39;: 5, &#39;外观设计&#39;: 0, &#39;发明授权&#39;: 1, &#39;省份&#39;: &#39;内蒙古自治区&#39;}
{&#39;年度&#39;: &#39;2019&#39;, &#39;实用新型&#39;: 4, &#39;发明公开&#39;: 3, &#39;外观设计&#39;: 0, &#39;发明授权&#39;: 1, &#39;省份&#39;: &#39;内蒙古自治区&#39;}
{&#39;年度&#39;: &#39;2020&#39;, &#39;实用新型&#39;: 4, &#39;发明公开&#39;: 22, &#39;外观设计&#39;: 0, &#39;发明授权&#39;: 2, &#39;省份&#39;: &#39;内蒙古自治区&#39;}
{&#39;年度&#39;: &#39;2021&#39;, &#39;实用新型&#39;: 5, &#39;发明公开&#39;: 18, &#39;外观设计&#39;: 1, &#39;发明授权&#39;: 0, &#39;省份&#39;: &#39;内蒙古自治区&#39;}
{&#39;年度&#39;: &#39;2022&#39;, &#39;实用新型&#39;: 0, &#39;发明公开&#39;: 3, &#39;外观设计&#39;: 0, &#39;发明授权&#39;: 0, &#39;省份&#39;: &#39;内蒙古自治区&#39;}
</code></pre></div><br>
<h3 id="37-路径列表">3.7 路径列表</h3>
<p>使用glob库查看专利申请数据集内的含 <em><strong>csv.gzip</strong></em> 的所有文件路径</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">glob</span>

<span class="c1">#剔除港、澳、台、海外</span>
<span class="n">not_in</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;3571万专利申请全量数据1985-2022年/台湾省.csv.gzip&#39;</span><span class="p">,</span>
          <span class="s1">&#39;3571万专利申请全量数据1985-2022年/澳门特别行政区.csv.gzip&#39;</span><span class="p">,</span> 
          <span class="s1">&#39;3571万专利申请全量数据1985-2022年/香港特别行政区.csv.gzip&#39;</span><span class="p">,</span> 
          <span class="s1">&#39;3571万专利申请全量数据1985-2022年/其他国家.csv.gzip&#39;</span><span class="p">]</span>


<span class="n">files</span> <span class="o">=</span> <span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="s1">&#39;3571万专利申请全量数据1985-2022年/*.csv.gzip&#39;</span><span class="p">)</span>
<span class="n">files</span> <span class="o">=</span> <span class="p">[</span><span class="n">f</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">files</span> <span class="k">if</span> <span class="n">f</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">not_in</span><span class="p">]</span>
<span class="n">files</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">[&#39;3571万专利申请全量数据1985-2022年/内蒙古自治区.csv.gzip&#39;,
 &#39;3571万专利申请全量数据1985-2022年/吉林省.csv.gzip&#39;,
 &#39;3571万专利申请全量数据1985-2022年/安徽省.csv.gzip&#39;,
 &#39;3571万专利申请全量数据1985-2022年/江苏省.csv.gzip&#39;,
 ......
 &#39;3571万专利申请全量数据1985-2022年/海南省.csv.gzip&#39;,
 &#39;3571万专利申请全量数据1985-2022年/河北省.csv.gzip&#39;,
 &#39;3571万专利申请全量数据1985-2022年/黑龙江省.csv.gzip&#39;,
 &#39;3571万专利申请全量数据1985-2022年/宁夏回族自治区.csv.gzip&#39;,
 &#39;3571万专利申请全量数据1985-2022年/广西壮族自治区.csv.gzip&#39;]
</code></pre></div><br>
<h3 id="38-批量运算">3.8 批量运算</h3>
<p>现在对所有省市进行刚刚的操作， 筛选出的人工智能专利详细信息保存到 <em><strong>AI_details.csv</strong></em> , 同时汇总面板数据(年度、省份、专利数量), 得到 <em><strong>AI_panel.xlsx</strong></em> 。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="o">%%</span><span class="n">time</span>

<span class="n">AI_rela_words</span> <span class="o">=</span> <span class="s1">&#39;人工智能|机器学习|AI|NLP|智能问答|智能问答|神经机器翻译|NLU|增量学习&#39;</span>
<span class="n">AI_Relatives_Patents</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">file</span> <span class="ow">in</span> <span class="n">files</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">file</span><span class="p">)</span>
    <span class="n">prov</span> <span class="o">=</span> <span class="n">file</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;/&#39;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;.csv.gzip&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">)</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">file</span><span class="p">,</span> <span class="n">compression</span><span class="o">=</span><span class="s1">&#39;gzip&#39;</span><span class="p">)</span>
    
    <span class="n">mask1</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;专利名称&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="n">AI_rela_words</span><span class="p">)</span>
    <span class="n">mask2</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;专利摘要&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="n">AI_rela_words</span><span class="p">)</span>

    <span class="n">ai_df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">mask1</span> <span class="o">&amp;</span> <span class="n">mask2</span><span class="p">]</span>
    <span class="n">ai_df</span><span class="p">[</span><span class="s1">&#39;year&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">ai_df</span><span class="p">[</span><span class="s2">&#34;申请日&#34;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">d</span><span class="p">:</span><span class="n">d</span><span class="p">[:</span><span class="mi">4</span><span class="p">])</span>
    
    <span class="c1">#保存全国AI专利详情信息</span>
    <span class="n">ai_df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;AI_details.csv&#39;</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    
    <span class="k">for</span> <span class="n">year</span><span class="p">,</span> <span class="n">ai_year_df</span> <span class="ow">in</span> <span class="n">ai_df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;year&#39;</span><span class="p">):</span>
        <span class="n">data</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
        <span class="n">data</span><span class="p">[</span><span class="s1">&#39;年度&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">year</span>
        <span class="n">data</span><span class="p">[</span><span class="s1">&#39;实用新型&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">ai_year_df</span><span class="p">[</span><span class="s1">&#39;专利类型&#39;</span><span class="p">]</span><span class="o">==</span><span class="s1">&#39;实用新型&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
        <span class="n">data</span><span class="p">[</span><span class="s1">&#39;发明公开&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">ai_year_df</span><span class="p">[</span><span class="s1">&#39;专利类型&#39;</span><span class="p">]</span><span class="o">==</span><span class="s1">&#39;发明公开&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
        <span class="n">data</span><span class="p">[</span><span class="s1">&#39;外观设计&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">ai_year_df</span><span class="p">[</span><span class="s1">&#39;专利类型&#39;</span><span class="p">]</span><span class="o">==</span><span class="s1">&#39;外观设计&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
        <span class="n">data</span><span class="p">[</span><span class="s1">&#39;发明授权&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">ai_year_df</span><span class="p">[</span><span class="s1">&#39;专利类型&#39;</span><span class="p">]</span><span class="o">==</span><span class="s1">&#39;发明授权&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
        <span class="n">data</span><span class="p">[</span><span class="s1">&#39;省份&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">prov</span>
        <span class="n">AI_Relatives_Patents</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">ai_panel_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">AI_Relatives_Patents</span><span class="p">)</span>
<span class="n">ai_panel_df</span><span class="o">.</span><span class="n">to_excel</span><span class="p">(</span><span class="s1">&#39;AI_panel.xlsx&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;记录数:&#39;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">ai_panel_df</span><span class="p">))</span>
<span class="n">ai_panel_df</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">3571万专利申请全量数据1985-2022年/内蒙古自治区.csv.gzip
3571万专利申请全量数据1985-2022年/吉林省.csv.gzip
......
3571万专利申请全量数据1985-2022年/宁夏回族自治区.csv.gzip
3571万专利申请全量数据1985-2022年/广西壮族自治区.csv.gzip

记录数: 394
CPU times: user 12min 40s, sys: 1min 1s, total: 13min 41s
Wall time: 13min 42s
</code></pre></div><p><img loading="lazy" src="img/04-df.png" alt=""  />
</p>
<br>
<h3 id="39-剔除重复">3.9 剔除重复</h3>
<p>AI_details.csv 会有一些重复内容，可以剔除重复内容，删除旧文件，导出新的不重复的文件。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">os</span>

<span class="n">AI_detail_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;AI_details.csv&#39;</span><span class="p">)</span>
<span class="n">AI_detail_df</span> <span class="o">=</span> <span class="n">AI_detail_df</span><span class="p">[</span><span class="n">AI_detail_df</span><span class="p">[</span><span class="s1">&#39;专利公开号&#39;</span><span class="p">]</span><span class="o">!=</span><span class="s1">&#39;专利公开号&#39;</span><span class="p">]</span>
<span class="n">AI_detail_df</span><span class="o">.</span><span class="n">drop_duplicates</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">os</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="s2">&#34;AI_details.csv&#34;</span><span class="p">)</span>
<span class="n">AI_detail_df</span><span class="o">.</span><span class="n">to_excel</span><span class="p">(</span><span class="s2">&#34;AI_details.xlsx&#34;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</code></pre></div><p><br><br></p>
<h3 id="四汇总代码">四、汇总代码</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">glob</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>


<span class="n">AI_rela_words</span> <span class="o">=</span> <span class="s1">&#39;人工智能|机器学习|AI|NLP|智能问答|智能问答|神经机器翻译|NLU|增量学习&#39;</span>

<span class="c1">#剔除港、澳、台、海外</span>
<span class="n">not_in</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;3571万专利申请全量数据1985-2022年/台湾省.csv.gzip&#39;</span><span class="p">,</span>
          <span class="s1">&#39;3571万专利申请全量数据1985-2022年/澳门特别行政区.csv.gzip&#39;</span><span class="p">,</span> 
          <span class="s1">&#39;3571万专利申请全量数据1985-2022年/香港特别行政区.csv.gzip&#39;</span><span class="p">,</span> 
          <span class="s1">&#39;3571万专利申请全量数据1985-2022年/其他国家.csv.gzip&#39;</span><span class="p">]</span>
<span class="n">files</span> <span class="o">=</span> <span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="s1">&#39;3571万专利申请全量数据1985-2022年/*.csv.gzip&#39;</span><span class="p">)</span>
<span class="n">files</span> <span class="o">=</span> <span class="p">[</span><span class="n">f</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">files</span> <span class="k">if</span> <span class="n">f</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">not_in</span><span class="p">]</span>


<span class="n">AI_Relatives_Patents</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">file</span> <span class="ow">in</span> <span class="n">files</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">file</span><span class="p">)</span>
    <span class="n">prov</span> <span class="o">=</span> <span class="n">file</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;/&#39;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;.csv.gzip&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">)</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">file</span><span class="p">,</span> <span class="n">compression</span><span class="o">=</span><span class="s1">&#39;gzip&#39;</span><span class="p">)</span>
    
    <span class="c1">#筛选出AI专利</span>
    <span class="n">mask1</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;专利名称&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="n">AI_rela_words</span><span class="p">)</span>
    <span class="n">mask2</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;专利摘要&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="n">AI_rela_words</span><span class="p">)</span>
    <span class="n">ai_df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">mask1</span> <span class="o">&amp;</span> <span class="n">mask2</span><span class="p">]</span>
    
    <span class="c1">#保存全国AI专利详情信息</span>
    <span class="n">ai_df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;AI_details.csv&#39;</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    
    <span class="n">ai_df</span><span class="p">[</span><span class="s1">&#39;year&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">ai_df</span><span class="p">[</span><span class="s2">&#34;申请日&#34;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">d</span><span class="p">:</span><span class="n">d</span><span class="p">[:</span><span class="mi">4</span><span class="p">])</span>
    <span class="k">for</span> <span class="n">year</span><span class="p">,</span> <span class="n">ai_year_df</span> <span class="ow">in</span> <span class="n">ai_df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;year&#39;</span><span class="p">):</span>
        <span class="n">data</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
        <span class="n">data</span><span class="p">[</span><span class="s1">&#39;年度&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">year</span>
        <span class="n">data</span><span class="p">[</span><span class="s1">&#39;实用新型&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">ai_year_df</span><span class="p">[</span><span class="s1">&#39;专利类型&#39;</span><span class="p">]</span><span class="o">==</span><span class="s1">&#39;实用新型&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
        <span class="n">data</span><span class="p">[</span><span class="s1">&#39;发明公开&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">ai_year_df</span><span class="p">[</span><span class="s1">&#39;专利类型&#39;</span><span class="p">]</span><span class="o">==</span><span class="s1">&#39;发明公开&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
        <span class="n">data</span><span class="p">[</span><span class="s1">&#39;外观设计&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">ai_year_df</span><span class="p">[</span><span class="s1">&#39;专利类型&#39;</span><span class="p">]</span><span class="o">==</span><span class="s1">&#39;外观设计&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
        <span class="n">data</span><span class="p">[</span><span class="s1">&#39;发明授权&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">ai_year_df</span><span class="p">[</span><span class="s1">&#39;专利类型&#39;</span><span class="p">]</span><span class="o">==</span><span class="s1">&#39;发明授权&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
        <span class="n">data</span><span class="p">[</span><span class="s1">&#39;省份&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">prov</span>
        <span class="n">AI_Relatives_Patents</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    

<span class="n">china_ai_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">AI_Relatives_Patents</span><span class="p">)</span>
<span class="n">china_ai_df</span><span class="o">.</span><span class="n">to_excel</span><span class="p">(</span><span class="s1">&#39;AI_panel.xlsx&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>


<span class="n">AI_detail_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;AI_details.csv&#39;</span><span class="p">)</span>
<span class="n">AI_detail_df</span> <span class="o">=</span> <span class="n">AI_detail_df</span><span class="p">[</span><span class="n">AI_detail_df</span><span class="p">[</span><span class="s1">&#39;专利公开号&#39;</span><span class="p">]</span><span class="o">!=</span><span class="s1">&#39;专利公开号&#39;</span><span class="p">]</span>
<span class="n">AI_detail_df</span><span class="o">.</span><span class="n">drop_duplicates</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">os</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="s2">&#34;AI_details.csv&#34;</span><span class="p">)</span>
<span class="n">AI_detail_df</span><span class="o">.</span><span class="n">to_excel</span><span class="p">(</span><span class="s2">&#34;AI_details.xlsx&#34;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</code></pre></div><p><br><br></p>
<h2 id="五欣赏下成品">五、欣赏下成品</h2>
<ul>
<li><a href="AI_panel.xlsx">点击下载AI_panel.xlsx</a></li>
<li><a href="AI_details.xlsx">点击下载AI_details.xlsx</a></li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">ai_panel_df2</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;AI_panel.csv&#39;</span><span class="p">)</span>
<span class="n">ai_panel_df2</span>
</code></pre></div><p><img loading="lazy" src="img/02-df.png" alt=""  />
</p>
<br>
<p>更多数据集，可点击前往 <a href="https://textdata.cn/blog/datasets_available_for_management_science/">LIST | 可供社科(经管)领域使用的数据集汇总</a></p>
<br>
<br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>代码 | 使用「新闻数据」构造概念词提及量「面板数据」</title>
      <link>https://textdata.cn/blog/2023-12-18-how-to-generate-panel-data-from-daily-news-dataset/</link>
      <pubDate>Sun, 17 Dec 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-12-18-how-to-generate-panel-data-from-daily-news-dataset/</guid>
      <description>使用新闻联播、经济日报、人民日报，生成某「个体」关于「某概念词频」的「面板数据」</description>
      <content:encoded><![CDATA[<h2 id="一任务">一、任务</h2>
<p><a href="https://textdata.cn/blog/2023-12-14-daily-news-dataset/">新闻数据集 | 含 人民日报/经济日报/光明日报 等 7 家媒体(2023.12.18)</a></p>
<p><a href="https://textdata.cn/blog/2023-02-26-cctv1-xwlb-news-text-dataset/">数据集(付费) | cctv新闻联播文稿数据集</a></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">- 500元  jjrb&amp;rmrb 
- 600元   jjrb &amp; rmrb &amp; xwlb 

加微信 372335839， 备注「姓名-学校-专业」
</code></pre></div><br>
<p>利用 jjrb和rmrb 这两套数据集，可以生成面板数据，字段有</p>
<ul>
<li><strong>Object</strong> 提及的概念词(Object)，可以是某类概念词(创新/三农) 或 行为主体(省、市、公司法人）。</li>
<li><strong>Date</strong> 日期， 粒度可以是年(月、周、日)</li>
<li><strong>MentionTimes</strong>  在Date期间，提及概念词(Object)的新闻条数</li>
<li><strong>MentionRatio</strong>  在Date期间，提及概念词(Object)的新闻条数/总新闻条数</li>
</ul>
<p>今天利用该数据集， 生成 <code>省份、日期(周/天）、提及该省新闻次数、提及该省新闻占比</code> 面板数据。</p>
<p><img loading="lazy" src="img/06-panel.png" alt=""  />
</p>
<p><img loading="lazy" src="img/07-plot.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="二数据操作">二、数据操作</h2>
<h3 id="21-原始数据格式">2.1 原始数据格式</h3>
<p>今天更新这两个数据集， 增加 <strong>jjrb.csv.gzip</strong> 和 <strong>rmrb.csv.gzip</strong>。 已购买 jjrb &amp; rmrb 的同学，可以微信 37233539 ，来获取这两个文件。</p>
<br>
<h3 id="22-读取jjrbrmrb">2.2 读取jjrb&amp;rmrb</h3>
<p>pandas可以直接读取 jjrb.csv.gzip 和 rmrb.csv.gzip 压缩文件，且这样读取的速度是比 jjrb.csv 和 rmrb.csv 要更快的。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">jjrb_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;jjrb.csv.gzip&#39;</span><span class="p">,</span> <span class="n">compression</span><span class="o">=</span><span class="s1">&#39;gzip&#39;</span><span class="p">)</span>
<span class="n">rmrb_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;rmrb.csv.gzip&#39;</span><span class="p">,</span> <span class="n">compression</span><span class="o">=</span><span class="s1">&#39;gzip&#39;</span><span class="p">)</span>

<span class="n">jjrb_df</span><span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">jjrb_df</span><span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">])</span>
<span class="n">rmrb_df</span><span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">rmrb_df</span><span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">])</span>
</code></pre></div><br>
<h3 id="23-数据集概况">2.3 数据集概况</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python">
<span class="c1">#查看前5条</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;【jjrb】&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;   日期覆盖: &#39;</span><span class="p">,</span> <span class="n">jjrb_df</span><span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">()</span><span class="o">.</span><span class="n">date</span><span class="p">(),</span> <span class="s1">&#39;~&#39;</span> <span class="p">,</span> <span class="n">jjrb_df</span><span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">.</span><span class="n">date</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;   记录数: &#39;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">jjrb_df</span><span class="p">))</span>
<span class="nb">print</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;【rmrb】&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;   日期覆盖: &#39;</span><span class="p">,</span> <span class="n">rmrb_df</span><span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">()</span><span class="o">.</span><span class="n">date</span><span class="p">(),</span> <span class="s1">&#39;~&#39;</span> <span class="p">,</span> <span class="n">rmrb_df</span><span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">.</span><span class="n">date</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;   记录数: &#39;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">rmrb_df</span><span class="p">))</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">【jjrb】
   日期覆盖:  2008-01-27 ~ 2022-12-31
   记录数:  379221

【rmrb】
   日期覆盖:  1946-05-15 ~ 2023-08-10
   记录数:  2030839
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">jjrb_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/01-jjrb.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">rmrb_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/02-rmrb.png" alt=""  />
</p>
<br>
<br>
<h3 id="23-记录存储形式">2.3 记录存储形式</h3>
<p>这两个新闻数据， 任意日期(日)内一般都会有多条新闻记录， 每条新闻记录是以一行单独存储。</p>
<p>以 <strong>rmrb_df</strong> 为例， 查看 <strong>2013-06-08</strong> 新闻记录，可以看到有多条记录。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#任意日期</span>
<span class="n">rmrb_df</span><span class="p">[</span><span class="n">rmrb_df</span><span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">]</span><span class="o">==</span><span class="s1">&#39;2013-06-08&#39;</span><span class="p">]</span>
</code></pre></div><p><img loading="lazy" src="img/03-filter-date.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="三生成面板数据">三、生成面板数据</h2>
<p>因为 rmrb 和 jjrb 的数据格式基本一样，接下来以 rmrb 为例， 逐步生成 <code>省份、日期(年度）、提及该省新闻次数、提及该省新闻占比</code> 面板数据， 字段名定义为 <code>Object、Date、MentionTimes、MentionRatio</code>。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">provs</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;浙江省&#39;</span><span class="p">,</span> <span class="s1">&#39;山东省&#39;</span><span class="p">,</span> <span class="s1">&#39;新疆维吾尔族自治区&#39;</span><span class="p">,</span> <span class="s1">&#39;上海市&#39;</span><span class="p">,</span> <span class="s1">&#39;四川省&#39;</span><span class="p">,</span> <span class="s1">&#39;重庆市&#39;</span><span class="p">,</span> <span class="s1">&#39;海南省&#39;</span><span class="p">,</span> <span class="s1">&#39;河北省&#39;</span><span class="p">,</span>
       <span class="s1">&#39;广西壮族自治区&#39;</span><span class="p">,</span> <span class="s1">&#39;云南省&#39;</span><span class="p">,</span> <span class="s1">&#39;黑龙江省&#39;</span><span class="p">,</span> <span class="s1">&#39;河南省&#39;</span><span class="p">,</span> <span class="s1">&#39;内蒙古自治区&#39;</span><span class="p">,</span> <span class="s1">&#39;北京市&#39;</span><span class="p">,</span> <span class="s1">&#39;宁夏回族自治区&#39;</span><span class="p">,</span> <span class="s1">&#39;甘肃省&#39;</span><span class="p">,</span>
       <span class="s1">&#39;安徽省&#39;</span><span class="p">,</span> <span class="s1">&#39;吉林省&#39;</span><span class="p">,</span> <span class="s1">&#39;陕西省&#39;</span><span class="p">,</span> <span class="s1">&#39;湖北省&#39;</span><span class="p">,</span> <span class="s1">&#39;青海省&#39;</span><span class="p">,</span> <span class="s1">&#39;江西省&#39;</span><span class="p">,</span> <span class="s1">&#39;天津市&#39;</span><span class="p">,</span> <span class="s1">&#39;山西省&#39;</span><span class="p">,</span> <span class="s1">&#39;广东省&#39;</span><span class="p">,</span>
       <span class="s1">&#39;贵州省&#39;</span><span class="p">,</span> <span class="s1">&#39;福建省&#39;</span><span class="p">,</span> <span class="s1">&#39;西藏自治区&#39;</span><span class="p">,</span> <span class="s1">&#39;湖南省&#39;</span><span class="p">,</span> <span class="s1">&#39;江苏省&#39;</span><span class="p">,</span> <span class="s1">&#39;辽宁省&#39;</span><span class="p">]</span>


<span class="n">prov_date_counts</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">date</span><span class="p">,</span> <span class="n">weekly_df</span> <span class="ow">in</span> <span class="n">rmrb_df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">Grouper</span><span class="p">(</span><span class="n">key</span><span class="o">=</span><span class="s1">&#39;date&#39;</span><span class="p">,</span> <span class="n">freq</span><span class="o">=</span><span class="s1">&#39;Y&#39;</span><span class="p">)):</span>
    <span class="k">for</span> <span class="n">prov</span> <span class="ow">in</span> <span class="n">provs</span><span class="p">:</span>
        <span class="n">mention_times</span> <span class="o">=</span> <span class="n">weekly_df</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="n">prov</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
        <span class="n">data</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;Date&#39;</span><span class="p">:</span> <span class="n">date</span><span class="p">,</span> 
                <span class="s1">&#39;Object&#39;</span><span class="p">:</span> <span class="n">prov</span><span class="p">,</span> 
                <span class="s1">&#39;MentionTimes&#39;</span><span class="p">:</span> <span class="n">mention_times</span><span class="p">,</span>
                <span class="s1">&#39;MentionRatio&#39;</span><span class="p">:</span> <span class="n">mention_times</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">weekly_df</span><span class="p">)</span>
               <span class="p">}</span>
        <span class="n">prov_date_counts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        
<span class="n">panel_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">prov_date_counts</span><span class="p">)</span>
<span class="n">panel_df</span>
</code></pre></div><p><img loading="lazy" src="img/04-year-panel.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">panel_df</span><span class="p">[</span><span class="n">panel_df</span><span class="p">[</span><span class="s1">&#39;Object&#39;</span><span class="p">]</span><span class="o">==</span><span class="s1">&#39;浙江省&#39;</span><span class="p">]</span>
</code></pre></div><p><img loading="lazy" src="img/05-filter-prov.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="四封装代码">四、封装代码</h2>
<p>我封装了代码， 大家可以拿来直接用。 支持csv/xls/xlsx新闻类文件数据， 字段可设定，周期(年Y月M周W日D时H)可设定。</p>
<br>
<h3 id="41-generate_panel_data">4.1 generate_panel_data</h3>
<p>generate_panel_data(file, objects, text_field=&lsquo;text&rsquo;, date_field=&lsquo;date&rsquo;, encoding=&lsquo;utf-8&rsquo;, freq=&lsquo;W&rsquo;)</p>
<ul>
<li><strong>file</strong> 数据文件路径， .csv 或 .csv.gzip、xlsx、xls</li>
<li><strong>objects</strong> 支持list和dict</li>
<li><strong>text_field</strong> 指定数据文件中「文本」字段名，默认为&rsquo;text'</li>
<li><strong>date_field</strong> 指定数据文件中「日期」字段名，默认为&rsquo;date'</li>
<li><strong>freq</strong> 生成面板数据日期的周期， 年Y、月M、周W、日D、时H</li>
<li><strong>encoding</strong> 数据文件编码格式， 默认utf-8编码， 可能有的csv文件需要调整该参数</li>
</ul>
<p>返回<strong>DataFrame</strong>，DataFrame字段含 <strong>Date</strong>、<strong>Object</strong>、<strong>MentionTimes</strong>、<strong>MentionRatio</strong></p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">generate_panel_data</span><span class="p">(</span><span class="n">file</span><span class="p">,</span> <span class="n">objects</span><span class="p">,</span> <span class="n">text_field</span><span class="o">=</span><span class="s1">&#39;text&#39;</span><span class="p">,</span> <span class="n">date_field</span><span class="o">=</span><span class="s1">&#39;date&#39;</span><span class="p">,</span> <span class="n">freq</span><span class="o">=</span><span class="s1">&#39;W&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">):</span>
    <span class="s2">&#34;&#34;&#34;
</span><span class="s2">    - file 数据文件路径， .csv 或 .csv.gzip、xlsx、xls
</span><span class="s2">    - objects 支持list和dict
</span><span class="s2">    - text_field 指定数据文件中「文本」字段名，默认为&#39;text&#39;
</span><span class="s2">    - date_field 指定数据文件中「日期」字段名，默认为&#39;date&#39;
</span><span class="s2">    - freq 生成面板数据日期的周期， 年Y、月M、周W、日D、时H
</span><span class="s2">    - encoding 数据文件编码格式， 默认utf-8编码， 可能有的csv文件需要调整该参数
</span><span class="s2">
</span><span class="s2">    返回DataFrame，DataFrame字段含Date、Object、MentionTimes、MentionRatio
</span><span class="s2">    &#34;&#34;&#34;</span>
    
    <span class="c1">#读取数据文件</span>
    <span class="k">if</span> <span class="s1">&#39;csv&#39;</span> <span class="ow">in</span> <span class="n">file</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">file</span><span class="p">,</span> <span class="n">compression</span><span class="o">=</span><span class="s1">&#39;gzip&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="n">encoding</span><span class="p">)</span>
        <span class="k">except</span><span class="p">:</span>
            <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">file</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="n">encoding</span><span class="p">)</span>
    <span class="k">elif</span> <span class="s1">&#39;.xlsx&#39;</span> <span class="ow">in</span> <span class="n">file</span><span class="p">:</span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_excel</span><span class="p">(</span><span class="n">file</span><span class="p">)</span>
    <span class="k">elif</span> <span class="s1">&#39;.xsx&#39;</span> <span class="ow">in</span> <span class="n">file</span><span class="p">:</span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_excel</span><span class="p">(</span><span class="n">file</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&#34;目前只支持csv、xlsx、xlsx三种文件格式&#34;</span><span class="p">)</span> 

        
    <span class="c1">#更改日期格式</span>
    <span class="n">df</span><span class="p">[</span><span class="n">date_field</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">date_field</span><span class="p">])</span>
    <span class="n">prov_date_counts</span> <span class="o">=</span> <span class="p">[]</span>
    
    <span class="c1">#构造面板数据</span>
    <span class="k">for</span> <span class="n">date</span><span class="p">,</span> <span class="n">freq_df</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">Grouper</span><span class="p">(</span><span class="n">key</span><span class="o">=</span><span class="n">date_field</span><span class="p">,</span> <span class="n">freq</span><span class="o">=</span><span class="n">freq</span><span class="p">)):</span>
        
        <span class="c1">#objects为list的操作</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">objects</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">obj</span> <span class="ow">in</span> <span class="n">objects</span><span class="p">:</span>
                <span class="c1">#统计出现obj新闻的次数</span>
                <span class="n">mention_times</span> <span class="o">=</span> <span class="n">freq_df</span><span class="p">[</span><span class="n">text_field</span><span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="n">obj</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
                <span class="n">data</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;Date&#39;</span><span class="p">:</span> <span class="n">date</span><span class="p">,</span> 
                        <span class="s1">&#39;Object&#39;</span><span class="p">:</span> <span class="n">obj</span><span class="p">,</span> 
                        <span class="s1">&#39;MentionTimes&#39;</span><span class="p">:</span> <span class="n">mention_times</span><span class="p">,</span>
                        <span class="s1">&#39;MentionRatio&#39;</span><span class="p">:</span> <span class="n">mention_times</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">freq_df</span><span class="p">)}</span>
                <span class="n">prov_date_counts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
                
        <span class="c1">#objects为dict的操作</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">objects</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">words</span> <span class="ow">in</span> <span class="n">objects</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="c1">#统计某概念词words出现的新闻的条数，等同于object出现次数。</span>
                <span class="n">mention_words_times</span> <span class="o">=</span> <span class="n">freq_df</span><span class="p">[</span><span class="n">text_field</span><span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="s1">&#39;|&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">words</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
                <span class="n">data</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;Date&#39;</span><span class="p">:</span> <span class="n">date</span><span class="p">,</span> 
                        <span class="s1">&#39;Object&#39;</span><span class="p">:</span> <span class="n">key</span><span class="p">,</span> 
                        <span class="s1">&#39;MentionTimes&#39;</span><span class="p">:</span> <span class="n">mention_words_times</span><span class="p">,</span>
                        <span class="s1">&#39;MentionRatio&#39;</span><span class="p">:</span> <span class="n">mention_words_times</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">freq_df</span><span class="p">)}</span>
                <span class="n">prov_date_counts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
                
        <span class="k">else</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;传入的objects参数有问题， 该参数必须是列表或字典&#39;</span><span class="p">)</span>
            <span class="k">break</span>
    <span class="n">panel_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">prov_date_counts</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">panel_df</span>
</code></pre></div><br>
<h3 id="42-plot_figure">4.2 plot_figure</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">plot_figure</span><span class="p">(</span><span class="n">panel_df</span><span class="p">,</span> <span class="n">title</span><span class="p">,</span> <span class="n">object_field</span><span class="o">=</span><span class="s1">&#39;Object&#39;</span><span class="p">,</span> <span class="n">date_field</span><span class="o">=</span><span class="s1">&#39;Date&#39;</span><span class="p">,</span> <span class="n">value_filed</span><span class="o">=</span><span class="s1">&#39;MentionRatio&#39;</span><span class="p">):</span>
    <span class="s2">&#34;&#34;&#34;
</span><span class="s2">    panel_df:  面板数据
</span><span class="s2">    title:  折线图标题
</span><span class="s2">    date_field: panel_df中的日期字段
</span><span class="s2">    value_filed: panel_df中的要绘图的值的字段名
</span><span class="s2">    &#34;&#34;&#34;</span>
    <span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
    <span class="kn">import</span> <span class="nn">matplotlib</span>
    <span class="kn">import</span> <span class="nn">scienceplots</span>
    <span class="kn">import</span> <span class="nn">platform</span>
    <span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
    <span class="kn">import</span> <span class="nn">matplotlib_inline</span>
    <span class="n">matplotlib_inline</span><span class="o">.</span><span class="n">backend_inline</span><span class="o">.</span><span class="n">set_matplotlib_formats</span><span class="p">(</span><span class="s1">&#39;png&#39;</span><span class="p">,</span> <span class="s1">&#39;svg&#39;</span><span class="p">)</span>
    <span class="kn">import</span> <span class="nn">jieba</span>
    <span class="kn">import</span> <span class="nn">warnings</span>
    <span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">([</span><span class="s1">&#39;science&#39;</span><span class="p">,</span> <span class="s1">&#39;no-latex&#39;</span><span class="p">,</span> <span class="s1">&#39;cjk-sc-font&#39;</span><span class="p">])</span>
    <span class="n">system</span> <span class="o">=</span> <span class="n">platform</span><span class="o">.</span><span class="n">system</span><span class="p">()</span>  <span class="c1"># 获取操作系统类型</span>
    <span class="k">if</span> <span class="n">system</span> <span class="o">==</span> <span class="s1">&#39;Windows&#39;</span><span class="p">:</span>
        <span class="n">font</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;family&#39;</span><span class="p">:</span> <span class="s1">&#39;SimHei&#39;</span><span class="p">}</span>
    <span class="k">elif</span> <span class="n">system</span> <span class="o">==</span> <span class="s1">&#39;Darwin&#39;</span><span class="p">:</span>
        <span class="n">font</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;family&#39;</span><span class="p">:</span> <span class="s1">&#39;Arial Unicode MS&#39;</span><span class="p">}</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">font</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;family&#39;</span><span class="p">:</span> <span class="s1">&#39;sans-serif&#39;</span><span class="p">}</span>
    <span class="n">matplotlib</span><span class="o">.</span><span class="n">rc</span><span class="p">(</span><span class="s1">&#39;font&#39;</span><span class="p">,</span> <span class="o">**</span><span class="n">font</span><span class="p">)</span>  <span class="c1"># 设置全局字体</span>
    <span class="n">panel_df</span><span class="p">[</span><span class="n">date_field</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">panel_df</span><span class="p">[</span><span class="n">date_field</span><span class="p">])</span>
    
    <span class="n">new_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">pivot_table</span><span class="p">(</span><span class="n">panel_df</span><span class="p">,</span> 
                            <span class="n">index</span><span class="o">=</span><span class="n">date_field</span><span class="p">,</span>
                            <span class="n">columns</span><span class="o">=</span><span class="n">object_field</span><span class="p">,</span>
                            <span class="n">values</span><span class="o">=</span><span class="n">value_filed</span><span class="p">)</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">new_df</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
    <span class="c1"># 添加图例，并指定位置和偏移</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper right&#39;</span><span class="p">,</span> <span class="n">bbox_to_anchor</span><span class="o">=</span><span class="p">(</span><span class="mf">1.15</span><span class="p">,</span> <span class="mf">1.05</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">title</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;年份&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">13</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;新闻提及次数&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">13</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div><br>
<h3 id="43-objects为列表">4.3 objects为列表</h3>
<p>现在假设我拿到一个csv文件， 知道内部有date、text两个字段，现在我想得到提及 四省的新闻次数的面板数据，周期为月份</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">provs2</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;山东省&#39;</span><span class="p">,</span> <span class="s1">&#39;河北省&#39;</span><span class="p">,</span> <span class="s1">&#39;湖南省&#39;</span><span class="p">,</span> <span class="s1">&#39;黑龙江省&#39;</span><span class="p">]</span>
<span class="n">panel_df2</span> <span class="o">=</span> <span class="n">generate_panel_data</span><span class="p">(</span><span class="n">file</span><span class="o">=</span><span class="s1">&#39;rmrb.csv.gzip&#39;</span><span class="p">,</span> 
                                <span class="n">objects</span><span class="o">=</span><span class="n">provs2</span><span class="p">,</span> 
                                <span class="c1">#实验数据csv文件的日期字段为text</span>
                                <span class="n">text_field</span><span class="o">=</span><span class="s1">&#39;text&#39;</span><span class="p">,</span>  
                                 <span class="c1">#实验数据csv文件的日期字段为date</span>
                                <span class="n">date_field</span><span class="o">=</span><span class="s1">&#39;date&#39;</span><span class="p">,</span> 
                                <span class="n">freq</span><span class="o">=</span><span class="s1">&#39;Y&#39;</span><span class="p">,</span>  <span class="c1">#年度</span>
                                <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span>
<span class="c1">#panel_df2.to_csv(&#39;RMRB新闻鲁冀湘黑四省(objects为列表)年度被提及占比.csv&#39;, index=False)</span>

<span class="n">panel_df2</span>
</code></pre></div><p><img loading="lazy" src="img/06-panel.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">plot_figure</span><span class="p">(</span><span class="n">panel_df</span><span class="o">=</span><span class="n">panel_df2</span><span class="p">,</span> 
            <span class="n">title</span><span class="o">=</span><span class="s1">&#39;RMRB新闻鲁、冀、湘、黑四省年度被提及占比(1946-2023)&#39;</span><span class="p">,</span> 
            <span class="n">object_field</span><span class="o">=</span><span class="s1">&#39;Object&#39;</span><span class="p">,</span> 
            <span class="n">date_field</span><span class="o">=</span><span class="s1">&#39;Date&#39;</span><span class="p">,</span> 
            <span class="n">value_filed</span><span class="o">=</span><span class="s1">&#39;MentionRatio&#39;</span><span class="p">)</span>
</code></pre></div><p><img loading="lazy" src="img/07-plot.png" alt=""  />
</p>
<br>
<h3 id="44-objects为字典">4.4 objects为字典</h3>
<p>现在假设我拿到一个csv文件， 知道内部有date、text两个字段，现在我想得到提及 三类概念词 新闻次数的面板数据，周期为月份</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#数据整理比较粗糙，大家能get到我的意思即可</span>
<span class="n">provs3</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;经济发展&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;经济&#39;</span><span class="p">,</span> <span class="s1">&#39;发展&#39;</span><span class="p">,</span> <span class="s1">&#39;建设&#39;</span><span class="p">,</span> <span class="s1">&#39;经济发展&#39;</span><span class="p">],</span> 
          <span class="s1">&#39;环境保护&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;环境保护&#39;</span><span class="p">,</span> <span class="s1">&#39;保护环境&#39;</span><span class="p">,</span> <span class="s1">&#39;绿水青山&#39;</span><span class="p">],</span>
          <span class="s1">&#39;司法建设&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;法律&#39;</span><span class="p">,</span> <span class="s1">&#39;司法&#39;</span><span class="p">,</span> <span class="s1">&#39;司法建设&#39;</span><span class="p">],</span>
        <span class="p">}</span>


<span class="n">panel_df3</span> <span class="o">=</span> <span class="n">generate_panel_data</span><span class="p">(</span><span class="n">file</span><span class="o">=</span><span class="s1">&#39;rmrb.csv.gzip&#39;</span><span class="p">,</span> 
                                <span class="n">objects</span><span class="o">=</span><span class="n">provs3</span><span class="p">,</span> 
                                <span class="c1">#实验数据csv文件的日期字段为text</span>
                                <span class="n">text_field</span><span class="o">=</span><span class="s1">&#39;text&#39;</span><span class="p">,</span>  
                                 <span class="c1">#实验数据csv文件的日期字段为date</span>
                                <span class="n">date_field</span><span class="o">=</span><span class="s1">&#39;date&#39;</span><span class="p">,</span> 
                                <span class="n">freq</span><span class="o">=</span><span class="s1">&#39;Y&#39;</span><span class="p">,</span>  <span class="c1">#年度</span>
                                <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span>
<span class="c1">#panel_df3.to_csv(&#39;RMRB新闻三概念词(objects为字典)年度被提及占比.csv&#39;, index=False)</span>
<span class="n">panel_df3</span>
</code></pre></div><p><img loading="lazy" src="img/08-panel.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">plot_figure</span><span class="p">(</span><span class="n">panel_df</span><span class="o">=</span><span class="n">panel_df3</span><span class="p">,</span> 
            <span class="n">title</span><span class="o">=</span><span class="s1">&#39;RMRB新闻经济、环境、司法三类概念词年度被提及占比(1946-2023)&#39;</span><span class="p">,</span> 
            <span class="n">object_field</span><span class="o">=</span><span class="s1">&#39;Object&#39;</span><span class="p">,</span> 
            <span class="n">date_field</span><span class="o">=</span><span class="s1">&#39;Date&#39;</span><span class="p">,</span> 
            <span class="n">value_filed</span><span class="o">=</span><span class="s1">&#39;MentionRatio&#39;</span><span class="p">)</span>
</code></pre></div><p><img loading="lazy" src="img/09-plot.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="四获取数据集">四、获取数据集</h2>
<p><a href="https://textdata.cn/blog/2023-12-14-daily-news-dataset/">新闻数据集 | 含 人民日报/经济日报/光明日报 等 7 家媒体(2023.12.18)</a></p>
<p><a href="https://textdata.cn/blog/2023-02-26-cctv1-xwlb-news-text-dataset/">数据集(付费) | cctv新闻联播文稿数据集</a></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">加微信 372335839， 备注「姓名-学校-专业」
</code></pre></div><br>
<p>更多数据集，可点击前往 <a href="https://textdata.cn/blog/datasets_available_for_management_science/">LIST | 可供社科(经管)领域使用的数据集汇总</a></p>
<br>
<br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>代码 | 使用「新闻数据」计算 「经济政策不确定性」指数</title>
      <link>https://textdata.cn/blog/2023-12-20-measure-china-economic-policy-uncertainty/</link>
      <pubDate>Sun, 17 Dec 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-12-20-measure-china-economic-policy-uncertainty/</guid>
      <description>使用新闻联播、经济日报、人民日报，计算经济政策不确定性指数</description>
      <content:encoded><![CDATA[<h2 id="一经济政策不确定性指标">一、经济政策不确定性指标</h2>
<p>经济政策不确定性(Economic Policy Uncertainty, EPU) 通常是用来衡量经济中政策不确定性水平的一种度量方式。 本文参考</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">Huang, Yun, and Paul Luk. &#34;Measuring economic policy uncertainty in China.&#34; China Economic Review 59 (2020): 101367
</code></pre></div><br>
<h3 id="11-新闻数据库">1.1 新闻数据库</h3>
<p><a href="https://textdata.cn/blog/2023-12-14-daily-news-dataset/">新闻数据集 | 含 人民日报/经济日报/光明日报 等 7 家媒体(2023.12.18)</a></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">人民日报rmrb:       1946-05-15 ~ 2023-12-18
光明日报gmrb:       1985-01-01 ~ 2023-12-18
人民政协报rmzxb:     2008-01-02 ~ 2023-12-18
经济日报jjrb:       2008-01-27 ~ 2023-12-18
中国青年报zqb:     2005-01-01 ~ 2023-12-18
南方周末nfzm:       2008-01-02 ~ 2023-5-31
</code></pre></div><br>
<h3 id="12-算法">1.2 算法</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">Step-1. 选择了114家中国大陆的报纸，其中包括北京、上海、广州和天津等主要城市的报纸。
Step-2. 对于每家报纸，搜索包含以下三个关键词之一的文章：经济、不确定性和政策。这些关键词的中文和英文对照可以在论文的表格1中找到。
Step-3. 将每个月的文章数量按照满足第一个关键词的文章数量进行缩放。
Step-4. 将时间序列标准化，使其在2000年1月至2011年12月期间的标准差为1。 保证所有媒体计算得到的epu是可比的。
Step-5. 对十家报纸的月度序列进行简单平均，并将指标归一化，使其在2000年1月至2011年12月期间的平均值为100。
</code></pre></div><p>如果是利用一个媒体进行 类 EPU 指标的构建， 只需用到算法中的前 3 个步骤。</p>
<p><br><br></p>
<h2 id="二基本知识">二、基本知识</h2>
<h3 id="21-查看数据">2.1 查看数据</h3>
<p>大邓的 <a href="https://textdata.cn/blog/2023-12-14-daily-news-dataset/"><strong>新闻数据集 | 含 人民日报/经济日报/光明日报 等 7 家媒体(2023.12.18)</strong></a>中的所有媒体， 均有csv格式， 内含 date 和 text 两个字段， csv中的每行是一条新闻。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;rmrb.csv.gzip&#39;</span><span class="p">,</span> <span class="n">compression</span><span class="o">=</span><span class="s1">&#39;gzip&#39;</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/01-df.png" alt=""  />
</p>
<br>
<h3 id="22-日期转化">2.2 日期转化</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df</span><span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;人民日报: &#39;</span><span class="p">,</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">()</span><span class="o">.</span><span class="n">date</span><span class="p">(),</span> <span class="s1">&#39;~&#39;</span><span class="p">,</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">.</span><span class="n">date</span><span class="p">())</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">人民日报:  1946-05-15 ~ 2023-12-18
</code></pre></div><br>
<h3 id="23-按日期进行分组">2.3 按日期进行分组</h3>
<p>使用日期进行分组， 常见的周期是年Y、月M、日D。 以 <code>df.groupby(pd.Grouper(key='date', freq='M'))</code> 为例， 会得到不同 year-month 及对应的dataframe 。观察 freq 设置成 Y、M、D， 代码运行结果，理解代码字段名含义。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="k">for</span> <span class="n">date</span><span class="p">,</span> <span class="n">Yfreq_df</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">Grouper</span><span class="p">(</span><span class="n">key</span><span class="o">=</span><span class="s1">&#39;date&#39;</span><span class="p">,</span> <span class="n">freq</span><span class="o">=</span><span class="s1">&#39;Y&#39;</span><span class="p">)):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">date</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="n">Yfreq_df</span><span class="p">))</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">1946-12-31 00:00:00 &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
1947-12-31 00:00:00 &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
1948-12-31 00:00:00 &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
1949-12-31 00:00:00 &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
1950-12-31 00:00:00 &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
1951-12-31 00:00:00 &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
1952-12-31 00:00:00 &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
......
2016-12-31 00:00:00 &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
2017-12-31 00:00:00 &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
2018-12-31 00:00:00 &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
2019-12-31 00:00:00 &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
2020-12-31 00:00:00 &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
2021-12-31 00:00:00 &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
2022-12-31 00:00:00 &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
2023-12-31 00:00:00 &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="k">for</span> <span class="n">date</span><span class="p">,</span> <span class="n">Mfreq_df</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">Grouper</span><span class="p">(</span><span class="n">key</span><span class="o">=</span><span class="s1">&#39;date&#39;</span><span class="p">,</span> <span class="n">freq</span><span class="o">=</span><span class="s1">&#39;M&#39;</span><span class="p">)):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">date</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="n">Mfreq_df</span><span class="p">))</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">1946-05-31 00:00:00 &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
1946-06-30 00:00:00 &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
1946-07-31 00:00:00 &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
1946-08-31 00:00:00 &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
1946-09-30 00:00:00 &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
1946-10-31 00:00:00 &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
1946-11-30 00:00:00 &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
......
2023-05-31 00:00:00 &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
2023-06-30 00:00:00 &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
2023-07-31 00:00:00 &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
2023-08-31 00:00:00 &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
2023-09-30 00:00:00 &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
2023-10-31 00:00:00 &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
2023-11-30 00:00:00 &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
2023-12-31 00:00:00 &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="k">for</span> <span class="n">date</span><span class="p">,</span> <span class="n">Dfreq_df</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">Grouper</span><span class="p">(</span><span class="n">key</span><span class="o">=</span><span class="s1">&#39;date&#39;</span><span class="p">,</span> <span class="n">freq</span><span class="o">=</span><span class="s1">&#39;D&#39;</span><span class="p">)):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">date</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="n">Dfreq_df</span><span class="p">))</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">1946-05-15 00:00:00 &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
1946-05-16 00:00:00 &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
1946-05-17 00:00:00 &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
1946-05-18 00:00:00 &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
1946-05-19 00:00:00 &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
1946-05-20 00:00:00 &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
1946-05-21 00:00:00 &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
......
2023-12-11 00:00:00 &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
2023-12-12 00:00:00 &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
2023-12-13 00:00:00 &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
2023-12-14 00:00:00 &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
2023-12-15 00:00:00 &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
2023-12-16 00:00:00 &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
2023-12-17 00:00:00 &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
2023-12-18 00:00:00 &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;

</code></pre></div><br>
<h3 id="24-文本操作">2.4 文本操作</h3>
<p>dataframe中字段如果是字符串格式， 可以用 .str属性， 该str属性具有以下特色功能。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">#某词
word_pattern1 = &#39;不确定&#39;
#某类词
word_pattern2 = &#39;不确定|不明确|波动|震荡&#39;

#是否含某词   
df[&#39;text&#39;].str.contains(word_pattern1)  
#是否含某类词   
df[&#39;text&#39;].str.contains(word_pattern2)  

#某词出现的次数 
df[&#39;text&#39;].str.count(word_pattern1)  


#某类词出现的次数 
df[&#39;text&#39;].str.count(word_pattern2)  
</code></pre></div><p>在 EPU 的计算中，使用的是contains。另外  即可以是</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">uncertainty_pattern</span> <span class="o">=</span> <span class="s1">&#39;不确定|不明确|波动|震荡|动荡|不稳|未明|不明朗|不清晰|未清晰|难料|难以预料|难以预测|难以预计|难以估计|无法预料|无法预测|无法预计|无法估计|不可预料|不可预测|不可预计|不可估计&#39;</span>


<span class="c1">#每条新闻是否出现 uncertainty_pattern ， 出现True，不出现False</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="n">uncertainty_pattern</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">0          False
1          False
2          False
3          False
4          False
           ...  
2014656    False
2014657    False
2014658    False
2014659    False
2014660    False
Name: text, Length: 2014661, dtype: bool
</code></pre></div><br>
<br>
<p>通过加总True的个数，得到出现 uncertainty_pattern 的新闻记录数</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="n">uncertainty_pattern</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">56358
</code></pre></div><br>
<h3 id="24-布尔值的计算">2.4 布尔值的计算</h3>
<p><em><strong>逻辑且</strong></em> 操作，</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">economic_pattern</span> <span class="o">=</span> <span class="s1">&#39;经济|金融&#39;</span>
<span class="n">uncertainty_pattern</span> <span class="o">=</span> <span class="s1">&#39;不确定|不明确|波动|震荡|动荡|不稳|未明|不明朗|不清晰|未清晰|难料|难以预料|难以预测|难以预计|难以估计|无法预料|无法预测|无法预计|无法估计|不可预料|不可预测|不可预计|不可估计&#39;</span>
<span class="n">policy_pattern</span> <span class="o">=</span> <span class="s1">&#39;政策|制度|体制|战略|措施|规章|规例|条例|政治|执政|政府|政委|国务院|人大|人民代表大会|中央|国家主席|总书记|国家领导人|总理|改革|整改|整治|规管|监管|财政|税|人民银行|央行|赤字|利率&#39;</span>
    
<span class="n">economic_mask</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="n">economic_pattern</span><span class="p">)</span>
<span class="n">policy_mask</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="n">policy_pattern</span><span class="p">)</span>
<span class="n">uncertainty_mask</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="n">uncertainty_pattern</span><span class="p">)</span>


<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;enconomic新闻条数: &#39;</span><span class="p">,</span> <span class="n">economic_mask</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;policy新闻条数: &#39;</span><span class="p">,</span> <span class="n">policy_mask</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;uncertainty新闻条数: &#39;</span><span class="p">,</span> <span class="n">uncertainty_mask</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>

<span class="nb">print</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;enconomic&amp;policy同时出现条数: &#39;</span><span class="p">,</span> <span class="p">(</span><span class="n">economic_mask</span> <span class="o">&amp;</span> <span class="n">policy_mask</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;enconomic&amp;policy&amp;uncertainty同时出现条数: &#39;</span><span class="p">,</span> <span class="p">(</span><span class="n">economic_mask</span> <span class="o">&amp;</span> <span class="n">policy_mask</span> <span class="o">&amp;</span> <span class="n">uncertainty_mask</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">enconomic新闻条数:  617182
policy新闻条数:  1246681
uncertainty新闻条数:  56358

enconomic&amp;policy同时出现条数:  510791
enconomic&amp;policy&amp;uncertainty同时出现条数:  34332
</code></pre></div><h3 id="25-相关内容">2.5 相关内容</h3>
<p>用到以上操作的代码，通过本文以及这4个推文，巩固 pandas 操作知识点。</p>
<ul>
<li>
<p><a href="https://textdata.cn/blog/2023-12-17-how-to-generate-panel-data-from-gov-report-dataset/"><strong>代码 | 使用地方gov工作报告生成某类概念词频「面板数据」</strong></a></p>
</li>
<li>
<p><a href="https://textdata.cn/blog/2023-12-18-how-to-generate-panel-data-from-daily-news-dataset/"><strong>代码 | 使用「新闻数据」构造概念词提及量「面板数据」</strong></a></p>
</li>
<li>
<p><a href="https://textdata.cn/blog/2023-02-26-cctv1-xwlb-news-text-dataset/"><strong>数据代码| 使用cctv新闻联播文稿构造「面板数据」</strong></a></p>
</li>
<li>
<p><a href="https://textdata.cn/blog/2028-12-18-how-to-extract-data-from-patent-application-dataset/"><strong>代码 | 使用3571w专利申请数据集构造「面板数据」</strong></a></p>
</li>
</ul>
<p><br><br></p>
<h2 id="三epu计算函数">三、EPU计算函数</h2>
<p>有了以上基本知识，就可以使用大邓设计的 <em><strong>cal_epu_index</strong></em> 函数，该函数可针对任意一个新闻数据(csv格式) 计算 EPU 。</p>
<p>需要注意， 因为是对一个媒体进行计算，所以没有进行标准化和归一化。</p>
<p>所以媒体1、媒体2计算得到的两个 <em><strong>epu1</strong></em>、<em><strong>epu2</strong></em> 进行数值大小的比较是没有意义的。 如果你有多个媒体，计算得到多个 <em><strong>epu1</strong></em> 、<em><strong>epu2</strong></em>、 <em><strong>epu3</strong></em>， 想计算 <em><strong>mean_epu</strong></em> , 那么记得实现论文算法里的 <em><strong>step4</strong></em>， 再执行 <em><strong>step5</strong></em> 求均值。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">cal_epu_index</span><span class="p">(</span><span class="n">csvf</span><span class="p">,</span> <span class="n">freq</span><span class="o">=</span><span class="s1">&#39;M&#39;</span><span class="p">):</span>
    <span class="s2">&#34;&#34;&#34;
</span><span class="s2">    csvf  新闻csv文件的位置， 含date和text两个字段，每行是一条新闻
</span><span class="s2">    freq  epu的粒度， 年Y、月M、日D
</span><span class="s2">    
</span><span class="s2">    #economic、uncertainty、policy整理自
</span><span class="s2">    #Huang, Yun, and Paul Luk. &#34;Measuring economic policy uncertainty in China.&#34; China Economic Review 59 (2020): 101367
</span><span class="s2">    
</span><span class="s2">    返回dataFrame, 含字段date和epu
</span><span class="s2">    &#34;&#34;&#34;</span>
    <span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
    <span class="n">economic_pattern</span> <span class="o">=</span> <span class="s1">&#39;经济|金融&#39;</span>
    <span class="n">uncertainty_pattern</span> <span class="o">=</span> <span class="s1">&#39;不确定|不明确|波动|震荡|动荡|不稳|未明|不明朗|不清晰|未清晰|难料|难以预料|难以预测|难以预计|难以估计|无法预料|无法预测|无法预计|无法估计|不可预料|不可预测|不可预计|不可估计&#39;</span>
    <span class="n">policy_pattern</span> <span class="o">=</span> <span class="s1">&#39;政策|制度|体制|战略|措施|规章|规例|条例|政治|执政|政府|政委|国务院|人大|人民代表大会|中央|国家主席|总书记|国家领导人|总理|改革|整改|整治|规管|监管|财政|税|人民银行|央行|赤字|利率&#39;</span>
    
    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">csvf</span><span class="p">,</span> <span class="n">compression</span><span class="o">=</span><span class="s1">&#39;gzip&#39;</span><span class="p">)</span>
    <span class="n">df</span><span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">])</span>
    
    <span class="n">datas</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">date</span><span class="p">,</span> <span class="n">period_df</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">Grouper</span><span class="p">(</span><span class="n">key</span><span class="o">=</span><span class="s1">&#39;date&#39;</span><span class="p">,</span> <span class="n">freq</span><span class="o">=</span><span class="n">freq</span><span class="p">)):</span>
        <span class="n">data</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
        <span class="n">data</span><span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">date</span> <span class="c1">#month是datetime型日期，一般为每个月的最后一日</span>
        <span class="n">economic_mask</span> <span class="o">=</span> <span class="n">period_df</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="n">economic_pattern</span><span class="p">)</span>
        <span class="n">policy_mask</span> <span class="o">=</span> <span class="n">period_df</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="n">policy_pattern</span><span class="p">)</span>
        <span class="n">uncertainty_mask</span> <span class="o">=</span> <span class="n">period_df</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="n">uncertainty_pattern</span><span class="p">)</span>

        <span class="c1">#在出现经济词的新闻中，统计出现政策、不确定新的比例</span>
        <span class="n">data</span><span class="p">[</span><span class="s1">&#39;epu&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">economic_mask</span> <span class="o">&amp;</span> <span class="n">policy_mask</span> <span class="o">&amp;</span> <span class="n">uncertainty_mask</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">/</span> <span class="n">economic_mask</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
        <span class="n">datas</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="n">raw_epu_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">datas</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">raw_epu_df</span>
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#人民日报</span>
<span class="n">rmrb_EPU_df</span> <span class="o">=</span> <span class="n">cal_epu_index</span><span class="p">(</span><span class="n">csvf</span><span class="o">=</span><span class="s1">&#39;rmrb.csv.gzip&#39;</span><span class="p">,</span> <span class="n">freq</span><span class="o">=</span><span class="s1">&#39;M&#39;</span><span class="p">)</span>

<span class="c1">#保存结果</span>
<span class="c1">#rmrb_EPU_df.to_csv(&#39;rmrb_epu.csv&#39;, index=False)</span>
<span class="n">rmrb_EPU_df</span>
</code></pre></div><p><img loading="lazy" src="img/02-df.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">gmrb_EPU_df</span> <span class="o">=</span> <span class="n">cal_epu_index</span><span class="p">(</span><span class="n">csvf</span><span class="o">=</span><span class="s1">&#39;gmrb.csv.gzip&#39;</span><span class="p">,</span> <span class="n">freq</span><span class="o">=</span><span class="s1">&#39;M&#39;</span><span class="p">)</span>

<span class="c1">#保存结果</span>
<span class="c1">#gmrb_EPU_df.to_csv(&#39;gmrb_epu.csv&#39;, index=False)</span>
<span class="n">gmrb_EPU_df</span>
</code></pre></div><p><img loading="lazy" src="img/03-df.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="四可视化">四、可视化</h2>
<h3 id="41-dfplot">4.1 df.plot</h3>
<p>df.plot使用的前提是要将日期字段调整为index, 满足下面形态的数据可以使用.plot绘图</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">rmrb_EPU_df</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="s1">&#39;date&#39;</span><span class="p">)</span>
</code></pre></div><p><img loading="lazy" src="img/04-df.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">rmrb_EPU_df</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="s1">&#39;date&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">title</span><span class="o">=</span><span class="s1">&#39;EPU Index </span><span class="se">\n</span><span class="s1">source: China Renmin Daily News&#39;</span><span class="p">)</span>
</code></pre></div><p><img loading="lazy" src="img/05-fig.png" alt=""  />
</p>
<br>
<h3 id="42-支持中文">4.2 支持中文</h3>
<p>支持中文的代码，无脑copy</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">matplotlib</span>
<span class="kn">import</span> <span class="nn">scienceplots</span>
<span class="kn">import</span> <span class="nn">platform</span>
<span class="kn">import</span> <span class="nn">matplotlib_inline</span>
<span class="n">matplotlib_inline</span><span class="o">.</span><span class="n">backend_inline</span><span class="o">.</span><span class="n">set_matplotlib_formats</span><span class="p">(</span><span class="s1">&#39;png&#39;</span><span class="p">,</span> <span class="s1">&#39;svg&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">([</span><span class="s1">&#39;science&#39;</span><span class="p">,</span> <span class="s1">&#39;no-latex&#39;</span><span class="p">,</span> <span class="s1">&#39;cjk-sc-font&#39;</span><span class="p">])</span>
<span class="n">system</span> <span class="o">=</span> <span class="n">platform</span><span class="o">.</span><span class="n">system</span><span class="p">()</span>  <span class="c1"># 获取操作系统类型</span>
<span class="k">if</span> <span class="n">system</span> <span class="o">==</span> <span class="s1">&#39;Windows&#39;</span><span class="p">:</span>
    <span class="n">font</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;family&#39;</span><span class="p">:</span> <span class="s1">&#39;SimHei&#39;</span><span class="p">}</span>
<span class="k">elif</span> <span class="n">system</span> <span class="o">==</span> <span class="s1">&#39;Darwin&#39;</span><span class="p">:</span>
    <span class="n">font</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;family&#39;</span><span class="p">:</span> <span class="s1">&#39;Arial Unicode MS&#39;</span><span class="p">}</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">font</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;family&#39;</span><span class="p">:</span> <span class="s1">&#39;sans-serif&#39;</span><span class="p">}</span>
<span class="n">matplotlib</span><span class="o">.</span><span class="n">rc</span><span class="p">(</span><span class="s1">&#39;font&#39;</span><span class="p">,</span> <span class="o">**</span><span class="n">font</span><span class="p">)</span>  <span class="c1"># 设置全局字体</span>



<span class="n">rmrb_EPU_df</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="s1">&#39;date&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;经济政策不确定性EPU </span><span class="se">\n</span><span class="s1">source: 人民日报&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;年份&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">13</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;EPU值&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">13</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/06-fig.png" alt=""  />
</p>
<br>
<h3 id="43-比较两个媒体的走势">4.3 比较两个媒体的走势</h3>
<p>两个新闻媒体覆盖的时间段不同，</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">人民日报rmrb:       1946-05-15 ~ 2023-12-18
光明日报gmrb:       1985-01-01 ~ 2023-12-18
</code></pre></div><p>截取1985-01-01之后的数据，进行比较。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">rmrb_EPU_df2</span> <span class="o">=</span> <span class="n">rmrb_EPU_df</span><span class="p">[</span><span class="n">rmrb_EPU_df</span><span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">]</span><span class="o">&gt;</span><span class="s1">&#39;1985-01-01&#39;</span><span class="p">]</span>
<span class="n">gmrb_EPU_df2</span> <span class="o">=</span> <span class="n">gmrb_EPU_df</span><span class="p">[</span><span class="n">gmrb_EPU_df</span><span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">]</span><span class="o">&gt;</span><span class="s1">&#39;1985-01-01&#39;</span><span class="p">]</span>


<span class="n">rmrb_EPU_df2</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="s1">&#39;date&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;月度经济政策不确定性EPU </span><span class="se">\n</span><span class="s1">source: 人民日报&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;年份&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">13</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;EPU值&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">13</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/07-fig.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">gmrb_EPU_df2</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="s1">&#39;date&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;月度经济政策不确定性EPU </span><span class="se">\n</span><span class="s1">source: 光明日报&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;年份&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">13</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;EPU值&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">13</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/08-fig.png" alt=""  />
</p>
<p>光明日报数据中缺失了1989年了，所以图中有空挡。但是从两个图中可以看到 epu 的走势大致一致。</p>
<p>作为事后诸葛的大邓， 从人民日报和光明日报计算出的EPU可以看到， 23年不应该投资，应该保守点。</p>
<p>嗯嗯， 同时作为投资小白，人群中的反向指标人，今年本人收益率-20%，大家开心不~</p>
<br>
<h2 id="五获取资料">五、获取资料</h2>
<p><a href="epu.ipynb">点击下载本文代码epu.ipynb</a></p>
<p><a href="rmrb_epu.csv">点击下载rmrb_epu.csv</a></p>
<p><a href="https://textdata.cn/blog/2023-12-14-daily-news-dataset/">点击购买 <strong>新闻数据集 | 含 人民日报/经济日报/光明日报 等 7 家媒体(2023.12.18)</strong></a></p>
<p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>代码 | 使用地方gov工作报告生成某类概念词词频「面板数据」</title>
      <link>https://textdata.cn/blog/2023-12-17-how-to-generate-panel-data-from-gov-report-dataset/</link>
      <pubDate>Sun, 17 Dec 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-12-17-how-to-generate-panel-data-from-gov-report-dataset/</guid>
      <description>使用31省市的2002-2023年的省级政府工作报告，绘制出的不同类别关键词的趋势图。直接上最终效果效果图</description>
      <content:encoded><![CDATA[<p>使用31省市的2002-2023年的省级政府工作报告，绘制出的不同类别关键词的趋势图。 直接上效果效果图</p>
<p><img loading="lazy" src="img/12-tri-agri.png" alt=""  />
</p>
<p><img loading="lazy" src="img/13-inovation-plot.png" alt=""  />
</p>
<p><img loading="lazy" src="img/14-enviroment-plot.png" alt=""  />
</p>
<br>
<p>其实绘制三种图的数据是面板型数据，今天主要分享如何利用省级政府工作报告构建某类概念词频(创新、环保、三农)的面板数据，并绘制8省市概念词频折线图。 大家可以根据自己的研究需要更改代码， 生成自己概念的词频面板数据。</p>
<br>
<br>
<h2 id="获取数据">获取数据</h2>
<p><a href="https://textdata.cn/blog/2023-12-17-gov-anual-report-dataset/">数据集(付费) | 国、省、市三级政府工作报告文本</a></p>
<p>数据集100元，  <strong>加微信 372335839， 备注「姓名-学校-专业」</strong>。</p>
<p><br><br></p>
<h2 id="一直接上代码">一、直接上代码</h2>
<h3 id="11-查看数据">1.1 查看数据</h3>
<p>读取省报告数据文件 <strong>prov_report2002-2023.csv</strong> ，<a href="https://textdata.cn/blog/2023-12-17-gov-anual-report-dataset/">点击链接，获取政府工作报告数据集</a></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;prov_report2002-2023.csv&#39;</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/01-df.png" alt=""  />
</p>
<br>
<h3 id="12-生成面板数据函数">1.2 生成面板数据函数</h3>
<p>假设你使用的政府(省、市)工作报告数据是大邓提供的，可以直接使用下面封装的函数，快速生成概念词典，指定省份指定年度区间的面板数据。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">generate_panel_data</span><span class="p">(</span><span class="n">csvf</span><span class="p">,</span> <span class="n">concept_words</span><span class="p">,</span> <span class="n">selected_provs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">selected_years</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="s2">&#34;&#34;&#34;
</span><span class="s2">    csvf: csv的文件路径
</span><span class="s2">    concept_words: 概念词词语列表
</span><span class="s2">    selected_provs: 筛选指定省份的数据进行计算，列表
</span><span class="s2">    selected_years: 筛选指定年度的数据进行计算，列表
</span><span class="s2">    
</span><span class="s2">    结果返回dataframe， 每一行代表一个省，每一列代表一年。
</span><span class="s2">    &#34;&#34;&#34;</span>
    
    <span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
    <span class="kn">import</span> <span class="nn">jieba</span>
    
    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">csvf</span><span class="p">)</span>
    <span class="n">df</span><span class="p">[</span><span class="s1">&#39;year&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;file&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">f</span><span class="p">:</span> <span class="n">f</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;/&#39;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;.txt&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">)[</span><span class="o">-</span><span class="mi">4</span><span class="p">:])</span>
    <span class="n">df</span><span class="p">[</span><span class="s1">&#39;prov&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;file&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">f</span><span class="p">:</span> <span class="n">f</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;/&#39;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;.txt&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">)[:</span><span class="o">-</span><span class="mi">4</span><span class="p">])</span> 


    <span class="n">table_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">pivot_table</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> 
                       <span class="n">columns</span><span class="o">=</span><span class="s1">&#39;year&#39;</span><span class="p">,</span>  <span class="c1">#列-年份</span>
                       <span class="n">index</span><span class="o">=</span><span class="s1">&#39;prov&#39;</span><span class="p">,</span>    <span class="c1">#行-省份</span>
                       <span class="n">values</span><span class="o">=</span><span class="s1">&#39;doc&#39;</span><span class="p">,</span>   <span class="c1">#单元格-文本</span>
                       <span class="n">aggfunc</span><span class="o">=</span><span class="k">lambda</span> <span class="n">cs</span><span class="p">:</span> <span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">cs</span><span class="p">))</span> <span class="c1">#让单元格填充文本</span>

    <span class="k">if</span> <span class="n">selected_provs</span><span class="p">:</span>
        <span class="n">table_df</span> <span class="o">=</span> <span class="n">table_df</span><span class="p">[</span><span class="n">table_df</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="n">selected_provs</span><span class="p">)]</span>
    
    <span class="k">if</span> <span class="n">selected_years</span><span class="p">:</span>
        <span class="n">selected_years</span> <span class="o">=</span> <span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">selected_years</span><span class="p">]</span>
        <span class="n">table_df</span> <span class="o">=</span> <span class="n">table_df</span><span class="p">[</span><span class="n">selected_years</span><span class="p">]</span>
        

    <span class="n">word_count_df</span> <span class="o">=</span> <span class="n">table_df</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">row</span><span class="p">:</span> <span class="n">row</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">jieba</span><span class="o">.</span><span class="n">lcut</span><span class="p">(</span><span class="n">t</span><span class="p">))))</span>
    <span class="n">concept_word_count_df</span> <span class="o">=</span> <span class="n">table_df</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">row</span><span class="p">:</span> <span class="n">row</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="s1">&#39;|&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">concept_words</span><span class="p">)))</span>
    <span class="n">concept_word_ratio_df</span> <span class="o">=</span> <span class="n">concept_word_count_df</span><span class="o">/</span><span class="n">word_count_df</span>
    <span class="k">return</span> <span class="n">concept_word_ratio_df</span>


<span class="n">concept_words</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;农村&#39;</span><span class="p">,</span> <span class="s1">&#39;农业&#39;</span><span class="p">,</span> <span class="s1">&#39;农民&#39;</span><span class="p">]</span>
<span class="c1">#所有省份，所有年度(2002-2023)</span>
<span class="n">panel_data_df</span> <span class="o">=</span> <span class="n">generate_panel_data</span><span class="p">(</span><span class="n">csvf</span><span class="o">=</span><span class="s1">&#39;prov_report2002-2023.csv&#39;</span><span class="p">,</span> 
                                    <span class="n">concept_words</span> <span class="o">=</span> <span class="n">concept_words</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">panel_data_df</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="c1">#如果需要保存</span>
<span class="c1">#panel_data_df.to_csv(&#39;文件路径2.csv&#39;, index=False)</span>

<span class="n">panel_data_df</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">(31, 23)
</code></pre></div><p><img loading="lazy" src="img/02-panel-data.png" alt=""  />
</p>
<br>
<p>生成 山东省河北省2010-2023期间政府工作报告提及三农词词频占比的面板数据</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">concept_words</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;农村&#39;</span><span class="p">,</span> <span class="s1">&#39;农业&#39;</span><span class="p">,</span> <span class="s1">&#39;农民&#39;</span><span class="p">]</span>
<span class="n">selected_provs</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;山东省&#39;</span><span class="p">,</span> <span class="s1">&#39;河北省&#39;</span><span class="p">]</span>
<span class="n">selected_years</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">2010</span><span class="p">,</span> <span class="mi">2024</span><span class="p">))</span>
<span class="n">panel_data_df</span> <span class="o">=</span> <span class="n">generate_panel_data</span><span class="p">(</span><span class="n">csvf</span><span class="o">=</span><span class="s1">&#39;prov_report2002-2023.csv&#39;</span><span class="p">,</span> 
                                    <span class="n">concept_words</span> <span class="o">=</span> <span class="n">concept_words</span><span class="p">,</span> 
                                    <span class="n">selected_provs</span> <span class="o">=</span> <span class="n">selected_provs</span><span class="p">,</span>
                                    <span class="n">selected_years</span> <span class="o">=</span> <span class="n">selected_years</span><span class="p">)</span>


<span class="c1">#如果需要保存</span>
<span class="c1">#panel_data_df.to_csv(&#39;文件路径2.csv&#39;, index=False)</span>

<span class="n">panel_data_df</span>
</code></pre></div><p><img loading="lazy" src="img/03-hebei-shandong-panel-data.png" alt=""  />
</p>
<br>
<h3 id="13-绘制折线图">1.3 绘制折线图</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">plot_line</span><span class="p">(</span><span class="n">panel_df</span><span class="p">,</span> <span class="n">title</span><span class="p">):</span>
    <span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
    <span class="kn">import</span> <span class="nn">matplotlib</span>
    <span class="kn">import</span> <span class="nn">scienceplots</span>
    <span class="kn">import</span> <span class="nn">platform</span>
    <span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
    <span class="kn">import</span> <span class="nn">matplotlib_inline</span>
    <span class="n">matplotlib_inline</span><span class="o">.</span><span class="n">backend_inline</span><span class="o">.</span><span class="n">set_matplotlib_formats</span><span class="p">(</span><span class="s1">&#39;png&#39;</span><span class="p">,</span> <span class="s1">&#39;svg&#39;</span><span class="p">)</span>
    <span class="kn">import</span> <span class="nn">jieba</span>
    <span class="kn">import</span> <span class="nn">warnings</span>
    <span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">([</span><span class="s1">&#39;science&#39;</span><span class="p">,</span> <span class="s1">&#39;no-latex&#39;</span><span class="p">,</span> <span class="s1">&#39;cjk-sc-font&#39;</span><span class="p">])</span>
    <span class="n">system</span> <span class="o">=</span> <span class="n">platform</span><span class="o">.</span><span class="n">system</span><span class="p">()</span>  <span class="c1"># 获取操作系统类型</span>

    <span class="k">if</span> <span class="n">system</span> <span class="o">==</span> <span class="s1">&#39;Windows&#39;</span><span class="p">:</span>
        <span class="n">font</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;family&#39;</span><span class="p">:</span> <span class="s1">&#39;SimHei&#39;</span><span class="p">}</span>
    <span class="k">elif</span> <span class="n">system</span> <span class="o">==</span> <span class="s1">&#39;Darwin&#39;</span><span class="p">:</span>
        <span class="n">font</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;family&#39;</span><span class="p">:</span> <span class="s1">&#39;Arial Unicode MS&#39;</span><span class="p">}</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">font</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;family&#39;</span><span class="p">:</span> <span class="s1">&#39;sans-serif&#39;</span><span class="p">}</span>
    <span class="n">matplotlib</span><span class="o">.</span><span class="n">rc</span><span class="p">(</span><span class="s1">&#39;font&#39;</span><span class="p">,</span> <span class="o">**</span><span class="n">font</span><span class="p">)</span>  <span class="c1"># 设置全局字体</span>
    
    
    
    <span class="n">panel_df_T</span> <span class="o">=</span> <span class="n">panel_df</span><span class="o">.</span><span class="n">T</span>
    <span class="n">panel_df_T</span><span class="o">.</span><span class="n">index</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">panel_df_T</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>

    <span class="n">ax</span> <span class="o">=</span> <span class="n">panel_df_T</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
    <span class="c1"># 添加图例，并指定位置和偏移</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper right&#39;</span><span class="p">,</span> <span class="n">bbox_to_anchor</span><span class="o">=</span><span class="p">(</span><span class="mf">1.15</span><span class="p">,</span> <span class="mf">1.05</span><span class="p">))</span>


    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">title</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;年份&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">13</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;词频&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">13</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div><p>现在我们试试</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">concept_words = [&#39;农村&#39;, &#39;农业&#39;, &#39;农民&#39;]
selected_provs = [&#39;山东省&#39;, &#39;河北省&#39;]
selected_years = list(range(2010, 2024)) #2010年-2023年

#生成面板数据
panel_data_df = generate_panel_data(csvf=&#39;prov_report2002-2023.csv&#39;, 
                                    concept_words = concept_words, 
                                    selected_provs = selected_provs,
                                    selected_years = selected_years)

#绘图
plot_line(panel_df=panel_data_df, 
          title=&#39;山东、河北三农词折线图(2010-2023)&#39;)
</code></pre></div><p><img loading="lazy" src="img/04-hebei-shandong-plot.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="二函数代码拆解">二、函数代码拆解</h2>
<h3 id="21-读取数据">2.1 读取数据</h3>
<p>36.6M的数据，含file和text两个字段， <a href="2023-12-17-gov-anual-report-dataset/"><strong>点击获取政府公告文件</strong></a></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-Python" data-lang="Python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;prov_report2002-2023.csv&#39;</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/01-df.png" alt=""  />
</p>
<br>
<h3 id="22-构建provyear字段">2.2 构建prov、year字段</h3>
<p>根据file中的形态</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">file = &#39;GovReportData/prov2002-2023/浙江省2023.txt&#39;
</code></pre></div><p>针对字段 file ， 使用 apply方法批量对 file 进行字符串的分割、替换、切片， 整理出 year 和 prov 的字段</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df</span><span class="p">[</span><span class="s1">&#39;year&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;file&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">f</span><span class="p">:</span> <span class="n">f</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;/&#39;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;.txt&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">)[</span><span class="o">-</span><span class="mi">4</span><span class="p">:])</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;prov&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;file&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">f</span><span class="p">:</span> <span class="n">f</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;/&#39;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;.txt&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">)[:</span><span class="o">-</span><span class="mi">4</span><span class="p">])</span> 
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/05-df.png" alt=""  />
</p>
<br>
<h3 id="23-构建透视表">2.3 构建透视表</h3>
<p>构建透视表，行索引名为省 prov，列名为时间year， 单元格内填充工作报告文本。</p>
<p>代码不用太深究，只要知道代码操作前后数据形态的变化即可。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">table_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">pivot_table</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> 
                       <span class="n">columns</span><span class="o">=</span><span class="s1">&#39;year&#39;</span><span class="p">,</span>  <span class="c1">#列-年份</span>
                       <span class="n">index</span><span class="o">=</span><span class="s1">&#39;prov&#39;</span><span class="p">,</span>    <span class="c1">#行-省份</span>
                       <span class="n">values</span><span class="o">=</span><span class="s1">&#39;doc&#39;</span><span class="p">,</span>   <span class="c1">#单元格-文本</span>
                       <span class="n">aggfunc</span><span class="o">=</span><span class="k">lambda</span> <span class="n">cs</span><span class="p">:</span> <span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">cs</span><span class="p">))</span> <span class="c1">#让单元格填充文本</span>

<span class="nb">print</span><span class="p">(</span><span class="n">table</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">table_df</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">(31, 23)
</code></pre></div><p><img loading="lazy" src="img/06-df.png" alt=""  />
</p>
<p>table_df是一个31行， 23列的矩阵。 每行代表一个省，每一列代表一个年份。</p>
<br>
<h3 id="24-统计总词数">2.4 统计总词数</h3>
<p>统计所有报告的词语数。代码高度抽象， 咱们只看结果。 从 table_df 变为 word_count_df</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">jieba</span>
<span class="n">word_count_df</span> <span class="o">=</span> <span class="n">table_df</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">row</span><span class="p">:</span> <span class="n">row</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">jieba</span><span class="o">.</span><span class="n">lcut</span><span class="p">(</span><span class="n">t</span><span class="p">))))</span>
<span class="n">word_count_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">(31, 23)
</code></pre></div><p><img loading="lazy" src="img/07-word_count_df.png" alt=""  />
</p>
<br>
<h3 id="25-统计概念词频占比">2.5 统计概念词频(占比)</h3>
<p>统计所有报告中，某概念词词频，以三农为例</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">concept_words</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;农村&#39;</span><span class="p">,</span> <span class="s1">&#39;农业&#39;</span><span class="p">,</span> <span class="s1">&#39;农民&#39;</span><span class="p">]</span>

<span class="n">concept_word_count_df</span> <span class="o">=</span> <span class="n">table_df</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">row</span><span class="p">:</span> <span class="n">row</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="s1">&#39;|&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">keywords</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">concept_word_count_df</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="c1">#为方便，只展示前5行</span>
<span class="n">concept_word_count_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">(31, 23)
</code></pre></div><p><img loading="lazy" src="img/08-tri-df.png" alt=""  />
</p>
<br>
<p>将数据转化为词频占比，即 **报告「三农词」出现次数/报告总词数 **</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">concept_word_ratio_df</span> <span class="o">=</span> <span class="n">concept_word_count_df</span><span class="o">/</span><span class="n">word_count_df</span>
<span class="nb">print</span><span class="p">(</span><span class="n">concept_word_ratio_df</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">concept_word_ratio_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">(31, 23)
</code></pre></div><p><img loading="lazy" src="img/09-concept_word_ratio_df.png" alt=""  />
</p>
<br>
<p>到目前为止， 已经将一坨文本，转化为结构化的面板数据， 其实现在就可以保存起来啦。</p>
<br>
<h3 id="26-保存结果">2.6 保存结果</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">concept_word_ratio_df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;concept_word_ratio.csv&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</code></pre></div><p><br><br></p>
<h2 id="三可视化">三、可视化</h2>
<h3 id="31-稍作解释">3.1 稍作解释</h3>
<p>可视化 plot_line 函数内部没有进行过多的数据变换， 仅仅只是进行了转置 和 日期格式变化。本小节只稍作解释，马上进入后续的三个可视化案例。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">concept_word_ratio_df_T = concept_word_ratio_df.T
concept_word_ratio_df_T
</code></pre></div><p><img loading="lazy" src="img/10-T.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">concept_word_ratio_df_T.index = pd.to_datetime(concept_word_ratio_df_T.index)
concept_word_ratio_df_T
</code></pre></div><p><img loading="lazy" src="img/11-datetime.png" alt=""  />
</p>
<br>
<h3 id="32-三农折线图">3.2 「三农」折线图</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">selected_provs</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;河北省&#39;</span><span class="p">,</span> <span class="s1">&#39;山东省&#39;</span><span class="p">,</span> <span class="s1">&#39;北京市&#39;</span><span class="p">,</span> <span class="s1">&#39;上海市&#39;</span><span class="p">,</span> <span class="s1">&#39;广东省&#39;</span><span class="p">,</span> <span class="s1">&#39;浙江省&#39;</span><span class="p">,</span> <span class="s1">&#39;黑龙江省&#39;</span><span class="p">,</span> <span class="s1">&#39;湖南省&#39;</span><span class="p">]</span>
<span class="n">concept_words</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;农村&#39;</span><span class="p">,</span> <span class="s1">&#39;农业&#39;</span><span class="p">,</span> <span class="s1">&#39;农民&#39;</span><span class="p">]</span>
<span class="n">tri_agri_panel_df</span> <span class="o">=</span> <span class="n">generate_panel_data</span><span class="p">(</span><span class="n">csvf</span><span class="o">=</span><span class="s1">&#39;prov_report2002-2023.csv&#39;</span><span class="p">,</span> 
                                        <span class="n">concept_words</span> <span class="o">=</span><span class="n">concept_words</span><span class="p">,</span> 
                                        <span class="n">selected_provs</span> <span class="o">=</span> <span class="n">selected_provs</span><span class="p">)</span>


<span class="n">plot_line</span><span class="p">(</span><span class="n">panel_df</span><span class="o">=</span><span class="n">tri_agri_panel_df</span><span class="p">,</span> 
          <span class="n">title</span><span class="o">=</span><span class="s1">&#39;8省市2002-2023年「三农」词频趋势&#39;</span><span class="p">)</span>
</code></pre></div><p><img loading="lazy" src="img/12-tri-agri.png" alt=""  />
</p>
<p>从上图中，可以看出</p>
<ul>
<li>05年提及三农词占比最多的是湖南，是20年以来8省市中占比值最高记录</li>
<li>大多数省份在07年达到峰值</li>
<li>07年前，工作报告中提及三农词提及三农词的占比趋势是<strong>上升的</strong></li>
<li>07年后，工作报告中提及三农词提及三农词的占比趋势是<strong>下升的</strong>。</li>
</ul>
<br>
<h3 id="33-创新折线图">3.3 「创新」折线图</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">selected_provs</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;河北省&#39;</span><span class="p">,</span> <span class="s1">&#39;山东省&#39;</span><span class="p">,</span> <span class="s1">&#39;北京市&#39;</span><span class="p">,</span> <span class="s1">&#39;上海市&#39;</span><span class="p">,</span> <span class="s1">&#39;广东省&#39;</span><span class="p">,</span> <span class="s1">&#39;浙江省&#39;</span><span class="p">,</span> <span class="s1">&#39;黑龙江省&#39;</span><span class="p">,</span> <span class="s1">&#39;湖南省&#39;</span><span class="p">]</span>
<span class="n">concept_words</span> <span class="o">=</span>  <span class="p">[</span><span class="s1">&#39;科学&#39;</span><span class="p">,</span> <span class="s1">&#39;技术&#39;</span><span class="p">,</span> <span class="s1">&#39;创新&#39;</span><span class="p">,</span> <span class="s1">&#39;研发&#39;</span><span class="p">,</span> <span class="s1">&#39;科技&#39;</span><span class="p">]</span>

<span class="n">inovation_panel_df</span> <span class="o">=</span> <span class="n">generate_panel_data</span><span class="p">(</span><span class="n">csvf</span><span class="o">=</span><span class="s1">&#39;prov_report2002-2023.csv&#39;</span><span class="p">,</span> 
                                        <span class="n">concept_words</span> <span class="o">=</span><span class="n">concept_words</span><span class="p">,</span> 
                                        <span class="n">selected_provs</span> <span class="o">=</span> <span class="n">selected_provs</span><span class="p">)</span>


<span class="n">plot_line</span><span class="p">(</span><span class="n">panel_df</span><span class="o">=</span><span class="n">inovation_panel_df</span><span class="p">,</span> 
          <span class="n">title</span><span class="o">=</span><span class="s1">&#39;8省市2002-2023年「创新」词频趋势&#39;</span><span class="p">)</span>
</code></pre></div><p><img loading="lazy" src="img/13-inovation-plot.png" alt=""  />
</p>
<p>从上图中，可以看出</p>
<ul>
<li>
<p>整体看，2000年以来八省市工作报告中提及科创相关词的比例是稳定的。</p>
</li>
<li>
<p>2010年之后， <strong>黑龙江</strong>是八省市中提起科创概念词最少的省份。</p>
</li>
<li>
<p>河北省2020年支棱起来了，是提及科创概念词最高的，而且是八省市所有年份最高！</p>
</li>
</ul>
<br>
<h3 id="34-环保折线图">3.4 「环保」折线图</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">selected_provs</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;河北省&#39;</span><span class="p">,</span> <span class="s1">&#39;山东省&#39;</span><span class="p">,</span> <span class="s1">&#39;北京市&#39;</span><span class="p">,</span> <span class="s1">&#39;上海市&#39;</span><span class="p">,</span> <span class="s1">&#39;广东省&#39;</span><span class="p">,</span> <span class="s1">&#39;浙江省&#39;</span><span class="p">,</span> <span class="s1">&#39;黑龙江省&#39;</span><span class="p">,</span> <span class="s1">&#39;湖南省&#39;</span><span class="p">]</span>
<span class="n">concept_words</span> <span class="o">=</span>  <span class="p">[</span><span class="s1">&#39;环境&#39;</span><span class="p">,</span> <span class="s1">&#39;环保&#39;</span><span class="p">,</span> <span class="s1">&#39;绿色&#39;</span><span class="p">,</span> <span class="s1">&#39;健康&#39;</span><span class="p">,</span> <span class="s1">&#39;青山&#39;</span><span class="p">,</span> <span class="s1">&#39;青山绿水&#39;</span><span class="p">,</span> <span class="s1">&#39;绿水&#39;</span><span class="p">]</span>


<span class="n">environment_panel_df</span> <span class="o">=</span> <span class="n">generate_panel_data</span><span class="p">(</span><span class="n">csvf</span><span class="o">=</span><span class="s1">&#39;prov_report2002-2023.csv&#39;</span><span class="p">,</span> 
                                        <span class="n">concept_words</span> <span class="o">=</span><span class="n">concept_words</span><span class="p">,</span> 
                                        <span class="n">selected_provs</span> <span class="o">=</span> <span class="n">selected_provs</span><span class="p">)</span>


<span class="n">plot_line</span><span class="p">(</span><span class="n">panel_df</span> <span class="o">=</span> <span class="n">environment_panel_df</span><span class="p">,</span> 
          <span class="n">title</span><span class="o">=</span><span class="s1">&#39;8省市2002-2023年「环保」词频趋势&#39;</span><span class="p">)</span>
</code></pre></div><p><img loading="lazy" src="img/14-enviroment-plot.png" alt=""  />
</p>
<br>
<br>
<h2 id="四获取数据集">四、获取数据集</h2>
<p><a href="https://textdata.cn/blog/2023-12-17-gov-anual-report-dataset/">数据集(付费) | 国、省、市三级政府工作报告文本</a></p>
<p>数据集100元，  <strong>加微信 372335839， 备注「姓名-学校-专业」</strong>。</p>
<br>
<br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>数据集(付费) | 国、省、市三级政府工作报告文本(1954-2023)</title>
      <link>https://textdata.cn/blog/2023-12-17-gov-anual-report-dataset/</link>
      <pubDate>Sun, 17 Dec 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-12-17-gov-anual-report-dataset/</guid>
      <description>&lt;h2 id=&#34;相关代码&#34;&gt;相关代码&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://textdata.cn/blog/2023-12-17-how-to-generate-panel-data-from-gov-report-dataset/&#34;&gt;代码 | 使用地方gov工作报告生成某类概念词词频面板数据&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;一数据集&#34;&gt;一、数据集&lt;/h2&gt;
&lt;h3 id=&#34;11-数据简介&#34;&gt;1.1 数据简介&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;国级(guo wu yuan)工作报告1954-2023, 记录数70

省级zf工作报告2002-2023, 记录数713

市级zf工作报告2003-2023, 记录数5922
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;数据集100元，  &lt;strong&gt;加微信 372335839， 备注「姓名-学校-专业」&lt;/strong&gt;。&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;12-文件树目录&#34;&gt;1.2 文件树目录&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;|- 代码.ipynb

|- GovReportData
    |-nation1954-2023
        |-1954.txt
        |-1955.txt
        |-...
        |-2022.txt
        |-2023.txt
        
    |-prov2002-2023
        |-安徽省2001.txt
        |-...
        |-安徽省2023.txt
        |-...
        |-浙江省2023.txt
        
    |-city2003-2023
        |-安康市2003.txt
        |-...
        |-安庆市2003.txt
        |-...
        |-安庆市2023.txt
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h3 id=&#34;13-查看缺失数据&#34;&gt;1.3 查看缺失数据&lt;/h3&gt;
&lt;p&gt;使用爬虫和人工搜集， 也不能保证数据的完整性， 下面给各位客官看下数据的缺失情况，方便大家使用数据时心里有数。&lt;/p&gt;
&lt;p&gt;缺失的txt文件非常小，一般只有几个字节，而正常的报告至少是几十kb。只需要通过审查小于1kb的文件即可得知缺失的数据。&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;131--国-缺失情况&#34;&gt;1.3.1  国-缺失情况&lt;/h3&gt;
&lt;p&gt;国家级(guo wu yuan)报告1954-2023，&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;os&lt;/span&gt;

&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;国级报告缺失: &lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\n&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;nation_files&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;sa&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;GovReportData/nation1954-2023/&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;year&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;.txt&amp;#39;&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;year&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;range&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1954&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2024&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)]&lt;/span&gt;
&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;file&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nation_files&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;fsize&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;os&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;path&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;getsize&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;file&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1024&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;#kb&lt;/span&gt;
    &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;fsize&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
        &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;file&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;split&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;/&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)[&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;replace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;.txt&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;国级报告缺失: 

1961
1962
1963
1965
1966
1967
1968
1969
1970
1971
1972
1973
1974
1976
1977
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h3 id=&#34;32-省-缺失情况&#34;&gt;3.2 省-缺失情况&lt;/h3&gt;
&lt;p&gt;2002-2023,省份缺失情况&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;省级报告缺失: &lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\n&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;prov_files&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;sa&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;GovReportData/prov2002-2023/&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;file&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&lt;/span&gt; 
              &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;file&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;os&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;listdir&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;GovReportData/prov2002-2023&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)]&lt;/span&gt;
&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;file&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;prov_files&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;fsize&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;os&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;path&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;getsize&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;file&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1024&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;#kb&lt;/span&gt;
    &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;fsize&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
        &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;file&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;split&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;/&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)[&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;replace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;.txt&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;省级报告缺失: 

云南省2001
新疆维吾尔族自治区2001
重庆市2001
广西壮族自治区2001
天津市2001
青海省2001
湖南省2001
西藏自治区2001
湖北省2001
山西省2001
江西省2001
江苏省2001
辽宁省2001
宁夏回族自治区2001
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h3 id=&#34;33-市-缺失情况&#34;&gt;3.3 市-缺失情况&lt;/h3&gt;
&lt;p&gt;2003-2023，市-缺失情况&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;市级报告缺失: &lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\n&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;data&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;dict&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;prov_files&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;sa&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;GovReportData/city2003-2023/&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;file&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&lt;/span&gt; 
              &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;file&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;os&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;listdir&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;GovReportData/city2003-2023&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)]&lt;/span&gt;
&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;file&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;prov_files&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;fsize&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;os&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;path&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;getsize&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;file&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1024&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;#kb&lt;/span&gt;
    &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;fsize&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
        &lt;span class=&#34;n&#34;&gt;city&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;file&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;split&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;/&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)[&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;replace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;.txt&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)[:&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
        &lt;span class=&#34;n&#34;&gt;year&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;file&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;split&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;/&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)[&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;replace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;.txt&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)[&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:]&lt;/span&gt;
        &lt;span class=&#34;n&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;setdefault&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;city&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[])&lt;/span&gt;
        &lt;span class=&#34;n&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;city&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;city&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;year&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
        
&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;key&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;value&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;items&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;():&lt;/span&gt;
    &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;key&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;value&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;市级报告缺失: 

苏州市 [&amp;#39;2003&amp;#39;]
酒泉市 [&amp;#39;2005&amp;#39;, &amp;#39;2004&amp;#39;, &amp;#39;2003&amp;#39;]
资阳市 [&amp;#39;2004&amp;#39;, &amp;#39;2003&amp;#39;]
双鸭山市 [&amp;#39;2008&amp;#39;, &amp;#39;2009&amp;#39;, &amp;#39;2014&amp;#39;, &amp;#39;2003&amp;#39;, &amp;#39;2007&amp;#39;, &amp;#39;2012&amp;#39;, &amp;#39;2006&amp;#39;, &amp;#39;2010&amp;#39;, &amp;#39;2004&amp;#39;, &amp;#39;2005&amp;#39;, &amp;#39;2011&amp;#39;]
七台河市 [&amp;#39;2005&amp;#39;, &amp;#39;2004&amp;#39;, &amp;#39;2006&amp;#39;, &amp;#39;2003&amp;#39;]
张家口市 [&amp;#39;2004&amp;#39;, &amp;#39;2005&amp;#39;, &amp;#39;2007&amp;#39;, &amp;#39;2006&amp;#39;, &amp;#39;2003&amp;#39;, &amp;#39;2009&amp;#39;]
抚州市 [&amp;#39;2004&amp;#39;, &amp;#39;2010&amp;#39;, &amp;#39;2005&amp;#39;, &amp;#39;2013&amp;#39;, &amp;#39;2007&amp;#39;, &amp;#39;2006&amp;#39;, &amp;#39;2003&amp;#39;, &amp;#39;2009&amp;#39;]
阳泉市 [&amp;#39;2008&amp;#39;, &amp;#39;2003&amp;#39;, &amp;#39;2007&amp;#39;, &amp;#39;2006&amp;#39;, &amp;#39;2010&amp;#39;, &amp;#39;2004&amp;#39;, &amp;#39;2005&amp;#39;]
湘潭市 [&amp;#39;2005&amp;#39;, &amp;#39;2004&amp;#39;, &amp;#39;2006&amp;#39;, &amp;#39;2007&amp;#39;, &amp;#39;2003&amp;#39;]
新余市 [&amp;#39;2009&amp;#39;, &amp;#39;2008&amp;#39;, &amp;#39;2003&amp;#39;, &amp;#39;2007&amp;#39;]
克拉玛依市 [&amp;#39;2011&amp;#39;, &amp;#39;2005&amp;#39;, &amp;#39;2004&amp;#39;, &amp;#39;2010&amp;#39;, &amp;#39;2006&amp;#39;, &amp;#39;2012&amp;#39;, &amp;#39;2013&amp;#39;, &amp;#39;2007&amp;#39;, &amp;#39;2003&amp;#39;, &amp;#39;2014&amp;#39;, &amp;#39;2015&amp;#39;, &amp;#39;2009&amp;#39;, &amp;#39;2008&amp;#39;]
铜陵市 [&amp;#39;2005&amp;#39;, &amp;#39;2004&amp;#39;, &amp;#39;2007&amp;#39;, &amp;#39;2003&amp;#39;]
宣城市 [&amp;#39;2003&amp;#39;]
昭通市 [&amp;#39;2007&amp;#39;, &amp;#39;2006&amp;#39;, &amp;#39;2004&amp;#39;, &amp;#39;2005&amp;#39;, &amp;#39;2003&amp;#39;, &amp;#39;2008&amp;#39;, &amp;#39;2009&amp;#39;]
忻州市 [&amp;#39;2003&amp;#39;, &amp;#39;2005&amp;#39;, &amp;#39;2004&amp;#39;, &amp;#39;2006&amp;#39;, &amp;#39;2008&amp;#39;]
永州市 [&amp;#39;2003&amp;#39;, &amp;#39;2004&amp;#39;, &amp;#39;2005&amp;#39;, &amp;#39;2006&amp;#39;, &amp;#39;2008&amp;#39;]
孝感市 [&amp;#39;2004&amp;#39;, &amp;#39;2003&amp;#39;]
定西市 [&amp;#39;2009&amp;#39;, &amp;#39;2003&amp;#39;, &amp;#39;2006&amp;#39;, &amp;#39;2004&amp;#39;, &amp;#39;2005&amp;#39;]
滁州市 [&amp;#39;2006&amp;#39;, &amp;#39;2004&amp;#39;, &amp;#39;2005&amp;#39;, &amp;#39;2003&amp;#39;]
湖州市 [&amp;#39;2008&amp;#39;, &amp;#39;2003&amp;#39;, &amp;#39;2013&amp;#39;, &amp;#39;2007&amp;#39;, &amp;#39;2005&amp;#39;, &amp;#39;2004&amp;#39;]
河池市 [&amp;#39;2003&amp;#39;]
呼和浩特市 [&amp;#39;2005&amp;#39;, &amp;#39;2004&amp;#39;, &amp;#39;2003&amp;#39;]
遵义市 [&amp;#39;2005&amp;#39;, &amp;#39;2004&amp;#39;, &amp;#39;2003&amp;#39;]
成都市 [&amp;#39;2004&amp;#39;, &amp;#39;2005&amp;#39;, &amp;#39;2003&amp;#39;]
南充市 [&amp;#39;2003&amp;#39;, &amp;#39;2005&amp;#39;, &amp;#39;2004&amp;#39;]
海东市 [&amp;#39;2008&amp;#39;, &amp;#39;2009&amp;#39;, &amp;#39;2003&amp;#39;, &amp;#39;2010&amp;#39;, &amp;#39;2004&amp;#39;, &amp;#39;2005&amp;#39;, &amp;#39;2011&amp;#39;, &amp;#39;2007&amp;#39;, &amp;#39;2012&amp;#39;, &amp;#39;2006&amp;#39;]
石家庄市 [&amp;#39;2003&amp;#39;, &amp;#39;2005&amp;#39;, &amp;#39;2004&amp;#39;]
运城市 [&amp;#39;2003&amp;#39;]
黄山市 [&amp;#39;2005&amp;#39;, &amp;#39;2004&amp;#39;, &amp;#39;2003&amp;#39;]
北海市 [&amp;#39;2003&amp;#39;, &amp;#39;2006&amp;#39;, &amp;#39;2005&amp;#39;, &amp;#39;2004&amp;#39;]
漳州市 [&amp;#39;2004&amp;#39;]
六安市 [&amp;#39;2003&amp;#39;, &amp;#39;2007&amp;#39;]
安康市 [&amp;#39;2003&amp;#39;, &amp;#39;2004&amp;#39;]
汕尾市 [&amp;#39;2003&amp;#39;, &amp;#39;2004&amp;#39;, &amp;#39;2005&amp;#39;]
合肥市 [&amp;#39;2003&amp;#39;, &amp;#39;2004&amp;#39;, &amp;#39;2005&amp;#39;]
宜昌市 [&amp;#39;2003&amp;#39;, &amp;#39;2010&amp;#39;, &amp;#39;2004&amp;#39;, &amp;#39;2022&amp;#39;]
乌兰察布市 [&amp;#39;2008&amp;#39;, &amp;#39;2009&amp;#39;, &amp;#39;2007&amp;#39;, &amp;#39;2006&amp;#39;, &amp;#39;2010&amp;#39;, &amp;#39;2004&amp;#39;, &amp;#39;2005&amp;#39;, &amp;#39;2003&amp;#39;]
衡水市 [&amp;#39;2008&amp;#39;, &amp;#39;2009&amp;#39;, &amp;#39;2007&amp;#39;, &amp;#39;2006&amp;#39;, &amp;#39;2010&amp;#39;, &amp;#39;2004&amp;#39;, &amp;#39;2011&amp;#39;, &amp;#39;2003&amp;#39;]
金昌市 [&amp;#39;2011&amp;#39;]
沧州市 [&amp;#39;2007&amp;#39;, &amp;#39;2009&amp;#39;, &amp;#39;2008&amp;#39;]
广安市 [&amp;#39;2005&amp;#39;, &amp;#39;2013&amp;#39;]
吉林市 [&amp;#39;2009&amp;#39;, &amp;#39;2008&amp;#39;, &amp;#39;2005&amp;#39;, &amp;#39;2010&amp;#39;, &amp;#39;2004&amp;#39;, &amp;#39;2003&amp;#39;]
临沧市 [&amp;#39;2003&amp;#39;]
潍坊市 [&amp;#39;2003&amp;#39;]
杭州市 [&amp;#39;2004&amp;#39;]
淮南市 [&amp;#39;2003&amp;#39;, &amp;#39;2005&amp;#39;, &amp;#39;2004&amp;#39;, &amp;#39;2007&amp;#39;]
吉安市 [&amp;#39;2004&amp;#39;, &amp;#39;2005&amp;#39;, &amp;#39;2006&amp;#39;, &amp;#39;2003&amp;#39;, &amp;#39;2008&amp;#39;, &amp;#39;2009&amp;#39;]
衢州市 [&amp;#39;2004&amp;#39;, &amp;#39;2005&amp;#39;, &amp;#39;2007&amp;#39;, &amp;#39;2006&amp;#39;, &amp;#39;2012&amp;#39;, &amp;#39;2003&amp;#39;, &amp;#39;2008&amp;#39;, &amp;#39;2009&amp;#39;]
邵阳市 [&amp;#39;2004&amp;#39;, &amp;#39;2005&amp;#39;, &amp;#39;2006&amp;#39;, &amp;#39;2003&amp;#39;, &amp;#39;2008&amp;#39;, &amp;#39;2009&amp;#39;]
乌鲁木齐市 [&amp;#39;2008&amp;#39;, &amp;#39;2009&amp;#39;, &amp;#39;2003&amp;#39;, &amp;#39;2007&amp;#39;, &amp;#39;2013&amp;#39;, &amp;#39;2012&amp;#39;, &amp;#39;2004&amp;#39;, &amp;#39;2005&amp;#39;, &amp;#39;2011&amp;#39;]
来宾市 [&amp;#39;2008&amp;#39;, &amp;#39;2009&amp;#39;, &amp;#39;2003&amp;#39;, &amp;#39;2013&amp;#39;, &amp;#39;2007&amp;#39;, &amp;#39;2012&amp;#39;, &amp;#39;2004&amp;#39;, &amp;#39;2010&amp;#39;, &amp;#39;2011&amp;#39;]
银川市 [&amp;#39;2007&amp;#39;, &amp;#39;2006&amp;#39;, &amp;#39;2004&amp;#39;, &amp;#39;2005&amp;#39;, &amp;#39;2003&amp;#39;, &amp;#39;2008&amp;#39;, &amp;#39;2009&amp;#39;]
淮北市 [&amp;#39;2005&amp;#39;, &amp;#39;2004&amp;#39;, &amp;#39;2003&amp;#39;]
镇江市 [&amp;#39;2009&amp;#39;, &amp;#39;2003&amp;#39;]
兰州市 [&amp;#39;2003&amp;#39;, &amp;#39;2004&amp;#39;, &amp;#39;2005&amp;#39;]
菏泽市 [&amp;#39;2003&amp;#39;]
廊坊市 [&amp;#39;2003&amp;#39;, &amp;#39;2004&amp;#39;, &amp;#39;2011&amp;#39;]
无锡市 [&amp;#39;2003&amp;#39;, &amp;#39;2004&amp;#39;]
丽江市 [&amp;#39;2003&amp;#39;, &amp;#39;2014&amp;#39;, &amp;#39;2011&amp;#39;, &amp;#39;2005&amp;#39;, &amp;#39;2013&amp;#39;, &amp;#39;2006&amp;#39;, &amp;#39;2012&amp;#39;, &amp;#39;2008&amp;#39;]
柳州市 [&amp;#39;2003&amp;#39;]
丹东市 [&amp;#39;2003&amp;#39;, &amp;#39;2004&amp;#39;, &amp;#39;2005&amp;#39;]
鹤岗市 [&amp;#39;2013&amp;#39;]
唐山市 [&amp;#39;2004&amp;#39;, &amp;#39;2003&amp;#39;]
渭南市 [&amp;#39;2003&amp;#39;, &amp;#39;2005&amp;#39;, &amp;#39;2004&amp;#39;]
徐州市 [&amp;#39;2003&amp;#39;]
绵阳市 [&amp;#39;2003&amp;#39;, &amp;#39;2004&amp;#39;]
百色市 [&amp;#39;2009&amp;#39;, &amp;#39;2008&amp;#39;, &amp;#39;2003&amp;#39;, &amp;#39;2004&amp;#39;, &amp;#39;2006&amp;#39;, &amp;#39;2012&amp;#39;]
鸡西市 [&amp;#39;2004&amp;#39;, &amp;#39;2003&amp;#39;]
昆明市 [&amp;#39;2003&amp;#39;, &amp;#39;2004&amp;#39;]
巴彦淖尔市 [&amp;#39;2008&amp;#39;, &amp;#39;2003&amp;#39;, &amp;#39;2004&amp;#39;, &amp;#39;2005&amp;#39;, &amp;#39;2006&amp;#39;]
上饶市 [&amp;#39;2003&amp;#39;, &amp;#39;2004&amp;#39;]
福州市 [&amp;#39;2005&amp;#39;, &amp;#39;2004&amp;#39;, &amp;#39;2003&amp;#39;]
蚌埠市 [&amp;#39;2003&amp;#39;, &amp;#39;2004&amp;#39;]
天水市 [&amp;#39;2003&amp;#39;, &amp;#39;2004&amp;#39;]
秦皇岛市 [&amp;#39;2009&amp;#39;, &amp;#39;2003&amp;#39;, &amp;#39;2004&amp;#39;, &amp;#39;2005&amp;#39;]
萍乡市 [&amp;#39;2009&amp;#39;, &amp;#39;2003&amp;#39;, &amp;#39;2013&amp;#39;, &amp;#39;2006&amp;#39;, &amp;#39;2012&amp;#39;]
吕梁市 [&amp;#39;2003&amp;#39;, &amp;#39;2004&amp;#39;]
内江市 [&amp;#39;2003&amp;#39;]
南平市 [&amp;#39;2007&amp;#39;, &amp;#39;2006&amp;#39;, &amp;#39;2004&amp;#39;, &amp;#39;2005&amp;#39;, &amp;#39;2009&amp;#39;]
拉萨市 [&amp;#39;2004&amp;#39;, &amp;#39;2006&amp;#39;]
营口市 [&amp;#39;2003&amp;#39;]
鹰潭市 [&amp;#39;2003&amp;#39;]
信阳市 [&amp;#39;2003&amp;#39;]
中卫市 [&amp;#39;2003&amp;#39;]
宝鸡市 [&amp;#39;2005&amp;#39;, &amp;#39;2004&amp;#39;, &amp;#39;2003&amp;#39;]
佳木斯市 [&amp;#39;2004&amp;#39;, &amp;#39;2005&amp;#39;, &amp;#39;2007&amp;#39;, &amp;#39;2006&amp;#39;, &amp;#39;2003&amp;#39;]
衡阳市 [&amp;#39;2004&amp;#39;, &amp;#39;2005&amp;#39;, &amp;#39;2006&amp;#39;, &amp;#39;2003&amp;#39;]
绥化市 [&amp;#39;2004&amp;#39;, &amp;#39;2006&amp;#39;]
临汾市 [&amp;#39;2006&amp;#39;, &amp;#39;2005&amp;#39;, &amp;#39;2004&amp;#39;, &amp;#39;2003&amp;#39;]
安庆市 [&amp;#39;2004&amp;#39;, &amp;#39;2003&amp;#39;]
怀化市 [&amp;#39;2005&amp;#39;, &amp;#39;2004&amp;#39;, &amp;#39;2006&amp;#39;, &amp;#39;2003&amp;#39;, &amp;#39;2015&amp;#39;]
陇南市 [&amp;#39;2003&amp;#39;, &amp;#39;2005&amp;#39;, &amp;#39;2004&amp;#39;, &amp;#39;2006&amp;#39;]
保山市 [&amp;#39;2003&amp;#39;, &amp;#39;2004&amp;#39;]
石嘴山市 [&amp;#39;2004&amp;#39;, &amp;#39;2003&amp;#39;]
赤峰市 [&amp;#39;2003&amp;#39;, &amp;#39;2004&amp;#39;]
郴州市 [&amp;#39;2003&amp;#39;, &amp;#39;2006&amp;#39;, &amp;#39;2004&amp;#39;]
景德镇市 [&amp;#39;2005&amp;#39;, &amp;#39;2004&amp;#39;, &amp;#39;2003&amp;#39;]
梅州市 [&amp;#39;2003&amp;#39;]
盐城市 [&amp;#39;2004&amp;#39;, &amp;#39;2005&amp;#39;, &amp;#39;2003&amp;#39;]
钦州市 [&amp;#39;2003&amp;#39;, &amp;#39;2004&amp;#39;]
白银市 [&amp;#39;2003&amp;#39;, &amp;#39;2005&amp;#39;, &amp;#39;2004&amp;#39;]
茂名市 [&amp;#39;2004&amp;#39;, &amp;#39;2003&amp;#39;]
贵港市 [&amp;#39;2013&amp;#39;]
乌海市 [&amp;#39;2003&amp;#39;, &amp;#39;2004&amp;#39;]
泉州市 [&amp;#39;2003&amp;#39;]
随州市 [&amp;#39;2006&amp;#39;, &amp;#39;2007&amp;#39;]
赣州市 [&amp;#39;2006&amp;#39;]
商洛市 [&amp;#39;2003&amp;#39;]
大庆市 [&amp;#39;2003&amp;#39;]
临沂市 [&amp;#39;2003&amp;#39;]
荆州市 [&amp;#39;2003&amp;#39;]
玉林市 [&amp;#39;2003&amp;#39;]
承德市 [&amp;#39;2006&amp;#39;, &amp;#39;2005&amp;#39;, &amp;#39;2004&amp;#39;, &amp;#39;2003&amp;#39;]
巴中市 [&amp;#39;2003&amp;#39;, &amp;#39;2005&amp;#39;, &amp;#39;2004&amp;#39;]
西宁市 [&amp;#39;2006&amp;#39;, &amp;#39;2011&amp;#39;, &amp;#39;2005&amp;#39;, &amp;#39;2004&amp;#39;, &amp;#39;2003&amp;#39;]
普洱市 [&amp;#39;2003&amp;#39;, &amp;#39;2004&amp;#39;]
遂宁市 [&amp;#39;2004&amp;#39;, &amp;#39;2003&amp;#39;]
自贡市 [&amp;#39;2005&amp;#39;, &amp;#39;2006&amp;#39;, &amp;#39;2003&amp;#39;]
德州市 [&amp;#39;2005&amp;#39;, &amp;#39;2004&amp;#39;, &amp;#39;2003&amp;#39;]
葫芦岛市 [&amp;#39;2003&amp;#39;]
德阳市 [&amp;#39;2004&amp;#39;, &amp;#39;2005&amp;#39;, &amp;#39;2003&amp;#39;]
固原市 [&amp;#39;2003&amp;#39;, &amp;#39;2004&amp;#39;, &amp;#39;2010&amp;#39;, &amp;#39;2005&amp;#39;, &amp;#39;2007&amp;#39;]
平凉市 [&amp;#39;2006&amp;#39;, &amp;#39;2004&amp;#39;, &amp;#39;2005&amp;#39;, &amp;#39;2003&amp;#39;]
阜阳市 [&amp;#39;2003&amp;#39;, &amp;#39;2005&amp;#39;, &amp;#39;2004&amp;#39;]
襄阳市 [&amp;#39;2004&amp;#39;]
淮安市 [&amp;#39;2003&amp;#39;, &amp;#39;2010&amp;#39;, &amp;#39;2004&amp;#39;]
咸宁市 [&amp;#39;2003&amp;#39;, &amp;#39;2005&amp;#39;, &amp;#39;2004&amp;#39;]
汉中市 [&amp;#39;2004&amp;#39;, &amp;#39;2003&amp;#39;]
齐齐哈尔市 [&amp;#39;2004&amp;#39;, &amp;#39;2005&amp;#39;, &amp;#39;2003&amp;#39;]
咸阳市 [&amp;#39;2003&amp;#39;, &amp;#39;2004&amp;#39;]
辽源市 [&amp;#39;2003&amp;#39;, &amp;#39;2004&amp;#39;, &amp;#39;2011&amp;#39;, &amp;#39;2005&amp;#39;]
达州市 [&amp;#39;2003&amp;#39;]
娄底市 [&amp;#39;2004&amp;#39;, &amp;#39;2003&amp;#39;]
铜川市 [&amp;#39;2003&amp;#39;, &amp;#39;2004&amp;#39;, &amp;#39;2005&amp;#39;]
亳州市 [&amp;#39;2003&amp;#39;]
长沙市 [&amp;#39;2003&amp;#39;]
东莞市 [&amp;#39;2004&amp;#39;]
贵阳市 [&amp;#39;2003&amp;#39;]
呼伦贝尔市 [&amp;#39;2004&amp;#39;]
庆阳市 [&amp;#39;2003&amp;#39;]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;br&gt;
&lt;h2 id=&#34;二读取数据&#34;&gt;二、读取数据&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;txt比较适合查看，但不太适合做数据分析，最好能汇总为excel&lt;/strong&gt;这种表数据， 每行一条记录， 每列代表一个字段。网上的汇总方法都很复杂的，至少要十几行代码，而且肯定会用到for循环，对编程小白非常不友好！&lt;/p&gt;
&lt;p&gt;使用大邓的目前开源的cntext两行就能搞定， cntext有付费的cntext2.0.0，但免费的就够用了。 打开命令行，执行安装命令 &lt;code&gt;pip3 install cntext&lt;/code&gt;&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;21-ctread_files&#34;&gt;2.1 ct.read_files&lt;/h3&gt;
&lt;p&gt;cntext内置ct.read_files函数，可以处理一切多文件汇总为dataframe。&lt;/p&gt;
&lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;ct&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read_files&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fformat&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;*.*&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;encoding&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;utf-8&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;recursive&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;kwargs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;参数&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;fformat&lt;/strong&gt; 文件路径识别模式, &lt;code&gt;*.*&lt;/code&gt;意味着识别一切文件格式，
- &lt;code&gt;*.txt&lt;/code&gt;识别所有txt
- &lt;code&gt;*.xls&lt;/code&gt;识别所有xls
- &lt;code&gt;*.pdf&lt;/code&gt;识别所有pdf，
- &lt;code&gt;data/*.txt&lt;/code&gt; 识别data文件夹内所有txt文件
- &lt;code&gt;data/*/*.txt&lt;/code&gt; 识别data文件夹内所有子文件夹内的所有txt文件&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;encoding&lt;/strong&gt; 文件编码方式， 一般情况不用设置。但是当csv、txt的文件编码不是utf-8时，需要传参。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;recursive&lt;/strong&gt; 默认遍历搜寻某文件夹下所有的文件&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
&lt;p&gt;目前cntext支持txt、csv、xlsx、xls、docx、pdf等常用的文件，返回dataFrame。 每个文件对应dataframe中的一行。&lt;/p&gt;
&lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;cntext&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;ct&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;#识别 GovReportData/nation1954-2023 内所有的txt&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;nation_df&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ct&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read_files&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fformat&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;GovReportData/nation1954-2023/*.txt&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;国级报告数: &amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;nation_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;nation_df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;head&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;国级报告数: 70
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/01-df.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;c1&#34;&gt;#识别 GovReportData/prov2002-2023 内所有的txt&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;prov_df&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ct&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read_files&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fformat&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;GovReportData/prov2002-2023/*.txt&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;省级报告数: &amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;prov_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;prov_df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;head&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;省级报告数: 713
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/02-df.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;c1&#34;&gt;#识别 GovReportData/city2003-2023 内所有的txt&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;city_df&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ct&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read_files&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fformat&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;GovReportData/city2003-2023/*.txt&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;市级报告数: &amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;city_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;city_df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;head&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;市级报告数: 5922
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/03-df.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;三数据清洗&#34;&gt;三、数据清洗&lt;/h2&gt;
&lt;h3 id=&#34;31-构造year字段&#34;&gt;3.1 构造year字段&lt;/h3&gt;
&lt;p&gt;分别给国、省、市三个df构建对应的year字段。国家级file字段&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;file = &amp;#39;GovReportData/nation1954-2023/2002.txt&amp;#39;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;可以看到，只要用 &lt;code&gt;file.split(&#39;/&#39;)[-1].replace(&#39;.txt&#39;, &#39;&#39;)&lt;/code&gt; 即可得到 &lt;code&gt;2002&lt;/code&gt; 。用 apply 方法对 file 使用 lambda 函数，得到 year 字段。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;nation_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;year&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nation_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;file&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;apply&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;lambda&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;split&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;/&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)[&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;replace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;.txt&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;nation_df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;head&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/04-df.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;br&gt;
&lt;p&gt;参照类似的思路，省、市略有不同，代码如下&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;prov_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;year&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;prov_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;file&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;apply&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;lambda&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;split&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;/&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)[&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;replace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;.txt&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)[&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:])&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;city_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;year&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;city_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;file&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;apply&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;lambda&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;split&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;/&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)[&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;replace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;.txt&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)[&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;br&gt;
&lt;h3 id=&#34;32-构造省市字段&#34;&gt;3.2 构造省、市字段&lt;/h3&gt;
&lt;p&gt;分别构建省市字段,&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;#省
file = &amp;#39;GovReportData/prov2002-2023/浙江省2023.txt&amp;#39;
file = &amp;#39;GovReportData/prov2002-2023/新疆维吾尔族自治区2016.txt&amp;#39;

#市
file = &amp;#39;GovReportData/city2003-2023/宜昌市2015.txt&amp;#39;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;可以看到，只要用 &lt;code&gt;file.split(&#39;/&#39;)[-1].replace(&#39;.txt&#39;, &#39;&#39;)[:-4]&lt;/code&gt; 即可分别得到 &lt;code&gt;浙江省、 新疆维吾尔族自治区、宜昌市&lt;/code&gt;。用 apply 方法对 file 使用 lambda 函数，得到  &lt;code&gt;prov 、city&lt;/code&gt; 字段。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;prov_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;prov&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;prov_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;file&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;apply&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;lambda&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;split&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;/&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)[&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;replace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;.txt&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)[:&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;city_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;city&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;city_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;file&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;apply&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;lambda&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;split&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;/&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)[&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;replace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;.txt&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)[:&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;city_df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;head&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/05-df.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;br&gt;
&lt;h2 id=&#34;四-文本分析&#34;&gt;四、 文本分析&lt;/h2&gt;
&lt;h3 id=&#34;41-国-词频&#34;&gt;4.1 国-词频&lt;/h3&gt;
&lt;p&gt;计算总词语数、某类词出现的次数，计算各政府提及【环保】的频率&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;jieba&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;nation_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;word_num&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nation_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;doc&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fillna&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;apply&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;lambda&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;jieba&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;lcut&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)))&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;nation_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;env_num&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nation_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;doc&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fillna&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;str&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;count&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;环保|环境|污染|青山|绿水&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;nation_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;env_ratio&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nation_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;env_num&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;nation_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;word_num&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;nation_df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;head&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/06-df.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;42-可视化&#34;&gt;4.2 可视化&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;plt&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;matplotlib&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;matplotlib_inline&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;matplotlib_inline&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;backend_inline&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;set_matplotlib_formats&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;png&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;svg&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;scienceplots&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;platform&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pandas&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pd&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;numpy&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;np&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;jieba&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;plt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;style&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;use&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;([&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;science&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;no-latex&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;cjk-sc-font&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;system&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;platform&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;system&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;# 获取操作系统类型&lt;/span&gt;

&lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;system&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;Windows&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;font&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;family&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;SimHei&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;span class=&#34;k&#34;&gt;elif&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;system&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;Darwin&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;font&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;family&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;Arial Unicode MS&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;span class=&#34;k&#34;&gt;else&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;font&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;family&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;sans-serif&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;matplotlib&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;rc&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;font&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;font&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;# 设置全局字体&lt;/span&gt;



&lt;span class=&#34;n&#34;&gt;plt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;figure&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;figsize&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;12&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;plt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;plot&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;nation_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;year&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nation_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;env_ratio&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;plt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;title&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;国级报告中「环保概念词」提及频率折线图(1954-2023)&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;plt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;show&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/gov-plot.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;p&gt;大家应该都学过正泰分布中， 数据中大多数的记录会落在 均值+-标准差 范围内，&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/mean&amp;#43;std.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;这里设置 &lt;strong&gt;top_nation_mask&lt;/strong&gt;、&lt;strong&gt;bottom_nation_mask&lt;/strong&gt; ，分别识别到最重视环保的年份、最不重视环保的年份&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;top_nation_mask&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nation_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;env_ratio&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mean&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nation_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;env_ratio&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;std&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;bottom_nation_mask&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nation_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;env_ratio&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mean&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nation_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;env_ratio&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;std&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;

&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;最重视环保的年份&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;nation_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;nation_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;env_ratio&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;top_nation_mask&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;year&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;values&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;

&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;

&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;最忽视环保的年份&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;nation_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;nation_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;env_ratio&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;bottom_nation_mask&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;][&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;year&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;values&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;最重视环保的年份
[&amp;#39;2016&amp;#39; &amp;#39;2017&amp;#39; &amp;#39;2003&amp;#39; &amp;#39;2015&amp;#39; &amp;#39;2001&amp;#39; &amp;#39;2005&amp;#39; &amp;#39;2007&amp;#39; &amp;#39;2006&amp;#39; &amp;#39;2023&amp;#39; &amp;#39;2021&amp;#39;
 &amp;#39;2019&amp;#39;]

最忽视环保的年份
[&amp;#39;1959&amp;#39; &amp;#39;1964&amp;#39; &amp;#39;1958&amp;#39; &amp;#39;1960&amp;#39; &amp;#39;1975&amp;#39; &amp;#39;1978&amp;#39; &amp;#39;1979&amp;#39; &amp;#39;1985&amp;#39; &amp;#39;1981&amp;#39; &amp;#39;1956&amp;#39;
 &amp;#39;1957&amp;#39; &amp;#39;1980&amp;#39; &amp;#39;1955&amp;#39; &amp;#39;1954&amp;#39; &amp;#39;1983&amp;#39;]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;p&gt;可以看到进入21世纪，国家对环保重视从报告中就能看出。而在前期，因为生存是首要解决的，对环境保护的认识事不足的。&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;42-省-词频&#34;&gt;4.2 省-词频&lt;/h3&gt;
&lt;p&gt;计算总词语数、某类词出现的次数，计算各省提及【环保】的频率。因为省份的记录有770条，现在咱们把条件变严格，&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt; top = mean+3*std, 
 bottom = mean-2std
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;大家可以自己设置条件的严格程度&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;prov_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;word_num&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;prov_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;doc&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fillna&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;apply&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;lambda&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;jieba&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;lcut&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)))&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;prov_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;env_num&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;prov_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;doc&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fillna&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;str&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;count&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;环保|环境|污染|青山|绿水&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;prov_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;env_ratio&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;prov_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;env_num&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;prov_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;word_num&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;top_prov_mask&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;prov_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;env_ratio&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mean&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;prov_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;env_ratio&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;std&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;bottom_prov_mask&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;prov_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;env_ratio&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mean&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;prov_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;env_ratio&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;std&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;

&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;最重视环保的省(年份)&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;prov_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;prov_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;env_ratio&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;top_prov_mask&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;][[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;prov&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;year&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/07-df.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;prov_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;prov_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;env_ratio&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;bottom_prov_mask&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;][[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;prov&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;year&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/08-df.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;重视环保结果挺合理的， 某人曾在浙江任职过，对环保比较重视，近年来浙江也比较重视环保，是真的很早就执行，环保搞得很好。而河北，笔者家乡，主要是跟钢铁产业关停并转，守卫di都蓝天有很大关系。&lt;/p&gt;
&lt;p&gt;比较忽视环保， 或者不怎么提及环保概念的省份， 也跟经济发展水平有一定关系，主要是重工业不发达， 自身自然的环境条件较好。&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;45--保存结果&#34;&gt;4.5  保存结果&lt;/h3&gt;
&lt;p&gt;将初步整理的结果保存到csv中，&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;nation_df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;to_csv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;nation_report1954-2023.csv&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;index&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;False&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;prov_df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;to_csv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;prov_report2002-2023.csv&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;index&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;False&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;city_df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;to_csv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;city_report2003-2023.csv&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;index&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;False&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;p&gt;更多内容可在大邓博客 textdata.cn 中寻找相关代码。&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;五获取数据&#34;&gt;五、获取数据&lt;/h2&gt;
&lt;p&gt;数据集100元，  &lt;strong&gt;加微信 372335839， 备注「姓名-学校-专业」&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;广而告之&#34;&gt;广而告之&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/call_for_paper/&#34;&gt;长期征稿&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/we_need_you/&#34;&gt;长期招募小伙伴&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/management_python_course/&#34;&gt;付费视频课 | Python实证指标构建与文本分析&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
      <content:encoded><![CDATA[<h2 id="相关代码">相关代码</h2>
<p><a href="https://textdata.cn/blog/2023-12-17-how-to-generate-panel-data-from-gov-report-dataset/">代码 | 使用地方gov工作报告生成某类概念词词频面板数据</a></p>
<p><br><br></p>
<h2 id="一数据集">一、数据集</h2>
<h3 id="11-数据简介">1.1 数据简介</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">国级(guo wu yuan)工作报告1954-2023, 记录数70

省级zf工作报告2002-2023, 记录数713

市级zf工作报告2003-2023, 记录数5922
</code></pre></div><p>数据集100元，  <strong>加微信 372335839， 备注「姓名-学校-专业」</strong>。</p>
<br>
<h3 id="12-文件树目录">1.2 文件树目录</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">|- 代码.ipynb

|- GovReportData
    |-nation1954-2023
        |-1954.txt
        |-1955.txt
        |-...
        |-2022.txt
        |-2023.txt
        
    |-prov2002-2023
        |-安徽省2001.txt
        |-...
        |-安徽省2023.txt
        |-...
        |-浙江省2023.txt
        
    |-city2003-2023
        |-安康市2003.txt
        |-...
        |-安庆市2003.txt
        |-...
        |-安庆市2023.txt
</code></pre></div><br>
<h3 id="13-查看缺失数据">1.3 查看缺失数据</h3>
<p>使用爬虫和人工搜集， 也不能保证数据的完整性， 下面给各位客官看下数据的缺失情况，方便大家使用数据时心里有数。</p>
<p>缺失的txt文件非常小，一般只有几个字节，而正常的报告至少是几十kb。只需要通过审查小于1kb的文件即可得知缺失的数据。</p>
<br>
<h3 id="131--国-缺失情况">1.3.1  国-缺失情况</h3>
<p>国家级(guo wu yuan)报告1954-2023，</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">os</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;国级报告缺失: </span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">nation_files</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s1">&#39;GovReportData/nation1954-2023/</span><span class="si">{</span><span class="n">year</span><span class="si">}</span><span class="s1">.txt&#39;</span> <span class="k">for</span> <span class="n">year</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1954</span><span class="p">,</span> <span class="mi">2024</span><span class="p">)]</span>
<span class="k">for</span> <span class="n">file</span> <span class="ow">in</span> <span class="n">nation_files</span><span class="p">:</span>
    <span class="n">fsize</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">getsize</span><span class="p">(</span><span class="n">file</span><span class="p">)</span><span class="o">/</span><span class="mi">1024</span>  <span class="c1">#kb</span>
    <span class="k">if</span> <span class="n">fsize</span><span class="o">&lt;</span><span class="mi">1</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">file</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;/&#39;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;.txt&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">))</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">国级报告缺失: 

1961
1962
1963
1965
1966
1967
1968
1969
1970
1971
1972
1973
1974
1976
1977
</code></pre></div><br>
<h3 id="32-省-缺失情况">3.2 省-缺失情况</h3>
<p>2002-2023,省份缺失情况</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;省级报告缺失: </span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="n">prov_files</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s1">&#39;GovReportData/prov2002-2023/</span><span class="si">{</span><span class="n">file</span><span class="si">}</span><span class="s1">&#39;</span> 
              <span class="k">for</span> <span class="n">file</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="s1">&#39;GovReportData/prov2002-2023&#39;</span><span class="p">)]</span>
<span class="k">for</span> <span class="n">file</span> <span class="ow">in</span> <span class="n">prov_files</span><span class="p">:</span>
    <span class="n">fsize</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">getsize</span><span class="p">(</span><span class="n">file</span><span class="p">)</span><span class="o">/</span><span class="mi">1024</span>  <span class="c1">#kb</span>
    <span class="k">if</span> <span class="n">fsize</span><span class="o">&lt;</span><span class="mi">1</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">file</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;/&#39;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;.txt&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">))</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">省级报告缺失: 

云南省2001
新疆维吾尔族自治区2001
重庆市2001
广西壮族自治区2001
天津市2001
青海省2001
湖南省2001
西藏自治区2001
湖北省2001
山西省2001
江西省2001
江苏省2001
辽宁省2001
宁夏回族自治区2001
</code></pre></div><br>
<h3 id="33-市-缺失情况">3.3 市-缺失情况</h3>
<p>2003-2023，市-缺失情况</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;市级报告缺失: </span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="n">data</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
<span class="n">prov_files</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s1">&#39;GovReportData/city2003-2023/</span><span class="si">{</span><span class="n">file</span><span class="si">}</span><span class="s1">&#39;</span> 
              <span class="k">for</span> <span class="n">file</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="s1">&#39;GovReportData/city2003-2023&#39;</span><span class="p">)]</span>
<span class="k">for</span> <span class="n">file</span> <span class="ow">in</span> <span class="n">prov_files</span><span class="p">:</span>
    <span class="n">fsize</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">getsize</span><span class="p">(</span><span class="n">file</span><span class="p">)</span><span class="o">/</span><span class="mi">1024</span>  <span class="c1">#kb</span>
    <span class="k">if</span> <span class="n">fsize</span><span class="o">&lt;</span><span class="mi">1</span><span class="p">:</span>
        <span class="n">city</span> <span class="o">=</span> <span class="n">file</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;/&#39;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;.txt&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">)[:</span><span class="o">-</span><span class="mi">4</span><span class="p">]</span>
        <span class="n">year</span> <span class="o">=</span> <span class="n">file</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;/&#39;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;.txt&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">)[</span><span class="o">-</span><span class="mi">4</span><span class="p">:]</span>
        <span class="n">data</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="n">city</span><span class="p">,</span> <span class="p">[])</span>
        <span class="n">data</span><span class="p">[</span><span class="n">city</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">city</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="n">year</span><span class="p">]</span>
        
<span class="k">for</span> <span class="n">key</span><span class="p">,</span><span class="n">value</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">市级报告缺失: 

苏州市 [&#39;2003&#39;]
酒泉市 [&#39;2005&#39;, &#39;2004&#39;, &#39;2003&#39;]
资阳市 [&#39;2004&#39;, &#39;2003&#39;]
双鸭山市 [&#39;2008&#39;, &#39;2009&#39;, &#39;2014&#39;, &#39;2003&#39;, &#39;2007&#39;, &#39;2012&#39;, &#39;2006&#39;, &#39;2010&#39;, &#39;2004&#39;, &#39;2005&#39;, &#39;2011&#39;]
七台河市 [&#39;2005&#39;, &#39;2004&#39;, &#39;2006&#39;, &#39;2003&#39;]
张家口市 [&#39;2004&#39;, &#39;2005&#39;, &#39;2007&#39;, &#39;2006&#39;, &#39;2003&#39;, &#39;2009&#39;]
抚州市 [&#39;2004&#39;, &#39;2010&#39;, &#39;2005&#39;, &#39;2013&#39;, &#39;2007&#39;, &#39;2006&#39;, &#39;2003&#39;, &#39;2009&#39;]
阳泉市 [&#39;2008&#39;, &#39;2003&#39;, &#39;2007&#39;, &#39;2006&#39;, &#39;2010&#39;, &#39;2004&#39;, &#39;2005&#39;]
湘潭市 [&#39;2005&#39;, &#39;2004&#39;, &#39;2006&#39;, &#39;2007&#39;, &#39;2003&#39;]
新余市 [&#39;2009&#39;, &#39;2008&#39;, &#39;2003&#39;, &#39;2007&#39;]
克拉玛依市 [&#39;2011&#39;, &#39;2005&#39;, &#39;2004&#39;, &#39;2010&#39;, &#39;2006&#39;, &#39;2012&#39;, &#39;2013&#39;, &#39;2007&#39;, &#39;2003&#39;, &#39;2014&#39;, &#39;2015&#39;, &#39;2009&#39;, &#39;2008&#39;]
铜陵市 [&#39;2005&#39;, &#39;2004&#39;, &#39;2007&#39;, &#39;2003&#39;]
宣城市 [&#39;2003&#39;]
昭通市 [&#39;2007&#39;, &#39;2006&#39;, &#39;2004&#39;, &#39;2005&#39;, &#39;2003&#39;, &#39;2008&#39;, &#39;2009&#39;]
忻州市 [&#39;2003&#39;, &#39;2005&#39;, &#39;2004&#39;, &#39;2006&#39;, &#39;2008&#39;]
永州市 [&#39;2003&#39;, &#39;2004&#39;, &#39;2005&#39;, &#39;2006&#39;, &#39;2008&#39;]
孝感市 [&#39;2004&#39;, &#39;2003&#39;]
定西市 [&#39;2009&#39;, &#39;2003&#39;, &#39;2006&#39;, &#39;2004&#39;, &#39;2005&#39;]
滁州市 [&#39;2006&#39;, &#39;2004&#39;, &#39;2005&#39;, &#39;2003&#39;]
湖州市 [&#39;2008&#39;, &#39;2003&#39;, &#39;2013&#39;, &#39;2007&#39;, &#39;2005&#39;, &#39;2004&#39;]
河池市 [&#39;2003&#39;]
呼和浩特市 [&#39;2005&#39;, &#39;2004&#39;, &#39;2003&#39;]
遵义市 [&#39;2005&#39;, &#39;2004&#39;, &#39;2003&#39;]
成都市 [&#39;2004&#39;, &#39;2005&#39;, &#39;2003&#39;]
南充市 [&#39;2003&#39;, &#39;2005&#39;, &#39;2004&#39;]
海东市 [&#39;2008&#39;, &#39;2009&#39;, &#39;2003&#39;, &#39;2010&#39;, &#39;2004&#39;, &#39;2005&#39;, &#39;2011&#39;, &#39;2007&#39;, &#39;2012&#39;, &#39;2006&#39;]
石家庄市 [&#39;2003&#39;, &#39;2005&#39;, &#39;2004&#39;]
运城市 [&#39;2003&#39;]
黄山市 [&#39;2005&#39;, &#39;2004&#39;, &#39;2003&#39;]
北海市 [&#39;2003&#39;, &#39;2006&#39;, &#39;2005&#39;, &#39;2004&#39;]
漳州市 [&#39;2004&#39;]
六安市 [&#39;2003&#39;, &#39;2007&#39;]
安康市 [&#39;2003&#39;, &#39;2004&#39;]
汕尾市 [&#39;2003&#39;, &#39;2004&#39;, &#39;2005&#39;]
合肥市 [&#39;2003&#39;, &#39;2004&#39;, &#39;2005&#39;]
宜昌市 [&#39;2003&#39;, &#39;2010&#39;, &#39;2004&#39;, &#39;2022&#39;]
乌兰察布市 [&#39;2008&#39;, &#39;2009&#39;, &#39;2007&#39;, &#39;2006&#39;, &#39;2010&#39;, &#39;2004&#39;, &#39;2005&#39;, &#39;2003&#39;]
衡水市 [&#39;2008&#39;, &#39;2009&#39;, &#39;2007&#39;, &#39;2006&#39;, &#39;2010&#39;, &#39;2004&#39;, &#39;2011&#39;, &#39;2003&#39;]
金昌市 [&#39;2011&#39;]
沧州市 [&#39;2007&#39;, &#39;2009&#39;, &#39;2008&#39;]
广安市 [&#39;2005&#39;, &#39;2013&#39;]
吉林市 [&#39;2009&#39;, &#39;2008&#39;, &#39;2005&#39;, &#39;2010&#39;, &#39;2004&#39;, &#39;2003&#39;]
临沧市 [&#39;2003&#39;]
潍坊市 [&#39;2003&#39;]
杭州市 [&#39;2004&#39;]
淮南市 [&#39;2003&#39;, &#39;2005&#39;, &#39;2004&#39;, &#39;2007&#39;]
吉安市 [&#39;2004&#39;, &#39;2005&#39;, &#39;2006&#39;, &#39;2003&#39;, &#39;2008&#39;, &#39;2009&#39;]
衢州市 [&#39;2004&#39;, &#39;2005&#39;, &#39;2007&#39;, &#39;2006&#39;, &#39;2012&#39;, &#39;2003&#39;, &#39;2008&#39;, &#39;2009&#39;]
邵阳市 [&#39;2004&#39;, &#39;2005&#39;, &#39;2006&#39;, &#39;2003&#39;, &#39;2008&#39;, &#39;2009&#39;]
乌鲁木齐市 [&#39;2008&#39;, &#39;2009&#39;, &#39;2003&#39;, &#39;2007&#39;, &#39;2013&#39;, &#39;2012&#39;, &#39;2004&#39;, &#39;2005&#39;, &#39;2011&#39;]
来宾市 [&#39;2008&#39;, &#39;2009&#39;, &#39;2003&#39;, &#39;2013&#39;, &#39;2007&#39;, &#39;2012&#39;, &#39;2004&#39;, &#39;2010&#39;, &#39;2011&#39;]
银川市 [&#39;2007&#39;, &#39;2006&#39;, &#39;2004&#39;, &#39;2005&#39;, &#39;2003&#39;, &#39;2008&#39;, &#39;2009&#39;]
淮北市 [&#39;2005&#39;, &#39;2004&#39;, &#39;2003&#39;]
镇江市 [&#39;2009&#39;, &#39;2003&#39;]
兰州市 [&#39;2003&#39;, &#39;2004&#39;, &#39;2005&#39;]
菏泽市 [&#39;2003&#39;]
廊坊市 [&#39;2003&#39;, &#39;2004&#39;, &#39;2011&#39;]
无锡市 [&#39;2003&#39;, &#39;2004&#39;]
丽江市 [&#39;2003&#39;, &#39;2014&#39;, &#39;2011&#39;, &#39;2005&#39;, &#39;2013&#39;, &#39;2006&#39;, &#39;2012&#39;, &#39;2008&#39;]
柳州市 [&#39;2003&#39;]
丹东市 [&#39;2003&#39;, &#39;2004&#39;, &#39;2005&#39;]
鹤岗市 [&#39;2013&#39;]
唐山市 [&#39;2004&#39;, &#39;2003&#39;]
渭南市 [&#39;2003&#39;, &#39;2005&#39;, &#39;2004&#39;]
徐州市 [&#39;2003&#39;]
绵阳市 [&#39;2003&#39;, &#39;2004&#39;]
百色市 [&#39;2009&#39;, &#39;2008&#39;, &#39;2003&#39;, &#39;2004&#39;, &#39;2006&#39;, &#39;2012&#39;]
鸡西市 [&#39;2004&#39;, &#39;2003&#39;]
昆明市 [&#39;2003&#39;, &#39;2004&#39;]
巴彦淖尔市 [&#39;2008&#39;, &#39;2003&#39;, &#39;2004&#39;, &#39;2005&#39;, &#39;2006&#39;]
上饶市 [&#39;2003&#39;, &#39;2004&#39;]
福州市 [&#39;2005&#39;, &#39;2004&#39;, &#39;2003&#39;]
蚌埠市 [&#39;2003&#39;, &#39;2004&#39;]
天水市 [&#39;2003&#39;, &#39;2004&#39;]
秦皇岛市 [&#39;2009&#39;, &#39;2003&#39;, &#39;2004&#39;, &#39;2005&#39;]
萍乡市 [&#39;2009&#39;, &#39;2003&#39;, &#39;2013&#39;, &#39;2006&#39;, &#39;2012&#39;]
吕梁市 [&#39;2003&#39;, &#39;2004&#39;]
内江市 [&#39;2003&#39;]
南平市 [&#39;2007&#39;, &#39;2006&#39;, &#39;2004&#39;, &#39;2005&#39;, &#39;2009&#39;]
拉萨市 [&#39;2004&#39;, &#39;2006&#39;]
营口市 [&#39;2003&#39;]
鹰潭市 [&#39;2003&#39;]
信阳市 [&#39;2003&#39;]
中卫市 [&#39;2003&#39;]
宝鸡市 [&#39;2005&#39;, &#39;2004&#39;, &#39;2003&#39;]
佳木斯市 [&#39;2004&#39;, &#39;2005&#39;, &#39;2007&#39;, &#39;2006&#39;, &#39;2003&#39;]
衡阳市 [&#39;2004&#39;, &#39;2005&#39;, &#39;2006&#39;, &#39;2003&#39;]
绥化市 [&#39;2004&#39;, &#39;2006&#39;]
临汾市 [&#39;2006&#39;, &#39;2005&#39;, &#39;2004&#39;, &#39;2003&#39;]
安庆市 [&#39;2004&#39;, &#39;2003&#39;]
怀化市 [&#39;2005&#39;, &#39;2004&#39;, &#39;2006&#39;, &#39;2003&#39;, &#39;2015&#39;]
陇南市 [&#39;2003&#39;, &#39;2005&#39;, &#39;2004&#39;, &#39;2006&#39;]
保山市 [&#39;2003&#39;, &#39;2004&#39;]
石嘴山市 [&#39;2004&#39;, &#39;2003&#39;]
赤峰市 [&#39;2003&#39;, &#39;2004&#39;]
郴州市 [&#39;2003&#39;, &#39;2006&#39;, &#39;2004&#39;]
景德镇市 [&#39;2005&#39;, &#39;2004&#39;, &#39;2003&#39;]
梅州市 [&#39;2003&#39;]
盐城市 [&#39;2004&#39;, &#39;2005&#39;, &#39;2003&#39;]
钦州市 [&#39;2003&#39;, &#39;2004&#39;]
白银市 [&#39;2003&#39;, &#39;2005&#39;, &#39;2004&#39;]
茂名市 [&#39;2004&#39;, &#39;2003&#39;]
贵港市 [&#39;2013&#39;]
乌海市 [&#39;2003&#39;, &#39;2004&#39;]
泉州市 [&#39;2003&#39;]
随州市 [&#39;2006&#39;, &#39;2007&#39;]
赣州市 [&#39;2006&#39;]
商洛市 [&#39;2003&#39;]
大庆市 [&#39;2003&#39;]
临沂市 [&#39;2003&#39;]
荆州市 [&#39;2003&#39;]
玉林市 [&#39;2003&#39;]
承德市 [&#39;2006&#39;, &#39;2005&#39;, &#39;2004&#39;, &#39;2003&#39;]
巴中市 [&#39;2003&#39;, &#39;2005&#39;, &#39;2004&#39;]
西宁市 [&#39;2006&#39;, &#39;2011&#39;, &#39;2005&#39;, &#39;2004&#39;, &#39;2003&#39;]
普洱市 [&#39;2003&#39;, &#39;2004&#39;]
遂宁市 [&#39;2004&#39;, &#39;2003&#39;]
自贡市 [&#39;2005&#39;, &#39;2006&#39;, &#39;2003&#39;]
德州市 [&#39;2005&#39;, &#39;2004&#39;, &#39;2003&#39;]
葫芦岛市 [&#39;2003&#39;]
德阳市 [&#39;2004&#39;, &#39;2005&#39;, &#39;2003&#39;]
固原市 [&#39;2003&#39;, &#39;2004&#39;, &#39;2010&#39;, &#39;2005&#39;, &#39;2007&#39;]
平凉市 [&#39;2006&#39;, &#39;2004&#39;, &#39;2005&#39;, &#39;2003&#39;]
阜阳市 [&#39;2003&#39;, &#39;2005&#39;, &#39;2004&#39;]
襄阳市 [&#39;2004&#39;]
淮安市 [&#39;2003&#39;, &#39;2010&#39;, &#39;2004&#39;]
咸宁市 [&#39;2003&#39;, &#39;2005&#39;, &#39;2004&#39;]
汉中市 [&#39;2004&#39;, &#39;2003&#39;]
齐齐哈尔市 [&#39;2004&#39;, &#39;2005&#39;, &#39;2003&#39;]
咸阳市 [&#39;2003&#39;, &#39;2004&#39;]
辽源市 [&#39;2003&#39;, &#39;2004&#39;, &#39;2011&#39;, &#39;2005&#39;]
达州市 [&#39;2003&#39;]
娄底市 [&#39;2004&#39;, &#39;2003&#39;]
铜川市 [&#39;2003&#39;, &#39;2004&#39;, &#39;2005&#39;]
亳州市 [&#39;2003&#39;]
长沙市 [&#39;2003&#39;]
东莞市 [&#39;2004&#39;]
贵阳市 [&#39;2003&#39;]
呼伦贝尔市 [&#39;2004&#39;]
庆阳市 [&#39;2003&#39;]
</code></pre></div><br>
<br>
<h2 id="二读取数据">二、读取数据</h2>
<p><strong>txt比较适合查看，但不太适合做数据分析，最好能汇总为excel</strong>这种表数据， 每行一条记录， 每列代表一个字段。网上的汇总方法都很复杂的，至少要十几行代码，而且肯定会用到for循环，对编程小白非常不友好！</p>
<p>使用大邓的目前开源的cntext两行就能搞定， cntext有付费的cntext2.0.0，但免费的就够用了。 打开命令行，执行安装命令 <code>pip3 install cntext</code></p>
<br>
<h3 id="21-ctread_files">2.1 ct.read_files</h3>
<p>cntext内置ct.read_files函数，可以处理一切多文件汇总为dataframe。</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">ct</span><span class="o">.</span><span class="n">read_files</span><span class="p">(</span><span class="n">fformat</span><span class="o">=</span><span class="s1">&#39;*.*&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">,</span> <span class="n">recursive</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</code></pre></div><p><strong>参数</strong></p>
<ul>
<li>
<p><strong>fformat</strong> 文件路径识别模式, <code>*.*</code>意味着识别一切文件格式，
- <code>*.txt</code>识别所有txt
- <code>*.xls</code>识别所有xls
- <code>*.pdf</code>识别所有pdf，
- <code>data/*.txt</code> 识别data文件夹内所有txt文件
- <code>data/*/*.txt</code> 识别data文件夹内所有子文件夹内的所有txt文件</p>
</li>
<li>
<p><strong>encoding</strong> 文件编码方式， 一般情况不用设置。但是当csv、txt的文件编码不是utf-8时，需要传参。</p>
</li>
<li>
<p><strong>recursive</strong> 默认遍历搜寻某文件夹下所有的文件</p>
</li>
</ul>
<br>
<p>目前cntext支持txt、csv、xlsx、xls、docx、pdf等常用的文件，返回dataFrame。 每个文件对应dataframe中的一行。</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>

<span class="c1">#识别 GovReportData/nation1954-2023 内所有的txt</span>
<span class="n">nation_df</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">read_files</span><span class="p">(</span><span class="n">fformat</span><span class="o">=</span><span class="s1">&#39;GovReportData/nation1954-2023/*.txt&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;国级报告数: &#39;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">nation_df</span><span class="p">))</span>
<span class="n">nation_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">国级报告数: 70
</code></pre></div><p><img loading="lazy" src="img/01-df.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#识别 GovReportData/prov2002-2023 内所有的txt</span>
<span class="n">prov_df</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">read_files</span><span class="p">(</span><span class="n">fformat</span><span class="o">=</span><span class="s1">&#39;GovReportData/prov2002-2023/*.txt&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;省级报告数: &#39;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">prov_df</span><span class="p">))</span>
<span class="n">prov_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">省级报告数: 713
</code></pre></div><p><img loading="lazy" src="img/02-df.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#识别 GovReportData/city2003-2023 内所有的txt</span>
<span class="n">city_df</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">read_files</span><span class="p">(</span><span class="n">fformat</span><span class="o">=</span><span class="s1">&#39;GovReportData/city2003-2023/*.txt&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;市级报告数: &#39;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">city_df</span><span class="p">))</span>
<span class="n">city_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">市级报告数: 5922
</code></pre></div><p><img loading="lazy" src="img/03-df.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="三数据清洗">三、数据清洗</h2>
<h3 id="31-构造year字段">3.1 构造year字段</h3>
<p>分别给国、省、市三个df构建对应的year字段。国家级file字段</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">file = &#39;GovReportData/nation1954-2023/2002.txt&#39;
</code></pre></div><p>可以看到，只要用 <code>file.split('/')[-1].replace('.txt', '')</code> 即可得到 <code>2002</code> 。用 apply 方法对 file 使用 lambda 函数，得到 year 字段。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">nation_df</span><span class="p">[</span><span class="s1">&#39;year&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">nation_df</span><span class="p">[</span><span class="s1">&#39;file&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">f</span><span class="p">:</span> <span class="n">f</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;/&#39;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;.txt&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">))</span>
<span class="n">nation_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/04-df.png" alt=""  />
</p>
<br>
<br>
<p>参照类似的思路，省、市略有不同，代码如下</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">prov_df</span><span class="p">[</span><span class="s1">&#39;year&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">prov_df</span><span class="p">[</span><span class="s1">&#39;file&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">f</span><span class="p">:</span> <span class="n">f</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;/&#39;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;.txt&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">)[</span><span class="o">-</span><span class="mi">4</span><span class="p">:])</span>
<span class="n">city_df</span><span class="p">[</span><span class="s1">&#39;year&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">city_df</span><span class="p">[</span><span class="s1">&#39;file&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">f</span><span class="p">:</span> <span class="n">f</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;/&#39;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;.txt&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">)[</span><span class="o">-</span><span class="mi">4</span><span class="p">:])</span>
</code></pre></div><br>
<br>
<h3 id="32-构造省市字段">3.2 构造省、市字段</h3>
<p>分别构建省市字段,</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">#省
file = &#39;GovReportData/prov2002-2023/浙江省2023.txt&#39;
file = &#39;GovReportData/prov2002-2023/新疆维吾尔族自治区2016.txt&#39;

#市
file = &#39;GovReportData/city2003-2023/宜昌市2015.txt&#39;
</code></pre></div><p>可以看到，只要用 <code>file.split('/')[-1].replace('.txt', '')[:-4]</code> 即可分别得到 <code>浙江省、 新疆维吾尔族自治区、宜昌市</code>。用 apply 方法对 file 使用 lambda 函数，得到  <code>prov 、city</code> 字段。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">prov_df</span><span class="p">[</span><span class="s1">&#39;prov&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">prov_df</span><span class="p">[</span><span class="s1">&#39;file&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">f</span><span class="p">:</span> <span class="n">f</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;/&#39;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;.txt&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">)[:</span><span class="o">-</span><span class="mi">4</span><span class="p">])</span>
<span class="n">city_df</span><span class="p">[</span><span class="s1">&#39;city&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">city_df</span><span class="p">[</span><span class="s1">&#39;file&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">f</span><span class="p">:</span> <span class="n">f</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;/&#39;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;.txt&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">)[:</span><span class="o">-</span><span class="mi">4</span><span class="p">])</span>

<span class="n">city_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/05-df.png" alt=""  />
</p>
<br>
<br>
<h2 id="四-文本分析">四、 文本分析</h2>
<h3 id="41-国-词频">4.1 国-词频</h3>
<p>计算总词语数、某类词出现的次数，计算各政府提及【环保】的频率</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">jieba</span>

<span class="n">nation_df</span><span class="p">[</span><span class="s1">&#39;word_num&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">nation_df</span><span class="p">[</span><span class="s1">&#39;doc&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">text</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">jieba</span><span class="o">.</span><span class="n">lcut</span><span class="p">(</span><span class="n">text</span><span class="p">)))</span>
<span class="n">nation_df</span><span class="p">[</span><span class="s1">&#39;env_num&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">nation_df</span><span class="p">[</span><span class="s1">&#39;doc&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="s1">&#39;环保|环境|污染|青山|绿水&#39;</span><span class="p">)</span>
<span class="n">nation_df</span><span class="p">[</span><span class="s1">&#39;env_ratio&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">nation_df</span><span class="p">[</span><span class="s1">&#39;env_num&#39;</span><span class="p">]</span><span class="o">/</span><span class="n">nation_df</span><span class="p">[</span><span class="s1">&#39;word_num&#39;</span><span class="p">]</span>
<span class="n">nation_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/06-df.png" alt=""  />
</p>
<br>
<h3 id="42-可视化">4.2 可视化</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">matplotlib</span>
<span class="kn">import</span> <span class="nn">matplotlib_inline</span>
<span class="n">matplotlib_inline</span><span class="o">.</span><span class="n">backend_inline</span><span class="o">.</span><span class="n">set_matplotlib_formats</span><span class="p">(</span><span class="s1">&#39;png&#39;</span><span class="p">,</span> <span class="s1">&#39;svg&#39;</span><span class="p">)</span>
<span class="kn">import</span> <span class="nn">scienceplots</span>
<span class="kn">import</span> <span class="nn">platform</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">jieba</span>

<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">([</span><span class="s1">&#39;science&#39;</span><span class="p">,</span> <span class="s1">&#39;no-latex&#39;</span><span class="p">,</span> <span class="s1">&#39;cjk-sc-font&#39;</span><span class="p">])</span>
<span class="n">system</span> <span class="o">=</span> <span class="n">platform</span><span class="o">.</span><span class="n">system</span><span class="p">()</span>  <span class="c1"># 获取操作系统类型</span>

<span class="k">if</span> <span class="n">system</span> <span class="o">==</span> <span class="s1">&#39;Windows&#39;</span><span class="p">:</span>
    <span class="n">font</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;family&#39;</span><span class="p">:</span> <span class="s1">&#39;SimHei&#39;</span><span class="p">}</span>
<span class="k">elif</span> <span class="n">system</span> <span class="o">==</span> <span class="s1">&#39;Darwin&#39;</span><span class="p">:</span>
    <span class="n">font</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;family&#39;</span><span class="p">:</span> <span class="s1">&#39;Arial Unicode MS&#39;</span><span class="p">}</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">font</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;family&#39;</span><span class="p">:</span> <span class="s1">&#39;sans-serif&#39;</span><span class="p">}</span>
<span class="n">matplotlib</span><span class="o">.</span><span class="n">rc</span><span class="p">(</span><span class="s1">&#39;font&#39;</span><span class="p">,</span> <span class="o">**</span><span class="n">font</span><span class="p">)</span>  <span class="c1"># 设置全局字体</span>



<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">nation_df</span><span class="p">[</span><span class="s1">&#39;year&#39;</span><span class="p">],</span> <span class="n">nation_df</span><span class="p">[</span><span class="s1">&#39;env_ratio&#39;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;国级报告中「环保概念词」提及频率折线图(1954-2023)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/gov-plot.png" alt=""  />
</p>
<br>
<p>大家应该都学过正泰分布中， 数据中大多数的记录会落在 均值+-标准差 范围内，</p>
<p><img loading="lazy" src="img/mean&#43;std.png" alt=""  />
</p>
<p>这里设置 <strong>top_nation_mask</strong>、<strong>bottom_nation_mask</strong> ，分别识别到最重视环保的年份、最不重视环保的年份</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">top_nation_mask</span> <span class="o">=</span> <span class="n">nation_df</span><span class="p">[</span><span class="s1">&#39;env_ratio&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="o">+</span> <span class="n">nation_df</span><span class="p">[</span><span class="s1">&#39;env_ratio&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">std</span><span class="p">()</span>
<span class="n">bottom_nation_mask</span> <span class="o">=</span> <span class="n">nation_df</span><span class="p">[</span><span class="s1">&#39;env_ratio&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="o">-</span> <span class="n">nation_df</span><span class="p">[</span><span class="s1">&#39;env_ratio&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">std</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;最重视环保的年份&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">nation_df</span><span class="p">[</span><span class="n">nation_df</span><span class="p">[</span><span class="s1">&#39;env_ratio&#39;</span><span class="p">]</span><span class="o">&gt;</span><span class="n">top_nation_mask</span><span class="p">]</span><span class="o">.</span><span class="n">year</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>

<span class="nb">print</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;最忽视环保的年份&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">nation_df</span><span class="p">[</span><span class="n">nation_df</span><span class="p">[</span><span class="s1">&#39;env_ratio&#39;</span><span class="p">]</span><span class="o">&lt;</span><span class="n">bottom_nation_mask</span><span class="p">][</span><span class="s1">&#39;year&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">最重视环保的年份
[&#39;2016&#39; &#39;2017&#39; &#39;2003&#39; &#39;2015&#39; &#39;2001&#39; &#39;2005&#39; &#39;2007&#39; &#39;2006&#39; &#39;2023&#39; &#39;2021&#39;
 &#39;2019&#39;]

最忽视环保的年份
[&#39;1959&#39; &#39;1964&#39; &#39;1958&#39; &#39;1960&#39; &#39;1975&#39; &#39;1978&#39; &#39;1979&#39; &#39;1985&#39; &#39;1981&#39; &#39;1956&#39;
 &#39;1957&#39; &#39;1980&#39; &#39;1955&#39; &#39;1954&#39; &#39;1983&#39;]
</code></pre></div><br>
<p>可以看到进入21世纪，国家对环保重视从报告中就能看出。而在前期，因为生存是首要解决的，对环境保护的认识事不足的。</p>
<br>
<h3 id="42-省-词频">4.2 省-词频</h3>
<p>计算总词语数、某类词出现的次数，计算各省提及【环保】的频率。因为省份的记录有770条，现在咱们把条件变严格，</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"> top = mean+3*std, 
 bottom = mean-2std
</code></pre></div><p>大家可以自己设置条件的严格程度</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">prov_df</span><span class="p">[</span><span class="s1">&#39;word_num&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">prov_df</span><span class="p">[</span><span class="s1">&#39;doc&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">text</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">jieba</span><span class="o">.</span><span class="n">lcut</span><span class="p">(</span><span class="n">text</span><span class="p">)))</span>
<span class="n">prov_df</span><span class="p">[</span><span class="s1">&#39;env_num&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">prov_df</span><span class="p">[</span><span class="s1">&#39;doc&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="s1">&#39;环保|环境|污染|青山|绿水&#39;</span><span class="p">)</span>
<span class="n">prov_df</span><span class="p">[</span><span class="s1">&#39;env_ratio&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">prov_df</span><span class="p">[</span><span class="s1">&#39;env_num&#39;</span><span class="p">]</span><span class="o">/</span><span class="n">prov_df</span><span class="p">[</span><span class="s1">&#39;word_num&#39;</span><span class="p">]</span>

<span class="n">top_prov_mask</span> <span class="o">=</span> <span class="n">prov_df</span><span class="p">[</span><span class="s1">&#39;env_ratio&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="o">+</span> <span class="mi">3</span><span class="o">*</span><span class="n">prov_df</span><span class="p">[</span><span class="s1">&#39;env_ratio&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">std</span><span class="p">()</span>
<span class="n">bottom_prov_mask</span> <span class="o">=</span> <span class="n">prov_df</span><span class="p">[</span><span class="s1">&#39;env_ratio&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="o">-</span> <span class="mi">2</span><span class="o">*</span><span class="n">prov_df</span><span class="p">[</span><span class="s1">&#39;env_ratio&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">std</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;最重视环保的省(年份)&#39;</span><span class="p">)</span>
<span class="n">prov_df</span><span class="p">[</span><span class="n">prov_df</span><span class="p">[</span><span class="s1">&#39;env_ratio&#39;</span><span class="p">]</span><span class="o">&gt;</span><span class="n">top_prov_mask</span><span class="p">][[</span><span class="s1">&#39;prov&#39;</span><span class="p">,</span> <span class="s1">&#39;year&#39;</span><span class="p">]]</span>
</code></pre></div><p><img loading="lazy" src="img/07-df.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">prov_df</span><span class="p">[</span><span class="n">prov_df</span><span class="p">[</span><span class="s1">&#39;env_ratio&#39;</span><span class="p">]</span><span class="o">&lt;</span><span class="n">bottom_prov_mask</span><span class="p">][[</span><span class="s1">&#39;prov&#39;</span><span class="p">,</span> <span class="s1">&#39;year&#39;</span><span class="p">]]</span>
</code></pre></div><p><img loading="lazy" src="img/08-df.png" alt=""  />
</p>
<p>重视环保结果挺合理的， 某人曾在浙江任职过，对环保比较重视，近年来浙江也比较重视环保，是真的很早就执行，环保搞得很好。而河北，笔者家乡，主要是跟钢铁产业关停并转，守卫di都蓝天有很大关系。</p>
<p>比较忽视环保， 或者不怎么提及环保概念的省份， 也跟经济发展水平有一定关系，主要是重工业不发达， 自身自然的环境条件较好。</p>
<br>
<h3 id="45--保存结果">4.5  保存结果</h3>
<p>将初步整理的结果保存到csv中，</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">nation_df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;nation_report1954-2023.csv&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">prov_df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;prov_report2002-2023.csv&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">city_df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;city_report2003-2023.csv&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</code></pre></div><br>
<p>更多内容可在大邓博客 textdata.cn 中寻找相关代码。</p>
<p><br><br></p>
<h2 id="五获取数据">五、获取数据</h2>
<p>数据集100元，  <strong>加微信 372335839， 备注「姓名-学校-专业」</strong>。</p>
<p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>付费数据(付费) | 使用cctv新闻联播文稿构造面板数据</title>
      <link>https://textdata.cn/blog/2023-02-26-cctv1-xwlb-news-text-dataset/</link>
      <pubDate>Sat, 16 Dec 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-02-26-cctv1-xwlb-news-text-dataset/</guid>
      <description>cctv新闻联播文稿数据集，可使用Python对其进行挖掘，借助文本挖掘技术研究鸿观经济政策、社会学、传播学等领域。</description>
      <content:encoded><![CDATA[<h2 id="一新闻联播">一、新闻联播</h2>
<h3 id="11-数据集概况">1.1 数据集概况</h3>
<p>全网最全的数据集， 记录缺失率最低的<strong>xwlb数据集</strong>，  <strong>新</strong>(fan)<strong>闻</strong>(rong)<strong>联</strong>(chang)<strong>播</strong>(sheng) 。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">数据来源: 央视网https://tv.cctv.com/lm/xwlb/ 
覆盖日期: 2006-09-01 ~ 2023-12-15
日记录数: 6315天
字段: date、 text
</code></pre></div><br>
<h3 id="12-研究用途">1.2 研究用途</h3>
<p>可从中提取丰富的指标，包括但不限于经济政策不确定性指数EPU 、 媒体关注度、媒体情绪、文本相似度。此外， 可训练词向量，开发新的概念词典，构建新的指标指数。数据带时间， 参照前面指标， 依主体、日期、指标进行计算， 可构造面板数据，因此在经济学、管理学、新闻传播学、公共管理等领域均有较高的研究价值。</p>
<p>相关参考文献</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">[1]洪永淼,刘俸奇,薛涧坡.政府与市场心理因素的经济影响及其测度[J].管理世界,2023,39(03):30-51.
[2]刘景江,郑畅然,洪永淼.机器学习如何赋能管理学研究？——国内外前沿综述和未来展望[J].管理世界,2023,39(09):191-216.
[3]张一帆,林建浩,樊嘉诚.新闻文本大数据与消费增速实时预测——基于叙事经济学的视角[J].金融研究,2023,(05):152-169.
[4]Huang, Yun, and Paul Luk. &#34;Measuring economic policy uncertainty in China.&#34; China Economic Review 59 (2020): 101367
[5]欧阳资生,陈世丽,杨希特,刘凤根,周学伟.经济政策不确定性、网络舆情与金融机构系统性风险[J].管理科学学报,2023,26(04):62-86.
[6]逯东,宋昕倍.媒体报道、上市公司年报可读性与融资约束[J].管理科学学报,2021,24(12):45-61.
[7]彭涛,黄福广,孙凌霞.经济政策不确定性与风险承担:基于风险投资的证据[J].管理科学学报,2021,24(03):98-114.
[8]庞锐.采纳与内化：多重制度压力如何影响河长制创新扩散——基于省级政府的定向配对事件史分析[J].公共管理学报,2023,20(02):25-37+165-166.
</code></pre></div><br>
<h3 id="13-获取数据">1.3 获取数据</h3>
<p>【新闻联播xwlb】按年度，每年50元。 全量购买200元。</p>
<p><strong>加微信 372335839， 备注「姓名-学校-专业」</strong>。</p>
<p>更多新闻类数据  <a href="https://textdata.cn/blog/2023-12-14-daily-news-dataset">数据集 | 人民日报/经济日报/光明日报 等 7 家新闻类文本数据集</a></p>
<p><br><br></p>
<h2 id="二数据检查">二、数据检查</h2>
<h3 id="21-读取数据">2.1 读取数据</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="c1">#6315天</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;cctv_xwlb.csv&#39;</span><span class="p">)</span>

<span class="c1">#变更日期格式，可进行日期计算</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">))</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">6315
</code></pre></div><p><img loading="lazy" src="img/df.png" alt=""  />
</p>
<br>
<h3 id="22-日期涵盖">2.2 日期涵盖</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">#执行过 df[&#39;date&#39;] = pd.to_datetime(df[&#39;date&#39;])
#才能进行日期计算

print(df[&#39;date&#39;].min().date())
print(df[&#39;date&#39;].max().date())
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">2006-09-01
2023-12-15
</code></pre></div><br>
<h3 id="33-缺失率">3.3 缺失率</h3>
<p>查看是否存在某些日期对应的文本是空</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">isna</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">0
</code></pre></div><br>
<p>生成2006-09-01-2023-12-15之间所有的日期datelist， 查看datelist哪些日期不在数据集中，以判断是否遗漏某些日期。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">datetime</span> <span class="k">as</span> <span class="nn">dt</span>  <span class="c1">#import datetime, timedelta  </span>
  
<span class="n">start_date</span> <span class="o">=</span> <span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="p">(</span><span class="mi">2006</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>  
<span class="n">end_date</span> <span class="o">=</span> <span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="p">(</span><span class="mi">2023</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">15</span><span class="p">)</span>  
<span class="n">delta</span> <span class="o">=</span> <span class="n">dt</span><span class="o">.</span><span class="n">timedelta</span><span class="p">(</span><span class="n">days</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  
  
<span class="n">date_list</span> <span class="o">=</span> <span class="p">[]</span>  
<span class="n">current_date</span> <span class="o">=</span> <span class="n">start_date</span>  
<span class="k">while</span> <span class="n">current_date</span> <span class="o">&lt;=</span> <span class="n">end_date</span><span class="p">:</span>  
    <span class="n">date_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">current_date</span><span class="p">)</span>  
    <span class="n">current_date</span> <span class="o">+=</span> <span class="n">delta</span>  
  
<span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">date_list</span><span class="p">)</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">date_list</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">1.0
</code></pre></div><p>2006-09-01~2023-12-15之间所有的日期， 均存在于新闻数据集中，也就是说数据集没有遗漏这期间任何一天的新闻。</p>
<p><br><br></p>
<h2 id="三实验">三、实验</h2>
<p>按月份(也可调整为周、年)计算一下正负面情绪词在新闻中出现次数， 然后转化为情感分值， 绘制成折线图。</p>
<ol>
<li>导入词典</li>
<li>设计算法, 如统计新闻总词数、正面词数、负面词数。</li>
<li>转化为情感分值</li>
<li>按月份汇总</li>
<li>绘制折线图</li>
</ol>
<h3 id="31-导入词典">3.1 导入词典</h3>
<p>使用cntext2.0.0内置的中文经济金融场景的情感词典，该词典比较适合xwlb这种题材，我们查看一下</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>
<span class="c1">#未开源cntext2.0.0</span>

<span class="n">diction</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">read_yaml_dict</span><span class="p">(</span><span class="s1">&#39;zh_common_FinanceSenti.yaml&#39;</span><span class="p">)[</span><span class="s1">&#39;Dictionary&#39;</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;pos词数&#39;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">diction</span><span class="p">[</span><span class="s1">&#39;pos&#39;</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;neg词数&#39;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">diction</span><span class="p">[</span><span class="s1">&#39;neg&#39;</span><span class="p">]))</span>


<span class="c1">#词典整理自论文， 大家也可自行整理</span>
<span class="nb">print</span><span class="p">(</span><span class="n">ct</span><span class="o">.</span><span class="n">read_yaml_dict</span><span class="p">(</span><span class="s1">&#39;zh_common_FinanceSenti.yaml&#39;</span><span class="p">))</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">pos词数 3338
neg词数 5890


{&#39;Refer&#39;: &#39;Fuwei Jiang, Joshua Lee, Xiumin Martin, and Guofu Zhou.“Manager Sentiment and Stock Returns” Journal of Financial Economics 132(1), 2019,126-149&#39;,
 
 &#39;Desc&#39;: &#39;Chinese Financial Sentiment Dictionary&#39;,
 &#39;Category&#39;: [&#39;pos&#39;, &#39;neg&#39;],
 
 &#39;Name&#39;: &#39;Chinese Financial Sentiment Dictionary&#39;,
 
 &#39;Dictionary&#39;: {&#39;pos&#39;: [&#39;安定&#39;, &#39;安康&#39;, &#39;帮助&#39;, &#39;榜样&#39;, &#39;饱满&#39;, ...  &#39;最合适&#39;, &#39;最小&#39;, &#39;最新进展&#39;, &#39;最早&#39;, &#39;遵法&#39;],
  
                &#39;neg&#39;: [&#39;败坏名声&#39;, &#39;被没收的&#39;, &#39;变节&#39;, &#39;不便&#39;, &#39;不适当&#39;, &#39;妨碍&#39;,  &#39;腐败&#39;,...&#39;唉声叹气&#39;, &#39;哀怨&#39;, &#39;哀叹&#39;, &#39;哀伤&#39;, &#39;哀悼&#39;]
}
</code></pre></div><br>
<p><strong>配置cntext-2.0.0-py3-none-any.whl的方法</strong></p>
<ol>
<li>
<p>将whl文件放置于电脑桌面。</p>
</li>
<li>
<p>打开cmd(mac打开terminal)， 输入 <code>cd desktop</code>,  按Enter回车键</p>
</li>
<li>
<p>继续在cmd(mac打开terminal)中，输入 <code>pip3 install cntext-2.0.0-py3-none-any.whl</code>,  按Enter回车键</p>
</li>
</ol>
<br>
<h3 id="32-统计词频">3.2 统计词频</h3>
<p>这里</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="o">%%</span><span class="n">time</span>  
<span class="kn">import</span> <span class="nn">jieba</span>
<span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>

<span class="n">diction</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">read_yaml_dict</span><span class="p">(</span><span class="s1">&#39;zh_common_FinanceSenti.yaml&#39;</span><span class="p">)[</span><span class="s1">&#39;Dictionary&#39;</span><span class="p">]</span>
<span class="n">pos_patern</span> <span class="o">=</span> <span class="s1">&#39;|&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">diction</span><span class="p">[</span><span class="s1">&#39;pos&#39;</span><span class="p">])</span>
<span class="n">neg_patern</span> <span class="o">=</span> <span class="s1">&#39;|&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">diction</span><span class="p">[</span><span class="s1">&#39;neg&#39;</span><span class="p">])</span>

<span class="n">df</span><span class="p">[</span><span class="s1">&#39;word_num&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">text</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">jieba</span><span class="o">.</span><span class="n">lcut</span><span class="p">(</span><span class="n">text</span><span class="p">)))</span>

<span class="c1">#正面词数</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;pos_num&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="n">pos_patern</span><span class="p">)</span>

<span class="c1">#负面词数</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;neg_num&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="n">neg_patern</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/df2.png" alt=""  />
</p>
<br>
<h3 id="33-计算情感值">3.3 计算情感值</h3>
<p>使用 <code>score = pos-neg/(pos+neg)</code>， 可以将数值范围调整到 <code>-1 ~ 1</code>之间。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df</span><span class="p">[</span><span class="s1">&#39;senti_score&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;pos_num&#39;</span><span class="p">]</span> <span class="o">-</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;neg_num&#39;</span><span class="p">])</span><span class="o">/</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;pos_num&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;neg_num&#39;</span><span class="p">])</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/df3.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;最小值&#39;</span><span class="p">,</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;senti_score&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;均值&#39;</span><span class="p">,</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;senti_score&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;中位数&#39;</span><span class="p">,</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;senti_score&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">median</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;最大&#39;</span><span class="p">,</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;senti_score&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">最小值 -0.36633663366336633
均值 0.5448464974146746
中位数 0.5657256687535572
最大 1.0
</code></pre></div><br>
<h3 id="34-按月份">3.4 按月份</h3>
<p>这里用到df.groupby方法， 可以按某种分组方法，得到不同组的dataframe集合。</p>
<p>dataframe集合可以通过for循环逐个迭代，分别计算对应年度的信息。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">month_datas</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">date</span><span class="p">,</span> <span class="n">year_df</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">Grouper</span><span class="p">(</span><span class="n">key</span><span class="o">=</span><span class="s1">&#39;date&#39;</span><span class="p">,</span> <span class="n">freq</span><span class="o">=</span><span class="s1">&#39;M&#39;</span><span class="p">)):</span>
    <span class="n">data</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
    
    <span class="n">data</span><span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">date</span>
    
    <span class="n">data</span><span class="p">[</span><span class="s1">&#39;senti_score&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">year_df</span><span class="p">[</span><span class="s1">&#39;senti_score&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="n">month_datas</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    
<span class="n">month_info_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">month_datas</span><span class="p">)</span>
<span class="n">month_info_df</span>
</code></pre></div><p><img loading="lazy" src="img/df4.png" alt=""  />
</p>
<br>
<h3 id="35-绘制月情感折线图">3.5 绘制月情感折线图</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">import matplotlib.pyplot as plt
import matplotlib
import matplotlib_inline
matplotlib_inline.backend_inline.set_matplotlib_formats(&#39;png&#39;, &#39;svg&#39;)
import scienceplots
import platform
import pandas as pd
import numpy as np


plt.style.use([&#39;science&#39;, &#39;no-latex&#39;, &#39;cjk-sc-font&#39;])
system = platform.system()  # 获取操作系统类型

if system == &#39;Windows&#39;:
    font = {&#39;family&#39;: &#39;SimHei&#39;}
elif system == &#39;Darwin&#39;:
    font = {&#39;family&#39;: &#39;Arial Unicode MS&#39;}
else:
    font = {&#39;family&#39;: &#39;sans-serif&#39;}
matplotlib.rc(&#39;font&#39;, **font)  # 设置全局字体


plt.figure(figsize=(12, 5))
plt.plot(month_info_df[&#39;date&#39;], month_info_df[&#39;senti_score&#39;])
plt.title(&#39;XWLB月度情感值折线图(2006-2023)&#39;)
plt.show()
</code></pre></div><p><img loading="lazy" src="img/plot.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="四获取数据">四、获取数据</h2>
<p>【新闻联播xwlb】按年度，每年50元。 全量购买100元。</p>
<p><strong>加微信 372335839， 备注「姓名-学校-专业」</strong>。</p>
<p>更多新闻类数据  <a href="https://textdata.cn/blog/2023-12-14-daily-news-dataset">数据集 | 人民日报/经济日报/光明日报 等 7 家新闻类文本数据集</a></p>
<p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">支持开票 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>新闻数据集 | 含 人民日报/经济日报/光明日报 等 7 家媒体(2023.12.18)</title>
      <link>https://textdata.cn/blog/2023-12-14-daily-news-dataset/</link>
      <pubDate>Thu, 14 Dec 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-12-14-daily-news-dataset/</guid>
      <description>日报数据集研究价值大， 您可从中提取丰富的指标，包括但不限于经济政策不确定性指数EPU 、 媒体关注度指数、文本相似度、情感分析。而且可训练词向量，构建新的词典，开发新的指标指数。计算机自然语言处理、经济学、管理学、新闻传播学、公共管理等领域均可使用。</description>
      <content:encoded><![CDATA[<p>新闻日报类数据集，含 <em><strong>人民日报</strong></em>、 <em><strong>光明日报</strong></em>、<em><strong>人民政协报</strong></em>、<em><strong>经济日报</strong></em>、<em><strong>中国青年报</strong></em>、  <em><strong>南方周末</strong></em>、<em><strong>新闻联播</strong></em> 等。</p>
<br>
<h2 id="一--研究用途">一、  研究用途</h2>
<p>新闻日报类数据 可提取丰富的指标，包括但不限于 **经济政策不确定性指数 **、 <strong>媒体关注度指数</strong>、<strong>文本相似度</strong>、<strong>情感分析</strong>。此外， 可训练词向量，开发新的概念词典。数据带时间， 参照前面指标， 依主体、日期、指标进行计算， 可构造面板数据，构建新的指标指数。因此在经济学、管理学、新闻传播学、公共管理等领域均有较高的研究价值。</p>
<p>相关参考文献</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">[1]洪永淼,刘俸奇,薛涧坡.政府与市场心理因素的经济影响及其测度[J].管理世界,2023,39(03):30-51.
[2]刘景江,郑畅然,洪永淼.机器学习如何赋能管理学研究？——国内外前沿综述和未来展望[J].管理世界,2023,39(09):191-216.
[3]张一帆,林建浩,樊嘉诚.新闻文本大数据与消费增速实时预测——基于叙事经济学的视角[J].金融研究,2023,(05):152-169.
[4]Huang, Yun, and Paul Luk. &#34;Measuring economic policy uncertainty in China.&#34; China Economic Review 59 (2020): 101367
[5]欧阳资生,陈世丽,杨希特,刘凤根,周学伟.经济政策不确定性、网络舆情与金融机构系统性风险[J].管理科学学报,2023,26(04):62-86.
[6]逯东,宋昕倍.媒体报道、上市公司年报可读性与融资约束[J].管理科学学报,2021,24(12):45-61.
[7]彭涛,黄福广,孙凌霞.经济政策不确定性与风险承担:基于风险投资的证据[J].管理科学学报,2021,24(03):98-114.
[8]庞锐.采纳与内化：多重制度压力如何影响河长制创新扩散——基于省级政府的定向配对事件史分析[J].公共管理学报,2023,20(02):25-37+165-166.
</code></pre></div><p><br><br></p>
<h2 id="二-数据集">二、 数据集</h2>
<h3 id="21-数据集概况">2.1 数据集概况</h3>
<p>除 <em><strong>新闻联播</strong></em> ，每天全部新闻存储到一个 TXT； 其余媒体， 每条新闻存储到一个 TXT。</p>
<p>数据集是通过 PYTHON 网络采集、数据清洗， 方便各位基于 <strong>公众号(博客)： 大邓和他的PYTHON</strong> 内的代码，构造概念词典面板数据</p>
<h4 id="211-人民日报">2.1.1 人民日报</h4>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">数据来源:    人民日报
覆盖日期:    1946-05-15 ~ 2023-12-18
新闻条数:    2014661
文件体积:    2.98G
购买价格:    40 元/年, TXT格式; 整卖 1000 元(TXT、CSV)
</code></pre></div><h4 id="212-光明日报">2.1.2 光明日报</h4>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">数据来源:    光明日报
覆盖日期:    1985-01-01 ~ 2023-12-18
新闻条数:    853348
文件体积:    1.47G
购买价格:    20 元/年, TXT格式; 整卖 500 元(TXT、CSV)
</code></pre></div><h4 id="213-人民政协报">2.1.3 人民政协报</h4>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">数据来源:    人民政协报
覆盖日期:    2008-01-02 ~ 2023-12-18
新闻条数:    339047
文件体积:    616M
购买价格:    20 元/年, TXT格式; 整卖 200 元(TXT、CSV)
</code></pre></div><h4 id="214-经济日报">2.1.4 经济日报</h4>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">数据来源:    经济日报
覆盖日期:    2008-01-27 ~ 2023-12-18
新闻条数:    373862
文件体积:    729M
购买价格:    20 元/年, TXT格式; 整卖 200 元(TXT、CSV)
</code></pre></div><h4 id="215-中国青年报">2.1.5 中国青年报</h4>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">数据来源:    中国青年报
覆盖日期:    2005-01-01 ~ 2023-12-18
新闻条数:    322735
文件体积:    760M
购买价格:    20 元/年, TXT格式; 整卖 200 元(TXT、CSV)
</code></pre></div><h4 id="216-南方周末">2.1.6 南方周末</h4>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">数据来源:    南方周末
覆盖日期:    2008-01-02 ~ 2023-05-31
新闻条数:    75788
文件体积:    284M
购买价格:    20 元/年, TXT格式;  整卖 200 元(TXT、CSV)
</code></pre></div><h4 id="218-新闻联播">2.1.8 新闻联播</h4>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">数据来源:    新闻联播
覆盖日期:    2006-09-01 ~ 2023-12-18
记录数量:    6318(每天一个txt)
文件体积:    136M
购买价格:    20 元/年, TXT格式; 整卖 100 元(TXT、CSV)
</code></pre></div><br>
<h3 id="22-购买数据">2.2 购买数据</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">人民日报:     40 元/年, TXT格式;  整卖 1000 元(TXT、CSV)
光明日报:     20 元/年, TXT格式;  整卖 500 元(TXT、CSV)
人民政协报:   20 元/年, TXT格式;  整卖 200 元(TXT、CSV)
经济日报:     20 元/年, TXT格式;  整卖 200 元(TXT、CSV)
中国青年:     20 元/年, TXT格式;  整卖 200 元(TXT、CSV)
南方周末:     20 元/年, TXT格式;  整卖 200 元(TXT、CSV)
新闻联播:     10 元/年, TXT格式;  整卖 100 元(TXT、CSV)
</code></pre></div><p>所有数据集打包优惠价 1688 元， 支持开票。</p>
<p>需要的请加微信372335839，备注【姓名-学校-专业-news】</p>
<br>
<p>更多数据集，请查看 <a href="https://textdata.cn/blog/datasets_available_for_management_science/"><strong>LIST | 可供社科(经管)领域使用的数据集汇总</strong></a></p>
<p><br><br></p>
<h2 id="三实验代码">三、实验代码</h2>
<p>新闻类数据集内有 txt 和 csv两种格式， 推荐使用 csv 进行数据分析。 后续我们也会持续围绕着新闻类数据集 (CSV格式) 进行持续的内容更新。</p>
<h3 id="31-读取csv">3.1 读取csv</h3>
<p>以 <em><strong>经济日报/ jjrb.csv.gzip</strong></em> 为例</p>
<p>压缩文件 <code>jjrb/csvs/2022.csv.gzip</code> 可直接读取</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="c1"># 当前代码所在的ipynb文件 与 「jjrb文件夹」是兄弟辈关系，同处于一个文件夹内</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;经济日报/jjrb.csv.gzip&#39;</span><span class="p">,</span> <span class="n">compression</span><span class="o">=</span><span class="s1">&#39;gzip&#39;</span><span class="p">)</span>

<span class="c1">#也可解压后再读取csv， 两者功效等同，但前者读取更快。</span>
<span class="c1">#df = pd.read_csv(&#39;经济日报/jjrb.csv&#39;)</span>


<span class="n">df</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">17394
</code></pre></div><p><img loading="lazy" src="img/01-df.png" alt=""  />
</p>
<br>
<h3 id="32-日期操作">3.2 日期操作</h3>
<h4 id="321-更改日期类型">3.2.1 更改日期类型</h4>
<p>首先要更改日期类型为datetime型， 这样方便后续日期的筛选和计算</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">df[&#39;date&#39;] = pd.to_datetime(df[&#39;date&#39;])
</code></pre></div><br>
<h4 id="322-日期的最大小值">3.2.2 日期的最大(小)值</h4>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">())</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">2023-12-18 00:00:00
2008-01-27 00:00:00
</code></pre></div><h4 id="323-筛选指定日期记录">3.2.3 筛选指定日期记录</h4>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">date_mask1</span> <span class="o">=</span> <span class="s1">&#39;2009-10-25&#39;</span>
<span class="c1">#date_mask2 = &#39;2009-10&#39;</span>
<span class="c1">#date_mask3 = &#39;2009&#39;</span>

<span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">]</span><span class="o">==</span><span class="n">date_mask1</span><span class="p">]</span>
</code></pre></div><p><img loading="lazy" src="img/02-df.png" alt=""  />
</p>
<br>
<h4 id="324-dt">3.2.4 .dt</h4>
<p>.dt可以查看 年year、月month、 日day， 查看年份</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">df[&#39;date&#39;].dt.year
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">0         2013
1         2013
2         2013
3         2013
4         2013
          ... 
373857    2023
373858    2023
373859    2023
373860    2023
373861    2023
Name: date, Length: 373862, dtype: int32

</code></pre></div><br>
<h3 id="33-文本操作">3.3 文本操作</h3>
<h3 id="331-是否含某类词">3.3.1 是否含某(类)词</h3>
<p>如检索 jjrb 中text字段中是否提到了「<em><strong>华为</strong></em>」这个词，至少出现一次，标记为True</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="s1">&#39;华为&#39;</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">0         False
1         False
2         False
3         False
4         False
          ...  
373857    False
373858    False
373859    False
373860    False
373861    False
Name: text, Length: 373862, dtype: object
</code></pre></div><br>
<p>text字段中提及「<em><strong>IT</strong></em>」相关词，如<code>电脑、手机、互联网、app</code>等，至少出现一次，标记为True</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="s1">&#39;电脑|手机|互联网|app&#39;</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">0         False
1         False
2         False
3         False
4         False
          ...  
373857     True
373858    False
373859    False
373860    False
373861     True
Name: text, Length: 373862, dtype: object
</code></pre></div><br>
<h4 id="332-含某类词记录数">3.3.2 含某(类)词记录数</h4>
<p>统计 <em><strong>经济日报</strong></em> 中出现 <em><strong>华为</strong></em> 、<em><strong>华为相关词</strong></em> 的新闻数量</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">huawei_record_num = df[&#39;text&#39;].str.contains(&#39;华为&#39;).sum()
IT_record_num = df[&#39;text&#39;].str.contains(&#39;电脑|手机|互联网|app&#39;).sum()

print(huawei_record_num)
print(IT_record_num)
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">2994
40674
</code></pre></div><br>
<h4 id="333-含某类词个数">3.3.3 含某类词个数</h4>
<p>每条新闻中含某(类)词的个数</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">df[&#39;huawei_word_num&#39;] = df[&#39;text&#39;].str.count(&#39;华为&#39;)
df[&#39;IT_word_num&#39;] = df[&#39;text&#39;].str.count(&#39;电脑|手机|互联网|app&#39;)

df[df[&#39;huawei_word_num&#39;]&gt;0]
</code></pre></div><p><img loading="lazy" src="img/03-df.png" alt=""  />
</p>
<br>
<p>IT_word_num的最大值、中位数、均值、最小值</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;IT max:&#39;</span><span class="p">,</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;IT_word_num&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;IT median:&#39;</span><span class="p">,</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;IT_word_num&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">median</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;IT mean:&#39;</span><span class="p">,</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;IT_word_num&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;IT min:&#39;</span><span class="p">,</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;IT_word_num&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">())</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">IT</span> <span class="nb">max</span><span class="p">:</span> <span class="mf">283.0</span>
<span class="n">IT</span> <span class="n">median</span><span class="p">:</span> <span class="mf">0.0</span>
<span class="n">IT</span> <span class="n">mean</span><span class="p">:</span> <span class="mf">0.3806961871084083</span>
<span class="n">IT</span> <span class="nb">min</span><span class="p">:</span> <span class="mf">0.0</span>
</code></pre></div><br>
<h3 id="34-按条件筛选">3.4 按条件筛选</h3>
<p>按照字段 IT_word_num，筛选出值大于10的记录。即新闻中至少出现10次IT词的记录</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;IT_word_num&#39;</span><span class="p">]</span><span class="o">&gt;</span><span class="mi">10</span><span class="p">]</span>
</code></pre></div><p><img loading="lazy" src="img/04-df-filter.png" alt=""  />
</p>
<br>
<p>多条件筛选, 结合且或非</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">#筛选出IT_word_num大于15， 且小于20
df[(df[&#39;IT_word_num&#39;]&gt;15) &amp; (df[&#39;IT_word_num&#39;]&lt;20)]
</code></pre></div><p><img loading="lazy" src="img/05-and.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#筛选出IT_word_num大于10， 或 huawei_word_num大于10</span>
<span class="n">df</span><span class="p">[(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;IT_word_num&#39;</span><span class="p">]</span><span class="o">&gt;</span><span class="mi">10</span><span class="p">)</span> <span class="o">|</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;huawei_word_num&#39;</span><span class="p">]</span><span class="o">&gt;</span><span class="mi">10</span><span class="p">)]</span>
</code></pre></div><p><img loading="lazy" src="img/06-or.png" alt=""  />
</p>
<br>
<h3 id="35-apply">3.5 .apply</h3>
<p>选择某字段，对该字段批量计算. 这里以统计某类概念词个数为例。是df[&lsquo;text&rsquo;].str.count的另类实现方法</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#df[&#39;IT_word_num&#39;] = df[&#39;text&#39;].str.count(&#39;电脑|手机|互联网|app&#39;)</span>

<span class="k">def</span> <span class="nf">count_IT</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">keywords</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;电脑&#39;</span><span class="p">,</span> <span class="s1">&#39;手机&#39;</span><span class="p">,</span> <span class="s1">&#39;互联网&#39;</span><span class="p">,</span> <span class="s1">&#39;app&#39;</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">keyword</span> <span class="ow">in</span> <span class="n">keywords</span><span class="p">:</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">result</span> <span class="o">+</span> <span class="n">text</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="n">keyword</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">result</span>
  
<span class="c1">#这两种算法结果是相同的，但是apply遇到nan数据会报错，所以这里都统一对nan替换为&#39;&#39;</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;IT_word_num&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="s1">&#39;电脑|手机|互联网|app&#39;</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;IT_word_num2&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">count_IT</span><span class="p">)</span>
</code></pre></div><br>
<br>
<h3 id="36--groupby分组">3.6  Groupby分组</h3>
<p>按月份逐月保存到csv中，首先要对dataframe进行分组，这里用到pd.Grouper(key,  freq)</p>
<ul>
<li>key 根据某字段进行分组</li>
<li>freq 周期， <code>年Y  月M   日D</code></li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="k">for</span> <span class="n">date</span><span class="p">,</span> <span class="n">year_df</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">Grouper</span><span class="p">(</span><span class="n">key</span><span class="o">=</span><span class="s1">&#39;date&#39;</span><span class="p">,</span> <span class="n">freq</span><span class="o">=</span><span class="s1">&#39;Y&#39;</span><span class="p">)):</span>
    <span class="c1">#这里的date， month_df都是特殊数据类型</span>
    <span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">date</span><span class="p">),</span> <span class="nb">type</span><span class="p">(</span><span class="n">year_df</span><span class="p">))</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt; &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt; &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt; &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt; &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt; &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt; &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt; &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt; &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt; &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt; &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt; &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt; &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt; &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt; &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt; &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt; &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
​
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">for date, month_df in df.groupby(pd.Grouper(key=&#39;date&#39;, freq=&#39;M&#39;)):
    #可以抽取出date中的年月信息
    print(date.year, date.month, type(month_df))
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">2008 1 &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
2008 2 &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
2008 3 &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
2008 4 &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
2008 5 &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
2008 6 &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
2008 7 &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
2008 8 &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
2008 9 &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
......
2023 1 &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
2023 2 &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
2023 3 &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
2023 4 &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
2023 5 &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
2023 6 &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
2023 7 &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
2023 8 &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
2023 9 &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
2023 10 &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
2023 11 &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
2023 12 &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="k">for</span> <span class="n">date</span><span class="p">,</span> <span class="n">month_df</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">Grouper</span><span class="p">(</span><span class="n">key</span><span class="o">=</span><span class="s1">&#39;date&#39;</span><span class="p">,</span> <span class="n">freq</span><span class="o">=</span><span class="s1">&#39;M&#39;</span><span class="p">)</span>
    <span class="c1">#以year-month.csv格式存储数据到csv中</span>
    <span class="n">month_df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">year</span><span class="si">}</span><span class="s1">-</span><span class="si">{</span><span class="n">month</span><span class="si">}</span><span class="s1">.csv&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</code></pre></div><br>
<br>
<h2 id="五购买数据">五、购买数据</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">人民日报:     40 元/年, TXT格式;  整卖 1000 元(TXT、CSV)
光明日报:     20 元/年, TXT格式;  整卖 500 元(TXT、CSV)
人民政协报:   20 元/年, TXT格式;  整卖 200 元(TXT、CSV)
经济日报:     20 元/年, TXT格式;  整卖 200 元(TXT、CSV)
中国青年:     20 元/年, TXT格式;  整卖 200 元(TXT、CSV)
南方周末:     20 元/年, TXT格式;  整卖 200 元(TXT、CSV)
新闻联播:     10 元/年, TXT格式;  整卖 100 元(TXT、CSV)
</code></pre></div><p>所有数据集打包优惠价 1888 元， 支持开票。</p>
<p>需要的请加微信372335839，备注【姓名-学校-专业-news】</p>
<br>
<p>更多数据集，请查看 <a href="https://textdata.cn/blog/datasets_available_for_management_science/"><strong>LIST | 可供社科(经管)领域使用的数据集汇总</strong></a></p>
<p><br><br></p>
<h2 id="六相关内容">六、相关内容</h2>
<p><a href="https://textdata.cn/blog/2023-12-18-how-to-generate-panel-data-from-daily-news-dataset"><strong>代码 | 使用「新闻数据」构造概念词提及量「面板数据」</strong></a></p>
<p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>数据集 | 上市公司 208 万条专利数据集 (1991-2022)</title>
      <link>https://textdata.cn/blog/2023-12-07-patent-application-dataset-of-listed-company-in-china-a-market/</link>
      <pubDate>Thu, 07 Dec 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-12-07-patent-application-dataset-of-listed-company-in-china-a-market/</guid>
      <description>上市公司专利申请数据集</description>
      <content:encoded><![CDATA[<h2 id="一上市公司专利数据集">一、上市公司专利数据集</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">上市公司数: 4393
专利记录数:  2083784
专利申请日:  1991-01-30 ~ 2022-12-31
原始来源:   国家知识产权局
</code></pre></div><p>内容为付费数据集， 50元， 加微信 372335839， 备注「姓名-学校-专业」</p>
<br>
<br>
<h2 id="二数据探索">二、数据探索</h2>
<h3 id="21-读取数据">2.1 读取数据</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="c1">#df = pd.read_csv(&#39;上市公司-专利明细数据1991-2022.csv&#39;)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;上市公司-专利明细数据1991-2022.csv.gzip&#39;</span><span class="p">,</span> <span class="n">compression</span><span class="o">=</span><span class="s1">&#39;gzip&#39;</span><span class="p">)</span>

<span class="c1">#剔除重复的</span>
<span class="n">df</span><span class="o">.</span><span class="n">drop_duplicates</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div><p><img loading="lazy" src="img/df1.png" alt=""  />
</p>
<br>
<h3 id="22-上市公司数--记录数">2.2 上市公司数 &amp; 记录数</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;上市公司数: </span><span class="si">{</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;股票代码&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">nunique</span><span class="p">()</span> <span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;专利申请数: </span><span class="si">{</span> <span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span> <span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">上市公司数: 4393
专利申请数: 2083784
</code></pre></div><br>
<h3 id="23-字段缺失率">2.3 字段缺失率</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;字段缺失率统计&#39;</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\n\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
    <span class="n">ratio</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="mi">100</span> <span class="o">*</span> <span class="n">df</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">isna</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span>
    <span class="c1">#print(f&#34;{col}: {ratio}%&#34;)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;</span><span class="si">{</span><span class="n">col</span><span class="si">:</span><span class="s2">&lt;</span><span class="si">{</span><span class="mi">10</span><span class="si">}}</span><span class="s2">: </span><span class="si">{</span><span class="n">ratio</span><span class="si">}</span><span class="s2">%&#34;</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">字段缺失率统计

股票代码      : 0.0%
原始企业名称    : 0.0%
专利申请主体    : 0.0%
专利名称      : 0.0%
发明人       : 0.0%
地址        : 0.04%
专利类型      : 0.04%
专利申请号     : 0.04%
申请公布号     : 58.61%
授权公布号     : 41.43%
专利申请日     : 0.0%
公开公告日     : 58.61%
授权公告日     : 41.43%
专利申请年份    : 0.0%
原始来源      : 0.0%
统计截至日期    : 0.0%
更新时间      : 0.0%
</code></pre></div><br>
<h3 id="24-记录的日期范围">2.4 记录的日期范围</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df</span><span class="p">[</span><span class="s1">&#39;专利申请日&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;专利申请日&#39;</span><span class="p">],</span> <span class="n">errors</span><span class="o">=</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;公开公告日&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;公开公告日&#39;</span><span class="p">],</span> <span class="n">errors</span><span class="o">=</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;授权公告日&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;授权公告日&#39;</span><span class="p">],</span> <span class="n">errors</span><span class="o">=</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>


<span class="nb">print</span><span class="p">(</span><span class="s2">&#34;专利申请日范围: </span><span class="si">{start}</span><span class="s2"> ~ </span><span class="si">{end}</span><span class="s2">&#34;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">start</span><span class="o">=</span><span class="nb">str</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;专利申请日&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">())[:</span><span class="mi">10</span><span class="p">],</span>
                                           <span class="n">end</span><span class="o">=</span><span class="nb">str</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;专利申请日&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">())[:</span><span class="mi">10</span><span class="p">]))</span>
      
      
<span class="nb">print</span><span class="p">(</span><span class="s2">&#34;公开公告日范围: </span><span class="si">{start}</span><span class="s2"> ~ </span><span class="si">{end}</span><span class="s2">&#34;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">start</span><span class="o">=</span><span class="nb">str</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;公开公告日&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">())[:</span><span class="mi">10</span><span class="p">],</span>
                                            <span class="n">end</span><span class="o">=</span><span class="nb">str</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;公开公告日&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">())[:</span><span class="mi">10</span><span class="p">]))</span>
      
      
<span class="nb">print</span><span class="p">(</span><span class="s2">&#34;授权公布日范围: </span><span class="si">{start}</span><span class="s2"> ~ </span><span class="si">{end}</span><span class="s2">&#34;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">start</span><span class="o">=</span><span class="nb">str</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;授权公告日&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">())[:</span><span class="mi">10</span><span class="p">],</span>
                                            <span class="n">end</span><span class="o">=</span><span class="nb">str</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;授权公告日&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">())[:</span><span class="mi">10</span><span class="p">]))</span>

</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">专利申请日范围: 1991-01-30 ~ 2022-12-31
公开公告日范围: 1994-08-31 ~ 2023-08-25
授权公布日范围: 1993-12-01 ~ 2023-08-25
</code></pre></div><p>日期的三种字段， <em><strong>专利申请日</strong></em> 缺失率为0， 而 <em><strong>公开公告日</strong></em> 、 <em><strong>授权公告日</strong></em> 都分别高达 58.61%、 41.43%。 个人认为数据集涵盖的日期范围，使用<em><strong>专利申请日</strong></em>  更合适一些。</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">matplotlib</span>
<span class="kn">import</span> <span class="nn">matplotlib_inline</span>
<span class="n">matplotlib_inline</span><span class="o">.</span><span class="n">backend_inline</span><span class="o">.</span><span class="n">set_matplotlib_formats</span><span class="p">(</span><span class="s1">&#39;png&#39;</span><span class="p">,</span> <span class="s1">&#39;svg&#39;</span><span class="p">)</span>
<span class="kn">import</span> <span class="nn">scienceplots</span>
<span class="kn">import</span> <span class="nn">platform</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">([</span><span class="s1">&#39;science&#39;</span><span class="p">,</span> <span class="s1">&#39;no-latex&#39;</span><span class="p">,</span> <span class="s1">&#39;cjk-sc-font&#39;</span><span class="p">])</span>
<span class="n">system</span> <span class="o">=</span> <span class="n">platform</span><span class="o">.</span><span class="n">system</span><span class="p">()</span>  <span class="c1"># 获取操作系统类型</span>

<span class="k">if</span> <span class="n">system</span> <span class="o">==</span> <span class="s1">&#39;Windows&#39;</span><span class="p">:</span>
    <span class="n">font</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;family&#39;</span><span class="p">:</span> <span class="s1">&#39;SimHei&#39;</span><span class="p">}</span>
<span class="k">elif</span> <span class="n">system</span> <span class="o">==</span> <span class="s1">&#39;Darwin&#39;</span><span class="p">:</span>
    <span class="n">font</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;family&#39;</span><span class="p">:</span> <span class="s1">&#39;Arial Unicode MS&#39;</span><span class="p">}</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">font</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;family&#39;</span><span class="p">:</span> <span class="s1">&#39;sans-serif&#39;</span><span class="p">}</span>
<span class="n">matplotlib</span><span class="o">.</span><span class="n">rc</span><span class="p">(</span><span class="s1">&#39;font&#39;</span><span class="p">,</span> <span class="o">**</span><span class="n">font</span><span class="p">)</span>  <span class="c1"># 设置全局字体</span>
    
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>


<span class="n">df</span><span class="p">[</span><span class="s1">&#39;专利申请日&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">dt</span><span class="o">.</span><span class="n">year</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s1">&#39;bar&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;上市公司专利数量(1991 ~ 2022)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">rotation</span><span class="o">=</span><span class="mi">45</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;年份&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;专利数量&#39;</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</code></pre></div><p><img loading="lazy" src="img/plot.png" alt=""  />
</p>
<br>
<h3 id="25-多个申请主体">2.5 多个申请主体</h3>
<p>申请主体可以是多个人，只要在 <em><strong>专利申请主体</strong></em> 中出现了 <code>;</code> , 则表示申请主体是对方的。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="c1">#专利申请人主体可以是单个人(组织)，也可以是多人(组织)</span>
<span class="n">df</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;专利申请主体&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="s1">&#39;;&#39;</span><span class="p">),</span> <span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">)][</span><span class="s1">&#39;专利申请主体&#39;</span><span class="p">]</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">4          浙江南都电源动力股份有限公司; 杭州南都能源科技有限公司; 杭州南都电池有限公司
8                         中国海洋石油总公司;  中海油能源发展股份有限公司
9                       格力电器(武汉)有限公司;  珠海格力电器股份有限公司
10                        广东美的制冷设备有限公司;  美的集团股份有限公司
13             中国石油化工股份有限公司;  中国石油化工股份有限公司石油化工科学研究院
                             ...                   
2085560                 新疆大全新能源股份有限公司; 内蒙古大全新能源有限公司
2085562         大族激光科技产业集团股份有限公司; 深圳市大族鼎盛智能装备科技有限公司
2085572     中国石油化工股份有限公司;  中国石油化工股份有限公司胜利油田分公司物探研究院
2085573                    广东工业大学;  中船海洋与防务装备股份有限公司
2085574            平高集团有限公司;  河南平高电气股份有限公司;  国家电网公司
Name: 专利申请主体, Length: 516473, dtype: object
</code></pre></div><br>
<p>申请主体超过10个的记录，为了展示方便，这里只显示 <code>['股票代码', '专利申请主体', '专利名称', '专利申请日']</code>这四个字段。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">df[df[&#39;专利申请主体&#39;].str.count(&#39;;&#39;)&gt;9][[&#39;股票代码&#39;, &#39;专利申请主体&#39;, &#39;专利名称&#39;, &#39;专利申请日&#39;]]
</code></pre></div><p><img loading="lazy" src="img/df2.png" alt=""  />
</p>
<br>
<p><strong>申请主体数</strong></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">df[&#39;专利申请主体&#39;].str.count(&#39;;&#39;)+1
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">0          1.0
1          1.0
2          1.0
3          1.0
4          3.0
          ... 
2085572    2.0
2085573    2.0
2085574    3.0
2085575    1.0
2085576    1.0
Name: 专利申请主体, Length: 2083784, dtype: float64
</code></pre></div><br>
<p>申请主体数的汇总</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;专利申请主体&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="s1">&#39;;&#39;</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">专利申请主体
1.0     1567311
2.0      428833
3.0       67820
4.0       13130
5.0        4364
6.0        1894
7.0         282
8.0          59
10.0         27
9.0          23
11.0         14
16.0          9
12.0          7
19.0          4
13.0          2
14.0          2
Name: count, dtype: int64
</code></pre></div><br>
<p>均值和方差</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">mainbody_mean = (df[&#39;专利申请主体&#39;].str.count(&#39;;&#39;)+1).mean()
mainbody_std = (df[&#39;专利申请主体&#39;].str.count(&#39;;&#39;)+1).std()

print(&#39;申请主体数均值:&#39;, mainbody_mean)
print(&#39;申请主体数标准差:&#39;,mainbody_std)
</code></pre></div><br>
<p>中学学过正态分布， 在一个正负标准差范围内， 能落下大部分的记录数。咱们看看 <strong>均值加减一个标准差</strong> 占总体的比例</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">mask1</span> <span class="o">=</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;专利申请主体&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="s1">&#39;;&#39;</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="o">&gt;</span> <span class="p">(</span><span class="n">mainbody_mean</span><span class="o">-</span><span class="n">mainbody_std</span><span class="p">)</span>
<span class="n">mask2</span> <span class="o">=</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;专利申请主体&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="s1">&#39;;&#39;</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="o">&lt;</span> <span class="p">(</span><span class="n">mainbody_mean</span><span class="o">+</span><span class="n">mainbody_std</span><span class="p">)</span>

<span class="c1">#落在 均值加减一个标准差范围内的数据占比75%</span>
<span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">mask1</span> <span class="o">&amp;</span> <span class="n">mask2</span><span class="p">])</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">0.7521465756527548
</code></pre></div><p><br><br></p>
<h2 id="三获取数据">三、获取数据</h2>
<p>内容为付费数据集， 50元， 加微信 372335839， 备注「姓名-学校-专业」</p>
<p><br><br></p>
<h2 id="四相关文献">四、相关文献</h2>
<p>使用专利数据的相关文献</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">[1]Bellstam, Gustaf, Sanjai Bhagat, and J. Anthony Cookson. &#34;A text-based analysis of corporate innovation.&#34; _Management Science_ 67, no. 7 (2021): 4004-4031.
[2]Arts, Sam, Bruno Cassiman, and Jianan Hou. &#34;Position and Differentiation of Firms in Technology Space.&#34; Management Science (2023).
</code></pre></div><p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>数据集 | 2.49亿条中国工商注册企业信息(23.9更新)</title>
      <link>https://textdata.cn/blog/2023-12-03-china-mainland-corporate-registration-information/</link>
      <pubDate>Sun, 03 Dec 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-12-03-china-mainland-corporate-registration-information/</guid>
      <description>341个地市， 2亿条工商注册信息， 网盘压缩文件夹体积17.6G</description>
      <content:encoded><![CDATA[<h2 id="工商数据集概况">工商数据集概况</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">地市数量: 347
记录数: 2.49亿条
文件夹体积: 160G
日期涵盖建国前~2023.9.19
</code></pre></div><p><img loading="lazy" src="img/dataset-screen.png" alt=""  />
</p>
<br>
<h3 id="字段">字段</h3>
<p>任意csv文件的字段包括</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">- 企业名称
- 英文名称
- 统一社会信用代码
- 企业类型
- 经营状态
- 成立日期
- 核准日期
- 法定代表人
- 注册咨本
- 实缴资本
- 参保人数
- 公司规模
- 经营范围
- 注册地址
- 营业期限
- 纳税人识别号
- 工商注册号
- 组织机构代码
- 联系电话(脱敏)
- 邮箱(脱敏)
- 纳税人资质
- 曾用名
- 所属省份
- 所属城市
- 所属区县
- 网站链接
- 所属行业
- 登记机关
- 经度
- 纬度
</code></pre></div><p>数据集已经脱敏处理， 避免分享过程出现违规(法)问题。 如果你想获取手机号，商业用途， 就不要联系我了！我没有，有也不卖。</p>
<br>
<h3 id="12-地市数量">1.2 地市数量</h3>
<p>347个地市</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">os</span>

<span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"> [
 &#39;北京.csv&#39;,
 &#39;上海.csv&#39;,
 &#39;南京.csv&#39;,
 ...
 &#39;重庆.csv&#39;,
  ]
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#347个地级市工商信息</span>
<span class="nb">len</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">())</span>
</code></pre></div><p>Run</p>
<pre><code>347
</code></pre>
<br>
<br>
<h2 id="读取">读取</h2>
<p>不考虑电脑内存容量限制， 读取 石家庄市、长沙市、杭州市。如果电脑内存很小，请先阅读  <a href="https://textdata.cn/blog/2023-11-17-how-handle-mega-csv-that-far-exceed-memory/">推荐 | 如何处理远超电脑内存的csv文件</a></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">sjz_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;石家庄.csv&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">,</span> <span class="n">low_memory</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">cs_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;长沙.csv&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">,</span> <span class="n">low_memory</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">hz_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;杭州.csv&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">,</span> <span class="n">low_memory</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1">#随机显示2条记录</span>
<span class="n">sjz_df</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</code></pre></div><p><img loading="lazy" src="img/df.png" alt=""  />
</p>
<br>
<p>石家庄.csv 企业记录数</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="nb">len</span><span class="p">(</span><span class="n">sjz_df</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">2010163
</code></pre></div><br>
<p>含有的字段有</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">sjz_df</span><span class="o">.</span><span class="n">columns</span>
</code></pre></div><pre><code>Index(['企业组织机构代码', '企业名称', '注册资本', '实缴资本', '纳税人识别号', '法定代表人', '企业状态', '所属行业',
       '企业名称', '英文名称', '统一社会信用代码', '企业类型', '经营状态', '成立日期', '核准日期', '法定代表人',
       '注册咨本', '实缴资本', '参保人数', '公司规模', '经营范围', '注册地址', '营业期限', '纳税人识别号', '工商注册号', '组织机构代码', '联系电话', '邮箱', '纳税人资质', '曾用名', '所属省份', '所属城市', '所属区县', '网站链接', '所属行业', '登记机关', '经度', '纬度'],
      dtype='object')
</code></pre>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">sjz_df</span><span class="p">[</span><span class="s1">&#39;成立日期&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">sjz_df</span><span class="p">[</span><span class="s1">&#39;成立日期&#39;</span><span class="p">])</span>

<span class="c1">#石家庄数据集日期范围</span>
<span class="nb">print</span><span class="p">(</span><span class="n">sjz_df</span><span class="p">[</span><span class="s1">&#39;成立日期&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">sjz_df</span><span class="p">[</span><span class="s1">&#39;成立日期&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">1917-01-30 00:00:00
2023-09-19 00:00:00
</code></pre></div><br>
<p>查看成立日期为1917-01-30的信息</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">datetime</span>

<span class="n">sjz_df</span><span class="p">[</span><span class="n">sjz_df</span><span class="p">[</span><span class="s1">&#39;成立日期&#39;</span><span class="p">]</span><span class="o">==</span><span class="n">datetime</span><span class="o">.</span><span class="n">datetime</span><span class="p">(</span><span class="n">year</span><span class="o">=</span><span class="mi">1917</span><span class="p">,</span> <span class="n">month</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">day</span><span class="o">=</span><span class="mi">30</span><span class="p">)]</span><span class="o">.</span><span class="n">to_dict</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">{&#39;企业组织机构代码&#39;: {913555: &#39;81130000MC0611518K&#39;},
 &#39;企业名称&#39;: {913555: &#39;中国铁路工会石家庄站委员会&#39;},
 &#39;注册资本&#39;: {913555: &#39;276.5万元人民币&#39;},
 &#39;实缴资本&#39;: {913555: &#39;-&#39;},
 &#39;纳税人识别号&#39;: {913555: &#39;81130000MC0611518K&#39;},
 &#39;法定代表人&#39;: {913555: &#39;韩海峰&#39;},
 &#39;企业状态&#39;: {913555: &#39;暂无&#39;},
 &#39;所属行业&#39;: {913555: &#39;公共管理、社会保障和社会组织&#39;},
 &#39;统一社会信用代码&#39;: {913555: &#39;81130000MC0611518K&#39;},
 &#39;工商注册号&#39;: {913555: nan},
 &#39;组织机构代码&#39;: {913555: &#39;-&#39;},
 &#39;登记机关&#39;: {913555: &#39;河北省总工会&#39;},
 &#39;成立日期&#39;: {913555: Timestamp(&#39;1917-01-30 00:00:00&#39;)},
 &#39;核准日期&#39;: {913555: &#39;1949-10-01&#39;},
 &#39;企业类型&#39;: {913555: &#39;-&#39;},
 &#39;经营期限&#39;: {913555: &#39;2019-04-01 至 2022-02-09&#39;},
 &#39;注册所在地&#39;: {913555: nan},
 &#39;地区编码&#39;: {913555: &#39;130105&#39;},
 &#39;详细地址&#39;: {913555: &#39;石家庄市新华区大桥路2号&#39;},
 &#39;经营范围&#39;: {913555: &#39;-&#39;},
 &#39;参保人数&#39;: {913555: 478.0},
 &#39;企业电话&#39;: {913555: nan},
 &#39;企业座机&#39;: {913555: nan},
 &#39;企业邮箱&#39;: {913555: nan}}
</code></pre></div><p><br><br></p>
<h2 id="可视化">可视化</h2>
<p>绘制一个1992-2023年的注册量折线图</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">matplotlib</span>
<span class="kn">import</span> <span class="nn">matplotlib_inline</span>
<span class="n">matplotlib_inline</span><span class="o">.</span><span class="n">backend_inline</span><span class="o">.</span><span class="n">set_matplotlib_formats</span><span class="p">(</span><span class="s1">&#39;png&#39;</span><span class="p">,</span> <span class="s1">&#39;svg&#39;</span><span class="p">)</span>
<span class="kn">import</span> <span class="nn">scienceplots</span>
<span class="kn">import</span> <span class="nn">platform</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">([</span><span class="s1">&#39;science&#39;</span><span class="p">,</span> <span class="s1">&#39;no-latex&#39;</span><span class="p">,</span> <span class="s1">&#39;cjk-sc-font&#39;</span><span class="p">])</span>
<span class="n">system</span> <span class="o">=</span> <span class="n">platform</span><span class="o">.</span><span class="n">system</span><span class="p">()</span>  <span class="c1"># 获取操作系统类型</span>

<span class="k">if</span> <span class="n">system</span> <span class="o">==</span> <span class="s1">&#39;Windows&#39;</span><span class="p">:</span>
    <span class="n">font</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;family&#39;</span><span class="p">:</span> <span class="s1">&#39;SimHei&#39;</span><span class="p">}</span>
<span class="k">elif</span> <span class="n">system</span> <span class="o">==</span> <span class="s1">&#39;Darwin&#39;</span><span class="p">:</span>
    <span class="n">font</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;family&#39;</span><span class="p">:</span> <span class="s1">&#39;Arial Unicode MS&#39;</span><span class="p">}</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">font</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;family&#39;</span><span class="p">:</span> <span class="s1">&#39;sans-serif&#39;</span><span class="p">}</span>
<span class="n">matplotlib</span><span class="o">.</span><span class="n">rc</span><span class="p">(</span><span class="s1">&#39;font&#39;</span><span class="p">,</span> <span class="o">**</span><span class="n">font</span><span class="p">)</span>  <span class="c1"># 设置全局字体</span>
    
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">years</span> <span class="o">=</span> <span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1992</span><span class="p">,</span> <span class="mi">2023</span><span class="p">)]</span>

<span class="n">sjz_df</span><span class="p">[</span><span class="s1">&#39;成立日期&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">slice</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="n">years</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;石家庄&#39;</span><span class="p">)</span>
<span class="n">cs_df</span><span class="p">[</span><span class="s1">&#39;成立日期&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">slice</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="n">years</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;长沙&#39;</span><span class="p">)</span>
<span class="n">hz_df</span><span class="p">[</span><span class="s1">&#39;成立日期&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">slice</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="n">years</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;杭州&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;工商企业注册量1992-2019年&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;年份&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;注册量&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper right&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>    
</code></pre></div><p><img loading="lazy" src="img/output_8_0.png" alt="svg"  />
</p>
<br>
<h2 id="数据集获取">数据集获取</h2>
<p>内容为付费数据集， 100元， 加微信 372335839， 备注「姓名-学校-专业-工商数据集」</p>
<p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>中国管理科学 | 使用业绩说明会文本数据测量上市公司前瞻性信息</title>
      <link>https://textdata.cn/blog/2023-09-08-earnings-communication-conference-forward-looking-statements-information/</link>
      <pubDate>Fri, 08 Sep 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-09-08-earnings-communication-conference-forward-looking-statements-information/</guid>
      <description>业绩说明会， 是我国上市公司和中小投资 者沟通交流的重要载体。 在年报披露后， 能够 帮助投资者快速、准确地抓取信息披露重点， 全面了解企业发展状况， 增进对企业价值及经 营理念的认同。上市公司的业绩说明会是金融领域中的重要事件，它为投资者、分析师和其他利益相关者提供了一个与公司管理层直接交流的平台。这种数据集的学术价值多方面体现。</description>
      <content:encoded><![CDATA[<p>最近几个月没怎么分享长技术文，正好昨天分享的付费数据集涉及到一篇论文，感觉用到了很多Python的地方，就想着做一期。这篇论文的Python实现，技术要点有两个部分</p>
<ol>
<li><strong>「构建词典」</strong>； 训练word2vec预训练语言模型，并使用该模型扩展出<strong>前瞻性词典集</strong></li>
<li><strong>「算前瞻性指标</strong>」； 根据<strong>前瞻性词典集</strong>,统计每个企业业绩说明会内的前瞻性词在总词数中的比例</li>
</ol>
<p>这两部分，分别对应本文 <strong>「二、实验-构建词典」</strong>、<strong>「三、计算前瞻性」</strong>。</p>
<p><strong>内容较长， 可能对初学小白不友好。 学完大邓课程「<a href="https://textdata.cn/blog/management_python_course/">Python实证指标构建与文本分析</a>」的同学，阅读起来会轻松一些</strong>。</p>
<p><br><br></p>
<p><strong>许帅,邵帅,何贤杰.业绩说明会前瞻性信息对分析师盈余预测准确性的影响——信口雌黄还是言而有征[J].中国管理科学:1-15.</strong></p>
<blockquote>
<p>摘要:本文以2007—2020年上市公司业绩说明会为背景，研究前瞻性信息披露对分析师预测的影响，发现业绩说明会中的前瞻性信息可以显著提升分析师盈余预测准确性。公司的信息不对称程度越高，前瞻性信息对分析师预测准确性提升越多。分析师专长工作经验越丰富，具备更强的信息捕捉能力，可以更好地吸收与理解业绩说明会中的前瞻性信息，做出更准确的预测。进一步，本文对前瞻性信息影响分析师预测的路径进行了讨论，认为前瞻性信息可能通过吸引分析师和机构投资者调研，增进分析师对上市公司经营状况的了解，进而提升盈余预测准确性。此外，本文发现，前瞻性信息中业绩相关类信息因具有更高的可信度，且与盈余因子直接相关，能够显著提升分析师盈余预测准确性。本研究为管理层披露与分析师的互动研究提供了增量证据，研究结果支持了业绩说明会有效性，对未来监管部门制定相关信息披露政策提供依据和建议。</p>
</blockquote>
<p><br><br></p>
<h2 id="一前瞻性指标衡量">一、前瞻性指标衡量</h2>
<p>本文关注业绩说明会中前瞻性信息披露的比重， 借鉴Li [5] 、Muslu等 [6] 和马黎珺等 [14] 对前瞻性信息的定义， 采用 “ 词袋法 ” 构建前瞻性 指标， <strong>运用Python软件中jieba中文分词技术统计在问答阶段前瞻性词汇词频占业绩说明会文本总词频（去除停用词）的比例</strong>。 同时， 手工剔除了诸如“请关注后续公告”、“详见以后公告”等不具备实质性前瞻性信息的词频。</p>
<p>在词典的选取上， 本文前瞻性词典集借鉴胡楠和薛付婧 [15] 的种子词汇， 为了保证词汇的全面性， 还将所有种子词导入到开源分析工具 word2vec中， 并在业绩说明会语料库中寻找与种子词内容接近程度最高的词汇，其中包含（1） 管理团队的预测，譬如“计划/预计/预测”等表 述；（2）出现未来时点的表述， 譬如“未来/以 后/明年/下半年”等表述；（3）暗示企业即将发 生的动作， 譬如“有望/后续”等表述， 共计 174个前瞻性词汇（详见附录2）。前瞻性指标比重越大，表明公司的前瞻性信息披露越多。</p>
<p><img loading="lazy" src="img/formular.png" alt=""  />
</p>
<p><img loading="lazy" src="img/dict1.png" alt=""  />
</p>
<br>
<h2 id="二实验-构建词典">二、实验-构建词典</h2>
<h3 id="21-整理数据">2.1 整理数据</h3>
<p>把 <a href="https://textdata.cn/blog/2023-09-08-china-a-share-market-listed-company-earnings-communication-conference/"><strong>数据集 | 84w条业绩说明会问答数据(2005-2023)</strong></a>汇总到一个txt文件内。为了保证问答上下文一致， 问答要放在相邻处。 可能需要安装</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">pip3 install openpyxl
pip3 install pandas
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_excel</span><span class="p">(</span><span class="s1">&#39;业绩说明会问答05-23.xlsx&#39;</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;提问内容&#39;</span><span class="p">]</span><span class="o">+</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;回答内容&#39;</span><span class="p">]</span>
<span class="n">df</span><span class="o">.</span><span class="n">dropna</span><span class="p">(</span><span class="n">subset</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">],</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/df1.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;业绩说明会05-23.txt&#39;</span><span class="p">,</span> <span class="s1">&#39;a+&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    
    <span class="c1">#为了保证问答上下文一致， 问答要放在相邻处</span>
    <span class="n">text</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">to_list</span><span class="p">())</span>
    <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
</code></pre></div><br>
<h3 id="22-训练word2vec">2.2 训练word2vec</h3>
<p>一般都是使用gensim库，对  <strong>「业绩说明会05-23.txt」</strong> 数据集进行训练，我已经封装到的cntext库内。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">pip3 install cntext==1.8.6
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>
<span class="kn">import</span> <span class="nn">os</span>


<span class="c1">#Init W2VModels. Support English and Chinese</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">W2VModels</span><span class="p">(</span><span class="n">cwd</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">getcwd</span><span class="p">(),</span> 
                     <span class="n">lang</span><span class="o">=</span><span class="s1">&#39;chinese&#39;</span><span class="p">)</span>  <span class="c1">#corpus data w2v_corpus.txt</span>


<span class="c1">#训练结束后，「业绩说明会05-23.100.6.bin」会出现在「output/Word2Vec」文件夹内 </span>
<span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">input_txt_file</span><span class="o">=</span><span class="s1">&#39;业绩说明会05-23.txt&#39;</span><span class="p">,</span> 
            <span class="n">model_name</span><span class="o">=</span><span class="s1">&#39;业绩说明会05-23.100.6.bin&#39;</span><span class="p">)</span>
</code></pre></div><br>
<p>需要注意， output/word2vec文件夹内会同时含有</p>
<ul>
<li><strong>业绩说明会05-23.100.6.bin</strong></li>
<li><strong>业绩说明会05-23.100.6.bin.vectors.npy</strong></li>
</ul>
<p>两个文件都不要删除， 这些是预训练词向量文件。</p>
<br>
<h3 id="23-扩展词典">2.3 扩展词典</h3>
<p>根据前瞻性研究需要，整理了一些种子词</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">seedwords</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;计划&#39;</span><span class="p">,</span> <span class="s1">&#39;预计&#39;</span><span class="p">,</span> <span class="s1">&#39;未来&#39;</span><span class="p">,</span> <span class="s1">&#39;目标&#39;</span><span class="p">,</span> <span class="s1">&#39;可能&#39;</span><span class="p">,</span> <span class="s1">&#39;如果&#39;</span><span class="p">,</span> <span class="s1">&#39;机遇&#39;</span><span class="p">,</span> <span class="s1">&#39;预期&#39;</span><span class="p">,</span> <span class="s1">&#39;挑战&#39;</span><span class="p">,</span> <span class="s1">&#39;预测&#39;</span><span class="p">,</span> <span class="s1">&#39;今后&#39;</span><span class="p">,</span> <span class="s1">&#39;目的&#39;</span><span class="p">,</span> <span class="s1">&#39;契机&#39;</span><span class="p">,</span> <span class="s1">&#39;前景&#39;</span><span class="p">,</span> <span class="s1">&#39;希望&#39;</span><span class="p">,</span> <span class="s1">&#39;展望&#39;</span><span class="p">,</span> <span class="s1">&#39;相信&#39;</span><span class="p">,</span> <span class="s1">&#39;愿景&#39;</span><span class="p">,</span> <span class="s1">&#39;期待&#39;</span><span class="p">,</span> <span class="s1">&#39;明年&#39;</span><span class="p">,</span> <span class="s1">&#39;期望&#39;</span><span class="p">]</span>
</code></pre></div><ol>
<li>导入word2vec预训练语言模型文件 <strong>业绩说明会05-23.100.6.bin</strong></li>
<li>寻找与种子词语义最相似的n个词。</li>
<li>经过人工检查，剔除n个词中与 <strong>前瞻性</strong> 无关的词语，最终得到 <strong>前瞻性词典</strong>(论文中是174个词)。</li>
</ol>
<p>但是，经过大邓测试发现业绩说明会训练得到的业绩说明会word2vec(05-23.100.6.bin)模型表现很差。</p>
<p>之前大邓用01-21年管理层讨论与分析训练过一个word2vec(<strong>mda01-21.200.6.bin</strong>)，</p>
<blockquote>
<p><a href="https://textdata.cn/blog/2023-03-24-load-w2v-and-expand-your-concpet-dicitonary/">预训练模型 | 金融会计类word2vec， 可扩展或构建领域内概念情感词典</a></p>
</blockquote>
<p>在这次前瞻性扩展词任务中，mda01-21.200.6.bin表现要远好于05-23.100.6.bin。</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">gensim.models</span> <span class="kn">import</span> <span class="n">KeyedVectors</span>

<span class="k">def</span> <span class="nf">load_w2v</span><span class="p">(</span><span class="n">w2v_path</span><span class="p">):</span>
    <span class="s2">&#34;&#34;&#34;
</span><span class="s2">    Load word2vec model
</span><span class="s2">
</span><span class="s2">    Args:
</span><span class="s2">        w2v_path (str): path of word2vec model
</span><span class="s2">
</span><span class="s2">    Returns:
</span><span class="s2">        model: word2vec model
</span><span class="s2">    &#34;&#34;&#34;</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Loading word2vec model...&#39;</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">KeyedVectors</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">w2v_path</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">model</span>


<span class="n">wv</span> <span class="o">=</span> <span class="n">load_w2v</span><span class="p">(</span><span class="s1">&#39;Embeddings/业绩说明会05-23.100.6.bin&#39;</span><span class="p">)</span>
<span class="n">wv2</span> <span class="o">=</span> <span class="n">load_w2v</span><span class="p">(</span><span class="s1">&#39;Embeddings/mda01-21.200.6.bin&#39;</span><span class="p">)</span>
</code></pre></div><pre><code>Loading word2vec model...
Loading word2vec model...
</code></pre>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#词汇量</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">wv</span><span class="o">.</span><span class="n">index_to_key</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">wv2</span><span class="o">.</span><span class="n">index_to_key</span><span class="p">))</span>
</code></pre></div><pre><code>198776
789539
</code></pre>
<p>​ <br>
<br></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#查询某词的词向量</span>
<span class="n">wv</span><span class="o">.</span><span class="n">get_vector</span><span class="p">(</span><span class="s1">&#39;创新&#39;</span><span class="p">)</span>

<span class="c1">#查询多个词的词向量</span>
<span class="c1">#wv.get_mean_vector([&#39;创新&#39;, &#39;研发&#39;])</span>
</code></pre></div><pre><code>array([ 0.43675017,  0.74739504,  3.3765798 , -0.29287583,  0.40125442,
    0.9364979 ,  0.62465197,  0.06480039,  0.12256158, -2.0735328 ,
   -0.256066  , -1.7680115 , -0.8514873 , -0.756108  ,  1.3441261 ,
   -0.18098126,  2.7290103 , -4.6596766 ,  0.4046495 , -4.0644083 ,
    0.6022293 ,  1.3569978 ,  1.0036035 ,  0.06123297, -2.0733726 ,
    2.2704456 , -1.2935334 , -0.2855776 ,  1.588003  ,  1.5027634 ,
    2.0897112 , -0.8861778 ,  0.4014722 , -0.41474393, -1.5390201 ,
    0.23899865, -0.9823706 , -2.986944  , -2.6887195 , -2.2386284 ,
    0.04810223,  1.3241886 , -0.71262985, -0.8015585 ,  1.5249555 ,
   -3.611584  , -1.4187033 , -1.6014036 ,  0.816903  ,  3.1821172 ,
   -1.7302881 , -0.8280679 , -1.2833163 ,  0.65565586, -0.8857021 ,
    2.098562  ,  1.4773984 ,  1.0931807 , -0.02242889,  1.1279039 ,
   -2.2318523 ,  0.24540211,  0.17126203,  2.5631666 , -1.7135285 ,
    0.60896975, -0.2654438 ,  0.5718087 , -1.4996717 ,  1.0189433 ,
    1.0205768 ,  3.7439635 , -0.3575424 , -3.189775  ,  0.6117708 ,
   -0.60615975,  2.940066  , -0.89338064, -0.626806  , -1.4389508 ,
   -1.1291629 , -2.2354846 , -0.6873424 ,  1.9574465 , -1.2231802 ,
    1.2850708 , -0.7581777 ,  0.8184319 ,  1.542834  , -0.8685869 ,
    1.1841776 , -0.4524089 , -0.8068617 ,  0.01519055, -0.23408687,
   -0.51564324,  0.20584114,  0.14295417,  0.5481142 ,  2.523313  ],
  dtype=float32)
</code></pre>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">expand_dictionary</span><span class="p">(</span><span class="n">wv</span><span class="p">,</span> <span class="n">seedwords</span><span class="p">,</span> <span class="n">topn</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
    <span class="s2">&#34;&#34;&#34;
</span><span class="s2">    According to the seed word file, select the top n words with the most similar semantics and save them in the directory save_dir.
</span><span class="s2">    
</span><span class="s2">    Args:
</span><span class="s2">        wv (Word2VecKeyedVectors): the word embedding model
</span><span class="s2">        seedwords (list): 种子词
</span><span class="s2">        topn (int, optional): Set the number of most similar words to retrieve to topn. Defaults to 100.
</span><span class="s2">        save_dir (str, optional): the directory to save the candidate words. Defaults to &#39;Word2Vec&#39;.
</span><span class="s2">    
</span><span class="s2">    Returns:
</span><span class="s2">    &#34;&#34;&#34;</span>
    <span class="n">simidx_scores</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="n">similars_candidate_idxs</span> <span class="o">=</span> <span class="p">[]</span> <span class="c1">#the candidate words of seedwords</span>
    <span class="n">dictionary</span> <span class="o">=</span> <span class="n">wv</span><span class="o">.</span><span class="n">key_to_index</span>
    <span class="n">seedidxs</span> <span class="o">=</span> <span class="p">[]</span> <span class="c1">#transform word to index</span>
    <span class="k">for</span> <span class="n">seed</span> <span class="ow">in</span> <span class="n">seedwords</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">seed</span> <span class="ow">in</span> <span class="n">dictionary</span><span class="p">:</span>
            <span class="n">seedidx</span> <span class="o">=</span> <span class="n">dictionary</span><span class="p">[</span><span class="n">seed</span><span class="p">]</span>
            <span class="n">seedidxs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">seedidx</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">seedidx</span> <span class="ow">in</span> <span class="n">seedidxs</span><span class="p">:</span>
        <span class="c1"># sims_words such as [(&#39;by&#39;, 0.99984), (&#39;or&#39;, 0.99982), (&#39;an&#39;, 0.99981), (&#39;up&#39;, 0.99980)]</span>
        <span class="n">sims_words</span> <span class="o">=</span> <span class="n">wv</span><span class="o">.</span><span class="n">similar_by_word</span><span class="p">(</span><span class="n">seedidx</span><span class="p">,</span> <span class="n">topn</span><span class="o">=</span><span class="n">topn</span><span class="p">)</span>
        <span class="c1">#Convert words to index and store them</span>
        <span class="n">similars_candidate_idxs</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="n">dictionary</span><span class="p">[</span><span class="n">sim</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span> <span class="k">for</span> <span class="n">sim</span> <span class="ow">in</span> <span class="n">sims_words</span><span class="p">])</span>
    <span class="n">similars_candidate_idxs</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">similars_candidate_idxs</span><span class="p">)</span>
    
    <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">similars_candidate_idxs</span><span class="p">:</span>
        <span class="n">score</span> <span class="o">=</span> <span class="n">wv</span><span class="o">.</span><span class="n">n_similarity</span><span class="p">([</span><span class="n">idx</span><span class="p">],</span> <span class="n">seedidxs</span><span class="p">)</span>
        <span class="n">simidx_scores</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">idx</span><span class="p">,</span> <span class="n">score</span><span class="p">))</span>
    <span class="n">simidxs</span> <span class="o">=</span> <span class="p">[</span><span class="n">w</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">simidx_scores</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">k</span><span class="p">:</span><span class="n">k</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)]</span>

    <span class="n">simwords</span> <span class="o">=</span> <span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">wv</span><span class="o">.</span><span class="n">index_to_key</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">simidxs</span><span class="p">][:</span><span class="n">topn</span><span class="p">]</span>

    <span class="n">resultwords</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">resultwords</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">seedwords</span><span class="p">)</span>
    <span class="n">resultwords</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">simwords</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">resultwords</span>


<span class="c1">#为了节省板面，这里设置为50</span>
<span class="c1">#论文中经过筛选留下174个词，实际上topn应该远大于174，</span>
<span class="n">expand_dictionary</span><span class="p">(</span><span class="n">wv</span><span class="o">=</span><span class="n">wv</span><span class="p">,</span> 
                  <span class="c1">#前瞻性种子词</span>
                  <span class="n">seedwords</span><span class="o">=</span> <span class="p">[</span><span class="s1">&#39;计划&#39;</span><span class="p">,</span> <span class="s1">&#39;预计&#39;</span><span class="p">,</span> <span class="s1">&#39;未来&#39;</span><span class="p">,</span> <span class="s1">&#39;目标&#39;</span><span class="p">,</span> <span class="s1">&#39;可能&#39;</span><span class="p">,</span> <span class="s1">&#39;如果&#39;</span><span class="p">,</span> <span class="s1">&#39;机遇&#39;</span><span class="p">,</span> <span class="s1">&#39;预期&#39;</span><span class="p">,</span> <span class="s1">&#39;挑战&#39;</span><span class="p">,</span> <span class="s1">&#39;预测&#39;</span><span class="p">,</span> <span class="s1">&#39;今后&#39;</span><span class="p">,</span> <span class="s1">&#39;目的&#39;</span><span class="p">,</span> <span class="s1">&#39;契机&#39;</span><span class="p">,</span> <span class="s1">&#39;前景&#39;</span><span class="p">,</span> <span class="s1">&#39;希望&#39;</span><span class="p">,</span> <span class="s1">&#39;展望&#39;</span><span class="p">,</span> <span class="s1">&#39;相信&#39;</span><span class="p">,</span> <span class="s1">&#39;愿景&#39;</span><span class="p">,</span> <span class="s1">&#39;期待&#39;</span><span class="p">,</span> <span class="s1">&#39;明年&#39;</span><span class="p">,</span> <span class="s1">&#39;期望&#39;</span><span class="p">],</span>
                  <span class="n">topn</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">[&#39;计划&#39;,
 &#39;预计&#39;,
 ......
 &#39;几年&#39;,
 &#39;积极影响&#39;,
 &#39;有何&#39;,
 &#39;谢谢您提问&#39;,
 &#39;今后&#39;,
 &#39;这块&#39;,
 &#39;近几年&#39;,
 &#39;近两年&#39;,
 &#39;请问李&#39;,
 &#39;裁员&#39;,
 &#39;亮点&#39;,
 &#39;准备采取&#39;,
 &#39;将会&#39;,
 &#39;接下来&#39;,
 &#39;有何规划&#39;,
 &#39;前景&#39;,
 &#39;管理层是否&#39;,
 &#39;未来几年&#39;,
 &#39;有没有新&#39;,
 &#39;发展状况&#39;,
 &#39;一块&#39;,
 &#39;当前&#39;,
 &#39;很大&#39;,
 &#39;这块业务&#39;,
 &#39;LNG船&#39;,
 &#39;具体措施您好&#39;,
 &#39;当下&#39;,
 &#39;是否能够&#39;,
 &#39;明后&#39;,
 &#39;一个台阶&#39;,
 &#39;是否符合&#39;,
 &#39;巨大&#39;,
 &#39;预判&#39;,
 &#39;对此&#39;,
 &#39;未来三年&#39;,
 &#39;资本开支&#39;,
 &#39;不少&#39;,
 &#39;未来是否&#39;,
 &#39;这方面&#39;,
 &#39;看法&#39;,
 &#39;今年以来&#39;,
 &#39;疫情结束&#39;,
 &#39;想知道&#39;,
 &#39;取得不错&#39;,
 &#39;谈谈&#39;,
 &#39;一步&#39;,
 &#39;今年是否&#39;,
 &#39;发展前景&#39;,
 &#39;东宝&#39;,
 &#39;现状&#39;]
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">expand_dictionary</span><span class="p">(</span><span class="n">wv</span><span class="o">=</span><span class="n">wv2</span><span class="p">,</span> 
                  <span class="c1">#前瞻性种子词</span>
                  <span class="n">seedwords</span><span class="o">=</span> <span class="p">[</span><span class="s1">&#39;计划&#39;</span><span class="p">,</span> <span class="s1">&#39;预计&#39;</span><span class="p">,</span> <span class="s1">&#39;未来&#39;</span><span class="p">,</span> <span class="s1">&#39;目标&#39;</span><span class="p">,</span> <span class="s1">&#39;可能&#39;</span><span class="p">,</span> <span class="s1">&#39;如果&#39;</span><span class="p">,</span> <span class="s1">&#39;机遇&#39;</span><span class="p">,</span> <span class="s1">&#39;预期&#39;</span><span class="p">,</span> <span class="s1">&#39;挑战&#39;</span><span class="p">,</span> <span class="s1">&#39;预测&#39;</span><span class="p">,</span> <span class="s1">&#39;今后&#39;</span><span class="p">,</span> <span class="s1">&#39;目的&#39;</span><span class="p">,</span> <span class="s1">&#39;契机&#39;</span><span class="p">,</span> <span class="s1">&#39;前景&#39;</span><span class="p">,</span> <span class="s1">&#39;希望&#39;</span><span class="p">,</span> <span class="s1">&#39;展望&#39;</span><span class="p">,</span> <span class="s1">&#39;相信&#39;</span><span class="p">,</span> <span class="s1">&#39;愿景&#39;</span><span class="p">,</span> <span class="s1">&#39;期待&#39;</span><span class="p">,</span> <span class="s1">&#39;明年&#39;</span><span class="p">,</span> <span class="s1">&#39;期望&#39;</span><span class="p">],</span>
                  <span class="n">topn</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">[&#39;计划&#39;,
 &#39;预计&#39;,
  ......
 &#39;相信&#39;,
 &#39;将会&#39;,
 &#39;未来&#39;,
 &#39;希望&#39;,
 &#39;预见&#39;,
 &#39;预期&#39;,
 &#39;可能&#39;,
 &#39;必将&#39;,
 &#39;应该&#39;,
 &#39;未来几年&#39;,
 &#39;今后&#39;,
 &#39;有望&#39;,
 &#39;目标&#39;,
 &#39;这一&#39;,
 &#39;当前&#39;,
 &#39;当下&#39;,
 &#39;无疑&#39;,
 &#39;期望&#39;,
 &#39;接下来&#39;,
 &#39;意味着&#39;,
 &#39;背景&#39;,
 &#39;期待&#39;,
 &#39;近期&#39;,
 &#39;下一阶段&#39;,
 &#39;机会&#39;,
 &#39;看到&#39;,
 &#39;预示&#39;,
 &#39;能够&#39;,
 &#39;短期内&#39;,
 &#39;未来一段时间&#39;,
 &#39;将来&#39;,
 &#39;展望未来&#39;,
 &#39;必须&#39;,
 &#39;真正&#39;,
 &#39;眼光&#39;,
 &#39;必然&#39;,
 &#39;还会&#39;,
 &#39;预计&#39;,
 &#39;未来十年&#39;,
 &#39;机遇&#39;,
 &#39;可能性&#39;,
 &#39;后续&#39;,
 &#39;潜在&#39;,
 &#39;决心&#39;,
 &#39;信心&#39;,
 &#39;仍然&#39;,
 &#39;非常&#39;,
 &#39;这为&#39;,
 &#39;未来五年&#39;,
 &#39;短时间&#39;]
</code></pre></div><p><strong>大邓假装经过很多检查，剔除不相关词语，最终跟论文一样，都得到了174个前瞻性词语。  需要说明，大邓已经将174个词内置到了cntext库(1.8.6中)</strong></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">import cntext as ct

#cntext已内置了论文中的174个前瞻性词集
fls_words = ct.load_pkl_dict(&#39;Chinese_FLS.pkl&#39;)[&#39;Chinese_FLS&#39;]
fls_words
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">[&#39;计划&#39;,
 &#39;预计&#39;,
 &#39;未来&#39;,
 &#39;目标&#39;,
 ......
 &#39;企业宗旨&#39;,
 &#39;宗旨&#39;,
 &#39;该愿景&#39;,
 &#39;愿望&#39;,
 &#39;心愿&#39;,
 &#39;盼望&#39;,
 &#39;祝愿&#39;,
 &#39;今年年底&#39;,
 &#39;今年底&#39;,
 &#39;明年初&#39;,
 &#39;第二季度&#39;,
 &#39;上半年&#39;,
 &#39;下半年&#39;,
 &#39;本月底&#39;,
 &#39;下周&#39;,
 &#39;马上&#39;,
 &#39;厚望&#39;,
 &#39;期盼&#39;,
 &#39;鞭策&#39;,
 &#39;梦想&#39;,
 &#39;愿&#39;]
</code></pre></div><p><br><br></p>
<h2 id="三计算前瞻性">三、计算前瞻性</h2>
<ol>
<li>汇总记录； 将同一年同一家上市公司的所有问答合并为一条记录，存储于df2中。</li>
<li>设计前瞻性计算函数 <strong>compute_fls</strong></li>
<li>对df2[&lsquo;text&rsquo;]使用前瞻性计算函数<strong>compute_fls</strong>，计算结果保存到字段<strong>Forward</strong></li>
</ol>
<h3 id="31-汇总记录">3.1 汇总记录</h3>
<p>将同一年同一家上市公司的所有问答合并为一条记录，存储于新df的text中。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df2</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">([</span><span class="s1">&#39;股票代码&#39;</span><span class="p">,</span> <span class="s1">&#39;会计年度&#39;</span><span class="p">])[</span><span class="s1">&#39;text&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">)</span><span class="o">.</span><span class="n">reset_index</span><span class="p">()</span>
<span class="n">df2</span><span class="o">.</span><span class="n">dropna</span><span class="p">(</span><span class="n">subset</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">],</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">df2</span>
</code></pre></div><p><img loading="lazy" src="img/df2.png" alt=""  />
</p>
<br>
<h3 id="32--设计前瞻性计算函数compute_fls">3.2  设计前瞻性计算函数compute_fls</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>
<span class="kn">import</span> <span class="nn">jieba</span>


<span class="n">fls_words</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">load_pkl_dict</span><span class="p">(</span><span class="s1">&#39;Chinese_FLS.pkl&#39;</span><span class="p">)[</span><span class="s1">&#39;Chinese_FLS&#39;</span><span class="p">]</span>
<span class="n">stopwords</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">load_pkl_dict</span><span class="p">(</span><span class="s1">&#39;STOPWORDS.pkl&#39;</span><span class="p">)[</span><span class="s1">&#39;STOPWORDS&#39;</span><span class="p">][</span><span class="s1">&#39;chinese&#39;</span><span class="p">]</span>

<span class="k">def</span> <span class="nf">compute_fls</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="n">num</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">words</span> <span class="o">=</span> <span class="n">jieba</span><span class="o">.</span><span class="n">lcut</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
    <span class="n">words</span> <span class="o">=</span> <span class="p">[</span><span class="n">w</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">words</span> <span class="k">if</span> <span class="n">w</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">stopwords</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">words</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">fls_words</span><span class="p">:</span>
            <span class="n">num</span><span class="o">+=</span><span class="mi">1</span>
    <span class="c1">#+1是为了防止分母为0的情况</span>
    <span class="k">return</span> <span class="n">num</span><span class="o">/</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">words</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div><br>
<h3 id="33-批量计算df2text">3.3 批量计算df2[&lsquo;text&rsquo;]</h3>
<p>对df2[&lsquo;text&rsquo;]批量使用前瞻性计算函数<strong>compute_fls</strong>，计算结果保存到字段<strong>Forward</strong></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">df2[&#39;Forward&#39;] = df2[&#39;text&#39;].apply(compute_fls)

df2.head()
</code></pre></div><p><img loading="lazy" src="img/df3.png" alt=""  />
</p>
<br>
<p>下图是论文中的Forward描述性统计，</p>
<p><img loading="lazy" src="img/stats.png" alt=""  />
</p>
<p>我们试着看看分析结果 <strong>df2[&lsquo;Forward&rsquo;]</strong> 的</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Forward最小值: &#39;</span><span class="p">,</span> <span class="n">df2</span><span class="p">[</span><span class="s1">&#39;Forward&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Forward中位数: &#39;</span><span class="p">,</span> <span class="n">df2</span><span class="p">[</span><span class="s1">&#39;Forward&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">median</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Forward均值: &#39;</span><span class="p">,</span> <span class="n">df2</span><span class="p">[</span><span class="s1">&#39;Forward&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Forward最大值: &#39;</span><span class="p">,</span> <span class="n">df2</span><span class="p">[</span><span class="s1">&#39;Forward&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Forward标准层: &#39;</span><span class="p">,</span> <span class="n">df2</span><span class="p">[</span><span class="s1">&#39;Forward&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">std</span><span class="p">())</span>
</code></pre></div><p>可以发现描述性统计信息与论文的存在较大差异，可能的原因包括但不限于</p>
<pre><code>  1. 数据集存在差异。**论文中选取2007-2020年中小板和创业板上市公司作为研究对象。**而本实验使用的A股2005年-2023年所有的上市公司作为实验对象。
  2. 可能筛选记录，文本太短的会议剔除。
  3. 使用的停用词表不同
  4. jieba导入自定义词典
</code></pre>
<p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>数据集 | 84w条业绩说明会问答数据(2005-2023)</title>
      <link>https://textdata.cn/blog/2023-09-08-china-a-share-market-listed-company-earnings-communication-conference/</link>
      <pubDate>Fri, 08 Sep 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-09-08-china-a-share-market-listed-company-earnings-communication-conference/</guid>
      <description>业绩说明会， 是我国上市公司和中小投资 者沟通交流的重要载体。 在年报披露后， 能够 帮助投资者快速、准确地抓取信息披露重点， 全面了解企业发展状况， 增进对企业价值及经 营理念的认同。上市公司的业绩说明会是金融领域中的重要事件，它为投资者、分析师和其他利益相关者提供了一个与公司管理层直接交流的平台。这种数据集的学术价值多方面体现。</description>
      <content:encoded><![CDATA[<p>业绩说明会， 是我国上市公司和中小投资 者沟通交流的重要载体。 在年报披露后， 能够 帮助投资者快速、准确地抓取信息披露重点， 全面了解企业发展状况， 增进对企业价值及经 营理念的认同。上市公司的业绩说明会是金融领域中的重要事件，它为投资者、分析师和其他利益相关者提供了一个与公司管理层直接交流的平台。这种数据集的学术价值多方面体现。</p>
<ul>
<li>公司沟通策略的研究：业绩说明会的数据可以帮助研究者深入了解公司如何与公众沟通其财务状况、业务策略和未来展望。这对于传播学、公关和企业战略研究领域都是宝贵的。</li>
<li>情感分析与市场反应：通过对业绩说明会中的语言和情感进行分析，研究者可以探索市场对公司信息披露的反应。这对于金融经济学和计量经济学的研究尤为重要。</li>
<li>公司治理与透明度：业绩说明会的频率、内容和与投资者的互动可以为研究者提供关于公司治理质量和透明度的线索。</li>
<li>预测模型的建立：这种数据集可以用于建立预测模型，预测公司的未来业绩、股价走势或其他相关指标。</li>
<li>行为金融学的研究：业绩说明会中的问题和答案可以为研究者提供关于投资者和分析师行为和心理的深入了解，从而深化我们对市场非理性行为的理解。</li>
<li>宏观经济指标的研究：通过对多家公司的业绩说明会数据进行汇总和分析，研究者可以获得宏观经济趋势和行业动态的宝贵见解。</li>
</ul>
<p>总之，上市公司业绩说明会数据集为学术界提供了一个独特的、多维度的研究视角，有助于深化我们对金融市场、公司策略和投资者行为的理解。</p>
<p><br><br></p>
<h2 id="数据集介绍">数据集介绍</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">上市公司业绩说明会问答数据

【年度】
 2005-2023年

【字段】
 - 股票代码
 - 会计年度
 - 问题序号
 - 提问内容
 - 提问时间
 - 回答人
 - 回答时间
 - 回答内容
 
 【数据量】
  841876
</code></pre></div><p><a href="code.ipynb">点击获取代码</a></p>
<p><a href="https://mp.weixin.qq.com/s/w7BWPwyI_UxQ6zprC96-qw">点击获取数据</a></p>
<p><br><br></p>
<h2 id="导入数据">导入数据</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_excel</span><span class="p">(</span><span class="s1">&#39;业绩说明会问答05-23.xlsx&#39;</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/df.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="s1">&#39;数据集覆盖的年度: </span><span class="si">{start}</span><span class="s1">~</span><span class="si">{end}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">start</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;会计年度&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> 
                                 <span class="n">end</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;会计年度&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>
</code></pre></div><pre><code>'数据集覆盖的年度: 2005~2023'
</code></pre>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#数据量</span>
<span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
</code></pre></div><pre><code>841876
</code></pre>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#字段包括</span>
<span class="n">df</span><span class="o">.</span><span class="n">columns</span>
</code></pre></div><pre><code>Index(['股票代码', '会计年度', '问题序号', '提问内容', '提问时间', '回答人', '回答时间', '回答内容'], dtype='object')
</code></pre>
<br>
<p>设置matplotlib</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">matplotlib</span>
<span class="kn">import</span> <span class="nn">matplotlib_inline</span>
<span class="n">matplotlib_inline</span><span class="o">.</span><span class="n">backend_inline</span><span class="o">.</span><span class="n">set_matplotlib_formats</span><span class="p">(</span><span class="s1">&#39;png&#39;</span><span class="p">,</span> <span class="s1">&#39;svg&#39;</span><span class="p">)</span>
<span class="c1">#pip3 install scienceplots</span>
<span class="kn">import</span> <span class="nn">scienceplots</span> 
<span class="kn">import</span> <span class="nn">platform</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">([</span><span class="s1">&#39;science&#39;</span><span class="p">,</span> <span class="s1">&#39;no-latex&#39;</span><span class="p">,</span> <span class="s1">&#39;cjk-sc-font&#39;</span><span class="p">])</span>
<span class="n">system</span> <span class="o">=</span> <span class="n">platform</span><span class="o">.</span><span class="n">system</span><span class="p">()</span>  <span class="c1"># 获取操作系统类型</span>

<span class="k">if</span> <span class="n">system</span> <span class="o">==</span> <span class="s1">&#39;Windows&#39;</span><span class="p">:</span>
    <span class="n">font</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;family&#39;</span><span class="p">:</span> <span class="s1">&#39;SimHei&#39;</span><span class="p">}</span>
<span class="k">elif</span> <span class="n">system</span> <span class="o">==</span> <span class="s1">&#39;Darwin&#39;</span><span class="p">:</span>
    <span class="n">font</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;family&#39;</span><span class="p">:</span> <span class="s1">&#39;Arial Unicode MS&#39;</span><span class="p">}</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">font</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;family&#39;</span><span class="p">:</span> <span class="s1">&#39;sans-serif&#39;</span><span class="p">}</span>
<span class="n">matplotlib</span><span class="o">.</span><span class="n">rc</span><span class="p">(</span><span class="s1">&#39;font&#39;</span><span class="p">,</span> <span class="o">**</span><span class="n">font</span><span class="p">)</span>  <span class="c1"># 设置全局字体</span>
    
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#年份变化(业绩说明会数量)</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;会计年度&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span><span class="o">.</span><span class="n">sort_index</span><span class="p">()</span>
</code></pre></div><pre><code>会计年度
2005     4042
2006    10051
2007    18906
2008    31782
2009    35802
2010    47141
2011    69439
2012    73231
2013    80456
2014    80690
2015    62764
2016    61820
2017    52543
2018    44279
2019    42009
2020    37026
2021    53898
2022    35917
2023       80
Name: count, dtype: int64
</code></pre>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df</span><span class="p">[</span><span class="s1">&#39;会计年度&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span><span class="o">.</span><span class="n">sort_index</span><span class="p">()</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s1">&#39;bar&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">rotation</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;会计年度&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;业绩说明会数量&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;业绩说明会数量年份变化&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/output_5_0.svg" alt="svg"  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">([</span><span class="s1">&#39;会计年度&#39;</span><span class="p">,</span> <span class="s1">&#39;股票代码&#39;</span><span class="p">])[</span><span class="s1">&#39;问题序号&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">count</span><span class="p">()</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;会计年度&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">rotation</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;会计年度&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;年度问答次数&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;业绩说明会平均问答次数年份变化&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/output_6_0.svg" alt="svg"  />
</p>
<p><br><br></p>
<h2 id="相关文献">相关文献</h2>
<p>许帅,邵帅,何贤杰.业绩说明会前瞻性信息对分析师盈余预测准确性的影响——信口雌黄还是言而有征[J].中国管理科学:1-15.</p>
<blockquote>
<p>摘要:本文以2007—2020年上市公司业绩说明会为背景，研究前瞻性信息披露对分析师预测的影响，发现业绩说明会中的前瞻性信息可以显著提升分析师盈余预测准确性。公司的信息不对称程度越高，前瞻性信息对分析师预测准确性提升越多。分析师专长工作经验越丰富，具备更强的信息捕捉能力，可以更好地吸收与理解业绩说明会中的前瞻性信息，做出更准确的预测。进一步，本文对前瞻性信息影响分析师预测的路径进行了讨论，认为前瞻性信息可能通过吸引分析师和机构投资者调研，增进分析师对上市公司经营状况的了解，进而提升盈余预测准确性。此外，本文发现，前瞻性信息中业绩相关类信息因具有更高的可信度，且与盈余因子直接相关，能够显著提升分析师盈余预测准确性。本研究为管理层披露与分析师的互动研究提供了增量证据，研究结果支持了业绩说明会有效性，对未来监管部门制定相关信息披露政策提供依据和建议。</p>
</blockquote>
<br>
<p>卞世博,管之凡,阎志鹏.答非所问与市场反应:基于业绩说明会的研究[J].管理科学学报,2021,24(04):109-126.</p>
<blockquote>
<p>摘要:对上市公司业绩说明会中投资者与管理层问答互动中管理层答非所问的现象进行了研究.本文以中小板和创业板上市公司召开的业绩说明会作为研究样本,利用文本分析方法对业绩说明会中管理层在回答投资者提问时答非所问的程度进行度量,进而实证分析了管理层的答非所问与市场反应和公司未来业绩表现之间的可能关联.结果发现:在控制其它因素之后,管理层的答非所问与市场反应之间呈现显著的负相关关系,即公司管理层的答非所问程度越高,随后公司股票的市场表现则就会越差,并且对于那些低分析师关注的公司尤为明显;而在公司未来业绩表现方面,管理层答非所问的程度越高,则公司未来的业绩表现则会越差.</p>
</blockquote>
<p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>数据集(付费) | 200w政府采购合同公告明细数据（1996.6-2022.12）</title>
      <link>https://textdata.cn/blog/2023-09-03-government-procurement-contract-data/</link>
      <pubDate>Thu, 31 Aug 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-09-03-government-procurement-contract-data/</guid>
      <description>&lt;h2 id=&#34;一数据集简介&#34;&gt;一、数据集简介&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;- 数据源 中国政府采购网
- 记录数 2247959
- 公告日期 1996-06 ~ 2022-12
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/01-cover.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;h2 id=&#34;二实验代码&#34;&gt;二、实验代码&lt;/h2&gt;
&lt;h3 id=&#34;21-读取数据&#34;&gt;2.1 读取数据&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pandas&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pd&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read_csv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;采购合同公告数据1996-2022.csv&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;合同公告日期&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;to_datetime&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;合同公告日期&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;head&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/df.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;22-记录数&#34;&gt;2.2 记录数&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;数据集记录数: &amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;数据集记录数:  2247959
&lt;/code&gt;&lt;/pre&gt;
&lt;br&gt;
&lt;h3 id=&#34;23-覆盖日期&#34;&gt;2.3 覆盖日期&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;c1&#34;&gt;#数据集公告日期起止&lt;/span&gt;
&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;合同公告&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;合同公告日期&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;min&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;())&lt;/span&gt;
&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;合同公告&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;合同公告日期&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;max&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;())&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;合同公告 1996-06-05 00:00:00
合同公告 2022-12-31 00:00:00
&lt;/code&gt;&lt;/pre&gt;
&lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;c1&#34;&gt;#政府采购合同数据，主要出现在2014年之后&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;合同公告日期&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;year&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;value_counts&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;合同公告日期
2022    1053198
2021     548979
2020     187800
2018     154920
2019     151068
2017      94191
2016      42195
2015      15543
2014         24
2011         13
2004          7
2008          5
2013          4
2009          3
2012          3
2010          2
2002          2
2000          1
1996          1
Name: count, dtype: int64
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h3 id=&#34;24-甲乙方人数&#34;&gt;2.4 甲(乙)方人数&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;c1&#34;&gt;#甲方乙方数量&lt;/span&gt;
&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;采购人(甲方)数: &amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;采购人(甲方)&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;nunique&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;())&lt;/span&gt;
&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;供应商(乙方)数:&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;供应商(乙方)&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;nunique&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;())&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;采购人(甲方)数:  189783
供应商(乙方)数: 388882
&lt;/code&gt;&lt;/pre&gt;
&lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;数据集字段:&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;columns&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;数据集字段: Index([&#39;合同编号&#39;, &#39;合同名称&#39;, &#39;项目编号&#39;, &#39;项目名称&#39;, &#39;采购人(甲方)&#39;, &#39;采购人地址&#39;, &#39;来源网站&#39;, &#39;供应商(乙方)&#39;,
       &#39;供应商地址&#39;, &#39;主要标的名称&#39;, &#39;规格型号或服务要求&#39;, &#39;主要标的数量&#39;, &#39;主要标的单价&#39;, &#39;合同金额(万元)&#39;,
       &#39;履约期限、地点等简要信息&#39;, &#39;采购方式&#39;, &#39;合同签订日期&#39;, &#39;合同公告日期&#39;, &#39;其他补充事宜&#39;, &#39;所属地域&#39;, &#39;所属行业&#39;,
       &#39;代理机构&#39;],
      dtype=&#39;object&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;三相关研究&#34;&gt;三、相关研究&lt;/h2&gt;
&lt;p&gt;相关研究近期文献&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;[1]周亚虹,蒲余路,陈诗一等.政府扶持与新型产业发展——以新能源为例[J].经济研究,2015,50(06):147-161.
[2]武威,刘国平.政府采购与经济发展：转型效应与协同效应——基于产业结构升级视角[J].财政研究,2021(08):77-90.
[3]孙薇,叶初升.政府采购何以牵动企业创新——兼论需求侧政策“拉力”与供给侧政策“推力”的协同[J].中国工业经济,2023(01):95-113.
[4]姜爱华,费堃桀,张鑫娜.政府采购、营商环境与企业创新——基于A股上市公司的经验证据[J].中央财经大学学报,2022(09):3-15.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;四获取数据&#34;&gt;四、获取数据&lt;/h2&gt;
&lt;p&gt;数据集 50 元，购买请加微信 372335839， 备注 【姓名-学校-专业】&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;广而告之&#34;&gt;广而告之&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/call_for_paper/&#34;&gt;长期征稿&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/we_need_you/&#34;&gt;长期招募小伙伴&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/management_python_course/&#34;&gt;付费视频课 | Python实证指标构建与文本分析&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
      <content:encoded><![CDATA[<h2 id="一数据集简介">一、数据集简介</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">- 数据源 中国政府采购网
- 记录数 2247959
- 公告日期 1996-06 ~ 2022-12
</code></pre></div><p><img loading="lazy" src="img/01-cover.png" alt=""  />
</p>
<br>
<h2 id="二实验代码">二、实验代码</h2>
<h3 id="21-读取数据">2.1 读取数据</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;采购合同公告数据1996-2022.csv&#39;</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;合同公告日期&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;合同公告日期&#39;</span><span class="p">])</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/df.png" alt=""  />
</p>
<br>
<h3 id="22-记录数">2.2 记录数</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;数据集记录数: &#39;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">))</span>
</code></pre></div><pre><code>数据集记录数:  2247959
</code></pre>
<br>
<h3 id="23-覆盖日期">2.3 覆盖日期</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#数据集公告日期起止</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;合同公告&#39;</span><span class="p">,</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;合同公告日期&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;合同公告&#39;</span><span class="p">,</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;合同公告日期&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>
</code></pre></div><pre><code>合同公告 1996-06-05 00:00:00
合同公告 2022-12-31 00:00:00
</code></pre>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#政府采购合同数据，主要出现在2014年之后</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;合同公告日期&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">dt</span><span class="o">.</span><span class="n">year</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">合同公告日期
2022    1053198
2021     548979
2020     187800
2018     154920
2019     151068
2017      94191
2016      42195
2015      15543
2014         24
2011         13
2004          7
2008          5
2013          4
2009          3
2012          3
2010          2
2002          2
2000          1
1996          1
Name: count, dtype: int64
</code></pre></div><br>
<h3 id="24-甲乙方人数">2.4 甲(乙)方人数</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#甲方乙方数量</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;采购人(甲方)数: &#39;</span><span class="p">,</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;采购人(甲方)&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">nunique</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;供应商(乙方)数:&#39;</span><span class="p">,</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;供应商(乙方)&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">nunique</span><span class="p">())</span>
</code></pre></div><pre><code>采购人(甲方)数:  189783
供应商(乙方)数: 388882
</code></pre>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;数据集字段:&#39;</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
</code></pre></div><pre><code>数据集字段: Index(['合同编号', '合同名称', '项目编号', '项目名称', '采购人(甲方)', '采购人地址', '来源网站', '供应商(乙方)',
       '供应商地址', '主要标的名称', '规格型号或服务要求', '主要标的数量', '主要标的单价', '合同金额(万元)',
       '履约期限、地点等简要信息', '采购方式', '合同签订日期', '合同公告日期', '其他补充事宜', '所属地域', '所属行业',
       '代理机构'],
      dtype='object')
</code></pre>
<p><br><br></p>
<h2 id="三相关研究">三、相关研究</h2>
<p>相关研究近期文献</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">[1]周亚虹,蒲余路,陈诗一等.政府扶持与新型产业发展——以新能源为例[J].经济研究,2015,50(06):147-161.
[2]武威,刘国平.政府采购与经济发展：转型效应与协同效应——基于产业结构升级视角[J].财政研究,2021(08):77-90.
[3]孙薇,叶初升.政府采购何以牵动企业创新——兼论需求侧政策“拉力”与供给侧政策“推力”的协同[J].中国工业经济,2023(01):95-113.
[4]姜爱华,费堃桀,张鑫娜.政府采购、营商环境与企业创新——基于A股上市公司的经验证据[J].中央财经大学学报,2022(09):3-15.
</code></pre></div><p><br><br></p>
<h2 id="四获取数据">四、获取数据</h2>
<p>数据集 50 元，购买请加微信 372335839， 备注 【姓名-学校-专业】</p>
<p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>数据集 | 2006年-2022年企业社会责任报告</title>
      <link>https://textdata.cn/blog/2023-08-11-china-a-market-corporate-social-responsibility-dataste/</link>
      <pubDate>Fri, 11 Aug 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-08-11-china-a-market-corporate-social-responsibility-dataste/</guid>
      <description>企业社会责任（csr)已成为全球学术界研究的热点，</description>
      <content:encoded><![CDATA[<p>近年来，企业社会责任（csr)已成为全球学术界研究的热点，</p>
<p><br><br></p>
<h2 id="一csr相关论文">一、CSR相关论文</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">[1]解学梅,朱琪玮.企业绿色创新实践如何破解“和谐共生”难题？[J].管理世界,2021,37(01):128-149+9.
[2]谢红军,吕雪.负责任的国际投资：ESG与中国OFDI[J].经济研究,2022,57(03):83-99.
[3]Schaefer, Sarah Desirée, Ralf Terlutter, and Sandra Diehl. &#34;Is my company really doing good? Factors influencing employees&#39; evaluation of the authenticity of their company&#39;s corporate social responsibility engagement.&#34; Journal of business research 101 (2019): 128-143.
</code></pre></div><p><br><br></p>
<p>CSR数据多为非结构文本数据，可以做词频统计、情感分析、话题模型等文本分析任务。今天给大家奉上A股CSR数据集， <strong>对文本分析感兴趣的同学， 欢迎报名视频课「Python实证指标构建与文本分析」</strong>。 本文仅展示A股企业社会责任数据集，并作简单分析。</p>
<p><br><br></p>
<h2 id="二csr数据集">二、CSR数据集</h2>
<p>目前这是市面上最全最完整的原始数据，数据已整理到xlsx文件（大小143M）。</p>
<p><strong>A股企业社会责任报告数据集</strong>基本信息</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">- 记录数9266
- 沪深1655家公司
- 时间跨度2006-2022年
</code></pre></div><p><br><br></p>
<h2 id="三导入数据">三、导入数据</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_excel</span><span class="p">(</span><span class="s1">&#39;CSR2006-2033.xlsx&#39;</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/df1.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#ESG报告数</span>
<span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<pre><code>9266
</code></pre>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#发布ESG报告的公司数</span>
<span class="n">df</span><span class="o">.</span><span class="n">code</span><span class="o">.</span><span class="n">nunique</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<pre><code>1655
</code></pre>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#有ESG报告的年份</span>

<span class="c1">#sorted(df[&#39;year&#39;].unique())</span>
<span class="nb">sorted</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">year</span><span class="o">.</span><span class="n">unique</span><span class="p">())</span>
</code></pre></div><p>Run</p>
<pre><code>[2006,
 2007,
 2008,
 2009,
 2010,
 2011,
 2012,
 2013,
 2014,
 2015,
 2016,
 2017,
 2018,
 2019,
 2020,
 2021,
 2022]
</code></pre>
<p><br><br></p>
<h2 id="四esg年度发布量">四、ESG年度发布量</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;year&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="nb">len</span><span class="p">)</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s1">&#39;bar&#39;</span><span class="p">)</span>  
</code></pre></div><p><img loading="lazy" src="img/output_6_1.png" alt=""  />
</p>
<p>​</p>
<p><br><br></p>
<h2 id="五沪深发布量">五、沪深发布量</h2>
<p>大邓记得深圳交易所大多数股票以0开头，上海交易所股票则大多以6开头。 可以简单通过第一位数字来判断两个交易所发布量</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#切片，选取股票代码字符串第二个位置的数字</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;code&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">slice</span><span class="p">(</span><span class="n">start</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">stop</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<pre><code>code
6    4562
0    3946
3     741
2       9
9       8
Name: count, dtype: int64
</code></pre>
<br>
<p>运行结果，除了0和6还出现了2、3/9。综上，股票代码</p>
<ul>
<li>6 最常见的上交所的股票代码</li>
<li>0 最常见的深交所的股票代码</li>
<li>3 创业板</li>
<li>2和9 我不太熟悉</li>
</ul>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;code&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;A6&#39;</span><span class="p">)]</span>
</code></pre></div><p><img loading="lazy" src="img/df2.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;code&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;A0&#39;</span><span class="p">)]</span>
</code></pre></div><p><img loading="lazy" src="img/df3.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#股票代码第一位出现2或者9的股票</span>
<span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;code&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">match</span><span class="p">(</span><span class="s1">&#39;A2|A9&#39;</span><span class="p">)]</span>
</code></pre></div><p><img loading="lazy" src="img/df4.png" alt=""  />
</p>
<p>​</p>
<p><br><br></p>
<h2 id="数据集获取">数据集获取</h2>
<p>数据整理不易，需要的话， <a href="https://mp.weixin.qq.com/s/NsLM2Rfo-a6bb1FGn0nrIA">点击链接进入购买页面</a>， 有疑问，加微信372335839， 备注「姓名-学校-专业」</p>
<p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>可视化 | 微博用户群体情绪随时间变化趋势</title>
      <link>https://textdata.cn/blog/2023-05-18-weibo-sentiment-score-line-plot/</link>
      <pubDate>Thu, 18 May 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-05-18-weibo-sentiment-score-line-plot/</guid>
      <description>&lt;p&gt;DataFrame数据如何绘制按时间趋势的折线图，今天以weibo数据集为例，绘制微博文本内容折线图&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;微博文本内容「平均长度随时间变化」&lt;/li&gt;
&lt;li&gt;微博文本内容「平均情感分值随时间变化」&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/output_8_0.svg&#34; alt=&#34;svg&#34;  /&gt;

&lt;img loading=&#34;lazy&#34; src=&#34;img/output_12_0.svg&#34; alt=&#34;svg&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;一准备工作&#34;&gt;一、准备工作&lt;/h2&gt;
&lt;h3 id=&#34;11-下载数据集&#34;&gt;1.1 下载数据集&lt;/h3&gt;
&lt;p&gt;数据集下载链接 &lt;a href=&#34;https://www.kaggle.com/datasets/dylanli/weibo-content-during-covid19-period&#34;&gt;https://www.kaggle.com/datasets/dylanli/weibo-content-during-covid19-period&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/download.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;p&gt;含8个json文件&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;user1.json、user2.json、user3.json、user4.json&lt;/li&gt;
&lt;li&gt;weibo1.json、weibo2.json、weibo3.json、weibo4.json&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这里仅尝试读取weibo1.json  &lt;br&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;os&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;os&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;listdir&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;[&#39;weibo2.json&#39;,
 &#39;.DS_Store&#39;,
 &#39;weibo3.json&#39;,
 &#39;Untitled.ipynb&#39;,
 &#39;weibo4.json&#39;,
 &#39;user1.json&#39;,
 &#39;user2.json&#39;,
 &#39;说明.md&#39;,
 &#39;user3.json&#39;,
 &#39;.ipynb_checkpoints&#39;,
 &#39;user4.json&#39;,
 &#39;weibo1.json&#39;]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h3 id=&#34;12-导入数据&#34;&gt;1.2 导入数据&lt;/h3&gt;
&lt;p&gt;导入 7138微博用户数据后，查看&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;数据量&lt;/li&gt;
&lt;li&gt;字段的数据类型&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pandas&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pd&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;weibo_df&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read_json&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;weibo1.json&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;weibo_df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;head&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/df1.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;c1&#34;&gt;#记录数&lt;/span&gt;
&lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;weibo_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;560840
&lt;/code&gt;&lt;/pre&gt;
&lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;c1&#34;&gt;#字段的数据类型&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;weibo_df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dtypes&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;_id                        object
user_id                    object
screen_name                object
id                         object
bid                        object
text                       object
pics                       object
video_url                  object
location                   object
created_at         datetime64[ns]
source                     object
attitudes_count             int64
comments_count              int64
reposts_count               int64
topics                     object
at_users                   object
retweet                    object
dtype: object
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;二数据分析&#34;&gt;二、数据分析&lt;/h2&gt;
&lt;p&gt;绘制微博内容&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;平均长度随时间变化&lt;/li&gt;
&lt;li&gt;平均情感分值随时间变化&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;21-平均长度随时间变化&#34;&gt;2.1 平均长度随时间变化&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;plt&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;matplotlib&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;matplotlib_inline&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;matplotlib_inline&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;backend_inline&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;set_matplotlib_formats&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;png&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;svg&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;scienceplots&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;platform&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;plt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;style&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;use&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;([&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;science&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;no-latex&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;cjk-sc-font&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;system&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;platform&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;system&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;# 获取操作系统类型&lt;/span&gt;

&lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;system&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;Windows&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;font&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;family&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;SimHei&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;span class=&#34;k&#34;&gt;elif&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;system&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;Darwin&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;font&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;family&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;Arial Unicode MS&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;span class=&#34;k&#34;&gt;else&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;font&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;family&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;sans-serif&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;matplotlib&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;rc&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;font&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;font&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;# 设置全局字体&lt;/span&gt;



&lt;span class=&#34;c1&#34;&gt;# 统计人均字符长度变化&lt;/span&gt;
&lt;span class=&#34;c1&#34;&gt;#df[&amp;#39;text_length&amp;#39;] = weibo_df[&amp;#39;text&amp;#39;].apply(lambda x: len(x))&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;weibo_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;text_length&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;weibo_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;text&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;str&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;df_avg_length&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;weibo_df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;groupby&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;created_at&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;text_length&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mean&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;reset_index&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;# 绘制人均字符长度变化图&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;plt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;figure&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;figsize&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;plt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;plot&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df_avg_length&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;created_at&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;df_avg_length&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;text_length&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;plt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;xlabel&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;日期&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;plt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ylabel&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;微博内容平均长度&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;plt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;title&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;微博内容平均长度随时间变化&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;plt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;xticks&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;rotation&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;45&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;plt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;show&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/output_8_0.svg&#34; alt=&#34;svg&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;22-平均情感分值随时间变化&#34;&gt;2.2 平均情感分值随时间变化&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;设计情感计算函数senti_score&lt;/li&gt;
&lt;li&gt;测试一条文本的情感计算实验&lt;/li&gt;
&lt;li&gt;推广到所有weibo内容的情感计算&lt;/li&gt;
&lt;li&gt;参考「平均长度随时间变化」，会「平均情感分值随时间变化」&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;cntext&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;ct&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;jieba&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;#1.8.4版本cntext&lt;/span&gt;
&lt;span class=&#34;c1&#34;&gt;#使用知网Hownet情感词典&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;pos_words&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ct&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;load_pkl_dict&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;HOWNET.pkl&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;HOWNET&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;][&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;pos&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;neg_words&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ct&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;load_pkl_dict&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;HOWNET.pkl&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;HOWNET&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;][&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;neg&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;


&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;senti_score&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;pos&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;neg&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;words&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;jieba&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;lcut&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
    &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;word&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;words&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
        &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;word&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pos_words&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
            &lt;span class=&#34;n&#34;&gt;pos&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pos&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;
        &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;word&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;neg_words&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
            &lt;span class=&#34;n&#34;&gt;neg&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;neg&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;
    &lt;span class=&#34;c1&#34;&gt;#(pos-neg)/(pos+neg)即可，为防止分母为0，特加1&lt;/span&gt;
    &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;pos&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;neg&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;pos&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;neg&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
    
    
&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;senti_score&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;我很开心！&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;senti_score&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;我很难过！&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;0.5
-0.5
&lt;/code&gt;&lt;/pre&gt;
&lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;weibo1_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;560840
&lt;/code&gt;&lt;/pre&gt;
&lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;plt&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;matplotlib&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;matplotlib_inline&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;matplotlib_inline&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;backend_inline&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;set_matplotlib_formats&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;png&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;svg&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;scienceplots&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;platform&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;numpy&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;np&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;#一共有560840条推特，这个部分代码运算量比较大，你所看到的情感变化图是按照1%随机抽样绘制的结果。&lt;/span&gt;
&lt;span class=&#34;c1&#34;&gt;#按照1%随机抽样绘制的结果, &lt;/span&gt;
&lt;span class=&#34;c1&#34;&gt;#np.random.seed(666)&lt;/span&gt;
&lt;span class=&#34;c1&#34;&gt;#weibo_df = weibo_df.sample(frac=0.01)&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;plt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;style&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;use&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;([&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;science&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;no-latex&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;cjk-sc-font&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;system&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;platform&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;system&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;# 获取操作系统类型&lt;/span&gt;

&lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;system&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;Windows&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;font&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;family&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;SimHei&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;span class=&#34;k&#34;&gt;elif&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;system&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;Darwin&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;font&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;family&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;Arial Unicode MS&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;span class=&#34;k&#34;&gt;else&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;font&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;family&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;sans-serif&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;matplotlib&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;rc&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;font&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;font&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;# 设置全局字体&lt;/span&gt;


&lt;span class=&#34;c1&#34;&gt;# 统计平均情感分值&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;weibo_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;senti&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;weibo_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;text&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;apply&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;senti_score&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;df_senti_avg_length&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;weibo_df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;groupby&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;created_at&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;senti&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mean&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;reset_index&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;# 绘制平均情感分值随时间变化&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;plt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;figure&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;figsize&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;plt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;plot&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df_senti_avg_length&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;created_at&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;df_senti_avg_length&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;senti&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;plt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;xlabel&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;日期&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;plt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ylabel&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;微博内容平均情感分值&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;plt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;title&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;微博内容平均情感分值随时间变化&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;plt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;xticks&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;rotation&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;45&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;plt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;show&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/output_12_0.svg&#34; alt=&#34;svg&#34;  /&gt;

​&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;广而告之&#34;&gt;广而告之&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/call_for_paper/&#34;&gt;长期征稿&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/we_need_you/&#34;&gt;长期招募小伙伴&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/management_python_course/&#34;&gt;付费视频课 | Python实证指标构建与文本分析&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
      <content:encoded><![CDATA[<p>DataFrame数据如何绘制按时间趋势的折线图，今天以weibo数据集为例，绘制微博文本内容折线图</p>
<ol>
<li>微博文本内容「平均长度随时间变化」</li>
<li>微博文本内容「平均情感分值随时间变化」</li>
</ol>
<p><img loading="lazy" src="img/output_8_0.svg" alt="svg"  />

<img loading="lazy" src="img/output_12_0.svg" alt="svg"  />
</p>
<p><br><br></p>
<h2 id="一准备工作">一、准备工作</h2>
<h3 id="11-下载数据集">1.1 下载数据集</h3>
<p>数据集下载链接 <a href="https://www.kaggle.com/datasets/dylanli/weibo-content-during-covid19-period">https://www.kaggle.com/datasets/dylanli/weibo-content-during-covid19-period</a></p>
<p><img loading="lazy" src="img/download.png" alt=""  />
</p>
<br>
<p>含8个json文件</p>
<ul>
<li>user1.json、user2.json、user3.json、user4.json</li>
<li>weibo1.json、weibo2.json、weibo3.json、weibo4.json</li>
</ul>
<p>这里仅尝试读取weibo1.json  <br></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">os</span>

<span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">()</span>
</code></pre></div><pre><code>['weibo2.json',
 '.DS_Store',
 'weibo3.json',
 'Untitled.ipynb',
 'weibo4.json',
 'user1.json',
 'user2.json',
 '说明.md',
 'user3.json',
 '.ipynb_checkpoints',
 'user4.json',
 'weibo1.json']
</code></pre>
<p><br><br></p>
<h3 id="12-导入数据">1.2 导入数据</h3>
<p>导入 7138微博用户数据后，查看</p>
<ol>
<li>数据量</li>
<li>字段的数据类型</li>
</ol>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">weibo_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_json</span><span class="p">(</span><span class="s1">&#39;weibo1.json&#39;</span><span class="p">)</span>
<span class="n">weibo_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/df1.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#记录数</span>
<span class="nb">len</span><span class="p">(</span><span class="n">weibo_df</span><span class="p">)</span>
</code></pre></div><pre><code>560840
</code></pre>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#字段的数据类型</span>
<span class="n">weibo_df</span><span class="o">.</span><span class="n">dtypes</span>
</code></pre></div><pre><code>_id                        object
user_id                    object
screen_name                object
id                         object
bid                        object
text                       object
pics                       object
video_url                  object
location                   object
created_at         datetime64[ns]
source                     object
attitudes_count             int64
comments_count              int64
reposts_count               int64
topics                     object
at_users                   object
retweet                    object
dtype: object
</code></pre>
<p><br><br></p>
<h2 id="二数据分析">二、数据分析</h2>
<p>绘制微博内容</p>
<ol>
<li>平均长度随时间变化</li>
<li>平均情感分值随时间变化</li>
</ol>
<h3 id="21-平均长度随时间变化">2.1 平均长度随时间变化</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">matplotlib</span>
<span class="kn">import</span> <span class="nn">matplotlib_inline</span>
<span class="n">matplotlib_inline</span><span class="o">.</span><span class="n">backend_inline</span><span class="o">.</span><span class="n">set_matplotlib_formats</span><span class="p">(</span><span class="s1">&#39;png&#39;</span><span class="p">,</span> <span class="s1">&#39;svg&#39;</span><span class="p">)</span>
<span class="kn">import</span> <span class="nn">scienceplots</span>
<span class="kn">import</span> <span class="nn">platform</span>

<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">([</span><span class="s1">&#39;science&#39;</span><span class="p">,</span> <span class="s1">&#39;no-latex&#39;</span><span class="p">,</span> <span class="s1">&#39;cjk-sc-font&#39;</span><span class="p">])</span>
<span class="n">system</span> <span class="o">=</span> <span class="n">platform</span><span class="o">.</span><span class="n">system</span><span class="p">()</span>  <span class="c1"># 获取操作系统类型</span>

<span class="k">if</span> <span class="n">system</span> <span class="o">==</span> <span class="s1">&#39;Windows&#39;</span><span class="p">:</span>
    <span class="n">font</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;family&#39;</span><span class="p">:</span> <span class="s1">&#39;SimHei&#39;</span><span class="p">}</span>
<span class="k">elif</span> <span class="n">system</span> <span class="o">==</span> <span class="s1">&#39;Darwin&#39;</span><span class="p">:</span>
    <span class="n">font</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;family&#39;</span><span class="p">:</span> <span class="s1">&#39;Arial Unicode MS&#39;</span><span class="p">}</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">font</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;family&#39;</span><span class="p">:</span> <span class="s1">&#39;sans-serif&#39;</span><span class="p">}</span>
<span class="n">matplotlib</span><span class="o">.</span><span class="n">rc</span><span class="p">(</span><span class="s1">&#39;font&#39;</span><span class="p">,</span> <span class="o">**</span><span class="n">font</span><span class="p">)</span>  <span class="c1"># 设置全局字体</span>



<span class="c1"># 统计人均字符长度变化</span>
<span class="c1">#df[&#39;text_length&#39;] = weibo_df[&#39;text&#39;].apply(lambda x: len(x))</span>
<span class="n">weibo_df</span><span class="p">[</span><span class="s1">&#39;text_length&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">weibo_df</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">len</span><span class="p">()</span>
<span class="n">df_avg_length</span> <span class="o">=</span> <span class="n">weibo_df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;created_at&#39;</span><span class="p">)[</span><span class="s1">&#39;text_length&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">reset_index</span><span class="p">()</span>

<span class="c1"># 绘制人均字符长度变化图</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">df_avg_length</span><span class="p">[</span><span class="s1">&#39;created_at&#39;</span><span class="p">],</span> <span class="n">df_avg_length</span><span class="p">[</span><span class="s1">&#39;text_length&#39;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;日期&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;微博内容平均长度&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;微博内容平均长度随时间变化&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">rotation</span><span class="o">=</span><span class="mi">45</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/output_8_0.svg" alt="svg"  />
</p>
<br>
<h3 id="22-平均情感分值随时间变化">2.2 平均情感分值随时间变化</h3>
<ol>
<li>设计情感计算函数senti_score</li>
<li>测试一条文本的情感计算实验</li>
<li>推广到所有weibo内容的情感计算</li>
<li>参考「平均长度随时间变化」，会「平均情感分值随时间变化」</li>
</ol>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>
<span class="kn">import</span> <span class="nn">jieba</span>

<span class="c1">#1.8.4版本cntext</span>
<span class="c1">#使用知网Hownet情感词典</span>
<span class="n">pos_words</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">load_pkl_dict</span><span class="p">(</span><span class="s1">&#39;HOWNET.pkl&#39;</span><span class="p">)[</span><span class="s1">&#39;HOWNET&#39;</span><span class="p">][</span><span class="s1">&#39;pos&#39;</span><span class="p">]</span>
<span class="n">neg_words</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">load_pkl_dict</span><span class="p">(</span><span class="s1">&#39;HOWNET.pkl&#39;</span><span class="p">)[</span><span class="s1">&#39;HOWNET&#39;</span><span class="p">][</span><span class="s1">&#39;neg&#39;</span><span class="p">]</span>


<span class="k">def</span> <span class="nf">senti_score</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="n">pos</span><span class="p">,</span><span class="n">neg</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span><span class="mi">0</span>
    <span class="n">words</span> <span class="o">=</span> <span class="n">jieba</span><span class="o">.</span><span class="n">lcut</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">words</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">pos_words</span><span class="p">:</span>
            <span class="n">pos</span> <span class="o">=</span> <span class="n">pos</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">neg_words</span><span class="p">:</span>
            <span class="n">neg</span> <span class="o">=</span> <span class="n">neg</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="c1">#(pos-neg)/(pos+neg)即可，为防止分母为0，特加1</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">pos</span><span class="o">-</span><span class="n">neg</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">pos</span><span class="o">+</span><span class="n">neg</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    
    
<span class="nb">print</span><span class="p">(</span><span class="n">senti_score</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="s1">&#39;我很开心！&#39;</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">senti_score</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="s1">&#39;我很难过！&#39;</span><span class="p">))</span>
</code></pre></div><pre><code>0.5
-0.5
</code></pre>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="nb">len</span><span class="p">(</span><span class="n">weibo1_df</span><span class="p">)</span>
</code></pre></div><pre><code>560840
</code></pre>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">matplotlib</span>
<span class="kn">import</span> <span class="nn">matplotlib_inline</span>
<span class="n">matplotlib_inline</span><span class="o">.</span><span class="n">backend_inline</span><span class="o">.</span><span class="n">set_matplotlib_formats</span><span class="p">(</span><span class="s1">&#39;png&#39;</span><span class="p">,</span> <span class="s1">&#39;svg&#39;</span><span class="p">)</span>
<span class="kn">import</span> <span class="nn">scienceplots</span>
<span class="kn">import</span> <span class="nn">platform</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="c1">#一共有560840条推特，这个部分代码运算量比较大，你所看到的情感变化图是按照1%随机抽样绘制的结果。</span>
<span class="c1">#按照1%随机抽样绘制的结果, </span>
<span class="c1">#np.random.seed(666)</span>
<span class="c1">#weibo_df = weibo_df.sample(frac=0.01)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">([</span><span class="s1">&#39;science&#39;</span><span class="p">,</span> <span class="s1">&#39;no-latex&#39;</span><span class="p">,</span> <span class="s1">&#39;cjk-sc-font&#39;</span><span class="p">])</span>
<span class="n">system</span> <span class="o">=</span> <span class="n">platform</span><span class="o">.</span><span class="n">system</span><span class="p">()</span>  <span class="c1"># 获取操作系统类型</span>

<span class="k">if</span> <span class="n">system</span> <span class="o">==</span> <span class="s1">&#39;Windows&#39;</span><span class="p">:</span>
    <span class="n">font</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;family&#39;</span><span class="p">:</span> <span class="s1">&#39;SimHei&#39;</span><span class="p">}</span>
<span class="k">elif</span> <span class="n">system</span> <span class="o">==</span> <span class="s1">&#39;Darwin&#39;</span><span class="p">:</span>
    <span class="n">font</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;family&#39;</span><span class="p">:</span> <span class="s1">&#39;Arial Unicode MS&#39;</span><span class="p">}</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">font</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;family&#39;</span><span class="p">:</span> <span class="s1">&#39;sans-serif&#39;</span><span class="p">}</span>
<span class="n">matplotlib</span><span class="o">.</span><span class="n">rc</span><span class="p">(</span><span class="s1">&#39;font&#39;</span><span class="p">,</span> <span class="o">**</span><span class="n">font</span><span class="p">)</span>  <span class="c1"># 设置全局字体</span>


<span class="c1"># 统计平均情感分值</span>
<span class="n">weibo_df</span><span class="p">[</span><span class="s1">&#39;senti&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">weibo_df</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">senti_score</span><span class="p">)</span>
<span class="n">df_senti_avg_length</span> <span class="o">=</span> <span class="n">weibo_df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;created_at&#39;</span><span class="p">)[</span><span class="s1">&#39;senti&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">reset_index</span><span class="p">()</span>

<span class="c1"># 绘制平均情感分值随时间变化</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">df_senti_avg_length</span><span class="p">[</span><span class="s1">&#39;created_at&#39;</span><span class="p">],</span> <span class="n">df_senti_avg_length</span><span class="p">[</span><span class="s1">&#39;senti&#39;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;日期&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;微博内容平均情感分值&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;微博内容平均情感分值随时间变化&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">rotation</span><span class="o">=</span><span class="mi">45</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/output_12_0.svg" alt="svg"  />

​</p>
<p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>实验数据 | 194城市楼市政策梳理(2010-2022)</title>
      <link>https://textdata.cn/blog/2023-05-17-china-200-city-real-estate-policy/</link>
      <pubDate>Wed, 17 May 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-05-17-china-200-city-real-estate-policy/</guid>
      <description>&lt;br&gt;
&lt;h2 id=&#34;楼市数据集&#34;&gt;楼市数据集&lt;/h2&gt;
&lt;p&gt;有热心粉丝分享了她整理的楼市政策文本，含三个文件&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;- 194城市楼市政策梳理2010-2022.xlsx
- 2023年楼市政策(截止2.24).xlsx
- 2022年1-10月楼市政策梳理.xlsx
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/2011-2022.png&#34; alt=&#34;&#34;  /&gt;

&lt;img loading=&#34;lazy&#34; src=&#34;img/2023%e5%85%a8%e5%9b%bd%e6%94%bf%e7%ad%96.png&#34; alt=&#34;&#34;  /&gt;

&lt;img loading=&#34;lazy&#34; src=&#34;img/2023%e5%9c%b0%e6%96%b9%e6%94%bf%e7%ad%96.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;br&gt;
&lt;h2 id=&#34;用途&#34;&gt;用途&lt;/h2&gt;
&lt;p&gt;该实验数据集，可用于练习&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;词频统计&lt;/li&gt;
&lt;li&gt;词云图&lt;/li&gt;
&lt;li&gt;相似度计算等。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;导入数据&#34;&gt;导入数据&lt;/h2&gt;
&lt;p&gt;因为每个xlsx文件中含有多个sheet， 可以根据sheet名读取不同的sheet表的数据。&lt;/p&gt;
&lt;p&gt;以 &lt;code&gt;194城市楼市政策梳理2010-2022.xlsx&lt;/code&gt; 为例， 导入表名为&lt;code&gt;宝鸡、保定、北海、北京、常州&lt;/code&gt;的数据。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/2011-2022.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pandas&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pd&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read_excel&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;194城市房产政策梳理2010-2022.xlsx&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sheet_name&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;宝鸡、保定、北海、北京、常州&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;head&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
&lt;pre&gt;&lt;code&gt;.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;/style&gt;&lt;/p&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;Unnamed: 0&lt;/th&gt;
      &lt;th&gt;城市名称&lt;/th&gt;
      &lt;th&gt;时间&lt;/th&gt;
      &lt;th&gt;标题&lt;/th&gt;
      &lt;th&gt;政策内容&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;宝鸡&lt;/td&gt;
      &lt;td&gt;2020.11.30&lt;/td&gt;
      &lt;td&gt;限贷政策&lt;/td&gt;
      &lt;td&gt;贷款年限30年，首套≤144㎡，贷款比例＞75%；首套＞144㎡，贷款比例70%；二套≤14...&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;宝鸡&lt;/td&gt;
      &lt;td&gt;2022.5.18&lt;/td&gt;
      &lt;td&gt;关于印发推进陕西自由贸易试验区贸易投资便利化改革创新若干措施的通知（土地政策）&lt;/td&gt;
      &lt;td&gt;优先保障自贸试验区合理用地需求，按照土地要素跟着项目走的原则，施行对产业链环节等多宗土地整体...&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;保定&lt;/td&gt;
      &lt;td&gt;2015.1.20&lt;/td&gt;
      &lt;td&gt;人才政策&lt;/td&gt;
      &lt;td&gt;户籍制度改革实施意见的提及放开人才落户限制。规定具有初级及以上专业技术职称、高级工（国家职业...&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;保定&lt;/td&gt;
      &lt;td&gt;2016.4.17&lt;/td&gt;
      &lt;td&gt;土地政策&lt;/td&gt;
      &lt;td&gt;供地计划对土地供应总量、用途结构、空间布局、土地供应导向等做了详细规定，其中土地供应导向中强...&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;保定&lt;/td&gt;
      &lt;td&gt;2016.4.20&lt;/td&gt;
      &lt;td&gt;土地政策&lt;/td&gt;
      &lt;td&gt;严格掌控土地供应，中心城区内经营性用地全部纳入政府储备。&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;城市名称&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;unique&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;    array([&amp;#39;宝鸡&amp;#39;, &amp;#39;保定&amp;#39;, &amp;#39;北海&amp;#39;, &amp;#39;北京&amp;#39;, &amp;#39;常州&amp;#39;, &amp;#39;成都&amp;#39;], dtype=object)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;时间&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;to_datetime&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;时间&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;

&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;时间&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;min&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;())&lt;/span&gt;
&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;时间&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;max&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;())&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;    2010-04-30 00:00:00
    2022-08-04 00:00:00
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;数据集获取&#34;&gt;数据集获取&lt;/h2&gt;
&lt;p&gt;链接: &lt;a href=&#34;https://pan.baidu.com/s/13neTAQzuY3wkJzmc1FjwFg&#34;&gt;https://pan.baidu.com/s/13neTAQzuY3wkJzmc1FjwFg&lt;/a&gt; 提取码: w2ra&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;广而告之&#34;&gt;广而告之&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/call_for_paper/&#34;&gt;长期征稿&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/we_need_you/&#34;&gt;长期招募小伙伴&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/management_python_course/&#34;&gt;付费视频课 | Python实证指标构建与文本分析&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
      <content:encoded><![CDATA[<br>
<h2 id="楼市数据集">楼市数据集</h2>
<p>有热心粉丝分享了她整理的楼市政策文本，含三个文件</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">- 194城市楼市政策梳理2010-2022.xlsx
- 2023年楼市政策(截止2.24).xlsx
- 2022年1-10月楼市政策梳理.xlsx
</code></pre></div><p><img loading="lazy" src="img/2011-2022.png" alt=""  />

<img loading="lazy" src="img/2023%e5%85%a8%e5%9b%bd%e6%94%bf%e7%ad%96.png" alt=""  />

<img loading="lazy" src="img/2023%e5%9c%b0%e6%96%b9%e6%94%bf%e7%ad%96.png" alt=""  />
</p>
<br>
<br>
<h2 id="用途">用途</h2>
<p>该实验数据集，可用于练习</p>
<ul>
<li>词频统计</li>
<li>词云图</li>
<li>相似度计算等。</li>
</ul>
<p><br><br></p>
<h2 id="导入数据">导入数据</h2>
<p>因为每个xlsx文件中含有多个sheet， 可以根据sheet名读取不同的sheet表的数据。</p>
<p>以 <code>194城市楼市政策梳理2010-2022.xlsx</code> 为例， 导入表名为<code>宝鸡、保定、北海、北京、常州</code>的数据。</p>
<p><img loading="lazy" src="img/2011-2022.png" alt=""  />
</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_excel</span><span class="p">(</span><span class="s1">&#39;194城市房产政策梳理2010-2022.xlsx&#39;</span><span class="p">,</span> <span class="n">sheet_name</span><span class="o">=</span><span class="s1">&#39;宝鸡、保定、北海、北京、常州&#39;</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Unnamed: 0</th>
      <th>城市名称</th>
      <th>时间</th>
      <th>标题</th>
      <th>政策内容</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>NaN</td>
      <td>宝鸡</td>
      <td>2020.11.30</td>
      <td>限贷政策</td>
      <td>贷款年限30年，首套≤144㎡，贷款比例＞75%；首套＞144㎡，贷款比例70%；二套≤14...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>NaN</td>
      <td>宝鸡</td>
      <td>2022.5.18</td>
      <td>关于印发推进陕西自由贸易试验区贸易投资便利化改革创新若干措施的通知（土地政策）</td>
      <td>优先保障自贸试验区合理用地需求，按照土地要素跟着项目走的原则，施行对产业链环节等多宗土地整体...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>NaN</td>
      <td>保定</td>
      <td>2015.1.20</td>
      <td>人才政策</td>
      <td>户籍制度改革实施意见的提及放开人才落户限制。规定具有初级及以上专业技术职称、高级工（国家职业...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>NaN</td>
      <td>保定</td>
      <td>2016.4.17</td>
      <td>土地政策</td>
      <td>供地计划对土地供应总量、用途结构、空间布局、土地供应导向等做了详细规定，其中土地供应导向中强...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>NaN</td>
      <td>保定</td>
      <td>2016.4.20</td>
      <td>土地政策</td>
      <td>严格掌控土地供应，中心城区内经营性用地全部纳入政府储备。</td>
    </tr>
  </tbody>
</table>
</div>
<p><br><br></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df</span><span class="p">[</span><span class="s1">&#39;城市名称&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">    array([&#39;宝鸡&#39;, &#39;保定&#39;, &#39;北海&#39;, &#39;北京&#39;, &#39;常州&#39;, &#39;成都&#39;], dtype=object)
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df</span><span class="p">[</span><span class="s1">&#39;时间&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;时间&#39;</span><span class="p">])</span>

<span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;时间&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;时间&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">    2010-04-30 00:00:00
    2022-08-04 00:00:00
</code></pre></div><p><br><br></p>
<h2 id="数据集获取">数据集获取</h2>
<p>链接: <a href="https://pan.baidu.com/s/13neTAQzuY3wkJzmc1FjwFg">https://pan.baidu.com/s/13neTAQzuY3wkJzmc1FjwFg</a> 提取码: w2ra</p>
<p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>数据集(付费) | 上市公司高管违规数据(2008-2022)</title>
      <link>https://textdata.cn/blog/2023-05-17-top-manager-violation/</link>
      <pubDate>Wed, 17 May 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-05-17-top-manager-violation/</guid>
      <description>&lt;p&gt;上市公司高管违规数据&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pandas&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pd&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;df3&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read_excel&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;高管违规次数.xlsx&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;  &lt;span class=&#34;n&#34;&gt;converters&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;股票代码&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;str&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;})&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;df3&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;head&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/df1.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;一算法&#34;&gt;一、算法&lt;/h2&gt;
&lt;p&gt;为得到&lt;code&gt;高管违规次数.xlsx&lt;/code&gt;，实现步骤:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;使用pd.read_excel()函数读取&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;高管违规数据集 &lt;code&gt;上市公司高管违规-原始数据.xlsx&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;股票代码列表 &lt;code&gt;行业代码.xlsx&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;然后我们使用pd.merge()函数将两个数据集按照股票代码和年度进行合并，使用全连接（how=&amp;lsquo;outer&amp;rsquo;）&lt;strong&gt;确保即使某些股票代码未出现在高管违规数据集中，也能保留在结果中&lt;/strong&gt;。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;接下来，我们使用groupby()函数按股票代码和年度进行分组，然后使用count()函数统计每个组的违规次数。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;检查结果， 无误后导出xlsx。字段包括股票代码、年度和违规次数。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;二实现过程&#34;&gt;二、实现过程&lt;/h2&gt;
&lt;h3 id=&#34;21-导入数据&#34;&gt;2.1 导入数据&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pandas&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pd&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;df1&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read_excel&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;行业代码.xlsx&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;  &lt;span class=&#34;n&#34;&gt;converters&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;股票代码&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;str&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;})&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;df1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;head&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/df2.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;df2&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read_excel&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;上市公司高管违规-原始数据.xlsx&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;converters&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;股票代码&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;str&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;})&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;df2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;公告日期&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;to_datetime&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;公告日期&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;df2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;会计年度&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;df2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;公告日期&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;year&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;df2&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;head&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/df3.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;22-合并&#34;&gt;2.2 合并&lt;/h3&gt;
&lt;p&gt;然后我们使用pd.merge()函数将两个数据集按照股票代码和年度进行合并，使用全连接（how=&amp;lsquo;outer&amp;rsquo;）确保即使某些股票代码未出现在高管违规数据集中，也能保留在结果中。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;merge&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;df2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;how&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;outer&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;on&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;股票代码&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;会计年度&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;head&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/df4.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;23-分组groupby&#34;&gt;2.3 分组Groupby&lt;/h3&gt;
&lt;p&gt;接下来，&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;使用groupby()函数按 &lt;code&gt;股票代码&lt;/code&gt; 和 &lt;code&gt;会计年度&lt;/code&gt; 进行分组&lt;/li&gt;
&lt;li&gt;然后使用count()函数统计每组次数&lt;/li&gt;
&lt;li&gt;并将计算命名为 &lt;code&gt;违规次数&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;result_df&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;groupby&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;([&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;股票代码&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;会计年度&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;违规行为&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;count&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;reset_index&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;违规次数&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;result_df&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/df5.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;24-检查保存&#34;&gt;2.4 检查&amp;amp;保存&lt;/h3&gt;
&lt;p&gt;检查结果， 无误后导出xlsx。字段包括股票代码、年度和违规次数。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/check.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;df2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;股票代码&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;==&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;871753&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;公告日期&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;year&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;==&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2022&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/df6.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;df2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;股票代码&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;==&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;873527&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;公告日期&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;year&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;==&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2018&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/df7.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;p&gt;这里仅随机检查了两个记录(现实中要多检查几次)， 与result_df中是一致的， 现在保存结果供后续实证分析&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;result_df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;to_excel&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;高管违规次数.xlsx&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;index&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;False&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;三获取数据&#34;&gt;三、获取数据&lt;/h2&gt;
&lt;p&gt;数据集 50 元 ， 加微信 &lt;strong&gt;372335839&lt;/strong&gt;, 备注【姓名-学校-专业-高管数据集】获取本数据集。&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;广而告之&#34;&gt;广而告之&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/call_for_paper/&#34;&gt;长期征稿&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/we_need_you/&#34;&gt;长期招募小伙伴&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/management_python_course/&#34;&gt;付费视频课 | Python实证指标构建与文本分析&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
      <content:encoded><![CDATA[<p>上市公司高管违规数据</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">df3</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_excel</span><span class="p">(</span><span class="s1">&#39;高管违规次数.xlsx&#39;</span><span class="p">,</span>  <span class="n">converters</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;股票代码&#39;</span><span class="p">:</span> <span class="nb">str</span><span class="p">})</span>
<span class="n">df3</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/df1.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="一算法">一、算法</h2>
<p>为得到<code>高管违规次数.xlsx</code>，实现步骤:</p>
<ol>
<li>
<p>使用pd.read_excel()函数读取</p>
<ul>
<li>高管违规数据集 <code>上市公司高管违规-原始数据.xlsx</code></li>
<li>股票代码列表 <code>行业代码.xlsx</code></li>
</ul>
</li>
<li>
<p>然后我们使用pd.merge()函数将两个数据集按照股票代码和年度进行合并，使用全连接（how=&lsquo;outer&rsquo;）<strong>确保即使某些股票代码未出现在高管违规数据集中，也能保留在结果中</strong>。</p>
</li>
<li>
<p>接下来，我们使用groupby()函数按股票代码和年度进行分组，然后使用count()函数统计每个组的违规次数。</p>
</li>
<li>
<p>检查结果， 无误后导出xlsx。字段包括股票代码、年度和违规次数。</p>
</li>
</ol>
<p><br><br></p>
<h2 id="二实现过程">二、实现过程</h2>
<h3 id="21-导入数据">2.1 导入数据</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">df1</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_excel</span><span class="p">(</span><span class="s1">&#39;行业代码.xlsx&#39;</span><span class="p">,</span>  <span class="n">converters</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;股票代码&#39;</span><span class="p">:</span> <span class="nb">str</span><span class="p">})</span>
<span class="n">df1</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/df2.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df2</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_excel</span><span class="p">(</span><span class="s1">&#39;上市公司高管违规-原始数据.xlsx&#39;</span><span class="p">,</span> <span class="n">converters</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;股票代码&#39;</span><span class="p">:</span> <span class="nb">str</span><span class="p">})</span>
<span class="n">df2</span><span class="p">[</span><span class="s1">&#39;公告日期&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">df2</span><span class="p">[</span><span class="s1">&#39;公告日期&#39;</span><span class="p">])</span>
<span class="n">df2</span><span class="p">[</span><span class="s1">&#39;会计年度&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df2</span><span class="p">[</span><span class="s1">&#39;公告日期&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">dt</span><span class="o">.</span><span class="n">year</span>
<span class="n">df2</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/df3.png" alt=""  />
</p>
<br>
<h3 id="22-合并">2.2 合并</h3>
<p>然后我们使用pd.merge()函数将两个数据集按照股票代码和年度进行合并，使用全连接（how=&lsquo;outer&rsquo;）确保即使某些股票代码未出现在高管违规数据集中，也能保留在结果中。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">df1</span><span class="p">,</span> <span class="n">df2</span><span class="p">,</span> <span class="n">how</span><span class="o">=</span><span class="s1">&#39;outer&#39;</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;股票代码&#39;</span><span class="p">,</span> <span class="s1">&#39;会计年度&#39;</span><span class="p">])</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/df4.png" alt=""  />
</p>
<br>
<h3 id="23-分组groupby">2.3 分组Groupby</h3>
<p>接下来，</p>
<ol>
<li>使用groupby()函数按 <code>股票代码</code> 和 <code>会计年度</code> 进行分组</li>
<li>然后使用count()函数统计每组次数</li>
<li>并将计算命名为 <code>违规次数</code></li>
</ol>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">result_df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">([</span><span class="s1">&#39;股票代码&#39;</span><span class="p">,</span> <span class="s1">&#39;会计年度&#39;</span><span class="p">])[</span><span class="s1">&#39;违规行为&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">count</span><span class="p">()</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;违规次数&#39;</span><span class="p">)</span>
<span class="n">result_df</span>
</code></pre></div><p><img loading="lazy" src="img/df5.png" alt=""  />
</p>
<br>
<h3 id="24-检查保存">2.4 检查&amp;保存</h3>
<p>检查结果， 无误后导出xlsx。字段包括股票代码、年度和违规次数。</p>
<p><img loading="lazy" src="img/check.png" alt=""  />
</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df2</span><span class="p">[(</span><span class="n">df2</span><span class="p">[</span><span class="s1">&#39;股票代码&#39;</span><span class="p">]</span><span class="o">==</span><span class="s1">&#39;871753&#39;</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">df2</span><span class="p">[</span><span class="s1">&#39;公告日期&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">dt</span><span class="o">.</span><span class="n">year</span><span class="o">==</span><span class="mi">2022</span><span class="p">)]</span>
</code></pre></div><p><img loading="lazy" src="img/df6.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df2</span><span class="p">[(</span><span class="n">df2</span><span class="p">[</span><span class="s1">&#39;股票代码&#39;</span><span class="p">]</span><span class="o">==</span><span class="s1">&#39;873527&#39;</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">df2</span><span class="p">[</span><span class="s1">&#39;公告日期&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">dt</span><span class="o">.</span><span class="n">year</span><span class="o">==</span><span class="mi">2018</span><span class="p">)]</span>
</code></pre></div><p><img loading="lazy" src="img/df7.png" alt=""  />
</p>
<br>
<p>这里仅随机检查了两个记录(现实中要多检查几次)， 与result_df中是一致的， 现在保存结果供后续实证分析</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">result_df</span><span class="o">.</span><span class="n">to_excel</span><span class="p">(</span><span class="s1">&#39;高管违规次数.xlsx&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</code></pre></div><p><br><br></p>
<h2 id="三获取数据">三、获取数据</h2>
<p>数据集 50 元 ， 加微信 <strong>372335839</strong>, 备注【姓名-学校-专业-高管数据集】获取本数据集。</p>
<p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>数据集 | B站/哔哩哔哩 1 亿用户数据</title>
      <link>https://textdata.cn/blog/2023-05-10-100m-bilibili-user-info-dataset/</link>
      <pubDate>Wed, 10 May 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-05-10-100m-bilibili-user-info-dataset/</guid>
      <description>&lt;h1 id=&#34;相关内容&#34;&gt;相关内容&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/2023-11-12-using-100m-bilibili-user-sign-data-to-training-word2vec/&#34;&gt;词向量 | 使用1亿B站用户签名训练word2vec词向量&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;一-数据集概括&#34;&gt;一、 数据集概括&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;数据源&lt;/strong&gt;: 哔哩哔哩&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;DateRange&lt;/strong&gt;:  &lt;strong&gt;2022-06 ~ 2022-11&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;数据下载地址&lt;/strong&gt;: &lt;a href=&#34;https://www.kaggle.com/datasets/beats0/bilibili-user&#34;&gt;https://www.kaggle.com/datasets/beats0/bilibili-user&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;数据量&lt;/strong&gt;: 1亿
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;字段&lt;/th&gt;
&lt;th&gt;数据类型&lt;/th&gt;
&lt;th&gt;含义&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;uid&lt;/td&gt;
&lt;td&gt;Number&lt;/td&gt;
&lt;td&gt;用户ID&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;code&lt;/td&gt;
&lt;td&gt;Number&lt;/td&gt;
&lt;td&gt;状态码&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;name&lt;/td&gt;
&lt;td&gt;String&lt;/td&gt;
&lt;td&gt;用户名&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;level&lt;/td&gt;
&lt;td&gt;Number&lt;/td&gt;
&lt;td&gt;用户等级 [0, 1, 2, 3, 4, 5, 6]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;sex&lt;/td&gt;
&lt;td&gt;String&lt;/td&gt;
&lt;td&gt;性别 [&amp;lsquo;男&amp;rsquo;, &amp;lsquo;女&amp;rsquo;, &amp;lsquo;保密&amp;rsquo;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;avatar&lt;/td&gt;
&lt;td&gt;String&lt;/td&gt;
&lt;td&gt;头像&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;sign&lt;/td&gt;
&lt;td&gt;String&lt;/td&gt;
&lt;td&gt;用户签名&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;vip_type&lt;/td&gt;
&lt;td&gt;Number&lt;/td&gt;
&lt;td&gt;会员类型（已过期不为0，0为从来不是会员）0：无 1：月度大会员 2：年度及以上大会员&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;vip_status&lt;/td&gt;
&lt;td&gt;Number&lt;/td&gt;
&lt;td&gt;状态码 0：无 1：有&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;vip_role&lt;/td&gt;
&lt;td&gt;Number&lt;/td&gt;
&lt;td&gt;会员类型 0：无 1：月度大会员 3：年度大会员 7：十年大会员 15：百年大会员&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;archive&lt;/td&gt;
&lt;td&gt;Number&lt;/td&gt;
&lt;td&gt;用户稿件数&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;fans&lt;/td&gt;
&lt;td&gt;Number&lt;/td&gt;
&lt;td&gt;粉丝数&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;friend&lt;/td&gt;
&lt;td&gt;Number&lt;/td&gt;
&lt;td&gt;关注数&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;like_num&lt;/td&gt;
&lt;td&gt;Number&lt;/td&gt;
&lt;td&gt;获赞数&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;is_senior&lt;/td&gt;
&lt;td&gt;Number&lt;/td&gt;
&lt;td&gt;是否为硬核会员 0：否 1：是&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;二读取数据&#34;&gt;二、读取数据&lt;/h2&gt;
&lt;p&gt;User.csv 文件有 10.44 G， 对一般的电脑而言需要将其分割为多个小份文件， 教程详情请看&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/2023-05-06-how-to-read-big-csv-file/&#34;&gt;&lt;strong&gt;单个csv文件体积大于电脑内存，怎么办&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;大邓就假装各位电脑内存很大，至少16G起步。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pandas&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pd&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read_csv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;User.csv&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;head&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/df.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;三其他操作&#34;&gt;三、其他操作&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;查看记录量&lt;/li&gt;
&lt;li&gt;字段数据类型&lt;/li&gt;
&lt;li&gt;粉丝量最多的10个用户&lt;/li&gt;
&lt;li&gt;性别分布&lt;/li&gt;
&lt;li&gt;签名中是否含Python&lt;/li&gt;
&lt;li&gt;&amp;hellip;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;31-数据集记录量&#34;&gt;3.1 数据集记录量&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;100000000
&lt;/code&gt;&lt;/pre&gt;
&lt;br&gt;
&lt;h3 id=&#34;32-字段的数据类型&#34;&gt;3.2 字段的数据类型&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dtypes&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;uid            int64
name          object
avatar        object
level          int64
sex           object
sign          object
vip_type       int64
vip_status     int64
vip_role       int64
archive        int64
fans           int64
friend         int64
like_num       int64
is_senior      int64
dtype: object
&lt;/code&gt;&lt;/pre&gt;
&lt;br&gt;
&lt;h3 id=&#34;33-粉丝量最多的10个用户&#34;&gt;3.3 粉丝量最多的10个用户&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;c1&#34;&gt;#粉丝量最多的10个用户&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;nlargest&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;fans&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/df2.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;34-性别分布&#34;&gt;3.4 性别分布&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sex&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;value_counts&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;保密    88236345
男      6488548
女      5273634
Name: sex, dtype: int64
&lt;/code&gt;&lt;/pre&gt;
&lt;br&gt;
&lt;h3 id=&#34;35-签名中是否含python&#34;&gt;3.5 签名中是否含Python&lt;/h3&gt;
&lt;p&gt;找找做Python的同行，返回的结果里没有大邓&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;new_df&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;sign&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;isna&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()]&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;python_ups&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;new_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;new_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;sign&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;str&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;contains&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;python&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)]&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;python_ups&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/df3.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;br&gt;
&lt;h2 id=&#34;广而告之&#34;&gt;广而告之&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/call_for_paper/&#34;&gt;长期征稿&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/we_need_you/&#34;&gt;长期招募小伙伴&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/management_python_course/&#34;&gt;付费视频课 | Python实证指标构建与文本分析&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
      <content:encoded><![CDATA[<h1 id="相关内容">相关内容</h1>
<ul>
<li><a href="https://textdata.cn/blog/2023-11-12-using-100m-bilibili-user-sign-data-to-training-word2vec/">词向量 | 使用1亿B站用户签名训练word2vec词向量</a></li>
</ul>
<p><br><br></p>
<h2 id="一-数据集概括">一、 数据集概括</h2>
<ul>
<li><strong>数据源</strong>: 哔哩哔哩</li>
<li><strong>DateRange</strong>:  <strong>2022-06 ~ 2022-11</strong></li>
<li><strong>数据下载地址</strong>: <a href="https://www.kaggle.com/datasets/beats0/bilibili-user">https://www.kaggle.com/datasets/beats0/bilibili-user</a></li>
<li><strong>数据量</strong>: 1亿
<table>
<thead>
<tr>
<th>字段</th>
<th>数据类型</th>
<th>含义</th>
</tr>
</thead>
<tbody>
<tr>
<td>uid</td>
<td>Number</td>
<td>用户ID</td>
</tr>
<tr>
<td>code</td>
<td>Number</td>
<td>状态码</td>
</tr>
<tr>
<td>name</td>
<td>String</td>
<td>用户名</td>
</tr>
<tr>
<td>level</td>
<td>Number</td>
<td>用户等级 [0, 1, 2, 3, 4, 5, 6]</td>
</tr>
<tr>
<td>sex</td>
<td>String</td>
<td>性别 [&lsquo;男&rsquo;, &lsquo;女&rsquo;, &lsquo;保密&rsquo;]</td>
</tr>
<tr>
<td>avatar</td>
<td>String</td>
<td>头像</td>
</tr>
<tr>
<td>sign</td>
<td>String</td>
<td>用户签名</td>
</tr>
<tr>
<td>vip_type</td>
<td>Number</td>
<td>会员类型（已过期不为0，0为从来不是会员）0：无 1：月度大会员 2：年度及以上大会员</td>
</tr>
<tr>
<td>vip_status</td>
<td>Number</td>
<td>状态码 0：无 1：有</td>
</tr>
<tr>
<td>vip_role</td>
<td>Number</td>
<td>会员类型 0：无 1：月度大会员 3：年度大会员 7：十年大会员 15：百年大会员</td>
</tr>
<tr>
<td>archive</td>
<td>Number</td>
<td>用户稿件数</td>
</tr>
<tr>
<td>fans</td>
<td>Number</td>
<td>粉丝数</td>
</tr>
<tr>
<td>friend</td>
<td>Number</td>
<td>关注数</td>
</tr>
<tr>
<td>like_num</td>
<td>Number</td>
<td>获赞数</td>
</tr>
<tr>
<td>is_senior</td>
<td>Number</td>
<td>是否为硬核会员 0：否 1：是</td>
</tr>
</tbody>
</table>
</li>
</ul>
<p><br><br></p>
<h2 id="二读取数据">二、读取数据</h2>
<p>User.csv 文件有 10.44 G， 对一般的电脑而言需要将其分割为多个小份文件， 教程详情请看</p>
<ul>
<li><a href="https://textdata.cn/blog/2023-05-06-how-to-read-big-csv-file/"><strong>单个csv文件体积大于电脑内存，怎么办</strong></a></li>
</ul>
<p>大邓就假装各位电脑内存很大，至少16G起步。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;User.csv&#39;</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/df.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="三其他操作">三、其他操作</h2>
<ul>
<li>查看记录量</li>
<li>字段数据类型</li>
<li>粉丝量最多的10个用户</li>
<li>性别分布</li>
<li>签名中是否含Python</li>
<li>&hellip;</li>
</ul>
<h3 id="31-数据集记录量">3.1 数据集记录量</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
</code></pre></div><pre><code>100000000
</code></pre>
<br>
<h3 id="32-字段的数据类型">3.2 字段的数据类型</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df</span><span class="o">.</span><span class="n">dtypes</span>
</code></pre></div><pre><code>uid            int64
name          object
avatar        object
level          int64
sex           object
sign          object
vip_type       int64
vip_status     int64
vip_role       int64
archive        int64
fans           int64
friend         int64
like_num       int64
is_senior      int64
dtype: object
</code></pre>
<br>
<h3 id="33-粉丝量最多的10个用户">3.3 粉丝量最多的10个用户</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#粉丝量最多的10个用户</span>
<span class="n">df</span><span class="o">.</span><span class="n">nlargest</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="s1">&#39;fans&#39;</span><span class="p">)</span>
</code></pre></div><p><img loading="lazy" src="img/df2.png" alt=""  />
</p>
<br>
<h3 id="34-性别分布">3.4 性别分布</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df</span><span class="o">.</span><span class="n">sex</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</code></pre></div><pre><code>保密    88236345
男      6488548
女      5273634
Name: sex, dtype: int64
</code></pre>
<br>
<h3 id="35-签名中是否含python">3.5 签名中是否含Python</h3>
<p>找找做Python的同行，返回的结果里没有大邓</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">new_df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="o">-</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;sign&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">isna</span><span class="p">()]</span>
<span class="n">python_ups</span> <span class="o">=</span> <span class="n">new_df</span><span class="p">[</span><span class="n">new_df</span><span class="p">[</span><span class="s1">&#39;sign&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="s1">&#39;python&#39;</span><span class="p">)]</span>
<span class="n">python_ups</span>
</code></pre></div><p><img loading="lazy" src="img/df3.png" alt=""  />
</p>
<br>
<br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>93G数据集 | 中国裁判文书网(2010-2021)</title>
      <link>https://textdata.cn/blog/2023-05-07-china-law-judgment-documents-datasets/</link>
      <pubDate>Sun, 07 May 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-05-07-china-law-judgment-documents-datasets/</guid>
      <description>中国裁判文书网数据集</description>
      <content:encoded><![CDATA[<h2 id="一中国裁判文书数据集">一、中国裁判文书数据集</h2>
<h3 id="11-数据集概括">1.1 数据集概括</h3>
<p>上亿条中国裁判文书， 公开案件主要覆盖<strong>2010.1 ~ 2021.10</strong>期间的记录， 数据集体量高达93G。</p>
<p><img loading="lazy" src="/Users/deng/Desktop/Blog/content/blog/2023-05-07-china-law-judgment-documents-datasets/img/wenshu.png" alt=""  />

<img loading="lazy" src="/Users/deng/Desktop/Blog/content/blog/2023-05-07-china-law-judgment-documents-datasets/img/years.png" alt=""  />
</p>
<br>
<h3 id="12-字段含">1.2 字段含</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">-  标题
-  审理法院
-  案件类型
-  网页链接
-  案号
-  审理程序
-  裁判日期
-  发布日期
-  文书内容
-  当事人
-  案由
-  法律依据
-  裁判年份
-  裁判月份
-  来源
</code></pre></div><br>
<h3 id="13-可用价值">1.3 可用价值</h3>
<p>根据字段信息， 从该数据集中提取一些新的指标，可广泛适用于</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">- 法学
- 经济学
- 管理学
- 社会学
- 传播学
- 政治学
- 等
</code></pre></div><h3 id="14-广告">1.4 广告</h3>
<p>数据体量越大，越乱(非结构的文本数据字段越多)，门槛越高(处理难度越大)， 该数据的潜在的相对价值越大。</p>
<p>使用这类数据需要读取大数据、文本清洗、文本分析，可以考虑学习「Python实证指标构建与文本分析」，内容包括文本分析方方面面的技能点。</p>
<p><br><br></p>
<h2 id="二导入数据">二、导入数据</h2>
<p>本数据集适合电脑内存16G及以上的同学购买和练习使用。 以2021年为例，打开数据集，可以看到每个数据文件都是很大的。</p>
<p><img loading="lazy" src="/Users/deng/Desktop/Blog/content/blog/2023-05-07-china-law-judgment-documents-datasets/img/one-year.png" alt=""  />
</p>
<p>内存8G以下的使用这些大体量数据需要参考这篇文章， 将大文件拆分成多个小文件，再分别读取分析。</p>
<p>这类数据集体量很大，几乎不可能用Excel等软件打开， 建议大家系统学习pandas库， 掌握该库后就能很方便的进行数值和文本类的数据分析。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;2021/2021-10.csv&#39;</span><span class="p">)</span>
<span class="c1">#随机抽5条显示</span>
<span class="n">df</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</code></pre></div><p><img loading="lazy" src="/Users/deng/Desktop/Blog/content/blog/2023-05-07-china-law-judgment-documents-datasets/img/df.png" alt=""  />
</p>
<br>
<p>裁判文书网， 2021年1月份数据量有</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">1158489
</code></pre></div><br>
<p>字段  <strong>「文书内容」</strong>  Nan数据占比</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;文书内容&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">isna</span><span class="p">()])</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>  

</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">0.2687681971947943
</code></pre></div><br>
<p>显示第一条非Nan的**「文书内容」**</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df</span><span class="p">[</span><span class="o">-</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;文书内容&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">isna</span><span class="p">()]</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div><p><img loading="lazy" src="/Users/deng/Desktop/Blog/content/blog/2023-05-07-china-law-judgment-documents-datasets/img/not-nan.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df</span><span class="p">[</span><span class="o">-</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;文书内容&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">isna</span><span class="p">()]</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">to_dict</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">{&#39;标题&#39;: {250: &#39;魏晓明与王力威借款合同纠纷案执行裁定书&#39;},
 &#39;审理法院&#39;: {250: &#39;黑龙江省诺敏河人民法院&#39;},
 &#39;案件类型&#39;: {250: &#39;执行案件&#39;},
 &#39;网页链接&#39;: {250: &#39;https://wenshu.court.gov.cn/website/wenshu/181107ANFZ0BXSK4/index.html?docId=789c47e53b1f421eaf18aca500f71309&#39;},
 &#39;案号&#39;: {250: &#39;（2021）黑7530执恢20号&#39;},
 &#39;审理程序&#39;: {250: &#39;执行实施&#39;},
 &#39;裁判日期&#39;: {250: &#39;2021-01-03&#39;},
 &#39;发布日期&#39;: {250: &#39;2021-01-03&#39;},
 &#39;文书内容&#39;: {250: &#39;黑龙江省诺敏河人民法院执 行 裁 定 书（2021）黑7530执恢20号申请执行人魏晓明，男，1964年1月1日出生，汉族，住沾河林业局。被执行人王力威，男，1977年8月18日出生，汉族，住沾河林业局。本院在执行魏晓明与王力威借款合同纠纷一案中，被执行人应履行债务80000元，执行回款50000元。未发现被执行人有其他财产可供执行。依照《最高人民法院关于适用〈中华人民共和国民事诉讼法〉的解释》第五百一十九条之规定，裁定如下：终结本次执行程序。申请执行人发现被执行人有可供执行财产的，可以再次申请执行。本裁定送达后立即生效。审判长\u3000\u3000谭国军审判员\u3000\u3000丁树桓审判员\u3000\u3000范颖杰二〇二一年一月三日书记员\u3000\u3000张晶洁&#39;},
 &#39;当事人&#39;: {250: &#39;魏晓明；王力威；魏晓明；王力威&#39;},
 &#39;案由&#39;: {250: &#39;借款合同纠纷&#39;},
 &#39;法律依据&#39;: {250: &#39;最高人民法院关于适用《中华人民共和国民事诉讼法》的解释:第五百一十九条第一款；最高人民法院关于适用《中华人民共和国民事诉讼法》的解释:第五百一十九条第二款&#39;},
 &#39;裁判年份&#39;: {250: 2021},
 &#39;裁判月份&#39;: {250: 1},
 &#39;来源&#39;: {250: &#39;公众号: 大邓和他的Python&#39;}}
</code></pre></div><p><br><br></p>
<h2 id="三小实验">三、小实验</h2>
<p>针对 2021-01.csv 数据，做下面三个小实验</p>
<ol>
<li>案件类型统计</li>
<li>前10类案由</li>
<li>涉及公司主体的案件占比</li>
<li>不同地域案件量的分布情况；</li>
</ol>
<h3 id="31-案件类型统计">3.1 案件类型统计</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;案件类型&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
</code></pre></div><p><img loading="lazy" src="/Users/deng/Desktop/Blog/content/blog/2023-05-07-china-law-judgment-documents-datasets/img/df2.png" alt=""  />
</p>
<br>
<h3 id="32-前10类案由">3.2 前10类案由</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;案由&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)[:</span><span class="mi">10</span><span class="p">])</span>
</code></pre></div><p><img loading="lazy" src="/Users/deng/Desktop/Blog/content/blog/2023-05-07-china-law-judgment-documents-datasets/img/df3.png" alt=""  />
</p>
<br>
<h3 id="33-涉及公司主体的案件占比">3.3 涉及公司主体的案件占比</h3>
<p>根据「当事人」是否含「公司」字眼</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df</span><span class="p">[</span><span class="s1">&#39;当事人&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="s1">&#39;公司&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">    0.43124190216739217
</code></pre></div><br>
<h3 id="34-不同地域案件量的分布">3.4 不同地域案件量的分布</h3>
<p>案号，命名地域+编号，应该可以通过案号计算出不同地域案件量的分布情况。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#slice是字符串切片操作，根据观察感觉是第7个字符是省份简称。</span>
<span class="n">provinces_ratio</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;案号&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">slice</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">provinces_ratio</span><span class="p">)</span>
</code></pre></div><p><img loading="lazy" src="/Users/deng/Desktop/Blog/content/blog/2023-05-07-china-law-judgment-documents-datasets/img/df4.png" alt=""  />
</p>
<br> 
<p>但经过实验，发现地域可以是省，也可以是地级市， 所以刚刚切片的实验鲁莽了。。。 不过以省份命名的案件量排名还是占据前列。</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="nb">print</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">provinces_ratio</span><span class="p">)</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">    [&#39;鲁&#39;, &#39;辽&#39;, &#39;豫&#39;, &#39;浙&#39;, &#39;苏&#39;, &#39;川&#39;, &#39;皖&#39;, &#39;粤&#39;, &#39;湘&#39;, &#39;沪&#39;, &#39;黔&#39;, &#39;鄂&#39;, &#39;京&#39;, &#39;陕&#39;, &#39;新&#39;, &#39;吉&#39;, &#39;渝&#39;, &#39;冀&#39;, &#39;赣&#39;, &#39;闽&#39;, &#39;黑&#39;, &#39;云&#39;, &#39;晋&#39;, &#39;津&#39;, &#39;桂&#39;, &#39;内&#39;, &#39;甘&#39;, &#39;宁&#39;, &#39;青&#39;, &#39;兵&#39;, &#39;藏&#39;, &#39;最&#39;, &#39;琼&#39;, &#39;0&#39;, &#39;1&#39;, &#39;初&#39;, &#39;）&#39;, &#39; &#39;, &#39;2&#39;, &#39;7&#39;, &#39;年&#39;, &#39;5&#39;, &#39;&#39;, &#39;4&#39;, &#39;凌&#39;, &#39;执&#39;, &#39;8&#39;, &#39;3&#39;, &#39;恢&#39;, &#39;特&#39;, &#39;9&#39;, &#39;温&#39;, &#39;刑&#39;, &#39;6&#39;, &#39;临&#39;, &#39;保&#39;, &#39;莱&#39;, &#39;峄&#39;, &#39;东&#39;, &#39;郯&#39;, &#39;神&#39;, &#39;缙&#39;, &#39;丽&#39;, &#39;泗&#39;, &#39;金&#39;, &#39;（&#39;, &#39;单&#39;, &#39;［&#39;, &#39;南&#39;, &#39;聊&#39;, &#39;问&#39;, &#39;鱼&#39;, &#39;﹝&#39;, &#39;长&#39;, &#39;乳&#39;, &#39;芝&#39;, &#39;嘉&#39;, &#39;应&#39;, &#39;立&#39;, &#39;齐&#39;, &#39;岚&#39;, &#39;湖&#39;, &#39;衢&#39;, &#39;台&#39;, &#39;射&#39;, &#39;浦&#39;, &#39;民&#39;, &#39;号&#39;, &#39;晥&#39;, &#39;伊&#39;, &#39;荣&#39;, &#39;柳&#39;, &#39;\u200c&#39;, &#39;市&#39;, &#39;善&#39;, &#39;盱&#39;, &#39;华&#39;, &#39;瑶&#39;, &#39;宿&#39;, &#39;柯&#39;, &#39;垦&#39;, &#39;河&#39;, &#39;？&#39;, &#39;溧&#39;, &#39;怀&#39;, &#39;中&#39;, &#39;右&#39;, &#39;司&#39;, &#39;西&#39;, &#39;微&#39;, &#39;异&#39;, &#39;行&#39;, &#39;集&#39;, &#39;乐&#39;, &#39;薛&#39;, &#39;北&#39;, &#39;上&#39;, &#39;沂&#39;, &#39;沭&#39;, &#39;烟&#39;, &#39;额&#39;, &#39;杭&#39;, &#39;甬&#39;, &#39;蓟&#39;, &#39;永&#39;, &#39;济&#39;, &#39;诸&#39;, &#39;受&#39;, &#39;×&#39;, &#39;开&#39;, &#39;财&#39;, &#39;诉&#39;, &#39;淅&#39;, &#39;枣&#39;, &#39;从&#39;, &#39;锡&#39;, &#39;呈&#39;, &#39;滕&#39;, &#39;阳&#39;, &#39;太&#39;, &#39;宜&#39;, &#39;峰&#39;, &#39;坊&#39;, &#39;滨&#39;, &#39;德&#39;, &#39;淮&#39;, &#39;正&#39;, &#39;牟&#39;, &#39;佛&#39;, &#39;运&#39;, &#39;威&#39;, &#39;兰&#39;, &#39;栖&#39;, &#39;古&#39;, &#39;包&#39;, &#39;人&#39;, &#39;依&#39;, &#39;康&#39;, &#39;启&#39;, &#39;昌&#39;, &#39;稷&#39;, &#39;穗&#39;, &#39;绍&#39;]
</code></pre></div><br>
<h2 id="四数据获取">四、数据获取</h2>
<p>注意该数据集没有判决书内容，时间覆盖到2021年10月。  如需要这份数据付费数据集， 100元， 加微信 372335839， 备注「姓名-学校-专业」</p>
<br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>从3571w条专利数据集「匹配」上市公司的专利信息</title>
      <link>https://textdata.cn/blog/2023-04-26-matching-listed-corporate-with-patent-dataset/</link>
      <pubDate>Wed, 26 Apr 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-04-26-matching-listed-corporate-with-patent-dataset/</guid>
      <description>3571万专利申请全量数据(1985-2022年)数据</description>
      <content:encoded><![CDATA[<h2 id="一问题">一、问题</h2>
<p>之前分享过 <a href="https://textdata.cn/blog/2023-04-13-3571w-patent-dataset-in-china-mainland/">数据集(付费) | 3571万条专利申请数据集(1985-2022年)</a> ， 没有涉及匹配数据的问题。 <strong>有学员反映，该数据集是否支持匹配上市公司。或者上市公司的专利数量等信息能否从该数据集中抽取， 答案是可以的</strong>。 如果对数据集了解，可以直接看第二部分，不熟悉的建议看下数据集大致信息。</p>
<br>
<h3 id="11-专利申请数据集">1.1 专利申请数据集</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">- 数据集名称：省份版知识产权局专利
- 时间跨度：1985-2022，专利申请总量3571万
- 数据来源：『国家知识产权局』
- 数据整理: 『公众号:大邓和他的Python』
</code></pre></div><br>
<h3 id="12-字段">1.2 字段</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"> -  专利公开号
 -  专利名称
 -  专利类型
 -  专利摘要
 -  【申请人】
 -  专利申请号
 -  申请日
 -  申请公布日
 -  授权公布号
 -  授权公布日
 -  申请地址
 -  主权项
 -  发明人
 -  分类号
 -  主分类号
 -  代理机构
 -  分案原申请号
 -  优先权
 -  国际申请
 -  国际公布
 -  代理人
 -  省份或国家代码
 -  法律状态
 -  专利领域
 -  专利学科
 -  多次公布
</code></pre></div><br>
<h3 id="13-数据集大小">1.3 数据集大小</h3>
<p>整体解压后大概70G，</p>
<p><img loading="lazy" src="img/screen-datasets.png" alt=""  />
</p>
<br>
<h3 id="13-分省统计">1.3 分省统计</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">| 省份(区域)       |  专利数  |
| :---------------| :------ |
| 广东省           | 5728705 |
| 江苏省           | 4879171 |
| 浙江省           | 3706820 |
| 山东省           | 2064446 |
| 北京市           | 2069913 |
| 四川省           | 1159551 |
| 天津市           | 712932  |
| 上海市           | 1548278 |
| 贵州省           | 265512  |
| 陕西省           | 655837  |
| 吉林省           | 232264  |
| 辽宁省           | 637853  |
| 湖北省           | 966384  |
| 山西省           | 233418  |
| 宁夏回族自治区    | 66919   |
| 西藏自治区        | 9911    |
| 广西壮族自治区    | 377658  |
| 江西省           | 519584  |
| 湖南省           | 743828  |
| 黑龙江省         | 357881  |
| 海南省           | 59202   |
| 福建省           | 1046473 |
| 安徽省           | 1342364 |
| 河北省           | 645420  |
| 重庆市           | 592382  |
| 内蒙古自治区      | 133277  |
| 云南省           | 252407  |
| 甘肃省           | 164274  |
| 新疆维吾尔自治区   | 124734  |
| 河南省           | 966477  |
| 青海省           | 34127   |
| 台湾省           | 401555  |
| 香港特别行政区    | 61636   |
| 澳门特别行政区    | 2010    |
| 其他国家         | 2948557 |
</code></pre></div><p><br><br></p>
<h2 id="二读取数据">二、读取数据</h2>
<p>数据集中的个别csv文件较大，例如广东省.csv体积10G。 我们就以建议分析的时候， 电脑内存大于等于16G的， 每次分析时不要开其他软件。</p>
<p>为了演示， 我选择用较小的 黑龙江省.csv 为例。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;黑龙江省.csv&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">,</span> <span class="n">low_memory</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<p><img loading="lazy" src="img/df.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;黑龙江省专利数量: &#39;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">))</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">河北省: 357881
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#数据集中的字段含</span>
<span class="n">df</span><span class="o">.</span><span class="n">columns</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">Index([&#39;专利公开号&#39;, &#39;专利名称&#39;, &#39;专利类型&#39;, &#39;专利摘要&#39;, 
&#39;申请人&#39;, &#39;专利申请号&#39;, &#39;申请日&#39;, &#39;申请公布日&#39;, 
&#39;授权公布号&#39;, &#39;授权公布日&#39;, &#39;申请地址&#39;, &#39;主权项&#39;, &#39;发明人&#39;,
&#39;分类号&#39;, &#39;主分类号&#39;, &#39;代理机构&#39;, &#39;分案原申请号&#39;, &#39;优先权&#39;, 
&#39;国际申请&#39;, &#39;国际公布&#39;, &#39;代理人&#39;, &#39;省份或国家代码&#39;,
&#39;法律状态&#39;, &#39;专利领域&#39;, &#39;专利学科&#39;, &#39;多次公布&#39;],
dtype=&#39;object&#39;)
</code></pre></div><p><br><br></p>
<p>大邓现在在大东北，知道黑龙江的上市公司有哈药集团和北大荒。 我们就查一下 「黑龙江省.csv」 专利申请的数据中是否有北大荒和哈药集团。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;北大荒专利数: &#39;</span><span class="p">,</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;申请人&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="s1">&#39;北大荒集团&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;哈药集团专利数: &#39;</span><span class="p">,</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;申请人&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="s1">&#39;哈药集团&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">北大荒专利数:  4
哈药集团专利数:  712
</code></pre></div><p>还真有!!! so， 这个  <a href="">数据集 | 3571万条专利申请数据集(1985-2022年)</a> 是真的可以匹配上市公司，做一些有价值的变量。 感叹完毕， 继续写点没营养的代码。</p>
<br>
<h2 id="三匹配公司">三、匹配公司</h2>
<p>从上面可以看出哈药集团专利数很多，咱们继续检查哈药集团的专利数据。那么如何筛选出某公司的所有专利申请记录数据呢？这里会用到DataFrame的布尔条件筛选，把值为True的筛选出来。</p>
<ol>
<li>宽松条件  <code>「申请人」含「哈药集团」字眼的</code></li>
<li>严格条件 <code>「申请人」所含字眼就是「哈药集团」四个字</code></li>
</ol>
<br>
<h3 id="31-宽松条件">3.1 宽松条件</h3>
<p>把「申请人」含「哈药集团」字眼的记录筛选出来</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df2</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;申请人&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="s1">&#39;哈药集团&#39;</span><span class="p">)</span><span class="o">==</span><span class="kc">True</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">df2</span><span class="p">))</span>
<span class="n">df2</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/df2.png" alt=""  />
</p>
<p>返回结果可以看到，申请人主体是有很多个不同的主体，都是「哈药集团」附属的子公司或分厂。</p>
<br>
<h3 id="31-严格条件">3.1 严格条件</h3>
<p>「申请人」所含字眼就是「哈药集团」四个字</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df3</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;申请人&#39;</span><span class="p">]</span><span class="o">==</span><span class="s1">&#39;哈药集团&#39;</span><span class="p">]</span>

<span class="n">df3</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/df3.png" alt=""  />
</p>
<p>严格条件筛选后，符合的记录数量为0 。 「哈药集团」这四个字是上市公司名称的缩写简写，所以直接这样做筛选，一般得到的结果都是0。  实际上，一个完整的公司名一般是 「属地+公司名+股份有限公司」。例如，</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df4</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;申请人&#39;</span><span class="p">]</span><span class="o">==</span><span class="s1">&#39;哈药集团三精制药四厂有限公司&#39;</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">df4</span><span class="p">))</span>
<span class="n">df4</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">28
</code></pre></div><p><img loading="lazy" src="img/df4.png" alt=""  />
</p>
<br>
<br>
<h2 id="四其他操作">四、其他操作</h2>
<h3 id="41-类型字段">4.1 类型字段</h3>
<p>想了解「哈药集团」相关公司「专利领域」的分布情况</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df3</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;申请人&#39;</span><span class="p">]</span><span class="o">==</span><span class="s1">&#39;哈药集团&#39;</span><span class="p">]</span>

<span class="n">df3</span><span class="p">[</span><span class="s1">&#39;专利领域&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">工程科技Ⅱ辑            265
医药卫生科技            250
工程科技Ⅰ辑            157
基础科学               34
农业科技                5
工程科技Ⅰ辑; 工程科技Ⅱ辑      1
Name: 专利领域, dtype: int64
</code></pre></div><p>可以看到 「哈药集团」 在医药相关的领域布局较多，农业科技只有5个，从中可以看出 「哈药集团」还是一个技术很专注的企业。</p>
<br>
<h3 id="42-如何剔除nan">4.2 如何剔除Nan</h3>
<p>如果对某个字段感兴趣， 比如「国际申请」</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df</span><span class="p">[</span><span class="s1">&#39;国际申请&#39;</span><span class="p">]</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">0         NaN
1         NaN
2         NaN
3         NaN
4         NaN
         ... 
357876    NaN
357877    NaN
357878    NaN
357879    NaN
357880    NaN
Name: 国际申请, Length: 357881, dtype: object
</code></pre></div><p>但肉眼所见全是Nan， <strong>如何剔除掉Nan， 显露出非Nan的记录呢？</strong></p>
<p>解决办法依然是使用DataFrame的逻辑布尔筛选数据。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df</span><span class="p">[</span><span class="o">~</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;国际申请&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">isna</span><span class="p">()]</span>
</code></pre></div><p><img loading="lazy" src="img/df5.png" alt=""  />

<br></p>
<br>
<h2 id="五获取3751w专利数据集">五、获取3751w专利数据集</h2>
<p>该数据集为付费数据集， 如需数据，点击该链接 <a href="https://textdata.cn/blog/2023-04-13-3571w-patent-dataset-in-china-mainland/">数据集(付费) | 3571万条专利申请数据集(1985-2022年)</a> 进行购买。</p>
<p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>实验 | 互联网黑话与MD&amp;A</title>
      <link>https://textdata.cn/blog/2023-04-26-chinese-it-industry-slangs-words/</link>
      <pubDate>Wed, 26 Apr 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-04-26-chinese-it-industry-slangs-words/</guid>
      <description>&lt;p&gt;最近大邓意外发现，使用mda预训练语言模型扩展互联网黑近义词，模型返回的有鼻子有眼的，这意味着上市公司高管在md&amp;amp;a中可能频繁使用了互联网黑话。&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;一互联网黑话&#34;&gt;一、互联网黑话&lt;/h2&gt;
&lt;h3 id=&#34;二字动词&#34;&gt;二字动词&lt;/h3&gt;
&lt;p&gt;复盘，赋能，沉淀，倒逼，落地，串联，协同，反晡，兼容，包装，重组，履约，晌应，量化，发力，布局，联动，细分，梳理，输出，加速，共建，支撑，融合，聚合，集成，对齐，对标，对焦，拆解，拉通，抽象，摸索，提炼，打通，打透，吃透，迁移，分发，分层，分装，穿梭，辐射，围绕，复用，渗透，扩展，开拓。&lt;/p&gt;
&lt;h3 id=&#34;二字名词&#34;&gt;二字名词&lt;/h3&gt;
&lt;p&gt;漏斗，中台，闭环，打法，拉通，纽带，矩阵，刺激，规模，场景，聚焦，维度，格局，形态，生态，话术，体系，抓手，赛道，认知，玩法，体感，感知，调性，心智，战役，合力，心力。&lt;/p&gt;
&lt;h3 id=&#34;三字名词&#34;&gt;三字名词&lt;/h3&gt;
&lt;p&gt;颗粒度，感知度，方法论，组合拳，引爆点，点线面，精细化，差异化，平台化，结构化，影响力，耦合性，易用性，一致性，端到端，短平快。&lt;/p&gt;
&lt;h3 id=&#34;四字名词&#34;&gt;四字名词&lt;/h3&gt;
&lt;p&gt;生命周期，价值转化，强化认知，资源倾斜，完善逻辑，抽离透传，复用打法，商业模式，快速响应，定性定量，关键路径，去中心化，结果导向，垂直领域，如何收口，归因分析，体验度量，信息屏障。&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;二模型近义词&#34;&gt;二、模型近义词&lt;/h2&gt;
&lt;p&gt;之前分享过一个中文金融领域的word2vec预训练语言模型，这里就不详细介绍模型参数。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://textdata.cn/blog/2023-03-24-load-w2v-and-expand-your-concpet-dicitonary/&#34;&gt;使用中文MD&amp;amp;A数据集训练word2vec预训练模型， 可扩展或新建会计金融等领域的情感词典&lt;/a&gt;&lt;/p&gt;
&lt;br&gt;
&lt;p&gt;文本分析最常用的方法是词典法(例如，LIWC)，而词向量模型可以帮助我们扩展或者构建概念情感词典。&lt;/p&gt;
&lt;p&gt;现在给大家演示只给一个词，返回topn个语义最相关的词。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 与 seedwords 最相关的前topn个词&lt;/span&gt;
&lt;span class=&#34;c1&#34;&gt;# wv是预训练语言模型&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;expand_dictionary&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
                  &lt;span class=&#34;n&#34;&gt;seedwords&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;复盘&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;
                  &lt;span class=&#34;n&#34;&gt;topn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;[&amp;#39;复盘&amp;#39;,
 &amp;#39;检视&amp;#39;,
 &amp;#39;检讨&amp;#39;,
 &amp;#39;KPI&amp;#39;,
 &amp;#39;考核评估&amp;#39;,
 &amp;#39;量化考核&amp;#39;,
 &amp;#39;跟踪考核&amp;#39;,
 &amp;#39;纠偏&amp;#39;,
 &amp;#39;过程跟踪&amp;#39;,
 &amp;#39;分析总结&amp;#39;,
 &amp;#39;KPI指标&amp;#39;]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;expand_dictionary&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
                  &lt;span class=&#34;n&#34;&gt;seedwords&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;赋能&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;
                  &lt;span class=&#34;n&#34;&gt;topn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;[&amp;#39;赋能&amp;#39;,
 &amp;#39;技术赋能&amp;#39;,
 &amp;#39;全面赋能&amp;#39;,
 &amp;#39;平台赋能&amp;#39;,
 &amp;#39;科技赋能&amp;#39;,
 &amp;#39;助力&amp;#39;,
 &amp;#39;数字化赋能&amp;#39;,
 &amp;#39;数据赋能&amp;#39;,
 &amp;#39;数智化&amp;#39;,
 &amp;#39;数据驱动&amp;#39;,
 &amp;#39;生态构建&amp;#39;]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;expand_dictionary&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
                  &lt;span class=&#34;n&#34;&gt;seedwords&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;感知度&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;
                  &lt;span class=&#34;n&#34;&gt;topn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;[&amp;#39;感知度&amp;#39;,
 &amp;#39;体验度&amp;#39;,
 &amp;#39;产品认知度&amp;#39;,
 &amp;#39;知晓度&amp;#39;,
 &amp;#39;购买率&amp;#39;,
 &amp;#39;品牌黏性&amp;#39;,
 &amp;#39;满意度忠诚度&amp;#39;,
 &amp;#39;忠诚度美誉度&amp;#39;,
 &amp;#39;消费者满意度&amp;#39;,
 &amp;#39;体验满意度&amp;#39;,
 &amp;#39;好感度&amp;#39;]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;expand_dictionary&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
                  &lt;span class=&#34;n&#34;&gt;seedwords&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;倒逼&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;
                  &lt;span class=&#34;n&#34;&gt;topn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;[&amp;#39;倒逼&amp;#39;, 
&amp;#39;倒逼企业&amp;#39;, 
&amp;#39;势在必行&amp;#39;, 
&amp;#39;迫使&amp;#39;, 
&amp;#39;大势所趋&amp;#39;, 
&amp;#39;促使&amp;#39;, 
&amp;#39;优胜劣汰&amp;#39;, 
&amp;#39;加速淘汰&amp;#39;, 
&amp;#39;势必&amp;#39;, 
&amp;#39;趋严&amp;#39;, 
&amp;#39;成为常态&amp;#39;]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;expand_dictionary&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
                  &lt;span class=&#34;n&#34;&gt;seedwords&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;闭环&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;
                  &lt;span class=&#34;n&#34;&gt;topn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;[&amp;#39;闭环&amp;#39;,
&amp;#39;完整闭环&amp;#39;, 
&amp;#39;全链路&amp;#39;, 
&amp;#39;全链条&amp;#39;, 
&amp;#39;全流程&amp;#39;, 
&amp;#39;闭环式&amp;#39;, 
&amp;#39;端端&amp;#39;, 
&amp;#39;端到端&amp;#39;, 
&amp;#39;服务闭环&amp;#39;, 
&amp;#39;全周期&amp;#39;, 
&amp;#39;闭环管理&amp;#39;]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;expand_dictionary&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
                  &lt;span class=&#34;n&#34;&gt;seedwords&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;端到端&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;
                  &lt;span class=&#34;n&#34;&gt;topn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;[&amp;#39;端到端&amp;#39;,
 &amp;#39;端端&amp;#39;,
 &amp;#39;端到端的&amp;#39;,
 &amp;#39;全链路&amp;#39;,
 &amp;#39;端端的&amp;#39;,
 &amp;#39;数字化运营&amp;#39;,
 &amp;#39;全业务流程&amp;#39;,
 &amp;#39;场景全&amp;#39;,
 &amp;#39;全链条&amp;#39;,
 &amp;#39;敏捷&amp;#39;,
 &amp;#39;全价值链&amp;#39;]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;可以看到， 返回的近义词都是挺互联网范儿的。 只有较为频繁使用， 语言模型才有可能捕捉到这种语义关系。这从侧面反映了近年来互联网高级黑话影响力之大。&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;三获取模型&#34;&gt;三、获取模型&lt;/h2&gt;
&lt;p&gt;模型训练不易， 为付费资源，如需使用请 &lt;a href=&#34;https://mp.weixin.qq.com/s/zle9-BR-ei1V8Nmul19_7w&#34;&gt;&lt;strong&gt;点击进入跳转购买链接&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;期待合作&#34;&gt;期待合作&lt;/h2&gt;
&lt;p&gt;cntext目前仍在技术迭代，版本2.0.0综合了训练语言模型&amp;amp;多语言模型对齐， 有较大的应用价值，期待有独特文本数据集交流合作。&lt;/p&gt;
&lt;p&gt;通过cntext2.0.0，理论上可以对文本所涉社会主体进行计算，适合企业文化、品牌印象、旅游目的地形象、国家形象等&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;同主体不同时间段， 文本中蕴含的文化态度认知变迁，&lt;/li&gt;
&lt;li&gt;或同时间段，不同主体的大样本文本蕴含的差异性&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;广而告之&#34;&gt;广而告之&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/call_for_paper/&#34;&gt;长期征稿&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/we_need_you/&#34;&gt;长期招募小伙伴&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/management_python_course/&#34;&gt;付费视频课 | Python实证指标构建与文本分析&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
      <content:encoded><![CDATA[<p>最近大邓意外发现，使用mda预训练语言模型扩展互联网黑近义词，模型返回的有鼻子有眼的，这意味着上市公司高管在md&amp;a中可能频繁使用了互联网黑话。</p>
<p><br><br></p>
<h2 id="一互联网黑话">一、互联网黑话</h2>
<h3 id="二字动词">二字动词</h3>
<p>复盘，赋能，沉淀，倒逼，落地，串联，协同，反晡，兼容，包装，重组，履约，晌应，量化，发力，布局，联动，细分，梳理，输出，加速，共建，支撑，融合，聚合，集成，对齐，对标，对焦，拆解，拉通，抽象，摸索，提炼，打通，打透，吃透，迁移，分发，分层，分装，穿梭，辐射，围绕，复用，渗透，扩展，开拓。</p>
<h3 id="二字名词">二字名词</h3>
<p>漏斗，中台，闭环，打法，拉通，纽带，矩阵，刺激，规模，场景，聚焦，维度，格局，形态，生态，话术，体系，抓手，赛道，认知，玩法，体感，感知，调性，心智，战役，合力，心力。</p>
<h3 id="三字名词">三字名词</h3>
<p>颗粒度，感知度，方法论，组合拳，引爆点，点线面，精细化，差异化，平台化，结构化，影响力，耦合性，易用性，一致性，端到端，短平快。</p>
<h3 id="四字名词">四字名词</h3>
<p>生命周期，价值转化，强化认知，资源倾斜，完善逻辑，抽离透传，复用打法，商业模式，快速响应，定性定量，关键路径，去中心化，结果导向，垂直领域，如何收口，归因分析，体验度量，信息屏障。</p>
<p><br><br></p>
<h2 id="二模型近义词">二、模型近义词</h2>
<p>之前分享过一个中文金融领域的word2vec预训练语言模型，这里就不详细介绍模型参数。</p>
<p><a href="https://textdata.cn/blog/2023-03-24-load-w2v-and-expand-your-concpet-dicitonary/">使用中文MD&amp;A数据集训练word2vec预训练模型， 可扩展或新建会计金融等领域的情感词典</a></p>
<br>
<p>文本分析最常用的方法是词典法(例如，LIWC)，而词向量模型可以帮助我们扩展或者构建概念情感词典。</p>
<p>现在给大家演示只给一个词，返回topn个语义最相关的词。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1"># 与 seedwords 最相关的前topn个词</span>
<span class="c1"># wv是预训练语言模型</span>
<span class="n">expand_dictionary</span><span class="p">(</span><span class="n">wv</span><span class="o">=</span><span class="n">wv</span><span class="p">,</span> 
                  <span class="n">seedwords</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;复盘&#39;</span><span class="p">],</span>
                  <span class="n">topn</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">[&#39;复盘&#39;,
 &#39;检视&#39;,
 &#39;检讨&#39;,
 &#39;KPI&#39;,
 &#39;考核评估&#39;,
 &#39;量化考核&#39;,
 &#39;跟踪考核&#39;,
 &#39;纠偏&#39;,
 &#39;过程跟踪&#39;,
 &#39;分析总结&#39;,
 &#39;KPI指标&#39;]
</code></pre></div> <br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">expand_dictionary</span><span class="p">(</span><span class="n">wv</span><span class="o">=</span><span class="n">wv</span><span class="p">,</span> 
                  <span class="n">seedwords</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;赋能&#39;</span><span class="p">],</span>
                  <span class="n">topn</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">[&#39;赋能&#39;,
 &#39;技术赋能&#39;,
 &#39;全面赋能&#39;,
 &#39;平台赋能&#39;,
 &#39;科技赋能&#39;,
 &#39;助力&#39;,
 &#39;数字化赋能&#39;,
 &#39;数据赋能&#39;,
 &#39;数智化&#39;,
 &#39;数据驱动&#39;,
 &#39;生态构建&#39;]
</code></pre></div> <br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">expand_dictionary</span><span class="p">(</span><span class="n">wv</span><span class="o">=</span><span class="n">wv</span><span class="p">,</span> 
                  <span class="n">seedwords</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;感知度&#39;</span><span class="p">],</span>
                  <span class="n">topn</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">[&#39;感知度&#39;,
 &#39;体验度&#39;,
 &#39;产品认知度&#39;,
 &#39;知晓度&#39;,
 &#39;购买率&#39;,
 &#39;品牌黏性&#39;,
 &#39;满意度忠诚度&#39;,
 &#39;忠诚度美誉度&#39;,
 &#39;消费者满意度&#39;,
 &#39;体验满意度&#39;,
 &#39;好感度&#39;]
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">expand_dictionary</span><span class="p">(</span><span class="n">wv</span><span class="o">=</span><span class="n">wv</span><span class="p">,</span> 
                  <span class="n">seedwords</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;倒逼&#39;</span><span class="p">],</span>
                  <span class="n">topn</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">[&#39;倒逼&#39;, 
&#39;倒逼企业&#39;, 
&#39;势在必行&#39;, 
&#39;迫使&#39;, 
&#39;大势所趋&#39;, 
&#39;促使&#39;, 
&#39;优胜劣汰&#39;, 
&#39;加速淘汰&#39;, 
&#39;势必&#39;, 
&#39;趋严&#39;, 
&#39;成为常态&#39;]
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">expand_dictionary</span><span class="p">(</span><span class="n">wv</span><span class="o">=</span><span class="n">wv</span><span class="p">,</span> 
                  <span class="n">seedwords</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;闭环&#39;</span><span class="p">],</span>
                  <span class="n">topn</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">[&#39;闭环&#39;,
&#39;完整闭环&#39;, 
&#39;全链路&#39;, 
&#39;全链条&#39;, 
&#39;全流程&#39;, 
&#39;闭环式&#39;, 
&#39;端端&#39;, 
&#39;端到端&#39;, 
&#39;服务闭环&#39;, 
&#39;全周期&#39;, 
&#39;闭环管理&#39;]
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">expand_dictionary</span><span class="p">(</span><span class="n">wv</span><span class="o">=</span><span class="n">wv</span><span class="p">,</span> 
                  <span class="n">seedwords</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;端到端&#39;</span><span class="p">],</span>
                  <span class="n">topn</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">[&#39;端到端&#39;,
 &#39;端端&#39;,
 &#39;端到端的&#39;,
 &#39;全链路&#39;,
 &#39;端端的&#39;,
 &#39;数字化运营&#39;,
 &#39;全业务流程&#39;,
 &#39;场景全&#39;,
 &#39;全链条&#39;,
 &#39;敏捷&#39;,
 &#39;全价值链&#39;]
</code></pre></div><p>可以看到， 返回的近义词都是挺互联网范儿的。 只有较为频繁使用， 语言模型才有可能捕捉到这种语义关系。这从侧面反映了近年来互联网高级黑话影响力之大。</p>
<p><br><br></p>
<h2 id="三获取模型">三、获取模型</h2>
<p>模型训练不易， 为付费资源，如需使用请 <a href="https://mp.weixin.qq.com/s/zle9-BR-ei1V8Nmul19_7w"><strong>点击进入跳转购买链接</strong></a></p>
<p><br><br></p>
<h2 id="期待合作">期待合作</h2>
<p>cntext目前仍在技术迭代，版本2.0.0综合了训练语言模型&amp;多语言模型对齐， 有较大的应用价值，期待有独特文本数据集交流合作。</p>
<p>通过cntext2.0.0，理论上可以对文本所涉社会主体进行计算，适合企业文化、品牌印象、旅游目的地形象、国家形象等</p>
<ul>
<li>同主体不同时间段， 文本中蕴含的文化态度认知变迁，</li>
<li>或同时间段，不同主体的大样本文本蕴含的差异性</li>
</ul>
<p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>数据集| 07-21年上市公司「委托贷款公告」</title>
      <link>https://textdata.cn/blog/2023-04-26-entrusted-loan-dataset/</link>
      <pubDate>Wed, 26 Apr 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-04-26-entrusted-loan-dataset/</guid>
      <description>沪深A股非金融类上市公司披露的委托贷款公告</description>
      <content:encoded><![CDATA[<h2 id="一数据集概况">一、数据集概况</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">- 数据来源：沪深A股非金融类上市公司披露的委托贷款公告
- 时间跨度：2007—2022年
- 所需指标
  - 贷款提供方和接收方名称
  - 借贷双方股权关联关系
  - 委托贷款金额
  - 利率
  - 贷款期限等借贷条款信息
</code></pre></div><p>数据集不大，只有2297条记录。</p>
<p><img loading="lazy" src="img/01-screen.png" alt=""  />

<img loading="lazy" src="img/02-raw-data.png" alt=""  />
</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">os</span>

<span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<pre><code>['raw_data',
 '委托贷款.csv',
 'img',
 '委托贷款(含有hash_id,跟pdf文件名一致).csv',
 '委托贷款.ipynb',
 '数据说明.txt']
</code></pre>
<p><br><br></p>
<h2 id="二导入数据">二、导入数据</h2>
<ol>
<li>委托贷款.csv</li>
<li>委托贷款(含有hash_id,跟pdf文件名一致).csv 比1多了hash_id</li>
</ol>
<p>两个csv均整理自raw_data, 把很多pdf汇总到csv中。 这两个csv数据差异不大，这里只读取 「委托贷款(含有hash_id,跟pdf文件名一致).csv」。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;委托贷款(含有hash_id,跟pdf文件名一致).csv&#39;</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/df1.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#记录数</span>
<span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">2297
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#不同「公告分类」的记录数</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;公告分类&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">())</span>
</code></pre></div><p><img loading="lazy" src="img/df2.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#「公告年份」的记录数</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;公告年份&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span><span class="o">.</span><span class="n">sort_index</span><span class="p">())</span>
</code></pre></div><p><img loading="lazy" src="img/df3.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#公告的文本长度</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;公告内容&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">len</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">    0        466.0
    1       1026.0
    2       2938.0
    3       3035.0
    4        921.0
             ...  
    2292     456.0
    2293    1116.0
    2294     477.0
    2295    1900.0
    2296    2950.0
    Name: 公告内容, Length: 2297, dtype: float64
</code></pre></div><p><br><br></p>
<h2 id="四数据集获取">四、数据集获取</h2>
<p>转发积攒30 或 30元  加微信372335839， 备注【姓名-学校-专业】</p>
<br>
<p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>数据集(付费) | 2014年-2022年监管问询函</title>
      <link>https://textdata.cn/blog/2023-04-17-china-a-market-inquiry-letter-datasets/</link>
      <pubDate>Mon, 17 Apr 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-04-17-china-a-market-inquiry-letter-datasets/</guid>
      <description>本文只是分享Python代码，大家可以结合之前公众号内的分享，做情感分析、词频统计、情感分析等。</description>
      <content:encoded><![CDATA[<p><strong>问询函</strong>，是指上海证券交易所和深圳证券交易所在审核上市公司相关公告过程中如果发现未达到“直接监管标准”(一般表现为信息披露不准确或内容不全)的问题时，会针对财务报告、并购重组、关联交易、股票异常波动和媒体报道的社会热点等事件发出问询函，要求上市公司在规定时间内书面回函并公开披露。倘若上市公司仍存在信息披露不准确或不全的问题，交易所会再次问询。</p>
<br>
<h2 id="一数据集详情">一、数据集详情</h2>
<p><strong>问询数据集</strong>，有 <strong>13454</strong> 条问询记录， 时间范围  <strong>2014.12~2022.12</strong>, 该数据集xlsx文件有159M 。</p>
<table>
<thead>
<tr>
<th>字段</th>
<th>含义</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>code</strong></td>
<td>股票代码</td>
</tr>
<tr>
<td><strong>corp_name</strong></td>
<td>上市公司简称</td>
</tr>
<tr>
<td><strong>let_cat</strong></td>
<td><strong>监管机构</strong>发出的问询函所属类别</td>
</tr>
<tr>
<td><strong>inq_title</strong></td>
<td>问询函的标题</td>
</tr>
<tr>
<td><strong>inq_content</strong></td>
<td>问询函中询问的具体内容</td>
</tr>
<tr>
<td><strong>reply_content</strong></td>
<td>上市公司回复的详细内容</td>
</tr>
<tr>
<td><strong>inq_date</strong></td>
<td>监管机构发函日期</td>
</tr>
<tr>
<td><strong>ddl_date</strong></td>
<td>规定限期回复日期</td>
</tr>
<tr>
<td><strong>reply_date</strong></td>
<td>公司实际回复日期</td>
</tr>
</tbody>
</table>
<p>本文只是小作演示，大家可以结合之前公众号内的分享，做情感分析、词频统计、情感分析等。</p>
<p><br><br></p>
<h2 id="二导入数据">二、导入数据</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>


<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_excel</span><span class="p">(</span><span class="s1">&#39;监管问询2014-2022.xlsx&#39;</span><span class="p">)</span>  
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/df.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#字段含</span>
<span class="n">df</span><span class="o">.</span><span class="n">columns</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">Index([&#39;code&#39;, &#39;corp_name&#39;, &#39;let_cat&#39;, &#39;inq_title&#39;, &#39;inq_content&#39;,
       &#39;reply_content&#39;, &#39;inq_date&#39;, &#39;ddl_date&#39;, &#39;reply_date&#39;],
          dtype=&#39;object&#39;)
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#数据量</span>
<span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">13454
</code></pre></div><p><br><br></p>
<h2 id="三数据分析">三、数据分析</h2>
<h3 id="31-更改日期格式">3.1 更改日期格式</h3>
<p>将日期字符串数据改为datetime类型数据，即可做日期间隔的计算。这里只演示公司回复日期与监管机构发函日期时间间隔。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df</span><span class="p">[</span><span class="s1">&#39;inq_date&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;inq_date&#39;</span><span class="p">])</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;ddl_date&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;ddl_date&#39;</span><span class="p">])</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;reply_date&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;reply_date&#39;</span><span class="p">])</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;duration1&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;reply_date&#39;</span><span class="p">]</span> <span class="o">-</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;inq_date&#39;</span><span class="p">]</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/df2.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#数据集的时间跨度</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;inq_date&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;inq_date&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">2014-12-04 00:00:00
2022-12-31 00:00:00
</code></pre></div><br>
<h3 id="32-问询量年度变化">3.2 问询量年度变化</h3>
<p>随着我国金融市场发展，监管越来越到位，再加上上市公司会越来越多， 问询量年度变化应该是越来越多。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">matplotlib</span>
<span class="kn">import</span> <span class="nn">matplotlib_inline</span>
<span class="n">matplotlib_inline</span><span class="o">.</span><span class="n">backend_inline</span><span class="o">.</span><span class="n">set_matplotlib_formats</span><span class="p">(</span><span class="s1">&#39;png&#39;</span><span class="p">,</span> <span class="s1">&#39;svg&#39;</span><span class="p">)</span>
<span class="kn">import</span> <span class="nn">scienceplots</span>
<span class="kn">import</span> <span class="nn">platform</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">([</span><span class="s1">&#39;science&#39;</span><span class="p">,</span> <span class="s1">&#39;no-latex&#39;</span><span class="p">,</span> <span class="s1">&#39;cjk-sc-font&#39;</span><span class="p">])</span>
<span class="n">system</span> <span class="o">=</span> <span class="n">platform</span><span class="o">.</span><span class="n">system</span><span class="p">()</span>  <span class="c1"># 获取操作系统类型</span>

<span class="k">if</span> <span class="n">system</span> <span class="o">==</span> <span class="s1">&#39;Windows&#39;</span><span class="p">:</span>
    <span class="n">font</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;family&#39;</span><span class="p">:</span> <span class="s1">&#39;SimHei&#39;</span><span class="p">}</span>
<span class="k">elif</span> <span class="n">system</span> <span class="o">==</span> <span class="s1">&#39;Darwin&#39;</span><span class="p">:</span>
    <span class="n">font</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;family&#39;</span><span class="p">:</span> <span class="s1">&#39;Arial Unicode MS&#39;</span><span class="p">}</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">font</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;family&#39;</span><span class="p">:</span> <span class="s1">&#39;sans-serif&#39;</span><span class="p">}</span>
<span class="n">matplotlib</span><span class="o">.</span><span class="n">rc</span><span class="p">(</span><span class="s1">&#39;font&#39;</span><span class="p">,</span> <span class="o">**</span><span class="n">font</span><span class="p">)</span>  <span class="c1"># 设置全局字体</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>


<span class="n">df</span><span class="p">[</span><span class="s1">&#39;inq_date&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">dt</span><span class="o">.</span><span class="n">year</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span><span class="o">.</span><span class="n">sort_index</span><span class="p">()</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s1">&#39;bar&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;监管机构发起问询量年度变化&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;问询量&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">13</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;年份&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">13</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</code></pre></div><p><img loading="lazy" src="img/output_8_1.svg" alt="svg"  />
</p>
<br>
<h3 id="33-问询回复间隔">3.3 问询回复间隔</h3>
<p>从监管机构发起问询与公司回复之间的时间差， 按道理</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df</span><span class="p">[</span><span class="s1">&#39;duration1&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;duration1&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">dt</span><span class="o">.</span><span class="n">days</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/df3.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">sz_mean</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;code&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;A0&#39;</span><span class="p">)]</span><span class="o">.</span><span class="n">duration1</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="n">sh_mean</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;code&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;A6&#39;</span><span class="p">)]</span><span class="o">.</span><span class="n">duration1</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;深市平均回复时间&#39;</span><span class="p">,</span> <span class="n">sz_mean</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;沪市平均回复时间&#39;</span><span class="p">,</span> <span class="n">sh_mean</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">深市平均回复时间 14.203594945719878
沪市平均回复时间 24.311458333333334
</code></pre></div><p>似乎沪市的上市公司回复的更慢</p>
<br>
<h3 id="34-公司回复问询函速度">3.4 公司回复问询函速度</h3>
<p>公司回复问询函的速度是越来越快还是越来越久？</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;inq_date&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">dt</span><span class="o">.</span><span class="n">year</span><span class="p">)[</span><span class="s1">&#39;duration1&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s1">&#39;line&#39;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;公司为回复监管机构问询函所需准备的时间(单位: 天)&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;准备天数&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">13</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;年份&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">13</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</code></pre></div><p><img loading="lazy" src="img/output_13_1.svg" alt="svg"  />

​</p>
<br>
<h3 id="34-文本长度静态对比">3.4 文本长度静态对比</h3>
<p>不考虑时间，比较沪深问询函内容及回复内容文本长度</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df</span><span class="p">[</span><span class="s1">&#39;inq_len&#39;</span><span class="p">]</span> <span class="o">=</span>  <span class="n">df</span><span class="p">[</span><span class="s1">&#39;inq_content&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">len</span><span class="p">()</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;reply_len&#39;</span><span class="p">]</span> <span class="o">=</span>  <span class="n">df</span><span class="p">[</span><span class="s1">&#39;reply_content&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">len</span><span class="p">()</span>


<span class="n">sz_inq_len_mean</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;code&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;A0&#39;</span><span class="p">)]</span><span class="o">.</span><span class="n">inq_len</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="n">sh_inq_len_mean</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;code&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;A6&#39;</span><span class="p">)]</span><span class="o">.</span><span class="n">inq_len</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;深市-监管机构平均问询函内容长度&#39;</span><span class="p">,</span> <span class="n">sz_inq_len_mean</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;沪市-监管机构平均问询函内容长度&#39;</span><span class="p">,</span> <span class="n">sh_inq_len_mean</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;-&#39;</span><span class="o">*</span><span class="mi">40</span><span class="p">,</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>


<span class="n">sz_reply_len_mean</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;code&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;A0&#39;</span><span class="p">)]</span><span class="o">.</span><span class="n">reply_len</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="n">sh_reply_len_mean</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;code&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;A6&#39;</span><span class="p">)]</span><span class="o">.</span><span class="n">reply_len</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;深市公司平均回复长度&#39;</span><span class="p">,</span> <span class="n">sz_reply_len_mean</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;沪市公司平均回复时间&#39;</span><span class="p">,</span> <span class="n">sh_reply_len_mean</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">
深市-监管机构平均问询函内容长度 1941.5452176578785
沪市-监管机构平均问询函内容长度 2037.675310033822
---------------------------------------- 

深市公司平均回复长度 14070.28757080973
沪市公司平均回复时间 17207.44938271604
</code></pre></div><p>似乎监管机构对沪市公司发起的问询内容更长， 而沪市的上市公司对应回应问询的内容也更长。</p>
<br>
<h3 id="35-随时间文本长度变化">3.5 随时间文本长度变化</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;inq_date&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">dt</span><span class="o">.</span><span class="n">year</span><span class="p">)[</span><span class="s1">&#39;inq_len&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s1">&#39;line&#39;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;监管机构问询函内容长度随时间的变化趋势&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;问询函长度&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;年份&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</code></pre></div><p><img loading="lazy" src="img/output_17_1.svg" alt="svg"  />

​</p>
<br>
<h2 id="数据集获取">数据集获取</h2>
<p>数据整理不易，需要的话， <a href="https://mp.weixin.qq.com/s/0NvFFJvkW2T9mTd1h4KxBw">点击链接进入购买页面</a>， 有疑问，加微信372335839， 备注「姓名-学校-专业」</p>
 <br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>文本分析 | 词典法的两种代码实现</title>
      <link>https://textdata.cn/blog/2023-04-17-two-method-for-liwc/</link>
      <pubDate>Mon, 17 Apr 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-04-17-two-method-for-liwc/</guid>
      <description>但这周末，我使用1.4G的mda数据集， 5w条记录。尝试计算某类词的出现次数， 该词典含几百个词。在我的96G内存的macbook中，运行了十几个小时都没结果。于是同一个问题，本文分享了两种实现方法。一般情况下，使用「方法一」即可。当第一种方法运行不出结果，可以尝试「方法二」。</description>
      <content:encoded><![CDATA[<h2 id="一问题描述">一、问题描述</h2>
<p>对csv、xlsx等类型做词典法分析，经常用到apply方法，但是之前分享到案例数据量比较小， 词典都是几个词， 一般都能运行出结果。</p>
<blockquote>
<p><a href="https://textdata.cn/blog/liwc_python_text_mining/">liwc其实就是一种词典法</a></p>
</blockquote>
<p>但这周末，我使用1.4G的mda数据集， 5w条记录。尝试计算某类词的出现次数， 该词典含几百个词。在我的96G内存的macbook中，运行了十几个小时都没结果。</p>
<p>于是同一个问题，本文分享了两种实现方法。<strong>一般情况下，使用「方法一」即可。当第一种方法运行不出结果，可以尝试「方法二」。</strong></p>
<p><br><br></p>
<h2 id="二方法一">二、方法一</h2>
<h3 id="21-读取数据">2.1 读取数据</h3>
<p>导入含5000条记录的mda数据 test_mda.csv ，这里声明格式，防止年份和股票代码被识别为数字。</p>
<blockquote>
<p>如果想要完整的mda数据，可以前往购买[]</p>
</blockquote>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python">
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="c1">#导入1000条测试数据</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;test_mda.csv&#39;</span><span class="p">,</span> <span class="n">converters</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;year&#39;</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="s1">&#39;code&#39;</span><span class="p">:</span> <span class="nb">str</span><span class="p">})</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/df1.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
</code></pre></div><pre><code>5000
</code></pre>
<br>
<h3 id="22-准备词典">2.2 准备词典</h3>
<p>为了节约时间，也构造了只有几个词语的词典。</p>
<blockquote>
<p>自己随机手写的词典，如果需要应用的自己的研究中, 请将这几个概念词典扩充的完备一些，词汇量尽可能多一些。</p>
</blockquote>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#创新</span>
<span class="n">inovation_words</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;创新&#39;</span><span class="p">,</span> <span class="s1">&#39;科技&#39;</span><span class="p">,</span> <span class="s1">&#39;研发&#39;</span><span class="p">,</span> <span class="s1">&#39;高校&#39;</span><span class="p">,</span> <span class="s1">&#39;技术&#39;</span><span class="p">,</span> <span class="s1">&#39;科学&#39;</span><span class="p">,</span> <span class="s1">&#39;理论&#39;</span><span class="p">,</span> <span class="s1">&#39;专利&#39;</span><span class="p">,</span> <span class="s1">&#39;攻克&#39;</span><span class="p">,</span> <span class="s1">&#39;改良&#39;</span><span class="p">,</span> <span class="s1">&#39;工艺&#39;</span><span class="p">,</span> <span class="s1">&#39;前沿&#39;</span><span class="p">,</span> <span class="s1">&#39;尖端&#39;</span><span class="p">]</span>

<span class="c1">#环保</span>
<span class="n">green_words</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;绿色&#39;</span><span class="p">,</span> <span class="s1">&#39;节能&#39;</span><span class="p">,</span> <span class="s1">&#39;低碳&#39;</span><span class="p">,</span> <span class="s1">&#39;环保&#39;</span><span class="p">,</span> <span class="s1">&#39;环境友好&#39;</span><span class="p">,</span> <span class="s1">&#39;无污染&#39;</span><span class="p">]</span>

<span class="c1">#短视主义</span>
<span class="n">push_words</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;加快&#39;</span><span class="p">,</span> <span class="s1">&#39;尽快&#39;</span><span class="p">,</span> <span class="s1">&#39;抓紧&#39;</span><span class="p">,</span> <span class="s1">&#39;月底&#39;</span><span class="p">,</span> <span class="s1">&#39;年底&#39;</span><span class="p">,</span> <span class="s1">&#39;争取&#39;</span><span class="p">,</span> <span class="s1">&#39;马上&#39;</span><span class="p">,</span> <span class="s1">&#39;立刻&#39;</span><span class="p">,</span> <span class="s1">&#39;年内&#39;</span><span class="p">,</span> <span class="s1">&#39;数月&#39;</span><span class="p">,</span> <span class="s1">&#39;数年&#39;</span><span class="p">]</span>

<span class="c1">#模棱两可</span>

<span class="n">prob_words</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;可能&#39;</span><span class="p">,</span> <span class="s1">&#39;大概&#39;</span><span class="p">,</span> <span class="s1">&#39;左右&#39;</span><span class="p">,</span> <span class="s1">&#39;估计&#39;</span><span class="p">,</span> <span class="s1">&#39;大约&#39;</span><span class="p">]</span>
</code></pre></div><br>
<h3 id="23-设计函数">2.3 设计函数</h3>
<p>该函数能实现对 inovation_words 和  green_words两类词的词频统计;</p>
<p>返回的结果包括总词频、green词频、 inovation词频。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">jieba</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="c1">#创新</span>
<span class="n">inovation_words</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;创新&#39;</span><span class="p">,</span> <span class="s1">&#39;科技&#39;</span><span class="p">,</span> <span class="s1">&#39;研发&#39;</span><span class="p">,</span> <span class="s1">&#39;高校&#39;</span><span class="p">,</span> <span class="s1">&#39;技术&#39;</span><span class="p">,</span> <span class="s1">&#39;科学&#39;</span><span class="p">,</span> <span class="s1">&#39;理论&#39;</span><span class="p">,</span> <span class="s1">&#39;专利&#39;</span><span class="p">,</span> <span class="s1">&#39;攻克&#39;</span><span class="p">,</span> <span class="s1">&#39;改良&#39;</span><span class="p">,</span> <span class="s1">&#39;工艺&#39;</span><span class="p">,</span> <span class="s1">&#39;前沿&#39;</span><span class="p">,</span> <span class="s1">&#39;尖端&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">]</span>
<span class="c1">#环保</span>
<span class="n">green_words</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;绿色&#39;</span><span class="p">,</span> <span class="s1">&#39;节能&#39;</span><span class="p">,</span> <span class="s1">&#39;低碳&#39;</span><span class="p">,</span> <span class="s1">&#39;环保&#39;</span><span class="p">,</span> <span class="s1">&#39;环境友好&#39;</span><span class="p">,</span> <span class="s1">&#39;无污染&#39;</span><span class="p">]</span>
<span class="c1">#短视主义</span>
<span class="n">push_words</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;加快&#39;</span><span class="p">,</span> <span class="s1">&#39;尽快&#39;</span><span class="p">,</span> <span class="s1">&#39;抓紧&#39;</span><span class="p">,</span> <span class="s1">&#39;月底&#39;</span><span class="p">,</span> <span class="s1">&#39;年底&#39;</span><span class="p">,</span> <span class="s1">&#39;争取&#39;</span><span class="p">,</span> <span class="s1">&#39;马上&#39;</span><span class="p">,</span> <span class="s1">&#39;立刻&#39;</span><span class="p">,</span> <span class="s1">&#39;年内&#39;</span><span class="p">,</span> <span class="s1">&#39;数月&#39;</span><span class="p">,</span> <span class="s1">&#39;数年&#39;</span><span class="p">]</span>
<span class="c1">#模棱两可</span>
<span class="n">prob_words</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;可能&#39;</span><span class="p">,</span> <span class="s1">&#39;大概&#39;</span><span class="p">,</span> <span class="s1">&#39;左右&#39;</span><span class="p">,</span> <span class="s1">&#39;估计&#39;</span><span class="p">,</span> <span class="s1">&#39;大约&#39;</span><span class="p">]</span>


<span class="k">def</span> <span class="nf">analysis_info</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="n">inovation_num</span><span class="p">,</span> <span class="n">green_num</span><span class="p">,</span> <span class="n">push_num</span><span class="p">,</span> <span class="n">prob_num</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span>
    <span class="n">words</span> <span class="o">=</span> <span class="n">jieba</span><span class="o">.</span><span class="n">lcut</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
    <span class="n">push_num</span> 
    
    <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">inovation_words</span><span class="p">:</span>
        <span class="n">inovation_num</span> <span class="o">=</span> <span class="n">inovation_num</span> <span class="o">+</span> <span class="n">words</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">green_words</span><span class="p">:</span>
        <span class="n">green_num</span> <span class="o">=</span> <span class="n">green_num</span> <span class="o">+</span> <span class="n">words</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>
        
    <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">push_words</span><span class="p">:</span>
        <span class="n">push_num</span> <span class="o">=</span> <span class="n">push_num</span> <span class="o">+</span> <span class="n">words</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>
        
    <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">prob_words</span><span class="p">:</span>
        <span class="n">prob_num</span> <span class="o">=</span> <span class="n">prob_num</span> <span class="o">+</span> <span class="n">words</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>
        
    <span class="n">res</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;words&#39;</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">words</span><span class="p">),</span>
        <span class="s1">&#39;inovation&#39;</span><span class="p">:</span> <span class="n">inovation_num</span><span class="p">,</span>
        <span class="s1">&#39;green&#39;</span><span class="p">:</span> <span class="n">green_num</span><span class="p">,</span>
        <span class="s1">&#39;push&#39;</span><span class="p">:</span> <span class="n">push_num</span><span class="p">,</span>
        <span class="s1">&#39;prob&#39;</span><span class="p">:</span> <span class="n">prob_num</span>
    <span class="p">}</span>
    
    <span class="k">return</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">res</span><span class="p">)</span>

<span class="n">analysis_info</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="s1">&#39;2022年是公司规范运作，坚持科技创新，保持持续发展。&#39;</span><span class="p">)</span>
</code></pre></div><pre><code>words        15
inovation     2
green         0
push          0
prob          0
dtype: int64
</code></pre>
<br>
<h3 id="24-批量计算">2.4 批量计算</h3>
<p>选中text列，对该列批量运行 analysis_info 。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">time</span>

<span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

<span class="n">info_df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">analysis_info</span><span class="p">)</span>
<span class="n">res_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">df</span><span class="p">,</span> <span class="n">info_df</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">end</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;耗时 </span><span class="si">{}</span><span class="s1"> s&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">end</span><span class="o">-</span><span class="n">start</span><span class="p">)))</span>

<span class="n">res_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>

</code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">耗时 112 s
</code></pre></div><p><img loading="lazy" src="img/df2.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="三方法二">三、方法二</h2>
<p>将中文分词后， 使用bag-of-words构造词语词频矩阵</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span> 
<span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">CountVectorizer</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">jieba</span>

<span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

<span class="n">df</span><span class="p">[</span><span class="s1">&#39;new_text&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">text</span><span class="p">:</span> <span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">jieba</span><span class="o">.</span><span class="n">cut</span><span class="p">(</span><span class="n">text</span><span class="p">)))</span>

<span class="n">vectorize</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">()</span>
<span class="n">dtm</span> <span class="o">=</span> <span class="n">vectorize</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">new_text</span><span class="p">)</span>
<span class="n">bagofword_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">dtm</span><span class="o">.</span><span class="n">toarray</span><span class="p">(),</span> 
                            <span class="n">columns</span><span class="o">=</span><span class="n">vectorize</span><span class="o">.</span><span class="n">get_feature_names_out</span><span class="p">())</span> 


<span class="c1">#创新</span>
<span class="n">inovation_words</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;创新&#39;</span><span class="p">,</span> <span class="s1">&#39;科技&#39;</span><span class="p">,</span> <span class="s1">&#39;研发&#39;</span><span class="p">,</span> <span class="s1">&#39;高校&#39;</span><span class="p">,</span> <span class="s1">&#39;技术&#39;</span><span class="p">,</span> <span class="s1">&#39;科学&#39;</span><span class="p">,</span> <span class="s1">&#39;理论&#39;</span><span class="p">,</span> <span class="s1">&#39;专利&#39;</span><span class="p">,</span> <span class="s1">&#39;攻克&#39;</span><span class="p">,</span> <span class="s1">&#39;改良&#39;</span><span class="p">,</span> <span class="s1">&#39;工艺&#39;</span><span class="p">,</span> <span class="s1">&#39;前沿&#39;</span><span class="p">,</span> <span class="s1">&#39;尖端&#39;</span><span class="p">]</span>
<span class="c1">#环保</span>
<span class="n">green_words</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;绿色&#39;</span><span class="p">,</span> <span class="s1">&#39;节能&#39;</span><span class="p">,</span> <span class="s1">&#39;低碳&#39;</span><span class="p">,</span> <span class="s1">&#39;环保&#39;</span><span class="p">,</span> <span class="s1">&#39;环境友好&#39;</span><span class="p">,</span> <span class="s1">&#39;无污染&#39;</span><span class="p">]</span>
<span class="c1">#短视主义</span>
<span class="n">push_words</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;加快&#39;</span><span class="p">,</span> <span class="s1">&#39;尽快&#39;</span><span class="p">,</span> <span class="s1">&#39;抓紧&#39;</span><span class="p">,</span> <span class="s1">&#39;月底&#39;</span><span class="p">,</span> <span class="s1">&#39;年底&#39;</span><span class="p">,</span> <span class="s1">&#39;争取&#39;</span><span class="p">,</span> <span class="s1">&#39;马上&#39;</span><span class="p">,</span> <span class="s1">&#39;立刻&#39;</span><span class="p">,</span> <span class="s1">&#39;年内&#39;</span><span class="p">,</span> <span class="s1">&#39;数月&#39;</span><span class="p">,</span> <span class="s1">&#39;数年&#39;</span><span class="p">]</span>
<span class="c1">#模棱两可</span>
<span class="n">prob_words</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;可能&#39;</span><span class="p">,</span> <span class="s1">&#39;大概&#39;</span><span class="p">,</span> <span class="s1">&#39;左右&#39;</span><span class="p">,</span> <span class="s1">&#39;估计&#39;</span><span class="p">,</span> <span class="s1">&#39;大约&#39;</span><span class="p">]</span>

<span class="n">INOVATION_WORDS</span> <span class="o">=</span> <span class="p">[</span><span class="n">w</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">inovation_words</span> <span class="k">if</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">bagofword_df</span><span class="o">.</span><span class="n">columns</span><span class="p">]</span>
<span class="n">GREEN_WORDS</span> <span class="o">=</span> <span class="p">[</span><span class="n">w</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">green_words</span> <span class="k">if</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">bagofword_df</span><span class="o">.</span><span class="n">columns</span><span class="p">]</span>
<span class="n">PUSH_WORDS</span> <span class="o">=</span> <span class="p">[</span><span class="n">w</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">push_words</span> <span class="k">if</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">bagofword_df</span><span class="o">.</span><span class="n">columns</span><span class="p">]</span>
<span class="n">PROB_WORDS</span> <span class="o">=</span> <span class="p">[</span><span class="n">w</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">prob_words</span> <span class="k">if</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">bagofword_df</span><span class="o">.</span><span class="n">columns</span><span class="p">]</span>

<span class="n">data</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;year&#39;</span><span class="p">:</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;year&#39;</span><span class="p">],</span>
        <span class="s1">&#39;code&#39;</span><span class="p">:</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;code&#39;</span><span class="p">],</span>
        <span class="s1">&#39;text&#39;</span><span class="p">:</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">],</span>
        
        <span class="s1">&#39;inovation&#39;</span><span class="p">:</span> <span class="n">bagofword_df</span><span class="p">[</span><span class="n">INOVATION_WORDS</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
        <span class="s1">&#39;green&#39;</span><span class="p">:</span> <span class="n">bagofword_df</span><span class="p">[</span><span class="n">GREEN_WORDS</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
        <span class="s1">&#39;push&#39;</span><span class="p">:</span> <span class="n">bagofword_df</span><span class="p">[</span><span class="n">PUSH_WORDS</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
        <span class="s1">&#39;prob&#39;</span><span class="p">:</span> <span class="n">bagofword_df</span><span class="p">[</span><span class="n">PROB_WORDS</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
        <span class="s1">&#39;words&#39;</span><span class="p">:</span> <span class="n">bagofword_df</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="nb">sum</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="p">}</span>


<span class="n">res_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">end</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;耗时 </span><span class="si">{}</span><span class="s1"> s&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">end</span><span class="o">-</span><span class="n">start</span><span class="p">)))</span>

<span class="n">res_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>

</code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">耗时 164 s
</code></pre></div><p><img loading="lazy" src="img/df2.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="四讨论">四、讨论</h2>
<p>analysis_info(text) 函数内含有4个for循环，for循环是效率很低的操作。 随着所要计算的词典数n的增加， 方法一时间会随着n的增长而线性增长。</p>
<p>而方法二， 最费时间的瓶颈是将文本转化为数字(比较费时间)，后续的计算均为向量化(矩阵化)的数值计算，随着词典数n的增加， 所消耗的时间会越来越短。</p>
<p><strong>一般情况下，使用「方法一」即可。当第一种方法运行不出结果，可以尝试「方法二」。</strong></p>
<p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>不要当真 | 词云图看婚姻的本质是什么</title>
      <link>https://textdata.cn/blog/2023-04-14-what-is-the-nature-of-marriage/</link>
      <pubDate>Fri, 14 Apr 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-04-14-what-is-the-nature-of-marriage/</guid>
      <description>&lt;h2 id=&#34;背景&#34;&gt;背景&lt;/h2&gt;
&lt;p&gt;今天在知乎刷到「婚姻的本质是什么?」。&lt;/p&gt;
&lt;p&gt;绝大多数回答都是跟私有产权、生产关系相关，直到有一个回答&lt;strong&gt;整个婚姻法里也没有关于爱情的只言片语，从头到尾就一个字，钱，所以婚姻本质上就是契约&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;一下子想到用词频统计试一下， 看看民法典婚姻家庭部分和非婚姻家庭部分两部分内容的侧重点分别是什么。&lt;/p&gt;
&lt;br&gt;
&lt;h2 id=&#34;数据准备&#34;&gt;数据准备&lt;/h2&gt;
&lt;p&gt;民法典章节目录如下， 把「第五编　婚姻家庭」单独拿出来做「&lt;a href=&#34;marital-relationship.txt&#34;&gt;婚姻家庭内容&lt;/a&gt;」， 剩下的内容做「&lt;a href=&#34;non-marital-relationship.txt&#34;&gt;非婚姻家庭内容&lt;/a&gt;」。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;- 第一编　总则
  - 第一章　基本规定
  - 第二章　自然人
  - 第三章　法人
  - 第四章　非法人组织
  - 第五章　民事权利
  - 第六章　民事法律行为
  - 第七章　代理
  - 第八章　民事责任
  - 第九章　诉讼时效
  - 第十章　期间计算
  
- 第二编　物权
  - 第一分编　通则
     - 第一章　一般规定
     - 第二章　物权的设立、变更、转让和消灭
     - 第三章　物权的保护
  - 第二分编　所有权
  - 第三分编　用益物权
  - 第四分编　担保物权
  - 第五分编　占有

- 第三编　合同
  - 第一分编　通则 
  - 第二分编　典型合同
  - 第三分编　准合同

- 第四编　人格权
    - 第一章　一般规定
    - 第二章　生命权、身体权和健康权
    - 第三章　姓名权和名称权
    - 第四章　肖像权
    - 第五章　名誉权和荣誉权
    - 第六章　隐私权和个人信息保护

- 第五编　婚姻家庭
   - 第一章　一般规定
   - 第二章　结婚
   - 第三章　家庭关系
       - 第一节　夫妻关系
       - 第二节　父母子女关系和其他近亲属关系
   - 第四章　离婚
   - 第五章　收养
      - 第一节　收养关系的成立
      - 第二节　收养的效力
      - 第三节　收养关系的解除
      
- 第六编　继承
   - 第一章　一般规定
   - 第二章　法定继承
   - 第三章　遗嘱继承和遗赠
   - 第四章　遗产的处理

- 第七编　侵权责任
   - 第一章　一般规定
   - 第二章　损害赔偿
   - 第三章　责任主体的特殊规定
   - 第四章　产品责任
   - 第五章　机动车交通事故责任
   - 第六章　医疗损害责任
   - 第七章　环境污染和生态破坏责任
   - 第八章　高度危险责任
   - 第九章　饲养动物损害责任
   - 第十章　建筑物和物件损害责任
- 附则
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h2 id=&#34;读取数据&#34;&gt;读取数据&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;c1&#34;&gt;#第五编　婚姻家庭&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;marital_relationship_text&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;open&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;marital-relationship.txt&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;encoding&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;utf-8&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;span class=&#34;c1&#34;&gt;#不含【第五编　婚姻家庭】其余部分&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;non_marital_relationship_text&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;open&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;non-marital-relationship.txt&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;encoding&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;utf-8&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;marital_relationship_text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[:&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;500&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;&#39;第五编\u3000婚姻家庭\n第一章\u3000一般规定\n第一千零四十条\u3000本编调整因婚姻家庭产生的民事关系。\n第一千零四十一条\u3000婚姻家庭受国家保护。\n实行婚姻自由、一夫一妻、男女平等的婚姻制度。\n保护妇女、未成年人、老年人、残疾人的合法权益。\n第一千零四十二条\u3000禁止包办、买卖婚姻和其他干涉婚姻自由的行为。禁止借婚姻索取财物。\n禁止重婚。禁止有配偶者与他人同居。\n禁止家庭暴力。禁止家庭成员间的虐待和遗弃。\n第一千零四十三条\u3000家庭应当树立优良家风，弘扬家庭美德，重视家庭文明建设。\n夫妻应当互相忠实，互相尊重，互相关爱；家庭成员应当敬老爱幼，互相帮助，维护平等、和睦、文明的婚姻家庭关系。\n第一千零四十四条\u3000收养应当遵循最有利于被收养人的原则，保障被收养人和收养人的合法权益。\n禁止借收养名义买卖未成年人。\n第一千零四十五条\u3000亲属包括配偶、血亲和姻亲。\n配偶、父母、子女、兄弟姐妹、祖父母、外祖父母、孙子女、外孙子女为近亲属。\n配偶、父母、子女和其他共同生活的近亲属为家庭成员。\n第二章\u3000结婚\n第一千零四十六条\u3000结婚应当男女双方完全自愿，禁止任何一方对另一方加以强迫，禁止任何组织或者个人加以干涉。\n第一千零四十七条\u3000结婚&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;cntext&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;ct&lt;/span&gt;

&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ct&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;__version__&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;#词频统计&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;civil_code_word_count&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ct&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;term_freq&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;civil_code_text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;marital_relationship_word_count&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ct&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;term_freq&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;marital_relationship_text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;non_marital_relationship_word_count&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ct&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;term_freq&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;non_marital_relationship_text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h2 id=&#34;词云图&#34;&gt;词云图&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pyecharts.options&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;opts&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pyecharts.charts&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;WordCloud&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;random&lt;/span&gt;


&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;plot_wordcloud&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wordcounts&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;title&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;wordcounts&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;w&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;str&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;w&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;f&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;wordcounts&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;items&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()]&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;wc&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;WordCloud&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;wc&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;add&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;series_name&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;data_pair&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wordcounts&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;word_size_range&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1000&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;wc&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;set_global_opts&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
        &lt;span class=&#34;n&#34;&gt;title_opts&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;opts&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;TitleOpts&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;title&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;title&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;title_textstyle_opts&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;opts&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;TextStyleOpts&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;font_size&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;23&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
                                 &lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;
        &lt;span class=&#34;n&#34;&gt;tooltip_opts&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;opts&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;TooltipOpts&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;is_show&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
    &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;wc&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;render_notebook&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;


&lt;span class=&#34;n&#34;&gt;plot_wordcloud&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wordcounts&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;marital_relationship_word_count&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
               &lt;span class=&#34;n&#34;&gt;title&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;民法典-婚姻家庭部分&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/marriage.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;plot_wordcloud&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wordcounts&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;non_marital_relationship_word_count&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
               &lt;span class=&#34;n&#34;&gt;title&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;民法典-非婚姻部分的&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/non-marriage.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;h2 id=&#34;不可当真的实验&#34;&gt;不可当真的实验&lt;/h2&gt;
&lt;p&gt;这里仅仅仅是一个实验，结果不可当真。毕竟使用性质的不同数据做分析，得出的结论可能会完全相反。&lt;/p&gt;
&lt;br&gt;
&lt;h2 id=&#34;广而告之&#34;&gt;广而告之&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/call_for_paper/&#34;&gt;长期征稿&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/we_need_you/&#34;&gt;长期招募小伙伴&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/management_python_course/&#34;&gt;付费视频课 | Python实证指标构建与文本分析&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
      <content:encoded><![CDATA[<h2 id="背景">背景</h2>
<p>今天在知乎刷到「婚姻的本质是什么?」。</p>
<p>绝大多数回答都是跟私有产权、生产关系相关，直到有一个回答<strong>整个婚姻法里也没有关于爱情的只言片语，从头到尾就一个字，钱，所以婚姻本质上就是契约</strong>。</p>
<p>一下子想到用词频统计试一下， 看看民法典婚姻家庭部分和非婚姻家庭部分两部分内容的侧重点分别是什么。</p>
<br>
<h2 id="数据准备">数据准备</h2>
<p>民法典章节目录如下， 把「第五编　婚姻家庭」单独拿出来做「<a href="marital-relationship.txt">婚姻家庭内容</a>」， 剩下的内容做「<a href="non-marital-relationship.txt">非婚姻家庭内容</a>」。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">- 第一编　总则
  - 第一章　基本规定
  - 第二章　自然人
  - 第三章　法人
  - 第四章　非法人组织
  - 第五章　民事权利
  - 第六章　民事法律行为
  - 第七章　代理
  - 第八章　民事责任
  - 第九章　诉讼时效
  - 第十章　期间计算
  
- 第二编　物权
  - 第一分编　通则
     - 第一章　一般规定
     - 第二章　物权的设立、变更、转让和消灭
     - 第三章　物权的保护
  - 第二分编　所有权
  - 第三分编　用益物权
  - 第四分编　担保物权
  - 第五分编　占有

- 第三编　合同
  - 第一分编　通则 
  - 第二分编　典型合同
  - 第三分编　准合同

- 第四编　人格权
    - 第一章　一般规定
    - 第二章　生命权、身体权和健康权
    - 第三章　姓名权和名称权
    - 第四章　肖像权
    - 第五章　名誉权和荣誉权
    - 第六章　隐私权和个人信息保护

- 第五编　婚姻家庭
   - 第一章　一般规定
   - 第二章　结婚
   - 第三章　家庭关系
       - 第一节　夫妻关系
       - 第二节　父母子女关系和其他近亲属关系
   - 第四章　离婚
   - 第五章　收养
      - 第一节　收养关系的成立
      - 第二节　收养的效力
      - 第三节　收养关系的解除
      
- 第六编　继承
   - 第一章　一般规定
   - 第二章　法定继承
   - 第三章　遗嘱继承和遗赠
   - 第四章　遗产的处理

- 第七编　侵权责任
   - 第一章　一般规定
   - 第二章　损害赔偿
   - 第三章　责任主体的特殊规定
   - 第四章　产品责任
   - 第五章　机动车交通事故责任
   - 第六章　医疗损害责任
   - 第七章　环境污染和生态破坏责任
   - 第八章　高度危险责任
   - 第九章　饲养动物损害责任
   - 第十章　建筑物和物件损害责任
- 附则
</code></pre></div><br>
<h2 id="读取数据">读取数据</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#第五编　婚姻家庭</span>
<span class="n">marital_relationship_text</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;marital-relationship.txt&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
<span class="c1">#不含【第五编　婚姻家庭】其余部分</span>
<span class="n">non_marital_relationship_text</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;non-marital-relationship.txt&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>

<span class="n">marital_relationship_text</span><span class="p">[:</span><span class="mi">500</span><span class="p">]</span>
</code></pre></div><pre><code>'第五编\u3000婚姻家庭\n第一章\u3000一般规定\n第一千零四十条\u3000本编调整因婚姻家庭产生的民事关系。\n第一千零四十一条\u3000婚姻家庭受国家保护。\n实行婚姻自由、一夫一妻、男女平等的婚姻制度。\n保护妇女、未成年人、老年人、残疾人的合法权益。\n第一千零四十二条\u3000禁止包办、买卖婚姻和其他干涉婚姻自由的行为。禁止借婚姻索取财物。\n禁止重婚。禁止有配偶者与他人同居。\n禁止家庭暴力。禁止家庭成员间的虐待和遗弃。\n第一千零四十三条\u3000家庭应当树立优良家风，弘扬家庭美德，重视家庭文明建设。\n夫妻应当互相忠实，互相尊重，互相关爱；家庭成员应当敬老爱幼，互相帮助，维护平等、和睦、文明的婚姻家庭关系。\n第一千零四十四条\u3000收养应当遵循最有利于被收养人的原则，保障被收养人和收养人的合法权益。\n禁止借收养名义买卖未成年人。\n第一千零四十五条\u3000亲属包括配偶、血亲和姻亲。\n配偶、父母、子女、兄弟姐妹、祖父母、外祖父母、孙子女、外孙子女为近亲属。\n配偶、父母、子女和其他共同生活的近亲属为家庭成员。\n第二章\u3000结婚\n第一千零四十六条\u3000结婚应当男女双方完全自愿，禁止任何一方对另一方加以强迫，禁止任何组织或者个人加以干涉。\n第一千零四十七条\u3000结婚'
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>

<span class="nb">print</span><span class="p">(</span><span class="n">ct</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span>

<span class="c1">#词频统计</span>
<span class="n">civil_code_word_count</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">term_freq</span><span class="p">(</span><span class="n">civil_code_text</span><span class="p">)</span>
<span class="n">marital_relationship_word_count</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">term_freq</span><span class="p">(</span><span class="n">marital_relationship_text</span><span class="p">)</span>
<span class="n">non_marital_relationship_word_count</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">term_freq</span><span class="p">(</span><span class="n">non_marital_relationship_text</span><span class="p">)</span>
</code></pre></div><br>
<h2 id="词云图">词云图</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pyecharts.options</span> <span class="k">as</span> <span class="nn">opts</span>
<span class="kn">from</span> <span class="nn">pyecharts.charts</span> <span class="kn">import</span> <span class="n">WordCloud</span>
<span class="kn">import</span> <span class="nn">random</span>


<span class="k">def</span> <span class="nf">plot_wordcloud</span><span class="p">(</span><span class="n">wordcounts</span><span class="p">,</span> <span class="n">title</span><span class="p">):</span>
    <span class="n">wordcounts</span> <span class="o">=</span> <span class="p">[(</span><span class="n">w</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">f</span><span class="p">))</span> <span class="k">for</span> <span class="n">w</span><span class="p">,</span><span class="n">f</span> <span class="ow">in</span> <span class="n">wordcounts</span><span class="o">.</span><span class="n">items</span><span class="p">()]</span>
    <span class="n">wc</span> <span class="o">=</span> <span class="n">WordCloud</span><span class="p">()</span>
    <span class="n">wc</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">series_name</span><span class="o">=</span><span class="s2">&#34;&#34;</span><span class="p">,</span> <span class="n">data_pair</span><span class="o">=</span><span class="n">wordcounts</span><span class="p">,</span> <span class="n">word_size_range</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1000</span><span class="p">])</span>
    <span class="n">wc</span><span class="o">.</span><span class="n">set_global_opts</span><span class="p">(</span>
        <span class="n">title_opts</span><span class="o">=</span><span class="n">opts</span><span class="o">.</span><span class="n">TitleOpts</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="n">title</span><span class="p">,</span> <span class="n">title_textstyle_opts</span><span class="o">=</span><span class="n">opts</span><span class="o">.</span><span class="n">TextStyleOpts</span><span class="p">(</span><span class="n">font_size</span><span class="o">=</span><span class="mi">23</span><span class="p">)</span>
                                 <span class="p">),</span>
        <span class="n">tooltip_opts</span><span class="o">=</span><span class="n">opts</span><span class="o">.</span><span class="n">TooltipOpts</span><span class="p">(</span><span class="n">is_show</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">wc</span><span class="o">.</span><span class="n">render_notebook</span><span class="p">()</span>


<span class="n">plot_wordcloud</span><span class="p">(</span><span class="n">wordcounts</span><span class="o">=</span><span class="n">marital_relationship_word_count</span><span class="p">,</span> 
               <span class="n">title</span><span class="o">=</span><span class="s1">&#39;民法典-婚姻家庭部分&#39;</span><span class="p">)</span>
</code></pre></div><p><img loading="lazy" src="img/marriage.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">plot_wordcloud</span><span class="p">(</span><span class="n">wordcounts</span><span class="o">=</span><span class="n">non_marital_relationship_word_count</span><span class="p">,</span> 
               <span class="n">title</span><span class="o">=</span><span class="s1">&#39;民法典-非婚姻部分的&#39;</span><span class="p">)</span>
</code></pre></div><p><img loading="lazy" src="img/non-marriage.png" alt=""  />
</p>
<br>
<h2 id="不可当真的实验">不可当真的实验</h2>
<p>这里仅仅仅是一个实验，结果不可当真。毕竟使用性质的不同数据做分析，得出的结论可能会完全相反。</p>
<br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>数据集 | 3571万条专利申请数据集(1985-2022年)</title>
      <link>https://textdata.cn/blog/2023-04-13-3571w-patent-dataset-in-china-mainland/</link>
      <pubDate>Thu, 13 Apr 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-04-13-3571w-patent-dataset-in-china-mainland/</guid>
      <description>3571万专利申请全量数据(1985-2022年)数据</description>
      <content:encoded><![CDATA[<h2 id="相关推文">相关推文</h2>
<p><a href="https://textdata.cn/blog/2023-04-26-matching-listed-corporate-with-patent-dataset/">从3571w条专利数据集「匹配」上市公司的专利信息</a></p>
<p><a href="https://textdata.cn/blog/2023-11-17-how-handle-mega-csv-that-far-exceed-memory/">推荐 | 如何处理远超电脑内存的csv文件</a></p>
<p><br><br></p>
<p>3571万专利申请全量数据(<strong>1985.01 ~ 2022.5</strong>)数据，解压后整个文件夹大概 20 G。</p>
<p><img loading="lazy" src="img/screen-datasets.png" alt=""  />
</p>
<br>
<p>为了方便各位下载，对数据进行了压缩，压缩后整个文件夹体积大概20G</p>
<p><img loading="lazy" src="img/screen-datasets2.png" alt=""  />
</p>
<br>
<h2 id="一数据介绍">一、数据介绍</h2>
<h3 id="11-数据集概况">1.1 数据集概况</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">- 数据集名称：省份版知识产权局专利
- 时间跨度：1985.1-2022.5，专利申请总量3571万
- 数据来源：『国家知识产权局』
- 数据整理: 『公众号:大邓和他的Python』
</code></pre></div><br>
<h3 id="12-分省统计">1.2 分省统计</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">| 省份(区域)       |  专利数  |
| :---------------| :------ |
| 广东省           | 5728705 |
| 江苏省           | 4879171 |
| 浙江省           | 3706820 |
| 山东省           | 2064446 |
| 北京市           | 2069913 |
| 四川省           | 1159551 |
| 天津市           | 712932  |
| 上海市           | 1548278 |
| 贵州省           | 265512  |
| 陕西省           | 655837  |
| 吉林省           | 232264  |
| 辽宁省           | 637853  |
| 湖北省           | 966384  |
| 山西省           | 233418  |
| 宁夏回族自治区    | 66919   |
| 西藏自治区        | 9911    |
| 广西壮族自治区    | 377658  |
| 江西省           | 519584  |
| 湖南省           | 743828  |
| 黑龙江省         | 357881  |
| 海南省           | 59202   |
| 福建省           | 1046473 |
| 安徽省           | 1342364 |
| 河北省           | 645420  |
| 重庆市           | 592382  |
| 内蒙古自治区      | 133277  |
| 云南省           | 252407  |
| 甘肃省           | 164274  |
| 新疆维吾尔自治区   | 124734  |
| 河南省           | 966477  |
| 青海省           | 34127   |
| 台湾省           | 401555  |
| 香港特别行政区    | 61636   |
| 澳门特别行政区    | 2010    |
| 其他国家         | 2948557 |
</code></pre></div><br>
<h3 id="13-字段">1.3 字段</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"> -  专利公开号
 -  专利名称
 -  专利类型
 -  专利摘要
 -  申请人(自然人、法人；可以是多个主题并列，用;间隔申请人主体)
 -  专利申请号
 -  申请日
 -  申请公布日
 -  授权公布号
 -  授权公布日
 -  申请地址
 -  主权项
 -  发明人
 -  分类号
 -  主分类号
 -  代理机构
 -  分案原申请号
 -  优先权
 -  国际申请
 -  国际公布
 -  代理人
 -  省份或国家代码
 -  法律状态
 -  专利领域
 -  专利学科
 -  多次公布
</code></pre></div><p><br><br></p>
<h2 id="二实验代码">二、实验代码</h2>
<h3 id="21-读取数据">2.1 读取数据</h3>
<p>数据集中的个别csv文件较大，例如 <strong>广东省.csv.gzip</strong>体积2.66G , 解压得到的 <strong>广东省.csv</strong> 10G。 建议直接读取.csv.gzip，这样会节省内存消耗。需要注意每次分析时不要开其他软件，如Word/PPT/Excel/WPS。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;河北省.csv.gzip&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">,</span> <span class="n">compression</span><span class="o">=</span><span class="s1">&#39;gzip&#39;</span><span class="p">,</span> <span class="n">low_memory</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="c1">#df = pd.read_csv(&#39;河北省.csv&#39;, encoding=&#39;utf-8&#39;, low_memory=False)</span>

<span class="n">df</span><span class="p">[</span><span class="s1">&#39;申请日&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;申请日&#39;</span><span class="p">])</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p>Run
<img loading="lazy" src="img/df.png" alt=""  />
</p>
<br>
<h3 id="22-记录数">2.2 记录数</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;河北省: &#39;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">))</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">河北省: 645420
</code></pre></div><br>
<h3 id="2-3-覆盖日期">2. 3 覆盖日期</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;申请日&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;申请日&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">1985-01-28 00:00:00
2022-05-24 00:00:00
</code></pre></div><br>
<h3 id="24-字段">2.4 字段</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df</span><span class="o">.</span><span class="n">columns</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">Index([&#39;专利公开号&#39;, &#39;专利名称&#39;, &#39;专利类型&#39;, &#39;专利摘要&#39;, 
&#39;申请人&#39;, &#39;专利申请号&#39;, &#39;申请日&#39;, &#39;申请公布日&#39;, 
&#39;授权公布号&#39;, &#39;授权公布日&#39;, &#39;申请地址&#39;, &#39;主权项&#39;, &#39;发明人&#39;,
&#39;分类号&#39;, &#39;主分类号&#39;, &#39;代理机构&#39;, &#39;分案原申请号&#39;, &#39;优先权&#39;, 
&#39;国际申请&#39;, &#39;国际公布&#39;, &#39;代理人&#39;, &#39;省份或国家代码&#39;,
&#39;法律状态&#39;, &#39;专利领域&#39;, &#39;专利学科&#39;, &#39;多次公布&#39;],
dtype=&#39;object&#39;)
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df</span><span class="p">[</span><span class="s1">&#39;专利类型&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">实用新型 361832
发明公开 155084
外观设计 107905
发明授权 20599
</code></pre></div><p><br><br></p>
<h2 id="三可视化">三、可视化</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="c1">#为减轻内存压力，可以选择需要的字段读取</span>
<span class="n">cols</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;申请日&#39;</span><span class="p">,</span> <span class="s1">&#39;授权公布日&#39;</span><span class="p">]</span>

<span class="c1">#读取数据</span>
<span class="n">guangdong_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;广东省.csv.gzip&#39;</span><span class="p">,</span> <span class="n">compression</span><span class="o">=</span><span class="s1">&#39;gzip&#39;</span><span class="p">,</span> <span class="n">usecols</span><span class="o">=</span><span class="n">cols</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">,</span> <span class="n">low_memory</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">jiangsu_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;江苏省.csv.gzip&#39;</span><span class="p">,</span> <span class="n">compression</span><span class="o">=</span><span class="s1">&#39;gzip&#39;</span><span class="p">,</span> <span class="n">usecols</span><span class="o">=</span><span class="n">cols</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">,</span> <span class="n">low_memory</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">shandong_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;山东省.csv.gzip&#39;</span><span class="p">,</span> <span class="n">compression</span><span class="o">=</span><span class="s1">&#39;gzip&#39;</span><span class="p">,</span> <span class="n">usecols</span><span class="o">=</span><span class="n">cols</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">,</span> <span class="n">low_memory</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">zhejiang_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;浙江省.csv.gzip&#39;</span><span class="p">,</span> <span class="n">compression</span><span class="o">=</span><span class="s1">&#39;gzip&#39;</span><span class="p">,</span> <span class="n">usecols</span><span class="o">=</span><span class="n">cols</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">,</span> <span class="n">low_memory</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">beijing_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;北京市.csv.gzip&#39;</span><span class="p">,</span> <span class="n">compression</span><span class="o">=</span><span class="s1">&#39;gzip&#39;</span><span class="p">,</span> <span class="n">usecols</span><span class="o">=</span><span class="n">cols</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">,</span> <span class="n">low_memory</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">shanghai_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;上海市.csv.gzip&#39;</span><span class="p">,</span> <span class="n">compression</span><span class="o">=</span><span class="s1">&#39;gzip&#39;</span><span class="p">,</span> <span class="n">usecols</span><span class="o">=</span><span class="n">cols</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">,</span> <span class="n">low_memory</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1">#显示前5行</span>
<span class="n">shanghai_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/df2.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">matplotlib</span>
<span class="kn">import</span> <span class="nn">matplotlib_inline</span>
<span class="n">matplotlib_inline</span><span class="o">.</span><span class="n">backend_inline</span><span class="o">.</span><span class="n">set_matplotlib_formats</span><span class="p">(</span><span class="s1">&#39;png&#39;</span><span class="p">,</span> <span class="s1">&#39;svg&#39;</span><span class="p">)</span>
<span class="kn">import</span> <span class="nn">scienceplots</span>
<span class="kn">import</span> <span class="nn">platform</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">([</span><span class="s1">&#39;science&#39;</span><span class="p">,</span> <span class="s1">&#39;no-latex&#39;</span><span class="p">,</span> <span class="s1">&#39;cjk-sc-font&#39;</span><span class="p">])</span>
<span class="n">system</span> <span class="o">=</span> <span class="n">platform</span><span class="o">.</span><span class="n">system</span><span class="p">()</span>  <span class="c1"># 获取操作系统类型</span>

<span class="k">if</span> <span class="n">system</span> <span class="o">==</span> <span class="s1">&#39;Windows&#39;</span><span class="p">:</span>
    <span class="n">font</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;family&#39;</span><span class="p">:</span> <span class="s1">&#39;SimHei&#39;</span><span class="p">}</span>
<span class="k">elif</span> <span class="n">system</span> <span class="o">==</span> <span class="s1">&#39;Darwin&#39;</span><span class="p">:</span>
    <span class="n">font</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;family&#39;</span><span class="p">:</span> <span class="s1">&#39;Arial Unicode MS&#39;</span><span class="p">}</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">font</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;family&#39;</span><span class="p">:</span> <span class="s1">&#39;sans-serif&#39;</span><span class="p">}</span>
<span class="n">matplotlib</span><span class="o">.</span><span class="n">rc</span><span class="p">(</span><span class="s1">&#39;font&#39;</span><span class="p">,</span> <span class="o">**</span><span class="n">font</span><span class="p">)</span>  <span class="c1"># 设置全局字体</span>
    
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">years</span> <span class="o">=</span> <span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2000</span><span class="p">,</span> <span class="mi">2020</span><span class="p">)]</span>


<span class="n">guangdong_df</span><span class="p">[</span><span class="s1">&#39;申请日&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">slice</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="n">years</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;广东&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">jiangsu_df</span><span class="p">[</span><span class="s1">&#39;申请日&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">slice</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="n">years</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;江苏&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">zhejiang_df</span><span class="p">[</span><span class="s1">&#39;申请日&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">slice</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="n">years</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;浙江&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">shandong_df</span><span class="p">[</span><span class="s1">&#39;申请日&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">slice</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="n">years</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;山东&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">beijing_df</span><span class="p">[</span><span class="s1">&#39;申请日&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">slice</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="n">years</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;北京&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">shanghai_df</span><span class="p">[</span><span class="s1">&#39;申请日&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">slice</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="n">years</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;上海&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">hebei_df</span><span class="p">[</span><span class="s1">&#39;申请日&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">slice</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="n">years</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;河北&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>



<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;七省市专利申请量(2000年-2019年)&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;年份(按申请日统计)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;申请量&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper right&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>    
</code></pre></div><p><img loading="lazy" src="img/output_7_0.png" alt=""  />
</p>
<ul>
<li>
<p>2012年， 申请量开始下降， 直至2014年，触底反弹。这个时期国内外宏观经济发生了什么？</p>
</li>
<li>
<p>不考虑人口规模， 在专利申请量可以看出广东、江苏、浙江体量还是比北京、上海、河北要高的。</p>
</li>
<li>
<p>2015年开始， 广东触底反弹后， 拉开了与江苏、浙江的体量。</p>
</li>
</ul>
<p><br><br></p>
<h2 id="四获取数据">四、获取数据</h2>
<p>内容为付费数据集，100元， 加微信 372335839， 备注「姓名-学校-专业」。</p>
<p><br><br></p>
<h2 id="五相关文献">五、相关文献</h2>
<p>使用专利数据做研究的文献</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">[1]Bellstam, Gustaf, Sanjai Bhagat, and J. Anthony Cookson. &#34;A text-based analysis of corporate innovation.&#34; _Management Science_ 67, no. 7 (2021): 4004-4031.
[2]Arts, Sam, Bruno Cassiman, and Jianan Hou. &#34;Position and Differentiation of Firms in Technology Space.&#34; Management Science (2023).
</code></pre></div><p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>数据集 | 3.9G 全国POI地点兴趣点数据集</title>
      <link>https://textdata.cn/blog/2023-04-12-china-poi-datasets/</link>
      <pubDate>Wed, 12 Apr 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-04-12-china-poi-datasets/</guid>
      <description>POI是英文&amp;#34;Point of Interest&amp;#34;的缩写，中文翻译为&amp;#34;兴趣点&amp;#34;或&amp;#34;兴趣地点&amp;#34;。在地理信息系统（GIS）和位置服务领域中，POI通常指代一些在地图上显示的特定地点或地理位置，例如商店、餐厅、公园、景点等。</description>
      <content:encoded><![CDATA[<p>POI是英文&quot;Point of Interest&quot;的缩写，中文翻译为&quot;兴趣点&quot;或&quot;兴趣地点&quot;。在地理信息系统（GIS）和位置服务领域中，POI通常指代一些在地图上显示的特定地点或地理位置，例如商店、餐厅、公园、景点等。</p>
<p>与之前分享的 <a href="https://textdata.cn/blog/2023-04-12-china-mainland-corporate-registration-information/"><strong>数据集 | 2亿条中国大陆工商企业注册信息</strong></a> ，可以结合起来使用。</p>
<br>
<h2 id="一数据集概况">一、数据集概况</h2>
<p>370个地市， 截止2022年12月份的POI数据集。压缩文件夹体积800M，解压3.9G。</p>
<p><img loading="lazy" src="img/size.png" alt=""  />
</p>
<p><img loading="lazy" src="img/code.png" alt=""  />
</p>
<p>解压后， 在「<strong>全国POI数据(2022年12月)</strong>」文件夹内新建一个 「<strong>代码.ipynb</strong>」，运行如下代码查看文件夹内的文件列表</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">glob</span>

<span class="c1"># 查询</span>
<span class="n">files</span> <span class="o">=</span> <span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="s1">&#39;*/*.csv&#39;</span><span class="p">)</span>
<span class="n">files</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">    [
    &#39;北京POI数据/北京市POI数据.csv&#39;,
    &#39;浙江省POI数据/杭州市POI数据.csv&#39;, 
     &#39;吉林省POI数据/长春市POI数据.csv&#39;,
     &#39;陕西省POI数据/西安市POI数据.csv&#39;,
     &#39;江苏省POI数据/南京市POI数据.csv&#39;,
     &#39;山东省POI数据/青岛市POI数据.csv&#39;,
     &#39;湖南省POI数据/长沙市POI数据.csv&#39;,
     &#39;辽宁省POI数据/大连市POI数据.csv&#39;,
     ...
     &#39;河北省POI数据/衡水市POI数据.csv&#39;,
    ]
</code></pre></div><br>
<p>地级市csv文件个数</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="nb">len</span><span class="p">(</span><span class="n">files</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">370
</code></pre></div><br>
<h2 id="二读取poi数据">二、读取POI数据</h2>
<p>读取北京、天津、青岛、上海、广州、杭州、长沙这几个城市poi数据(大家可以根据自己的兴趣更改城市)</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">bj_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;北京POI数据/北京市POI数据.csv&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span>
<span class="n">qd_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;山东省POI数据/青岛市POI数据.csv&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span>
<span class="n">tj_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;天津市POI数据/天津市POI数据.csv&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span>


<span class="n">sh_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;上海POI数据/上海市POI数据.csv&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span>
<span class="n">gz_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;广东省POI数据/广州市POI数据.csv&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span>
<span class="n">hz_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;浙江省POI数据/杭州市POI数据.csv&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span>
<span class="n">cs_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;湖南省POI数据/长沙市POI数据.csv&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span>


<span class="n">hz_df</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</code></pre></div><p><img loading="lazy" src="img/df.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#该文件poi记录数</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;北京poi记录数: &#39;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">bj_df</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;天津poi记录数: &#39;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">tj_df</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;青岛poi记录数: &#39;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">qd_df</span><span class="p">))</span>

<span class="nb">print</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;上海poi记录数: &#39;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">sh_df</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;广州poi记录数: &#39;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">gz_df</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;杭州poi记录数: &#39;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">hz_df</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;长沙poi记录数: &#39;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">cs_df</span><span class="p">))</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">    北京poi记录数:  679413
    天津poi记录数:  409020
    青岛poi记录数:  426314
    
    上海poi记录数:  780347
    广州poi记录数:  793056
    杭州poi记录数:  534595
    长沙poi记录数:  406489
</code></pre></div><br>
<h2 id="三简单分析">三、简单分析</h2>
<p>对比北京、天津、青岛、上海、广州、杭州、长沙这几个城市poi大类占比情况，探索性分析， 大家可以根据自己的兴趣更改城市</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">matplotlib</span>
<span class="kn">import</span> <span class="nn">matplotlib_inline</span>
<span class="n">matplotlib_inline</span><span class="o">.</span><span class="n">backend_inline</span><span class="o">.</span><span class="n">set_matplotlib_formats</span><span class="p">(</span><span class="s1">&#39;png&#39;</span><span class="p">,</span> <span class="s1">&#39;svg&#39;</span><span class="p">)</span>
<span class="kn">import</span> <span class="nn">scienceplots</span>
<span class="kn">import</span> <span class="nn">platform</span>

<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">([</span><span class="s1">&#39;science&#39;</span><span class="p">,</span> <span class="s1">&#39;no-latex&#39;</span><span class="p">,</span> <span class="s1">&#39;cjk-sc-font&#39;</span><span class="p">])</span>
<span class="n">system</span> <span class="o">=</span> <span class="n">platform</span><span class="o">.</span><span class="n">system</span><span class="p">()</span>  <span class="c1"># 获取操作系统类型</span>

<span class="k">if</span> <span class="n">system</span> <span class="o">==</span> <span class="s1">&#39;Windows&#39;</span><span class="p">:</span>
    <span class="n">font</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;family&#39;</span><span class="p">:</span> <span class="s1">&#39;SimHei&#39;</span><span class="p">}</span>
<span class="k">elif</span> <span class="n">system</span> <span class="o">==</span> <span class="s1">&#39;Darwin&#39;</span><span class="p">:</span>
    <span class="n">font</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;family&#39;</span><span class="p">:</span> <span class="s1">&#39;Arial Unicode MS&#39;</span><span class="p">}</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">font</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;family&#39;</span><span class="p">:</span> <span class="s1">&#39;sans-serif&#39;</span><span class="p">}</span>
<span class="n">matplotlib</span><span class="o">.</span><span class="n">rc</span><span class="p">(</span><span class="s1">&#39;font&#39;</span><span class="p">,</span> <span class="o">**</span><span class="n">font</span><span class="p">)</span>  <span class="c1"># 设置全局字体</span>




<span class="c1"># 统计各城市的大类POI数量</span>
<span class="n">bj_poi_count</span> <span class="o">=</span> <span class="n">bj_df</span><span class="p">[</span><span class="s1">&#39;大类&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">tj_poi_count</span> <span class="o">=</span> <span class="n">tj_df</span><span class="p">[</span><span class="s1">&#39;大类&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">qd_poi_count</span> <span class="o">=</span> <span class="n">qd_df</span><span class="p">[</span><span class="s1">&#39;大类&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>


<span class="n">sh_poi_count</span> <span class="o">=</span> <span class="n">sh_df</span><span class="p">[</span><span class="s1">&#39;大类&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">hz_poi_count</span> <span class="o">=</span> <span class="n">hz_df</span><span class="p">[</span><span class="s1">&#39;大类&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">gz_poi_count</span> <span class="o">=</span> <span class="n">gz_df</span><span class="p">[</span><span class="s1">&#39;大类&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">cs_poi_count</span> <span class="o">=</span> <span class="n">cs_df</span><span class="p">[</span><span class="s1">&#39;大类&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>



<span class="c1"># 创建一个包含所有城市的分组条形图</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="c1"># 计算每个城市的条形图位置</span>
<span class="n">bar_width</span> <span class="o">=</span> <span class="mf">0.07</span>

<span class="n">bar_positions</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">bj_poi_count</span><span class="p">))</span>

<span class="n">bj_bars</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">bar_positions</span><span class="p">,</span> 
                 <span class="n">bj_poi_count</span><span class="p">,</span> 
                 <span class="n">width</span><span class="o">=</span><span class="n">bar_width</span><span class="p">,</span> 
                 <span class="n">label</span><span class="o">=</span><span class="s1">&#39;北京&#39;</span><span class="p">)</span>


<span class="n">tj_bars</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">bar</span><span class="p">([</span><span class="n">p</span> <span class="o">+</span> <span class="n">bar_width</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">bar_positions</span><span class="p">],</span> 
                 <span class="n">tj_poi_count</span><span class="p">,</span> 
                 <span class="n">width</span><span class="o">=</span><span class="n">bar_width</span><span class="p">,</span> 
                 <span class="n">label</span><span class="o">=</span><span class="s1">&#39;天津&#39;</span><span class="p">)</span>


<span class="n">qd_bars</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">bar</span><span class="p">([</span><span class="n">p</span> <span class="o">+</span> <span class="mi">2</span><span class="o">*</span><span class="n">bar_width</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">bar_positions</span><span class="p">],</span> 
                 <span class="n">dl_poi_count</span><span class="p">,</span> 
                 <span class="n">width</span><span class="o">=</span><span class="n">bar_width</span><span class="p">,</span> 
                 <span class="n">label</span><span class="o">=</span><span class="s1">&#39;青岛&#39;</span><span class="p">)</span>


<span class="n">sh_bars</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">bar</span><span class="p">([</span><span class="n">p</span> <span class="o">+</span> <span class="mi">3</span><span class="o">*</span><span class="n">bar_width</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">bar_positions</span><span class="p">],</span> 
                 <span class="n">sh_poi_count</span><span class="p">,</span> 
                 <span class="n">width</span><span class="o">=</span><span class="n">bar_width</span><span class="p">,</span> 
                 <span class="n">label</span><span class="o">=</span><span class="s1">&#39;上海&#39;</span><span class="p">)</span>


<span class="n">hz_bars</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">bar</span><span class="p">([</span><span class="n">p</span> <span class="o">+</span> <span class="mi">4</span> <span class="o">*</span> <span class="n">bar_width</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">bar_positions</span><span class="p">],</span> 
                 <span class="n">hz_poi_count</span><span class="p">,</span> 
                 <span class="n">width</span><span class="o">=</span><span class="n">bar_width</span><span class="p">,</span> 
                 <span class="n">label</span><span class="o">=</span><span class="s1">&#39;杭州&#39;</span><span class="p">)</span>

<span class="n">gz_bars</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">bar</span><span class="p">([</span><span class="n">p</span> <span class="o">+</span> <span class="mi">5</span> <span class="o">*</span> <span class="n">bar_width</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">bar_positions</span><span class="p">],</span> 
                 <span class="n">gz_poi_count</span><span class="p">,</span> 
                 <span class="n">width</span><span class="o">=</span><span class="n">bar_width</span><span class="p">,</span> 
                 <span class="n">label</span><span class="o">=</span><span class="s1">&#39;广州&#39;</span><span class="p">)</span>


<span class="n">cs_bars</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">bar</span><span class="p">([</span><span class="n">p</span> <span class="o">+</span> <span class="mi">6</span> <span class="o">*</span> <span class="n">bar_width</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">bar_positions</span><span class="p">],</span> 
                 <span class="n">cs_poi_count</span><span class="p">,</span> 
                 <span class="n">width</span><span class="o">=</span><span class="n">bar_width</span><span class="p">,</span> 
                 <span class="n">label</span><span class="o">=</span><span class="s1">&#39;长沙&#39;</span><span class="p">)</span>


<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;POI地理兴趣点城市比较&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;POI大类&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;POI类别占比&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">([</span><span class="n">p</span> <span class="o">+</span> <span class="n">bar_width</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">bar_positions</span><span class="p">])</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xticklabels</span><span class="p">(</span><span class="n">bj_poi_count</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>  <span class="c1"># 添加图例</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/output_8_0.svg" alt="svg"  />
</p>
<p>7个城市中，从poi大类占比来看，</p>
<ul>
<li>交通设施&amp;科教文化&amp;休闲娱乐&amp;运动健身&amp;金融机构&amp;旅游景点， 北京位列top1</li>
<li>购物消费， 长沙位列top1</li>
<li>餐饮美食， 广州位列top1</li>
<li>生活服务&amp;公司企业， 上海位列top1</li>
<li>酒店住宿， 杭州位列top1</li>
<li>汽车相关， 天津位列top1</li>
</ul>
<br>
<h2 id="数据获取">数据获取</h2>
<p><a href="https://mp.weixin.qq.com/s/YA1MdUUe9fntV6d6nN6Z6g">付费内容， 点击链接进入跳转页面</a> 有疑问，加微信372335839， 备注「姓名-学校-专业」</p>
<br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>中文心理词典，含具体性、可成象性等指标</title>
      <link>https://textdata.cn/blog/2023-04-05-chinese-concreteness-dictionary-from-behavior-research-method/</link>
      <pubDate>Wed, 05 Apr 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-04-05-chinese-concreteness-dictionary-from-behavior-research-method/</guid>
      <description>该研究建立了一个**汉字书写的心理语言学数据库**。该数据库挑选出了1600个频率分布广泛的汉字，采用听写任务，总共203名被试来书写这些汉字，采集了被试的书写潜伏期、书写时长、书写正确率，并收集了1600汉字的14个词汇变量。研究结果发现，字频、习得年龄、语境是影响正字法通达、运动执行和书写正确率的共同因素；语音变量（是否为形声字、规则性、同音字密度）影响正字法通达，但不影响运动执行；语义变量（表象性和具体性）只影响书写正确率。研究结果对汉字书写产生机制有着重要启发。作为第一个大规模的汉字书写的心理语言学数据库，该数据库可以作为二次数据分析的资源以及书写实验材料制作的工具</description>
      <content:encoded><![CDATA[<p>之前分享过 <a href="https://textdata.cn/blog/jcr_concreteness_computation/"><strong>JCR的一篇语言具体性</strong></a>的研究应用，<strong>语言具体性Concreteness</strong>描述了一个词在多大程度上是指一个实际的、有形的或“真实的”实体，以一种更具体、更熟悉、更容易被眼睛或心灵感知的方式描述对象和行为。但是具体性词典是英文的。今天分享的这篇论文是1600个词，含具体性和表象性词典。</p>
<br>
<p>Wang, Ruiming, Shuting Huang, Yacong Zhou, and Zhenguang G. Cai. &ldquo;Chinese character handwriting: A large-scale behavioral study and a database.&rdquo; Behavior Research Methods 52 (2020): 82-96.</p>
<br>
<h2 id="摘要">摘要</h2>
<p>该研究建立了一个<strong>汉字书写的心理语言学数据库</strong>。该数据库挑选出了1600个频率分布广泛的汉字，采用听写任务，总共203名被试来书写这些汉字，采集了被试的书写潜伏期、书写时长、书写正确率，并收集了1600汉字的14个词汇变量。研究结果发现，字频、习得年龄、语境是影响正字法通达、运动执行和书写正确率的共同因素；语音变量（是否为形声字、规则性、同音字密度）影响正字法通达，但不影响运动执行；语义变量（表象性和具体性）只影响书写正确率。研究结果对汉字书写产生机制有着重要启发。作为第一个大规模的汉字书写的心理语言学数据库，该数据库可以作为二次数据分析的资源以及书写实验材料制作的工具。数据库免费公开，访问网址为：https://osf.io/7s9kq/。</p>
<br>
<h2 id="字段">字段</h2>
<p>字段有很多，我挑选最重要的翻译过来。</p>
<table>
<thead>
<tr>
<th style="text-align:right">Item</th>
<th style="text-align:left">Item number of characters</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right">Character</td>
<td style="text-align:left">中文单字</td>
</tr>
<tr>
<td style="text-align:right">Word</td>
<td style="text-align:left">由该字组成的词语</td>
</tr>
<tr>
<td style="text-align:right">&hellip;</td>
<td style="text-align:left">&hellip;</td>
</tr>
<tr>
<td style="text-align:right"><strong>zImageability</strong></td>
<td style="text-align:left">可成像性（归一化评分）</td>
</tr>
<tr>
<td style="text-align:right"><strong>zConcreteness</strong></td>
<td style="text-align:left">具体性（归一化评分)</td>
</tr>
<tr>
<td style="text-align:right">&hellip;</td>
<td style="text-align:left">&hellip;</td>
</tr>
</tbody>
</table>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_excel</span><span class="p">(</span><span class="s1">&#39;Database.xlsx&#39;</span><span class="p">,</span> <span class="n">sheet_name</span><span class="o">=</span><span class="s1">&#39;Data&#39;</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">columns</span>
</code></pre></div><p>Run</p>
<pre><code>Index(['Item', 'Character', 'Word', 'nOccurrence', 'nACC', 'nMisheard', 'nTOP',
       'nMisspelt', 'nMisremembered', 'ACC', 'Misheard', 'TOP', 'Misspelt',
       'Misremembered', 'Latency_Correct', 'Duration_Correct', 'Latency_z',
       'Duration_z', 'FreqCount', 'FreqContext', 'AoA', 'nMeaning',
       'zImageability', 'zConcreteness', 'Phonogram', 'SRO', 'zRegularity',
       'logHomoDen', 'nStroke', 'nRadical', 'Comp_LR', 'Comp_TD',
       'zwFamiliarity'],
      dtype='object')
</code></pre>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df</span><span class="p">[[</span><span class="s1">&#39;Character&#39;</span><span class="p">,</span> <span class="s1">&#39;Word&#39;</span><span class="p">,</span> <span class="s1">&#39;zConcreteness&#39;</span><span class="p">,</span> <span class="s1">&#39;zImageability&#39;</span><span class="p">]]</span>
</code></pre></div><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Character</th>
      <th>Word</th>
      <th>zConcreteness</th>
      <th>zImageability</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>哀</td>
      <td>悲哀</td>
      <td>-0.103212</td>
      <td>0.404177</td>
    </tr>
    <tr>
      <th>1</th>
      <td>癌</td>
      <td>癌症</td>
      <td>0.319844</td>
      <td>0.176291</td>
    </tr>
    <tr>
      <th>2</th>
      <td>疤</td>
      <td>伤疤</td>
      <td>1.180032</td>
      <td>0.919010</td>
    </tr>
    <tr>
      <th>3</th>
      <td>白</td>
      <td>明白</td>
      <td>0.691302</td>
      <td>0.527291</td>
    </tr>
    <tr>
      <th>4</th>
      <td>百</td>
      <td>一百</td>
      <td>-0.234004</td>
      <td>-0.039290</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>1595</th>
      <td>组</td>
      <td>小组</td>
      <td>-0.556125</td>
      <td>-0.326855</td>
    </tr>
    <tr>
      <th>1596</th>
      <td>钻</td>
      <td>钻石</td>
      <td>0.412641</td>
      <td>0.116090</td>
    </tr>
    <tr>
      <th>1597</th>
      <td>嘴</td>
      <td>住嘴</td>
      <td>1.447112</td>
      <td>0.846971</td>
    </tr>
    <tr>
      <th>1598</th>
      <td>醉</td>
      <td>麻醉</td>
      <td>0.297512</td>
      <td>0.596776</td>
    </tr>
    <tr>
      <th>1599</th>
      <td>作</td>
      <td>工作</td>
      <td>-0.817521</td>
      <td>-0.933269</td>
    </tr>
  </tbody>
</table>
<p>1600 rows × 4 columns</p>
</div>
<br>
## 广而告之
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>词向量(付费) | 使用MD&amp;A2001-2022语料训练Word2Vec模型</title>
      <link>https://textdata.cn/blog/2023-03-24-load-w2v-and-expand-your-concpet-dicitonary/</link>
      <pubDate>Fri, 24 Mar 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-03-24-load-w2v-and-expand-your-concpet-dicitonary/</guid>
      <description>&lt;h2 id=&#34;相关内容&#34;&gt;相关内容&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/the_text_analysis_list_about_ms/&#34;&gt;LIST | 社科(经管)文本挖掘文献汇总&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/text_analysis_code_list_about_ms/&#34;&gt;LIST | 文本分析代码汇总&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/datasets_available_for_management_science/&#34;&gt;LIST | 可供社科(经管)领域使用的数据集&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/management_python_course/&#34;&gt;Python实证指标构建与文本分析&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/2023-11-20-word2vec-by-year-by-province/&#34;&gt;使用3751w专利申请数据集按年份(按省份)训练词向量&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/2023-11-10-training-word2vec-model-using-china-3751w-patent-application-dataset/&#34;&gt;预训练模型 | 使用1000w专利摘要训练word2vec模型，可用于开发词典&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;相关文献&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;[0]刘景江,郑畅然,洪永淼.机器学习如何赋能管理学研究？——国内外前沿综述和未来展望[J].管理世界,2023,39(09):191-216.
[1]冉雅璇,李志强,刘佳妮,张逸石.大数据时代下社会科学研究方法的拓展——基于词嵌入技术的文本分析的应用[J].南开管理评论:1-27.
[3]胡楠,薛付婧,王昊楠.管理者短视主义影响企业长期投资吗？——基于文本分析和机器学习[J].管理世界,2021,37(05):139-156+11+19-21.
[4]Kai Li, Feng Mai, Rui Shen, Xinyan Yan, Measuring Corporate Culture Using Machine Learning, *The Review of Financial Studies*,2020
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;一训练&#34;&gt;一、训练&lt;/h2&gt;
&lt;h3 id=&#34;11-导入mda数据&#34;&gt;1.1 导入mda数据&lt;/h3&gt;
&lt;p&gt;读取2001-2022年的&lt;strong&gt;管理层讨论与分析mda&lt;/strong&gt;数据&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pandas&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pd&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read_excel&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;mda01-22.xlsx&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;head&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;55439
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/df.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;12-构造语料&#34;&gt;1.2 构造语料&lt;/h3&gt;
&lt;p&gt;从 &lt;strong&gt;mda01-22.xlsx&lt;/strong&gt; 数据中抽取出所有文本，写入到 &lt;strong&gt;mda01-22.txt&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;k&#34;&gt;with&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;open&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;mda01-22.txt&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;a+&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;encoding&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;utf-8&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;text&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;join&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;text&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;write&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h3 id=&#34;13-配置cntext环境&#34;&gt;1.3 配置cntext环境&lt;/h3&gt;
&lt;p&gt;使用2.0.0版本cntext库(该版本暂不开源，需付费购买)。 将得到的 &lt;strong&gt;cntext-2.0.0-py3-none-any.whl&lt;/strong&gt; 文件放置于电脑桌面，  win系统打开&lt;strong&gt;cmd&lt;/strong&gt;(Mac打开terminal)， 输入如下命令(将工作环境切换至桌面)&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;cd desktop
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;个别Win用户如无效，试试&lt;code&gt;cd Desktop&lt;/code&gt; 。&lt;/p&gt;
&lt;p&gt;继续在cmd (terminal) 中执行如下命令安装cntext2.0.0&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;pip3 install cntext-2.0.0-py3-none-any.whl 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h3 id=&#34;14-训练word2vec&#34;&gt;1.4 训练word2vec&lt;/h3&gt;
&lt;p&gt;设置模型参数配置&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;mda01-22 使用2001-2022年度mda数据训练&lt;/li&gt;
&lt;li&gt;200 嵌入的维度数，即每个词的向量长度是200&lt;/li&gt;
&lt;li&gt;6 词语上下文的窗口是6&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;o&#34;&gt;%%&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;time&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;#程序结束后，可查看总的运行时间&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;cntext&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;ct&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;w2v&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ct&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;W2VModel&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;corpus_file&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;mda01-22.txt&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;w2v&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;train&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;vector_size&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;200&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;window_size&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;6&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;min_count&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;6&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;save_dir&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;Word2Vec&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;Building prefix dict from the default dictionary ...
Start Preprocessing Corpus...
Dumping model to file cache /var/folders/y0/4gqxky0s2t94x1c1qhlwr6100000gn/T/jieba.cache
Loading model cost 0.278 seconds.
Prefix dict has been built successfully.
Start Training! This may take a while. Please be patient...

Training word2vec model took 3532 seconds

Note: The Word2Vec model has been saved to output/Word2Vec

CPU times: user 1h 30min 45s, sys: 30.1 s, total: 1h 31min 15s
Wall time: 58min 57s
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;经过不到两个小时时间， 训练出的中国A股市场词向量模型(如下截图)，词汇量 914058， 模型文件 1.49G。模型可广泛用于经济管理等领域概念(情感)词典的构建或扩展。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;mda01-22.200.6.bin&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;mda01-22.200.6.bin.syn1neg.npy&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;mda01-22.200.6.bin.wv.vectors.npy&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/pretained-screen.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;为什么这样确定200和6，可以看这篇 &lt;a href=&#34;https://textdata.cn/blog/2023-03-15-39faq-about-word-embeddings-for-social-science&#34;&gt;词嵌入技术在社会科学领域进行数据挖掘常见39个FAQ汇总&lt;/a&gt;&lt;/p&gt;
&lt;br&gt;
&lt;br&gt;
&lt;h2 id=&#34;二导入模型&#34;&gt;二、导入模型&lt;/h2&gt;
&lt;p&gt;需要用到两个自定义函数load_w2v、expand_dictionary，源代码太长，为了提高阅读体验， 放在文末。大家记得用这两个函数前一定要先导入。&lt;a href=&#34;mda_pretained_model_code.ipynb&#34;&gt;&lt;strong&gt;点击代码&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;c1&#34;&gt;#先导入load_w2v、expand_dictionary函数源代码&lt;/span&gt;


&lt;span class=&#34;c1&#34;&gt;#读取模型文件&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;w2v_model&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;load_w2v&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;w2v_path&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;Word2Vec/mda01-21.200.6.bin&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;w2v_model&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Loading word2vec model...
&amp;lt;gensim.models.word2vec.Word2Vec at 0x310dd9990&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;br&gt;
&lt;h2 id=&#34;注意&#34;&gt;注意&lt;/h2&gt;
&lt;p&gt;之前购买过mda01-21.100.6.bin的可以留意下， &amp;lt;gensim.models.word2vec.Word2Vec&amp;gt;和&amp;lt;gensim.models.keyedvectors.KeyedVectors&amp;gt;
是有区别的。&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h3 id=&#34;三w2v_model的使用&#34;&gt;三、w2v_model的使用&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;查看词汇量&lt;/li&gt;
&lt;li&gt;查询某词向量&lt;/li&gt;
&lt;li&gt;查看多个词的均值向量&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;更多内容，建议查看下gensim库的文档&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;c1&#34;&gt;#词汇量&lt;/span&gt;
&lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;w2v_model&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;index_to_key&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;914058  
&lt;/code&gt;&lt;/pre&gt;
&lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;c1&#34;&gt;#查询某词的词向量&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;w2v_model&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;get_vector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;创新&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;array([-1.36441350e-01, -2.02002168e+00, -1.49168205e+00,  2.65202689e+00,
        1.49721682e+00,  2.14851022e+00, -1.54925853e-01, -2.25241160e+00,
       -3.58773202e-01,  1.54530525e+00, -7.62950361e-01, -9.77181852e-01,
        6.70365512e-01, -3.20203233e+00,  3.18079638e+00,  1.66510820e+00,
        9.80131567e-01,  1.62199986e+00,  1.80585206e+00,  4.08179426e+00,
       -1.26518166e+00,  3.75929743e-01,  5.72038591e-01,  1.16134119e+00,
        2.55617023e+00, -2.25110960e+00, -2.61538339e+00, -5.71992218e-01,
        8.70356798e-01, -1.85045290e+00, -2.85597444e-01, -9.15628672e-01,
       -2.03667688e+00,  2.11716801e-01,  2.94088912e+00, -2.32688546e+00,
        2.20858502e+00,  8.81347775e-01, -7.99135566e-01, -8.61206651e-01,
       -4.45446587e+00, -1.73757005e+00, -3.36678886e+00, -2.82611530e-02,
       -1.62726247e+00, -8.49750221e-01,  4.13731128e-01, -1.62519825e+00,
        3.03865957e+00, -1.39746085e-01,  8.22233260e-01, -7.97697455e-02,
        1.72468078e+00,  2.94929433e+00,  9.72453177e-01, -1.12741642e-01,
        8.18425417e-01, -9.05264139e-01,  2.61516261e+00,  8.02830994e-01,
        2.40420485e+00,  8.85799348e-01, -1.08665645e+00,  8.21912348e-01,
       -4.39456075e-01, -2.57663131e+00,  2.38062453e+00, -4.58515882e-01,
        2.12767506e+00, -2.01356173e-01,  2.71096081e-01,  9.51708496e-01,
       -3.05705309e+00, -6.06385887e-01, -1.38406023e-01,  2.36809158e+00,
       -2.49158549e+00,  2.71105647e+00, -3.07211792e-03,  1.04273570e+00,
        1.44201803e+00, -5.65704823e-01,  2.85488725e-01,  1.43495277e-01,
       -1.39421299e-01,  9.24086392e-01,  4.25374925e-01, -1.56690669e+00,
        1.67641795e+00, -1.03729677e+00, -1.45472065e-01, -2.11022258e+00,
       -1.81541741e+00, -8.66766050e-02,  8.72350857e-02,  1.17173791e+00,
       -3.07721123e-02,  5.84330797e-01,  1.47265148e+00, -1.76913440e+00,
       -8.48391712e-01, -3.25056529e+00,  7.14846313e-01, -2.98076987e-01,
        1.13966620e+00, -1.42698896e+00,  6.93505168e-01, -2.04717040e+00,
       -1.53559577e+00,  1.01942134e+00, -1.58283603e+00,  9.08654630e-01,
       -1.90529859e+00, -9.43309963e-01,  4.12964225e-01, -2.50713086e+00,
       -4.24056143e-01, -4.10613680e+00,  3.60615468e+00, -4.19765860e-01,
       -2.41174579e+00,  6.80675328e-01,  2.99834704e+00,  1.05610855e-01,
       -7.84325838e-01,  3.24065971e+00, -1.85072863e+00, -2.12448812e+00,
       -2.83468294e+00, -5.77759802e-01, -3.13433480e+00, -6.91670418e-01,
        2.99401569e+00, -5.16145706e-01,  9.09552336e-01, -5.52680910e-01,
       -2.88360894e-01,  1.11991334e+00, -1.11737549e+00,  1.15479147e+00,
       -4.63319182e-01,  1.38351321e+00, -3.02179503e+00,  1.24334955e+00,
        1.93393975e-01, -8.27962995e-01, -2.37227559e+00, -9.26931739e-01,
        6.72517180e-01,  1.27736795e+00,  1.98695862e+00,  1.41960573e+00,
       -3.73892736e+00, -3.14201683e-01, -7.19093859e-01,  1.86080355e-02,
       -2.68105698e+00,  1.04344964e+00,  9.46133554e-01, -2.06151366e+00,
       -2.84214950e+00,  1.17004764e+00,  1.24577022e+00, -1.10806060e+00,
        9.93207514e-01,  8.46789181e-01, -3.09691691e+00,  2.12616014e+00,
       -1.49274826e+00, -1.53214395e+00, -9.95470941e-01,  1.23463202e+00,
       -2.18907285e+00, -4.94913310e-01,  2.80939412e+00,  1.68149090e+00,
        1.48991072e+00,  3.83729649e+00,  4.72325265e-01,  1.37606680e+00,
        2.14257884e+00,  3.18186909e-01,  5.98093605e+00,  1.46744043e-01,
       -2.37729326e-01,  1.20463884e+00, -1.55812174e-01, -5.03088772e-01,
        4.53981996e-01,  1.95544350e+00, -2.32564354e+00, -4.09389853e-01,
        1.89125270e-01,  2.62835431e+00,  9.81123984e-01, -9.51041043e-01,
       -1.14294410e-01,  1.10983588e-01,  9.30419266e-02, -9.84693542e-02],
      dtype=float32)
&lt;/code&gt;&lt;/pre&gt;
&lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;c1&#34;&gt;#查询多个词的词向量&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;w2v_model&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;get_mean_vector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;([&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;创新&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;研发&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Ruj&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;array([ 0.03019853, -0.01928307, -0.05371316,  0.00053774,  0.02516318,
        0.10103251, -0.03914721, -0.08307559,  0.00444389,  0.09456791,
       -0.05761364, -0.03459097,  0.04394419, -0.10181106,  0.1418381 ,
        0.05334964,  0.01820264,  0.01493831,  0.01626587,  0.17402864,
       -0.02859601,  0.04538149,  0.03768233,  0.05431981,  0.15405464,
       -0.03632693, -0.08566202, -0.00595666,  0.08378439, -0.11071078,
       -0.05904576, -0.06451955, -0.1076955 ,  0.05141645,  0.11710279,
       -0.09403889,  0.08633652, -0.06743232,  0.00328483,  0.01589498,
       -0.11226317, -0.05367877, -0.057222  , -0.00685401, -0.04531868,
       -0.02090884,  0.01426806, -0.04787309,  0.1325518 , -0.00498158,
        0.01912023, -0.02292867,  0.08855374,  0.07697155,  0.01407153,
       -0.02378988,  0.03745927,  0.00889686,  0.12555045,  0.04007044,
        0.06247196,  0.04912657, -0.06158784,  0.06346396,  0.00197599,
       -0.04995281,  0.05125345, -0.01584197,  0.07572784,  0.02580263,
       -0.02904062, -0.0008835 , -0.08365948, -0.05539802, -0.07523517,
        0.04622741, -0.12007375,  0.05453204, -0.02054051,  0.02937108,
        0.10272598, -0.0089594 ,  0.05172383,  0.00588922, -0.0010917 ,
        0.02603476, -0.01580217, -0.07810815,  0.06964722, -0.04709972,
       -0.0316673 , -0.05055645, -0.05096703,  0.02772727, -0.03495743,
        0.09567484, -0.0071935 , -0.01266821,  0.00074132, -0.07593331,
       -0.02928162, -0.12574387,  0.02437552, -0.0228716 , -0.03047204,
       -0.03948782,  0.07722469, -0.07440004, -0.00951135,  0.05531401,
       -0.03240326,  0.00389662, -0.05632257, -0.05030375,  0.02883579,
       -0.06157173,  0.00584065, -0.16594191,  0.1108149 , -0.00243916,
       -0.09964953,  0.02029083,  0.03522225, -0.01167114, -0.04048527,
        0.08301719, -0.04682562, -0.0714631 , -0.07355815, -0.0496731 ,
       -0.05303175, -0.03625978,  0.06879813, -0.09117774,  0.0323513 ,
       -0.01808765, -0.01746182,  0.02472609, -0.00873791, -0.00951474,
       -0.02176155,  0.02394484, -0.07035318,  0.10963078,  0.01004294,
       -0.02269555, -0.09929934, -0.02897175,  0.02157164,  0.05608977,
        0.09083252, -0.00525982, -0.09866816, -0.02736895, -0.02923711,
        0.05582205, -0.04462272,  0.01932517,  0.04468061,  0.00317996,
       -0.04182415,  0.03061792,  0.04278665,  0.02939183,  0.03475334,
       -0.00898206, -0.08902986,  0.08294971, -0.00942507, -0.02125597,
       -0.01008157,  0.04477865, -0.08366893, -0.00074587,  0.08328778,
        0.02653155,  0.04581301,  0.10532658, -0.04637942,  0.04722971,
        0.06853952, -0.00235328,  0.18312256, -0.0457427 ,  0.00874868,
        0.08945092, -0.01135547, -0.04203002,  0.02408407,  0.0594779 ,
       -0.05467811,  0.01946783,  0.07095537,  0.04226222, -0.0018304 ,
       -0.00086302,  0.04624099,  0.01009499,  0.04783599,  0.02535392],
      dtype=float32)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;有了每个词或者概念的向量，可以结合cntext旧版本单语言模型内的态度偏见的度量。&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;四扩展词典&#34;&gt;四、扩展词典&lt;/h2&gt;
&lt;p&gt;做词典法的文本分析，最重要的是有自己的领域词典。之前受限于技术难度，文科生的我也一直在用形容词的通用情感词典。现在依托word2vec技术， 可以加速人工构建的准确率和效率。&lt;/p&gt;
&lt;p&gt;下面是在 mda01-22.200.6.bin 上做的词典扩展测试，函数expand_dictionary会根据种子词选取最准确的topn个词。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;c1&#34;&gt;#短视主义词  实验&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;expand_dictionary&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;w2v_model&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
                  &lt;span class=&#34;n&#34;&gt;seedwords&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;抓紧&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;立刻&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;月底&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;年底&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;年终&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;争取&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;力争&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;
                  &lt;span class=&#34;n&#34;&gt;topn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;30&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[&#39;抓紧&#39;,
 &#39;立刻&#39;,
 &#39;月底&#39;,
 &#39;年底&#39;,
 &#39;年终&#39;,
 &#39;争取&#39;,
 &#39;力争&#39;,
 &#39;争取&#39;,
 &#39;力争&#39;,
 &#39;年底&#39;,
 &#39;月底&#39;,
 &#39;3月底&#39;,
 &#39;尽快&#39;,
 &#39;上半年&#39;,
 &#39;努力争取&#39;,
 &#39;年内实现&#39;,
 &#39;抓紧&#39;,
 &#39;工作争取&#39;,
 &#39;尽早&#39;,
 &#39;6月底&#39;,
 &#39;工作力争&#39;,
 &#39;7月份&#39;,
 &#39;年底完成&#39;,
 &#39;确保&#39;,
 &#39;早日&#39;,
 &#39;有望&#39;,
 &#39;全力&#39;,
 &#39;创造条件&#39;,
 &#39;3月份&#39;,
 &#39;加紧&#39;,
 &#39;力争实现&#39;,
 &#39;力争今年&#39;,
 &#39;月底前&#39;,
 &#39;10月底&#39;,
 &#39;4月份&#39;,
 &#39;继续&#39;,
 &#39;月初&#39;]
&lt;/code&gt;&lt;/pre&gt;
&lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;expand_dictionary&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;w2v_model&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
                  &lt;span class=&#34;n&#34;&gt;seedwords&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;团结&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;拼搏&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;  &lt;span class=&#34;s1&#34;&gt;&amp;#39;克服&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;  &lt;span class=&#34;s1&#34;&gt;&amp;#39;勇攀高峰&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;  &lt;span class=&#34;s1&#34;&gt;&amp;#39;友善&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;  &lt;span class=&#34;s1&#34;&gt;&amp;#39;进取&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;
                  &lt;span class=&#34;n&#34;&gt;topn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;30&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[&#39;团结&#39;,
 &#39;拼搏&#39;,
 &#39;克服&#39;,
 &#39;勇攀高峰&#39;,
 &#39;友善&#39;,
 &#39;进取&#39;,
 &#39;拼搏&#39;,
 &#39;艰苦奋斗&#39;,
 &#39;团结拼搏&#39;,
 &#39;勇于担当&#39;,
 &#39;锐意进取&#39;,
 &#39;勇气&#39;,
 &#39;团结&#39;,
 &#39;团结奋进&#39;,
 &#39;团结一致&#39;,
 &#39;顽强拼搏&#39;,
 &#39;上下一心&#39;,
 &#39;实干&#39;,
 &#39;拼搏进取&#39;,
 &#39;积极进取&#39;,
 &#39;奋力拼搏&#39;,
 &#39;奋进&#39;,
 &#39;坚定信念&#39;,
 &#39;团结一心&#39;,
 &#39;精诚团结&#39;,
 &#39;顽强&#39;,
 &#39;踏实&#39;,
 &#39;团结协作&#39;,
 &#39;求真务实&#39;,
 &#39;团结奋斗&#39;,
 &#39;奋发有为&#39;,
 &#39;同心协力&#39;,
 &#39;脚踏实地&#39;,
 &#39;开拓进取&#39;,
 &#39;进取&#39;,
 &#39;勇于&#39;]
&lt;/code&gt;&lt;/pre&gt;
&lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;expand_dictionary&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;w2v_model&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
                  &lt;span class=&#34;n&#34;&gt;seedwords&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;创新&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;科技&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;  &lt;span class=&#34;s1&#34;&gt;&amp;#39;研发&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;  &lt;span class=&#34;s1&#34;&gt;&amp;#39;技术&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;  &lt;span class=&#34;s1&#34;&gt;&amp;#39;标准&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;
                  &lt;span class=&#34;n&#34;&gt;topn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;30&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[&#39;创新&#39;,
 &#39;科技&#39;,
 &#39;研发&#39;,
 &#39;技术&#39;,
 &#39;标准&#39;,
 &#39;技术创新&#39;,
 &#39;技术研发&#39;,
 &#39;先进技术&#39;,
 &#39;关键技术&#39;,
 &#39;创新性&#39;,
 &#39;前沿技术&#39;,
 &#39;科技创新&#39;,
 &#39;技术应用&#39;,
 &#39;产品开发&#39;,
 &#39;自主创新&#39;,
 &#39;新技术&#39;,
 &#39;科研&#39;,
 &#39;产品研发&#39;,
 &#39;自主研发&#39;,
 &#39;技术开发&#39;,
 &#39;工艺技术&#39;,
 &#39;技术标准&#39;,
 &#39;基础研究&#39;,
 &#39;集成创新&#39;,
 &#39;核心技术&#39;,
 &#39;成熟技术&#39;,
 &#39;研发创新&#39;,
 &#39;理论技术&#39;,
 &#39;前沿技术研发&#39;,
 &#39;工艺&#39;,
 &#39;科技成果&#39;,
 &#39;技术研究&#39;,
 &#39;标准制定&#39;,
 &#39;技术装备&#39;,
 &#39;技术相结合&#39;]
&lt;/code&gt;&lt;/pre&gt;
&lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;expand_dictionary&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;w2v_model&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
                  &lt;span class=&#34;n&#34;&gt;seedwords&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;竞争&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;竞争力&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;
                  &lt;span class=&#34;n&#34;&gt;topn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;30&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[&#39;竞争&#39;,
 &#39;竞争力&#39;,
 &#39;竞争能力&#39;,
 &#39;市场竞争&#39;,
 &#39;竞争优势&#39;,
 &#39;市场竞争力&#39;,
 &#39;竞&#39;,
 &#39;竞争实力&#39;,
 &#39;激烈竞争&#39;,
 &#39;参与市场竞争&#39;,
 &#39;国际竞争&#39;,
 &#39;市场竞争能力&#39;,
 &#39;竞争态势&#39;,
 &#39;市场竞争优势&#39;,
 &#39;行业竞争&#39;,
 &#39;综合竞争力&#39;,
 &#39;竞争对手&#39;,
 &#39;未来市场竞争&#39;,
 &#39;产品竞争力&#39;,
 &#39;之间竞争&#39;,
 &#39;核心竞争力&#39;,
 &#39;参与竞争&#39;,
 &#39;核心竞争能力&#39;,
 &#39;竞争日趋激烈&#39;,
 &#39;国际化竞争&#39;,
 &#39;国际竞争力&#39;,
 &#39;竟争力&#39;,
 &#39;市场化竞争&#39;,
 &#39;同质化竞争&#39;,
 &#39;竞争力关键&#39;,
 &#39;价格竞争&#39;,
 &#39;整体竞争力&#39;]
&lt;/code&gt;&lt;/pre&gt;
&lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;expand_dictionary&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;w2v_model&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
                  &lt;span class=&#34;n&#34;&gt;seedwords&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;疫情&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;扩散&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;防控&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;反复&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;冲击&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;
                  &lt;span class=&#34;n&#34;&gt;topn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;30&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[&#39;疫情&#39;,
 &#39;扩散&#39;,
 &#39;防控&#39;,
 &#39;反复&#39;,
 &#39;冲击&#39;,
 &#39;蔓延&#39;,
 &#39;疫情&#39;,
 &#39;疫情爆发&#39;,
 &#39;疫情冲击&#39;,
 &#39;新冠疫情&#39;,
 &#39;肆虐&#39;,
 &#39;新冠肺炎&#39;,
 &#39;疫情蔓延&#39;,
 &#39;本次疫情&#39;,
 &#39;散发&#39;,
 &#39;疫情扩散&#39;,
 &#39;疫情影响&#39;,
 &#39;疫情反复&#39;,
 &#39;疫情传播&#39;,
 &#39;肺炎疫情&#39;,
 &#39;国内疫情&#39;,
 &#39;击&#39;,
 &#39;各地疫情&#39;,
 &#39;疫情全球&#39;,
 &#39;疫情多点&#39;,
 &#39;全球疫情&#39;,
 &#39;持续蔓延&#39;,
 &#39;多点散发&#39;,
 &#39;疫情导致&#39;,
 &#39;疫情暴发&#39;,
 &#39;病毒疫情&#39;,
 &#39;疫情持续&#39;,
 &#39;疫情初期&#39;,
 &#39;疫情出现&#39;,
 &#39;防控措施&#39;]
&lt;/code&gt;&lt;/pre&gt;
&lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;expand_dictionary&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;w2v_model&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
                  &lt;span class=&#34;n&#34;&gt;seedwords&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;旧&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;老&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;后&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;落后&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;
                  &lt;span class=&#34;n&#34;&gt;topn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;30&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[&#39;旧&#39;,
 &#39;老&#39;,
 &#39;后&#39;,
 &#39;落后&#39;,
 &#39;老&#39;,
 &#39;旧&#39;,
 &#39;陈旧&#39;,
 &#39;老旧&#39;,
 &#39;淘汰&#39;,
 &#39;低效率&#39;,
 &#39;低效&#39;,
 &#39;部分老旧&#39;,
 &#39;进行改造&#39;,
 &#39;老旧设备&#39;,
 &#39;工艺落后&#39;,
 &#39;设备陈旧&#39;,
 &#39;能耗高&#39;,
 &#39;更新改造&#39;,
 &#39;落后工艺&#39;,
 &#39;技术落后&#39;,
 &#39;改造&#39;,
 &#39;翻新&#39;,
 &#39;简陋&#39;,
 &#39;旧设备&#39;,
 &#39;拆除&#39;,
 &#39;现象严重&#39;,
 &#39;原有&#39;,
 &#39;相对落后&#39;,
 &#39;产能淘汰&#39;,
 &#39;加快淘汰&#39;,
 &#39;搬&#39;,
 &#39;替换&#39;,
 &#39;大批&#39;,
 &#39;迁&#39;]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;五源代码&#34;&gt;五、源代码&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;gensim.models&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;KeyedVectors&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pathlib&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Path&lt;/span&gt;


&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;load_w2v&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;w2v_path&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
    &lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&amp;#34;
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;    Load word2vec model
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;    Args:
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;        w2v_path (str): path of word2vec model
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;    Returns:
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;        model: word2vec model
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;    &amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;
    &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;Loading word2vec model...&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;model&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;KeyedVectors&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;load&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;w2v_path&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
    &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;model&lt;/span&gt;


&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;expand_dictionary&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;seedwords&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;topn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;100&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
    &lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&amp;#34;
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;    According to the seed word file, select the top n words with the most similar semantics and save them in the directory save_dir.
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;    
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;    Args:
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;        wv (Word2VecKeyedVectors): the word embedding model
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;        seedwords (list): 种子词
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;        topn (int, optional): Set the number of most similar words to retrieve to topn. Defaults to 100.
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;        save_dir (str, optional): the directory to save the candidate words. Defaults to &amp;#39;Word2Vec&amp;#39;.
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;    
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;    Returns:
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;    &amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;simidx_scores&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt;

    &lt;span class=&#34;n&#34;&gt;similars_candidate_idxs&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;#the candidate words of seedwords&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;dictionary&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;key_to_index&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;seedidxs&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;#transform word to index&lt;/span&gt;
    &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;seed&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;seedwords&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
        &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;seed&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;dictionary&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
            &lt;span class=&#34;n&#34;&gt;seedidx&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;dictionary&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;seed&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
            &lt;span class=&#34;n&#34;&gt;seedidxs&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;append&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;seedidx&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
    &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;seedidx&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;seedidxs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
        &lt;span class=&#34;c1&#34;&gt;# sims_words such as [(&amp;#39;by&amp;#39;, 0.99984), (&amp;#39;or&amp;#39;, 0.99982), (&amp;#39;an&amp;#39;, 0.99981), (&amp;#39;up&amp;#39;, 0.99980)]&lt;/span&gt;
        &lt;span class=&#34;n&#34;&gt;sims_words&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;similar_by_word&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;seedidx&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;topn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;topn&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
        &lt;span class=&#34;c1&#34;&gt;#Convert words to index and store them&lt;/span&gt;
        &lt;span class=&#34;n&#34;&gt;similars_candidate_idxs&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;extend&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;([&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dictionary&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sim&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]]&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sim&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sims_words&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;similars_candidate_idxs&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;set&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;similars_candidate_idxs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
    
    &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;idx&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;similars_candidate_idxs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
        &lt;span class=&#34;n&#34;&gt;score&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;n_similarity&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;([&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;idx&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;seedidxs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
        &lt;span class=&#34;n&#34;&gt;simidx_scores&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;append&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;((&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;idx&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;score&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;simidxs&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;w&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;w&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;sorted&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;simidx_scores&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;key&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;lambda&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;k&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;k&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;reverse&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)]&lt;/span&gt;

    &lt;span class=&#34;n&#34;&gt;simwords&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;str&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;index_to_key&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;idx&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;idx&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;simidxs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;][:&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;topn&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;

    &lt;span class=&#34;n&#34;&gt;resultwords&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;resultwords&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;extend&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;seedwords&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;resultwords&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;extend&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;simwords&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
    
    &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;resultwords&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;六获取模型&#34;&gt;六、获取模型&lt;/h2&gt;
&lt;p&gt;内容创作不易， 本文为付费内容，&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;- 50元    2001-2022年报MDA.xlsx  

- 50元    cntext-2.0.0-py3-none-any.whl

- 100元   Word2Vec相关模型文件(mda01-22.200.6.bin)

- 150元   
    - 2001-2022年报MDA.xlsx  
    - cntext-2.0.0-py3-none-any.whl  
    - Word2Vec相关模型文件(mda01-22.200.6.bin)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;加微信 372335839， 备注「姓名-学校-专业-word2vec」&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;广而告之&#34;&gt;广而告之&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/call_for_paper/&#34;&gt;长期征稿&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/we_need_you/&#34;&gt;长期招募小伙伴&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/management_python_course/&#34;&gt;付费视频课 | Python实证指标构建与文本分析&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
      <content:encoded><![CDATA[<h2 id="相关内容">相关内容</h2>
<ul>
<li><a href="https://textdata.cn/blog/the_text_analysis_list_about_ms/">LIST | 社科(经管)文本挖掘文献汇总</a></li>
<li><a href="https://textdata.cn/blog/text_analysis_code_list_about_ms/">LIST | 文本分析代码汇总</a></li>
<li><a href="https://textdata.cn/blog/datasets_available_for_management_science/">LIST | 可供社科(经管)领域使用的数据集</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">Python实证指标构建与文本分析</a></li>
<li><a href="https://textdata.cn/blog/2023-11-20-word2vec-by-year-by-province/">使用3751w专利申请数据集按年份(按省份)训练词向量</a></li>
<li><a href="https://textdata.cn/blog/2023-11-10-training-word2vec-model-using-china-3751w-patent-application-dataset/">预训练模型 | 使用1000w专利摘要训练word2vec模型，可用于开发词典</a></li>
</ul>
<p>相关文献</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">[0]刘景江,郑畅然,洪永淼.机器学习如何赋能管理学研究？——国内外前沿综述和未来展望[J].管理世界,2023,39(09):191-216.
[1]冉雅璇,李志强,刘佳妮,张逸石.大数据时代下社会科学研究方法的拓展——基于词嵌入技术的文本分析的应用[J].南开管理评论:1-27.
[3]胡楠,薛付婧,王昊楠.管理者短视主义影响企业长期投资吗？——基于文本分析和机器学习[J].管理世界,2021,37(05):139-156+11+19-21.
[4]Kai Li, Feng Mai, Rui Shen, Xinyan Yan, Measuring Corporate Culture Using Machine Learning, *The Review of Financial Studies*,2020
</code></pre></div><p><br><br></p>
<h2 id="一训练">一、训练</h2>
<h3 id="11-导入mda数据">1.1 导入mda数据</h3>
<p>读取2001-2022年的<strong>管理层讨论与分析mda</strong>数据</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_excel</span><span class="p">(</span><span class="s1">&#39;mda01-22.xlsx&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">))</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">55439
</code></pre></div><p><img loading="lazy" src="img/df.png" alt=""  />
</p>
<br>
<h3 id="12-构造语料">1.2 构造语料</h3>
<p>从 <strong>mda01-22.xlsx</strong> 数据中抽取出所有文本，写入到 <strong>mda01-22.txt</strong></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;mda01-22.txt&#39;</span><span class="p">,</span> <span class="s1">&#39;a+&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">text</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">])</span>
    <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
</code></pre></div><br>
<h3 id="13-配置cntext环境">1.3 配置cntext环境</h3>
<p>使用2.0.0版本cntext库(该版本暂不开源，需付费购买)。 将得到的 <strong>cntext-2.0.0-py3-none-any.whl</strong> 文件放置于电脑桌面，  win系统打开<strong>cmd</strong>(Mac打开terminal)， 输入如下命令(将工作环境切换至桌面)</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">cd desktop
</code></pre></div><p>个别Win用户如无效，试试<code>cd Desktop</code> 。</p>
<p>继续在cmd (terminal) 中执行如下命令安装cntext2.0.0</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">pip3 install cntext-2.0.0-py3-none-any.whl 
</code></pre></div><br>
<h3 id="14-训练word2vec">1.4 训练word2vec</h3>
<p>设置模型参数配置</p>
<ul>
<li>mda01-22 使用2001-2022年度mda数据训练</li>
<li>200 嵌入的维度数，即每个词的向量长度是200</li>
<li>6 词语上下文的窗口是6</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="o">%%</span><span class="n">time</span>  <span class="c1">#程序结束后，可查看总的运行时间</span>
<span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>

<span class="n">w2v</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">W2VModel</span><span class="p">(</span><span class="n">corpus_file</span><span class="o">=</span><span class="s1">&#39;mda01-22.txt&#39;</span><span class="p">)</span>
<span class="n">w2v</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">vector_size</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">window_size</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">min_count</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">save_dir</span><span class="o">=</span><span class="s1">&#39;Word2Vec&#39;</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">Building prefix dict from the default dictionary ...
Start Preprocessing Corpus...
Dumping model to file cache /var/folders/y0/4gqxky0s2t94x1c1qhlwr6100000gn/T/jieba.cache
Loading model cost 0.278 seconds.
Prefix dict has been built successfully.
Start Training! This may take a while. Please be patient...

Training word2vec model took 3532 seconds

Note: The Word2Vec model has been saved to output/Word2Vec

CPU times: user 1h 30min 45s, sys: 30.1 s, total: 1h 31min 15s
Wall time: 58min 57s
</code></pre></div><p>经过不到两个小时时间， 训练出的中国A股市场词向量模型(如下截图)，词汇量 914058， 模型文件 1.49G。模型可广泛用于经济管理等领域概念(情感)词典的构建或扩展。</p>
<ul>
<li><strong>mda01-22.200.6.bin</strong></li>
<li><strong>mda01-22.200.6.bin.syn1neg.npy</strong></li>
<li><strong>mda01-22.200.6.bin.wv.vectors.npy</strong></li>
</ul>
<p><img loading="lazy" src="img/pretained-screen.png" alt=""  />
</p>
<p>为什么这样确定200和6，可以看这篇 <a href="https://textdata.cn/blog/2023-03-15-39faq-about-word-embeddings-for-social-science">词嵌入技术在社会科学领域进行数据挖掘常见39个FAQ汇总</a></p>
<br>
<br>
<h2 id="二导入模型">二、导入模型</h2>
<p>需要用到两个自定义函数load_w2v、expand_dictionary，源代码太长，为了提高阅读体验， 放在文末。大家记得用这两个函数前一定要先导入。<a href="mda_pretained_model_code.ipynb"><strong>点击代码</strong></a></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#先导入load_w2v、expand_dictionary函数源代码</span>


<span class="c1">#读取模型文件</span>
<span class="n">w2v_model</span> <span class="o">=</span> <span class="n">load_w2v</span><span class="p">(</span><span class="n">w2v_path</span><span class="o">=</span><span class="s1">&#39;Word2Vec/mda01-21.200.6.bin&#39;</span><span class="p">)</span>
<span class="n">w2v_model</span>
</code></pre></div><pre><code>Loading word2vec model...
&lt;gensim.models.word2vec.Word2Vec at 0x310dd9990&gt;
</code></pre>
<br>
<h2 id="注意">注意</h2>
<p>之前购买过mda01-21.100.6.bin的可以留意下， &lt;gensim.models.word2vec.Word2Vec&gt;和&lt;gensim.models.keyedvectors.KeyedVectors&gt;
是有区别的。</p>
<p><br><br></p>
<h3 id="三w2v_model的使用">三、w2v_model的使用</h3>
<ul>
<li>查看词汇量</li>
<li>查询某词向量</li>
<li>查看多个词的均值向量</li>
</ul>
<p>更多内容，建议查看下gensim库的文档</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#词汇量</span>
<span class="nb">len</span><span class="p">(</span><span class="n">w2v_model</span><span class="o">.</span><span class="n">wv</span><span class="o">.</span><span class="n">index_to_key</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<pre><code>914058  
</code></pre>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#查询某词的词向量</span>
<span class="n">w2v_model</span><span class="o">.</span><span class="n">wv</span><span class="o">.</span><span class="n">get_vector</span><span class="p">(</span><span class="s1">&#39;创新&#39;</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<pre><code>array([-1.36441350e-01, -2.02002168e+00, -1.49168205e+00,  2.65202689e+00,
        1.49721682e+00,  2.14851022e+00, -1.54925853e-01, -2.25241160e+00,
       -3.58773202e-01,  1.54530525e+00, -7.62950361e-01, -9.77181852e-01,
        6.70365512e-01, -3.20203233e+00,  3.18079638e+00,  1.66510820e+00,
        9.80131567e-01,  1.62199986e+00,  1.80585206e+00,  4.08179426e+00,
       -1.26518166e+00,  3.75929743e-01,  5.72038591e-01,  1.16134119e+00,
        2.55617023e+00, -2.25110960e+00, -2.61538339e+00, -5.71992218e-01,
        8.70356798e-01, -1.85045290e+00, -2.85597444e-01, -9.15628672e-01,
       -2.03667688e+00,  2.11716801e-01,  2.94088912e+00, -2.32688546e+00,
        2.20858502e+00,  8.81347775e-01, -7.99135566e-01, -8.61206651e-01,
       -4.45446587e+00, -1.73757005e+00, -3.36678886e+00, -2.82611530e-02,
       -1.62726247e+00, -8.49750221e-01,  4.13731128e-01, -1.62519825e+00,
        3.03865957e+00, -1.39746085e-01,  8.22233260e-01, -7.97697455e-02,
        1.72468078e+00,  2.94929433e+00,  9.72453177e-01, -1.12741642e-01,
        8.18425417e-01, -9.05264139e-01,  2.61516261e+00,  8.02830994e-01,
        2.40420485e+00,  8.85799348e-01, -1.08665645e+00,  8.21912348e-01,
       -4.39456075e-01, -2.57663131e+00,  2.38062453e+00, -4.58515882e-01,
        2.12767506e+00, -2.01356173e-01,  2.71096081e-01,  9.51708496e-01,
       -3.05705309e+00, -6.06385887e-01, -1.38406023e-01,  2.36809158e+00,
       -2.49158549e+00,  2.71105647e+00, -3.07211792e-03,  1.04273570e+00,
        1.44201803e+00, -5.65704823e-01,  2.85488725e-01,  1.43495277e-01,
       -1.39421299e-01,  9.24086392e-01,  4.25374925e-01, -1.56690669e+00,
        1.67641795e+00, -1.03729677e+00, -1.45472065e-01, -2.11022258e+00,
       -1.81541741e+00, -8.66766050e-02,  8.72350857e-02,  1.17173791e+00,
       -3.07721123e-02,  5.84330797e-01,  1.47265148e+00, -1.76913440e+00,
       -8.48391712e-01, -3.25056529e+00,  7.14846313e-01, -2.98076987e-01,
        1.13966620e+00, -1.42698896e+00,  6.93505168e-01, -2.04717040e+00,
       -1.53559577e+00,  1.01942134e+00, -1.58283603e+00,  9.08654630e-01,
       -1.90529859e+00, -9.43309963e-01,  4.12964225e-01, -2.50713086e+00,
       -4.24056143e-01, -4.10613680e+00,  3.60615468e+00, -4.19765860e-01,
       -2.41174579e+00,  6.80675328e-01,  2.99834704e+00,  1.05610855e-01,
       -7.84325838e-01,  3.24065971e+00, -1.85072863e+00, -2.12448812e+00,
       -2.83468294e+00, -5.77759802e-01, -3.13433480e+00, -6.91670418e-01,
        2.99401569e+00, -5.16145706e-01,  9.09552336e-01, -5.52680910e-01,
       -2.88360894e-01,  1.11991334e+00, -1.11737549e+00,  1.15479147e+00,
       -4.63319182e-01,  1.38351321e+00, -3.02179503e+00,  1.24334955e+00,
        1.93393975e-01, -8.27962995e-01, -2.37227559e+00, -9.26931739e-01,
        6.72517180e-01,  1.27736795e+00,  1.98695862e+00,  1.41960573e+00,
       -3.73892736e+00, -3.14201683e-01, -7.19093859e-01,  1.86080355e-02,
       -2.68105698e+00,  1.04344964e+00,  9.46133554e-01, -2.06151366e+00,
       -2.84214950e+00,  1.17004764e+00,  1.24577022e+00, -1.10806060e+00,
        9.93207514e-01,  8.46789181e-01, -3.09691691e+00,  2.12616014e+00,
       -1.49274826e+00, -1.53214395e+00, -9.95470941e-01,  1.23463202e+00,
       -2.18907285e+00, -4.94913310e-01,  2.80939412e+00,  1.68149090e+00,
        1.48991072e+00,  3.83729649e+00,  4.72325265e-01,  1.37606680e+00,
        2.14257884e+00,  3.18186909e-01,  5.98093605e+00,  1.46744043e-01,
       -2.37729326e-01,  1.20463884e+00, -1.55812174e-01, -5.03088772e-01,
        4.53981996e-01,  1.95544350e+00, -2.32564354e+00, -4.09389853e-01,
        1.89125270e-01,  2.62835431e+00,  9.81123984e-01, -9.51041043e-01,
       -1.14294410e-01,  1.10983588e-01,  9.30419266e-02, -9.84693542e-02],
      dtype=float32)
</code></pre>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#查询多个词的词向量</span>
<span class="n">w2v_model</span><span class="o">.</span><span class="n">wv</span><span class="o">.</span><span class="n">get_mean_vector</span><span class="p">([</span><span class="s1">&#39;创新&#39;</span><span class="p">,</span> <span class="s1">&#39;研发&#39;</span><span class="p">])</span>
</code></pre></div><p>Ruj</p>
<pre><code>array([ 0.03019853, -0.01928307, -0.05371316,  0.00053774,  0.02516318,
        0.10103251, -0.03914721, -0.08307559,  0.00444389,  0.09456791,
       -0.05761364, -0.03459097,  0.04394419, -0.10181106,  0.1418381 ,
        0.05334964,  0.01820264,  0.01493831,  0.01626587,  0.17402864,
       -0.02859601,  0.04538149,  0.03768233,  0.05431981,  0.15405464,
       -0.03632693, -0.08566202, -0.00595666,  0.08378439, -0.11071078,
       -0.05904576, -0.06451955, -0.1076955 ,  0.05141645,  0.11710279,
       -0.09403889,  0.08633652, -0.06743232,  0.00328483,  0.01589498,
       -0.11226317, -0.05367877, -0.057222  , -0.00685401, -0.04531868,
       -0.02090884,  0.01426806, -0.04787309,  0.1325518 , -0.00498158,
        0.01912023, -0.02292867,  0.08855374,  0.07697155,  0.01407153,
       -0.02378988,  0.03745927,  0.00889686,  0.12555045,  0.04007044,
        0.06247196,  0.04912657, -0.06158784,  0.06346396,  0.00197599,
       -0.04995281,  0.05125345, -0.01584197,  0.07572784,  0.02580263,
       -0.02904062, -0.0008835 , -0.08365948, -0.05539802, -0.07523517,
        0.04622741, -0.12007375,  0.05453204, -0.02054051,  0.02937108,
        0.10272598, -0.0089594 ,  0.05172383,  0.00588922, -0.0010917 ,
        0.02603476, -0.01580217, -0.07810815,  0.06964722, -0.04709972,
       -0.0316673 , -0.05055645, -0.05096703,  0.02772727, -0.03495743,
        0.09567484, -0.0071935 , -0.01266821,  0.00074132, -0.07593331,
       -0.02928162, -0.12574387,  0.02437552, -0.0228716 , -0.03047204,
       -0.03948782,  0.07722469, -0.07440004, -0.00951135,  0.05531401,
       -0.03240326,  0.00389662, -0.05632257, -0.05030375,  0.02883579,
       -0.06157173,  0.00584065, -0.16594191,  0.1108149 , -0.00243916,
       -0.09964953,  0.02029083,  0.03522225, -0.01167114, -0.04048527,
        0.08301719, -0.04682562, -0.0714631 , -0.07355815, -0.0496731 ,
       -0.05303175, -0.03625978,  0.06879813, -0.09117774,  0.0323513 ,
       -0.01808765, -0.01746182,  0.02472609, -0.00873791, -0.00951474,
       -0.02176155,  0.02394484, -0.07035318,  0.10963078,  0.01004294,
       -0.02269555, -0.09929934, -0.02897175,  0.02157164,  0.05608977,
        0.09083252, -0.00525982, -0.09866816, -0.02736895, -0.02923711,
        0.05582205, -0.04462272,  0.01932517,  0.04468061,  0.00317996,
       -0.04182415,  0.03061792,  0.04278665,  0.02939183,  0.03475334,
       -0.00898206, -0.08902986,  0.08294971, -0.00942507, -0.02125597,
       -0.01008157,  0.04477865, -0.08366893, -0.00074587,  0.08328778,
        0.02653155,  0.04581301,  0.10532658, -0.04637942,  0.04722971,
        0.06853952, -0.00235328,  0.18312256, -0.0457427 ,  0.00874868,
        0.08945092, -0.01135547, -0.04203002,  0.02408407,  0.0594779 ,
       -0.05467811,  0.01946783,  0.07095537,  0.04226222, -0.0018304 ,
       -0.00086302,  0.04624099,  0.01009499,  0.04783599,  0.02535392],
      dtype=float32)
</code></pre>
<p>有了每个词或者概念的向量，可以结合cntext旧版本单语言模型内的态度偏见的度量。</p>
<p><br><br></p>
<h2 id="四扩展词典">四、扩展词典</h2>
<p>做词典法的文本分析，最重要的是有自己的领域词典。之前受限于技术难度，文科生的我也一直在用形容词的通用情感词典。现在依托word2vec技术， 可以加速人工构建的准确率和效率。</p>
<p>下面是在 mda01-22.200.6.bin 上做的词典扩展测试，函数expand_dictionary会根据种子词选取最准确的topn个词。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#短视主义词  实验</span>
<span class="n">expand_dictionary</span><span class="p">(</span><span class="n">wv</span><span class="o">=</span><span class="n">w2v_model</span><span class="o">.</span><span class="n">wv</span><span class="p">,</span> 
                  <span class="n">seedwords</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;抓紧&#39;</span><span class="p">,</span> <span class="s1">&#39;立刻&#39;</span><span class="p">,</span> <span class="s1">&#39;月底&#39;</span><span class="p">,</span> <span class="s1">&#39;年底&#39;</span><span class="p">,</span> <span class="s1">&#39;年终&#39;</span><span class="p">,</span> <span class="s1">&#39;争取&#39;</span><span class="p">,</span> <span class="s1">&#39;力争&#39;</span><span class="p">],</span>
                  <span class="n">topn</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<pre><code>['抓紧',
 '立刻',
 '月底',
 '年底',
 '年终',
 '争取',
 '力争',
 '争取',
 '力争',
 '年底',
 '月底',
 '3月底',
 '尽快',
 '上半年',
 '努力争取',
 '年内实现',
 '抓紧',
 '工作争取',
 '尽早',
 '6月底',
 '工作力争',
 '7月份',
 '年底完成',
 '确保',
 '早日',
 '有望',
 '全力',
 '创造条件',
 '3月份',
 '加紧',
 '力争实现',
 '力争今年',
 '月底前',
 '10月底',
 '4月份',
 '继续',
 '月初']
</code></pre>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">expand_dictionary</span><span class="p">(</span><span class="n">wv</span><span class="o">=</span><span class="n">w2v_model</span><span class="o">.</span><span class="n">wv</span><span class="p">,</span> 
                  <span class="n">seedwords</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;团结&#39;</span><span class="p">,</span> <span class="s1">&#39;拼搏&#39;</span><span class="p">,</span>  <span class="s1">&#39;克服&#39;</span><span class="p">,</span>  <span class="s1">&#39;勇攀高峰&#39;</span><span class="p">,</span>  <span class="s1">&#39;友善&#39;</span><span class="p">,</span>  <span class="s1">&#39;进取&#39;</span><span class="p">],</span>
                  <span class="n">topn</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<pre><code>['团结',
 '拼搏',
 '克服',
 '勇攀高峰',
 '友善',
 '进取',
 '拼搏',
 '艰苦奋斗',
 '团结拼搏',
 '勇于担当',
 '锐意进取',
 '勇气',
 '团结',
 '团结奋进',
 '团结一致',
 '顽强拼搏',
 '上下一心',
 '实干',
 '拼搏进取',
 '积极进取',
 '奋力拼搏',
 '奋进',
 '坚定信念',
 '团结一心',
 '精诚团结',
 '顽强',
 '踏实',
 '团结协作',
 '求真务实',
 '团结奋斗',
 '奋发有为',
 '同心协力',
 '脚踏实地',
 '开拓进取',
 '进取',
 '勇于']
</code></pre>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">expand_dictionary</span><span class="p">(</span><span class="n">wv</span><span class="o">=</span><span class="n">w2v_model</span><span class="o">.</span><span class="n">wv</span><span class="p">,</span> 
                  <span class="n">seedwords</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;创新&#39;</span><span class="p">,</span> <span class="s1">&#39;科技&#39;</span><span class="p">,</span>  <span class="s1">&#39;研发&#39;</span><span class="p">,</span>  <span class="s1">&#39;技术&#39;</span><span class="p">,</span>  <span class="s1">&#39;标准&#39;</span><span class="p">],</span>
                  <span class="n">topn</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<pre><code>['创新',
 '科技',
 '研发',
 '技术',
 '标准',
 '技术创新',
 '技术研发',
 '先进技术',
 '关键技术',
 '创新性',
 '前沿技术',
 '科技创新',
 '技术应用',
 '产品开发',
 '自主创新',
 '新技术',
 '科研',
 '产品研发',
 '自主研发',
 '技术开发',
 '工艺技术',
 '技术标准',
 '基础研究',
 '集成创新',
 '核心技术',
 '成熟技术',
 '研发创新',
 '理论技术',
 '前沿技术研发',
 '工艺',
 '科技成果',
 '技术研究',
 '标准制定',
 '技术装备',
 '技术相结合']
</code></pre>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">expand_dictionary</span><span class="p">(</span><span class="n">wv</span><span class="o">=</span><span class="n">w2v_model</span><span class="o">.</span><span class="n">wv</span><span class="p">,</span> 
                  <span class="n">seedwords</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;竞争&#39;</span><span class="p">,</span> <span class="s1">&#39;竞争力&#39;</span><span class="p">],</span>
                  <span class="n">topn</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<pre><code>['竞争',
 '竞争力',
 '竞争能力',
 '市场竞争',
 '竞争优势',
 '市场竞争力',
 '竞',
 '竞争实力',
 '激烈竞争',
 '参与市场竞争',
 '国际竞争',
 '市场竞争能力',
 '竞争态势',
 '市场竞争优势',
 '行业竞争',
 '综合竞争力',
 '竞争对手',
 '未来市场竞争',
 '产品竞争力',
 '之间竞争',
 '核心竞争力',
 '参与竞争',
 '核心竞争能力',
 '竞争日趋激烈',
 '国际化竞争',
 '国际竞争力',
 '竟争力',
 '市场化竞争',
 '同质化竞争',
 '竞争力关键',
 '价格竞争',
 '整体竞争力']
</code></pre>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">expand_dictionary</span><span class="p">(</span><span class="n">wv</span><span class="o">=</span><span class="n">w2v_model</span><span class="o">.</span><span class="n">wv</span><span class="p">,</span> 
                  <span class="n">seedwords</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;疫情&#39;</span><span class="p">,</span> <span class="s1">&#39;扩散&#39;</span><span class="p">,</span> <span class="s1">&#39;防控&#39;</span><span class="p">,</span> <span class="s1">&#39;反复&#39;</span><span class="p">,</span> <span class="s1">&#39;冲击&#39;</span><span class="p">],</span>
                  <span class="n">topn</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<pre><code>['疫情',
 '扩散',
 '防控',
 '反复',
 '冲击',
 '蔓延',
 '疫情',
 '疫情爆发',
 '疫情冲击',
 '新冠疫情',
 '肆虐',
 '新冠肺炎',
 '疫情蔓延',
 '本次疫情',
 '散发',
 '疫情扩散',
 '疫情影响',
 '疫情反复',
 '疫情传播',
 '肺炎疫情',
 '国内疫情',
 '击',
 '各地疫情',
 '疫情全球',
 '疫情多点',
 '全球疫情',
 '持续蔓延',
 '多点散发',
 '疫情导致',
 '疫情暴发',
 '病毒疫情',
 '疫情持续',
 '疫情初期',
 '疫情出现',
 '防控措施']
</code></pre>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">expand_dictionary</span><span class="p">(</span><span class="n">wv</span><span class="o">=</span><span class="n">w2v_model</span><span class="o">.</span><span class="n">wv</span><span class="p">,</span> 
                  <span class="n">seedwords</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;旧&#39;</span><span class="p">,</span> <span class="s1">&#39;老&#39;</span><span class="p">,</span> <span class="s1">&#39;后&#39;</span><span class="p">,</span> <span class="s1">&#39;落后&#39;</span><span class="p">],</span>
                  <span class="n">topn</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<pre><code>['旧',
 '老',
 '后',
 '落后',
 '老',
 '旧',
 '陈旧',
 '老旧',
 '淘汰',
 '低效率',
 '低效',
 '部分老旧',
 '进行改造',
 '老旧设备',
 '工艺落后',
 '设备陈旧',
 '能耗高',
 '更新改造',
 '落后工艺',
 '技术落后',
 '改造',
 '翻新',
 '简陋',
 '旧设备',
 '拆除',
 '现象严重',
 '原有',
 '相对落后',
 '产能淘汰',
 '加快淘汰',
 '搬',
 '替换',
 '大批',
 '迁']
</code></pre>
<p><br><br></p>
<h2 id="五源代码">五、源代码</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">gensim.models</span> <span class="kn">import</span> <span class="n">KeyedVectors</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>


<span class="k">def</span> <span class="nf">load_w2v</span><span class="p">(</span><span class="n">w2v_path</span><span class="p">):</span>
    <span class="s2">&#34;&#34;&#34;
</span><span class="s2">    Load word2vec model
</span><span class="s2">
</span><span class="s2">    Args:
</span><span class="s2">        w2v_path (str): path of word2vec model
</span><span class="s2">
</span><span class="s2">    Returns:
</span><span class="s2">        model: word2vec model
</span><span class="s2">    &#34;&#34;&#34;</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Loading word2vec model...&#39;</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">KeyedVectors</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">w2v_path</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">model</span>


<span class="k">def</span> <span class="nf">expand_dictionary</span><span class="p">(</span><span class="n">wv</span><span class="p">,</span> <span class="n">seedwords</span><span class="p">,</span> <span class="n">topn</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
    <span class="s2">&#34;&#34;&#34;
</span><span class="s2">    According to the seed word file, select the top n words with the most similar semantics and save them in the directory save_dir.
</span><span class="s2">    
</span><span class="s2">    Args:
</span><span class="s2">        wv (Word2VecKeyedVectors): the word embedding model
</span><span class="s2">        seedwords (list): 种子词
</span><span class="s2">        topn (int, optional): Set the number of most similar words to retrieve to topn. Defaults to 100.
</span><span class="s2">        save_dir (str, optional): the directory to save the candidate words. Defaults to &#39;Word2Vec&#39;.
</span><span class="s2">    
</span><span class="s2">    Returns:
</span><span class="s2">    &#34;&#34;&#34;</span>
    <span class="n">simidx_scores</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="n">similars_candidate_idxs</span> <span class="o">=</span> <span class="p">[]</span> <span class="c1">#the candidate words of seedwords</span>
    <span class="n">dictionary</span> <span class="o">=</span> <span class="n">wv</span><span class="o">.</span><span class="n">key_to_index</span>
    <span class="n">seedidxs</span> <span class="o">=</span> <span class="p">[]</span> <span class="c1">#transform word to index</span>
    <span class="k">for</span> <span class="n">seed</span> <span class="ow">in</span> <span class="n">seedwords</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">seed</span> <span class="ow">in</span> <span class="n">dictionary</span><span class="p">:</span>
            <span class="n">seedidx</span> <span class="o">=</span> <span class="n">dictionary</span><span class="p">[</span><span class="n">seed</span><span class="p">]</span>
            <span class="n">seedidxs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">seedidx</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">seedidx</span> <span class="ow">in</span> <span class="n">seedidxs</span><span class="p">:</span>
        <span class="c1"># sims_words such as [(&#39;by&#39;, 0.99984), (&#39;or&#39;, 0.99982), (&#39;an&#39;, 0.99981), (&#39;up&#39;, 0.99980)]</span>
        <span class="n">sims_words</span> <span class="o">=</span> <span class="n">wv</span><span class="o">.</span><span class="n">similar_by_word</span><span class="p">(</span><span class="n">seedidx</span><span class="p">,</span> <span class="n">topn</span><span class="o">=</span><span class="n">topn</span><span class="p">)</span>
        <span class="c1">#Convert words to index and store them</span>
        <span class="n">similars_candidate_idxs</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="n">dictionary</span><span class="p">[</span><span class="n">sim</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span> <span class="k">for</span> <span class="n">sim</span> <span class="ow">in</span> <span class="n">sims_words</span><span class="p">])</span>
    <span class="n">similars_candidate_idxs</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">similars_candidate_idxs</span><span class="p">)</span>
    
    <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">similars_candidate_idxs</span><span class="p">:</span>
        <span class="n">score</span> <span class="o">=</span> <span class="n">wv</span><span class="o">.</span><span class="n">n_similarity</span><span class="p">([</span><span class="n">idx</span><span class="p">],</span> <span class="n">seedidxs</span><span class="p">)</span>
        <span class="n">simidx_scores</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">idx</span><span class="p">,</span> <span class="n">score</span><span class="p">))</span>
    <span class="n">simidxs</span> <span class="o">=</span> <span class="p">[</span><span class="n">w</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">simidx_scores</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">k</span><span class="p">:</span><span class="n">k</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)]</span>

    <span class="n">simwords</span> <span class="o">=</span> <span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">wv</span><span class="o">.</span><span class="n">index_to_key</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">simidxs</span><span class="p">][:</span><span class="n">topn</span><span class="p">]</span>

    <span class="n">resultwords</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">resultwords</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">seedwords</span><span class="p">)</span>
    <span class="n">resultwords</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">simwords</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">resultwords</span>
</code></pre></div><p><br><br></p>
<h2 id="六获取模型">六、获取模型</h2>
<p>内容创作不易， 本文为付费内容，</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">- 50元    2001-2022年报MDA.xlsx  

- 50元    cntext-2.0.0-py3-none-any.whl

- 100元   Word2Vec相关模型文件(mda01-22.200.6.bin)

- 150元   
    - 2001-2022年报MDA.xlsx  
    - cntext-2.0.0-py3-none-any.whl  
    - Word2Vec相关模型文件(mda01-22.200.6.bin)
</code></pre></div><p>加微信 372335839， 备注「姓名-学校-专业-word2vec」</p>
<p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>可视化 | 睡前消息的科学社会、科学技术、社会化抚养话题可视化</title>
      <link>https://textdata.cn/blog/2023-03-22-bedtime-topic_model_visualization/</link>
      <pubDate>Wed, 22 Mar 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-03-22-bedtime-topic_model_visualization/</guid>
      <description>睡前消息是我最喜欢看的节目， 基本上隔两天不看睡不踏实。本次分享，不涉及观点之争，纯属技术玩乐。</description>
      <content:encoded><![CDATA[<p>我的信仰是科学的唯物史观，虽然一直觉得爷爷是伟人，但是没有系统钻研小本本，所以似懂非懂，好在有睡前消息这个节目，可以时不时的聆听到半个世纪前的伟人智慧。</p>
<p><img loading="lazy" src="img/df4.png" alt=""  />
</p>
<p><img loading="lazy" src="img/%e7%a7%91%e5%ad%a6%e7%a4%be%e4%bc%9a.png" alt=""  />
</p>
<br>
<h2 id="一读取数据">一、读取数据</h2>
<p>睡前消息是我最喜欢看的节目， 基本上隔两天不看睡不踏实。本次分享，不涉及观点之争，纯属技术玩乐。</p>
<p><a href="https://textdata.cn/blog/2023-03-06-bedtime-news-datasets/">数据集 | 马前卒工作室睡前消息文稿汇总</a></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>


<span class="n">bed_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;bedtime_news.csv&#39;</span><span class="p">,</span> <span class="n">converters</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;date&#39;</span><span class="p">:</span> <span class="nb">str</span><span class="p">})</span>
<span class="n">bed_df</span><span class="o">.</span><span class="n">date</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">bed_df</span><span class="o">.</span><span class="n">date</span><span class="p">)</span>
<span class="n">bed_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/df1.png" alt=""  />
</p>
<Br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#数据集起始日期</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">bed_df</span><span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">())[:</span><span class="mi">10</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">bed_df</span><span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">())[:</span><span class="mi">10</span><span class="p">])</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">2019-07-12
2022-11-29
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#数据集含有的节目数</span>
<span class="nb">len</span><span class="p">(</span><span class="n">bed_df</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">522
</code></pre></div><br>
<br>
<h2 id="二准备工作">二、准备工作</h2>
<h3 id="21-自定义词典">2.1 自定义词典</h3>
<ul>
<li>科学、技术</li>
<li>社会化抚养</li>
<li>债务、独山县</li>
<li>中医、以岭药业</li>
</ul>
<p>将感兴趣的词加入到jieba自定义词典中，防止被错分。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">jieba</span>

<span class="n">diywords</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;科学&#39;</span><span class="p">,</span> <span class="s1">&#39;技术&#39;</span><span class="p">,</span> <span class="s1">&#39;社会化抚养&#39;</span><span class="p">,</span> <span class="s1">&#39;债务&#39;</span><span class="p">,</span> <span class="s1">&#39;独山县&#39;</span><span class="p">,</span> <span class="s1">&#39;毛选&#39;</span><span class="p">,</span> <span class="s1">&#39;唯物&#39;</span><span class="p">,</span> <span class="s1">&#39;社会实验&#39;</span><span class="p">]</span>
<span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">diywords</span><span class="p">:</span>
    <span class="n">jieba</span><span class="o">.</span><span class="n">add_word</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
</code></pre></div><br>
<h3 id="22-word_in_context">2.2 word_in_context</h3>
<p>在这里定义了一个word_in_context函数，可以查看某些关键词上下文环境。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">jieba</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">from</span> <span class="nn">nltk.tokenize</span> <span class="kn">import</span> <span class="n">word_tokenize</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">warnings</span>


<span class="k">def</span> <span class="nf">word_in_context</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">keywords</span><span class="p">,</span> <span class="n">window</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">lang</span><span class="o">=</span><span class="s1">&#39;chinese&#39;</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">lang</span><span class="o">==</span><span class="s1">&#39;chinese&#39;</span><span class="p">:</span>
        <span class="n">words</span> <span class="o">=</span> <span class="n">jieba</span><span class="o">.</span><span class="n">lcut</span><span class="p">(</span><span class="n">text</span><span class="o">.</span><span class="n">lower</span><span class="p">())</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">words</span> <span class="o">=</span> <span class="n">word_tokenize</span><span class="p">(</span><span class="n">text</span><span class="o">.</span><span class="n">lower</span><span class="p">())</span>
        <span class="k">except</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&#34;你应该安装nltk和对应的nltk_data, 请看B站https://www.bilibili.com/video/BV14A411i7DB&#34;</span><span class="p">)</span>
            <span class="n">words</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39; &#39;</span><span class="p">)</span>
    <span class="n">keywords</span> <span class="o">=</span> <span class="p">[</span><span class="n">w</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">keywords</span><span class="p">]</span>
    <span class="n">kw_idxss</span> <span class="o">=</span> <span class="p">[[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">words</span><span class="p">)</span> <span class="k">if</span> <span class="n">x</span> <span class="o">==</span> <span class="n">keyword</span><span class="p">]</span> <span class="k">for</span> <span class="n">keyword</span> <span class="ow">in</span> <span class="n">keywords</span><span class="p">]</span>
    <span class="n">rows</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">keyword</span><span class="p">,</span> <span class="n">kw_idxs</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">keywords</span><span class="p">,</span> <span class="n">kw_idxss</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">kw_idxs</span><span class="p">:</span>
            <span class="n">half</span> <span class="o">=</span> <span class="nb">int</span><span class="p">((</span><span class="n">window</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span>
            <span class="n">start</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">idx</span> <span class="o">-</span> <span class="n">half</span><span class="p">)</span>
            <span class="n">end</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">words</span><span class="p">),</span> <span class="n">idx</span> <span class="o">+</span> <span class="n">half</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">row</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;keyword&#39;</span><span class="p">:</span> <span class="n">keyword</span><span class="p">,</span> 
                   <span class="s1">&#39;context&#39;</span><span class="p">:</span> <span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">words</span><span class="p">[</span><span class="n">start</span><span class="p">:</span> <span class="n">end</span><span class="p">])</span> <span class="k">if</span> <span class="n">lang</span><span class="o">==</span><span class="s1">&#39;chinese&#39;</span> <span class="k">else</span> <span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">words</span><span class="p">[</span><span class="n">start</span><span class="p">:</span> <span class="n">end</span><span class="p">])</span>
                      <span class="p">}</span>
            <span class="n">rows</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">row</span><span class="p">)</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">rows</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">df</span>


<span class="c1">#测试【打算】前后上下文5个单词</span>
<span class="n">word_in_context</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="s1">&#39;根本没打算过真抓到人，当然也不打算付钱。转发推送：还有一个话题&#39;</span><span class="p">,</span> 
                <span class="n">keywords</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;打算&#39;</span><span class="p">],</span> 
                <span class="n">window</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> 
                <span class="n">lang</span><span class="o">=</span><span class="s1">&#39;chinese&#39;</span><span class="p">)</span>
</code></pre></div><br>
<h3 id="23-词云图">2.3 词云图</h3>
<p>pip install pyecharts==2.0.1</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">plot_wordcloud</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">title</span><span class="p">):</span>
    <span class="kn">import</span> <span class="nn">pyecharts.options</span> <span class="k">as</span> <span class="nn">opts</span>
    <span class="kn">from</span> <span class="nn">pyecharts.charts</span> <span class="kn">import</span> <span class="n">WordCloud</span>
    <span class="n">text</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;context&#39;</span><span class="p">])</span>
    <span class="n">text</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">re</span><span class="o">.</span><span class="n">findall</span><span class="p">(</span><span class="s1">&#39;[</span><span class="se">\u4e00</span><span class="s1">-</span><span class="se">\u9fa5</span><span class="s1">]+&#39;</span><span class="p">,</span> <span class="n">text</span><span class="p">))</span>
    <span class="n">words</span> <span class="o">=</span> <span class="n">jieba</span><span class="o">.</span><span class="n">lcut</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
    <span class="n">words</span> <span class="o">=</span> <span class="p">[</span><span class="n">w</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">words</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">w</span><span class="p">)</span><span class="o">&gt;=</span><span class="mi">2</span><span class="p">]</span>
    <span class="n">wordfreqs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="nb">set</span><span class="p">(</span><span class="n">words</span><span class="p">):</span>
        <span class="n">freq</span> <span class="o">=</span> <span class="n">words</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
        <span class="n">wordfreqs</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">word</span><span class="p">,</span> <span class="n">freq</span><span class="p">))</span>
    <span class="n">wordfreqs</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">wordfreqs</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">k</span><span class="p">:</span><span class="n">k</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">wordfreqs</span> <span class="o">=</span> <span class="p">[(</span><span class="n">w</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">f</span><span class="p">))</span> <span class="k">for</span> <span class="n">w</span><span class="p">,</span><span class="n">f</span> <span class="ow">in</span> <span class="n">wordfreqs</span><span class="p">]</span>
    <span class="n">cloud</span> <span class="o">=</span> <span class="n">WordCloud</span><span class="p">()</span>
    <span class="n">cloud</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">series_name</span><span class="o">=</span><span class="s2">&#34;&#34;</span><span class="p">,</span> <span class="n">data_pair</span><span class="o">=</span><span class="n">wordfreqs</span><span class="p">,</span> <span class="n">word_size_range</span><span class="o">=</span><span class="p">[</span><span class="mi">20</span><span class="p">,</span> <span class="mi">100</span><span class="p">])</span>
    <span class="n">cloud</span><span class="o">.</span><span class="n">set_global_opts</span><span class="p">(</span><span class="n">title_opts</span><span class="o">=</span><span class="n">opts</span><span class="o">.</span><span class="n">TitleOpts</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="n">title</span><span class="p">,</span> 
                                                    <span class="n">title_textstyle_opts</span><span class="o">=</span><span class="n">opts</span><span class="o">.</span><span class="n">TextStyleOpts</span><span class="p">(</span><span class="n">font_size</span><span class="o">=</span><span class="mi">23</span><span class="p">)),</span>
                          <span class="n">tooltip_opts</span><span class="o">=</span><span class="n">opts</span><span class="o">.</span><span class="n">TooltipOpts</span><span class="p">(</span><span class="n">is_show</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
    <span class="n">cloud</span><span class="o">.</span><span class="n">render</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">{}</span><span class="s1">.html&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">title</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">cloud</span><span class="o">.</span><span class="n">render_notebook</span><span class="p">()</span>
</code></pre></div><p><br><br></p>
<h2 id="三话题分析">三、话题分析</h2>
<p>相比LDA机器学习算法的晦涩难懂，其实可以用word_in_context对指定关键词进行定位和分析，数据处理的过程清晰透明。</p>
<h3 id="31-topic-社会化抚养">3.1 Topic-社会化抚养</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">dfs</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">bed_df</span><span class="o">.</span><span class="n">iterrows</span><span class="p">():</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">word_in_context</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="n">row</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">],</span> 
                            <span class="n">keywords</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;社会化抚养&#39;</span><span class="p">],</span> 
                            <span class="n">window</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>
    <span class="n">df</span><span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">row</span><span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">]</span>
    <span class="n">dfs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
    
<span class="n">topic_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">dfs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">topic_df</span>
</code></pre></div><p><img loading="lazy" src="img/df2.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#涉及该主题的节目数</span>
<span class="nb">len</span><span class="p">(</span><span class="n">topic_df</span><span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">())</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">65
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#占比</span>
<span class="nb">len</span><span class="p">(</span><span class="n">topic_df</span><span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">())</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">bed_df</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">0.12452107279693486
</code></pre></div><br>
<p>在咱们这个数据集中，睡前消息500多期节目中，有65期谈及社会化抚养的，比例12%。</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">plot_wordcloud</span><span class="p">(</span><span class="n">df</span><span class="o">=</span><span class="n">topic_df</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s1">&#39;社会化抚养&#39;</span><span class="p">)</span>
</code></pre></div><p><img loading="lazy" src="img/%e7%a4%be%e4%bc%9a%e5%8c%96%e6%8a%9a%e5%85%bb.png" alt=""  />
</p>
<br>
<h3 id="32-topic-科学技术">3.2 Topic-科学技术</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">dfs2</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">bed_df</span><span class="o">.</span><span class="n">iterrows</span><span class="p">():</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">word_in_context</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="n">row</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">],</span> 
                            <span class="n">keywords</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;科学&#39;</span><span class="p">,</span> <span class="s1">&#39;技术&#39;</span><span class="p">],</span> 
                            <span class="n">window</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>
    <span class="n">df</span><span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">row</span><span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">]</span>
    <span class="n">dfs2</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
    
<span class="n">topic_df2</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">dfs2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">topic_df2</span>
</code></pre></div><p><img loading="lazy" src="img/df3.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#涉及该主题的节目数</span>
<span class="nb">len</span><span class="p">(</span><span class="n">topic_df2</span><span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">())</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">411
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#占比</span>
<span class="nb">len</span><span class="p">(</span><span class="n">topic_df2</span><span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">())</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">bed_df</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">0.7873563218390804
</code></pre></div><br>
<p>在咱们这个数据集中，睡前消息500多期节目中，有411期谈及社会化抚养的，比例79%。</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">plot_wordcloud</span><span class="p">(</span><span class="n">df</span><span class="o">=</span><span class="n">topic_df</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s1">&#39;科学技术&#39;</span><span class="p">)</span>
</code></pre></div><p><img loading="lazy" src="img/%e7%a7%91%e5%ad%a6%e6%8a%80%e6%9c%af.png" alt=""  />
</p>
<br>
<h2 id="33-科学社会">3.3 科学社会</h2>
<p>面对社会问题，睡前消息倡导科学社会实验， 也喜欢讲毛选语录， 两者所涉及的是唯物的观点，科学社会的观点。放在一起试试</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">dfs3</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">bed_df</span><span class="o">.</span><span class="n">iterrows</span><span class="p">():</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">word_in_context</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="n">row</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">],</span> 
                            <span class="n">keywords</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;毛选&#39;</span><span class="p">,</span> <span class="s1">&#39;唯物&#39;</span><span class="p">,</span> <span class="s1">&#39;社会实验&#39;</span><span class="p">],</span> 
                            <span class="n">window</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
    <span class="n">df</span><span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">row</span><span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">]</span>
    <span class="n">dfs3</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
    
<span class="n">topic_df3</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">dfs3</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">topic_df3</span>
</code></pre></div><p><img loading="lazy" src="img/df4.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#涉及该主题的节目数</span>
<span class="nb">len</span><span class="p">(</span><span class="n">topic_df3</span><span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">())</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">14
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="nb">len</span><span class="p">(</span><span class="n">topic_df3</span><span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">())</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">bed_df</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">0.02681992337164751
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">plot_wordcloud</span><span class="p">(</span><span class="n">df</span><span class="o">=</span><span class="n">topic_df3</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s1">&#39;科学社会&#39;</span><span class="p">)</span>
</code></pre></div><p><img loading="lazy" src="img/%e7%a7%91%e5%ad%a6%e7%a4%be%e4%bc%9a.png" alt=""  />
</p>
<br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>Nature | 通用中英文六维语义情感词典</title>
      <link>https://textdata.cn/blog/2023-03-20-nature-six-semantic-dimension-database/</link>
      <pubDate>Mon, 20 Mar 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-03-20-nature-six-semantic-dimension-database/</guid>
      <description>来自心理学和认知神经科学的证据表明，人类大脑的语义系统包含几个特定的子系统，每个子系统都代表语义信息的特定维度。对这些不同语义维度上的词语评分可以帮助研究语义维度对语言处理的行为和神经影响，并根据人类认知系统的语义空间建立语言含义的计算表示。现有的语义评分数据库提供了数百到数千个词语的评分，但这无法支持对自然文本或语音的全面语义分析。本文报告了一个大型数据库——六维语义数据库（SSDD， 后文「数据库」均用「词典」代替），其中包含对 17,940个常用汉语词语在六个主要语义维度上的主观评分：视觉、运动、社交、情感、时间和空间。此外，使用计算模型学习主观评分和词嵌入之间的映射关系，我们在SSDD中包括了1,427,992个汉语和1,515,633个英语词语的估计语义评分。SSDD将有助于自然语言处理、文本分析和大脑中的语义表示研究。</description>
      <content:encoded><![CDATA[<h2 id="应用价值">应用价值</h2>
<p>对于大量散落在网络中的文本数据， 可以度量用户在视觉、运动、社交、情感、时间和空间等维度上心理、认知、抽象层面的信息。</p>
<br>
<p>Wang, S., Zhang, Y., Shi, W. et al. A large dataset of semantic ratings and its computational extension. Sci Data 10, 106 (2023). <a href="https://doi.org/10.1038/s41597-023-01995-6">https://doi.org/10.1038/s41597-023-01995-6</a></p>
<p><img loading="lazy" src="img/cover.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="一摘要">一、摘要</h2>
<p>来自心理学和认知神经科学的证据表明，人类大脑的语义系统包含几个特定的子系统，每个子系统都代表语义信息的特定维度。对这些不同语义维度上的词语评分可以帮助研究语义维度对语言处理的行为和神经影响，并根据人类认知系统的语义空间建立语言含义的计算表示。现有的语义评分数据库提供了数百到数千个词语的评分，但这无法支持对自然文本或语音的全面语义分析。本文报告了一个大型数据库——<strong>六维语义数据库</strong>（SSDD， 后文「数据库」均用「词典」代替），其中包含对 <strong>17,940</strong> 个常用汉语词语在六个主要语义维度上的主观评分：<strong>视觉、运动、社交、情感、时间和空间</strong>。此外，使用计算模型学习主观评分和词嵌入之间的映射关系，我们在SSDD中包括了1,427,992个汉语和1,515,633个英语词语的估计语义评分。SSDD将有助于自然语言处理、文本分析和大脑中的语义表示研究。</p>
<p><br><br></p>
<h2 id="二背景">二、背景</h2>
<p>大量行为和神经证据表明，单词语义表示分布在不同的神经子系统中， 每个子系统代表着特定的语义信息维度。这些语义子系统和维度为人类语义系统的组织提供了重要线索。为了研究单词在人脑中的 <strong>意义表示</strong> 和 <strong>信息加工</strong>, 许多研究基于心理和神经生物学可行的语义维度，通过人员标准构建了单词的词典。与现有NLP领域的embeddings相比， 基于特定意义维度所构建的词典可以在经验语义纬度上提供量化的评分， 使得研究者可以调查语义维度对语言处理的行为和神经影响， 并建立语言含义的(表示)计算。</p>
<p>然而现有的词典只包含数百、数钱个词，不足以支持自然文本或语音的全面语义分析。该研究提供了一个大型的语义评分语义词典， 名为<strong>六维语义</strong>（Six Semantic Dimension Database，SSDD）词典， <strong>每个中英文词语含六个维度的得分(可以理解为效价valence),分别是视觉、运动、社交、情感、时间、空间</strong>。 其中视觉和运动维度反映了感觉运动体验对语义表示的影响。感觉和运动维度可能是最常研究的语义维度之一，它们对于对象和动作概念的重要性已经得到了很好的确认。在与语义表示相关的多个感官维度中，我们选择了视觉维度，因为视觉是主导的感觉模态。视觉和运动语义对认知处理的行为和神经影响已经被许多研究证实。社交和情感维度反映了社会情感体验对语义表示的影响。<strong>这些维度具有可分离的神经相关性，并且对于心理和抽象概念的表示尤其重要</strong>。Huth等人采用数据驱动方法研究了大脑中的语义表示组织，并发现社交情感和感官运动语义与最重要的数据驱动语义维度的两端相关联。因此，社交和情感维度可以作为视觉和运动维度的重要补充，以反映语义表示。时间和空间维度对于事件和情境的表示尤为重要。神经心理学和神经影像研究也表明这些维度具有可分离的神经相关性。Binder等人对经验语义属性进行了全面的综述，反映了六个维度的代表性。Binder等人总结了属于14个领域的65个语义维度，其中超过2/3的维度属于视觉、运动、社交、情感、时间和空间领域。SSDD将这六个领域作为粗粒度语义维度，并为每个维度提供了一般评分。</p>
<p><br><br></p>
<h2 id="三构建方法">三、构建方法</h2>
<h3 id="31-标准者被试人员">3.1 标准者(被试人员)</h3>
<p>该研究找了85位心理、神经都正常的本硕中国学生， 通过数据质量评估，最终保留了80位学生的数据标注结果。</p>
<br>
<h3 id="32-待标注的17940中文词">3.2 待标注的17940中文词</h3>
<p>待标注中文词，一共有17940个， 是由三种数据源筛选得来</p>
<ol>
<li>中文维基百科12814高频词</li>
<li>fMRI领域研究(发表&amp;未发表)的4915个中文词</li>
<li>最后一组项目是来自Binder等人和Tamir等人的语义评分实验中英文刺激词的211个汉语翻译。</li>
</ol>
<br>
<h3 id="33-标注过程">3.3 标注过程</h3>
<ul>
<li>该研究对17980个词进行了6个标注实验的， 每个实验聚焦于一个语义维度（视觉、运动、社交、情感、时间、空间）。</li>
<li>每个标注实验会分成18个session，每个session含1000个词(最后一个session有940个词)</li>
<li>标准过程使用问卷星</li>
<li>情绪维度标注的时候，使用13-point scale标准标注(-6表示非常负面， 0表示中性， 6表示非常积极)</li>
<li>剩下的5维（视觉、运动、社交、时间、空间）使用7-point scale标准标注(1表示非常低， 7表示非常高)</li>
<li>每次标注前， 标注者需要阅读标注指南，指南会含有一些语义例子。</li>
<li>为了控制标准数据质量， 保证每位标注者与所有标准者的相关性大于0.5，最终拒绝了28个session大概0.87%的数据量。</li>
</ul>
<br>
<h3 id="34-扩充词典">3.4 扩充词典</h3>
<p>标准的17940个中文词的六维度数据，可以认为是标准数据。用机器学习方法，想办法扩充词典。</p>
<p>该团队检验了语义上下文不敏感的词嵌入算法(word2vec/Glove)和 对上下文语义敏感的嵌入算法(GPT2, BERT ERNIE, and MacBERT) ，让这6类嵌入模型分别预测， 确定下表现效果较好的Word2vec和MacBERT算法。</p>
<p>使用Word2vec和MacBERT预测剩下所有的中文词，共扩展出1427992个中文词。</p>
<p>人类在视觉、运动、社交、情感、时间、空间六个维度上是共通的，结合语言嵌入模型可以在不同语言中进行语义空间对齐，该研究根据英文嵌入语言模型，也预测出了1,515,633个词。</p>
<br>
<br>
<h2 id="四ssdd">四、SSDD</h2>
<p>SSDD包含两个数据集：</p>
<ul>
<li>第一个是17,940个常用汉语词语在六个语义维度上的主观评分。</li>
<li>第二个是主观评分数据的计算扩展。我们将主观评分与计算模型相结合，然后估算出1,427,992个汉语和1,515,633个英语单词的语义评分。</li>
</ul>
<p>该研究标准、训练的源代码数据均已开源，https://osf.io/n5vke/</p>
<p><img loading="lazy" src="img/osf.png" alt=""  />
</p>
<p>由于数据量太大， 这里只给大家读取并显示17940个标注的6维语义数据, 其实对于经管社科研究， 标注的 <a href="Rated_semantic_dimensions.csv">17940个词</a> 已经是很大的情感词典了。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;Rated_semantic_dimensions.csv&#39;</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/df1.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#词汇量</span>
<span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">17940
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1"># 计算相关性矩阵</span>
<span class="n">df</span><span class="o">.</span><span class="n">corr</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/df2.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">corr_df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">corr</span><span class="p">()</span>
<span class="n">mark</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">cell</span><span class="p">:</span> <span class="s1">&#39;background-color: </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="s1">&#39;red&#39;</span> <span class="k">if</span> <span class="n">cell</span> <span class="o">&gt;</span> <span class="mf">0.4</span> <span class="k">else</span> <span class="s1">&#39;&#39;</span>
<span class="n">color_matrix</span> <span class="o">=</span> <span class="n">corr_df</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">applymap</span><span class="p">(</span><span class="n">mark</span><span class="p">)</span>
<span class="n">color_matrix</span>
</code></pre></div><p><img loading="lazy" src="img/df3.png" alt=""  />
</p>
<p>相关性最高的单元格是Motor与Vision， 6个维度相关性均小于0.5 ， 六维的选择是很合理。</p>
<p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>word_in_context | 查看某类词的上下文，更好的理解文本数据</title>
      <link>https://textdata.cn/blog/2023-03-19-word-in-context/</link>
      <pubDate>Sun, 19 Mar 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-03-19-word-in-context/</guid>
      <description>通过一个单词所处的语境，我们可以了解该单词的含义。**该谚语源于英国语言学家 J.R. Firth 的理论，他认为单词的含义是由其周围的语境和与之相伴的其他单词所决定的，因此我们需要通过单词出现的上下文来理解其含义。这一理论在语言学、自然语言处理等领域有着广泛的应用。之前分享过 [ 使用正则表达式、文本向量化、线性回归算法从md&amp;amp;a数据中计算 「企业融资约束指标」 ]， 使用的是正则表达式识别融资约束文本。但是正则表达式设计十分复杂且有难度，在此之前，如果能够查看某些融资关键词附近上下文， 可帮助研究者更全面地了解数据集中关键词的使用情况和语境，更好的设计正则表达式，亦或许意外找出新的有价值的线索。</description>
      <content:encoded><![CDATA[<p>Firth（1957）有一句名言，理解一个词要从ta身边入手。</p>
<blockquote>
<p>You shall know a word by the company it keeps</p>
</blockquote>
<p>通过一个单词所处的语境，我们可以了解该单词的含义。<strong>该谚语源于英国语言学家 J.R. Firth 的理论，他认为单词的含义是由其周围的语境和与之相伴的其他单词所决定的，因此我们需要通过单词出现的上下文来理解其含义。这一理论在语言学、自然语言处理等领域有着广泛的应用</strong>。之前分享过</p>
<p><img loading="lazy" src="img/39faq-firth_words.png" alt=""  />
</p>
<p>之前分享过 <a href="https://textdata.cn/blog/2023-12-31-using-regex-to-compute-the-financial_constraints"> 使用正则表达式、文本向量化、线性回归算法从md&amp;a数据中计算 「企业融资约束指标」 </a>， 使用的是正则表达式识别融资约束文本。但是正则表达式设计十分复杂且有难度，在此之前，如果能够查看某些融资关键词附近上下文， 可帮助研究者更全面地了解数据集中关键词的使用情况和语境，更好的设计正则表达式，亦或许意外找出新的有价值的线索。</p>
<br>
<h2 id="代码">代码</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">jieba</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">from</span> <span class="nn">nltk.tokenize</span> <span class="kn">import</span> <span class="n">word_tokenize</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">warnings</span>

<span class="k">def</span> <span class="nf">word_in_context</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">keywords</span><span class="p">,</span> <span class="n">window</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">lang</span><span class="o">=</span><span class="s1">&#39;chinese&#39;</span><span class="p">):</span>
    <span class="s2">&#34;&#34;&#34;
</span><span class="s2">    Given text and keywords, the task is to find the text where the keyword appears
</span><span class="s2">    Args:
</span><span class="s2">        text (str): input document, string format
</span><span class="s2">        keywords (list): keywords
</span><span class="s2">        window (int): return the text where the keyword appears, default is 3, meaning return 3 word.
</span><span class="s2">        lang (str, optional): setting the lang, only support chinese and english. Defaults to &#39;chinese&#39;.
</span><span class="s2">
</span><span class="s2">    Returns:
</span><span class="s2">        list contains multiple dictionaries, where each dictionary contains the sentence, keyword, and the sentence where the keyword appears
</span><span class="s2">    &#34;&#34;&#34;</span>
    <span class="k">if</span> <span class="n">lang</span><span class="o">==</span><span class="s1">&#39;chinese&#39;</span><span class="p">:</span>
        <span class="n">words</span> <span class="o">=</span> <span class="n">jieba</span><span class="o">.</span><span class="n">lcut</span><span class="p">(</span><span class="n">text</span><span class="o">.</span><span class="n">lower</span><span class="p">())</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">words</span> <span class="o">=</span> <span class="n">word_tokenize</span><span class="p">(</span><span class="n">text</span><span class="o">.</span><span class="n">lower</span><span class="p">())</span>
        <span class="k">except</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&#34;你应该安装nltk和对应的nltk_data, 请看B站https://www.bilibili.com/video/BV14A411i7DB&#34;</span><span class="p">)</span>
            <span class="n">words</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39; &#39;</span><span class="p">)</span>
    <span class="n">keywords</span> <span class="o">=</span> <span class="p">[</span><span class="n">w</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">keywords</span><span class="p">]</span>
    <span class="n">kw_idxss</span> <span class="o">=</span> <span class="p">[[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">words</span><span class="p">)</span> <span class="k">if</span> <span class="n">x</span> <span class="o">==</span> <span class="n">keyword</span><span class="p">]</span> <span class="k">for</span> <span class="n">keyword</span> <span class="ow">in</span> <span class="n">keywords</span><span class="p">]</span>
    <span class="n">rows</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">keyword</span><span class="p">,</span> <span class="n">kw_idxs</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">keywords</span><span class="p">,</span> <span class="n">kw_idxss</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">kw_idxs</span><span class="p">:</span>
            <span class="n">half</span> <span class="o">=</span> <span class="nb">int</span><span class="p">((</span><span class="n">window</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span>
            <span class="n">start</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">idx</span> <span class="o">-</span> <span class="n">half</span><span class="p">)</span>
            <span class="n">end</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">words</span><span class="p">),</span> <span class="n">idx</span> <span class="o">+</span> <span class="n">half</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">row</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;keyword&#39;</span><span class="p">:</span> <span class="n">keyword</span><span class="p">,</span> 
                   <span class="s1">&#39;context&#39;</span><span class="p">:</span> <span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">words</span><span class="p">[</span><span class="n">start</span><span class="p">:</span> <span class="n">end</span><span class="p">])</span> <span class="k">if</span> <span class="n">lang</span><span class="o">==</span><span class="s1">&#39;chinese&#39;</span> <span class="k">else</span> <span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">words</span><span class="p">[</span><span class="n">start</span><span class="p">:</span> <span class="n">end</span><span class="p">])</span>
                      <span class="p">}</span>
            <span class="n">rows</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">row</span><span class="p">)</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">rows</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">df</span>


</code></pre></div><p><br><br></p>
<h2 id="练习">练习</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#测试代码，假设zh_text是年报文本，从找找出丝网词相关词的上下文</span>
<span class="n">zh_text</span> <span class="o">=</span> <span class="s2">&#34;&#34;&#34;
</span><span class="s2">【插入一条自家广告】大邓自己家的家，
</span><span class="s2">安平县多隆丝网制品，生产销售不锈钢轧花网、
</span><span class="s2">电焊网、石笼网、刀片刺绳、冲孔网等丝网制品。
</span><span class="s2">联系人 邓颖静 0318-7686899
</span><span class="s2">
</span><span class="s2">人生苦短，我学Python
</span><span class="s2">在社科中，可以用Python做文本分析
</span><span class="s2">Python是一门功能强大的编程语言，广泛应用在经管社科领域。
</span><span class="s2">可以做网络爬虫、文本分析、LDA话题模型、相似度分析等。
</span><span class="s2">
</span><span class="s2">今年经济不景气，形势异常严峻。
</span><span class="s2">由于疫情不景气，静默管理， 产品积压， 公司经营困难。
</span><span class="s2">保就业促就业，任务十分艰巨。
</span><span class="s2">&#34;&#34;&#34;</span>

<span class="c1">#【产品词】上下文</span>
<span class="n">word_in_context</span><span class="p">(</span><span class="n">text</span> <span class="o">=</span> <span class="n">zh_text</span><span class="p">,</span> 
                <span class="n">keywords</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;石笼&#39;</span><span class="p">],</span> 
                <span class="n">window</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> 
                <span class="n">lang</span><span class="o">=</span><span class="s1">&#39;chinese&#39;</span><span class="p">)</span>
</code></pre></div><table>
<thead>
<tr>
<th>keyword</th>
<th>context</th>
</tr>
</thead>
<tbody>
<tr>
<td>石笼</td>
<td>电焊网、石笼网、刀片刺绳</td>
</tr>
</tbody>
</table>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#【经营】上下文</span>
<span class="n">word_in_context</span><span class="p">(</span><span class="n">text</span> <span class="o">=</span> <span class="n">zh_text</span><span class="p">,</span> 
                <span class="n">keywords</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;经营&#39;</span><span class="p">],</span> 
                <span class="n">window</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> 
                <span class="n">lang</span><span class="o">=</span><span class="s1">&#39;chinese&#39;</span><span class="p">)</span>
</code></pre></div><table>
<thead>
<tr>
<th>keyword</th>
<th>context</th>
</tr>
</thead>
<tbody>
<tr>
<td>经营</td>
<td>&gt;积压， 公司经营困难。\n保</td>
</tr>
</tbody>
</table>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#【Python】上下文</span>
<span class="n">word_in_context</span><span class="p">(</span><span class="n">text</span> <span class="o">=</span> <span class="n">zh_text</span><span class="p">,</span> 
                <span class="n">keywords</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;python&#39;</span><span class="p">],</span> 
                <span class="n">window</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> 
                <span class="n">lang</span><span class="o">=</span><span class="s1">&#39;chinese&#39;</span><span class="p">)</span>
</code></pre></div><table>
<thead>
<tr>
<th>keyword</th>
<th>context</th>
</tr>
</thead>
<tbody>
<tr>
<td>python</td>
<td>人生苦短，我学python\n在社科中</td>
</tr>
<tr>
<td>python</td>
<td>中，可以用python做文本分析\n</td>
</tr>
<tr>
<td>python</td>
<td>做文本分析\npython是一门功能强大的</td>
</tr>
</tbody>
</table>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>数据集 | 2001-2022年A股上市公司年报&amp;管理层讨论与分析</title>
      <link>https://textdata.cn/blog/2023-03-23-china-a-share-market-dataset-mda-from-01-to-21/</link>
      <pubDate>Thu, 16 Mar 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-03-23-china-a-share-market-dataset-mda-from-01-to-21/</guid>
      <description>&lt;p&gt;2001-2022年A股年报数据集，含2个文件，共2G。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;年报 &lt;strong&gt;A01-22.xlsx&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;管理层讨论与分析 &lt;strong&gt;mda01-22.xlsx&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;xlsx与csv相比，同样的数据量，文件体积会小很多。截图对比&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/dataset.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;注意， 当数据的记录数小于100w条， 数据如果不考虑体积，存储到csv和xlsx都是okay的，推荐xlsx。当数据记录数大于100w， 只能存储到csv。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;数据获取&#34;&gt;数据获取&lt;/h2&gt;
&lt;p&gt;数据集不单卖， 打包50元，&lt;strong&gt;加微信 372335839， 备注「姓名-学校-专业」&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;一年报数据&#34;&gt;一、年报数据&lt;/h2&gt;
&lt;p&gt;2001-2022年， 年报数据&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pandas&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pd&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read_excel&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;A01-22.xlsx&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;head&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/df1.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;55222
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;二mda数据&#34;&gt;二、MD&amp;amp;A数据&lt;/h2&gt;
&lt;p&gt;2001-2022年MD&amp;amp;A数据&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pandas&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pd&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;mda_df&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read_excel&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;mda01-22.xlsx&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;mda_df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;head&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/df2.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mda_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;55439
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;广而告之&#34;&gt;广而告之&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/call_for_paper/&#34;&gt;长期征稿&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/we_need_you/&#34;&gt;长期招募小伙伴&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/management_python_course/&#34;&gt;付费视频课 | Python实证指标构建与文本分析&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
      <content:encoded><![CDATA[<p>2001-2022年A股年报数据集，含2个文件，共2G。</p>
<ul>
<li>
<p>年报 <strong>A01-22.xlsx</strong></p>
</li>
<li>
<p>管理层讨论与分析 <strong>mda01-22.xlsx</strong></p>
</li>
</ul>
<p>xlsx与csv相比，同样的数据量，文件体积会小很多。截图对比</p>
<p><img loading="lazy" src="img/dataset.png" alt=""  />
</p>
<blockquote>
<p>注意， 当数据的记录数小于100w条， 数据如果不考虑体积，存储到csv和xlsx都是okay的，推荐xlsx。当数据记录数大于100w， 只能存储到csv。</p>
</blockquote>
<p><br><br></p>
<h2 id="数据获取">数据获取</h2>
<p>数据集不单卖， 打包50元，<strong>加微信 372335839， 备注「姓名-学校-专业」</strong>。</p>
<p><br><br></p>
<h2 id="一年报数据">一、年报数据</h2>
<p>2001-2022年， 年报数据</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_excel</span><span class="p">(</span><span class="s1">&#39;A01-22.xlsx&#39;</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<p><img loading="lazy" src="img/df1.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">55222
</code></pre></div><p><br><br></p>
<h2 id="二mda数据">二、MD&amp;A数据</h2>
<p>2001-2022年MD&amp;A数据</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">mda_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_excel</span><span class="p">(</span><span class="s1">&#39;mda01-22.xlsx&#39;</span><span class="p">)</span>
<span class="n">mda_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<p><img loading="lazy" src="img/df2.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="nb">len</span><span class="p">(</span><span class="n">mda_df</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">55439
</code></pre></div><p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>采购合同数据集 | 政府采购何以牵动企业创新</title>
      <link>https://textdata.cn/blog/2023-03-15-gov-procurement-promote-enterpise-innovation/</link>
      <pubDate>Wed, 15 Mar 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-03-15-gov-procurement-promote-enterpise-innovation/</guid>
      <description>中国地方政府采购合同数据是中国政府采购网中国政府购买服务信息平台披露的政府采购合同信息，主要囊括了采购人（甲方）、采购人所属行政区、供应商（乙方）以及合同金额等关键信息。数据自 2008-06-12 ~ 2021-02-03， 共有 648538 条 。如果某个政府采购合同的以上三项信息中包含关键词库内任意一个关键词，那么该合同就被认定为政府创新采购合同。</description>
      <content:encoded><![CDATA[<h2 id="一数据集概况">一、数据集概况</h2>
<p>中国地方政府采购合同数据是中国政府采购网中国政府购买服务信息平台披露的政府采购合同信息，主要囊括了采购人（甲方）、采购人所属行政区、供应商（乙方）以及合同金额等关键信息。数据自 2008-06-12 ~ 2021-02-03， 共有 648538 条 。</p>
<p>网址: <a href="http://www.cgpnews.cn/">http://www.cgpnews.cn/</a></p>
<br>
<table>
<thead>
<tr>
<th>字段</th>
<th>字段标题</th>
<th>字段说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>purchaser</td>
<td>采购人</td>
<td>采购人（甲方）</td>
</tr>
<tr>
<td>address</td>
<td>所属地域</td>
<td>采购人（甲方）所属地域</td>
</tr>
<tr>
<td>administrative_code</td>
<td>行政区代码</td>
<td>采购人（甲方）所属行政区代码（中华人民共和国 6 位行政区划代码，中华人民共和国民政部 2019 年 6 月版）</td>
</tr>
<tr>
<td>provincial_region</td>
<td>省级行政区</td>
<td>采购人（甲方）所属省级行政区（中华人民共和国的第 一级行政区，中国共计 34 个省级行政区，包括 23 个省、 5 个自治区、4 个直辖市、2 个特别行政区）</td>
</tr>
<tr>
<td>perfecture_division</td>
<td>地级行政区</td>
<td>采购人（甲方）所属地级行政区（中华人民共和国的第 二级行政区，中国大陆共计 333 个地级行政区，包括 293 个地级市、7 个地区、30 个自治州、3 个盟）</td>
</tr>
<tr>
<td>supplier</td>
<td>供应商名称</td>
<td>供应商（乙方）名称</td>
</tr>
<tr>
<td>industry</td>
<td>所属行业</td>
<td>供应商（乙方）名称所属行业</td>
</tr>
<tr>
<td>contract_number</td>
<td>合同编号</td>
<td>合同编号</td>
</tr>
<tr>
<td>contract_name</td>
<td>合同名称</td>
<td>合同名称</td>
</tr>
<tr>
<td>contract_amount</td>
<td>合同金额</td>
<td>合同金额（单位: 万元）</td>
</tr>
<tr>
<td>project_number</td>
<td>项目编号</td>
<td>项目编号</td>
</tr>
<tr>
<td>project_name</td>
<td>项目名称</td>
<td>项目名称</td>
</tr>
<tr>
<td>contract_date</td>
<td>签订日期</td>
<td>签订日期</td>
</tr>
<tr>
<td>announcement_date</td>
<td>公告日期</td>
<td>公告日期</td>
</tr>
<tr>
<td>agency</td>
<td>代理机构</td>
<td>代理机构</td>
</tr>
<tr>
<td>contract_id</td>
<td>合同标识</td>
<td>合同唯一标识符</td>
</tr>
<tr>
<td>if_joint</td>
<td>是否众包</td>
<td>一个采购合同是否对应多家供应商。是记为“1”，否记为 “0”</td>
</tr>
</tbody>
</table>
<p><br><br></p>
<h2 id="二读取数据集">二、读取数据集</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;data/中国地方政府采购合同.csv&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">,</span> <span class="n">low_memory</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/df.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">648538
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df</span><span class="p">[</span><span class="s1">&#39;contract_date&#39;</span><span class="p">]</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">    0        2020-12-02
    1        2020-06-14
    2        2020-05-28
    3        2020-05-14
    4        2020-05-13
                ...    
    648533   2018-11-07
    648534   2018-11-07
    648535   2018-11-07
    648536   2018-11-01
    648537   2018-10-30
    Name: contract_date, Length: 648538, dtype: datetime64[ns]
</code></pre></div><p><br><br></p>
<h2 id="三相关论文">三、相关论文</h2>
<p>孙薇,叶初升.政府采购何以牵动企业创新——兼论需求侧政策“拉力”与供给侧政策“推力”的协同[J].中国工业经济,2023,(01):1-19.</p>
<br>
<h3 id="31-方法">3.1 方法</h3>
<p>通过 <strong>Python爬虫技术</strong> 获取中国政府采购新闻网 2015—2020 年 64 余万条政府采购合同数据，采用 <strong>文本分析方法</strong> 识别出政府创新采购，进而利用政府创新采购合同与中国 A 股上市企业匹配数据，实证检验政府创 新采购的创新效应及其影响机制，并对需求侧的政府创新支持“拉力”和供给侧的政府创新支持“推力”进行异质性分析，进一步探讨了两侧创新支持政策实施中的协同性问题，从而为政府精准施策提供学术依据。</p>
<br>
<h3 id="32-创新">3.2 创新</h3>
<p>本文的边际贡献在于：</p>
<ul>
<li>①<strong>基于政府采购合同数据，使用文本分析方法，从总体的政府采购中识 别出政府创新采购，为准确评估政府采购政策的创新效应创造了前提条件</strong>；</li>
<li>②在一个理论框架内阐 明了政府创新采购影响企业创新的机制，并进行了相应的实证检验，从理论和实证两个方面丰富了 需求侧创新政策激励效应的研究；</li>
<li>③从政策组合的整体视角考察了两侧创新支持政策的协同性问 题，为新发展阶段全面提升中国创新激励政策的实施效果、更好发挥“有为政府”在创新驱动中的作 用提供了重要的政策启示。</li>
</ul>
<br>
<h3 id="33-算法">3.3 算法</h3>
<p><strong>本文将各级国家机关和事业单位对创新产品和服务的采购界定为政府创新采购，并应用文本分析方法从总体的政府采购中加以识别</strong>。</p>
<p>本文使用的政府采购查询系统，对于每一份合同，网站都披露了合同名称、签订日期、合同金额、供应商名称、采购人 名称、所属地区等信息。 由于从 2015 年开始可以查询到较为详细的采购合同信息，因此，本文选取 2015—2020 年作为实证研究的年份区间。</p>
<p>（1）基于文本分析的政府创新采购识别。 本文的文本分析基于 Python 的 jieba分词实现。 为提升分词结果的可靠性，本文构建了行业词库和停用词库，以形成对 Jieba 分词自带词库的有益补充。 基于以上词库，对《重大技术装备自主创新指导目录（2012）》和《战略性新兴产业分类（2018）》中的 “重点产品和服务目录”以及手工收集的各地区创新产品目录进行分词 ，并对分词结果进行精细化的人工筛选，最终得到包含“智能电网” “液相色谱仪” “智能医疗系统” “物联网网关” “旋翼无人机” “管道机器人” 等 3000 余个词汇的政府创新采购关键词库。 随后，对 2015—2020 年 64 余万条政 府采购合同的“合同名称”“ 主要标的名称”和“规格型号或服务要求”进行分词。 <strong>如果某个政府采购合同的以上三项信息中包含关键词库内任意一个关键词，那么该合同就被认定为政府创新采购合同</strong>。</p>
<p>（2）“政府创新采购合同-上市企业”匹配。 在对各企业供应商的名称初步清洗之后，采用 Python 的 levenshtein distance 算法，进行“政府创新采购合同—上市企业”匹配。 为提升匹配精度， 同时开展模糊匹配和精确匹配，并以人工校对的方式汇总匹配结果。  考虑到上市企业往往会有较多子公司参与政府采购的招投标，本文手工整理了分年度的上市企业母、子公司名称，据此匹配，并将匹配结果合并。 最终共有 873 家上市企业匹配到政府创新采购合同，在本文的总样本中，每家上市企业平均获得政府创新采购合同约 1.21 份。</p>
<h2 id="四python技术细节">四、Python技术细节</h2>
<ol>
<li>网络爬虫采集政府采购网数据</li>
<li>jieba分词</li>
</ol>
<ul>
<li>导入创新技术相关词，更新jieba自定义词库</li>
<li>分词</li>
</ul>
<ol start="3">
<li>使用if语句判断是否含某创新词</li>
<li>文本相似度进行采购合同上市公司匹配。levenshtein distance</li>
</ol>
<p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>EDGAR | 25年数据的预训练词向量模型</title>
      <link>https://textdata.cn/blog/2023-03-08-edgar-w2v-and-corpus/</link>
      <pubDate>Wed, 08 Mar 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-03-08-edgar-w2v-and-corpus/</guid>
      <description>EDGAR 是美国证券交易委员会（SEC）的电子数据收集、分析和检索系统。EDGAR系统允许公众通过互联网访问公司提交给SEC的各种文件，例如注册声明、年度报告和其他披露文件。这些文件包括公司的财务信息、业务信息和其他关键信息，对于投资者和研究人员来说非常有用。金融等方向的同学，如果想用 **词嵌入** 技术开展研究， 可以考虑使用这个开源的数据集。EDGAR is an electronic data collection, analysis, and retrieval system of the US Securities and Exchange Commission (SEC). The EDGAR system allows the public to access various documents submitted to the SEC by companies through the internet, such as registration statements, annual reports, and other disclosure documents. These documents include financial information, business information, and other key information of the companies, which is very useful for investors and researchers. Students in finance and related fields who want to conduct research using word embedding techniques may consider using this open-source dataset.</description>
      <content:encoded><![CDATA[<p>EDGAR 是美国证券交易委员会（SEC）的电子数据收集、分析和检索系统。EDGAR系统允许公众通过互联网访问公司提交给SEC的各种文件，例如注册声明、年度报告和其他披露文件。这些文件包括公司的财务信息、业务信息和其他关键信息，对于投资者和研究人员来说非常有用。</p>
<p>金融等方向的同学，如果想用 <strong>词嵌入</strong> 技术开展研究， 可以考虑使用这个开源的数据集。</p>
<br>
<h2 id="一edgar-corpus">一、EDGAR-CORPUS</h2>
<p>在 EMNLP 2021同时举办的经济与自然语言处理研讨会（ECONLP）论文集中， 发布了EDGAR-CORPUS，这是一个新颖的语料库，包括美国所有上市公司超过25年的年报。</p>
<p>所有报告都已下载，拆分为相应的项目（部分），并以清洁、易于使用的JSON格式提供。</p>
<h3 id="11-下载数据">1.1 下载数据</h3>
<p><a href="https://zenodo.org/record/5528490">https://zenodo.org/record/5528490</a></p>
<p><img loading="lazy" src="img/edgar-corpus.png" alt=""  />
</p>
<br>
<h3 id="1-2-引用格式">1. 2 引用格式</h3>
<p>Lefteris Loukas, Manos Fergadiotis, Ion Androutsopoulos, &amp; Prodromos Malakasiotis. (2021). EDGAR-CORPUS [Data set]. Zenodo. <a href="https://doi.org/10.5281/zenodo.5528490">https://doi.org/10.5281/zenodo.5528490</a></p>
<p><br><br></p>
<h2 id="二edgar-w2v-embeddings">二、EDGAR-W2V Embeddings</h2>
<p>EDGAR-W2V 是在 EDGAR-CORPUS 上训练的词嵌入模型。 它是一个200维的模型，包含 10 万个金融词汇。EDGAR-W2V的相关信息可以在题为“EDGAR-CORPUS: Billions of Tokens Make The World Go Round”的论文中找到，该论文发表于2021年EMNLP会议上的经济学和自然语言处理研讨会（ECONLP）。</p>
<h3 id="11-下载模型">1.1 下载模型</h3>
<p><a href="https://zenodo.org/record/5524358">https://zenodo.org/record/5524358</a>
<img loading="lazy" src="img/edgar-w2v.png" alt=""  />
</p>
<br>
<h3 id="1-2-引用格式-1">1. 2 引用格式</h3>
<p>Lefteris Loukas, Manos Fergadiotis, Ion Androutsopoulos, &amp; Prodromos Malakasiotis. (2021). EDGAR-W2V Embeddings. Zenodo. <a href="https://doi.org/10.5281/zenodo.5524358">https://doi.org/10.5281/zenodo.5524358</a></p>
<br>
<h2 id="三代码">三、代码</h2>
<h3 id="31-导入词汇表">3.1 导入词汇表</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">vocab</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;edgar.word.w2v.200.vocab&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">read</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;词汇量: &#39;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">))</span>

<span class="c1">#显示前100个</span>
<span class="nb">print</span><span class="p">(</span><span class="n">vocab</span><span class="p">[:</span><span class="mi">100</span><span class="p">])</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">词汇量:  100000

[&#39;the&#39;,
 &#39;,&#39;,
 &#39;of&#39;,
 &#39;.&#39;,
 &#39;and&#39;,
 &#39;to&#39;,
 &#39;NEWLINETOKEN&#39;,
 &#39;in&#39;,
 &#39;a&#39;,
 &#39;for&#39;,
 ......
 &#39;including&#39;,
 &#39;accounting&#39;,
 &#39;operating&#39;,
 &#39;1&#39;,
 &#39;fair&#39;,
 &#39;also&#39;,
 &#39;credit&#39;,
 &#39;capital&#39;,
 &#39;notes&#39;,
 &#39;securities&#39;,
 &#39;rate&#39;]
</code></pre></div><br>
<h3 id="31-导入w2v模型文件">3.1 导入W2V模型文件</h3>
<p>edgar.word.w2v.200.bin只存储了</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">gensim.models.keyedvectors</span> <span class="kn">import</span> <span class="n">KeyedVectors</span>

<span class="n">edgar_wv</span> <span class="o">=</span> <span class="n">KeyedVectors</span><span class="o">.</span><span class="n">load_word2vec_format</span><span class="p">(</span><span class="s1">&#39;edgar.word.w2v.200.bin&#39;</span><span class="p">,</span> 
                                             <span class="n">binary</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
                                             <span class="n">unicode_errors</span><span class="o">=</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>
</code></pre></div><br>
<p>查看某个词的词向量, 返回长度200维的向量</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="nb">print</span><span class="p">(</span><span class="n">edgar_wv</span><span class="p">[</span><span class="s1">&#39;stock&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">edgar_wv</span><span class="p">[</span><span class="s1">&#39;stock&#39;</span><span class="p">]</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">(200,)

array([ 0.19913645, -0.06109103, -0.20294489, -0.3233174 ,  0.33050874,
        0.4720499 ,  0.1584721 , -0.73845965, -0.320686  , -0.03934   ,
        0.24570467,  0.33919033, -0.42398626, -0.0519694 ,  0.5614962 ,
        0.06250261,  0.12337335,  0.4284085 , -0.18471783,  0.27163157,
       -0.25374356, -0.30515426, -0.53030056,  0.14488244,  0.23602249,
        0.17834061,  0.5282402 ,  0.35811898,  0.02480956, -0.27537134,
        0.46796346,  0.14656937, -0.24058165, -0.02558263,  0.2823333 ,
        0.13227813, -0.35262054, -0.3534915 , -0.08498703,  0.13652588,
        0.19062333, -0.59584695,  0.4724787 ,  0.0899151 , -0.30575767,
        0.0894967 , -0.42695883,  0.14332667,  0.32162446,  0.5205731 ,
       -0.34024504, -0.15563595,  0.09534936, -0.03550521, -0.24585967,
       -0.70967376,  0.23757844,  0.19296522, -0.14549816, -0.34093133,
        0.44992575, -0.31520963, -0.19251363, -0.2664489 ,  0.22087495,
       -0.0226051 ,  0.02213453, -0.31526777,  0.02245333,  0.01845511,
        0.4727852 ,  0.0823371 , -0.28313273, -0.96016574, -0.34687626,
        0.31235287, -0.2581088 , -0.7164211 ,  0.6806588 ,  0.31276935,
       -0.166056  , -0.5558513 ,  0.10650715, -0.34121472,  0.01264491,
        0.3823984 , -0.6213977 ,  0.532256  , -0.11913523,  0.22344823,
        0.3172406 , -0.08887295,  0.14381133,  0.23814514, -0.09513577,
        0.10691381,  0.13318019, -0.10131137,  0.51121044, -0.13446783,
       -0.34249052,  0.21858525, -0.66716367, -0.1002802 ,  0.1822924 ,
       -0.17896068,  0.36693272, -0.26906306,  0.16348957,  0.309529  ,
       -0.5283489 ,  0.38473064, -0.4563293 , -0.36093566,  0.02899153,
       -0.16942917, -0.24810787,  0.04769324,  0.07288674,  0.05372427,
       -0.21368156, -0.2308374 , -0.47956762,  0.26331866,  0.08796341,
        0.0316316 , -0.04519949,  0.03246075, -0.06966034,  0.08757813,
        0.16438614, -0.16775173, -0.10321777,  0.21712255,  0.1252789 ,
       -0.34793332,  0.01499637, -0.32516828,  0.15845637, -0.1023875 ,
       -0.05895114, -0.08138125,  0.08420486, -0.18958494, -0.22417304,
        0.5160968 ,  0.13966903,  0.17438166,  0.13805066, -0.1817818 ,
        0.09644702, -0.34120768,  0.36722133, -0.06767058, -0.3896219 ,
       -0.1555085 , -0.07321457, -0.24285823, -0.23933856,  0.26198393,
       -0.12067977,  0.4152437 , -0.5361226 ,  0.02143142, -0.47723222,
       -0.27638227, -0.272431  ,  0.27474684,  0.02058701,  0.398542  ,
        0.12495182, -0.43948382, -0.41649124, -0.10416509, -0.013862  ,
        0.2630676 ,  0.0534305 ,  0.26379627, -0.33174622,  0.30189517,
        0.13504176, -0.09992695,  0.6300687 , -0.14120325, -0.04877585,
        0.3973992 ,  0.50578755,  0.07440792, -0.10353652, -0.60702443,
       -0.09498709,  0.1284441 , -0.13405691, -0.19467972, -0.09931252,
       -0.28807166, -0.49167937,  0.501096  ,  0.41336802, -0.4281704 ],
      dtype=float32)
</code></pre></div><p><br><br></p>
<h2 id="四相关内容">四、相关内容</h2>
<p>如果想了解更多词嵌入(或词向量)信息，可以阅读:</p>
<ul>
<li><a href="https://textdata.cn/blog/wordembeddingsinsocialscience/">转载 | 大数据时代下社会科学研究方法的拓展——基于词嵌入技术的文本分析的应用</a></li>
<li><a href="https://textdata.cn/blog/from_sysbol_to_embeddings_in_computational_social_science/">转载 | 从符号到嵌入：计算社会科学的两种文本表示</a></li>
<li><a href="https://textdata.cn/blog/2023-03-15-39faq-about-word-embeddings-for-social-science/">词嵌入技术在社会科学领域进行数据挖掘常见39个FAQ汇总</a></li>
<li><a href="https://textdata.cn/blog/embeddingsandattitude/">词嵌入测量不同群体对某概念的态度(偏见)</a></li>
<li><a href="https://textdata.cn/blog/2022-09-07-management-science-disrupt-science-and-technology">Management Science | 使用网络算法识别创新的颠覆性与否</a></li>
<li><a href="https://textdata.cn/blog/2023-03-03-extracts-cognitive-information-and-visualization-with-embedings/">可视化 | 词嵌入模型用于计算社科领域刻板印象等信息（含代码）</a></li>
<li><a href="https://textdata.cn/blog//2022-11-14-pnas_naming_unrelated_words_predicts_creativity/">PNAS | 使用语义距离测量一个人的创新力(发散思维)得分</a></li>
<li><a href="https://textdata.cn/blog/douban_w2v/">豆瓣影评 | 探索词向量妙处</a></li>
<li><a href="https://textdata.cn/blog/whatlies_word2vec/">whatlies库 | 可视化词向量</a></li>
<li><a href="https://textdata.cn/blog/embeddings_resource_usage_method/">中文词向量资源汇总 &amp; 使用方法</a></li>
<li><a href="https://textdata.cn/blog/pretained_nlp_models/">NLP资源 | 汽车、金融等9大领域预训练词向量模型下载资源</a></li>
<li><a href="https://textdata.cn/blog/2022-10-16-aligned-word-vectors/">数据集 | 多语言对齐词向量预训练模型</a></li>
</ul>
<p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://hidadeng.github.io/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://hidadeng.github.io/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://hidadeng.github.io/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>数据集 | 马前卒工作室睡前消息文稿汇总</title>
      <link>https://textdata.cn/blog/2023-03-06-bedtime-news-datasets/</link>
      <pubDate>Mon, 06 Mar 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-03-06-bedtime-news-datasets/</guid>
      <description>一直有观看马前卒工作室睡前消息的习惯， 感觉他的内容很理性， 透露着马列科学社会风。 引爆全网的两个话题独山县债务问题、以岭药业连花清瘟胶囊事件。 **数据可以拿来练习词频统计、词云图制作、情感分析、lda话题建模。已整理为csv文件，留给需要的人**。</description>
      <content:encoded><![CDATA[<p>一直有观看马前卒工作室睡前消息的习惯， 感觉他的内容很理性， 透露着马列科学社会风。 引爆全网的两个话题独山县债务问题、以岭药业连花清瘟胶囊事件。 <strong>数据可以拿来练习词频统计、词云图制作、情感分析、lda话题建模。已整理为csv文件，留给需要的人</strong>。</p>
<p><img loading="lazy" src="img/yilingyaoye.jpg" alt=""  />
</p>
<p><img loading="lazy" src="img/dushanxian.jpeg" alt=""  />
</p>
<br>
<h2 id="一原始数据">一、原始数据</h2>
<p>『睡前消息』截止2023年3月6日，已经更新至559期. 文稿资源来自 <a href="https://archive.bedtime.news/zh/main">https://archive.bedtime.news/zh/main</a></p>
<p>原始数据集下载下来是这个样子</p>
<p><img loading="lazy" src="img/directory.png" alt=""  />
</p>
<p><img loading="lazy" src="img/sub_dir.png" alt=""  />
</p>
<p><img loading="lazy" src="img/filelists.png" alt=""  />
</p>
<br>
<p>数据集文件夹的目录树结构</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">- 睡前消息文本 第1-100期
    |- 001-010期
       |- 2019 07 12 第一期.docx
       |- 2019 07 16 第二期.docx
       |- 2019 07 19 第三期.docx
       |- 2019 07 23 第四期.docx
       |- ...
    |- 011-020期
    |- 021-030期
    |-...
- 睡前消息文本 第101-200期
- 睡前消息文本 第201-300期
- 睡前消息文本 第301-400期
- 睡前消息文本 第401-500期
- 睡前消息文本 第501-最新
- bedtime_news.csv
- code.ipynb
</code></pre></div><br>
<h2 id="一整理数据">一、整理数据</h2>
<p>原始数据docx文件存储，数据集是2层文件夹结构。可以使用glob库提供文件路径识别功能</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-PYTHON" data-lang="PYTHON"><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">glob</span>
<span class="kn">import</span> <span class="nn">csv</span>
<span class="kn">from</span> <span class="nn">pdfdocx</span> <span class="kn">import</span> <span class="n">read_docx</span>

<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;bedtime_news.csv&#39;</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">,</span> <span class="n">newline</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">csvf</span><span class="p">:</span>
    <span class="n">fieldnames</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">,</span> <span class="s1">&#39;name&#39;</span><span class="p">,</span> <span class="s1">&#39;text&#39;</span><span class="p">]</span>
    <span class="n">writer</span> <span class="o">=</span> <span class="n">csv</span><span class="o">.</span><span class="n">DictWriter</span><span class="p">(</span><span class="n">csvf</span><span class="p">,</span> <span class="n">fieldnames</span> <span class="o">=</span> <span class="n">fieldnames</span><span class="p">)</span>
    <span class="n">writer</span><span class="o">.</span><span class="n">writeheader</span><span class="p">()</span>

    <span class="c1"># 使用glob模块查找所有的docx文件路径</span>
    <span class="n">docx_files</span> <span class="o">=</span> <span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="s2">&#34;**/*.docx&#34;</span><span class="p">,</span> <span class="n">recursive</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">docx_files</span> <span class="o">=</span> <span class="p">[</span><span class="n">f</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">docx_files</span> <span class="k">if</span> <span class="s1">&#39;DS&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">f</span><span class="p">]</span>

    <span class="c1"># 输出所有docx文件路径</span>
    <span class="k">for</span> <span class="n">file_path</span> <span class="ow">in</span> <span class="n">docx_files</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">file_path</span><span class="p">)</span>
        <span class="n">file_name</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s1">&#39;\s&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">file_path</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;/&#39;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
        <span class="k">if</span> <span class="n">file_name</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;22&#39;</span><span class="p">):</span>
            <span class="n">file_name</span> <span class="o">=</span> <span class="s1">&#39;2022&#39;</span><span class="o">+</span> <span class="n">file_name</span><span class="p">[</span><span class="mi">2</span><span class="p">:]</span>
        <span class="n">date</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">findall</span><span class="p">(</span><span class="s1">&#39;\d</span><span class="si">{8}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">file_name</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">episode</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s1">&#39;.docx&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">file_name</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">date</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">))</span>
        <span class="n">text</span> <span class="o">=</span> <span class="n">read_docx</span><span class="p">(</span><span class="n">file_path</span><span class="p">)</span>
        <span class="n">data</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&#34;date&#34;</span><span class="p">:</span> <span class="nb">str</span><span class="p">(</span><span class="n">date</span><span class="p">),</span> 
                <span class="s2">&#34;name&#34;</span><span class="p">:</span> <span class="n">file_path</span><span class="p">,</span>
                <span class="s2">&#34;text&#34;</span><span class="p">:</span><span class="n">text</span><span class="p">}</span>
        <span class="n">writer</span><span class="o">.</span><span class="n">writerow</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</code></pre></div><br>
<h2 id="二导入csv">二、导入csv</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&#34;bedtime_news.csv&#34;</span><span class="p">,</span> <span class="n">converters</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;date&#39;</span><span class="p">:</span> <span class="nb">str</span><span class="p">})</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<p><img loading="lazy" src="img/df.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">522
</code></pre></div><br>
<h2 id="获取方式">获取方式</h2>
<p>链接: <a href="https://pan.baidu.com/s/1Qor_FNBnGuTsq4NpF3vzVQ">https://pan.baidu.com/s/1Qor_FNBnGuTsq4NpF3vzVQ</a> 提取码: t8pq</p>
<br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://hidadeng.github.io/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://hidadeng.github.io/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>1850万条 | 世界地图POI兴趣点数据集</title>
      <link>https://textdata.cn/blog/2022-12-10-1850w-poi-dataset/</link>
      <pubDate>Sat, 10 Dec 2022 00:00:00 +0000</pubDate>
      
      <guid>/blog/2022-12-10-1850w-poi-dataset/</guid>
      <description>1850万条世界地图POI兴趣点数据集，可用于GIS、区域经济等领域的研究</description>
      <content:encoded><![CDATA[<h2 id="世界地图poi兴趣点数据集">世界地图POI兴趣点数据集</h2>
<p>POI数据集包含全球超过 1850 万个 POI， 数据按国家或地区组织分别以 CSV 文存档中， 数据集每月更新一次。</p>
<br>
<h2 id="数据价值">数据价值</h2>
<p>POI数据集含 区域位置、商业地点、营业时间，运营主体，网站等信息， 可用于GIS、区域经济等领域的研究。
<strong>文末有数据集获取方式</strong> , 数据集中包含的字段有</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">- ID OpenStreetMap ID
- NAME 地名、国际名称
- CATEGORY、SUBCATEGORY POI类目/子类目
- LAT、LON 经度、纬度
- SRID 基于OSM标签的POI分类（14类167子类）
- WKT   WGS84中的geometry (WKT)；
- IMAGE 链接到照片/图像；
- OPENING_HOURS  营业时间
- WIKIPEDIA 链接到维基百科文章；
- LAST_UPDATE 上次更新日期，
- OPERATOR 运营商
- ALTERNATIVE_NAME 备用名称
- INTERNATIONAL_NAME 国际名称（通常为英文或音译为拉丁字符）；
- STREET、HOUSENUMBER 地址（街道、门牌号）
- POSTCODE、CITY、COUNTRY   地址（邮编、城市、国家）；
- DESCRIPTION 完整描述（如果在 OSM 中列出）；
- PHONE、FAX、WEBSITE、EMAIL      联系人（电话号码、传真号码、网站、邮箱）；
- OTHER_TAGS 而其余标记值列在“OTHER_TAGS”列下。
</code></pre></div><br>
<p><img loading="lazy" src="img/world.png" alt=""  />
</p>
<p><img loading="lazy" src="img/asia.png" alt=""  />
</p>
<br>
<h3 id="数据质量对比">数据质量对比</h3>
<p>OpenStreetMap（简称OSM，中文是公开地图）是一个网上地图协作计划，目标是创造一个内容自由且能让所有人编辑的世界地图。OSM的数据有两种来源</p>
<ul>
<li>广大用户的贡献（众包），包括利用 GPS 设备自行测绘和根据卫星影像地图（Bing/Yahoo!/Landsat等）绘制两种，</li>
<li>少数政府部门的测绘机构及商业公司根据相应授权提供。</li>
</ul>
<p>而Google的数据则主要依靠专业测绘商采购（在中国主要是 AutoNavi/高德），以自己采集（街景）、政府部门提供（主要是NASA的Landsat影像）和用户贡献（Google Map Maker）作为补充。据此不难看出，OSM数据的优势主要体现在更新及时，而Google则胜在较强的专业性和准确性。至于数据的覆盖面，这要看OSM贡献者数量和Google财力与测绘商能力的对比。当OSM贡献者的数量和参与热情达到一定水平，其数据的数量和质量完全不逊于Google（请看OSM上德国地图）。维基百科战胜大英百科全书即是侧证。</p>
<br>
<h2 id="导入数据">导入数据</h2>
<p>以中国数据为例</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;china-pois.osm.csv&#39;</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s1">&#39;|&#39;</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/df.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#poi数据量</span>
<span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
</code></pre></div><pre><code>911246
</code></pre>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#poi数据集的字段</span>
<span class="n">df</span><span class="o">.</span><span class="n">columns</span>
</code></pre></div><pre><code>Index(['ID', 'NAME', 'CATEGORY', 'SUBCATEGORY', 'LON', 'LAT', 'SRID', 'WKT',
       'CITY', 'IMAGE', 'EMAIL', 'COUNTRY', 'OPENING_HOURS', 'WIKIPEDIA',
       'OPERATOR', 'DESCRIPTION', 'LAST_UPDATE', 'ALTERNATIVE_NAME',
       'POSTCODE', 'INTERNATIONAL_NAME', 'WEBSITE', 'PHONE', 'NAME_EN',
       'STREET', 'HOUSENUMBER', 'FAX', 'OTHER_TAGS'],
      dtype='object')
</code></pre>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#poi类型分布</span>
<span class="n">df</span><span class="o">.</span><span class="n">CATEGORY</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</code></pre></div><pre><code>SETTLEMENTS      397769
TRANSPORT        198462
EDUCATION         56087
LANDUSE           50161
TOURISM           47618
SHOP              42939
EAT/DRINK         28386
PUBLICSERVICE     22905
AUTOMOTIVE        14809
ACCOMMODATION     13092
BUSINESS          12573
HEALTH            10747
RELIGIOUS          8039
SPORT              7659
Name: CATEGORY, dtype: int64
</code></pre>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#经纬度范围</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;经度(东)&#39;</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">LON</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;经度(西)&#39;</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">LON</span><span class="o">.</span><span class="n">min</span><span class="p">())</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;纬度(北)&#39;</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">LAT</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;纬度(南)&#39;</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">LAT</span><span class="o">.</span><span class="n">min</span><span class="p">())</span>
</code></pre></div><pre><code>经度(东) 135.08528800000002
经度(西) 72.2818637
纬度(北) 53.56513885988782
纬度(南) 15.1251016
</code></pre>
<br>
<h2 id="字段解析">字段解析</h2>
<ul>
<li>ID OpenStreetMap ID</li>
<li>NAME 地名、国际名称</li>
<li>CATEGORY、SUBCATEGORY POI类目/子类目</li>
<li>LAT、LON 经度、纬度</li>
<li>SRID 基于OSM标签的POI分类（14类167子类）</li>
<li>WKT   WGS84中的geometry (WKT)；</li>
<li>IMAGE 链接到照片/图像；</li>
<li>OPENING_HOURS  营业时间</li>
<li>WIKIPEDIA 链接到维基百科文章；</li>
<li>LAST_UPDATE 上次更新日期，</li>
<li>OPERATOR 运营商</li>
<li>ALTERNATIVE_NAME 备用名称</li>
<li>INTERNATIONAL_NAME 国际名称（通常为英文或音译为拉丁字符）；</li>
<li>STREET、HOUSENUMBER 地址（街道、门牌号）</li>
<li>POSTCODE、CITY、COUNTRY   地址（邮编、城市、国家）；</li>
<li>DESCRIPTION 完整描述（如果在 OSM 中列出）；</li>
<li>PHONE、FAX、WEBSITE、EMAIL      联系人（电话号码、传真号码、网站、邮箱）；</li>
<li>OTHER_TAGS 而其余标记值列在“OTHER_TAGS”列下。</li>
</ul>
<br>
<h2 id="下载地址">下载地址</h2>
<p>数据集下载地址</p>
<p><a href="http://download.slipo.eu/results/osm-to-csv/poi/">http://download.slipo.eu/results/osm-to-csv/poi/</a></p>
<br>
<h2 id="参考资料">参考资料</h2>
<ul>
<li><a href="http://slipo.eu/?p=1551">http://slipo.eu/?p=1551</a></li>
<li>OpenStreetMap百度词条</li>
<li><a href="https://www.zhihu.com/question/19993564/answer/14428059">https://www.zhihu.com/question/19993564/answer/14428059</a></li>
<li><a href="http://download.slipo.eu/results/osm-to-csv/poi/">http://download.slipo.eu/results/osm-to-csv/poi/</a></li>
</ul>
<br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>数据集 | 80w知乎用户问答数据</title>
      <link>https://textdata.cn/blog/2023-03-06-zhihurec-dataset/</link>
      <pubDate>Sat, 10 Dec 2022 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-03-06-zhihurec-dataset/</guid>
      <description>ZhihuRec数据集由清华大学信息检索组（THUIR）和知乎公司共同构建，仅供研究使用。ZhihuRec 数据集是从知识共享平台（知乎）收集的，该平台由 10 天内收集的约 100M 交互、798K 用户、165K 问题、554K 答案、240K 作者、70K 主题和超过 501K 用户查询日志组成。 还有用户、答案、问题、作者和主题的描述，这些都是匿名的。 据我们所知，这是用于个性化推荐的最大的真实世界交互数据集。由于ZhihuRec数据集包含约100M的用户回答印象日志，因此也称为ZhihuRec-100M。 还构建了从 ZhihuRec-100M 数据集随机采样的两个较小的数据集，分别称为 ZhihuRec-20M 和 ZhihuRec-1M，以满足各种应用需求。 它们包含大约 20M 和 1M 的用户回答印象日志，可以看作是一个中等大小的数据集和一个相对较小的数据集。</description>
      <content:encoded><![CDATA[<h2 id="一zhihurec介绍">一、ZhihuRec介绍</h2>
<p>ZhihuRec数据集由 <strong>清华大学信息检索组</strong>（THUIR）和  <strong>知乎公司</strong> 共同构建，仅供研究使用。ZhihuRec 数据集是从知识共享平台（知乎）收集的，该平台由 10 天内收集的约 一亿(100M) 次交互、798K 用户、165K 问题、554K 答案、240K 作者、70K 主题和超过 501K 用户查询日志组成。 还有用户、答案、问题、作者和主题的描述，这些都是匿名的。 据我们所知，这是用于个性化推荐的最大的真实世界交互数据集。由于ZhihuRec数据集包含约100M的用户回答印象日志，因此也称为ZhihuRec-100M。 还构建了从 ZhihuRec-100M 数据集随机采样的两个较小的数据集，分别称为 ZhihuRec-20M 和 ZhihuRec-1M，以满足各种应用需求。 它们包含大约 20M 和 1M 的用户回答印象日志，可以看作是一个中等大小的数据集和一个相对较小的数据集。</p>
<br>
<p><strong>ZhihuRec项目及下载地址</strong></p>
<ul>
<li><a href="https://github.com/THUIR/ZhihuRec-Dataset">https://github.com/THUIR/ZhihuRec-Dataset</a></li>
<li><a href="https://cloud.tsinghua.edu.cn/d/d6c045c55aa14bb39ebc/">https://cloud.tsinghua.edu.cn/d/d6c045c55aa14bb39ebc/</a></li>
</ul>
<p><br><br></p>
<h2 id="二数据集详情">二、数据集详情</h2>
<h3 id="21-数据集内的文件">2.1 数据集内的文件</h3>
<table>
<thead>
<tr>
<th style="text-align:left">Filename</th>
<th style="text-align:right">Size</th>
<th style="text-align:left">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><code>inter_impression.csv</code></td>
<td style="text-align:right">2.6GB</td>
<td style="text-align:left">user clicks and impressions</td>
</tr>
<tr>
<td style="text-align:left"><code>inter_query.csv</code></td>
<td style="text-align:right">111MB</td>
<td style="text-align:left">user queries</td>
</tr>
<tr>
<td style="text-align:left"><code>info_user.csv</code></td>
<td style="text-align:right">135MB</td>
<td style="text-align:left">the features of the users occured in the dataset</td>
</tr>
<tr>
<td style="text-align:left"><code>info_answer.csv</code></td>
<td style="text-align:right">917MB</td>
<td style="text-align:left">the features of the answers occured in the dataset</td>
</tr>
<tr>
<td style="text-align:left"><code>info_question.csv</code></td>
<td style="text-align:right">14MB</td>
<td style="text-align:left">the features of the questions occured in the dataset</td>
</tr>
<tr>
<td style="text-align:left"><code>info_author.csv</code></td>
<td style="text-align:right">3.1MB</td>
<td style="text-align:left">the features of the authors occured in the dataset</td>
</tr>
<tr>
<td style="text-align:left"><code>info_topic.csv</code></td>
<td style="text-align:right">413KB</td>
<td style="text-align:left">the IDs of the topics occured in the dataset</td>
</tr>
<tr>
<td style="text-align:left"><code>info_token.csv</code></td>
<td style="text-align:right">409MB</td>
<td style="text-align:left">the features of the tokens occured in the dataset</td>
</tr>
</tbody>
</table>
<br>
<h3 id="22-数据集统计信息">2.2 数据集统计信息</h3>
<table>
<thead>
<tr>
<th style="text-align:left">Dataset</th>
<th style="text-align:right">ZhihuRec-100M</th>
<th style="text-align:right">ZhihuRec-20M</th>
<th style="text-align:right">ZhihuRec-1M</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><strong>#impressions</strong> *</td>
<td style="text-align:right">99,978,523</td>
<td style="text-align:right">19,999,857</td>
<td style="text-align:right">999,970</td>
</tr>
<tr>
<td style="text-align:left">#clicks</td>
<td style="text-align:right">26,981,583</td>
<td style="text-align:right">5,402,345</td>
<td style="text-align:right">268,656</td>
</tr>
<tr>
<td style="text-align:left">#clicks : #non-clicks</td>
<td style="text-align:right">1 : 2.71</td>
<td style="text-align:right">1 : 2.70</td>
<td style="text-align:right">1 : 2.72</td>
</tr>
<tr>
<td style="text-align:left"><strong>#queries</strong> *</td>
<td style="text-align:right">3,899,553</td>
<td style="text-align:right">776,201</td>
<td style="text-align:right">38,422</td>
</tr>
<tr>
<td style="text-align:left"><strong>#users</strong> *</td>
<td style="text-align:right">798,086</td>
<td style="text-align:right">159,642</td>
<td style="text-align:right">7,974</td>
</tr>
<tr>
<td style="text-align:left">avg #impressions per user</td>
<td style="text-align:right">125.27</td>
<td style="text-align:right">125.28</td>
<td style="text-align:right">125.40</td>
</tr>
<tr>
<td style="text-align:left">avg #clicks per user</td>
<td style="text-align:right">33.81</td>
<td style="text-align:right">33.84</td>
<td style="text-align:right">33.69</td>
</tr>
<tr>
<td style="text-align:left">#users with queries</td>
<td style="text-align:right">501,893</td>
<td style="text-align:right">100,271</td>
<td style="text-align:right">5,047</td>
</tr>
<tr>
<td style="text-align:left">avg #queries per user</td>
<td style="text-align:right">7.77</td>
<td style="text-align:right">7.74</td>
<td style="text-align:right">7.61</td>
</tr>
<tr>
<td style="text-align:left"><strong>#answers</strong> *</td>
<td style="text-align:right">554,976</td>
<td style="text-align:right">343,103</td>
<td style="text-align:right">81,563</td>
</tr>
<tr>
<td style="text-align:left"><strong>#questions</strong> *</td>
<td style="text-align:right">165,012</td>
<td style="text-align:right">104,130</td>
<td style="text-align:right">29,340</td>
</tr>
<tr>
<td style="text-align:left"><strong>#authors</strong> *</td>
<td style="text-align:right">240,956</td>
<td style="text-align:right">167,796</td>
<td style="text-align:right">47,888</td>
</tr>
<tr>
<td style="text-align:left"><strong>#topics</strong> *</td>
<td style="text-align:right">72,318</td>
<td style="text-align:right">54,785</td>
<td style="text-align:right">22,897</td>
</tr>
<tr>
<td style="text-align:left"><strong>#tokens</strong> *</td>
<td style="text-align:right">556,546</td>
<td style="text-align:right">428,334</td>
<td style="text-align:right">249,586</td>
</tr>
</tbody>
</table>
<br>
<h3 id="23--数据集字段">2.3  数据集字段</h3>
<blockquote>
<p>Some fields in the data set are null, which are represented by empty strings in the file.</p>
</blockquote>
<h3 id="inter_impressioncsv"><code>inter_impression.csv</code></h3>
<table>
<thead>
<tr>
<th style="text-align:right">Index</th>
<th style="text-align:center">Nullable</th>
<th style="text-align:left">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right">0</td>
<td style="text-align:center"></td>
<td style="text-align:left">user ID</td>
</tr>
<tr>
<td style="text-align:right">1</td>
<td style="text-align:center"></td>
<td style="text-align:left">answer ID</td>
</tr>
<tr>
<td style="text-align:right">2</td>
<td style="text-align:center"></td>
<td style="text-align:left">impression timestamp</td>
</tr>
<tr>
<td style="text-align:right">3</td>
<td style="text-align:center"></td>
<td style="text-align:left">click timestamp (0 for non-click)</td>
</tr>
</tbody>
</table>
<br>
<h3 id="inter_querycsv"><code>inter_query.csv</code></h3>
<table>
<thead>
<tr>
<th style="text-align:right">Index</th>
<th style="text-align:center">Nullable</th>
<th style="text-align:left">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right">0</td>
<td style="text-align:center"></td>
<td style="text-align:left">user ID</td>
</tr>
<tr>
<td style="text-align:right">1</td>
<td style="text-align:center"></td>
<td style="text-align:left">token IDs in the query (separated by spaces)</td>
</tr>
<tr>
<td style="text-align:right">2</td>
<td style="text-align:center"></td>
<td style="text-align:left">query timestamp</td>
</tr>
</tbody>
</table>
<br>
<h3 id="info_usercsv"><code>info_user.csv</code></h3>
<table>
<thead>
<tr>
<th style="text-align:right">Index</th>
<th style="text-align:center">Nullable</th>
<th style="text-align:left">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right">0</td>
<td style="text-align:center"></td>
<td style="text-align:left">user ID</td>
</tr>
<tr>
<td style="text-align:right">1</td>
<td style="text-align:center"></td>
<td style="text-align:left">register timestamp</td>
</tr>
<tr>
<td style="text-align:right">2</td>
<td style="text-align:center"></td>
<td style="text-align:left">gender</td>
</tr>
<tr>
<td style="text-align:right">3</td>
<td style="text-align:center"></td>
<td style="text-align:left">login frequency</td>
</tr>
<tr>
<td style="text-align:right">4</td>
<td style="text-align:center"></td>
<td style="text-align:left">#followers</td>
</tr>
<tr>
<td style="text-align:right">5</td>
<td style="text-align:center"></td>
<td style="text-align:left">#topics followed by this user</td>
</tr>
<tr>
<td style="text-align:right">6</td>
<td style="text-align:center"></td>
<td style="text-align:left">#questions followed by this user</td>
</tr>
<tr>
<td style="text-align:right">7</td>
<td style="text-align:center"></td>
<td style="text-align:left">#answers</td>
</tr>
<tr>
<td style="text-align:right">8</td>
<td style="text-align:center"></td>
<td style="text-align:left">#questions</td>
</tr>
<tr>
<td style="text-align:right">9</td>
<td style="text-align:center"></td>
<td style="text-align:left">#comments</td>
</tr>
<tr>
<td style="text-align:right">10</td>
<td style="text-align:center"></td>
<td style="text-align:left">#thanks received by this user</td>
</tr>
<tr>
<td style="text-align:right">11</td>
<td style="text-align:center"></td>
<td style="text-align:left">#comments received by this user</td>
</tr>
<tr>
<td style="text-align:right">12</td>
<td style="text-align:center"></td>
<td style="text-align:left">#likes received by this user</td>
</tr>
<tr>
<td style="text-align:right">13</td>
<td style="text-align:center"></td>
<td style="text-align:left">#dislikes received by this user</td>
</tr>
<tr>
<td style="text-align:right">14</td>
<td style="text-align:center"></td>
<td style="text-align:left">register type</td>
</tr>
<tr>
<td style="text-align:right">15</td>
<td style="text-align:center"></td>
<td style="text-align:left">register platform</td>
</tr>
<tr>
<td style="text-align:right">16</td>
<td style="text-align:center"></td>
<td style="text-align:left">from android or not</td>
</tr>
<tr>
<td style="text-align:right">17</td>
<td style="text-align:center"></td>
<td style="text-align:left">from iphone or not</td>
</tr>
<tr>
<td style="text-align:right">18</td>
<td style="text-align:center"></td>
<td style="text-align:left">from ipad or not</td>
</tr>
<tr>
<td style="text-align:right">19</td>
<td style="text-align:center"></td>
<td style="text-align:left">from pc or not</td>
</tr>
<tr>
<td style="text-align:right">20</td>
<td style="text-align:center"></td>
<td style="text-align:left">from mobile web or not</td>
</tr>
<tr>
<td style="text-align:right">21</td>
<td style="text-align:center"></td>
<td style="text-align:left">device model</td>
</tr>
<tr>
<td style="text-align:right">22</td>
<td style="text-align:center"></td>
<td style="text-align:left">device brand</td>
</tr>
<tr>
<td style="text-align:right">23</td>
<td style="text-align:center"></td>
<td style="text-align:left">platform</td>
</tr>
<tr>
<td style="text-align:right">24</td>
<td style="text-align:center"></td>
<td style="text-align:left">province</td>
</tr>
<tr>
<td style="text-align:right">25</td>
<td style="text-align:center"></td>
<td style="text-align:left">city</td>
</tr>
<tr>
<td style="text-align:right">26</td>
<td style="text-align:center">$\sqrt{}$</td>
<td style="text-align:left">topic IDs followed by this user (separated by spaces)</td>
</tr>
</tbody>
</table>
<br>
<h3 id="info_answercsv"><code>info_answer.csv</code></h3>
<table>
<thead>
<tr>
<th style="text-align:right">Index</th>
<th style="text-align:center">Nullable</th>
<th style="text-align:left">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right">0</td>
<td style="text-align:center"></td>
<td style="text-align:left">answer ID</td>
</tr>
<tr>
<td style="text-align:right">1</td>
<td style="text-align:center">$\sqrt{}$</td>
<td style="text-align:left">question ID</td>
</tr>
<tr>
<td style="text-align:right">2</td>
<td style="text-align:center"></td>
<td style="text-align:left">anonymous or not</td>
</tr>
<tr>
<td style="text-align:right">3</td>
<td style="text-align:center">$\sqrt{}$</td>
<td style="text-align:left">author ID (null for anonymous)</td>
</tr>
<tr>
<td style="text-align:right">4</td>
<td style="text-align:center"></td>
<td style="text-align:left">labeled high-value answer or not</td>
</tr>
<tr>
<td style="text-align:right">5</td>
<td style="text-align:center"></td>
<td style="text-align:left">recommended by the editor or not</td>
</tr>
<tr>
<td style="text-align:right">6</td>
<td style="text-align:center"></td>
<td style="text-align:left">create timestamp</td>
</tr>
<tr>
<td style="text-align:right">7</td>
<td style="text-align:center"></td>
<td style="text-align:left">contain pictures or not</td>
</tr>
<tr>
<td style="text-align:right">8</td>
<td style="text-align:center"></td>
<td style="text-align:left">contain videos or not</td>
</tr>
<tr>
<td style="text-align:right">9</td>
<td style="text-align:center"></td>
<td style="text-align:left">#thanks</td>
</tr>
<tr>
<td style="text-align:right">10</td>
<td style="text-align:center"></td>
<td style="text-align:left">#likes</td>
</tr>
<tr>
<td style="text-align:right">11</td>
<td style="text-align:center"></td>
<td style="text-align:left">#comments</td>
</tr>
<tr>
<td style="text-align:right">12</td>
<td style="text-align:center"></td>
<td style="text-align:left">#collections</td>
</tr>
<tr>
<td style="text-align:right">13</td>
<td style="text-align:center"></td>
<td style="text-align:left">#dislikes</td>
</tr>
<tr>
<td style="text-align:right">14</td>
<td style="text-align:center"></td>
<td style="text-align:left">#reports</td>
</tr>
<tr>
<td style="text-align:right">15</td>
<td style="text-align:center"></td>
<td style="text-align:left">#helpless</td>
</tr>
<tr>
<td style="text-align:right">16</td>
<td style="text-align:center">$\sqrt{}$</td>
<td style="text-align:left">token IDs in the answer (separated by spaces)</td>
</tr>
<tr>
<td style="text-align:right">17</td>
<td style="text-align:center">$\sqrt{}$</td>
<td style="text-align:left">topic IDs of the answer (separated by spaces)</td>
</tr>
</tbody>
</table>
<br>
<h3 id="info_questioncsv"><code>info_question.csv</code></h3>
<table>
<thead>
<tr>
<th style="text-align:right">Index</th>
<th style="text-align:center">Nullable</th>
<th style="text-align:left">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right">0</td>
<td style="text-align:center"></td>
<td style="text-align:left">question ID</td>
</tr>
<tr>
<td style="text-align:right">1</td>
<td style="text-align:center"></td>
<td style="text-align:left">create timestamp</td>
</tr>
<tr>
<td style="text-align:right">2</td>
<td style="text-align:center"></td>
<td style="text-align:left">#answers</td>
</tr>
<tr>
<td style="text-align:right">3</td>
<td style="text-align:center"></td>
<td style="text-align:left">#followers</td>
</tr>
<tr>
<td style="text-align:right">4</td>
<td style="text-align:center"></td>
<td style="text-align:left">#invitations</td>
</tr>
<tr>
<td style="text-align:right">5</td>
<td style="text-align:center"></td>
<td style="text-align:left">#comments</td>
</tr>
<tr>
<td style="text-align:right">6</td>
<td style="text-align:center">$\sqrt{}$</td>
<td style="text-align:left">token IDs in the question (separated by spaces)</td>
</tr>
<tr>
<td style="text-align:right">7</td>
<td style="text-align:center">$\sqrt{}$</td>
<td style="text-align:left">topic IDs of the queation (separated by spaces)</td>
</tr>
</tbody>
</table>
<br>
<h3 id="info_authorcsv"><code>info_author.csv</code></h3>
<table>
<thead>
<tr>
<th style="text-align:right">Index</th>
<th style="text-align:center">Nullable</th>
<th style="text-align:left">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right">0</td>
<td style="text-align:center"></td>
<td style="text-align:left">author ID</td>
</tr>
<tr>
<td style="text-align:right">1</td>
<td style="text-align:center"></td>
<td style="text-align:left">is excellent author or not</td>
</tr>
<tr>
<td style="text-align:right">2</td>
<td style="text-align:center"></td>
<td style="text-align:left">#followers</td>
</tr>
<tr>
<td style="text-align:right">3</td>
<td style="text-align:center"></td>
<td style="text-align:left">is excellent answerer or not</td>
</tr>
</tbody>
</table>
<br>
<h3 id="info_topiccsv"><code>info_topic.csv</code></h3>
<table>
<thead>
<tr>
<th style="text-align:right">Index</th>
<th style="text-align:center">Nullable</th>
<th style="text-align:left">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right">0</td>
<td style="text-align:center"></td>
<td style="text-align:left">topic ID</td>
</tr>
</tbody>
</table>
<br>
<h3 id="info_tokencsv"><code>info_token.csv</code></h3>
<table>
<thead>
<tr>
<th style="text-align:right">Index</th>
<th style="text-align:center">Nullable</th>
<th style="text-align:left">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right">0</td>
<td style="text-align:center"></td>
<td style="text-align:left">token ID *</td>
</tr>
<tr>
<td style="text-align:right">1</td>
<td style="text-align:center"></td>
<td style="text-align:left">word vector trained by word2vec (64 dimensions, separated by spaces)</td>
</tr>
</tbody>
</table>
<blockquote>
<p>* ZhihuRec can&rsquo;t provide the corresponding text of tokens for privacy reasons. Researchers can use word vectors in the dataset or train word vectors from scratch.</p>
</blockquote>
<p><br><br></p>
<h2 id="引用说明">引用说明</h2>
<p>ZhihuRec dataset can be downloaded from <a href="https://cloud.tsinghua.edu.cn/d/d6c045c55aa14bb39ebc/">here</a>, and it is for the paper:</p>
<p><a href="https://arxiv.org/abs/2106.06467">Bin Hao, Min Zhang, Weizhi Ma, Shaoyun Shi, Xinxing Yu, Houzhi Shan, Yiqun Liu and Shaoping Ma, 2021, A Large-Scale Rich Context Query and Recommendation Dataset in Online Knowledge-Sharing. arXiv preprint arXiv:2106.06467.</a></p>
<p>please cite the paper if you use this dataset:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">@misc{hao2021largescale,
      title={A Large-Scale Rich Context Query and Recommendation Dataset in Online Knowledge-Sharing},
      author={Bin Hao and Min Zhang and Weizhi Ma and Shaoyun Shi and Xinxing Yu and Houzhi Shan and Yiqun Liu and Shaoping Ma},
      year={2021},
      eprint={2106.06467},
      archivePrefix={arXiv},
      primaryClass={cs.IR}
}
</code></pre></div><p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://hidadeng.github.io/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://hidadeng.github.io/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://hidadeng.github.io/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>数据集 | 585w企业工商注册信息</title>
      <link>https://textdata.cn/blog/2022-12-07-585w-chinese-enterprise-registration-data/</link>
      <pubDate>Tue, 06 Dec 2022 00:00:00 +0000</pubDate>
      
      <guid>/blog/2022-12-07-585w-chinese-enterprise-registration-data/</guid>
      <description>585w企业工商注册信息</description>
      <content:encoded><![CDATA[<p>1978-2019.4,  585w中国大陆企业注册信息</p>
<p>文末有 enterprise-registration-data-of-chinese-mainland.csv 数据获取方式。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;enterprise-registration-data-of-chinese-mainland.csv&#39;</span><span class="p">,</span> 
                 <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">,</span> 
                 <span class="c1">#忽略有问题的记录</span>
                 <span class="n">on_bad_lines</span><span class="o">=</span><span class="s1">&#39;skip&#39;</span><span class="p">)</span>

<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<p><img loading="lazy" src="img/df1.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#剔除大邓广告</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;企业类型&#39;</span><span class="p">]</span><span class="o">!=</span><span class="s1">&#39;公众号: 大邓和他的Python&#39;</span><span class="p">]</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<p><img loading="lazy" src="img/df2.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#记录</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;记录数: &#39;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">))</span>

<span class="c1">#</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;字段有: &#39;</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">&#39;记录数: 12756270&#39;

&#39;字段有: [&#39;企业名称&#39;, &#39;统一社会信用代码&#39;, &#39;注册日期&#39;, &#39;企业类型&#39;, &#39;法人代表&#39;, &#39;注册资金&#39;, &#39;经营范围&#39;, &#39;所在省份&#39;,
       &#39;地区&#39;, &#39;注册地址&#39;]&#39;
</code></pre></div><br>
<p>但数据可能会有重复，这里以企业名称作为唯一标识，可以查看真实的数据量</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;真实记录数: &#39;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;企业名称&#39;</span><span class="p">])))</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">&#39;真实记录数: 5888382&#39;
</code></pre></div><br>
<br>
<h2 id="二如何将多个csv汇总到一个csv中">二、如何将多个csv汇总到一个csv中？</h2>
<p>那么这个enterprise-registration-data-of-chinese-mainland.csv怎么来的？</p>
<p>原始的数据集结构</p>
<p><img loading="lazy" src="img/screen-1.png" alt=""  />

<img loading="lazy" src="img/screen-2.png" alt=""  />
</p>
<br>
<p>先局部实验成功后，推广到整体。</p>
<ol>
<li>获取路径列表</li>
<li>尝试读取任意一个csv文件</li>
<li>尝试合并两个df</li>
<li>合并所有csv到一个文件内</li>
</ol>
<br>
<h3 id="21-获取路径列表">2.1 获取路径列表</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">os</span>

<span class="c1">#大邓电脑为Mac</span>
<span class="c1">#Mac容易在文件夹中生成奇怪的.DS_Store</span>
<span class="c1">#该操作为获取文件夹列表，同时剔除.DS_Store</span>
<span class="n">y_dirs</span> <span class="o">=</span> <span class="p">[</span><span class="n">di</span> <span class="k">for</span> <span class="n">di</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="s1">&#39;csv&#39;</span><span class="p">)</span> <span class="k">if</span> <span class="s1">&#39;.DS_Store&#39;</span><span class="o">!=</span><span class="n">di</span><span class="p">]</span>
<span class="k">for</span> <span class="n">y_dir</span> <span class="ow">in</span> <span class="n">y_dirs</span><span class="p">:</span>
    <span class="c1">#在年份文件夹内有很多csv文件</span>
    <span class="n">fs</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;csv/</span><span class="si">{}</span><span class="s1">/</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">y_dir</span><span class="p">,</span> <span class="n">fn</span><span class="p">)</span> 
          <span class="k">for</span> <span class="n">fn</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="s1">&#39;csv/</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">y_dir</span><span class="p">))</span>
          <span class="k">if</span> <span class="s1">&#39;.csv&#39;</span> <span class="ow">in</span> <span class="n">fn</span><span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">fs</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">......
......
[&#39;csv/2013/河南.csv&#39;, &#39;csv/2013/青海.csv&#39;, &#39;csv/2013/河北.csv&#39;, &#39;csv/2013/浙江.csv&#39;, &#39;csv/2013/内蒙古.csv&#39;, &#39;csv/2013/辽宁.csv&#39;, &#39;csv/2013/天津.csv&#39;, &#39;csv/2013/福建.csv&#39;, &#39;csv/2013/吉林.csv&#39;, &#39;csv/2013/西藏.csv&#39;, &#39;csv/2013/四川.csv&#39;, &#39;csv/2013/云南.csv&#39;, &#39;csv/2013/宁夏.csv&#39;, &#39;csv/2013/新疆.csv&#39;, &#39;csv/2013/安徽.csv&#39;, &#39;csv/2013/重庆.csv&#39;, &#39;csv/2013/贵州.csv&#39;, &#39;csv/2013/湖南.csv&#39;, &#39;csv/2013/海南.csv&#39;, &#39;csv/2013/湖北.csv&#39;, &#39;csv/2013/江西.csv&#39;, &#39;csv/2013/广东.csv&#39;, &#39;csv/2013/北京.csv&#39;, &#39;csv/2013/山西.csv&#39;, &#39;csv/2013/上海.csv&#39;, &#39;csv/2013/陕西.csv&#39;, &#39;csv/2013/黑龙江.csv&#39;, &#39;csv/2013/甘肃.csv&#39;, &#39;csv/2013/江苏.csv&#39;, &#39;csv/2013/山东.csv&#39;, &#39;csv/2013/广西.csv&#39;]

[&#39;csv/2014/河南.csv&#39;, &#39;csv/2014/青海.csv&#39;, &#39;csv/2014/河北.csv&#39;, &#39;csv/2014/浙江.csv&#39;, &#39;csv/2014/内蒙古.csv&#39;, &#39;csv/2014/辽宁.csv&#39;, &#39;csv/2014/天津.csv&#39;, &#39;csv/2014/福建.csv&#39;, &#39;csv/2014/吉林.csv&#39;, &#39;csv/2014/西藏.csv&#39;, &#39;csv/2014/四川.csv&#39;, &#39;csv/2014/云南.csv&#39;, &#39;csv/2014/宁夏.csv&#39;, &#39;csv/2014/新疆.csv&#39;, &#39;csv/2014/安徽.csv&#39;, &#39;csv/2014/重庆.csv&#39;, &#39;csv/2014/贵州.csv&#39;, &#39;csv/2014/湖南.csv&#39;, &#39;csv/2014/海南.csv&#39;, &#39;csv/2014/湖北.csv&#39;, &#39;csv/2014/江西.csv&#39;, &#39;csv/2014/广东.csv&#39;, &#39;csv/2014/北京.csv&#39;, &#39;csv/2014/山西.csv&#39;, &#39;csv/2014/上海.csv&#39;, &#39;csv/2014/陕西.csv&#39;, &#39;csv/2014/黑龙江.csv&#39;, &#39;csv/2014/甘肃.csv&#39;, &#39;csv/2014/江苏.csv&#39;, &#39;csv/2014/山东.csv&#39;, &#39;csv/2014/广西.csv&#39;]

[&#39;csv/2015/河南.csv&#39;, &#39;csv/2015/青海.csv&#39;, &#39;csv/2015/河北.csv&#39;, &#39;csv/2015/浙江.csv&#39;, &#39;csv/2015/内蒙古.csv&#39;, &#39;csv/2015/辽宁.csv&#39;, &#39;csv/2015/天津.csv&#39;, &#39;csv/2015/福建.csv&#39;, &#39;csv/2015/吉林.csv&#39;, &#39;csv/2015/西藏.csv&#39;, &#39;csv/2015/四川.csv&#39;, &#39;csv/2015/云南.csv&#39;, &#39;csv/2015/宁夏.csv&#39;, &#39;csv/2015/新疆.csv&#39;, &#39;csv/2015/安徽.csv&#39;, &#39;csv/2015/重庆.csv&#39;, &#39;csv/2015/贵州.csv&#39;, &#39;csv/2015/湖南.csv&#39;, &#39;csv/2015/海南.csv&#39;, &#39;csv/2015/湖北.csv&#39;, &#39;csv/2015/江西.csv&#39;, &#39;csv/2015/广东.csv&#39;, &#39;csv/2015/北京.csv&#39;, &#39;csv/2015/山西.csv&#39;, &#39;csv/2015/上海.csv&#39;, &#39;csv/2015/陕西.csv&#39;, &#39;csv/2015/黑龙江.csv&#39;, &#39;csv/2015/甘肃.csv&#39;, &#39;csv/2015/江苏.csv&#39;, &#39;csv/2015/山东.csv&#39;, &#39;csv/2015/广西.csv&#39;]

.....
.....
</code></pre></div><p><br><br></p>
<h3 id="22-尝试读取任意一个csv文件">2.2 尝试读取任意一个csv文件</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">df1</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;csv/2012/辽宁.csv&#39;</span><span class="p">,</span> 
                  <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">,</span> 
                  <span class="n">on_bad_lines</span><span class="o">=</span><span class="s1">&#39;skip&#39;</span><span class="p">)</span>

<span class="n">df1</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<p><img loading="lazy" src="img/df3.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df2</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;csv/2013/青海.csv&#39;</span><span class="p">,</span> 
                  <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">,</span> 
                  <span class="n">on_bad_lines</span><span class="o">=</span><span class="s1">&#39;skip&#39;</span><span class="p">)</span>

<span class="n">df2</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<p><img loading="lazy" src="img/df4.png" alt=""  />
</p>
<br>
<h3 id="23-尝试合并两个df">2.3 尝试合并两个df</h3>
<p>两个df垂直方向堆积，不增加字段种类，所以选择 pd.concat函数。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df12</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">df1</span><span class="p">,</span> <span class="n">df2</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">df12</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<p><img loading="lazy" src="img/df3.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#检查记录数</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">df1</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">df2</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">df12</span><span class="p">))</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">10246
4417
14663
</code></pre></div><br>
<h3 id="24-合并所有csv到一个文件内">2.4 合并所有csv到一个文件内</h3>
<p>将步骤1、2、3代码整理，汇总</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="c1">#存df列表</span>
<span class="n">dfs</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1">#文件路径列表</span>
<span class="n">y_dirs</span> <span class="o">=</span> <span class="p">[</span><span class="n">di</span> <span class="k">for</span> <span class="n">di</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="s1">&#39;csv&#39;</span><span class="p">)</span> <span class="k">if</span> <span class="s1">&#39;.DS_Store&#39;</span><span class="o">!=</span><span class="n">di</span><span class="p">]</span>
<span class="k">for</span> <span class="n">y_dir</span> <span class="ow">in</span> <span class="n">y_dirs</span><span class="p">:</span>
    <span class="n">csvfs</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;csv/</span><span class="si">{}</span><span class="s1">/</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">y_dir</span><span class="p">,</span> <span class="n">fn</span><span class="p">)</span> 
             <span class="k">for</span> <span class="n">fn</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="s1">&#39;csv/</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">y_dir</span><span class="p">))</span>
             <span class="k">if</span> <span class="s1">&#39;.csv&#39;</span> <span class="ow">in</span> <span class="n">fn</span><span class="p">]</span>
    
    <span class="k">for</span> <span class="n">csvf</span> <span class="ow">in</span> <span class="n">csvfs</span><span class="p">:</span>
        
        <span class="c1">#读取csv，得到df</span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">csvf</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">,</span> <span class="n">on_bad_lines</span><span class="o">=</span><span class="s1">&#39;skip&#39;</span><span class="p">)</span>
        <span class="c1">#存入df列表</span>
        <span class="n">dfs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
        
<span class="c1">#合并dfs为alldf</span>
<span class="n">alldf</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">dfs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1">#导出为data.csv</span>
<span class="n">alldf</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;enterprise-registration-data-of-chinese-mainland.csv&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</code></pre></div><p><br><br></p>
<h2 id="三数据获取">三、数据获取</h2>
<p>转发本文至朋友圈集赞50+， 加微信372335839， 备注【姓名-学校-专业-1200w工商】获取本文数据。</p>
<p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>12G数据集 |  23w条Kickstarter项目信息</title>
      <link>https://textdata.cn/blog/2022-12-04-kickstarters_dataset/</link>
      <pubDate>Sun, 04 Dec 2022 00:00:00 +0000</pubDate>
      
      <guid>/blog/2022-12-04-kickstarters_dataset/</guid>
      <description>2016年3月写好的kickstarter爬虫，每月执行一次。截止2022年11月， 所有压缩文件累积11.42G。文末有数据获取方式</description>
      <content:encoded><![CDATA[<h2 id="kickstarter介绍">Kickstarter介绍</h2>
<p>Kickstarter于2009年4月在美国纽约成立，是一个专为具有创意方案的企业筹资的众筹网站平台。</p>
<p>kickstarter平台的运作方式相对来说比较简单而有效：该平台的用户一方是有创新意渴望进行创作和创造的人，另一方则是愿意为他们出资金的人，然后见证新发明新创作新产品的出现。kickstarter网站的创意性活动包括：<strong>音乐，网页设计，平面设计，动画，作家</strong>以及所有有能力创造以及影响他人的活动。</p>
<p><br><br></p>
<h2 id="12g数据集">12G数据集</h2>
<p><strong>2016年3月</strong> 写好的kickstarter爬虫，每月执行一次。截止<strong>2022年11月</strong>， 所有压缩文件累积11.42G。<strong>文末有数据获取方式</strong></p>
<p><img loading="lazy" src="img/kickstarter_datasets_dir_screen.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="参考论文">参考论文</h2>
<p>该数据集研究价值，可用于研究市场营销、创新创业、信息管理等， 部分使用kickstarter作为研究对象的论文。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">[1]王伟,陈伟,祝效国,王洪伟. 众筹融资成功率与语言风格的说服性-基于Kickstarter的实证研究.*管理世界*.2016;5:81-98.
[2]Dai, Hengchen and Dennis J. Zhang. “Prosocial Goal Pursuit in Crowdfunding: Evidence from Kickstarter.” Journal of Marketing Research 56 (2019): 498 - 517.
[3]Gafni, H., Marom, D.M., Robb, A.M., &amp; Sade, O. (2020). Gender Dynamics in Crowdfunding (Kickstarter): Evidence on Entrepreneurs, Backers, and Taste-Based Discrimination*. Review of Finance.
[4]Jensen, Lasse Skovgaard and Ali Gürcan Özkil. “Identifying challenges in crowdfunded product development: a review of Kickstarter projects.” Design Science 4 (2018): n. pag.
</code></pre></div><br>
<br>
<h2 id="查看数据">查看数据</h2>
<p>任意选择一个zip文件解压会得到json文件，注意 <strong>不同json文件不太一样，所以本文的代码可能要有调整。</strong></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="c1">#读取任意一个zip解压得到的csv文件</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_json</span><span class="p">(</span><span class="s1">&#39;data/Kickstarter_2022-06-09T03_20_03_365Z.json&#39;</span><span class="p">,</span> <span class="n">lines</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<p><img loading="lazy" src="img/df.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">230346
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1"># 选中projects字段</span>
<span class="n">projects</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;data&#39;</span><span class="p">]</span>
<span class="n">projects</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">    0         {&#39;id&#39;: 947118202, &#39;photo&#39;: {&#39;key&#39;: &#39;assets/029...
    1         {&#39;id&#39;: 426094497, &#39;photo&#39;: {&#39;key&#39;: &#39;assets/029...
    2         {&#39;id&#39;: 44835253, &#39;photo&#39;: {&#39;key&#39;: &#39;assets/034/...
    3         {&#39;id&#39;: 1001767271, &#39;photo&#39;: {&#39;key&#39;: &#39;assets/03...
    4         {&#39;id&#39;: 1880345176, &#39;photo&#39;: {&#39;key&#39;: &#39;assets/03...
                                    ...                        
    230341    {&#39;id&#39;: 676753351, &#39;photo&#39;: {&#39;key&#39;: &#39;assets/012...
    230342    {&#39;id&#39;: 1579378115, &#39;photo&#39;: {&#39;key&#39;: &#39;assets/02...
    230343    {&#39;id&#39;: 1281094926, &#39;photo&#39;: {&#39;key&#39;: &#39;assets/02...
    230344    {&#39;id&#39;: 783009016, &#39;photo&#39;: {&#39;key&#39;: &#39;assets/012...
    230345    {&#39;id&#39;: 324368296, &#39;photo&#39;: {&#39;key&#39;: &#39;assets/012...
    Name: data, Length: 230346, dtype: object
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#查看第一行，data列</span>
<span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;data&#39;</span><span class="p">]</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">    {&#39;id&#39;: 947118202,
     &#39;photo&#39;: {&#39;key&#39;: &#39;assets/029/542/393/098b025d0c25cc15e5b5f673b9ec992a_original.png&#39;,
      &#39;full&#39;: &#39;https://ksr-ugc.imgix.net/assets/029/542/393/098b025d0c25cc15e5b5f673b9ec992a_original.png?ixlib=rb-4.0.2&amp;crop=faces&amp;w=560&amp;h=315&amp;fit=crop&amp;v=1592675400&amp;auto=format&amp;frame=1&amp;q=92&amp;s=26209d432871ad2e9cca642527c291d9&#39;,
      &#39;ed&#39;: &#39;https://ksr-ugc.imgix.net/assets/029/542/393/098b025d0c25cc15e5b5f673b9ec992a_original.png?ixlib=rb-4.0.2&amp;crop=faces&amp;w=352&amp;h=198&amp;fit=crop&amp;v=1592675400&amp;auto=format&amp;frame=1&amp;q=92&amp;s=db82255e6639d5951506e0f2ed4d7d8b&#39;,
      &#39;med&#39;: &#39;https://ksr-ugc.imgix.net/assets/029/542/393/098b025d0c25cc15e5b5f673b9ec992a_original.png?ixlib=rb-4.0.2&amp;crop=faces&amp;w=272&amp;h=153&amp;fit=crop&amp;v=1592675400&amp;auto=format&amp;frame=1&amp;q=92&amp;s=f7b43116136000c8efa892bdbdd2d956&#39;,
      &#39;little&#39;: &#39;https://ksr-ugc.imgix.net/assets/029/542/393/098b025d0c25cc15e5b5f673b9ec992a_original.png?ixlib=rb-4.0.2&amp;crop=faces&amp;w=208&amp;h=117&amp;fit=crop&amp;v=1592675400&amp;auto=format&amp;frame=1&amp;q=92&amp;s=a52e3c34066a020e040c517c614a8b36&#39;,
      &#39;small&#39;: &#39;https://ksr-ugc.imgix.net/assets/029/542/393/098b025d0c25cc15e5b5f673b9ec992a_original.png?ixlib=rb-4.0.2&amp;crop=faces&amp;w=160&amp;h=90&amp;fit=crop&amp;v=1592675400&amp;auto=format&amp;frame=1&amp;q=92&amp;s=6c5f1c254119ffe914b50250f8e2899f&#39;,
      &#39;thumb&#39;: &#39;https://ksr-ugc.imgix.net/assets/029/542/393/098b025d0c25cc15e5b5f673b9ec992a_original.png?ixlib=rb-4.0.2&amp;crop=faces&amp;w=48&amp;h=27&amp;fit=crop&amp;v=1592675400&amp;auto=format&amp;frame=1&amp;q=92&amp;s=0222f379ed51059eb73adc7436f07b1e&#39;,
      &#39;1024x576&#39;: &#39;https://ksr-ugc.imgix.net/assets/029/542/393/098b025d0c25cc15e5b5f673b9ec992a_original.png?ixlib=rb-4.0.2&amp;crop=faces&amp;w=1024&amp;h=576&amp;fit=crop&amp;v=1592675400&amp;auto=format&amp;frame=1&amp;q=92&amp;s=d01546c5e88f3f47e0dddc48b5dce9df&#39;,
      &#39;1536x864&#39;: &#39;https://ksr-ugc.imgix.net/assets/029/542/393/098b025d0c25cc15e5b5f673b9ec992a_original.png?ixlib=rb-4.0.2&amp;crop=faces&amp;w=1552&amp;h=873&amp;fit=crop&amp;v=1592675400&amp;auto=format&amp;frame=1&amp;q=92&amp;s=f47505da909a374642906e6d418474e7&#39;},
     &#39;name&#39;: &#39;Paint Rogue&#39;,
     &#39;blurb&#39;: &#39;Roguelike | Platformer | Shooter&#39;,
     &#39;goal&#39;: 5000,
     &#39;pledged&#39;: 5268.22,
     &#39;state&#39;: &#39;successful&#39;,
     &#39;slug&#39;: &#39;paint-rogue&#39;,
     &#39;disable_communication&#39;: False,
     &#39;country&#39;: &#39;AU&#39;,
     &#39;country_displayable_name&#39;: &#39;Australia&#39;,
     &#39;currency&#39;: &#39;AUD&#39;,
     &#39;currency_symbol&#39;: &#39;$&#39;,
     &#39;currency_trailing_code&#39;: True,
     &#39;deadline&#39;: 1594247312,
     &#39;state_changed_at&#39;: 1594247312,
     &#39;created_at&#39;: 1591152439,
     &#39;launched_at&#39;: 1591655312,
     &#39;staff_pick&#39;: False,
     &#39;is_starrable&#39;: False,
     &#39;backers_count&#39;: 42,
     &#39;static_usd_rate&#39;: 0.69681992,
     &#39;usd_pledged&#39;: &#39;3671.0006389424&#39;,
     &#39;converted_pledged_amount&#39;: 3657,
     &#39;fx_rate&#39;: 0.7200616400000001,
     &#39;usd_exchange_rate&#39;: 0.69423473,
     &#39;current_currency&#39;: &#39;USD&#39;,
     &#39;usd_type&#39;: &#39;international&#39;,
     &#39;creator&#39;: {&#39;id&#39;: 1018782761,
      &#39;name&#39;: &#39;Andrew Von Stieglitz&#39;,
      &#39;is_registered&#39;: None,
      &#39;is_email_verified&#39;: None,
      &#39;chosen_currency&#39;: None,
      &#39;is_superbacker&#39;: None,
      &#39;avatar&#39;: {&#39;thumb&#39;: &#39;https://ksr-ugc.imgix.net/assets/024/628/691/39e3fdc8db723302f544f7161e32c4b7_original.png?ixlib=rb-4.0.2&amp;w=40&amp;h=40&amp;fit=crop&amp;v=1554207776&amp;auto=format&amp;frame=1&amp;q=92&amp;s=bf4ce960e83b57310b93c40dda68e213&#39;,
       &#39;small&#39;: &#39;https://ksr-ugc.imgix.net/assets/024/628/691/39e3fdc8db723302f544f7161e32c4b7_original.png?ixlib=rb-4.0.2&amp;w=80&amp;h=80&amp;fit=crop&amp;v=1554207776&amp;auto=format&amp;frame=1&amp;q=92&amp;s=a862ab30490c90cd08186f448884142d&#39;,
       &#39;medium&#39;: &#39;https://ksr-ugc.imgix.net/assets/024/628/691/39e3fdc8db723302f544f7161e32c4b7_original.png?ixlib=rb-4.0.2&amp;w=160&amp;h=160&amp;fit=crop&amp;v=1554207776&amp;auto=format&amp;frame=1&amp;q=92&amp;s=38923ac11699d68a7aae93ce126b97b6&#39;},
      &#39;urls&#39;: {&#39;web&#39;: {&#39;user&#39;: &#39;https://www.kickstarter.com/profile/1018782761&#39;},
       &#39;api&#39;: {&#39;user&#39;: &#39;https://api.kickstarter.com/v1/users/1018782761?signature=1654832212.14f9df54b2643f080ad98cacb07314f94757d9c1&#39;}}},
     &#39;location&#39;: {&#39;id&#39;: 1105779,
      &#39;name&#39;: &#39;Sydney&#39;,
      &#39;slug&#39;: &#39;sydney-au&#39;,
      &#39;short_name&#39;: &#39;Sydney, AU&#39;,
      &#39;displayable_name&#39;: &#39;Sydney, AU&#39;,
      &#39;localized_name&#39;: &#39;Sydney&#39;,
      &#39;country&#39;: &#39;AU&#39;,
      &#39;state&#39;: &#39;NSW&#39;,
      &#39;type&#39;: &#39;Town&#39;,
      &#39;is_root&#39;: False,
      &#39;expanded_country&#39;: &#39;Australia&#39;,
      &#39;urls&#39;: {&#39;web&#39;: {&#39;discover&#39;: &#39;https://www.kickstarter.com/discover/places/sydney-au&#39;,
        &#39;location&#39;: &#39;https://www.kickstarter.com/locations/sydney-au&#39;},
       &#39;api&#39;: {&#39;nearby_projects&#39;: &#39;https://api.kickstarter.com/v1/discover?signature=1654814982.2fcf49a7b611d4414d14b1dbe41ac53623192e6a&amp;woe_id=1105779&#39;}}},
     &#39;category&#39;: {&#39;id&#39;: 35,
      &#39;name&#39;: &#39;Video Games&#39;,
      &#39;analytics_name&#39;: &#39;Video Games&#39;,
      &#39;slug&#39;: &#39;games/video games&#39;,
      &#39;position&#39;: 7,
      &#39;parent_id&#39;: 12,
      &#39;parent_name&#39;: &#39;Games&#39;,
      &#39;color&#39;: 51627,
      &#39;urls&#39;: {&#39;web&#39;: {&#39;discover&#39;: &#39;http://www.kickstarter.com/discover/categories/games/video%20games&#39;}}},
     &#39;profile&#39;: {&#39;id&#39;: 4007060,
      &#39;project_id&#39;: 4007060,
      &#39;state&#39;: &#39;active&#39;,
      &#39;state_changed_at&#39;: 1594267960,
      &#39;name&#39;: &#39;Paint Rogue&#39;,
      &#39;blurb&#39;: &#39;Roguelike | Platformer | Shooter&#39;,
      &#39;background_color&#39;: &#39;&#39;,
      &#39;text_color&#39;: &#39;ffffff&#39;,
      &#39;link_background_color&#39;: &#39;&#39;,
      &#39;link_text_color&#39;: &#39;&#39;,
      &#39;link_text&#39;: &#39;Follow along!&#39;,
      &#39;link_url&#39;: &#39;https://www.kickstarter.com/projects/1018782761/paint-rogue/&#39;,
      &#39;show_feature_image&#39;: True,
      &#39;background_image_opacity&#39;: 0.5700000000000001,
      &#39;background_image_attributes&#39;: {&#39;id&#39;: 29758105,
       &#39;image_urls&#39;: {&#39;default&#39;: &#39;https://ksr-ugc.imgix.net/assets/029/758/105/971e42c0e19ca75fbae0943aa874c3c2_original.png?ixlib=rb-4.0.2&amp;w=1600&amp;fit=max&amp;v=1594267934&amp;auto=format&amp;frame=1&amp;q=92&amp;s=b91907c9e125e206a11a1bcef322c142&#39;,
        &#39;baseball_card&#39;: &#39;https://ksr-ugc.imgix.net/assets/029/758/105/971e42c0e19ca75fbae0943aa874c3c2_original.png?ixlib=rb-4.0.2&amp;w=460&amp;fit=max&amp;v=1594267934&amp;auto=format&amp;frame=1&amp;q=92&amp;s=e7af2286d1f74a51672fbb6060ad43c8&#39;}},
      &#39;should_show_feature_image_section&#39;: False,
      &#39;feature_image_attributes&#39;: {&#39;image_urls&#39;: {&#39;default&#39;: &#39;https://ksr-ugc.imgix.net/assets/029/542/393/098b025d0c25cc15e5b5f673b9ec992a_original.png?ixlib=rb-4.0.2&amp;crop=faces&amp;w=1552&amp;h=873&amp;fit=crop&amp;v=1592675400&amp;auto=format&amp;frame=1&amp;q=92&amp;s=f47505da909a374642906e6d418474e7&#39;,
        &#39;baseball_card&#39;: &#39;https://ksr-ugc.imgix.net/assets/029/542/393/098b025d0c25cc15e5b5f673b9ec992a_original.png?ixlib=rb-4.0.2&amp;crop=faces&amp;w=560&amp;h=315&amp;fit=crop&amp;v=1592675400&amp;auto=format&amp;frame=1&amp;q=92&amp;s=26209d432871ad2e9cca642527c291d9&#39;}}},
     &#39;spotlight&#39;: True,
     &#39;urls&#39;: {&#39;web&#39;: {&#39;project&#39;: &#39;https://www.kickstarter.com/projects/1018782761/paint-rogue?ref=discovery_category_newest&#39;,
       &#39;rewards&#39;: &#39;https://www.kickstarter.com/projects/1018782761/paint-rogue/rewards&#39;}},
     &#39;source_url&#39;: &#39;https://www.kickstarter.com/discover/categories/games/video%20games&#39;}
</code></pre></div><p><br><br></p>
<h2 id="字段">字段</h2>
<p>以第一条为例，查看每条众筹项目数据中的字段，</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;data&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
</code></pre></div><p>Run，运行结果#为后期加入的字段解释</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">    dict_keys([
    &#39;id&#39;, &#39;photo&#39;,  #id、图片链接
    &#39;name&#39;, &#39;blurb&#39;,  #项目名
    &#39;goal&#39;,   #项目筹资目标金额
    &#39;pledged&#39;, 
    &#39;state&#39;,  #项目状态
    &#39;slug&#39;,  
    &#39;disable_communication&#39;, 
    &#39;country&#39;, &#39;country_displayable_name&#39;,   #国家
    &#39;currency&#39;, &#39;currency_symbol&#39;, &#39;currency_trailing_code&#39;,  #货币
    &#39;deadline&#39;, &#39;state_changed_at&#39;,  #项目筹资截止时间(时间戳格式)
    &#39;created_at&#39;,  #项目创建时间(时间戳格式)
    &#39;launched_at&#39;,  #项目上架时间(时间戳格式)
    &#39;staff_pick&#39;, &#39;is_starrable&#39;, 
    &#39;backers_count&#39;,  #资助人数
    &#39;static_usd_rate&#39;, &#39;usd_pledged&#39;, &#39;converted_pledged_amount&#39;, &#39;fx_rate&#39;, &#39;usd_exchange_rate&#39;, &#39;current_currency&#39;, &#39;usd_type&#39;, 
    &#39;creator&#39;,  #项目发起人信息
    &#39;location&#39;,  #地址
    &#39;category&#39;,  #项目所属类目信息
    &#39;profile&#39;,  #项目基本信息
    &#39;spotlight&#39;, 
    &#39;urls&#39;,  #项目链接
    &#39;source_url&#39;])
</code></pre></div><br>
<p>以第一条数据为例，依次查看这几个字段的信息</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#众筹项目具名</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;项目名&#39;</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;data&#39;</span><span class="p">][</span><span class="s1">&#39;name&#39;</span><span class="p">],</span> <span class="n">end</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\n\n</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;项目链接</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;data&#39;</span><span class="p">][</span><span class="s1">&#39;urls&#39;</span><span class="p">],</span> <span class="n">end</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\n\n</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="c1">#众筹项目的目标总金额</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;目标总金额: </span><span class="si">{goal}{currency}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">goal</span><span class="o">=</span><span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;data&#39;</span><span class="p">][</span><span class="s1">&#39;goal&#39;</span><span class="p">],</span> 
                                          <span class="n">currency</span><span class="o">=</span><span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;data&#39;</span><span class="p">][</span><span class="s1">&#39;currency&#39;</span><span class="p">]))</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">    项目名 Paint Rogue
    
    项目链接
     {&#39;web&#39;: {&#39;project&#39;: &#39;https://www.kickstarter.com/projects/1018782761/paint-rogue?ref=discovery_category_newest&#39;, &#39;rewards&#39;: &#39;https://www.kickstarter.com/projects/1018782761/paint-rogue/rewards&#39;}}
    
    目标总金额: 5000AUD
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#众筹项目发起人信息</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;项目发起人信息</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;data&#39;</span><span class="p">][</span><span class="s1">&#39;creator&#39;</span><span class="p">],</span> <span class="n">end</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\n\n</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;项目基本信息</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;data&#39;</span><span class="p">][</span><span class="s1">&#39;profile&#39;</span><span class="p">],</span> <span class="n">end</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\n\n</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="c1">#众筹项目坐标</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;地址: &#39;</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;data&#39;</span><span class="p">][</span><span class="s1">&#39;location&#39;</span><span class="p">],</span> <span class="n">end</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\n\n</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="c1">#众筹项目货币</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;货币:&#39;</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;data&#39;</span><span class="p">][</span><span class="s1">&#39;currency&#39;</span><span class="p">],</span> <span class="n">end</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\n\n</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="c1">#众筹项目所在国家</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;所在国家: &#39;</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;data&#39;</span><span class="p">][</span><span class="s1">&#39;country_displayable_name&#39;</span><span class="p">],</span> <span class="n">end</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\n\n</span><span class="s1">&#39;</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">    项目发起人信息
     {&#39;id&#39;: 1018782761, &#39;name&#39;: &#39;Andrew Von Stieglitz&#39;, &#39;is_registered&#39;: None, &#39;is_email_verified&#39;: None, &#39;chosen_currency&#39;: None, &#39;is_superbacker&#39;: None, &#39;avatar&#39;: {&#39;thumb&#39;: &#39;https://ksr-ugc.imgix.net/assets/024/628/691/39e3fdc8db723302f544f7161e32c4b7_original.png?ixlib=rb-4.0.2&amp;w=40&amp;h=40&amp;fit=crop&amp;v=1554207776&amp;auto=format&amp;frame=1&amp;q=92&amp;s=bf4ce960e83b57310b93c40dda68e213&#39;, &#39;small&#39;: &#39;https://ksr-ugc.imgix.net/assets/024/628/691/39e3fdc8db723302f544f7161e32c4b7_original.png?ixlib=rb-4.0.2&amp;w=80&amp;h=80&amp;fit=crop&amp;v=1554207776&amp;auto=format&amp;frame=1&amp;q=92&amp;s=a862ab30490c90cd08186f448884142d&#39;, &#39;medium&#39;: &#39;https://ksr-ugc.imgix.net/assets/024/628/691/39e3fdc8db723302f544f7161e32c4b7_original.png?ixlib=rb-4.0.2&amp;w=160&amp;h=160&amp;fit=crop&amp;v=1554207776&amp;auto=format&amp;frame=1&amp;q=92&amp;s=38923ac11699d68a7aae93ce126b97b6&#39;}, &#39;urls&#39;: {&#39;web&#39;: {&#39;user&#39;: &#39;https://www.kickstarter.com/profile/1018782761&#39;}, &#39;api&#39;: {&#39;user&#39;: &#39;https://api.kickstarter.com/v1/users/1018782761?signature=1654832212.14f9df54b2643f080ad98cacb07314f94757d9c1&#39;}}}
    
    项目基本信息
     {&#39;id&#39;: 4007060, &#39;project_id&#39;: 4007060, &#39;state&#39;: &#39;active&#39;, &#39;state_changed_at&#39;: 1594267960, &#39;name&#39;: &#39;Paint Rogue&#39;, &#39;blurb&#39;: &#39;Roguelike | Platformer | Shooter&#39;, &#39;background_color&#39;: &#39;&#39;, &#39;text_color&#39;: &#39;ffffff&#39;, &#39;link_background_color&#39;: &#39;&#39;, &#39;link_text_color&#39;: &#39;&#39;, &#39;link_text&#39;: &#39;Follow along!&#39;, &#39;link_url&#39;: &#39;https://www.kickstarter.com/projects/1018782761/paint-rogue/&#39;, &#39;show_feature_image&#39;: True, &#39;background_image_opacity&#39;: 0.5700000000000001, &#39;background_image_attributes&#39;: {&#39;id&#39;: 29758105, &#39;image_urls&#39;: {&#39;default&#39;: &#39;https://ksr-ugc.imgix.net/assets/029/758/105/971e42c0e19ca75fbae0943aa874c3c2_original.png?ixlib=rb-4.0.2&amp;w=1600&amp;fit=max&amp;v=1594267934&amp;auto=format&amp;frame=1&amp;q=92&amp;s=b91907c9e125e206a11a1bcef322c142&#39;, &#39;baseball_card&#39;: &#39;https://ksr-ugc.imgix.net/assets/029/758/105/971e42c0e19ca75fbae0943aa874c3c2_original.png?ixlib=rb-4.0.2&amp;w=460&amp;fit=max&amp;v=1594267934&amp;auto=format&amp;frame=1&amp;q=92&amp;s=e7af2286d1f74a51672fbb6060ad43c8&#39;}}, &#39;should_show_feature_image_section&#39;: False, &#39;feature_image_attributes&#39;: {&#39;image_urls&#39;: {&#39;default&#39;: &#39;https://ksr-ugc.imgix.net/assets/029/542/393/098b025d0c25cc15e5b5f673b9ec992a_original.png?ixlib=rb-4.0.2&amp;crop=faces&amp;w=1552&amp;h=873&amp;fit=crop&amp;v=1592675400&amp;auto=format&amp;frame=1&amp;q=92&amp;s=f47505da909a374642906e6d418474e7&#39;, &#39;baseball_card&#39;: &#39;https://ksr-ugc.imgix.net/assets/029/542/393/098b025d0c25cc15e5b5f673b9ec992a_original.png?ixlib=rb-4.0.2&amp;crop=faces&amp;w=560&amp;h=315&amp;fit=crop&amp;v=1592675400&amp;auto=format&amp;frame=1&amp;q=92&amp;s=26209d432871ad2e9cca642527c291d9&#39;}}}
    
    地址:  {&#39;id&#39;: 1105779, &#39;name&#39;: &#39;Sydney&#39;, &#39;slug&#39;: &#39;sydney-au&#39;, &#39;short_name&#39;: &#39;Sydney, AU&#39;, &#39;displayable_name&#39;: &#39;Sydney, AU&#39;, &#39;localized_name&#39;: &#39;Sydney&#39;, &#39;country&#39;: &#39;AU&#39;, &#39;state&#39;: &#39;NSW&#39;, &#39;type&#39;: &#39;Town&#39;, &#39;is_root&#39;: False, &#39;expanded_country&#39;: &#39;Australia&#39;, &#39;urls&#39;: {&#39;web&#39;: {&#39;discover&#39;: &#39;https://www.kickstarter.com/discover/places/sydney-au&#39;, &#39;location&#39;: &#39;https://www.kickstarter.com/locations/sydney-au&#39;}, &#39;api&#39;: {&#39;nearby_projects&#39;: &#39;https://api.kickstarter.com/v1/discover?signature=1654814982.2fcf49a7b611d4414d14b1dbe41ac53623192e6a&amp;woe_id=1105779&#39;}}}
    
    货币: AUD
    
    所在国家:  Australia
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#众筹项目创建时间</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;项目创建时间: &#39;</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;data&#39;</span><span class="p">][</span><span class="s1">&#39;created_at&#39;</span><span class="p">])</span>

<span class="c1">#众筹项目上架时间</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;项目上架时间: &#39;</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;data&#39;</span><span class="p">][</span><span class="s1">&#39;launched_at&#39;</span><span class="p">])</span>

<span class="c1">#众筹项目截止时间</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;项目截止时间: &#39;</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;data&#39;</span><span class="p">][</span><span class="s1">&#39;deadline&#39;</span><span class="p">])</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">    项目创建时间:  1591152439
    项目上架时间:  1591655312
    项目截止时间:  1594247312
</code></pre></div><br>
<h3 id="时间戳转日期">时间戳转日期</h3>
<p>1591152439是时间戳，以某时间点距1970之间的秒数作为时间。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#时间戳转日期</span>

<span class="kn">import</span> <span class="nn">datetime</span>

<span class="k">def</span> <span class="nf">timestamp2str</span><span class="p">(</span><span class="n">timestamp</span><span class="p">):</span>
    <span class="n">d</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">fromtimestamp</span><span class="p">(</span><span class="n">timestamp</span><span class="p">)</span>
    <span class="k">return</span> <span class="s1">&#39;</span><span class="si">{year}</span><span class="s1">-</span><span class="si">{month}</span><span class="s1">-</span><span class="si">{day}</span><span class="s1"> </span><span class="si">{hour}</span><span class="s1">:</span><span class="si">{minute}</span><span class="s1">:</span><span class="si">{second}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">year</span><span class="o">=</span><span class="n">d</span><span class="o">.</span><span class="n">year</span><span class="p">,</span>
                                                                 <span class="n">month</span><span class="o">=</span><span class="n">d</span><span class="o">.</span><span class="n">month</span><span class="p">,</span>
                                                                 <span class="n">day</span><span class="o">=</span><span class="n">d</span><span class="o">.</span><span class="n">day</span><span class="p">,</span>
                                                                 <span class="n">hour</span><span class="o">=</span><span class="n">d</span><span class="o">.</span><span class="n">hour</span><span class="p">,</span>
                                                                 <span class="n">minute</span><span class="o">=</span><span class="n">d</span><span class="o">.</span><span class="n">minute</span><span class="p">,</span>
                                                                 <span class="n">second</span><span class="o">=</span><span class="n">d</span><span class="o">.</span><span class="n">second</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;创建时间&#39;</span><span class="p">,</span> <span class="n">timestamp2str</span><span class="p">(</span><span class="mi">1591152439</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;上架时间&#39;</span><span class="p">,</span> <span class="n">timestamp2str</span><span class="p">(</span><span class="mi">1591655312</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;截止时间&#39;</span><span class="p">,</span> <span class="n">timestamp2str</span><span class="p">(</span><span class="mi">1594247312</span><span class="p">))</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">创建时间 2020-6-3 10:47:19
上架时间 2020-6-9 6:28:32
截止时间 2020-7-9 6:28:32
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#众筹项目产品 所属类目信息</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;众筹类目:&#39;</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;data&#39;</span><span class="p">][</span><span class="s1">&#39;category&#39;</span><span class="p">],</span> <span class="n">end</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\n\n</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="c1"># 众筹类目根链接</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;众筹类目根链接:&#39;</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;data&#39;</span><span class="p">][</span><span class="s1">&#39;source_url&#39;</span><span class="p">])</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">    众筹类目: {&#39;id&#39;: 35, &#39;name&#39;: &#39;Video Games&#39;, &#39;analytics_name&#39;: &#39;Video Games&#39;, &#39;slug&#39;: &#39;games/video games&#39;, &#39;position&#39;: 7, &#39;parent_id&#39;: 12, &#39;parent_name&#39;: &#39;Games&#39;, &#39;color&#39;: 51627, &#39;urls&#39;: {&#39;web&#39;: {&#39;discover&#39;: &#39;http://www.kickstarter.com/discover/categories/games/video%20games&#39;}}}
    
    众筹类目根链接: https://www.kickstarter.com/discover/categories/games/video%20games
</code></pre></div><p><br><br></p>
<h2 id="数据获取方法">数据获取方法</h2>
<p>转发分享至朋友圈，集赞50+, 加微信 372335839 ， 备注「姓名-学校-专业-Kickstarter」</p>
<p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>JM2022综述 | 黄金领域: 为营销研究(新洞察)采集网络数据</title>
      <link>https://textdata.cn/blog/2022-12-03-scraping-web-data-for-marketing-insights/</link>
      <pubDate>Sat, 03 Dec 2022 00:00:00 +0000</pubDate>
      
      <guid>/blog/2022-12-03-scraping-web-data-for-marketing-insights/</guid>
      <description>Journal of Marketing 2022年一篇关于营销领域网络爬虫的文献综述</description>
      <content:encoded><![CDATA[<p>Boegershausen, Johannes, Hannes Datta, Abhishek Borah, and Andrew Stephen. &ldquo;Fields of gold: Scraping web data for marketing insights.&rdquo; <em>Journal of Marketing</em> (2022).</p>
<p>本文是JM中少有的技术流综述文，阅读起来晦涩难懂，我们就大概知道怎么回事， 查看有没有自己感兴趣的研究(方法)即可。该文作者为该综述专门开发了一个 web-scraping.org 的网站,截图如下</p>
<p><img loading="lazy" src="img/01-web-scraping.png" alt=""  />

<img loading="lazy" src="img/02-web-scraping.png" alt=""  />
</p>

<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
  <iframe src="https://www.youtube.com/embed/KiyFyLEkqNk" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video"></iframe>
</div>

<br>
<h2 id="摘要">摘要</h2>
<p>市场营销学者越来越多使用网络爬虫和API接口，从互联网收集数据。尽管网络数据得到广泛使用，但很少有学者关注收集过程中面临的各种挑战。<strong>研究人员如何确保采集的数据集是有效的？</strong> 虽然现有资源强调提取网络数据的技术细节，<strong>但作者提出了一种新的方法框架，重点是提高其有效性</strong>。特别是，该框架强调解决有效性问题， 需要在数据采集的三个阶段(<strong>选择数据源、设计数据收集和提取数据</strong>)联合考虑技术和法律/伦理问题。作者进一步审查了营销Top5期刊上300 篇使用网络数据的论文，并总结提出了如何使用网络数据促进营销研究。本文最后指出了未来研究的方向，高价值的网络数据源和新方法。</p>
<p><strong>Keywords：</strong></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">- web scraping
- application programming interface, API
- crawling
- validity
- user-generated content
- social media
big data
</code></pre></div><br>
<h2 id="一网络数据的魅力">一、网络数据的魅力</h2>
<p>社会和商业生活的加速数字化创造了数量空前的消费者和企业行为数字痕迹。 每分钟，全球用户在 Google 上进行 570 万次搜索，进行 600 万次商业交易，并在 Instagram 上分享6.5万张照片（Statista 2021）。 由此产生的网络数据——规模庞大、形式多样，而且通常可以在互联网上公开访问——对于那些想要量化消费、深入了解企业行为并跟踪难以或昂贵地观察社会活动的营销学者来说，这是一个潜在的金矿 . 网络数据对营销研究的重要性反映在越来越多的有影响力的出版物中，涵盖消费者文化理论、消费者心理学、实证建模和营销策略等。</p>
<p><img loading="lazy" src="img/fig-1-increased-use-of-web-data-in-marketing.png" alt=""  />
</p>
<p>整理了 <strong>营销领域 top 5 期刊( JM、JMR、JCR、JCP、MS) 的 313 篇论文</strong> ，经过整理绘制图-1（Figure1）， 使用网络数据进行研究的量呈现快速上涨的趋势。使用网络数据的论文占比，从2010年的4%提升到2020年的15%。 者313篇论文，数据的获取方式统计</p>
<ul>
<li>**59% 的论文使用了 <strong>网络爬虫</strong> 采集数据</li>
<li>12% 的论文使用API收集数据</li>
<li>9% 的论文同时使用了网络爬虫和API</li>
<li>20% 使用人工从网站手动复制粘贴数据</li>
</ul>
<p><strong>使用 网络数据 的论文，平均被引用次数 7.55， 远高于 非网络数据 的 3.90</strong>。</p>
<br>
<p>使用网络数据做新研究，大致有4种实现路径</p>
<ol>
<li><strong>研究新现象，新场景</strong>
<ul>
<li>网络世界产生的不同于现实世界的情景，可以研究新现象</li>
</ul>
</li>
<li><strong>繁荣生态价值</strong>
<ul>
<li>比如，对亚马逊评论数据进行研究，研究发现可以帮助亚马逊平台进行改善。</li>
</ul>
</li>
<li><strong>促进方法论进步</strong>
<ul>
<li>文本、图片、音频、视频等</li>
</ul>
</li>
<li><strong>提高测量效果(快、准、好、全)</strong>
<ul>
<li>借助一些API，可以对已有的数据集增加新的信息量。</li>
<li>例如，日期数据，结合HolidayAPI，可以查看日期的节假日信息</li>
<li>给定日期和IP地址，使用Weather Underground可以查看天气信息</li>
</ul>
</li>
</ol>
<p><img loading="lazy" src="img/table-1-four-pathway-of-knowledge-creation-using-web-data.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="二数据采集的方法框架">二、数据采集的方法框架</h2>
<p>在使用 **网络爬虫 和 API ** 自动收集网络数据时，研究人员通常会在 **研究有效性、技术可行性和法律/伦理风险 **1 三者间权衡利弊得失，研究人员如何解决这些权衡，通过增强或破坏 <strong>统计结论有效性、内部有效性、结构有效性和外部有效性</strong> 来塑造研究结果的可信度（Shadish、Cook 和 Campbell 2002）。</p>
<p><img loading="lazy" src="img/fig-2-methodological-framework-for-collecting-web-data.png" alt=""  />
</p>
<p>本文开发了一个方法框架，为使用 网络爬虫 和 API 自动收集网络数据提供指导。图 2（Figure 2） 涵盖三个关键阶段</p>
<ul>
<li><strong>数据源选择</strong></li>
<li><strong>设计方案</strong>
<ul>
<li>从网站中抽取哪些信息</li>
<li>采集频率，即 每天(周/月)重复运行一次爬虫，得到面板数据</li>
</ul>
</li>
<li><strong>执行数据采集</strong>
<ul>
<li>如何改善爬虫运行效率</li>
<li>如何处理原始信息，完整的保存为原始格式html、json，还是只抽取存储当前想要的字段</li>
</ul>
</li>
</ul>
<p>研究人员通常从一组广泛的潜在数据源开始，并根据三个关键考虑因素（有效性、技术可行性和法律/道德风险）剔除其中一些数据源。这三个考虑因素出现在倒金字塔的角落，底部的有效性强调其重要性。鉴于在收集最终数据集之前难以预测其确切特征，研究人员在设计、原型化和完善数据收集时经常重新考虑这些因素。未能解决技术或法律/伦理问题可能意味着网络数据无法有意义地告知研究问题。</p>
<h3 id="21-数据源面临的挑战解决办法">2.1 数据源面临的挑战(解决办法)</h3>
<ol>
<li>探索潜在网络数据源
<ul>
<li>由于网络资源在质量、稳定性和可检索性方面存在巨大差异，研究人员可能倾向于只考虑主要或熟悉的平台。 对数据世界的彻底探索允许令人信服的理论检验和识别可能难以以其他方式注意到的新颖的、新兴的营销现象。</li>
</ul>
</li>
<li>考虑网络爬虫的替代方案
<ul>
<li>由于网络抓取是最流行的网络数据提取方法，研究人员可能会忽视其他提取数据的方法。 API 提供了一种记录和授权的方式来获取许多来源的 Web 数据。 一些来源还提供现成的数据集。 使用此类替代方案可以节省时间并最大限度地减少法律风险。</li>
</ul>
</li>
<li>将数据与场景结合对应起来
<ul>
<li>Web 数据通常没有大量的文档。 尽早识别潜在相关的背景信息对于研究的相关性和有效性至关重要。
<img loading="lazy" src="img/table-2-chanllenges-and-solutions-in-selecting-web-data-sources.png" alt=""  />
</li>
</ul>
</li>
</ol>
<br>
<h3 id="22-设计数据采集方案">2.2 设计数据采集方案</h3>
<ol>
<li>从页面抽取什么信息，从有效性、合法、技术可行性 三个方面论证。</li>
<li>如何进行数据抽样？</li>
<li>以什么频率(每天、周、月)进行数据采集</li>
</ol>
<p><img loading="lazy" src="img/table-3-1-chanllenges-and-solutions-in-selecting-web-data-sources.png" alt=""  />

<img loading="lazy" src="img/table-3-2-chanllenges-and-solutions-in-selecting-web-data-sources.png" alt=""  />
</p>
<br>
<h3 id="23-执行数据采集">2.3 执行数据采集</h3>
<ol>
<li>如何改善爬虫运行效率</li>
<li>如何监控数据质量</li>
<li>整理数据文档(记录)
<img loading="lazy" src="img/table-4-chanllenges-and-solutions-in-selecting-web-data-sources.png" alt=""  />
</li>
</ol>
<br>
<h2 id="部分参考文献">部分参考文献</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">[1]Allard, Thomas, Lea H. Dunn, and Katherine White. &#34;Negative reviews, positive impact: Consumer empathetic responding to unfair word of mouth.&#34; Journal of Marketing 84, no. 4 (2020): 86-108.
[2]Gao, Weihe, Li Ji, Yong Liu, and Qi Sun. &#34;Branding cultural products in international markets: a study of hollywood movies in China.&#34; Journal of Marketing 84, no. 3 (2020): 86-105.
[3]Reich, Taly, and Sam J. Maglio. &#34;Featuring mistakes: The persuasive impact of purchase mistakes in online reviews.&#34; Journal of Marketing 84, no. 1 (2020): 52-65.
[4]Lee, Jeffrey K., and Ann Kronrod. &#34;The strength of weak-tie consensus language.&#34; Journal of Marketing Research 57, no. 2 (2020): 353-374.
[5]Matz, Sandra C., Cristina Segalin, David Stillwell, Sandrine R. Müller, and Maarten W. Bos. &#34;Predicting the personal appeal of marketing images using computational methods.&#34; Journal of Consumer Psychology 29, no. 3 (2019): 370-390.
[6]Dai, Hengchen, and Dennis J. Zhang. &#34;Prosocial goal pursuit in crowdfunding: Evidence from kickstarter.&#34; Journal of Marketing Research 56, no. 3 (2019): 498-517.
[7]Luffarelli, Jonathan, Mudra Mukesh, and Ammara Mahmood. &#34;Let the logo do the talking: The influence of logo descriptiveness on brand equity.&#34; Journal of Marketing Research 56, no. 5 (2019): 862-878.
[8]Bond, Samuel D., Stephen X. He, and Wen Wen. &#34;Speaking for “free”: Word of mouth in free-and paid-product settings.&#34; Journal of Marketing Research 56, no. 2 (2019): 276-290.
[9]Han, Kyuhong, Jihye Jung, Vikas Mittal, Jinyong Daniel Zyung, and Hajo Adam. &#34;Political identity and financial risk taking: Insights from social dominance orientation.&#34; Journal of Marketing Research 56, no. 4 (2019): 581-601.
[10]Netzer, Oded, Alain Lemaire, and Michal Herzenstein. &#34;When words sweat: Identifying signals for loan default in the text of loan applications.&#34; Journal of Marketing Research 56, no. 6 (2019): 960-980.
[11]Toubia, Olivier, Garud Iyengar, Renée Bunnell, and Alain Lemaire. &#34;Extracting features of entertainment products: A guided latent dirichlet allocation approach informed by the psychology of media consumption.&#34; Journal of Marketing Research 56, no. 1 (2019): 18-36.
[12]Van Laer, Tom, Jennifer Edson Escalas, Stephan Ludwig, and Ellis A. Van Den Hende. &#34;What happens in Vegas stays on TripAdvisor? A theory and technique to understand narrativity in consumer reviews.&#34; Journal of Consumer Research 46, no. 2 (2019): 267-285.
[13]Zhong, Ning, and David A. Schweidel. &#34;Capturing changes in social media content: A multiple latent changepoint topic model.&#34; Marketing Science 39, no. 4 (2020): 827-846.
[14]Colicev, Anatoli, Ashwin Malshe, Koen Pauwels, and Peter O&#39;Connor. &#34;Improving consumer mindset metrics and shareholder value through social media: The different roles of owned and earned media.&#34; Journal of Marketing 82, no. 1 (2018): 37-56.
[15]Liu, Xuan, Savannah Wei Shi, Thales Teixeira, and Michel Wedel. &#34;Video content marketing: The making of clips.&#34; Journal of Marketing 82, no. 4 (2018): 86-101.
[16]Liu, Jia, and Olivier Toubia. &#34;A semantic approach for estimating consumer content preferences from online search queries.&#34; Marketing Science 37, no. 6 (2018): 930-952.
[17]Nam, Hyoryung, Yogesh V. Joshi, and P. K. Kannan. &#34;Harvesting brand information from social tags.&#34; Journal of Marketing 81, no. 4 (2017): 88-108.
[18]Packard, Grant, and Jonah Berger. &#34;How language shapes word of mouth&#39;s impact.&#34; Journal of Marketing Research 54, no. 4 (2017): 572-588.
</code></pre></div><br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>魔搭 | 中文AI模型开源社区</title>
      <link>https://textdata.cn/blog/2022-11-09-chinese-modelscope-open-source/</link>
      <pubDate>Wed, 09 Nov 2022 00:00:00 +0000</pubDate>
      
      <guid>/blog/2022-11-09-chinese-modelscope-open-source/</guid>
      <description>ModelScope社区成立于2022 年6月，是一个模型开源社区及创新平台，由阿里巴巴达摩院，联合CCF开源发展委员会，共同作为项目发起方。社区联合国内AI领域合作伙伴与高校机构，致力于通过开放的社区合作，构建深度学习相关的模型开源，并开源相关模型服务创新技术，推动模型应用生态的繁荣发展。</description>
      <content:encoded><![CDATA[<h2 id="关于modelscope">关于ModelScope</h2>
<p>ModelScope社区成立于 2022 年 6 月，是一个模型开源社区及创新平台，由阿里巴巴达摩院，联合CCF开源发展委员会，共同作为项目发起方。</p>
<blockquote>
<p>社区联合国内AI领域合作伙伴与高校机构，致力于通过开放的社区合作，构建深度学习相关的模型开源，并开源相关模型服务创新技术，推动模型应用生态的繁荣发展。</p>
</blockquote>
<p>期待ModelScope会有不一样的表现。</p>
<p>与ModelScope类似的网站有</p>
<ul>
<li>国际 huggingface是较早将AI模型开源的网站，用户群体庞大，社区内有丰富的数据集、模型，文档详实。</li>
<li>国内 百度飞桨是国内AI模型开源较好的网站，用户群体较大，更新活跃，但是文档质量。。。</li>
</ul>
<p>目前ModelScope刚刚上线不久，模型和数据集都不怎么多</p>
<p><img loading="lazy" src="img/model_scope_homepage.png" alt=""  />
</p>
<br>
<h2 id="heading"></h2>
<h1 id="名词解释"><strong>名词解释</strong></h1>
<p>ModelScope平台是以模型为中心的模型开源社区，与模型的使用相关，您需要先了解如下概念。</p>
<table>
<thead>
<tr>
<th><strong>基础概念</strong></th>
<th><strong>定义</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>任务</td>
<td>任务（Task）指某一领域具体的应用，以用于完成特定场景的任务。例如图像分类、文本生成、语音识别等，您可根据任务的输入输出找到适合您的应用场景的任务类型，通过任务的筛选来查找您所需的模型。</td>
</tr>
<tr>
<td>模型</td>
<td>模型（Model）是指一个具体的模型实例，包括模型网络结构和相应参数。ModelScope平台提供丰富的模型信息供用户体验与使用。</td>
</tr>
<tr>
<td>模型库</td>
<td>模型库（Modelhub）是指对模型进行存储、版本管理和相关操作的模型服务，用户上传和共享的模型将存储至ModelScope的模型库中，同时用户也可在Model hub中创建属于自己的模型存储库，并沿用平台提供的模型库管理功能进行模型管理。</td>
</tr>
<tr>
<td>数据集</td>
<td>数据集（Dataset）是方便共享及访问的数据集合，可用于算法训练、测试、验证，通常以表格形式出现。按照模态可划分为文本、图像、音频、视频、多模态等。</td>
</tr>
<tr>
<td>数据集库</td>
<td>数据集库（Datasethub）用于集中管理数据，支持模型进行训练、预测等，使各类型数据具备易访问、易管理、易共享的特点。</td>
</tr>
<tr>
<td>ModelScope Library</td>
<td>ModelScope Library是ModelScope平台自研的一套Python Library框架，通过调用特定的方法，用户可以只写短短的几行代码，就可以完成模型的推理、训练和评估等任务，也可以在此基础上快速进行二次开发，实现自己的创新想法。</td>
</tr>
</tbody>
</table>
<br>
<h2 id="一模型探索">一、模型探索</h2>
<p>首先访问平台网址https://www.modelscope.cn/models， 您将看见平台上已有的所有公开模型，根据任务筛选或者关键词搜索可查找您感兴趣的模型。</p>
<p><img loading="lazy" src="img/1-model_explore.png" alt=""  />
</p>
<br>
<h2 id="二环境准备">二、环境准备</h2>
<h3 id="21-本地开发环境">2.1 本地开发环境</h3>
<p>如果您需要在本地运行模型，需要进行相应的环境安装准备，包括：</p>
<ul>
<li><strong>安装python环境</strong>。支持python3，不支持python2，建议3.7版本及以上。我们推荐您使用Anaconda进行安装。</li>
<li><strong>安装深度学习框架</strong>。ModelScope Library目前支持Tensorflow，Pytorch两大深度学习框架进行模型训练、推理。您可根据模型所需的框架选择适合的框架进行安装。</li>
<li><strong>安装ModelScope Library</strong>。我们提供两种安装方式，您可选择适合的方式进行安装。
<ul>
<li>pip安装。ModelScope提供了根据不同领域的安装包，您可根据对应的模型选择所需的安装包。</li>
<li>使用源码安装。</li>
<li>更完整的安装信息参考：环境安装指南。</li>
</ul>
</li>
</ul>
<h3 id="22-在线notebook">2.2 在线Notebook</h3>
<p>若您觉得本地安装较为复杂， ModelScope平台也提供在线的运行环境，您可直接在Notebook中运行，Notebook中提供官方镜像无需自主进行环境安装，更加方便快捷，推荐大家使用！</p>
<p>注意：该功能需要您登录后使用，新用户注册ModelScope账号并完成阿里云账号绑定后即可获得免费算力资源，详情请参阅免费额度说明 。</p>
<p><img loading="lazy" src="img/model_scode_free_online_notebook.png" alt=""  />
</p>
<p><img loading="lazy" src="img/model_scode_free_online_notebook-2.png" alt=""  />
</p>
<br>
<h2 id="三2分钟跑通模型推理">三、2分钟跑通模型推理</h2>
<p>若您准备好本地环境或者已经打开一个Notebook的预装环境实例，则根据下述代码可对该模型进行推理。 使用modelscope pipeline接口只需要两步，同样以上述中文分词模型（damo/nlp_structbert_word-segmentation_chinese-base）为例简单说明：</p>
<p>首先根据task实例化一个pipeline对象</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">modelscope.pipelines</span> <span class="kn">import</span> <span class="n">pipeline</span>
<span class="n">word_segmentation</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span><span class="s1">&#39;word-segmentation&#39;</span><span class="p">,</span><span class="n">model</span><span class="o">=</span><span class="s1">&#39;damo/nlp_structbert_word-segmentation_chinese-base&#39;</span><span class="p">)</span>
</code></pre></div><p>输入数据，拿到结果</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">input_str</span> <span class="o">=</span> <span class="s1">&#39;今天天气不错，适合出去游玩&#39;</span>
<span class="nb">print</span><span class="p">(</span><span class="n">word_segmentation</span><span class="p">(</span><span class="n">input_str</span><span class="p">))</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">{&#39;output&#39;: &#39;今天 天气 不错 ， 适合 出去 游玩&#39;}
</code></pre></div><br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>十万级 | 多领域因果事件对数据集对外开源</title>
      <link>https://textdata.cn/blog/2022-11-07-chinese-casual-text-datasets/</link>
      <pubDate>Mon, 07 Nov 2022 00:00:00 +0000</pubDate>
      
      <guid>/blog/2022-11-07-chinese-casual-text-datasets/</guid>
      <description>description用于SEO优化</description>
      <content:encoded><![CDATA[<h2 id="作者">作者</h2>
<p>刘焕勇，NLP开源爱好者与践行者，主页：https://liuhuanyong.github.io。</p>
<p>就职于360人工智能研究院、曾就职于中国科学院软件研究所。</p>
<p>老刘说NLP，将定期发布语言资源、工程实践、技术总结等内容，欢迎关注。</p>
<br>
<p>开放文本中蕴含着大量的逻辑性知识，以刻画事物之间逻辑传导关系的逻辑类知识库是推动知识推理发展的重要基础。
因果抽取是一个十分有趣的话题，研发大规模逻辑推理知识库有助于支持实体或事件等传导驱动决策任务，而目前尚未有开源的因果事件对出现，为了弥补这一空缺，本文对外开源一个面向多领域的十万级因果事件对数据集，可以自行转成因果关系图谱，展开更多有趣实验，供大家一起参考。
地址：https://github.com/liuhuanyong/CausalDataset</p>
<h2 id="一因果抽取常用方法">一、因果抽取常用方法</h2>
<p>我们在《<strong>事件图谱技术：因果关系事件对抽取常用方法的解析与动手实践</strong>》中讲述了因果抽取的方法，从传统模式规则、语义分析、依存句法、序列标注四种方式进行实践，并配上实现项目进行讲解，这涵盖了当前因果事件抽取的常用方式。</p>
<p>地址： <a href="https://github.com/liuhuanyong/CausalityEventExtraction">https://github.com/liuhuanyong/CausalityEventExtraction</a></p>
<h3 id="11-基于模式匹配的因果事件对提取">1.1 基于模式匹配的因果事件对提取</h3>
<p>基于模式匹配的方式，是进行因果抽取的入门级以及兜底方式，充分利用好语言学知识，具有显式标记的因果关联词、因果表达句式进行归纳，并配以正则表达式实现，可以有效地提取出大量的因果事件对。</p>
<br>
<h3 id="12-基于语义角色的因果事件抽取">1.2 基于语义角色的因果事件抽取</h3>
<p>基于触发词模式匹配的方法无法捕捉因果事件之间的关联关系，因此可以借助依存句法分析以及语义角色标注的方式进行处理。</p>
<p>以因果关系触发词为核心动作，首先从语义角色方面找寻该触发词动作的实施对象和受事对象，将实施对象作为原因事件，将受事对象作为结果事件，并根据词性过滤事件；</p>
<br>
<h3 id="13-基于依存句法的因果事件抽取">1.3 基于依存句法的因果事件抽取</h3>
<p>由于自然语言处理的复杂性，LTP中未能对一些子句中的因果关系触发词进行语义角色标注，或者只标注了一部分，即A0和A1未同时被标注出来，因此利用依存句法分析来抽取此类情况下的因果事件对。</p>
<br> 
<h3 id="14-基于序列标注的因果抽取">1.4 基于序列标注的因果抽取</h3>
<p>针对基于规则的因果抽取模型中的不足，可以使用基于Bert微调的序列标注模型。在序列标签的设计上，模型的序列标签采用BIO标签体系，标签类型主要为cause、triger、effect。
为了能方便地根据标签结果进行因果三元组组合，在设计标签体系时也对单因果、多因果进行了区分，分别设置为multi-cause、multi-effect。</p>
<p><br><br></p>
<h2 id="二基于多领域文本数据集的因果事件对">二、基于多领域文本数据集的因果事件对</h2>
<p>为了得到多领域因果事件对，我们以清华大学开源的文本分类数据集THUnews，<strong>THUCNews是根据新浪新闻RSS订阅频道2005~2011年间的历史数据筛选过滤生成，包含74万篇新闻文档（2.19 GB），均为UTF-8纯文本格式</strong>。</p>
<p>其在原始新浪新闻分类体系的基础上，重新整合划分出14个候选分类类别：财经、彩票、房产、股票、家居、教育、科技、社会、时尚、时政、体育、星座、游戏、娱乐。满足了多领域性的需求。</p>
<p><strong>数据地址：http://thuctc.thunlp.org/#中文文本分类数据集THUCNews</strong></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">训练因果抽取识别模型，最终去重得到了100,688条因果关系对，通过对频次进行统计，可以过滤出质量较高的因果对，下面显示了格式为原因事件@结构事件\t出现频次格式下的数据样例。
投资风险巨大@本金全部亏损 248
用户友好界面@模式帮助用户选择场景 38
政策消息面和技术面所有信息@交易者预期变 37
磨砂表面处理@触感更佳 31
加上F2大光圈和丰富手动功能@机器推出受到消费者广泛关注 26
金属材质设计@整体造型更具品质感 25
商务机型中并常见@上下边框显得厚 23
顶盖采用工程塑料制成配@笔记本外壳防滑耐磨 19
取消传统曲面过度@iPhone4底部扬声器变得硕大 17
准专业机型GRDIGITALII和GX200电子水平仪功能引进@使用R10拍摄高楼山水 16
镜头位移减震功能以及闪光灯控制系统@低光照下拍摄照片时噪 14
像素触摸式液晶屏幕@操控方面人性化 14
采用直线条形式边框风格@整体看上去大气 14
像素摄像头镶嵌屏幕上方@视频聊天方便 14
</code></pre></div><br>
<h3 id="21-关于地震相关的因果事件对">2.1 关于“地震”相关的因果事件对</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">日本东北部海域发生里氏大地震@重大人员伤亡和财产损失 6
日本东北部海域发生里氏地震@重大人员伤亡和财产损失 5
印尼西爪哇省附近印度洋海域发生里氏地震@人死亡人受伤 4
智利中南部城市康塞普西翁附近发生里氏强烈地震@重大人员伤亡 3
智利发生里氏地震@重大人员伤亡和财产损失 3
东部凡省发生强烈地震@死亡人数 3
上周五地震中受损核反应堆发生爆炸@核工业相关公司股票 3
日本大地震@金融市场动 3
最近地震和海啸灾害中复苏@日元汇率下跌 3
日本东北部大地震@全球关注 2
汶川地震期间捐款数目@高度关注 2
</code></pre></div><br>
<h3 id="22-与贬值相关的因果事件对">2.2 与“贬值”相关的因果事件对</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">虚拟道具贬值@广范围用户付费意愿越来越低 3
流动性过剩加剧@贬值趋势 3
日本核泄露事件@外资产贬值 3
全球性经济复苏以及贬值流动性过剩@全球商品价格出现暴涨 3
朝鲜进行货币贬值@市场经济瘫痪 2
欧洲主权债务危机深化和亚洲国家货币贬值@日本有警惕金融资本市场动荡 2
游戏公司滥发虚拟物品@玩家虚拟物品贬值 2
住房价格贬值@全球经济下滑形势演变成 2
中长期内贬值@资金撤离资产 2
持续贬值和人民币升值预期@中国内地成为资金洼地 2
韩元贬值@进口商品价格上升 2
货币大体上呈贬值趋势@国际油价名义价格走高 2
朱广沪时期大面积召人@国家队贬值 1
</code></pre></div><br>
<h3 id="23-与恋爱相关的因果事件对">2.3 与“恋爱”相关的因果事件对</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">恋爱观婚姻观@观众极大兴趣 2
恋爱问题@学生意外伤害事 2
人相知相惜@恋爱温度始终保持合适系数 1
持人大爆钱包@恋爱故事 1
来美丽密令恋爱线人电影@陆毅闪耀大银幕上 1
李成儒和小演员侯角恋爱往事@媒体关注 1
歌曲转换过渡上显得流畅@听起来实在如男女恋爱中不伦恋 1
抓紧时间南京谈恋爱@台上台下哄笑 1
公司安排工作@没时间恋爱 1
强打精神去面对@恋爱没有兴趣 1
</code></pre></div><br>
<br>
<h2 id="总结">总结</h2>
<p>本文以清华大学开源的文本分类数据集THUnews，对外开源了一个面向多领域的十万级因果事件对数据集，并介绍了常用技术方法。当然，数据的质量也有不足之处，规模不大，可以加以改善。</p>
<br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>1.5G数据集 | 200万条Indiegogo众筹项目信息</title>
      <link>https://textdata.cn/blog/2022-12-08-indiegogo-dataset/</link>
      <pubDate>Sun, 16 Oct 2022 00:00:00 +0000</pubDate>
      
      <guid>/blog/2022-12-08-indiegogo-dataset/</guid>
      <description>1.57G indiegogo-dataset.jpeg</description>
      <content:encoded><![CDATA[<h2 id="indiegogo">Indiegogo</h2>
<p>Indiegogo成立于2008年，全球最大的科创新品首发和众筹平台， 是美国最早的众筹平台之一。</p>
<p><br><br></p>
<h2 id="参考论文">参考论文</h2>
<p>该数据集研究价值，可用于研究市场营销、创新创业、信息管理等， 部分使用众筹数据集作为研究对象的论文。</p>
<blockquote>
<p>[1]王伟,陈伟,祝效国,王洪伟. 众筹融资成功率与语言风格的说服性-基于Kickstarter的实证研究.<em>管理世界</em>.2016;5:81-98.
[2]Dai, Hengchen and Dennis J. Zhang. “Prosocial Goal Pursuit in Crowdfunding: Evidence from Kickstarter.” Journal of Marketing Research 56 (2019): 498 - 517.
[3]Gafni, H., Marom, D.M., Robb, A.M., &amp; Sade, O. (2020). Gender Dynamics in Crowdfunding (Kickstarter): Evidence on Entrepreneurs, Backers, and Taste-Based Discrimination*. Review of Finance.
[4]Jensen, Lasse Skovgaard and Ali Gürcan Özkil. “Identifying challenges in crowdfunded product development: a review of Kickstarter projects.” Design Science 4 (2018): n. pag.</p>
</blockquote>
<p><br><br></p>
<h2 id="indiegogo数据">Indiegogo数据</h2>
<p>2016年4月写好的Indiegogo爬虫，每月执行一次, 最新的数据 可以前往https://webrobots.io/indiegogo-dataset/</p>
<p><img loading="lazy" src="img/web_robot.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="原始数据">‘原始’数据</h2>
<p>Web Robot网上公开的的Indiegogo原始数据几十个 csv文件,</p>
<p><img loading="lazy" src="img/zips.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="整理">整理</h2>
<p>将上图的zip全部合并为一个 Indiegogo_dataset.csv , 该文件 1.57G 。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>

<span class="n">dff</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;Indiegogo_Dataset/Indiegogo_dataset.csv&#39;</span><span class="p">,</span> <span class="n">on_bad_lines</span><span class="o">=</span><span class="s1">&#39;skip&#39;</span><span class="p">)</span>
<span class="n">dff</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<p><img loading="lazy" src="img/df.png" alt=""  />
</p>
<br>
<p>数据集的字段有</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df</span><span class="o">.</span><span class="n">columns</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">Index([&#39;bullet_point&#39;, 
       &#39;category&#39;, &#39;category_url&#39;,  #项目类目及url
       &#39;clickthrough_url&#39;, #进入当前项目经由的某url
       &#39;close_date&#39;,  #项目截止日期
       &#39;currency&#39;,  #货币
       &#39;funds_raised_amount&#39;,  #当前已筹集的资金
       &#39;funds_raised_percent&#39;, #筹集资金进度(当前筹资/项目目标金额)
       &#39;image_url&#39;,  #图片url
       &#39;is_indemand&#39;, 
       &#39;is_pre_launch&#39;, #是否为预演
       &#39;offered_by&#39;,  #项目发起人
       &#39;open_date&#39;, #项目开始日期
       &#39;perk_goal_percentage&#39;, &#39;perks_claimed&#39;, 
       &#39;price_offered&#39;, #众筹价
       &#39;price_retail&#39;, #零售价
       &#39;product_stage&#39;,  #产品阶段
       &#39;project_id&#39;, #项目id
       &#39;project_type&#39;, #项目类型
       &#39;source_url&#39;, #项目url
       &#39;tagline&#39;, &#39;tags&#39;, #标签
       &#39;title&#39; ], #项目标题
      dtype=&#39;object&#39;)
</code></pre></div><p><br><br></p>
<h2 id="数据获取">数据获取</h2>
<ul>
<li>原始数据
<ul>
<li><a href="https://webrobots.io/indiegogo-dataset/">https://webrobots.io/indiegogo-dataset/</a></li>
</ul>
</li>
<li>整理的1.57G csv,
<ul>
<li>链接: <a href="https://pan.baidu.com/s/1j3PtV4GbFsyhjmr0NLbnKg">https://pan.baidu.com/s/1j3PtV4GbFsyhjmr0NLbnKg</a> 提取码: vfyc</li>
</ul>
</li>
</ul>
<p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>14G数据集 | 2007-2021年A股上市公司年度报告（txt文件）</title>
      <link>https://textdata.cn/blog/2022-10-21-2007-2021-a-share-reports-dataset/</link>
      <pubDate>Sun, 16 Oct 2022 00:00:00 +0000</pubDate>
      
      <guid>/blog/2022-10-21-2007-2021-a-share-reports-dataset/</guid>
      <description>2007-2021年A股上市公司年度报告（txt文件）</description>
      <content:encoded><![CDATA[<p>2007-2021年A股上市公司年度报告, 整理不易，请转发分享。</p>
<br>
<h2 id="截图">截图</h2>
<p><img loading="lazy" src="img/07-21.png" alt=""  />

<img loading="lazy" src="img/2007.png" alt=""  />
</p>
<br>
<h2 id="获取">获取</h2>
<blockquote>
<p>链接: <a href="https://pan.baidu.com/s/1jw6VGGAN9cxROoqWN2X4vw">https://pan.baidu.com/s/1jw6VGGAN9cxROoqWN2X4vw</a> 提取码: g3cn</p>
</blockquote>
<br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>数据集 | 多语言对齐词向量预训练模型</title>
      <link>https://textdata.cn/blog/2022-10-16-aligned-word-vectors/</link>
      <pubDate>Sun, 16 Oct 2022 00:00:00 +0000</pubDate>
      
      <guid>/blog/2022-10-16-aligned-word-vectors/</guid>
      <description>借助该预训练模型，应该能做可做跨文化对比分析</description>
      <content:encoded><![CDATA[<h2 id="介绍">介绍</h2>
<p>Facebook研究者使用 fastText 算法，对维基百科(44种语言)语料数据进行了训练，最终生成了 44 种语言的对齐词向量。</p>
<br>
<h2 id="用途">用途</h2>
<p>wiki数据集有个优点，即由于众人分享、翻译，将不同语言的百科词条进行了翻译整理。所以facebook使用wiki训练对齐词向量有助于提升翻译准确性。与此同时，因为翻译者处于不同的语言和文化背景下，词条及词条内容必然蕴含着语言所特有的文化信息线索，有可能有助于我们挖掘跨语言的文化差异。例如中文词条<code>护士</code>和 英文词条<code>nurse</code> ，可以借助对齐词向量，比较护士这个群体在性别、种族等语义上的差异。</p>
<p>之前分享过的内容</p>
<ul>
<li><a href="https://textdata.cn/blog/embeddingsandattitude/">词嵌入测量不同群体对某概念的态度(偏见)</a></li>
<li><a href="https://textdata.cn/blog/wordembeddingsinsocialscience/">转载 | 大数据时代下社会科学研究方法的拓展&mdash;&mdash;基于词嵌入技术的文本分析的应用</a></li>
<li><a href="https://textdata.cn/blog/from_sysbol_to_embeddings_in_computational_social_science/">转载 | 从符号到嵌入：计算社会科学的两种文本表示</a></li>
<li><a href="https://textdata.cn/blog/literatureembeddings/">文献汇总 | 词嵌入 与 社会科学中的偏见(态度)</a></li>
</ul>
<p>不过fastText算法认为词语有不同的大小划分层次，从大到小分别是词语、词缀、字符等，使用 Joulin 等人 (2018) 中描述的 RCSLS 方法进行比对。</p>
<table>
<thead>
<tr>
<th><strong>Code</strong></th>
<th><strong>en-es</strong></th>
<th><strong>es-en</strong></th>
<th><strong>en-fr</strong></th>
<th><strong>fr-en</strong></th>
<th><strong>en-de</strong></th>
<th><strong>de-en</strong></th>
<th><strong>en-ru</strong></th>
<th><strong>ru-en</strong></th>
<th><strong>en-zh</strong></th>
<th><strong>zh-en</strong></th>
<th><strong>avg</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>Joulin et al. [<a href="https://arxiv.org/abs/1804.07745">1</a>]</td>
<td>84.1</td>
<td>86.3</td>
<td>83.3</td>
<td>84.1</td>
<td><strong>79.1</strong></td>
<td>76.3</td>
<td><strong>57.9</strong></td>
<td><strong>67.2</strong></td>
<td>45.9</td>
<td>46.4</td>
<td>71.1</td>
</tr>
<tr>
<td>This implementation (10 epochs)</td>
<td>84.2</td>
<td><strong>86.6</strong></td>
<td><strong>83.9</strong></td>
<td>84.7</td>
<td>78.3</td>
<td>76.6</td>
<td>57.6</td>
<td>66.7</td>
<td><strong>47.6</strong></td>
<td><strong>47.4</strong></td>
<td>71.4</td>
</tr>
<tr>
<td>This implementation (unsup. model selection)</td>
<td><strong>84.3</strong></td>
<td><strong>86.6</strong></td>
<td><strong>83.9</strong></td>
<td><strong>85.0</strong></td>
<td>78.7</td>
<td><strong>76.7</strong></td>
<td>57.6</td>
<td>67.1</td>
<td><strong>47.6</strong></td>
<td><strong>47.4</strong></td>
<td><strong>71.5</strong></td>
</tr>
</tbody>
</table>
<p>算法得出的词向量在西方，尤其是西欧语言之间进行语义对齐，效果可能更好。而中文、日语等汉字语言，是由偏旁部首组成，与西方字母语言还是存在一定差异。上表也可以看出中英语义对齐准确率47%， 而其他语言之间对齐准确率平均为71%。</p>
<br>
<h2 id="模型资源">模型资源</h2>
<p><a href="https://fasttext.cc/docs/en/aligned-vectors.html">https://fasttext.cc/docs/en/aligned-vectors.html</a></p>
<p>对齐预训练向量模型下载链接</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>Afrikaans: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.af.align.vec"><em>text</em></a></td>
<td>Arabic: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.ar.align.vec"><em>text</em></a></td>
<td>Bulgarian: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.bg.align.vec"><em>text</em></a></td>
<td>Bengali: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.bn.align.vec"><em>text</em></a></td>
</tr>
<tr>
<td>Bosnian: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.bs.align.vec"><em>text</em></a></td>
<td>Catalan: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.ca.align.vec"><em>text</em></a></td>
<td>Czech: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.cs.align.vec"><em>text</em></a></td>
<td>Danish: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.da.align.vec"><em>text</em></a></td>
</tr>
<tr>
<td>German: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.de.align.vec"><em>text</em></a></td>
<td>Greek: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.el.align.vec"><em>text</em></a></td>
<td>English: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.en.align.vec"><em>text</em></a></td>
<td>Spanish: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.es.align.vec"><em>text</em></a></td>
</tr>
<tr>
<td>Estonian: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.et.align.vec"><em>text</em></a></td>
<td>Persian: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.fa.align.vec"><em>text</em></a></td>
<td>Finnish: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.fi.align.vec"><em>text</em></a></td>
<td>French: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.fr.align.vec"><em>text</em></a></td>
</tr>
<tr>
<td>Hebrew: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.he.align.vec"><em>text</em></a></td>
<td>Hindi: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.hi.align.vec"><em>text</em></a></td>
<td>Croatian: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.hr.align.vec"><em>text</em></a></td>
<td>Hungarian: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.hu.align.vec"><em>text</em></a></td>
</tr>
<tr>
<td>Indonesian: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.id.align.vec"><em>text</em></a></td>
<td>Italian: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.it.align.vec"><em>text</em></a></td>
<td>Korean: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.ko.align.vec"><em>text</em></a></td>
<td>Lithuanian: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.lt.align.vec"><em>text</em></a></td>
</tr>
<tr>
<td>Latvian: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.lv.align.vec"><em>text</em></a></td>
<td>Macedonian: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.mk.align.vec"><em>text</em></a></td>
<td>Malay: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.ms.align.vec"><em>text</em></a></td>
<td>Dutch: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.nl.align.vec"><em>text</em></a></td>
</tr>
<tr>
<td>Norwegian: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.no.align.vec"><em>text</em></a></td>
<td>Polish: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.pl.align.vec"><em>text</em></a></td>
<td>Portuguese: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.pt.align.vec"><em>text</em></a></td>
<td>Romanian: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.ro.align.vec"><em>text</em></a></td>
</tr>
<tr>
<td>Russian: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.ru.align.vec"><em>text</em></a></td>
<td>Slovak: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.sk.align.vec"><em>text</em></a></td>
<td>Slovenian: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.sl.align.vec"><em>text</em></a></td>
<td>Albanian: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.sq.align.vec"><em>text</em></a></td>
</tr>
<tr>
<td>Swedish: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.sv.align.vec"><em>text</em></a></td>
<td>Tamil: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.ta.align.vec"><em>text</em></a></td>
<td>Thai: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.th.align.vec"><em>text</em></a></td>
<td>Tagalog: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.tl.align.vec"><em>text</em></a></td>
</tr>
<tr>
<td>Turkish: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.tr.align.vec"><em>text</em></a></td>
<td>Ukrainian: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.uk.align.vec"><em>text</em></a></td>
<td>Vietnamese: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.vi.align.vec"><em>text</em></a></td>
<td>Chinese: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.zh.align.vec"><em>text</em></a></td>
</tr>
</tbody>
</table>
<br>
<h2 id="格式">格式</h2>
<p>词向量默认使用的fastText格式</p>
<ul>
<li>第一行给了词向量的维数</li>
<li>从第二行开始，每一行由词语及对应的词向量组成。</li>
<li>数值之间使用空格间隔</li>
</ul>
<br>
<h2 id="代码">代码</h2>
<h3 id="导入模型">导入模型</h3>
<p>使用gensim导入fastText方法训练出的 预训练语言模型</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">gensim.models</span> <span class="kn">import</span> <span class="n">KeyedVectors</span>

<span class="c1">#导入刚刚下载的预训练模型</span>
<span class="c1">#该词向量模型300维</span>
<span class="n">zh_w2v_model</span> <span class="o">=</span> <span class="n">KeyedVectors</span><span class="o">.</span><span class="n">load_word2vec_format</span><span class="p">(</span><span class="s1">&#39;wiki.zh.align.vec&#39;</span><span class="p">,</span> <span class="n">binary</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1">#英文词向量模型5G，太大了。如果内存小于16G不要使用下面命令</span>
<span class="c1">#en_w2v_model = KeyedVectors.load_word2vec_format(&#39;wiki.en.align.vec&#39;, binary=False)</span>
</code></pre></div><p>一旦导入成功，就可以进行向量计算。这里仅进行简单演示</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#获取某词的词向量</span>
<span class="n">zh_w2v_model</span><span class="o">.</span><span class="n">get_vector</span><span class="p">(</span><span class="s1">&#39;护士&#39;</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<pre><code>array([ 0.0733,  0.0782,  0.0188, -0.0027, -0.0052,...,  0.0586,  0.0166,
       -0.1401, -0.0545, -0.0125,  0.0373, -0.0681,  0.063 ],
      dtype=float32)
</code></pre>
<br>
<p>在中文中， 护士职业的主要从业者为女性，反应在词向量相似度上，如下</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="nb">print</span><span class="p">(</span><span class="n">zh_w2v_model</span><span class="o">.</span><span class="n">similarity</span><span class="p">(</span><span class="s1">&#39;护士&#39;</span><span class="p">,</span> <span class="s1">&#39;女性&#39;</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">zh_w2v_model</span><span class="o">.</span><span class="n">similarity</span><span class="p">(</span><span class="s1">&#39;护士&#39;</span><span class="p">,</span> <span class="s1">&#39;男性&#39;</span><span class="p">))</span>
</code></pre></div><p>Run</p>
<pre><code>0.4417011
0.378651
</code></pre>
<br>
<p>更多w2v_model用法可参考 <a href="https://textdata.cn/blog/douban_w2v/">豆瓣影评 | 探索词向量妙处</a></p>
<br>
<h2 id="文献">文献</h2>
<p>如果使用了facebook的预训练词向量，请引用以下两篇文献。</p>
<ul>
<li>Joulin, Armand, Piotr Bojanowski, Tomas Mikolov, Hervé Jégou, and Edouard Grave. &ldquo;Loss in translation: Learning bilingual word mapping with a retrieval criterion.&rdquo; arXiv preprint arXiv:1804.07745 (2018).</li>
<li>Bojanowski, Piotr, Edouard Grave, Armand Joulin, and Tomas Mikolov. &ldquo;Enriching word vectors with subword information.&rdquo; Transactions of the association for computational linguistics 5 (2017): 135-146.</li>
</ul>
<br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>数据集 | 企业社会责任报告数据集</title>
      <link>https://textdata.cn/blog/coporate_social_responsibility_datasets/</link>
      <pubDate>Thu, 04 Aug 2022 00:00:00 +0000</pubDate>
      
      <guid>/blog/coporate_social_responsibility_datasets/</guid>
      <description>近年来，企业社会责任（csr)已成为全球学术界研究的热点。国内外各大顶刊都先后刊登了多篇关于csr的文章，比如《企业绿色创新实践如何破解“和谐共生”难题？》（发表于管理世界）、《负责任的国际投资：ESG与中国OFDI》（发表于经济研究）、《Is my company really doing good? Factors influencing employees&amp;#39; evaluation of the authenticity of their company&amp;#39;s corporate social responsibility engagement》（发表于JBR）等。这些文章核心变量的构建大都基于对企业社会责任报告的内容分析和挖掘。比如《企业绿色创新实践如何破解“和谐共生”难题？》的被解释变量（绿色创新）以及部分解释变量（二元合法性和伦理型领导）。可见，社会责任报告对于我们研究esg至关重要。因此，接下来小编就带大家爬取深交所上市公司历年的社会责任报告，希望能够给大家带来一些帮助。In recent years, corporate social responsibility (csr) has become a research hotspot in the global academic circles. Major top journals at home and abroad have successively published many articles on CSR, such as How can corporate green innovation practice solve the problem of harmonious symbiosis? (published in Governance World), Responsible International Investment: ESG and China&amp;#39;s OFDI (published in Economic Research), Is my company really doing good? Factors influencing employees&amp;#39; evaluation of the authenticity of their company&amp;#39;s corporate social responsibility engagement (published in JBR) et al. The construction of core variables in these articles is mostly based on the content analysis and mining of corporate social responsibility reports. For example, How can corporate green innovation practice solve the problem of harmonious symbiosis? 》The explained variable (green innovation) and part of the explanatory variables (dual legitimacy and ethical leadership). It can be seen that the social responsibility report is very important for us to study esg. Therefore, the next editor will take you to crawl the social responsibility reports of companies listed on the Shenzhen Stock Exchange over the years, hoping to bring you some help.</description>
      <content:encoded><![CDATA[<blockquote>
<p>作者:张延丰 哈工程在读博士</p>
</blockquote>
<p>近年来，企业社会责任（csr)已成为全球学术界研究的热点。国内外各大顶刊都先后刊登了多篇关于csr的文章，比如《企业绿色创新实践如何破解“和谐共生”难题？》（发表于管理世界）、《负责任的国际投资：ESG与中国OFDI》（发表于经济研究）、《Is my company really doing good? Factors influencing employees' evaluation of the authenticity of their company&rsquo;s corporate social responsibility engagement》（发表于JBR）等。这些文章核心变量的构建大都基于对企业社会责任报告的内容分析和挖掘。比如《企业绿色创新实践如何破解“和谐共生”难题？》的被解释变量（绿色创新）以及部分解释变量（二元合法性和伦理型领导）。可见，社会责任报告对于我们研究esg至关重要。因此，接下来小编就带大家爬取深交所上市公司历年的社会责任报告，希望能够给大家带来一些帮助。</p>
<br>
<h2 id="获取数据集">获取数据集</h2>
<p>采集4000多个pdf文件。经过数据清洗，将20G的pdf数据，汇总整理到170M的csv文件内。</p>
<p><img loading="lazy" src="img/datasets.png" alt=""  />
</p>
<p>数据整理不易，如需获取本数据集，请转发本文至朋友圈集赞满30+**， 加微信【372335839】，备注【深圳ESG数据集】</p>
<img src="img/wechat.jpg" style="zoom:50%;" />
<p><br><br></p>
<h2 id="一构建网络爬虫">一、构建网络爬虫</h2>
<p>数据采集分为多个步骤</p>
<ol>
<li>找网址规律(GET or POST), 构造url参数</li>
<li>伪装请求，防止被封</li>
<li>构造csv，存储信心</li>
<li>执行整个爬虫</li>
</ol>
<h3 id="11-url">1.1 url</h3>
<p>打开X交所的 <a href="http://www.szse.cn/disclosure/listed/notice/">http://www.szse.cn/disclosure/listed/notice/</a> ，同时打开浏览器开发者工具network面板，在截图左侧输入框输入关键词 『社会责任报告』，按下回车。</p>
<p>此时开发者工具network面板出现很多网络交换信息， 点击检查发现下图</p>
<p><img loading="lazy" src="img/01-%e7%bd%91%e5%9d%80%e8%a7%84%e5%be%8b.png" alt=""  />
</p>
<p>发现该页面数据是<strong>POST</strong>请求，网址为</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">http://www.szse.cn/api/disc/announcement/annList?random=random参数
</code></pre></div><h3 id="12-headers">1.2 headers</h3>
<p>同时也能发现伪装头参数，现将两个重要信息整理为</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">url</span> <span class="o">=</span> <span class="s1">&#39;http://www.szse.cn/api/disc/announcement/annList?random=</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">())</span>

<span class="c1">#伪装头</span>
<span class="n">headers</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;Accept&#39;</span><span class="p">:</span> <span class="s1">&#39;application/json, text/javascript, */*; q=0.01&#39;</span><span class="p">,</span>
           <span class="s1">&#39;Accept-Encoding&#39;</span><span class="p">:</span> <span class="s1">&#39;gzip, deflate&#39;</span><span class="p">,</span>
           <span class="s1">&#39;Accept-Language&#39;</span><span class="p">:</span> <span class="s1">&#39;zh-CN,zh;q=0.9,en;q=0.8&#39;</span><span class="p">,</span>
           <span class="s1">&#39;Content-Type&#39;</span><span class="p">:</span> <span class="s1">&#39;application/json&#39;</span><span class="p">,</span>
           <span class="s1">&#39;Host&#39;</span><span class="p">:</span> <span class="s1">&#39;www.szse.cn&#39;</span><span class="p">,</span>
           <span class="s1">&#39;Origin&#39;</span><span class="p">:</span> <span class="s1">&#39;http://www.szse.cn&#39;</span><span class="p">,</span>
           <span class="s1">&#39;Proxy-Connection&#39;</span><span class="p">:</span> <span class="s1">&#39;close&#39;</span><span class="p">,</span>
           <span class="s1">&#39;Referer&#39;</span><span class="p">:</span> <span class="s1">&#39;http://www.szse.cn/disclosure/listed/fixed/index.html&#39;</span><span class="p">,</span>
           <span class="s1">&#39;User-Agent&#39;</span><span class="p">:</span> <span class="s1">&#39;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.132 Safari/537.36&#39;</span><span class="p">,</span>
           <span class="s1">&#39;X-Request-Type&#39;</span><span class="p">:</span> <span class="s1">&#39;ajax&#39;</span><span class="p">,</span>
           <span class="s1">&#39;X-Requested-With&#39;</span><span class="p">:</span> <span class="s1">&#39;XMLHttpRequest&#39;</span><span class="p">}</span>
</code></pre></div><h3 id="13-data参数">1.3 data参数</h3>
<p>POST请求需要构造data参数，在开发者对应于payload, 整理为Python格式</p>
<p><img loading="lazy" src="img/02-payload.png" alt=""  />
</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">
</code></pre></div><p><br><br></p>
<h3 id="14-preview">1.4 preview</h3>
<p>看到左侧渲染后的数据，同时也能在开发者工具network面板看到肉眼背后的源数据。我们使用preview预览截图再次确认网址规律没有问题。</p>
<p><img loading="lazy" src="img/03-data-preview.jpg" alt=""  />
</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">keyword</span> <span class="o">=</span> <span class="s1">&#39;社会责任报告&#39;</span>
<span class="n">page</span> <span class="o">=</span> <span class="mi">1</span>

<span class="c1">#post方法参数</span>
<span class="n">payload</span> <span class="o">=</span><span class="p">{</span><span class="s2">&#34;seDate&#34;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&#34;&#34;</span><span class="p">,</span><span class="s2">&#34;&#34;</span><span class="p">],</span>
           <span class="s2">&#34;searchKey&#34;</span><span class="p">:</span> <span class="p">[</span><span class="n">keyword</span><span class="p">],</span>
           <span class="s2">&#34;channelCode&#34;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&#34;listedNotice_disc&#34;</span><span class="p">],</span>
           <span class="s2">&#34;pageSize&#34;</span><span class="p">:</span> <span class="mi">50</span><span class="p">,</span>
           <span class="s2">&#34;pageNum&#34;</span><span class="p">:</span> <span class="n">page</span><span class="p">}</span>
</code></pre></div><h3 id="15-csv">1.5 csv</h3>
<p>现在已经把爬虫最重要的工作做完了，剩下的就是想办法构造出csv，并将数据存入csv。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#定义csv字段，存储PDF链接信息至data/esg_links.csv</span>
<span class="n">csvf</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;data/esg_links.csv&#39;</span><span class="p">,</span> <span class="s1">&#39;a+&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">,</span> <span class="n">newline</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
<span class="n">fieldnames</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;id&#39;</span><span class="p">,</span> <span class="s1">&#39;name&#39;</span><span class="p">,</span> <span class="s1">&#39;code&#39;</span><span class="p">,</span> <span class="s1">&#39;date&#39;</span><span class="p">,</span> <span class="s1">&#39;title&#39;</span><span class="p">,</span> <span class="s1">&#39;pdf_link&#39;</span><span class="p">,</span> <span class="s1">&#39;size&#39;</span><span class="p">]</span>
<span class="n">writer</span> <span class="o">=</span> <span class="n">csv</span><span class="o">.</span><span class="n">DictWriter</span><span class="p">(</span><span class="n">csvf</span><span class="p">,</span> <span class="n">fieldnames</span><span class="o">=</span><span class="n">fieldnames</span><span class="p">)</span>
<span class="n">writer</span><span class="o">.</span><span class="n">writeheader</span><span class="p">()</span>

<span class="n">test_data</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;pdf_link&#39;</span><span class="p">:</span> <span class="s1">&#39;测试pdf文件链接&#39;</span><span class="p">,</span>
             <span class="s1">&#39;code&#39;</span><span class="p">:</span> <span class="s1">&#39;测试股票代码&#39;</span><span class="p">,</span>
             <span class="s1">&#39;name&#39;</span><span class="p">:</span> <span class="s1">&#39;股票名称&#39;</span><span class="p">,</span>
             <span class="s1">&#39;title&#39;</span><span class="p">:</span> <span class="s1">&#39;报告名称&#39;</span><span class="p">,</span>
             <span class="s1">&#39;date&#39;</span><span class="p">:</span> <span class="s1">&#39;发布日期&#39;</span><span class="p">,</span>
             <span class="s1">&#39;size&#39;</span><span class="p">:</span> <span class="s1">&#39;pdf文件字节大小&#39;</span><span class="p">,</span>
             <span class="s1">&#39;id&#39;</span><span class="p">:</span> <span class="s1">&#39;数据id&#39;</span><span class="p">}</span>
             
<span class="n">writer</span><span class="o">.</span><span class="n">writerow</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span>

<span class="c1">#关闭csv</span>
<span class="n">csvf</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</code></pre></div><p><br><br></p>
<h2 id="二爬虫代码完整">二、爬虫代码(完整)</h2>
<p>当你看到本文时，该完整代码很有可能会随着网站变化而失效。不要悲伤难过， 按照爬虫思路自己diy即可。如果没有爬虫基础，学习 <a href="https://www.bilibili.com/video/BV1AE411r7ph">大邓的B站爬虫视频</a> ，</p>
<p><img loading="lazy" src="img/%e5%a4%a7%e9%82%93%e7%88%ac%e8%99%ab.jpg" alt=""  />
</p>
<p>自己懂爬虫原理diy代码，比改别人的代码来的更容易。将前面的准备工作组织起来, 就形成了下面的完整代码</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">requests</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">csv</span>

<span class="n">keyword</span> <span class="o">=</span> <span class="s2">&#34;社会责任报告&#34;</span>

<span class="c1">#定义csv字段，存储PDF链接信息至data/esg_links.csv</span>
<span class="n">csvf</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;data/esg_links.csv&#39;</span><span class="p">,</span> <span class="s1">&#39;a+&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">,</span> <span class="n">newline</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
<span class="n">fieldnames</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;id&#39;</span><span class="p">,</span> <span class="s1">&#39;name&#39;</span><span class="p">,</span> <span class="s1">&#39;code&#39;</span><span class="p">,</span> <span class="s1">&#39;date&#39;</span><span class="p">,</span> <span class="s1">&#39;title&#39;</span><span class="p">,</span> <span class="s1">&#39;pdf_link&#39;</span><span class="p">,</span> <span class="s1">&#39;size&#39;</span><span class="p">]</span>
<span class="n">writer</span> <span class="o">=</span> <span class="n">csv</span><span class="o">.</span><span class="n">DictWriter</span><span class="p">(</span><span class="n">csvf</span><span class="p">,</span> <span class="n">fieldnames</span><span class="o">=</span><span class="n">fieldnames</span><span class="p">)</span>
<span class="n">writer</span><span class="o">.</span><span class="n">writeheader</span><span class="p">()</span>

<span class="c1">#伪装头</span>
<span class="n">headers</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;Accept&#39;</span><span class="p">:</span> <span class="s1">&#39;application/json, text/javascript, */*; q=0.01&#39;</span><span class="p">,</span>
           <span class="s1">&#39;Accept-Encoding&#39;</span><span class="p">:</span> <span class="s1">&#39;gzip, deflate&#39;</span><span class="p">,</span>
           <span class="s1">&#39;Accept-Language&#39;</span><span class="p">:</span> <span class="s1">&#39;zh-CN,zh;q=0.9,en;q=0.8&#39;</span><span class="p">,</span>
           <span class="s1">&#39;Content-Type&#39;</span><span class="p">:</span> <span class="s1">&#39;application/json&#39;</span><span class="p">,</span>
           <span class="s1">&#39;Host&#39;</span><span class="p">:</span> <span class="s1">&#39;www.szse.cn&#39;</span><span class="p">,</span>
           <span class="s1">&#39;Origin&#39;</span><span class="p">:</span> <span class="s1">&#39;http://www.szse.cn&#39;</span><span class="p">,</span>
           <span class="s1">&#39;Proxy-Connection&#39;</span><span class="p">:</span> <span class="s1">&#39;close&#39;</span><span class="p">,</span>
           <span class="s1">&#39;Referer&#39;</span><span class="p">:</span> <span class="s1">&#39;http://www.szse.cn/disclosure/listed/fixed/index.html&#39;</span><span class="p">,</span>
           <span class="s1">&#39;User-Agent&#39;</span><span class="p">:</span> <span class="s1">&#39;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.132 Safari/537.36&#39;</span><span class="p">,</span>
           <span class="s1">&#39;X-Request-Type&#39;</span><span class="p">:</span> <span class="s1">&#39;ajax&#39;</span><span class="p">,</span>
           <span class="s1">&#39;X-Requested-With&#39;</span><span class="p">:</span> <span class="s1">&#39;XMLHttpRequest&#39;</span><span class="p">}</span>

<span class="n">page</span> <span class="o">=</span> <span class="mi">1</span>

<span class="c1">#post方法参数</span>
<span class="n">payload</span> <span class="o">=</span><span class="p">{</span><span class="s2">&#34;seDate&#34;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&#34;&#34;</span><span class="p">,</span><span class="s2">&#34;&#34;</span><span class="p">],</span>
           <span class="s2">&#34;searchKey&#34;</span><span class="p">:</span> <span class="p">[</span><span class="n">keyword</span><span class="p">],</span>
           <span class="s2">&#34;channelCode&#34;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&#34;listedNotice_disc&#34;</span><span class="p">],</span>
           <span class="s2">&#34;pageSize&#34;</span><span class="p">:</span> <span class="mi">50</span><span class="p">,</span>
           <span class="s2">&#34;pageNum&#34;</span><span class="p">:</span> <span class="n">page</span><span class="p">}</span>

<span class="c1">#发起请求</span>
<span class="n">url</span> <span class="o">=</span> <span class="s1">&#39;http://www.szse.cn/api/disc/announcement/annList?random=</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">())</span>
<span class="n">resp</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">post</span><span class="p">(</span><span class="n">url</span><span class="p">,</span>
                     <span class="n">headers</span><span class="o">=</span><span class="n">headers</span><span class="p">,</span>
                     <span class="n">data</span><span class="o">=</span><span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">payload</span><span class="p">))</span>

<span class="c1">#当data关键词有对应的非空列表，循环一直进行。</span>
<span class="k">while</span> <span class="n">resp</span><span class="o">.</span><span class="n">json</span><span class="p">()[</span><span class="s1">&#39;data&#39;</span><span class="p">]:</span>
    <span class="n">payload</span><span class="p">[</span><span class="s1">&#39;pageNum&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">page</span>
    <span class="n">resp</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">post</span><span class="p">(</span><span class="n">url</span><span class="p">,</span>
                     <span class="n">headers</span><span class="o">=</span><span class="n">headers</span><span class="p">,</span>
                     <span class="n">data</span><span class="o">=</span><span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">payload</span><span class="p">))</span>
    
    <span class="n">esgs</span> <span class="o">=</span> <span class="n">resp</span><span class="o">.</span><span class="n">json</span><span class="p">()[</span><span class="s1">&#39;data&#39;</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">esg</span> <span class="ow">in</span> <span class="n">esgs</span><span class="p">:</span>
        <span class="c1">#以字典样式写入csv</span>
        <span class="n">data</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;pdf_link&#39;</span><span class="p">:</span> <span class="s1">&#39;http://disc.static.szse.cn/download&#39;</span><span class="o">+</span> <span class="n">esg</span><span class="p">[</span><span class="s1">&#39;attachPath&#39;</span><span class="p">],</span>
                <span class="c1">#为防止股票代码被exel等软件识别为数字，特转为字符串，并加sz标识。</span>
                <span class="s1">&#39;code&#39;</span><span class="p">:</span> <span class="s1">&#39;sz&#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">esg</span><span class="p">[</span><span class="s1">&#39;secCode&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">]),</span> 
                <span class="s1">&#39;name&#39;</span><span class="p">:</span> <span class="n">esg</span><span class="p">[</span><span class="s1">&#39;secName&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span>
                <span class="s1">&#39;title&#39;</span><span class="p">:</span> <span class="n">esg</span><span class="p">[</span><span class="s1">&#39;title&#39;</span><span class="p">],</span>
                <span class="s1">&#39;date&#39;</span><span class="p">:</span> <span class="n">esg</span><span class="p">[</span><span class="s1">&#39;publishTime&#39;</span><span class="p">],</span>
                <span class="s1">&#39;size&#39;</span><span class="p">:</span> <span class="n">esg</span><span class="p">[</span><span class="s1">&#39;attachSize&#39;</span><span class="p">],</span>
                <span class="s1">&#39;id&#39;</span><span class="p">:</span> <span class="n">esg</span><span class="p">[</span><span class="s1">&#39;id&#39;</span><span class="p">]}</span>
        <span class="n">writer</span><span class="o">.</span><span class="n">writerow</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

    <span class="n">page</span> <span class="o">=</span> <span class="n">page</span> <span class="o">+</span> <span class="mi">1</span>
    
<span class="c1">#关闭csv</span>
<span class="n">csvf</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</code></pre></div><p><br><br></p>
<h2 id="三查看csv">三、查看csv</h2>
<p>使用pandas读取 <code>data/esg_links.csv</code>,</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;esg_links.csv&#39;</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/04-df.png" alt=""  />
</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">4392
</code></pre></div><p>一共有4392条 「企业社会责任」 的报告数据。</p>
<p><br><br></p>
<h2 id="四批量下载">四、批量下载</h2>
<p>下载就简单多了， 直接使用定义好的爬虫代码。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">requests</span>

<span class="k">def</span> <span class="nf">download</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">file</span><span class="p">):</span>
    <span class="s2">&#34;&#34;&#34;
</span><span class="s2">    下载多媒体及文件
</span><span class="s2">    url： 多媒体文件链接（结尾有文件格式名）
</span><span class="s2">    file: 存储文件的路径（结尾有文件格式名）
</span><span class="s2">    &#34;&#34;&#34;</span>
    <span class="n">resp</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
    <span class="c1">#获取到二进制数据</span>
    <span class="n">binarydata</span> <span class="o">=</span> <span class="n">resp</span><span class="o">.</span><span class="n">content</span>
    <span class="c1">#以二进制形式将数据流存入fname中</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">file</span><span class="p">,</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">binarydata</span><span class="p">)</span> 
        

<span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>

<span class="k">for</span> <span class="n">link</span><span class="p">,</span> <span class="n">title</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;pdf_link&#39;</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;title&#39;</span><span class="p">]):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">title</span><span class="p">)</span>
    <span class="n">download</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="n">link</span><span class="p">,</span> <span class="n">file</span><span class="o">=</span><span class="s1">&#39;data/</span><span class="si">{}</span><span class="s1">.pdf&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">title</span><span class="p">))</span>
    <span class="n">i</span> <span class="o">=</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">0 山河药辅：山河药辅2021年度社会责任报告
1 新 希 望：2021年企业社会责任报告（英文版）
2 天原股份：宜宾天原集团股份有限公司社会责任报告
3 五 粮 液：2021年度社会责任报告（英文版）
4 中兵红箭：2021年度社会责任报告	
......
......
148 苏宁环球：2021年社会责任报告
149 蓝色光标：2021年度企业社会责任报告
150 开尔新材：2021年度社会责任报告
151 中顺洁柔：2021年社会责任报告
......
......

4391 闽东电力：2006年度社会责任报告
4392  阳光发展：2006年度社会责任报告书
</code></pre></div><p>采集过程中，被封锁在所难免，所以记得每次停止采集的位置，在csv中删除该位置之前的数据。然后重新运行代码即可。</p>
<h3 id="注意">注意</h3>
<p>即时解决以上问题，可能遇到奇怪的问题。比如</p>
<p><img loading="lazy" src="img/07-error.png" alt=""  />
</p>
<p>检查发现相比其他几百kb的pdf，问题文件大小只有几kb。问题可能是被网站封锁或网络不稳定导致，标记好问题pdf的链接，重新批量下载一遍。</p>
<p><img loading="lazy" src="img/06-error.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="汇总至csv">汇总至csv</h2>
<p>很多企业社会责任报告是图片合成的，所以这里的pdf体积很大。将data文件夹中的4000多个pdf汇总至esg_data.csv中，能节约出电脑内存空间，也方便后续数据分析。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">pdfdocx</span> <span class="kn">import</span> <span class="n">read_pdf</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">csv</span>

<span class="n">i</span> <span class="o">=</span> <span class="mi">1</span>

<span class="c1">#新建esg_data.csv，用于存储企业社会责任报告数据</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;esg_data.csv&#39;</span><span class="p">,</span> <span class="s1">&#39;a+&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">,</span> <span class="n">newline</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">csvf</span><span class="p">:</span>
    <span class="n">fieldnames</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;id&#39;</span><span class="p">,</span> <span class="s1">&#39;name&#39;</span><span class="p">,</span> <span class="s1">&#39;code&#39;</span><span class="p">,</span> <span class="s1">&#39;date&#39;</span><span class="p">,</span> <span class="s1">&#39;title&#39;</span><span class="p">,</span> <span class="s1">&#39;pdf_link&#39;</span><span class="p">,</span> <span class="s1">&#39;size&#39;</span><span class="p">,</span> <span class="s1">&#39;report_content&#39;</span><span class="p">]</span>
    <span class="n">writer</span> <span class="o">=</span> <span class="n">csv</span><span class="o">.</span><span class="n">DictWriter</span><span class="p">(</span><span class="n">csvf</span><span class="p">,</span> <span class="n">fieldnames</span><span class="o">=</span><span class="n">fieldnames</span><span class="p">)</span>
    <span class="n">writer</span><span class="o">.</span><span class="n">writeheader</span><span class="p">()</span>

    <span class="n">files</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="s1">&#39;data&#39;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">file</span> <span class="ow">in</span> <span class="n">files</span><span class="p">:</span>
        <span class="n">record_of_df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;title&#39;</span><span class="p">]</span><span class="o">==</span><span class="n">file</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;.pdf&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">)]</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">record_of_df</span><span class="o">.</span><span class="n">to_dict</span><span class="p">()</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">file</span><span class="p">)</span>
        <span class="n">data</span><span class="p">[</span><span class="s1">&#39;report_content&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">read_pdf</span><span class="p">(</span><span class="s1">&#39;data/</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">file</span><span class="p">))</span>
        <span class="n">writer</span><span class="o">.</span><span class="n">writerow</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="n">i</span> <span class="o">=</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span>
</code></pre></div><p>最后，数据从20G的data文件夹(4000多个PDF)压缩为一个170M的esg_data.csv文件。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">esg_reports_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;esg_data.csv&#39;</span><span class="p">)</span>
<span class="n">esg_reports_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/08-esg_reports_df.png" alt=""  />
</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="nb">len</span><span class="p">(</span><span class="n">esg_reports_df</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">4346
</code></pre></div><p><br><br></p>
<h2 id="五相关文献">五、相关文献</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">[1]解学梅, &amp; 朱琪玮. (2021). 企业绿色创新实践如何破解 “和谐共生” 难题?. 管理世界, 37(1), 128-149.
[2]谢红军 &amp; 吕雪.(2022).负责任的国际投资：ESG与中国OFDI. 经济研究(03),83-99.
[3]Schaefer, S. D., Terlutter, R., &amp; Diehl, S. (2019). Is my company really doing good? Factors influencing employees&#39; evaluation of the authenticity of their company&#39;s corporate social responsibility engagement. Journal of business research, 101, 128-143.
</code></pre></div><p><br><br></p>
<h2 id="六其他广告">六、其他(广告)</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>中文金融领域知识图谱的数据集ChainKnowledgeGraph</title>
      <link>https://textdata.cn/blog/chain_knowledge_graph/</link>
      <pubDate>Mon, 06 Dec 2021 16:42:10 +0600</pubDate>
      
      <guid>/blog/chain_knowledge_graph/</guid>
      <description>本文围绕金融领域，推出面向上市公司的产业链图谱。  </description>
      <content:encoded><![CDATA[<p>领域知识图谱的数据集，当前还比较缺失，而作为构建难度最大的产业链图谱领域更为空白。产业链作为产业经济学中的一个概念，是各个产业部门之间基于一定的技术经济关联，并依据特定的逻辑关系和时空布局关系客观形成的链条式关联关系形态。从本质上来说，产业链的本质是用于描述一个具有某种内在联系的企业群结构，产业链中大量存在着上下游关系和相互价值的交换，上游环节向下游环节输送产品或服务，下游环节向上游环节反馈信息。</p>
<p>作者已经先后发布两大领域的实体图谱数据： <br>
1、情报领域【武器装备知识图谱】，地址：https://github.com/liuhuanyong/QAonMilitaryKG<br>
2、医疗领域【医疗知识图谱】，地址： <a href="https://github.com/liuhuanyong/QASystemOnMedicalKG">https://github.com/liuhuanyong/QASystemOnMedicalKG</a></p>
<p>当前，为了进一步推动产业发展，本文围绕金融领域，推出面向上市公司的产业链图谱。</p>
<p>项目地址：</p>

<figure >
    
        <img src="img/1.png" width="800" />
    
    
</figure>

<br>
<h2 id="一项目构成">一、项目构成</h2>
<p>产业链知识图谱包括A股上市公司、行业和产品共3类实体，包括上市公司所属行业关系、行业上级关系、产品上游原材料关系、产品下游产品关系、公司主营产品、产品小类共6大类。</p>
<p>通过数据处理、抽取，最终建成图谱规模数十万，其中包括上市公司4,654家，行业511个，产品95,559条、上游材料56,824条，上级行业480条，下游产品390条，产品小类52,937条，所属行业3,946条。  <br>

<figure >
    
        <img src="img/2.png" width="800" />
    
    
</figure>
</p>
<br>
<h2 id="二项目构建">二、项目构建</h2>
<p>1、实体构建<br>
1）上市公司<br>
目前上市公司已经达到四千多家，是我国重要的公司代表与行业标杆，本图谱选取上市公司作为基础实体之一。通过交易所公开信息中，可以得到上市公司代码、全称、简称、注册地址、挂牌等多个信息。</p>

<figure >
    
        <img src="img/3.png" width="800" />
    
    
</figure>

<p>2）行业分类<br>
行业是产业链图谱中另一个核心内容，也是承载产业、公司及产品的一个媒介，通过这一领携作用，可以生产出大量的行业指数、热点行业等指标。<br>
目前关于行业，已经陆续出现多个行业规范，代表性的有申万三级行业分类、国民经济行业分类等。中国上市公司所属行业的分类准则是依据营业收入等财务数据为主要分类标准和依据，所采用财务数据为经过会计事务所审计并已公开披露的合并报表数据。<br>
2021年6月，申万发布了2021版的行业分类规范，将1级行业从28个调整至31个、2级行业从104个调整至134个、3级行业从227个调整至346个，新增1级行业美容护理等，新增2级行业，并将上市公司进行了归属。本图谱选用申万行业作为基础数据。<br>

<figure >
    
        <img src="img/4.png" width="800" />
    
    
</figure>
</p>
<p>3）业务产品 <br>
业务产品主要指公司主营范围、经营的产品，用于对一个公司的定位。可以从公司的经营范围、年报等文本中进行提取得到。<br>

<figure >
    
        <img src="img/5.png" width="800" />
    
    
</figure>
</p>
<p>2、关系构建 <br>
1）公司所属行业 <br>
通过公开的上市公司行业分类表，可以得到上市公司所对应的行业分类数据。 <br>

<figure >
    
        <img src="img/6.png" width="800" />
    
    
</figure>
</p>
<p>2）行业上级关系 <br>
通过公开的行业三级分类情况，可以通过组合的形式得到行业之间的上级关系数据。 <br>

<figure >
    
        <img src="img/7.png" width="800" />
    
    
</figure>
</p>
<p>3）公司主营产品关系<br>
上市公司的经营产品数据可以从两个方面来获得，一个是从公司简介中的经营范围中结合制定的规则进行提取，另一个是从公司每年发布的半年报、年报中进行提取。这些报告中会有按经营业务、经营产品、经营地域等几个角度对公司的营收占比进行统计，也可以通过制定规则的方式进行提取。第二种方法中，由于已经有统计数据，所以我们可以根据占比数据大小，对主营产品这一关系进行赋值。<br>

<figure >
    
        <img src="img/8.png" width="800" />
    
    
</figure>
</p>
<p>4）产品之间的上下游关系<br>
产品之间的上下游关系，是展示产品之间传导逻辑关系的一个重要方法，包括上游原材料以及下游产品两大类。我们可以多种来获取：<br>
一种是基于规则模式匹配的方式进行抽取，如抽取上游原材料这一关系可以由诸如&quot;a是b的原料/原材料/主要构件/重要原材料/  上游原料&quot;的模式进行抽取&quot;，而下游产品，则同理可以通过&quot;A是B的下游成品/产品&quot;等模式进行提取。<br>
另一种是基于序列标注的提取。还有一种是基于现有结构化知识图谱的提取，例如已经结构化好的百科知识三元组，可以通过设定谓词及其扩展进行过滤。<br>

<figure >
    
        <img src="img/9.png" width="800" />
    
    
</figure>
</p>
<p>5）产品之间的小类关系<br>
对于一个产品而言，其是有大小层级分类的，在缺少大类产品名称的时候，可以通过计算小类产品来得到相应指标。与产品之间的上下游数据类似，可以通过启发式规则的方式进行提取，如“A是一种B”，也可以通过字符之间的组成成分进行匹配生成，如“螺纹钢”是“精细螺纹钢”的一个大类。<br>

<figure >
    
        <img src="img/10.png" width="800" />
    
    
</figure>
</p>
<br>
<h2 id="三项目运行">三、项目运行</h2>
<p>1、data文件夹下包括了本项目的数据信息：<br>
1)company.json:公司实体数据<br>
2)industry.json:行业实体数据 <br>
3)product.json:产品实体数据 <br>
4)company_industry.json:公司-行业关系数据 <br>
5)industry_industry.json:行业-行业关系数据 <br>
6)product_product.json:产品-产品数据 <br>
7)company_product.json:公司-产品数据</p>
<p>2、项目运行:<br>
python build_graph.py</p>
<br>
<h2 id="四项目总结">四、项目总结</h2>
<p>产业链图谱是众多领域知识图谱中较为棘手的一种，本项目通过现有的数据，借助数据处理、结构化提取方式，设计、构建并形成了一个节点100,718，关系边169,153的十万级别产业链图谱。就产业链图谱的构建而言，我们需要至少从以上三个方面加以考虑：</p>
<ul>
<li>其一，产业链的主观性与标准性。产业链的主观性较强，不同的人对产业链的构建、产业链节点、关系的类型，产业链的颗粒度问题都有不同的理解。不同的设定会直接导致不同的应用结果。正如我们所看到的，目前存在不同的行业标准，不同的网站、机构也将公司归为不同的行业。</li>
<li>其二，产业链的动态性和全面性。产业链需要具备足够大的复用性和扩展性，几千家上市公司实际上是冰山一角。国内有几千万家公司，而且不断会有新增，如何将新增的公司融入到这个额产业链中，也是一个很大挑战。此外，产业本身是动态的， 随着行业的发展，不断会有新的行业出现。如何捕捉这种行业的变化，使得整个图谱变得与时俱进，也是需要考量的点。</li>
<li>其三，产业链的定量推理特性。单纯定性的构建产业链知识图谱，如果没有足够的参数，仅有知识表达是无法进行推理的，推理要求知识图谱Schema具备节点间推理传导的必备参数，以及影响推理传导的其他关键参数。对于必备参数来说，从公司到产品必须有主营占比、市场占比、产能占比等数据，从产品到产品必须有成本占比和消耗占比等数据。</li>
</ul>
<br>
<h2 id="参考数据来源">参考数据来源</h2>
<p>1、申万行业：http://www.swsindex.com<br>
2、深交所: <a href="http://www.szse.cn">http://www.szse.cn</a><br>
3、上交所: <a href="http://www.sse.com.cn">http://www.sse.com.cn</a></p>
<p>If any question about the project or me ,see <a href="https://liuhuanyong.github.io/">https://liuhuanyong.github.io/</a></p>
<p>如有自然语言处理、知识图谱、事理图谱、社会计算、语言资源建设等问题或合作，可联系我： <br>
1、我的github项目介绍：https://liuhuanyong.github.io<br>
2、我的csdn博客：https://blog.csdn.net/lhy2014<br>
3、about me:刘焕勇，lhy_<a href="mailto:in_blcu@126.com">in_blcu@126.com</a>.      <br>
4、我的技术公众号:老刘说NLP</p>
<br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>中文语义常用词典ChineseSemanticKB</title>
      <link>https://textdata.cn/blog/chinese_semantic_kb/</link>
      <pubDate>Mon, 06 Dec 2021 16:40:10 +0600</pubDate>
      
      <guid>/blog/chinese_semantic_kb/</guid>
      <description>面向中文处理的12类、百万规模的语义常用词典，包括34万抽象语义库、34万反义语义库、43万同义语义库等，可支持句子扩展、转写、事件抽象与泛化等多种应用场景。</description>
      <content:encoded><![CDATA[<h2 id="chinesesemantickb">ChineseSemanticKB</h2>
<p>ChineseSemanticKB,chinese semantic knowledge base, 面向中文处理的12类、百万规模的语义常用词典，包括34万抽象语义库、34万反义语义库、43万同义语义库等，可支持句子扩展、转写、事件抽象与泛化等多种应用场景。</p>
<br>
<h2 id="项目介绍">项目介绍</h2>
<p>语义知识库是自然语言处理中十分重要的一个基础资源，与学术界追求算法模型不同，工业界的自然语言处理对于底层的词汇知识库、语义知识库等多种资源依赖度很高，具体体现在：<br>
1、具有落地场景的自然语言处理任务都是业务高度相关，一个业务需求刚进去，需要解决的是业务的词汇问题，无基础词库，无项目冷启动；<br>
2、规则和正则启动下的工业级应用，规则的扩展、泛化都需要底层的词汇网络做支撑；<br>
3、目前包括搜索、问答、舆情监控、事件分析等应用，与标签体系的运作关系密切，而这与先验的底层词汇库依赖性很强；<br>
4、自然语言场景越来越关注推理层面，即所谓的“认知”层面，认知背后的各种逻辑关系库，是驱动这一决策的根本途径；<br>
5、当前，面向中文开源词库的工作存在少量、分散的状态，无论从规模，还是质量，都需要进一步聚合；<br>
因此，我从过往的开源工作中进一步抽离和整理，形成了中文处理的12类、百万规模的语义常用词典，包括34万抽象语义库、34万反义语义库、43万同义语义库等，用于相关下游任务。</p>
<p>项目放于dict当中，可直接下载，不建议二次建库共享，尊重开源。</p>
<br>
<h2 id="词库的类别">词库的类别</h2>
<table>
<thead>
<tr>
<th style="text-align:left">词库类型</th>
<th style="text-align:center">词库规模</th>
<th style="text-align:center">词库举例</th>
<th style="text-align:center">词库应用</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">抽象关系库</td>
<td style="text-align:center">346,048</td>
<td style="text-align:center">座椅,抽象,家具</td>
<td style="text-align:center">事件抽象与泛化，人民币贬值到货币贬值，再到美元贬值，可支持查询扩展、推荐等任务</td>
</tr>
<tr>
<td style="text-align:left">反义关系库</td>
<td style="text-align:center">34,380</td>
<td style="text-align:center">开心@苦恼</td>
<td style="text-align:center">可用于句子改写，开心改苦恼，支持数据增强，句子生成</td>
</tr>
<tr>
<td style="text-align:left">同义关系库</td>
<td style="text-align:center">424,826</td>
<td style="text-align:center">开心@高兴</td>
<td style="text-align:center">可用于查询扩展、数据增强，也可结合抽象关系库完成推荐等任务</td>
</tr>
<tr>
<td style="text-align:left">简称关系库</td>
<td style="text-align:center">136,081</td>
<td style="text-align:center">北京大学@北大</td>
<td style="text-align:center">可用于句子标准化、句子改写、实体消歧等任务</td>
</tr>
<tr>
<td style="text-align:left">程度副词</td>
<td style="text-align:center">222</td>
<td style="text-align:center">极其,2.0</td>
<td style="text-align:center">可用于情感强度计算，带情感色彩的句子生成</td>
</tr>
<tr>
<td style="text-align:left">否定词</td>
<td style="text-align:center">586</td>
<td style="text-align:center">不,无,没有</td>
<td style="text-align:center">可用于情感计算等任务</td>
</tr>
<tr>
<td style="text-align:left">节日时间词</td>
<td style="text-align:center">54</td>
<td style="text-align:center">春节、五四节</td>
<td style="text-align:center">可用于时间词识别等任务</td>
</tr>
<tr>
<td style="text-align:left">量比词</td>
<td style="text-align:center">7</td>
<td style="text-align:center">占比、环比、同比</td>
<td style="text-align:center">可用于金融领域指标类数据提取任务</td>
</tr>
<tr>
<td style="text-align:left">数量介词</td>
<td style="text-align:center">24</td>
<td style="text-align:center">大约、达到、超过</td>
<td style="text-align:center">可用于金融事件抽象或主干化的搭配词处理任务</td>
</tr>
<tr>
<td style="text-align:left">停用词</td>
<td style="text-align:center">3,861</td>
<td style="text-align:center">？、的、着</td>
<td style="text-align:center">常规的文本特征提取等任务</td>
</tr>
<tr>
<td style="text-align:left">修饰副词</td>
<td style="text-align:center">222</td>
<td style="text-align:center">所、有所</td>
<td style="text-align:center">可结合程度副词完成情感强度计算等任务</td>
</tr>
<tr>
<td style="text-align:left">情态词</td>
<td style="text-align:center">77</td>
<td style="text-align:center">肯定、应该、大概</td>
<td style="text-align:center">可用于句子主观性计算、舆情与可信度计算</td>
</tr>
</tbody>
</table>
<br>
<h2 id="总结">总结</h2>
<p>1、本项目开源了一个目前可用于事件处理以及工业舆情的12类语义词库，总规模数目一百余万；<br>
2、本项目开源的34万抽象语义库、34万反义语义库、43万同义语义库，在作者的实际工作中【事件处理、事理抽取、事件推理】等有重要用途;<br>
3、中文常用语义常用词典，均来源于公开文本+人工整理+机器抽取形成，其中若有质量不高之处，可积极批评指正;<br>
4、中文开源事业还是要坚持做下去，尽可能地缩短自然语言处理学术界和工业界之间的鸿沟。</p>
<blockquote>
<p>If any question about the project or me ,see <a href="https://liuhuanyong.github.io/">https://liuhuanyong.github.io/</a>.<br>
如有自然语言处理、知识图谱、事理图谱、社会计算、语言资源建设等问题或合作，可联系我：     <br>
1、我的github项目介绍：https://liuhuanyong.github.io  <br>
2、我的csdn技术博客：https://blog.csdn.net/lhy2014 <br>
3、我的联系方式: 刘焕勇，中国科学院软件研究所，lhy_<a href="mailto:in_blcu@126.com">in_blcu@126.com</a>. <br>
4、我的共享知识库项目：刘焕勇，数据地平线，http://www.openkg.cn/organization/datahorizon.<br>
5、我的工业项目：刘焕勇，数据地平线，大规模实时事理学习系统：https://xueji.datahorizon.cn.  <br>
6、我的工业项目：刘焕勇，数据地平线，面向事件和语义的自然语言处理工具箱：https://nlp.datahorizon.cn</p>
</blockquote>
<br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>70G上交所年报数据集</title>
      <link>https://textdata.cn/blog/70g_china_market_anunal_report_datasets/</link>
      <pubDate>Mon, 22 Nov 2021 20:40:10 +0600</pubDate>
      
      <guid>/blog/70g_china_market_anunal_report_datasets/</guid>
      <description>Python网络爬虫与文本分析， 70g会计年报pdf数据集免费下载</description>
      <content:encoded><![CDATA[<h2 id="70g年报pdf数据集">70G年报pdf数据集</h2>
<p><img loading="lazy" src="img/1.gif" alt=""  />
</p>
<h2 id="数据下载说明">数据下载说明</h2>
<p>所有pdf均来自上海证券交易所官网，使用shreport库进行的下载。</p>
<p><img loading="lazy" src="img/2.png" alt=""  />
</p>
<h2 id="报告信息汇总文件">报告信息汇总文件</h2>
<h4 id="heading"></h4>
<p><img loading="lazy" src="img/3.gif" alt=""  />
</p>
<p>summary.xlsx内字段</p>
<ul>
<li>company 上市公司企业名</li>
<li>code 股票代码</li>
<li>type 报告类型</li>
<li>year 报告年份</li>
<li>date 报告发布日期</li>
<li>pdf 报告pdf文件下载链接</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">import pandas as pd
from pathlib import Path


#报告汇总文件summary.xlsx
df = pd.read_excel(&#39;summary.xlsx&#39;)
df.head()
</code></pre></div><p><img loading="lazy" src="img/4.png" alt=""  />
</p>
<p>一共有报告71126份</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">len(df)
71149
</code></pre></div><p>一共有上市公司1486家</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">len(df[&#39;company&#39;].unique())
1486
</code></pre></div><h2 id="summary文件夹">summary文件夹</h2>
<p>summary文件夹内是每家公司的报告披露情况</p>
<p><img loading="lazy" src="img/5.gif" alt=""  />
</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">df1 = pd.read_excel(&#39;summary/600000.xlsx&#39;)
df1.head()
</code></pre></div><p><img loading="lazy" src="img/6.png" alt=""  />
</p>
<p>浦发银行一共有75份定期报告</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">len(df1)
75
</code></pre></div><h2 id="reports文件夹">reports文件夹</h2>
<p>reports文件夹存放着以各各公司股票代码命名的文件夹</p>
<p>文件夹内是该公司所有定期报告</p>
<p><img loading="lazy" src="img/7.gif" alt=""  />
</p>
<h2 id="读取pdf报告">读取pdf报告</h2>
<p>可使用pdfdocx库读取pdf,</p>
<p>pdfdocx文档链接 <a href="https://github.com/thunderhit/pdfdocx">https://github.com/thunderhit/pdfdocx</a></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">from pdfdocx import read_pdf

p_text = read_pdf(&#39;reports/600000/600000_2012_1.pdf&#39;)
p_text
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">上海浦东发展银行股份有限公司 \n\n2012 年第一季度报告 \n\n \n\n \n\n§1 重要提示 \n\n1.1 公司董事会、监事会及其董事、监事、高级管理人员保证本报告所载资料不存在任何虚假记载、\n\n误导性陈述或者重大遗漏，并对其内容的真实性、准确性和完整性承担个别及连带责任。\n\n1.2 公司于 2012 年 4 月 26 日以通讯表决的方式召开第四届董事会第二十六次会议审议通过本报告，\n\n1.4 公司董事长、行长吉晓辉、财务总监刘信义及财务机构负责人傅能声明：保证本季度报告中财务\n\n公司全体董事出席董事会会议并行使表决权。\n\n1.3 公司第一季度财务报告未经审计。\n\n报告的真实、完整。\n\n \n§2 公司基本情况 \n\n2.1 主要会计数据及财务指标 \n\n本报告期末 \n\n上年度期末 \n\n币种:人民币 \n\n本报告期末比上年\n度期末增减(%) \n\n总资产(千元) \n\n归属于上市公司股东的所有者权益(千元) \n\n2,804,646,567\n\n157,055,724\n\n2,684,693,689 \n148,891,235 \n\n归属于上市公司股东的每股净资产(元) \n\n8.420\n\n7.982 \n\n4.47 \n5.48 \n5.49 \n\n经营活动产生的现金流量净额(千元) \n\n每股经营活动产生的现金流\n\n \n\n \n \n母公司现金流量表 \n \n2012 年 1—3 月 \n \n编制单位: 上海浦东发展银行股份有限公司....
</code></pre></div><h2 id="70g数据下载">70G数据下载</h2>
<p>链接:https://pan.baidu.com/s/14PI6MbxunFQ3fZOfR33zkw 密码:osoi</p>
<br>
<br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
  </channel>
</rss>
