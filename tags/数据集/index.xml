<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>数据集 on 大邓和他的PYTHON</title>
    <link>/tags/%E6%95%B0%E6%8D%AE%E9%9B%86/</link>
    <description>Recent content in 数据集 on 大邓和他的PYTHON</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh</language>
    <lastBuildDate>Thu, 04 Aug 2022 00:00:00 +0000</lastBuildDate><atom:link href="/tags/%E6%95%B0%E6%8D%AE%E9%9B%86/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>17G报告数据 | 企业社会责任报告</title>
      <link>https://hidadeng.github.io/blog/coporate_social_responsibility_17g_datasets/</link>
      <pubDate>Thu, 04 Aug 2022 00:00:00 +0000</pubDate>
      
      <guid>/blog/coporate_social_responsibility_17g_datasets/</guid>
      <description>近年来，企业社会责任（CSR)已成为全球学术界研究的热点。国内外各大顶刊都先后刊登了多篇关于CSR的文章，比如《企业绿色创新实践如何破解“和谐共生”难题？》（发表于管理世界）、《负责任的国际投资：ESG与中国OFDI》（发表于经济研究）、《Is my company really doing good? Factors influencing employees&amp;#39; evaluation of the authenticity of their company&amp;#39;s corporate social responsibility engagement》（发表于JBR）等。这些文章核心变量的构建大都基于对企业社会责任报告的内容分析和挖掘。比如《企业绿色创新实践如何破解“和谐共生”难题？》的被解释变量（绿色创新）以及部分解释变量（二元合法性和伦理型领导）。可见，社会责任报告对于我们研究CSR至关重要。因此，接下来小编就带大家爬取深交所上市公司历年的社会责任报告，希望能够给大家带来一些帮助。</description>
      <content:encoded><![CDATA[<blockquote>
<p>作者:张延丰 哈工程在读博士</p>
</blockquote>
<p>近年来，企业社会责任（CSR)已成为全球学术界研究的热点。国内外各大顶刊都先后刊登了多篇关于CSR的文章，比如《企业绿色创新实践如何破解“和谐共生”难题？》（发表于管理世界）、《负责任的国际投资：ESG与中国OFDI》（发表于经济研究）、《Is my company really doing good? Factors influencing employees' evaluation of the authenticity of their company&rsquo;s corporate social responsibility engagement》（发表于JBR）等。这些文章核心变量的构建大都基于对企业社会责任报告的内容分析和挖掘。比如《企业绿色创新实践如何破解“和谐共生”难题？》的被解释变量（绿色创新）以及部分解释变量（二元合法性和伦理型领导）。可见，社会责任报告对于我们研究CSR至关重要。因此，接下来小编就带大家爬取深交所上市公司历年的社会责任报告，希望能够给大家带来一些帮助。</p>
<br>
<h2 id="获取数据集">获取数据集</h2>
<p>代码撰写不易，而运行该爬虫耗时十数小时， 如需获取本数据集，请转发本文至朋友圈集赞满30， 加微信【372335839】，备注【社会责任数据集】</p>
<p><img loading="lazy" src="img/dataset.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="一构建网络爬虫">一、构建网络爬虫</h2>
<p>数据采集分为多个步骤</p>
<ol>
<li>找网址规律(GET or POST), 构造url参数</li>
<li>伪装请求，防止被封</li>
<li>构造csv，存储信心</li>
<li>执行整个爬虫</li>
</ol>
<h3 id="11-url">1.1 url</h3>
<p>打开X交所的 <a href="http://www.szse.cn/disclosure/listed/notice/">http://www.szse.cn/disclosure/listed/notice/</a> ，同时打开浏览器开发者工具network面板，在截图左侧输入框输入关键词 『社会责任报告』，按下回车。</p>
<p>此时开发者工具network面板出现很多网络交换信息， 点击检查发现下图</p>
<p><img loading="lazy" src="img/01-%e7%bd%91%e5%9d%80%e8%a7%84%e5%be%8b.png" alt=""  />
</p>
<p>发现该页面数据是<strong>POST</strong>请求，网址为</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">http://www.szse.cn/api/disc/announcement/annList?random=random参数
</code></pre></div><h3 id="12-headers">1.2 headers</h3>
<p>同时也能发现伪装头参数，现将两个重要信息整理为</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">url</span> <span class="o">=</span> <span class="s1">&#39;http://www.szse.cn/api/disc/announcement/annList?random=</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">())</span>

<span class="c1">#伪装头</span>
<span class="n">headers</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;Accept&#39;</span><span class="p">:</span> <span class="s1">&#39;application/json, text/javascript, */*; q=0.01&#39;</span><span class="p">,</span>
           <span class="s1">&#39;Accept-Encoding&#39;</span><span class="p">:</span> <span class="s1">&#39;gzip, deflate&#39;</span><span class="p">,</span>
           <span class="s1">&#39;Accept-Language&#39;</span><span class="p">:</span> <span class="s1">&#39;zh-CN,zh;q=0.9,en;q=0.8&#39;</span><span class="p">,</span>
           <span class="s1">&#39;Content-Type&#39;</span><span class="p">:</span> <span class="s1">&#39;application/json&#39;</span><span class="p">,</span>
           <span class="s1">&#39;Host&#39;</span><span class="p">:</span> <span class="s1">&#39;www.szse.cn&#39;</span><span class="p">,</span>
           <span class="s1">&#39;Origin&#39;</span><span class="p">:</span> <span class="s1">&#39;http://www.szse.cn&#39;</span><span class="p">,</span>
           <span class="s1">&#39;Proxy-Connection&#39;</span><span class="p">:</span> <span class="s1">&#39;close&#39;</span><span class="p">,</span>
           <span class="s1">&#39;Referer&#39;</span><span class="p">:</span> <span class="s1">&#39;http://www.szse.cn/disclosure/listed/fixed/index.html&#39;</span><span class="p">,</span>
           <span class="s1">&#39;User-Agent&#39;</span><span class="p">:</span> <span class="s1">&#39;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.132 Safari/537.36&#39;</span><span class="p">,</span>
           <span class="s1">&#39;X-Request-Type&#39;</span><span class="p">:</span> <span class="s1">&#39;ajax&#39;</span><span class="p">,</span>
           <span class="s1">&#39;X-Requested-With&#39;</span><span class="p">:</span> <span class="s1">&#39;XMLHttpRequest&#39;</span><span class="p">}</span>
</code></pre></div><h3 id="13-data参数">1.3 data参数</h3>
<p>POST请求需要构造data参数，在开发者对应于payload, 整理为Python格式</p>
<p><img loading="lazy" src="img/02-payload.png" alt=""  />
</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">
</code></pre></div><p><br><br></p>
<h3 id="14-preview">1.4 preview</h3>
<p>看到左侧渲染后的数据，同时也能在开发者工具network面板看到肉眼背后的源数据。我们使用preview预览截图再次确认网址规律没有问题。</p>
<p><img loading="lazy" src="img/03-data-preview.jpg" alt=""  />
</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">keyword</span> <span class="o">=</span> <span class="s1">&#39;社会责任报告&#39;</span>
<span class="n">page</span> <span class="o">=</span> <span class="mi">1</span>

<span class="c1">#post方法参数</span>
<span class="n">payload</span> <span class="o">=</span><span class="p">{</span><span class="s2">&#34;seDate&#34;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&#34;&#34;</span><span class="p">,</span><span class="s2">&#34;&#34;</span><span class="p">],</span>
           <span class="s2">&#34;searchKey&#34;</span><span class="p">:</span> <span class="p">[</span><span class="n">keyword</span><span class="p">],</span>
           <span class="s2">&#34;channelCode&#34;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&#34;listedNotice_disc&#34;</span><span class="p">],</span>
           <span class="s2">&#34;pageSize&#34;</span><span class="p">:</span> <span class="mi">50</span><span class="p">,</span>
           <span class="s2">&#34;pageNum&#34;</span><span class="p">:</span> <span class="n">page</span><span class="p">}</span>
</code></pre></div><h3 id="15-csv">1.5 csv</h3>
<p>现在已经把爬虫最重要的工作做完了，剩下的就是想办法构造出csv，并将数据存入csv。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#定义csv字段，存储PDF链接信息至data/csr_links.csv</span>
<span class="n">csvf</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;data/csr_links.csv&#39;</span><span class="p">,</span> <span class="s1">&#39;a+&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">,</span> <span class="n">newline</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
<span class="n">fieldnames</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;id&#39;</span><span class="p">,</span> <span class="s1">&#39;name&#39;</span><span class="p">,</span> <span class="s1">&#39;code&#39;</span><span class="p">,</span> <span class="s1">&#39;date&#39;</span><span class="p">,</span> <span class="s1">&#39;title&#39;</span><span class="p">,</span> <span class="s1">&#39;pdf_link&#39;</span><span class="p">,</span> <span class="s1">&#39;size&#39;</span><span class="p">]</span>
<span class="n">writer</span> <span class="o">=</span> <span class="n">csv</span><span class="o">.</span><span class="n">DictWriter</span><span class="p">(</span><span class="n">csvf</span><span class="p">,</span> <span class="n">fieldnames</span><span class="o">=</span><span class="n">fieldnames</span><span class="p">)</span>
<span class="n">writer</span><span class="o">.</span><span class="n">writeheader</span><span class="p">()</span>

<span class="n">test_data</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;pdf_link&#39;</span><span class="p">:</span> <span class="s1">&#39;测试pdf文件链接&#39;</span><span class="p">,</span>
             <span class="s1">&#39;code&#39;</span><span class="p">:</span> <span class="s1">&#39;测试股票代码&#39;</span><span class="p">,</span>
             <span class="s1">&#39;name&#39;</span><span class="p">:</span> <span class="s1">&#39;股票名称&#39;</span><span class="p">,</span>
             <span class="s1">&#39;title&#39;</span><span class="p">:</span> <span class="s1">&#39;报告名称&#39;</span><span class="p">,</span>
             <span class="s1">&#39;date&#39;</span><span class="p">:</span> <span class="s1">&#39;发布日期&#39;</span><span class="p">,</span>
             <span class="s1">&#39;size&#39;</span><span class="p">:</span> <span class="s1">&#39;pdf文件字节大小&#39;</span><span class="p">,</span>
             <span class="s1">&#39;id&#39;</span><span class="p">:</span> <span class="s1">&#39;数据id&#39;</span><span class="p">}</span>
             
<span class="n">writer</span><span class="o">.</span><span class="n">writerow</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span>

<span class="c1">#关闭csv</span>
<span class="n">csvf</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</code></pre></div><p><br><br></p>
<h2 id="二爬虫代码完整">二、爬虫代码(完整)</h2>
<p>当你看到本文时，该完整代码很有可能会随着网站变化而失效。不要悲伤难过， 按照爬虫思路自己diy即可。如果没有爬虫基础，学习 <a href="https://www.bilibili.com/video/BV1AE411r7ph">大邓的B站爬虫视频</a> ，</p>
<p><img loading="lazy" src="img/%e5%a4%a7%e9%82%93%e7%88%ac%e8%99%ab.jpg" alt=""  />
</p>
<p>自己懂爬虫原理diy代码，比改别人的代码来的更容易。将前面的准备工作组织起来, 就形成了下面的完整代码</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">requests</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">csv</span>

<span class="n">keyword</span> <span class="o">=</span> <span class="s2">&#34;社会责任报告&#34;</span>

<span class="c1">#定义csv字段，存储PDF链接信息至data/csr_links.csv</span>
<span class="n">csvf</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;data/csr_links.csv&#39;</span><span class="p">,</span> <span class="s1">&#39;a+&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">,</span> <span class="n">newline</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
<span class="n">fieldnames</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;id&#39;</span><span class="p">,</span> <span class="s1">&#39;name&#39;</span><span class="p">,</span> <span class="s1">&#39;code&#39;</span><span class="p">,</span> <span class="s1">&#39;date&#39;</span><span class="p">,</span> <span class="s1">&#39;title&#39;</span><span class="p">,</span> <span class="s1">&#39;pdf_link&#39;</span><span class="p">,</span> <span class="s1">&#39;size&#39;</span><span class="p">]</span>
<span class="n">writer</span> <span class="o">=</span> <span class="n">csv</span><span class="o">.</span><span class="n">DictWriter</span><span class="p">(</span><span class="n">csvf</span><span class="p">,</span> <span class="n">fieldnames</span><span class="o">=</span><span class="n">fieldnames</span><span class="p">)</span>
<span class="n">writer</span><span class="o">.</span><span class="n">writeheader</span><span class="p">()</span>

<span class="c1">#伪装头</span>
<span class="n">headers</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;Accept&#39;</span><span class="p">:</span> <span class="s1">&#39;application/json, text/javascript, */*; q=0.01&#39;</span><span class="p">,</span>
           <span class="s1">&#39;Accept-Encoding&#39;</span><span class="p">:</span> <span class="s1">&#39;gzip, deflate&#39;</span><span class="p">,</span>
           <span class="s1">&#39;Accept-Language&#39;</span><span class="p">:</span> <span class="s1">&#39;zh-CN,zh;q=0.9,en;q=0.8&#39;</span><span class="p">,</span>
           <span class="s1">&#39;Content-Type&#39;</span><span class="p">:</span> <span class="s1">&#39;application/json&#39;</span><span class="p">,</span>
           <span class="s1">&#39;Host&#39;</span><span class="p">:</span> <span class="s1">&#39;www.szse.cn&#39;</span><span class="p">,</span>
           <span class="s1">&#39;Origin&#39;</span><span class="p">:</span> <span class="s1">&#39;http://www.szse.cn&#39;</span><span class="p">,</span>
           <span class="s1">&#39;Proxy-Connection&#39;</span><span class="p">:</span> <span class="s1">&#39;close&#39;</span><span class="p">,</span>
           <span class="s1">&#39;Referer&#39;</span><span class="p">:</span> <span class="s1">&#39;http://www.szse.cn/disclosure/listed/fixed/index.html&#39;</span><span class="p">,</span>
           <span class="s1">&#39;User-Agent&#39;</span><span class="p">:</span> <span class="s1">&#39;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.132 Safari/537.36&#39;</span><span class="p">,</span>
           <span class="s1">&#39;X-Request-Type&#39;</span><span class="p">:</span> <span class="s1">&#39;ajax&#39;</span><span class="p">,</span>
           <span class="s1">&#39;X-Requested-With&#39;</span><span class="p">:</span> <span class="s1">&#39;XMLHttpRequest&#39;</span><span class="p">}</span>

<span class="n">page</span> <span class="o">=</span> <span class="mi">1</span>

<span class="c1">#post方法参数</span>
<span class="n">payload</span> <span class="o">=</span><span class="p">{</span><span class="s2">&#34;seDate&#34;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&#34;&#34;</span><span class="p">,</span><span class="s2">&#34;&#34;</span><span class="p">],</span>
           <span class="s2">&#34;searchKey&#34;</span><span class="p">:</span> <span class="p">[</span><span class="n">keyword</span><span class="p">],</span>
           <span class="s2">&#34;channelCode&#34;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&#34;listedNotice_disc&#34;</span><span class="p">],</span>
           <span class="s2">&#34;pageSize&#34;</span><span class="p">:</span> <span class="mi">50</span><span class="p">,</span>
           <span class="s2">&#34;pageNum&#34;</span><span class="p">:</span> <span class="n">page</span><span class="p">}</span>

<span class="c1">#发起请求</span>
<span class="n">url</span> <span class="o">=</span> <span class="s1">&#39;http://www.szse.cn/api/disc/announcement/annList?random=</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">())</span>
<span class="n">resp</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">post</span><span class="p">(</span><span class="n">url</span><span class="p">,</span>
                     <span class="n">headers</span><span class="o">=</span><span class="n">headers</span><span class="p">,</span>
                     <span class="n">data</span><span class="o">=</span><span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">payload</span><span class="p">))</span>

<span class="c1">#当data关键词有对应的非空列表，循环一直进行。</span>
<span class="k">while</span> <span class="n">resp</span><span class="o">.</span><span class="n">json</span><span class="p">()[</span><span class="s1">&#39;data&#39;</span><span class="p">]:</span>
    <span class="n">payload</span><span class="p">[</span><span class="s1">&#39;pageNum&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">page</span>
    <span class="n">resp</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">post</span><span class="p">(</span><span class="n">url</span><span class="p">,</span>
                     <span class="n">headers</span><span class="o">=</span><span class="n">headers</span><span class="p">,</span>
                     <span class="n">data</span><span class="o">=</span><span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">payload</span><span class="p">))</span>
    
    <span class="n">csrs</span> <span class="o">=</span> <span class="n">resp</span><span class="o">.</span><span class="n">json</span><span class="p">()[</span><span class="s1">&#39;data&#39;</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">csr</span> <span class="ow">in</span> <span class="n">csrs</span><span class="p">:</span>
        <span class="c1">#以字典样式写入csv</span>
        <span class="n">data</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;pdf_link&#39;</span><span class="p">:</span> <span class="s1">&#39;http://disc.static.szse.cn/download&#39;</span><span class="o">+</span> <span class="n">csr</span><span class="p">[</span><span class="s1">&#39;attachPath&#39;</span><span class="p">],</span>
                <span class="s1">&#39;code&#39;</span><span class="p">:</span> <span class="nb">str</span><span class="p">(</span><span class="n">csr</span><span class="p">[</span><span class="s1">&#39;secCode&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">]),</span>
                <span class="s1">&#39;name&#39;</span><span class="p">:</span> <span class="n">csr</span><span class="p">[</span><span class="s1">&#39;secName&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span>
                <span class="s1">&#39;title&#39;</span><span class="p">:</span> <span class="n">csr</span><span class="p">[</span><span class="s1">&#39;title&#39;</span><span class="p">],</span>
                <span class="s1">&#39;date&#39;</span><span class="p">:</span> <span class="n">csr</span><span class="p">[</span><span class="s1">&#39;publishTime&#39;</span><span class="p">],</span>
                <span class="s1">&#39;size&#39;</span><span class="p">:</span> <span class="n">csr</span><span class="p">[</span><span class="s1">&#39;attachSize&#39;</span><span class="p">],</span>
                <span class="s1">&#39;id&#39;</span><span class="p">:</span> <span class="n">csr</span><span class="p">[</span><span class="s1">&#39;id&#39;</span><span class="p">]}</span>
        <span class="n">writer</span><span class="o">.</span><span class="n">writerow</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

    <span class="n">page</span> <span class="o">=</span> <span class="n">page</span> <span class="o">+</span> <span class="mi">1</span>
    
<span class="c1">#关闭csv</span>
<span class="n">csvf</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</code></pre></div><p><br><br></p>
<h2 id="三查看csv">三、查看csv</h2>
<p>使用pandas读取 <code>data/csr_links.csv</code>,</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="c1">#股票代码设置为字符串类型，防止000876	识别为876</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;csr_links.csv&#39;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;code&#39;</span><span class="p">:</span> <span class="nb">str</span><span class="p">})</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/04-df.png" alt=""  />
</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">4392
</code></pre></div><p>一共有4392条 「企业社会责任」 的报告数据。</p>
<p><br><br></p>
<h2 id="四批量下载">四、批量下载</h2>
<p>下载就简单多了， 直接使用定义好的爬虫代码。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">requests</span>

<span class="k">def</span> <span class="nf">download</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">file</span><span class="p">):</span>
    <span class="s2">&#34;&#34;&#34;
</span><span class="s2">    下载多媒体及文件
</span><span class="s2">    url： 多媒体文件链接（结尾有文件格式名）
</span><span class="s2">    file: 存储文件的路径（结尾有文件格式名）
</span><span class="s2">    &#34;&#34;&#34;</span>
    <span class="n">resp</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
    <span class="c1">#获取到二进制数据</span>
    <span class="n">binarydata</span> <span class="o">=</span> <span class="n">resp</span><span class="o">.</span><span class="n">content</span>
    <span class="c1">#以二进制形式将数据流存入fname中</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">file</span><span class="p">,</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">binarydata</span><span class="p">)</span> 
        

<span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>

<span class="k">for</span> <span class="n">link</span><span class="p">,</span> <span class="n">title</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;pdf_link&#39;</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;title&#39;</span><span class="p">]):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">title</span><span class="p">)</span>
    <span class="n">download</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="n">link</span><span class="p">,</span> <span class="n">file</span><span class="o">=</span><span class="s1">&#39;data/</span><span class="si">{}</span><span class="s1">.pdf&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">title</span><span class="p">))</span>
    <span class="n">i</span> <span class="o">=</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">0 山河药辅：山河药辅2021年度社会责任报告
1 新 希 望：2021年企业社会责任报告（英文版）
2 天原股份：宜宾天原集团股份有限公司社会责任报告
3 五 粮 液：2021年度社会责任报告（英文版）
4 中兵红箭：2021年度社会责任报告	
......
......
148 苏宁环球：2021年社会责任报告
149 蓝色光标：2021年度企业社会责任报告
150 开尔新材：2021年度社会责任报告
151 中顺洁柔：2021年社会责任报告
......
......

4391 闽东电力：2006年度社会责任报告
4392  阳光发展：2006年度社会责任报告书
</code></pre></div><p>采集过程中，被封锁在所难免，所以记得每次停止采集的位置，在csv中删除该位置之前的数据。然后重新运行代码即可。</p>
<p><br><br></p>
<h2 id="五相关文献">五、相关文献</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">[1]解学梅, &amp; 朱琪玮. (2021). 企业绿色创新实践如何破解 “和谐共生” 难题?. 管理世界, 37(1), 128-149.
[2]谢红军 &amp; 吕雪.(2022).负责任的国际投资：ESG与中国OFDI. 经济研究(03),83-99.
[3]Schaefer, S. D., Terlutter, R., &amp; Diehl, S. (2019). Is my company really doing good? Factors influencing employees&#39; evaluation of the authenticity of their company&#39;s corporate social responsibility engagement. Journal of business research, 101, 128-143.
</code></pre></div><p><br><br></p>
<h2 id="六其他广告">六、其他(广告)</h2>
<ul>
<li><a href="https://hidadeng.github.io/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://hidadeng.github.io/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://hidadeng.github.io/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>中文金融领域知识图谱的数据集ChainKnowledgeGraph</title>
      <link>https://hidadeng.github.io/blog/chain_knowledge_graph/</link>
      <pubDate>Mon, 06 Dec 2021 16:42:10 +0600</pubDate>
      
      <guid>/blog/chain_knowledge_graph/</guid>
      <description>本文围绕金融领域，推出面向上市公司的产业链图谱。  </description>
      <content:encoded><![CDATA[<p>领域知识图谱的数据集，当前还比较缺失，而作为构建难度最大的产业链图谱领域更为空白。产业链作为产业经济学中的一个概念，是各个产业部门之间基于一定的技术经济关联，并依据特定的逻辑关系和时空布局关系客观形成的链条式关联关系形态。从本质上来说，产业链的本质是用于描述一个具有某种内在联系的企业群结构，产业链中大量存在着上下游关系和相互价值的交换，上游环节向下游环节输送产品或服务，下游环节向上游环节反馈信息。</p>
<p>作者已经先后发布两大领域的实体图谱数据： <br>
1、情报领域【武器装备知识图谱】，地址：https://github.com/liuhuanyong/QAonMilitaryKG<br>
2、医疗领域【医疗知识图谱】，地址： <a href="https://github.com/liuhuanyong/QASystemOnMedicalKG">https://github.com/liuhuanyong/QASystemOnMedicalKG</a></p>
<p>当前，为了进一步推动产业发展，本文围绕金融领域，推出面向上市公司的产业链图谱。</p>
<p>项目地址：</p>

<figure >
    
        <img src="img/1.png" width="800" />
    
    
</figure>

<br>
<h2 id="一项目构成">一、项目构成</h2>
<p>产业链知识图谱包括A股上市公司、行业和产品共3类实体，包括上市公司所属行业关系、行业上级关系、产品上游原材料关系、产品下游产品关系、公司主营产品、产品小类共6大类。</p>
<p>通过数据处理、抽取，最终建成图谱规模数十万，其中包括上市公司4,654家，行业511个，产品95,559条、上游材料56,824条，上级行业480条，下游产品390条，产品小类52,937条，所属行业3,946条。  <br>

<figure >
    
        <img src="img/2.png" width="800" />
    
    
</figure>
</p>
<br>
<h2 id="二项目构建">二、项目构建</h2>
<p>1、实体构建<br>
1）上市公司<br>
目前上市公司已经达到四千多家，是我国重要的公司代表与行业标杆，本图谱选取上市公司作为基础实体之一。通过交易所公开信息中，可以得到上市公司代码、全称、简称、注册地址、挂牌等多个信息。</p>

<figure >
    
        <img src="img/3.png" width="800" />
    
    
</figure>

<p>2）行业分类<br>
行业是产业链图谱中另一个核心内容，也是承载产业、公司及产品的一个媒介，通过这一领携作用，可以生产出大量的行业指数、热点行业等指标。<br>
目前关于行业，已经陆续出现多个行业规范，代表性的有申万三级行业分类、国民经济行业分类等。中国上市公司所属行业的分类准则是依据营业收入等财务数据为主要分类标准和依据，所采用财务数据为经过会计事务所审计并已公开披露的合并报表数据。<br>
2021年6月，申万发布了2021版的行业分类规范，将1级行业从28个调整至31个、2级行业从104个调整至134个、3级行业从227个调整至346个，新增1级行业美容护理等，新增2级行业，并将上市公司进行了归属。本图谱选用申万行业作为基础数据。<br>

<figure >
    
        <img src="img/4.png" width="800" />
    
    
</figure>
</p>
<p>3）业务产品 <br>
业务产品主要指公司主营范围、经营的产品，用于对一个公司的定位。可以从公司的经营范围、年报等文本中进行提取得到。<br>

<figure >
    
        <img src="img/5.png" width="800" />
    
    
</figure>
</p>
<p>2、关系构建 <br>
1）公司所属行业 <br>
通过公开的上市公司行业分类表，可以得到上市公司所对应的行业分类数据。 <br>

<figure >
    
        <img src="img/6.png" width="800" />
    
    
</figure>
</p>
<p>2）行业上级关系 <br>
通过公开的行业三级分类情况，可以通过组合的形式得到行业之间的上级关系数据。 <br>

<figure >
    
        <img src="img/7.png" width="800" />
    
    
</figure>
</p>
<p>3）公司主营产品关系<br>
上市公司的经营产品数据可以从两个方面来获得，一个是从公司简介中的经营范围中结合制定的规则进行提取，另一个是从公司每年发布的半年报、年报中进行提取。这些报告中会有按经营业务、经营产品、经营地域等几个角度对公司的营收占比进行统计，也可以通过制定规则的方式进行提取。第二种方法中，由于已经有统计数据，所以我们可以根据占比数据大小，对主营产品这一关系进行赋值。<br>

<figure >
    
        <img src="img/8.png" width="800" />
    
    
</figure>
</p>
<p>4）产品之间的上下游关系<br>
产品之间的上下游关系，是展示产品之间传导逻辑关系的一个重要方法，包括上游原材料以及下游产品两大类。我们可以多种来获取：<br>
一种是基于规则模式匹配的方式进行抽取，如抽取上游原材料这一关系可以由诸如&quot;a是b的原料/原材料/主要构件/重要原材料/  上游原料&quot;的模式进行抽取&quot;，而下游产品，则同理可以通过&quot;A是B的下游成品/产品&quot;等模式进行提取。<br>
另一种是基于序列标注的提取。还有一种是基于现有结构化知识图谱的提取，例如已经结构化好的百科知识三元组，可以通过设定谓词及其扩展进行过滤。<br>

<figure >
    
        <img src="img/9.png" width="800" />
    
    
</figure>
</p>
<p>5）产品之间的小类关系<br>
对于一个产品而言，其是有大小层级分类的，在缺少大类产品名称的时候，可以通过计算小类产品来得到相应指标。与产品之间的上下游数据类似，可以通过启发式规则的方式进行提取，如“A是一种B”，也可以通过字符之间的组成成分进行匹配生成，如“螺纹钢”是“精细螺纹钢”的一个大类。<br>

<figure >
    
        <img src="img/10.png" width="800" />
    
    
</figure>
</p>
<br>
<h2 id="三项目运行">三、项目运行</h2>
<p>1、data文件夹下包括了本项目的数据信息：<br>
1)company.json:公司实体数据<br>
2)industry.json:行业实体数据 <br>
3)product.json:产品实体数据 <br>
4)company_industry.json:公司-行业关系数据 <br>
5)industry_industry.json:行业-行业关系数据 <br>
6)product_product.json:产品-产品数据 <br>
7)company_product.json:公司-产品数据</p>
<p>2、项目运行:<br>
python build_graph.py</p>
<br>
<h2 id="四项目总结">四、项目总结</h2>
<p>产业链图谱是众多领域知识图谱中较为棘手的一种，本项目通过现有的数据，借助数据处理、结构化提取方式，设计、构建并形成了一个节点100,718，关系边169,153的十万级别产业链图谱。就产业链图谱的构建而言，我们需要至少从以上三个方面加以考虑：</p>
<ul>
<li>其一，产业链的主观性与标准性。产业链的主观性较强，不同的人对产业链的构建、产业链节点、关系的类型，产业链的颗粒度问题都有不同的理解。不同的设定会直接导致不同的应用结果。正如我们所看到的，目前存在不同的行业标准，不同的网站、机构也将公司归为不同的行业。</li>
<li>其二，产业链的动态性和全面性。产业链需要具备足够大的复用性和扩展性，几千家上市公司实际上是冰山一角。国内有几千万家公司，而且不断会有新增，如何将新增的公司融入到这个额产业链中，也是一个很大挑战。此外，产业本身是动态的， 随着行业的发展，不断会有新的行业出现。如何捕捉这种行业的变化，使得整个图谱变得与时俱进，也是需要考量的点。</li>
<li>其三，产业链的定量推理特性。单纯定性的构建产业链知识图谱，如果没有足够的参数，仅有知识表达是无法进行推理的，推理要求知识图谱Schema具备节点间推理传导的必备参数，以及影响推理传导的其他关键参数。对于必备参数来说，从公司到产品必须有主营占比、市场占比、产能占比等数据，从产品到产品必须有成本占比和消耗占比等数据。</li>
</ul>
<br>
<h2 id="参考数据来源">参考数据来源</h2>
<p>1、申万行业：http://www.swsindex.com<br>
2、深交所: <a href="http://www.szse.cn">http://www.szse.cn</a><br>
3、上交所: <a href="http://www.sse.com.cn">http://www.sse.com.cn</a></p>
<p>If any question about the project or me ,see <a href="https://liuhuanyong.github.io/">https://liuhuanyong.github.io/</a></p>
<p>如有自然语言处理、知识图谱、事理图谱、社会计算、语言资源建设等问题或合作，可联系我： <br>
1、我的github项目介绍：https://liuhuanyong.github.io<br>
2、我的csdn博客：https://blog.csdn.net/lhy2014<br>
3、about me:刘焕勇，lhy_<a href="mailto:in_blcu@126.com">in_blcu@126.com</a>.      <br>
4、我的技术公众号:老刘说NLP</p>
<br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://hidadeng.github.io/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://hidadeng.github.io/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://hidadeng.github.io/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>中文语义常用词典ChineseSemanticKB</title>
      <link>https://hidadeng.github.io/blog/chinese_semantic_lb/</link>
      <pubDate>Mon, 06 Dec 2021 16:40:10 +0600</pubDate>
      
      <guid>/blog/chinese_semantic_lb/</guid>
      <description>面向中文处理的12类、百万规模的语义常用词典，包括34万抽象语义库、34万反义语义库、43万同义语义库等，可支持句子扩展、转写、事件抽象与泛化等多种应用场景。</description>
      <content:encoded><![CDATA[<h2 id="chinesesemantickb">ChineseSemanticKB</h2>
<p>ChineseSemanticKB,chinese semantic knowledge base, 面向中文处理的12类、百万规模的语义常用词典，包括34万抽象语义库、34万反义语义库、43万同义语义库等，可支持句子扩展、转写、事件抽象与泛化等多种应用场景。</p>
<br>
<h2 id="项目介绍">项目介绍</h2>
<p>语义知识库是自然语言处理中十分重要的一个基础资源，与学术界追求算法模型不同，工业界的自然语言处理对于底层的词汇知识库、语义知识库等多种资源依赖度很高，具体体现在：<br>
1、具有落地场景的自然语言处理任务都是业务高度相关，一个业务需求刚进去，需要解决的是业务的词汇问题，无基础词库，无项目冷启动；<br>
2、规则和正则启动下的工业级应用，规则的扩展、泛化都需要底层的词汇网络做支撑；<br>
3、目前包括搜索、问答、舆情监控、事件分析等应用，与标签体系的运作关系密切，而这与先验的底层词汇库依赖性很强；<br>
4、自然语言场景越来越关注推理层面，即所谓的“认知”层面，认知背后的各种逻辑关系库，是驱动这一决策的根本途径；<br>
5、当前，面向中文开源词库的工作存在少量、分散的状态，无论从规模，还是质量，都需要进一步聚合；<br>
因此，我从过往的开源工作中进一步抽离和整理，形成了中文处理的12类、百万规模的语义常用词典，包括34万抽象语义库、34万反义语义库、43万同义语义库等，用于相关下游任务。</p>
<p>项目放于dict当中，可直接下载，不建议二次建库共享，尊重开源。</p>
<br>
<h2 id="词库的类别">词库的类别</h2>
<table>
<thead>
<tr>
<th style="text-align:left">词库类型</th>
<th style="text-align:center">词库规模</th>
<th style="text-align:center">词库举例</th>
<th style="text-align:center">词库应用</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">抽象关系库</td>
<td style="text-align:center">346,048</td>
<td style="text-align:center">座椅,抽象,家具</td>
<td style="text-align:center">事件抽象与泛化，人民币贬值到货币贬值，再到美元贬值，可支持查询扩展、推荐等任务</td>
</tr>
<tr>
<td style="text-align:left">反义关系库</td>
<td style="text-align:center">34,380</td>
<td style="text-align:center">开心@苦恼</td>
<td style="text-align:center">可用于句子改写，开心改苦恼，支持数据增强，句子生成</td>
</tr>
<tr>
<td style="text-align:left">同义关系库</td>
<td style="text-align:center">424,826</td>
<td style="text-align:center">开心@高兴</td>
<td style="text-align:center">可用于查询扩展、数据增强，也可结合抽象关系库完成推荐等任务</td>
</tr>
<tr>
<td style="text-align:left">简称关系库</td>
<td style="text-align:center">136,081</td>
<td style="text-align:center">北京大学@北大</td>
<td style="text-align:center">可用于句子标准化、句子改写、实体消歧等任务</td>
</tr>
<tr>
<td style="text-align:left">程度副词</td>
<td style="text-align:center">222</td>
<td style="text-align:center">极其,2.0</td>
<td style="text-align:center">可用于情感强度计算，带情感色彩的句子生成</td>
</tr>
<tr>
<td style="text-align:left">否定词</td>
<td style="text-align:center">586</td>
<td style="text-align:center">不,无,没有</td>
<td style="text-align:center">可用于情感计算等任务</td>
</tr>
<tr>
<td style="text-align:left">节日时间词</td>
<td style="text-align:center">54</td>
<td style="text-align:center">春节、五四节</td>
<td style="text-align:center">可用于时间词识别等任务</td>
</tr>
<tr>
<td style="text-align:left">量比词</td>
<td style="text-align:center">7</td>
<td style="text-align:center">占比、环比、同比</td>
<td style="text-align:center">可用于金融领域指标类数据提取任务</td>
</tr>
<tr>
<td style="text-align:left">数量介词</td>
<td style="text-align:center">24</td>
<td style="text-align:center">大约、达到、超过</td>
<td style="text-align:center">可用于金融事件抽象或主干化的搭配词处理任务</td>
</tr>
<tr>
<td style="text-align:left">停用词</td>
<td style="text-align:center">3,861</td>
<td style="text-align:center">？、的、着</td>
<td style="text-align:center">常规的文本特征提取等任务</td>
</tr>
<tr>
<td style="text-align:left">修饰副词</td>
<td style="text-align:center">222</td>
<td style="text-align:center">所、有所</td>
<td style="text-align:center">可结合程度副词完成情感强度计算等任务</td>
</tr>
<tr>
<td style="text-align:left">情态词</td>
<td style="text-align:center">77</td>
<td style="text-align:center">肯定、应该、大概</td>
<td style="text-align:center">可用于句子主观性计算、舆情与可信度计算</td>
</tr>
</tbody>
</table>
<br>
<h2 id="总结">总结</h2>
<p>1、本项目开源了一个目前可用于事件处理以及工业舆情的12类语义词库，总规模数目一百余万；<br>
2、本项目开源的34万抽象语义库、34万反义语义库、43万同义语义库，在作者的实际工作中【事件处理、事理抽取、事件推理】等有重要用途;<br>
3、中文常用语义常用词典，均来源于公开文本+人工整理+机器抽取形成，其中若有质量不高之处，可积极批评指正;<br>
4、中文开源事业还是要坚持做下去，尽可能地缩短自然语言处理学术界和工业界之间的鸿沟。</p>
<blockquote>
<p>If any question about the project or me ,see <a href="https://liuhuanyong.github.io/">https://liuhuanyong.github.io/</a>.<br>
如有自然语言处理、知识图谱、事理图谱、社会计算、语言资源建设等问题或合作，可联系我：     <br>
1、我的github项目介绍：https://liuhuanyong.github.io  <br>
2、我的csdn技术博客：https://blog.csdn.net/lhy2014 <br>
3、我的联系方式: 刘焕勇，中国科学院软件研究所，lhy_<a href="mailto:in_blcu@126.com">in_blcu@126.com</a>. <br>
4、我的共享知识库项目：刘焕勇，数据地平线，http://www.openkg.cn/organization/datahorizon.<br>
5、我的工业项目：刘焕勇，数据地平线，大规模实时事理学习系统：https://xueji.datahorizon.cn.  <br>
6、我的工业项目：刘焕勇，数据地平线，面向事件和语义的自然语言处理工具箱：https://nlp.datahorizon.cn</p>
</blockquote>
<br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://hidadeng.github.io/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://hidadeng.github.io/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://hidadeng.github.io/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>70G上交所年报数据集</title>
      <link>https://hidadeng.github.io/blog/70g_china_market_anunal_report_datasets/</link>
      <pubDate>Mon, 22 Nov 2021 20:40:10 +0600</pubDate>
      
      <guid>/blog/70g_china_market_anunal_report_datasets/</guid>
      <description>Python网络爬虫与文本分析， 70g会计年报pdf数据集免费下载</description>
      <content:encoded><![CDATA[<h2 id="70g年报pdf数据集">70G年报pdf数据集</h2>
<p><img loading="lazy" src="img/1.gif" alt=""  />
</p>
<h2 id="数据下载说明">数据下载说明</h2>
<p>所有pdf均来自上海证券交易所官网，使用shreport库进行的下载。</p>
<p><img loading="lazy" src="img/2.png" alt=""  />
</p>
<h2 id="报告信息汇总文件">报告信息汇总文件</h2>
<h4 id="heading"></h4>
<p><img loading="lazy" src="img/3.gif" alt=""  />
</p>
<p>summary.xlsx内字段</p>
<ul>
<li>company 上市公司企业名</li>
<li>code 股票代码</li>
<li>type 报告类型</li>
<li>year 报告年份</li>
<li>date 报告发布日期</li>
<li>pdf 报告pdf文件下载链接</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">import pandas as pd
from pathlib import Path


#报告汇总文件summary.xlsx
df = pd.read_excel(&#39;summary.xlsx&#39;)
df.head()
</code></pre></div><p><img loading="lazy" src="img/4.png" alt=""  />
</p>
<p>一共有报告71126份</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">len(df)
71149
</code></pre></div><p>一共有上市公司1486家</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">len(df[&#39;company&#39;].unique())
1486
</code></pre></div><h2 id="summary文件夹">summary文件夹</h2>
<p>summary文件夹内是每家公司的报告披露情况</p>
<p><img loading="lazy" src="img/5.gif" alt=""  />
</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">df1 = pd.read_excel(&#39;summary/600000.xlsx&#39;)
df1.head()
</code></pre></div><p><img loading="lazy" src="img/6.png" alt=""  />
</p>
<p>浦发银行一共有75份定期报告</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">len(df1)
75
</code></pre></div><h2 id="reports文件夹">reports文件夹</h2>
<p>reports文件夹存放着以各各公司股票代码命名的文件夹</p>
<p>文件夹内是该公司所有定期报告</p>
<p><img loading="lazy" src="img/7.gif" alt=""  />
</p>
<h2 id="读取pdf报告">读取pdf报告</h2>
<p>可使用pdfdocx库读取pdf,</p>
<p>pdfdocx文档链接 <a href="https://github.com/thunderhit/pdfdocx">https://github.com/thunderhit/pdfdocx</a></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">from pdfdocx import read_pdf

p_text = read_pdf(&#39;reports/600000/600000_2012_1.pdf&#39;)
p_text
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">上海浦东发展银行股份有限公司 \n\n2012 年第一季度报告 \n\n \n\n \n\n§1 重要提示 \n\n1.1 公司董事会、监事会及其董事、监事、高级管理人员保证本报告所载资料不存在任何虚假记载、\n\n误导性陈述或者重大遗漏，并对其内容的真实性、准确性和完整性承担个别及连带责任。\n\n1.2 公司于 2012 年 4 月 26 日以通讯表决的方式召开第四届董事会第二十六次会议审议通过本报告，\n\n1.4 公司董事长、行长吉晓辉、财务总监刘信义及财务机构负责人傅能声明：保证本季度报告中财务\n\n公司全体董事出席董事会会议并行使表决权。\n\n1.3 公司第一季度财务报告未经审计。\n\n报告的真实、完整。\n\n \n§2 公司基本情况 \n\n2.1 主要会计数据及财务指标 \n\n本报告期末 \n\n上年度期末 \n\n币种:人民币 \n\n本报告期末比上年\n度期末增减(%) \n\n总资产(千元) \n\n归属于上市公司股东的所有者权益(千元) \n\n2,804,646,567\n\n157,055,724\n\n2,684,693,689 \n148,891,235 \n\n归属于上市公司股东的每股净资产(元) \n\n8.420\n\n7.982 \n\n4.47 \n5.48 \n5.49 \n\n经营活动产生的现金流量净额(千元) \n\n每股经营活动产生的现金流\n\n \n\n \n \n母公司现金流量表 \n \n2012 年 1—3 月 \n \n编制单位: 上海浦东发展银行股份有限公司....
</code></pre></div><h2 id="70g数据下载">70G数据下载</h2>
<p>链接:https://pan.baidu.com/s/14PI6MbxunFQ3fZOfR33zkw 密码:osoi</p>
<br>
<br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://hidadeng.github.io/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://hidadeng.github.io/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://hidadeng.github.io/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
  </channel>
</rss>
