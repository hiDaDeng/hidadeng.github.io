<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>数据集 on 大邓和他的PYTHON</title>
    <link>/tags/%E6%95%B0%E6%8D%AE%E9%9B%86/</link>
    <description>Recent content in 数据集 on 大邓和他的PYTHON</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh</language>
    <lastBuildDate>Wed, 05 Apr 2023 00:00:00 +0000</lastBuildDate><atom:link href="/tags/%E6%95%B0%E6%8D%AE%E9%9B%86/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>可视化 | 99-21年地方政府报告环保、科技、三农等关键词变化趋势</title>
      <link>https://textdata.cn/blog/2023-03-19-visualize-8-province-gov-anual-report/</link>
      <pubDate>Sun, 19 Mar 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-03-19-visualize-8-province-gov-anual-report/</guid>
      <description>使用31省市的1999-2021年的省级政府工作报告，绘制出的不同类别关键词的趋势图。直接上最终效果效果图</description>
      <content:encoded><![CDATA[<p>使用31省市的1999-2021年的省级政府工作报告，绘制出的不同类别关键词的趋势图。直接上最终效果效果图</p>
<p><img loading="lazy" src="img/%e5%9b%be1.png" alt=""  />
</p>
<p><img loading="lazy" src="img/%e5%9b%be2.png" alt=""  />
</p>
<br>
<h2 id="一准备数据">一、准备数据</h2>
<p>31M的数据，含file和text两个字段， <a href="gov_reports.csv"><strong>点击下载gov_reports.csv</strong></a></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-Python" data-lang="Python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;gov_reports.csv&#39;</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/df1.png" alt=""  />
</p>
<br>
<p>用正则表达式整理出省份和年份的字段</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df</span><span class="p">[</span><span class="s1">&#39;year&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;file&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">f</span><span class="p">:</span> <span class="n">re</span><span class="o">.</span><span class="n">findall</span><span class="p">(</span><span class="s1">&#39;\d</span><span class="si">{4}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">f</span><span class="p">)[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;prov&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;file&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">f</span><span class="p">:</span> <span class="n">re</span><span class="o">.</span><span class="n">findall</span><span class="p">(</span><span class="s1">&#39;/(.*?)/&#39;</span><span class="p">,</span> <span class="n">f</span><span class="p">)[</span><span class="mi">0</span><span class="p">])</span> 
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/df2.png" alt=""  />
</p>
<p>构建透视表，行索引名为省份，列名为年份， 单元格内填充工作报告。代码比较复杂， 其实我也似懂非懂，死记硬背吧。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">table_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">pivot_table</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> 
                       <span class="n">columns</span><span class="o">=</span><span class="s1">&#39;year&#39;</span><span class="p">,</span>  <span class="c1">#列-年份</span>
                       <span class="n">index</span><span class="o">=</span><span class="s1">&#39;prov&#39;</span><span class="p">,</span>    <span class="c1">#行-省份</span>
                       <span class="n">values</span><span class="o">=</span><span class="s1">&#39;text&#39;</span><span class="p">,</span>   <span class="c1">#单元格-文本</span>
                       <span class="n">aggfunc</span><span class="o">=</span><span class="k">lambda</span> <span class="n">cs</span><span class="p">:</span> <span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">cs</span><span class="p">))</span> <span class="c1">#让单元格填充文本</span>

<span class="n">table_df</span>
</code></pre></div><p><img loading="lazy" src="img/df3.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="二构建可视化函数">二、构建可视化函数</h2>
<p>本部分代码实现的功能</p>
<ol>
<li>构建关键词词频统计函数keywords_frequency
<ul>
<li>输入的是文本和关键词列表</li>
<li>返回的是一个数字</li>
</ul>
</li>
<li>对table_df中的每个单元格使用keywords_frequency函数
<ul>
<li>applymap从水平和垂直方向同时应用keywords_frequency</li>
<li>调用pyecharts可视化</li>
</ul>
</li>
</ol>
<p>代码比较费劲，不太方便讲，直接给完整代码</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#pip install pyecharts==2.0.1</span>
<span class="kn">from</span> <span class="nn">pyecharts</span> <span class="kn">import</span> <span class="n">options</span> <span class="k">as</span> <span class="n">opts</span>
<span class="kn">from</span> <span class="nn">pyecharts.charts</span> <span class="kn">import</span> <span class="n">Line</span>
<span class="kn">import</span> <span class="nn">jieba</span>

<span class="k">def</span> <span class="nf">keywords_frequency</span><span class="p">(</span><span class="n">cell</span><span class="p">,</span> <span class="n">keywords</span><span class="p">):</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">wcount</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">words</span> <span class="o">=</span> <span class="n">jieba</span><span class="o">.</span><span class="n">lcut</span><span class="p">(</span><span class="n">cell</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">keyw</span> <span class="ow">in</span> <span class="n">keywords</span><span class="p">:</span>
            <span class="n">wcount</span> <span class="o">+=</span> <span class="n">words</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="n">keyw</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">wcount</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">words</span><span class="p">)</span>
    <span class="k">except</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">0</span>
    
    

<span class="k">def</span> <span class="nf">plot_trends</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">keywords</span><span class="p">,</span> <span class="n">title</span><span class="p">):</span>
    <span class="n">df2</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">applymap</span><span class="p">(</span><span class="k">lambda</span> <span class="n">cell</span><span class="p">:</span> <span class="n">keywords_frequency</span><span class="p">(</span><span class="n">cell</span><span class="p">,</span> <span class="n">keywords</span><span class="p">))</span> 
    <span class="n">line_chart</span> <span class="o">=</span> <span class="n">Line</span><span class="p">()</span>
    <span class="n">line_chart</span><span class="o">.</span><span class="n">add_xaxis</span><span class="p">(</span><span class="n">xaxis_data</span><span class="o">=</span><span class="n">df2</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span>
    <span class="k">for</span> <span class="n">linename</span> <span class="ow">in</span> <span class="n">df2</span><span class="o">.</span><span class="n">index</span><span class="p">:</span>
        <span class="n">linedata</span> <span class="o">=</span> <span class="n">df2</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">linename</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
        <span class="n">line_chart</span><span class="o">.</span><span class="n">add_yaxis</span><span class="p">(</span><span class="n">series_name</span> <span class="o">=</span> <span class="n">linename</span><span class="p">,</span> 
                             <span class="n">y_axis</span><span class="o">=</span><span class="n">linedata</span><span class="p">,</span>
                             <span class="n">label_opts</span><span class="o">=</span><span class="n">opts</span><span class="o">.</span><span class="n">LabelOpts</span><span class="p">(</span><span class="n">formatter</span><span class="o">=</span><span class="s2">&#34;</span><span class="si">{b}</span><span class="s2">&#34;</span><span class="p">,</span> 
                                                       <span class="n">position</span><span class="o">=</span><span class="s2">&#34;right&#34;</span><span class="p">,</span> 
                                                       <span class="n">is_show</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
    <span class="n">line_chart</span><span class="o">.</span><span class="n">set_global_opts</span><span class="p">(</span>
        <span class="n">title_opts</span><span class="o">=</span><span class="n">opts</span><span class="o">.</span><span class="n">TitleOpts</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="n">title</span><span class="p">,</span>
                                  <span class="n">pos_top</span><span class="o">=</span><span class="s2">&#34;5%&#34;</span><span class="p">,</span>
                                  <span class="n">pos_right</span><span class="o">=</span><span class="s1">&#39;30%&#39;</span><span class="p">),</span>
        <span class="n">xaxis_opts</span><span class="o">=</span><span class="n">opts</span><span class="o">.</span><span class="n">AxisOpts</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&#34;Year&#34;</span><span class="p">),</span>
        <span class="n">yaxis_opts</span><span class="o">=</span><span class="n">opts</span><span class="o">.</span><span class="n">AxisOpts</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&#34;Value&#34;</span><span class="p">),</span>
        <span class="n">legend_opts</span><span class="o">=</span><span class="n">opts</span><span class="o">.</span><span class="n">LegendOpts</span><span class="p">(</span><span class="n">pos_right</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">orient</span><span class="o">=</span><span class="s1">&#39;vertical&#39;</span><span class="p">),</span>

    <span class="p">)</span>

    <span class="c1"># Render the chart as an HTML file</span>
    <span class="k">return</span> <span class="n">line_chart</span><span class="o">.</span><span class="n">render_notebook</span><span class="p">()</span>
    
</code></pre></div><p><br><br></p>
<h2 id="三成品展示">三、成品展示</h2>
<h3 id="31-三农">3.1 三农</h3>
<p>展示三农问题关键词20年来变化，因为省份太多会干扰视觉，这里大邓挑选了8个省市。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">selected_df</span> <span class="o">=</span> <span class="n">table_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[[</span><span class="s1">&#39;河北&#39;</span><span class="p">,</span> <span class="s1">&#39;山东&#39;</span><span class="p">,</span> <span class="s1">&#39;北京&#39;</span><span class="p">,</span> <span class="s1">&#39;上海&#39;</span><span class="p">,</span> <span class="s1">&#39;广东&#39;</span><span class="p">,</span> <span class="s1">&#39;浙江&#39;</span><span class="p">,</span> <span class="s1">&#39;黑龙江&#39;</span><span class="p">,</span> <span class="s1">&#39;湖南&#39;</span><span class="p">],:]</span>
<span class="n">keywords</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;农村&#39;</span><span class="p">,</span> <span class="s1">&#39;农业&#39;</span><span class="p">,</span> <span class="s1">&#39;农民&#39;</span><span class="p">]</span>
<span class="n">title</span><span class="o">=</span><span class="s1">&#39;各地政府年度工作报告三农词讨论趋势(1999-2021)&#39;</span><span class="p">,</span>

<span class="n">plot_trends</span><span class="p">(</span><span class="n">df</span><span class="o">=</span><span class="n">selected_df</span><span class="p">,</span> 
            <span class="n">keywords</span><span class="o">=</span><span class="n">keywords</span><span class="p">,</span> 
            <span class="n">title</span><span class="o">=</span><span class="n">title</span><span class="p">)</span>
</code></pre></div><p><img loading="lazy" src="img/%e5%9b%be1.png" alt=""  />
</p>
<p>从上图中，可以看出</p>
<ul>
<li>05年提及三农词占比最多的是湖南，是20年以来8省市中占比值最高记录</li>
<li>大多数省份在07年达到峰值</li>
<li>07年前，工作报告中提及三农词提及三农词的占比趋势是<strong>上升的</strong></li>
<li>07年后，工作报告中提及三农词提及三农词的占比趋势是<strong>下升的</strong>。</li>
</ul>
<p><br><br></p>
<h3 id="32-科学技术">3.2 科学技术</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">selected_df</span> <span class="o">=</span> <span class="n">table_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[[</span><span class="s1">&#39;河北&#39;</span><span class="p">,</span> <span class="s1">&#39;山东&#39;</span><span class="p">,</span> <span class="s1">&#39;北京&#39;</span><span class="p">,</span> <span class="s1">&#39;上海&#39;</span><span class="p">,</span> <span class="s1">&#39;广东&#39;</span><span class="p">,</span> <span class="s1">&#39;浙江&#39;</span><span class="p">,</span> <span class="s1">&#39;黑龙江&#39;</span><span class="p">,</span> <span class="s1">&#39;湖南&#39;</span><span class="p">],:]</span>
<span class="n">keywords</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;科学&#39;</span><span class="p">,</span> <span class="s1">&#39;技术&#39;</span><span class="p">,</span> <span class="s1">&#39;创新&#39;</span><span class="p">]</span>
<span class="n">title</span><span class="o">=</span><span class="s1">&#39;各地政府年度工作报告科学技术词讨论趋势(1999-2021)&#39;</span><span class="p">,</span>

<span class="n">plot_trends</span><span class="p">(</span><span class="n">df</span><span class="o">=</span><span class="n">selected_df</span><span class="p">,</span> 
            <span class="n">keywords</span><span class="o">=</span><span class="n">keywords</span><span class="p">,</span> 
            <span class="n">title</span><span class="o">=</span><span class="n">title</span><span class="p">)</span>
</code></pre></div><p><img loading="lazy" src="img/%e5%9b%be2.png" alt=""  />
</p>
<p>从上图中，可以看出</p>
<ul>
<li>
<p>从2000年以来， 工作报告中提及科学技术词提及的占比趋势一直是稳步<strong>上升的</strong></p>
</li>
<li>
<p>8省市20多年的工作报告中，提及科学技术词最少的省份是<strong>黑龙江</strong>。</p>
</li>
<li>
<p>07年后，工作报告中提及三农词提及三农词的占比趋势是<strong>下升的</strong>。</p>
</li>
</ul>
<br>
<h3 id="33-环保">3.3 环保</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">selected_df</span> <span class="o">=</span> <span class="n">table_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[[</span><span class="s1">&#39;河北&#39;</span><span class="p">,</span> <span class="s1">&#39;山东&#39;</span><span class="p">,</span> <span class="s1">&#39;北京&#39;</span><span class="p">,</span> <span class="s1">&#39;上海&#39;</span><span class="p">,</span> <span class="s1">&#39;广东&#39;</span><span class="p">,</span> <span class="s1">&#39;浙江&#39;</span><span class="p">,</span> <span class="s1">&#39;黑龙江&#39;</span><span class="p">,</span> <span class="s1">&#39;湖南&#39;</span><span class="p">],:]</span>
<span class="n">keywords</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;环境&#39;</span><span class="p">,</span> <span class="s1">&#39;环保&#39;</span><span class="p">,</span> <span class="s1">&#39;绿色&#39;</span><span class="p">,</span> <span class="s1">&#39;健康&#39;</span><span class="p">,</span> <span class="s1">&#39;青山&#39;</span><span class="p">,</span> <span class="s1">&#39;青山绿水&#39;</span><span class="p">,</span> <span class="s1">&#39;绿水&#39;</span><span class="p">]</span>
<span class="n">title</span><span class="o">=</span><span class="s1">&#39;各地政府年度工作报告环保词讨论趋势(1999-2021)&#39;</span><span class="p">,</span>

<span class="n">plot_trends</span><span class="p">(</span><span class="n">df</span><span class="o">=</span><span class="n">selected_df</span><span class="p">,</span> 
            <span class="n">keywords</span><span class="o">=</span><span class="n">keywords</span><span class="p">,</span> 
            <span class="n">title</span><span class="o">=</span><span class="n">title</span><span class="p">)</span>
</code></pre></div><p><img loading="lazy" src="img/%e5%9b%be3.png" alt=""  />
</p>
<p>从上图中，可以看出</p>
<ul>
<li>
<p>08、09年均值较低，前后提及环保词占比更高。可能的原因有</p>
<ul>
<li>08年处于全球金融危机，经济不景气，相对正常年份，少管不管环境问题。</li>
<li>为准备北京奥运会，各地都有环保压力， 体现在08年前提及占比值整体处于较高水平</li>
<li>奥运后，松一口气？</li>
</ul>
</li>
<li>
<p>最近几年，提及值一直处于上升趋势</p>
</li>
</ul>
<p><img loading="lazy" src="img/%e5%9b%be4.png" alt=""  />
</p>
<p>在看上图， 06-12年的北京和河北，趋势不太一样。</p>
<ul>
<li>北京09达到局部最高值后下降了几年</li>
<li>河北06-09与北京反着来，一直在下降</li>
<li>河北09之后，可能是钢铁等行业较多，环保压力随着国家的重视，被迫快速拉升</li>
</ul>
<br>
<p>基本跟自己的记忆产生了联系，数据可视化效果还是挺不错的。</p>
<br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>中文心理词典，含具体性、可成象性等指标</title>
      <link>https://textdata.cn/blog/2023-04-05-chinese-concreteness-dictionary-from-behavior-research-method/</link>
      <pubDate>Wed, 05 Apr 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-04-05-chinese-concreteness-dictionary-from-behavior-research-method/</guid>
      <description>该研究建立了一个**汉字书写的心理语言学数据库**。该数据库挑选出了1600个频率分布广泛的汉字，采用听写任务，总共203名被试来书写这些汉字，采集了被试的书写潜伏期、书写时长、书写正确率，并收集了1600汉字的14个词汇变量。研究结果发现，字频、习得年龄、语境是影响正字法通达、运动执行和书写正确率的共同因素；语音变量（是否为形声字、规则性、同音字密度）影响正字法通达，但不影响运动执行；语义变量（表象性和具体性）只影响书写正确率。研究结果对汉字书写产生机制有着重要启发。作为第一个大规模的汉字书写的心理语言学数据库，该数据库可以作为二次数据分析的资源以及书写实验材料制作的工具</description>
      <content:encoded><![CDATA[<p>之前分享过 <a href="https://textdata.cn/blog/jcr_concreteness_computation/"><strong>JCR的一篇语言具体性</strong></a>的研究应用，<strong>语言具体性Concreteness</strong>描述了一个词在多大程度上是指一个实际的、有形的或“真实的”实体，以一种更具体、更熟悉、更容易被眼睛或心灵感知的方式描述对象和行为。但是具体性词典是英文的。今天分享的这篇论文是1600个词，含具体性和表象性词典。</p>
<br>
<p>Wang, Ruiming, Shuting Huang, Yacong Zhou, and Zhenguang G. Cai. &ldquo;Chinese character handwriting: A large-scale behavioral study and a database.&rdquo; Behavior Research Methods 52 (2020): 82-96.</p>
<br>
<h2 id="摘要">摘要</h2>
<p>该研究建立了一个<strong>汉字书写的心理语言学数据库</strong>。该数据库挑选出了1600个频率分布广泛的汉字，采用听写任务，总共203名被试来书写这些汉字，采集了被试的书写潜伏期、书写时长、书写正确率，并收集了1600汉字的14个词汇变量。研究结果发现，字频、习得年龄、语境是影响正字法通达、运动执行和书写正确率的共同因素；语音变量（是否为形声字、规则性、同音字密度）影响正字法通达，但不影响运动执行；语义变量（表象性和具体性）只影响书写正确率。研究结果对汉字书写产生机制有着重要启发。作为第一个大规模的汉字书写的心理语言学数据库，该数据库可以作为二次数据分析的资源以及书写实验材料制作的工具。数据库免费公开，访问网址为：https://osf.io/7s9kq/。</p>
<br>
<h2 id="字段">字段</h2>
<p>字段有很多，我挑选最重要的翻译过来。</p>
<table>
<thead>
<tr>
<th style="text-align:right">Item</th>
<th style="text-align:left">Item number of characters</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right">Character</td>
<td style="text-align:left">中文单字</td>
</tr>
<tr>
<td style="text-align:right">Word</td>
<td style="text-align:left">由该字组成的词语</td>
</tr>
<tr>
<td style="text-align:right">&hellip;</td>
<td style="text-align:left">&hellip;</td>
</tr>
<tr>
<td style="text-align:right"><strong>zImageability</strong></td>
<td style="text-align:left">可成像性（归一化评分）</td>
</tr>
<tr>
<td style="text-align:right"><strong>zConcreteness</strong></td>
<td style="text-align:left">具体性（归一化评分)</td>
</tr>
<tr>
<td style="text-align:right">&hellip;</td>
<td style="text-align:left">&hellip;</td>
</tr>
</tbody>
</table>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_excel</span><span class="p">(</span><span class="s1">&#39;Database.xlsx&#39;</span><span class="p">,</span> <span class="n">sheet_name</span><span class="o">=</span><span class="s1">&#39;Data&#39;</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">columns</span>
</code></pre></div><p>Run</p>
<pre><code>Index(['Item', 'Character', 'Word', 'nOccurrence', 'nACC', 'nMisheard', 'nTOP',
       'nMisspelt', 'nMisremembered', 'ACC', 'Misheard', 'TOP', 'Misspelt',
       'Misremembered', 'Latency_Correct', 'Duration_Correct', 'Latency_z',
       'Duration_z', 'FreqCount', 'FreqContext', 'AoA', 'nMeaning',
       'zImageability', 'zConcreteness', 'Phonogram', 'SRO', 'zRegularity',
       'logHomoDen', 'nStroke', 'nRadical', 'Comp_LR', 'Comp_TD',
       'zwFamiliarity'],
      dtype='object')
</code></pre>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df</span><span class="p">[[</span><span class="s1">&#39;Character&#39;</span><span class="p">,</span> <span class="s1">&#39;Word&#39;</span><span class="p">,</span> <span class="s1">&#39;zConcreteness&#39;</span><span class="p">,</span> <span class="s1">&#39;zImageability&#39;</span><span class="p">]]</span>
</code></pre></div><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Character</th>
      <th>Word</th>
      <th>zConcreteness</th>
      <th>zImageability</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>哀</td>
      <td>悲哀</td>
      <td>-0.103212</td>
      <td>0.404177</td>
    </tr>
    <tr>
      <th>1</th>
      <td>癌</td>
      <td>癌症</td>
      <td>0.319844</td>
      <td>0.176291</td>
    </tr>
    <tr>
      <th>2</th>
      <td>疤</td>
      <td>伤疤</td>
      <td>1.180032</td>
      <td>0.919010</td>
    </tr>
    <tr>
      <th>3</th>
      <td>白</td>
      <td>明白</td>
      <td>0.691302</td>
      <td>0.527291</td>
    </tr>
    <tr>
      <th>4</th>
      <td>百</td>
      <td>一百</td>
      <td>-0.234004</td>
      <td>-0.039290</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>1595</th>
      <td>组</td>
      <td>小组</td>
      <td>-0.556125</td>
      <td>-0.326855</td>
    </tr>
    <tr>
      <th>1596</th>
      <td>钻</td>
      <td>钻石</td>
      <td>0.412641</td>
      <td>0.116090</td>
    </tr>
    <tr>
      <th>1597</th>
      <td>嘴</td>
      <td>住嘴</td>
      <td>1.447112</td>
      <td>0.846971</td>
    </tr>
    <tr>
      <th>1598</th>
      <td>醉</td>
      <td>麻醉</td>
      <td>0.297512</td>
      <td>0.596776</td>
    </tr>
    <tr>
      <th>1599</th>
      <td>作</td>
      <td>工作</td>
      <td>-0.817521</td>
      <td>-0.933269</td>
    </tr>
  </tbody>
</table>
<p>1600 rows × 4 columns</p>
</div>
<br>
## 广而告之
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>预训练模型 | 金融会计类word2vec， 可扩展或构建领域内概念情感词典</title>
      <link>https://textdata.cn/blog/2023-03-24-load-w2v-and-expand-your-concpet-dicitonary/</link>
      <pubDate>Fri, 24 Mar 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-03-24-load-w2v-and-expand-your-concpet-dicitonary/</guid>
      <description>&lt;h2 id=&#34;一介绍&#34;&gt;一、介绍&lt;/h2&gt;
&lt;p&gt;使用2001-2021年的&lt;strong&gt;管理层讨论与分析mda&lt;/strong&gt;数据(1.45G)，训练出的中国A股市场词向量模型，词汇量789539， 模型文件650M。可广泛用于经济管理等领域概念(情感)词典的构建或扩展。&lt;/p&gt;
&lt;p&gt;训练环境为内存256G的windows服务器(日常办公电脑内存16G居多)， 2.0.0版本cntext库(该版本暂不开源，最新可获取的版本为1.8.4)。在该环境下，我也尝试使用14G的年报数据，训练了两天，跑不出结果，256G的内存基本用光了。所以cntext训练模型，适合的数据规模是1G左右。模型文件&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;mda01-21.200.6.bin&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;mda01-21.200.6.bin.vectors.npy&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;pretained-screen.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;参数解读&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;mda01-21 使用2001-2021年度的mda数据训练&lt;/li&gt;
&lt;li&gt;200 嵌入的维度数，即每个词的向量长度是200&lt;/li&gt;
&lt;li&gt;6 词语上下文的窗口是6&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;为什么这样确定200和6，可以看这篇 &lt;a href=&#34;https://textdata.cn/blog/2023-03-15-39faq-about-word-embeddings-for-social-science&#34;&gt;词嵌入技术在社会科学领域进行数据挖掘常见39个FAQ汇总&lt;/a&gt;&lt;/p&gt;
&lt;br&gt;
&lt;br&gt;
&lt;h2 id=&#34;二导入模型&#34;&gt;二、导入模型&lt;/h2&gt;
&lt;p&gt;需要用到两个自定义函数load_w2v、expand_dictionary，源代码太长，为了提高阅读体验， 放在文末。大家记得用这两个函数前一定要先导入。&lt;a href=&#34;mda_pretained_model_code.ipynb&#34;&gt;&lt;strong&gt;点击下载本文&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;c1&#34;&gt;#先导入load_w2v、expand_dictionary函数源代码&lt;/span&gt;


&lt;span class=&#34;c1&#34;&gt;#读取模型文件&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;load_w2v&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;w2v_path&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;model/mda01-21.200.6.bin&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Loading word2vec model...
&amp;lt;gensim.models.keyedvectors.KeyedVectors at 0x7fcc91900a90&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;三wv的使用&#34;&gt;三、wv的使用&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;查看词汇量&lt;/li&gt;
&lt;li&gt;查询某词向量&lt;/li&gt;
&lt;li&gt;查看多个词的均值向量&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;更多内容，建议查看下gensim库的文档&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;c1&#34;&gt;#词汇量&lt;/span&gt;
&lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;index_to_key&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;789539
&lt;/code&gt;&lt;/pre&gt;
&lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;c1&#34;&gt;#查询某词的词向量&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;get_vector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;创新&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;array([ 4.34389877e+00, -4.93447453e-01,  2.17293240e-02,  1.90846980e+00,
        8.75901580e-01, -7.95542181e-01, -1.12950909e+00,  7.44228721e-01,
        7.38122821e-01,  6.42377853e-01,  3.99175316e-01,  2.17924786e+00,
        9.30410504e-01, -3.23538423e+00, -2.91860670e-01,  1.04046893e+00,
       -1.73857129e+00, -1.12141383e+00,  3.51870751e+00, -8.69141936e-01,
        4.95228887e-01,  4.80194688e-01, -3.35257435e+00,  7.16054797e-01,
        2.29016230e-01,  2.40962386e+00, -7.40825295e-01,  2.18998361e+00,
       -3.37587762e+00, -1.30376315e+00,  5.08445930e+00, -1.68504322e+00,
       -1.60081315e+00, -8.33779454e-01, -7.58818448e-01, -1.78838921e+00,
        2.44672084e+00,  2.27579999e+00, -2.52457595e+00,  1.36214256e-01,
       -3.09675723e-01, -6.98232710e-01,  1.73018420e+00, -8.05342972e-01,
       -1.70148358e-01, -2.43612671e+00, -1.23085886e-01,  2.83124876e+00,
        3.89446110e-01, -3.16048344e-03, -2.09607935e+00, -1.49788404e+00,
        8.58029604e-01, -1.26923633e+00,  1.86084434e-01,  9.13471103e-01,
        1.53111053e+00, -2.57916182e-01,  1.83742964e+00,  1.50475979e+00,
        6.84375539e-02,  2.76320624e+00,  1.02619076e+00,  9.41017449e-01,
        1.66149962e+00, -2.49254084e+00, -7.78038025e-01, -6.52620196e-01,
       -1.59455287e+00, -4.13568115e+00,  2.78383470e+00, -5.71591198e-01,
       -8.45031738e-01,  4.54110718e+00,  1.67990357e-01,  2.12474012e+00,
       -2.25404716e+00, -8.35567772e-01,  9.91619170e-01, -2.55307484e+00,
        2.39850569e+00,  7.65280128e-01,  2.64600372e+00,  2.58998632e-01,
       -6.56729996e-01, -1.55601549e+00,  1.49751770e+00,  8.47311080e-01,
       -2.05665565e+00, -1.14815748e+00,  1.97350585e+00,  1.02964830e+00,
       -3.87644440e-01, -9.38048363e-01, -2.55545706e-01, -7.02206418e-03,
       -2.94358826e+00, -7.96167493e-01,  1.59571424e-01,  1.25497723e+00,
        7.12080002e-01, -1.34656525e+00,  1.54059935e+00, -1.12930894e+00,
       -3.66737366e+00, -7.17270374e-01, -2.69604278e+00,  1.90242791e+00,
        9.33268607e-01, -4.67624277e-01,  3.51641893e+00,  5.66355512e-02,
       -1.31763351e+00,  1.53379011e+00,  2.32190108e+00, -5.21186776e-02,
        4.06406015e-01,  4.48809415e-01, -3.68958092e+00, -1.01650321e+00,
       -1.08470261e+00, -1.93710685e+00,  2.27287245e+00, -6.63952589e-01,
        1.88207674e+00, -1.20226216e+00,  1.08953261e+00,  1.32847381e+00,
        1.38213491e+00,  1.47196710e+00, -2.06643629e+00,  1.99588931e+00,
       -1.64155555e+00, -2.24964902e-01, -2.74115324e+00, -3.16747665e+00,
        1.24095821e+00, -4.10616726e-01, -3.48466903e-01,  1.38452172e+00,
       -1.45676279e+00, -3.54911834e-02, -4.73554075e-01, -4.23114252e+00,
        1.52749741e+00,  7.25808144e-01, -4.50003862e-01, -3.16014004e+00,
        2.60309219e+00, -2.11320925e+00,  3.61347020e-01,  1.73625088e+00,
        1.57609022e+00, -2.08762145e+00,  2.18810892e+00,  1.20706499e+00,
       -1.82370770e+00,  1.22358835e+00, -8.91464829e-01, -3.30527711e+00,
       -3.72515142e-01, -6.23329699e-01,  8.11975658e-01, -8.52464736e-01,
       -9.35325995e-02, -4.06904364e+00,  1.57146180e+00,  7.85030201e-02,
        1.94540334e+00,  2.13809991e+00, -1.58913553e+00, -3.81727874e-01,
       -2.08527303e+00,  5.89691937e-01,  2.55564898e-01,  2.38364622e-01,
        3.64680409e+00,  4.18930590e-01,  1.62034535e+00, -4.63252217e-02,
        5.80206394e-01,  5.55441022e-01,  1.91946900e+00, -1.89253080e+00,
        1.77489519e+00, -3.15311766e+00,  6.48138940e-01,  1.15823770e+00,
       -2.54519200e+00, -1.03516951e-01,  1.15724599e+00, -1.83681571e+00,
       -9.87860620e-01, -1.99984312e+00,  2.76547909e-01,  8.02748859e-01,
        1.99196494e+00, -1.43310416e+00, -2.03039408e+00, -7.19777197e-02],
      dtype=float32)
&lt;/code&gt;&lt;/pre&gt;
&lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;c1&#34;&gt;#查询多个词的词向量&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;get_mean_vector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;([&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;创新&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;研发&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Ruj&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;array([ 0.17623448, -0.02220692, -0.01040847,  0.03616136,  0.04931263,
       -0.06220303, -0.02846557, -0.00156435,  0.04524047,  0.03185674,
        0.01104859,  0.06962118, -0.01969986, -0.10831943, -0.0524368 ,
        0.00623383, -0.04149605, -0.004912  ,  0.13154642, -0.04317038,
       -0.00407438,  0.00923527, -0.13339072,  0.01446994, -0.00153984,
        0.12378754, -0.06064663,  0.09322313, -0.07711462, -0.05880795,
        0.13697049,  0.0133168 ,  0.02769322,  0.02677607,  0.02549294,
       -0.04504526,  0.06267191,  0.02421109, -0.13401456,  0.01423616,
        0.01860182,  0.00344108,  0.04811918,  0.02748652,  0.0190251 ,
       -0.03800797,  0.01517046,  0.06439836,  0.01320594,  0.04748138,
       -0.08914943, -0.00642068,  0.01786153, -0.02472607, -0.04597819,
        0.05832303,  0.11275461, -0.0387079 ,  0.06912261,  0.05287468,
       -0.04447906,  0.10994074, -0.04371417,  0.01227543,  0.07498093,
       -0.11285575, -0.03113984, -0.01122221, -0.03913497, -0.12117577,
        0.08593786, -0.04319173, -0.01860389,  0.15636683,  0.02267851,
        0.0922839 , -0.12106322, -0.07572737,  0.0191772 , -0.00977821,
        0.00455545,  0.01378978,  0.04774487, -0.02080727,  0.01015578,
       -0.04695337,  0.0848957 , -0.01112909, -0.03210922,  0.01151857,
        0.02214565,  0.03220333, -0.02468888, -0.07493623, -0.03724978,
       -0.00716823, -0.12043905, -0.0560291 , -0.00666756,  0.03659805,
        0.0532646 , -0.05371486,  0.06905847,  0.00660356, -0.10362111,
       -0.0015829 , -0.13282564,  0.08241726,  0.00993685,  0.04208402,
        0.03087696,  0.04765649, -0.00834742,  0.07236902,  0.04473683,
       -0.02643864, -0.0050621 ,  0.04462356, -0.0832998 , -0.05533891,
        0.00664944, -0.13001585,  0.07607447, -0.00764748,  0.01410657,
       -0.03057465,  0.0250505 ,  0.09252612, -0.00784517,  0.0386237 ,
       -0.059011  ,  0.05357389, -0.04604931,  0.04388874, -0.0971131 ,
       -0.09777305,  0.02943253, -0.04103448, -0.03944859,  0.09638489,
       -0.02226706,  0.02822194, -0.0093646 , -0.11203568,  0.06142627,
        0.04761236,  0.02720375, -0.09777595,  0.04048391, -0.06758034,
       -0.01500905,  0.02439078,  0.07150253, -0.02562411,  0.02533657,
        0.00799897, -0.06416934,  0.03153701, -0.03944302, -0.04653639,
       -0.04123383, -0.01590026,  0.03051148, -0.02014856, -0.01448381,
       -0.10517117, -0.00649814,  0.02478252,  0.02855514,  0.09052269,
       -0.03505059, -0.03173327, -0.06641324,  0.06284194,  0.01993516,
        0.01349441,  0.1410133 , -0.05283241,  0.03687092, -0.02535007,
        0.00415636,  0.05841105,  0.07389537, -0.13176979,  0.06759793,
       -0.092868  ,  0.01370211,  0.06616284, -0.09137756, -0.01640504,
        0.06095972, -0.05725639, -0.04122292,  0.00598698,  0.02904861,
        0.0442962 ,  0.07399555, -0.04657119, -0.07636161,  0.03204561],
      dtype=float32)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;有了每个词或者概念的向量，可以结合cntext旧版本单语言模型内的态度偏见的度量。&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;四扩展词典&#34;&gt;四、扩展词典&lt;/h2&gt;
&lt;p&gt;做词典法的文本分析，最重要的是有自己的领域词典。之前受限于技术难度，文科生的我也一直在用形容词的通用情感词典。现在依托word2vec技术， 可以加速人工构建的准确率和效率。&lt;/p&gt;
&lt;p&gt;下面是在 mda01-21.200.6.bin 上做的词典扩展测试，函数expand_dictionary会根据种子词选取最准确的topn个词。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;c1&#34;&gt;#短视主义词  实验&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;expand_dictionary&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
                  &lt;span class=&#34;n&#34;&gt;seedwords&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;抓紧&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;立刻&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;月底&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;年底&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;年终&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;争取&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;力争&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;
                  &lt;span class=&#34;n&#34;&gt;topn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;30&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[&#39;抓紧&#39;,
 &#39;立刻&#39;,
 &#39;月底&#39;,
 &#39;年底&#39;,
 &#39;年终&#39;,
 &#39;争取&#39;,
 &#39;力争&#39;,
 &#39;争取&#39;,
 &#39;力争&#39;,
 &#39;年内&#39;,
 &#39;月底&#39;,
 &#39;年底&#39;,
 &#39;尽早&#39;,
 &#39;3月底&#39;,
 &#39;尽快&#39;,
 &#39;抓紧&#39;,
 &#39;6月份&#39;,
 &#39;4月份&#39;,
 &#39;月份&#39;,
 &#39;工作力争&#39;,
 &#39;努力争取&#39;,
 &#39;工作争取&#39;,
 &#39;10月底&#39;,
 &#39;年内实现&#39;,
 &#39;年底完成&#39;,
 &#39;中旬&#39;,
 &#39;7月份&#39;,
 &#39;9月底&#39;,
 &#39;有望&#39;,
 &#39;月底前&#39;,
 &#39;早日&#39;,
 &#39;全力&#39;,
 &#39;继续&#39;,
 &#39;月初&#39;,
 &#39;努力&#39;,
 &#39;确保&#39;,
 &#39;8月份&#39;]
&lt;/code&gt;&lt;/pre&gt;
&lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;expand_dictionary&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
                  &lt;span class=&#34;n&#34;&gt;seedwords&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;团结&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;拼搏&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;  &lt;span class=&#34;s1&#34;&gt;&amp;#39;克服&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;  &lt;span class=&#34;s1&#34;&gt;&amp;#39;勇攀高峰&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;  &lt;span class=&#34;s1&#34;&gt;&amp;#39;友善&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;  &lt;span class=&#34;s1&#34;&gt;&amp;#39;进取&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;
                  &lt;span class=&#34;n&#34;&gt;topn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;30&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[&#39;团结&#39;,
 &#39;拼搏&#39;,
 &#39;克服&#39;,
 &#39;勇攀高峰&#39;,
 &#39;友善&#39;,
 &#39;进取&#39;,
 &#39;拼搏&#39;,
 &#39;艰苦奋斗&#39;,
 &#39;坚定信念&#39;,
 &#39;团结拼搏&#39;,
 &#39;上下同心&#39;,
 &#39;团结&#39;,
 &#39;顽强拼搏&#39;,
 &#39;勇于担当&#39;,
 &#39;团结一致&#39;,
 &#39;团结奋进&#39;,
 &#39;精诚团结&#39;,
 &#39;齐心协力&#39;,
 &#39;开拓进取&#39;,
 &#39;奋进&#39;,
 &#39;团结一心&#39;,
 &#39;实干&#39;,
 &#39;同心协力&#39;,
 &#39;团结协作&#39;,
 &#39;锐意进取&#39;,
 &#39;积极进取&#39;,
 &#39;奋力拼搏&#39;,
 &#39;拼搏精神&#39;,
 &#39;努力拼搏&#39;,
 &#39;进取&#39;,
 &#39;奋发有为&#39;,
 &#39;扎实工作&#39;,
 &#39;同心同德&#39;,
 &#39;拼搏进取&#39;,
 &#39;脚踏实地&#39;,
 &#39;励精图治&#39;]
&lt;/code&gt;&lt;/pre&gt;
&lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;expand_dictionary&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
                  &lt;span class=&#34;n&#34;&gt;seedwords&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;创新&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;科技&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;  &lt;span class=&#34;s1&#34;&gt;&amp;#39;研发&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;  &lt;span class=&#34;s1&#34;&gt;&amp;#39;技术&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;  &lt;span class=&#34;s1&#34;&gt;&amp;#39;标准&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;
                  &lt;span class=&#34;n&#34;&gt;topn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;30&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[&#39;创新&#39;,
 &#39;科技&#39;,
 &#39;研发&#39;,
 &#39;技术&#39;,
 &#39;标准&#39;,
 &#39;创新&#39;,
 &#39;技术创新&#39;,
 &#39;技术研发&#39;,
 &#39;科技创新&#39;,
 &#39;先进技术&#39;,
 &#39;自主创新&#39;,
 &#39;前沿技术&#39;,
 &#39;关键技术&#39;,
 &#39;科研&#39;,
 &#39;新技术&#39;,
 &#39;创新性&#39;,
 &#39;研发创新&#39;,
 &#39;产品研发&#39;,
 &#39;基础研究&#39;,
 &#39;产品开发&#39;,
 &#39;集成创新&#39;,
 &#39;核心技术&#39;,
 &#39;自主研发&#39;,
 &#39;技术应用&#39;,
 &#39;技术集成&#39;,
 &#39;前沿科技&#39;,
 &#39;技术标准&#39;,
 &#39;工艺技术&#39;,
 &#39;科技成果&#39;,
 &#39;技术开发&#39;,
 &#39;尖端技术&#39;,
 &#39;工程技术&#39;,
 &#39;技术相结合&#39;,
 &#39;科学技术&#39;,
 &#39;工艺&#39;]
&lt;/code&gt;&lt;/pre&gt;
&lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;expand_dictionary&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
                  &lt;span class=&#34;n&#34;&gt;seedwords&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;竞争&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;竞争力&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;
                  &lt;span class=&#34;n&#34;&gt;topn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;30&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[&#39;竞争&#39;,
 &#39;竞争力&#39;,
 &#39;竞争能力&#39;,
 &#39;竞争优势&#39;,
 &#39;市场竞争&#39;,
 &#39;竞&#39;,
 &#39;市场竞争力&#39;,
 &#39;竞争实力&#39;,
 &#39;参与市场竞争&#39;,
 &#39;国际竞争&#39;,
 &#39;市场竞争能力&#39;,
 &#39;核心竞争力&#39;,
 &#39;激烈竞争&#39;,
 &#39;市场竞争优势&#39;,
 &#39;竞争态势&#39;,
 &#39;参与竞争&#39;,
 &#39;竞争力重要&#39;,
 &#39;竞争对手&#39;,
 &#39;创新能力&#39;,
 &#39;综合竞争力&#39;,
 &#39;价格竞争&#39;,
 &#39;之间竞争&#39;,
 &#39;核心竞争能力&#39;,
 &#39;未来市场竞争&#39;,
 &#39;国际竞争力&#39;,
 &#39;影响力竞争力&#39;,
 &#39;国际化竞争&#39;,
 &#39;行业竞争&#39;,
 &#39;综合竞争能力&#39;,
 &#39;竞争日趋激烈&#39;,
 &#39;产品竞争力&#39;,
 &#39;竞争力影响力&#39;]
&lt;/code&gt;&lt;/pre&gt;
&lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;expand_dictionary&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
                  &lt;span class=&#34;n&#34;&gt;seedwords&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;疫情&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;扩散&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;防控&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;反复&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;冲击&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;
                  &lt;span class=&#34;n&#34;&gt;topn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;30&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[&#39;疫情&#39;,
 &#39;扩散&#39;,
 &#39;防控&#39;,
 &#39;反复&#39;,
 &#39;冲击&#39;,
 &#39;蔓延&#39;,
 &#39;疫情冲击&#39;,
 &#39;疫情爆发&#39;,
 &#39;新冠疫情&#39;,
 &#39;新冠肺炎&#39;,
 &#39;疫情蔓延&#39;,
 &#39;疫情暴发&#39;,
 &#39;肆虐&#39;,
 &#39;本次疫情&#39;,
 &#39;冲击疫情&#39;,
 &#39;新冠病毒&#39;,
 &#39;疫情扩散&#39;,
 &#39;全球蔓延&#39;,
 &#39;疫情影响&#39;,
 &#39;病毒疫情&#39;,
 &#39;肺炎疫情&#39;,
 &#39;击&#39;,
 &#39;持续蔓延&#39;,
 &#39;疫情持续&#39;,
 &#39;各地疫情&#39;,
 &#39;疫情突然&#39;,
 &#39;疫情全球&#39;,
 &#39;疫情传播&#39;,
 &#39;疫情反复&#39;,
 &#39;散发&#39;,
 &#39;变异毒株&#39;,
 &#39;疫情导致&#39;,
 &#39;疫情肆虐&#39;,
 &#39;全球疫情&#39;,
 &#39;全球新冠&#39;]
&lt;/code&gt;&lt;/pre&gt;
&lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;expand_dictionary&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
                  &lt;span class=&#34;n&#34;&gt;seedwords&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;旧&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;老&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;后&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;落后&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;
                  &lt;span class=&#34;n&#34;&gt;topn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;30&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[&#39;旧&#39;,
 &#39;老&#39;,
 &#39;后&#39;,
 &#39;落后&#39;,
 &#39;旧&#39;,
 &#39;老&#39;,
 &#39;陈旧&#39;,
 &#39;老旧&#39;,
 &#39;淘汰&#39;,
 &#39;高能耗&#39;,
 &#39;低效率&#39;,
 &#39;设备陈旧&#39;,
 &#39;能耗高&#39;,
 &#39;老旧设备&#39;,
 &#39;落后工艺&#39;,
 &#39;进行改造&#39;,
 &#39;工艺落后&#39;,
 &#39;技术落后&#39;,
 &#39;翻新&#39;,
 &#39;更新改造&#39;,
 &#39;改造&#39;,
 &#39;更新&#39;,
 &#39;替换&#39;,
 &#39;改造更新&#39;,
 &#39;旧设备&#39;,
 &#39;污染重&#39;,
 &#39;淘汰一批&#39;,
 &#39;拆除&#39;,
 &#39;污染严重&#39;,
 &#39;简陋&#39;,
 &#39;产能落后&#39;,
 &#39;相对落后&#39;,
 &#39;产能淘汰&#39;,
 &#39;效率低下&#39;]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;五源代码&#34;&gt;五、源代码&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;gensim.models&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;KeyedVectors&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pathlib&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Path&lt;/span&gt;


&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;load_w2v&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;w2v_path&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
    &lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&amp;#34;
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;    Load word2vec model
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;    Args:
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;        w2v_path (str): path of word2vec model
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;    Returns:
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;        model: word2vec model
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;    &amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;
    &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;Loading word2vec model...&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;model&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;KeyedVectors&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;load&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;w2v_path&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
    &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;model&lt;/span&gt;


&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;expand_dictionary&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;seedwords&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;topn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;100&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
    &lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&amp;#34;
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;    According to the seed word file, select the top n words with the most similar semantics and save them in the directory save_dir.
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;    
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;    Args:
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;        wv (Word2VecKeyedVectors): the word embedding model
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;        seedwords (list): 种子词
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;        topn (int, optional): Set the number of most similar words to retrieve to topn. Defaults to 100.
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;        save_dir (str, optional): the directory to save the candidate words. Defaults to &amp;#39;Word2Vec&amp;#39;.
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;    
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;    Returns:
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;    &amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;simidx_scores&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt;

    &lt;span class=&#34;n&#34;&gt;similars_candidate_idxs&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;#the candidate words of seedwords&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;dictionary&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;key_to_index&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;seedidxs&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;#transform word to index&lt;/span&gt;
    &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;seed&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;seedwords&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
        &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;seed&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;dictionary&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
            &lt;span class=&#34;n&#34;&gt;seedidx&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;dictionary&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;seed&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
            &lt;span class=&#34;n&#34;&gt;seedidxs&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;append&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;seedidx&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
    &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;seedidx&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;seedidxs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
        &lt;span class=&#34;c1&#34;&gt;# sims_words such as [(&amp;#39;by&amp;#39;, 0.99984), (&amp;#39;or&amp;#39;, 0.99982), (&amp;#39;an&amp;#39;, 0.99981), (&amp;#39;up&amp;#39;, 0.99980)]&lt;/span&gt;
        &lt;span class=&#34;n&#34;&gt;sims_words&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;similar_by_word&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;seedidx&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;topn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;topn&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
        &lt;span class=&#34;c1&#34;&gt;#Convert words to index and store them&lt;/span&gt;
        &lt;span class=&#34;n&#34;&gt;similars_candidate_idxs&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;extend&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;([&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dictionary&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sim&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]]&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sim&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sims_words&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;similars_candidate_idxs&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;set&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;similars_candidate_idxs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
    
    &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;idx&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;similars_candidate_idxs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
        &lt;span class=&#34;n&#34;&gt;score&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;n_similarity&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;([&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;idx&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;seedidxs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
        &lt;span class=&#34;n&#34;&gt;simidx_scores&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;append&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;((&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;idx&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;score&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;simidxs&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;w&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;w&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;sorted&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;simidx_scores&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;key&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;lambda&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;k&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;k&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;reverse&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)]&lt;/span&gt;

    &lt;span class=&#34;n&#34;&gt;simwords&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;str&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;index_to_key&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;idx&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;idx&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;simidxs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;][:&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;topn&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;

    &lt;span class=&#34;n&#34;&gt;resultwords&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;resultwords&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;extend&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;seedwords&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;resultwords&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;extend&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;simwords&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
    
    &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;resultwords&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;获取模型&#34;&gt;获取模型&lt;/h2&gt;
&lt;p&gt;模型训练不易， 为付费资源，如需使用请 &lt;a href=&#34;https://mp.weixin.qq.com/s/zle9-BR-ei1V8Nmul19_7w&#34;&gt;&lt;strong&gt;点击进入跳转购买链接&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;期待合作&#34;&gt;期待合作&lt;/h2&gt;
&lt;p&gt;cntext目前仍在技术迭代，版本2.0.0综合了训练语言模型&amp;amp;多语言模型对齐， 有较大的应用价值，期待有独特文本数据集交流合作。&lt;/p&gt;
&lt;p&gt;通过cntext2.0.0，理论上可以对文本所涉社会主体进行计算，适合企业文化、品牌印象、旅游目的地形象、国家形象等&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;同主体不同时间段， 文本中蕴含的文化态度认知变迁，&lt;/li&gt;
&lt;li&gt;或同时间段，不同主体的大样本文本蕴含的差异性&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;广而告之&#34;&gt;广而告之&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/call_for_paper/&#34;&gt;长期征稿&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/we_need_you/&#34;&gt;长期招募小伙伴&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/management_python_course/&#34;&gt;付费视频课 | Python实证指标构建与文本分析&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
      <content:encoded><![CDATA[<h2 id="一介绍">一、介绍</h2>
<p>使用2001-2021年的<strong>管理层讨论与分析mda</strong>数据(1.45G)，训练出的中国A股市场词向量模型，词汇量789539， 模型文件650M。可广泛用于经济管理等领域概念(情感)词典的构建或扩展。</p>
<p>训练环境为内存256G的windows服务器(日常办公电脑内存16G居多)， 2.0.0版本cntext库(该版本暂不开源，最新可获取的版本为1.8.4)。在该环境下，我也尝试使用14G的年报数据，训练了两天，跑不出结果，256G的内存基本用光了。所以cntext训练模型，适合的数据规模是1G左右。模型文件</p>
<ul>
<li><strong>mda01-21.200.6.bin</strong></li>
<li><strong>mda01-21.200.6.bin.vectors.npy</strong></li>
</ul>
<p><img loading="lazy" src="pretained-screen.png" alt=""  />
</p>
<p>参数解读</p>
<ul>
<li>mda01-21 使用2001-2021年度的mda数据训练</li>
<li>200 嵌入的维度数，即每个词的向量长度是200</li>
<li>6 词语上下文的窗口是6</li>
</ul>
<p>为什么这样确定200和6，可以看这篇 <a href="https://textdata.cn/blog/2023-03-15-39faq-about-word-embeddings-for-social-science">词嵌入技术在社会科学领域进行数据挖掘常见39个FAQ汇总</a></p>
<br>
<br>
<h2 id="二导入模型">二、导入模型</h2>
<p>需要用到两个自定义函数load_w2v、expand_dictionary，源代码太长，为了提高阅读体验， 放在文末。大家记得用这两个函数前一定要先导入。<a href="mda_pretained_model_code.ipynb"><strong>点击下载本文</strong></a></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#先导入load_w2v、expand_dictionary函数源代码</span>


<span class="c1">#读取模型文件</span>
<span class="n">wv</span> <span class="o">=</span> <span class="n">load_w2v</span><span class="p">(</span><span class="n">w2v_path</span><span class="o">=</span><span class="s1">&#39;model/mda01-21.200.6.bin&#39;</span><span class="p">)</span>
<span class="n">wv</span>
</code></pre></div><pre><code>Loading word2vec model...
&lt;gensim.models.keyedvectors.KeyedVectors at 0x7fcc91900a90&gt;
</code></pre>
<h3 id="三wv的使用">三、wv的使用</h3>
<ul>
<li>查看词汇量</li>
<li>查询某词向量</li>
<li>查看多个词的均值向量</li>
</ul>
<p>更多内容，建议查看下gensim库的文档</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#词汇量</span>
<span class="nb">len</span><span class="p">(</span><span class="n">wv</span><span class="o">.</span><span class="n">index_to_key</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<pre><code>789539
</code></pre>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#查询某词的词向量</span>
<span class="n">wv</span><span class="o">.</span><span class="n">get_vector</span><span class="p">(</span><span class="s1">&#39;创新&#39;</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<pre><code>array([ 4.34389877e+00, -4.93447453e-01,  2.17293240e-02,  1.90846980e+00,
        8.75901580e-01, -7.95542181e-01, -1.12950909e+00,  7.44228721e-01,
        7.38122821e-01,  6.42377853e-01,  3.99175316e-01,  2.17924786e+00,
        9.30410504e-01, -3.23538423e+00, -2.91860670e-01,  1.04046893e+00,
       -1.73857129e+00, -1.12141383e+00,  3.51870751e+00, -8.69141936e-01,
        4.95228887e-01,  4.80194688e-01, -3.35257435e+00,  7.16054797e-01,
        2.29016230e-01,  2.40962386e+00, -7.40825295e-01,  2.18998361e+00,
       -3.37587762e+00, -1.30376315e+00,  5.08445930e+00, -1.68504322e+00,
       -1.60081315e+00, -8.33779454e-01, -7.58818448e-01, -1.78838921e+00,
        2.44672084e+00,  2.27579999e+00, -2.52457595e+00,  1.36214256e-01,
       -3.09675723e-01, -6.98232710e-01,  1.73018420e+00, -8.05342972e-01,
       -1.70148358e-01, -2.43612671e+00, -1.23085886e-01,  2.83124876e+00,
        3.89446110e-01, -3.16048344e-03, -2.09607935e+00, -1.49788404e+00,
        8.58029604e-01, -1.26923633e+00,  1.86084434e-01,  9.13471103e-01,
        1.53111053e+00, -2.57916182e-01,  1.83742964e+00,  1.50475979e+00,
        6.84375539e-02,  2.76320624e+00,  1.02619076e+00,  9.41017449e-01,
        1.66149962e+00, -2.49254084e+00, -7.78038025e-01, -6.52620196e-01,
       -1.59455287e+00, -4.13568115e+00,  2.78383470e+00, -5.71591198e-01,
       -8.45031738e-01,  4.54110718e+00,  1.67990357e-01,  2.12474012e+00,
       -2.25404716e+00, -8.35567772e-01,  9.91619170e-01, -2.55307484e+00,
        2.39850569e+00,  7.65280128e-01,  2.64600372e+00,  2.58998632e-01,
       -6.56729996e-01, -1.55601549e+00,  1.49751770e+00,  8.47311080e-01,
       -2.05665565e+00, -1.14815748e+00,  1.97350585e+00,  1.02964830e+00,
       -3.87644440e-01, -9.38048363e-01, -2.55545706e-01, -7.02206418e-03,
       -2.94358826e+00, -7.96167493e-01,  1.59571424e-01,  1.25497723e+00,
        7.12080002e-01, -1.34656525e+00,  1.54059935e+00, -1.12930894e+00,
       -3.66737366e+00, -7.17270374e-01, -2.69604278e+00,  1.90242791e+00,
        9.33268607e-01, -4.67624277e-01,  3.51641893e+00,  5.66355512e-02,
       -1.31763351e+00,  1.53379011e+00,  2.32190108e+00, -5.21186776e-02,
        4.06406015e-01,  4.48809415e-01, -3.68958092e+00, -1.01650321e+00,
       -1.08470261e+00, -1.93710685e+00,  2.27287245e+00, -6.63952589e-01,
        1.88207674e+00, -1.20226216e+00,  1.08953261e+00,  1.32847381e+00,
        1.38213491e+00,  1.47196710e+00, -2.06643629e+00,  1.99588931e+00,
       -1.64155555e+00, -2.24964902e-01, -2.74115324e+00, -3.16747665e+00,
        1.24095821e+00, -4.10616726e-01, -3.48466903e-01,  1.38452172e+00,
       -1.45676279e+00, -3.54911834e-02, -4.73554075e-01, -4.23114252e+00,
        1.52749741e+00,  7.25808144e-01, -4.50003862e-01, -3.16014004e+00,
        2.60309219e+00, -2.11320925e+00,  3.61347020e-01,  1.73625088e+00,
        1.57609022e+00, -2.08762145e+00,  2.18810892e+00,  1.20706499e+00,
       -1.82370770e+00,  1.22358835e+00, -8.91464829e-01, -3.30527711e+00,
       -3.72515142e-01, -6.23329699e-01,  8.11975658e-01, -8.52464736e-01,
       -9.35325995e-02, -4.06904364e+00,  1.57146180e+00,  7.85030201e-02,
        1.94540334e+00,  2.13809991e+00, -1.58913553e+00, -3.81727874e-01,
       -2.08527303e+00,  5.89691937e-01,  2.55564898e-01,  2.38364622e-01,
        3.64680409e+00,  4.18930590e-01,  1.62034535e+00, -4.63252217e-02,
        5.80206394e-01,  5.55441022e-01,  1.91946900e+00, -1.89253080e+00,
        1.77489519e+00, -3.15311766e+00,  6.48138940e-01,  1.15823770e+00,
       -2.54519200e+00, -1.03516951e-01,  1.15724599e+00, -1.83681571e+00,
       -9.87860620e-01, -1.99984312e+00,  2.76547909e-01,  8.02748859e-01,
        1.99196494e+00, -1.43310416e+00, -2.03039408e+00, -7.19777197e-02],
      dtype=float32)
</code></pre>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#查询多个词的词向量</span>
<span class="n">wv</span><span class="o">.</span><span class="n">get_mean_vector</span><span class="p">([</span><span class="s1">&#39;创新&#39;</span><span class="p">,</span> <span class="s1">&#39;研发&#39;</span><span class="p">])</span>
</code></pre></div><p>Ruj</p>
<pre><code>array([ 0.17623448, -0.02220692, -0.01040847,  0.03616136,  0.04931263,
       -0.06220303, -0.02846557, -0.00156435,  0.04524047,  0.03185674,
        0.01104859,  0.06962118, -0.01969986, -0.10831943, -0.0524368 ,
        0.00623383, -0.04149605, -0.004912  ,  0.13154642, -0.04317038,
       -0.00407438,  0.00923527, -0.13339072,  0.01446994, -0.00153984,
        0.12378754, -0.06064663,  0.09322313, -0.07711462, -0.05880795,
        0.13697049,  0.0133168 ,  0.02769322,  0.02677607,  0.02549294,
       -0.04504526,  0.06267191,  0.02421109, -0.13401456,  0.01423616,
        0.01860182,  0.00344108,  0.04811918,  0.02748652,  0.0190251 ,
       -0.03800797,  0.01517046,  0.06439836,  0.01320594,  0.04748138,
       -0.08914943, -0.00642068,  0.01786153, -0.02472607, -0.04597819,
        0.05832303,  0.11275461, -0.0387079 ,  0.06912261,  0.05287468,
       -0.04447906,  0.10994074, -0.04371417,  0.01227543,  0.07498093,
       -0.11285575, -0.03113984, -0.01122221, -0.03913497, -0.12117577,
        0.08593786, -0.04319173, -0.01860389,  0.15636683,  0.02267851,
        0.0922839 , -0.12106322, -0.07572737,  0.0191772 , -0.00977821,
        0.00455545,  0.01378978,  0.04774487, -0.02080727,  0.01015578,
       -0.04695337,  0.0848957 , -0.01112909, -0.03210922,  0.01151857,
        0.02214565,  0.03220333, -0.02468888, -0.07493623, -0.03724978,
       -0.00716823, -0.12043905, -0.0560291 , -0.00666756,  0.03659805,
        0.0532646 , -0.05371486,  0.06905847,  0.00660356, -0.10362111,
       -0.0015829 , -0.13282564,  0.08241726,  0.00993685,  0.04208402,
        0.03087696,  0.04765649, -0.00834742,  0.07236902,  0.04473683,
       -0.02643864, -0.0050621 ,  0.04462356, -0.0832998 , -0.05533891,
        0.00664944, -0.13001585,  0.07607447, -0.00764748,  0.01410657,
       -0.03057465,  0.0250505 ,  0.09252612, -0.00784517,  0.0386237 ,
       -0.059011  ,  0.05357389, -0.04604931,  0.04388874, -0.0971131 ,
       -0.09777305,  0.02943253, -0.04103448, -0.03944859,  0.09638489,
       -0.02226706,  0.02822194, -0.0093646 , -0.11203568,  0.06142627,
        0.04761236,  0.02720375, -0.09777595,  0.04048391, -0.06758034,
       -0.01500905,  0.02439078,  0.07150253, -0.02562411,  0.02533657,
        0.00799897, -0.06416934,  0.03153701, -0.03944302, -0.04653639,
       -0.04123383, -0.01590026,  0.03051148, -0.02014856, -0.01448381,
       -0.10517117, -0.00649814,  0.02478252,  0.02855514,  0.09052269,
       -0.03505059, -0.03173327, -0.06641324,  0.06284194,  0.01993516,
        0.01349441,  0.1410133 , -0.05283241,  0.03687092, -0.02535007,
        0.00415636,  0.05841105,  0.07389537, -0.13176979,  0.06759793,
       -0.092868  ,  0.01370211,  0.06616284, -0.09137756, -0.01640504,
        0.06095972, -0.05725639, -0.04122292,  0.00598698,  0.02904861,
        0.0442962 ,  0.07399555, -0.04657119, -0.07636161,  0.03204561],
      dtype=float32)
</code></pre>
<p>有了每个词或者概念的向量，可以结合cntext旧版本单语言模型内的态度偏见的度量。</p>
<p><br><br></p>
<h2 id="四扩展词典">四、扩展词典</h2>
<p>做词典法的文本分析，最重要的是有自己的领域词典。之前受限于技术难度，文科生的我也一直在用形容词的通用情感词典。现在依托word2vec技术， 可以加速人工构建的准确率和效率。</p>
<p>下面是在 mda01-21.200.6.bin 上做的词典扩展测试，函数expand_dictionary会根据种子词选取最准确的topn个词。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#短视主义词  实验</span>
<span class="n">expand_dictionary</span><span class="p">(</span><span class="n">wv</span><span class="o">=</span><span class="n">wv</span><span class="p">,</span> 
                  <span class="n">seedwords</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;抓紧&#39;</span><span class="p">,</span> <span class="s1">&#39;立刻&#39;</span><span class="p">,</span> <span class="s1">&#39;月底&#39;</span><span class="p">,</span> <span class="s1">&#39;年底&#39;</span><span class="p">,</span> <span class="s1">&#39;年终&#39;</span><span class="p">,</span> <span class="s1">&#39;争取&#39;</span><span class="p">,</span> <span class="s1">&#39;力争&#39;</span><span class="p">],</span>
                  <span class="n">topn</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<pre><code>['抓紧',
 '立刻',
 '月底',
 '年底',
 '年终',
 '争取',
 '力争',
 '争取',
 '力争',
 '年内',
 '月底',
 '年底',
 '尽早',
 '3月底',
 '尽快',
 '抓紧',
 '6月份',
 '4月份',
 '月份',
 '工作力争',
 '努力争取',
 '工作争取',
 '10月底',
 '年内实现',
 '年底完成',
 '中旬',
 '7月份',
 '9月底',
 '有望',
 '月底前',
 '早日',
 '全力',
 '继续',
 '月初',
 '努力',
 '确保',
 '8月份']
</code></pre>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">expand_dictionary</span><span class="p">(</span><span class="n">wv</span><span class="o">=</span><span class="n">wv</span><span class="p">,</span> 
                  <span class="n">seedwords</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;团结&#39;</span><span class="p">,</span> <span class="s1">&#39;拼搏&#39;</span><span class="p">,</span>  <span class="s1">&#39;克服&#39;</span><span class="p">,</span>  <span class="s1">&#39;勇攀高峰&#39;</span><span class="p">,</span>  <span class="s1">&#39;友善&#39;</span><span class="p">,</span>  <span class="s1">&#39;进取&#39;</span><span class="p">],</span>
                  <span class="n">topn</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<pre><code>['团结',
 '拼搏',
 '克服',
 '勇攀高峰',
 '友善',
 '进取',
 '拼搏',
 '艰苦奋斗',
 '坚定信念',
 '团结拼搏',
 '上下同心',
 '团结',
 '顽强拼搏',
 '勇于担当',
 '团结一致',
 '团结奋进',
 '精诚团结',
 '齐心协力',
 '开拓进取',
 '奋进',
 '团结一心',
 '实干',
 '同心协力',
 '团结协作',
 '锐意进取',
 '积极进取',
 '奋力拼搏',
 '拼搏精神',
 '努力拼搏',
 '进取',
 '奋发有为',
 '扎实工作',
 '同心同德',
 '拼搏进取',
 '脚踏实地',
 '励精图治']
</code></pre>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">expand_dictionary</span><span class="p">(</span><span class="n">wv</span><span class="o">=</span><span class="n">wv</span><span class="p">,</span> 
                  <span class="n">seedwords</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;创新&#39;</span><span class="p">,</span> <span class="s1">&#39;科技&#39;</span><span class="p">,</span>  <span class="s1">&#39;研发&#39;</span><span class="p">,</span>  <span class="s1">&#39;技术&#39;</span><span class="p">,</span>  <span class="s1">&#39;标准&#39;</span><span class="p">],</span>
                  <span class="n">topn</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<pre><code>['创新',
 '科技',
 '研发',
 '技术',
 '标准',
 '创新',
 '技术创新',
 '技术研发',
 '科技创新',
 '先进技术',
 '自主创新',
 '前沿技术',
 '关键技术',
 '科研',
 '新技术',
 '创新性',
 '研发创新',
 '产品研发',
 '基础研究',
 '产品开发',
 '集成创新',
 '核心技术',
 '自主研发',
 '技术应用',
 '技术集成',
 '前沿科技',
 '技术标准',
 '工艺技术',
 '科技成果',
 '技术开发',
 '尖端技术',
 '工程技术',
 '技术相结合',
 '科学技术',
 '工艺']
</code></pre>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">expand_dictionary</span><span class="p">(</span><span class="n">wv</span><span class="o">=</span><span class="n">wv</span><span class="p">,</span> 
                  <span class="n">seedwords</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;竞争&#39;</span><span class="p">,</span> <span class="s1">&#39;竞争力&#39;</span><span class="p">],</span>
                  <span class="n">topn</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<pre><code>['竞争',
 '竞争力',
 '竞争能力',
 '竞争优势',
 '市场竞争',
 '竞',
 '市场竞争力',
 '竞争实力',
 '参与市场竞争',
 '国际竞争',
 '市场竞争能力',
 '核心竞争力',
 '激烈竞争',
 '市场竞争优势',
 '竞争态势',
 '参与竞争',
 '竞争力重要',
 '竞争对手',
 '创新能力',
 '综合竞争力',
 '价格竞争',
 '之间竞争',
 '核心竞争能力',
 '未来市场竞争',
 '国际竞争力',
 '影响力竞争力',
 '国际化竞争',
 '行业竞争',
 '综合竞争能力',
 '竞争日趋激烈',
 '产品竞争力',
 '竞争力影响力']
</code></pre>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">expand_dictionary</span><span class="p">(</span><span class="n">wv</span><span class="o">=</span><span class="n">wv</span><span class="p">,</span> 
                  <span class="n">seedwords</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;疫情&#39;</span><span class="p">,</span> <span class="s1">&#39;扩散&#39;</span><span class="p">,</span> <span class="s1">&#39;防控&#39;</span><span class="p">,</span> <span class="s1">&#39;反复&#39;</span><span class="p">,</span> <span class="s1">&#39;冲击&#39;</span><span class="p">],</span>
                  <span class="n">topn</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<pre><code>['疫情',
 '扩散',
 '防控',
 '反复',
 '冲击',
 '蔓延',
 '疫情冲击',
 '疫情爆发',
 '新冠疫情',
 '新冠肺炎',
 '疫情蔓延',
 '疫情暴发',
 '肆虐',
 '本次疫情',
 '冲击疫情',
 '新冠病毒',
 '疫情扩散',
 '全球蔓延',
 '疫情影响',
 '病毒疫情',
 '肺炎疫情',
 '击',
 '持续蔓延',
 '疫情持续',
 '各地疫情',
 '疫情突然',
 '疫情全球',
 '疫情传播',
 '疫情反复',
 '散发',
 '变异毒株',
 '疫情导致',
 '疫情肆虐',
 '全球疫情',
 '全球新冠']
</code></pre>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">expand_dictionary</span><span class="p">(</span><span class="n">wv</span><span class="o">=</span><span class="n">wv</span><span class="p">,</span> 
                  <span class="n">seedwords</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;旧&#39;</span><span class="p">,</span> <span class="s1">&#39;老&#39;</span><span class="p">,</span> <span class="s1">&#39;后&#39;</span><span class="p">,</span> <span class="s1">&#39;落后&#39;</span><span class="p">],</span>
                  <span class="n">topn</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<pre><code>['旧',
 '老',
 '后',
 '落后',
 '旧',
 '老',
 '陈旧',
 '老旧',
 '淘汰',
 '高能耗',
 '低效率',
 '设备陈旧',
 '能耗高',
 '老旧设备',
 '落后工艺',
 '进行改造',
 '工艺落后',
 '技术落后',
 '翻新',
 '更新改造',
 '改造',
 '更新',
 '替换',
 '改造更新',
 '旧设备',
 '污染重',
 '淘汰一批',
 '拆除',
 '污染严重',
 '简陋',
 '产能落后',
 '相对落后',
 '产能淘汰',
 '效率低下']
</code></pre>
<p><br><br></p>
<h2 id="五源代码">五、源代码</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">gensim.models</span> <span class="kn">import</span> <span class="n">KeyedVectors</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>


<span class="k">def</span> <span class="nf">load_w2v</span><span class="p">(</span><span class="n">w2v_path</span><span class="p">):</span>
    <span class="s2">&#34;&#34;&#34;
</span><span class="s2">    Load word2vec model
</span><span class="s2">
</span><span class="s2">    Args:
</span><span class="s2">        w2v_path (str): path of word2vec model
</span><span class="s2">
</span><span class="s2">    Returns:
</span><span class="s2">        model: word2vec model
</span><span class="s2">    &#34;&#34;&#34;</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Loading word2vec model...&#39;</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">KeyedVectors</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">w2v_path</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">model</span>


<span class="k">def</span> <span class="nf">expand_dictionary</span><span class="p">(</span><span class="n">wv</span><span class="p">,</span> <span class="n">seedwords</span><span class="p">,</span> <span class="n">topn</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
    <span class="s2">&#34;&#34;&#34;
</span><span class="s2">    According to the seed word file, select the top n words with the most similar semantics and save them in the directory save_dir.
</span><span class="s2">    
</span><span class="s2">    Args:
</span><span class="s2">        wv (Word2VecKeyedVectors): the word embedding model
</span><span class="s2">        seedwords (list): 种子词
</span><span class="s2">        topn (int, optional): Set the number of most similar words to retrieve to topn. Defaults to 100.
</span><span class="s2">        save_dir (str, optional): the directory to save the candidate words. Defaults to &#39;Word2Vec&#39;.
</span><span class="s2">    
</span><span class="s2">    Returns:
</span><span class="s2">    &#34;&#34;&#34;</span>
    <span class="n">simidx_scores</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="n">similars_candidate_idxs</span> <span class="o">=</span> <span class="p">[]</span> <span class="c1">#the candidate words of seedwords</span>
    <span class="n">dictionary</span> <span class="o">=</span> <span class="n">wv</span><span class="o">.</span><span class="n">key_to_index</span>
    <span class="n">seedidxs</span> <span class="o">=</span> <span class="p">[]</span> <span class="c1">#transform word to index</span>
    <span class="k">for</span> <span class="n">seed</span> <span class="ow">in</span> <span class="n">seedwords</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">seed</span> <span class="ow">in</span> <span class="n">dictionary</span><span class="p">:</span>
            <span class="n">seedidx</span> <span class="o">=</span> <span class="n">dictionary</span><span class="p">[</span><span class="n">seed</span><span class="p">]</span>
            <span class="n">seedidxs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">seedidx</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">seedidx</span> <span class="ow">in</span> <span class="n">seedidxs</span><span class="p">:</span>
        <span class="c1"># sims_words such as [(&#39;by&#39;, 0.99984), (&#39;or&#39;, 0.99982), (&#39;an&#39;, 0.99981), (&#39;up&#39;, 0.99980)]</span>
        <span class="n">sims_words</span> <span class="o">=</span> <span class="n">wv</span><span class="o">.</span><span class="n">similar_by_word</span><span class="p">(</span><span class="n">seedidx</span><span class="p">,</span> <span class="n">topn</span><span class="o">=</span><span class="n">topn</span><span class="p">)</span>
        <span class="c1">#Convert words to index and store them</span>
        <span class="n">similars_candidate_idxs</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="n">dictionary</span><span class="p">[</span><span class="n">sim</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span> <span class="k">for</span> <span class="n">sim</span> <span class="ow">in</span> <span class="n">sims_words</span><span class="p">])</span>
    <span class="n">similars_candidate_idxs</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">similars_candidate_idxs</span><span class="p">)</span>
    
    <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">similars_candidate_idxs</span><span class="p">:</span>
        <span class="n">score</span> <span class="o">=</span> <span class="n">wv</span><span class="o">.</span><span class="n">n_similarity</span><span class="p">([</span><span class="n">idx</span><span class="p">],</span> <span class="n">seedidxs</span><span class="p">)</span>
        <span class="n">simidx_scores</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">idx</span><span class="p">,</span> <span class="n">score</span><span class="p">))</span>
    <span class="n">simidxs</span> <span class="o">=</span> <span class="p">[</span><span class="n">w</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">simidx_scores</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">k</span><span class="p">:</span><span class="n">k</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)]</span>

    <span class="n">simwords</span> <span class="o">=</span> <span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">wv</span><span class="o">.</span><span class="n">index_to_key</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">simidxs</span><span class="p">][:</span><span class="n">topn</span><span class="p">]</span>

    <span class="n">resultwords</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">resultwords</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">seedwords</span><span class="p">)</span>
    <span class="n">resultwords</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">simwords</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">resultwords</span>
</code></pre></div><p><br><br></p>
<h2 id="获取模型">获取模型</h2>
<p>模型训练不易， 为付费资源，如需使用请 <a href="https://mp.weixin.qq.com/s/zle9-BR-ei1V8Nmul19_7w"><strong>点击进入跳转购买链接</strong></a></p>
<p><br><br></p>
<h2 id="期待合作">期待合作</h2>
<p>cntext目前仍在技术迭代，版本2.0.0综合了训练语言模型&amp;多语言模型对齐， 有较大的应用价值，期待有独特文本数据集交流合作。</p>
<p>通过cntext2.0.0，理论上可以对文本所涉社会主体进行计算，适合企业文化、品牌印象、旅游目的地形象、国家形象等</p>
<ul>
<li>同主体不同时间段， 文本中蕴含的文化态度认知变迁，</li>
<li>或同时间段，不同主体的大样本文本蕴含的差异性</li>
</ul>
<p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>可视化 | 睡前消息的科学社会、科学技术、社会化抚养话题可视化</title>
      <link>https://textdata.cn/blog/2023-03-22-bedtime-topic_model_visualization/</link>
      <pubDate>Wed, 22 Mar 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-03-22-bedtime-topic_model_visualization/</guid>
      <description>睡前消息是我最喜欢看的节目， 基本上隔两天不看睡不踏实。本次分享，不涉及观点之争，纯属技术玩乐。</description>
      <content:encoded><![CDATA[<p>我的信仰是科学的唯物史观，虽然一直觉得爷爷是伟人，但是没有系统钻研小本本，所以似懂非懂，好在有睡前消息这个节目，可以时不时的聆听到半个世纪前的伟人智慧。</p>
<p><img loading="lazy" src="img/df4.png" alt=""  />
</p>
<p><img loading="lazy" src="img/%e7%a7%91%e5%ad%a6%e7%a4%be%e4%bc%9a.png" alt=""  />
</p>
<br>
<h2 id="一读取数据">一、读取数据</h2>
<p>睡前消息是我最喜欢看的节目， 基本上隔两天不看睡不踏实。本次分享，不涉及观点之争，纯属技术玩乐。</p>
<p><a href="https://textdata.cn/blog/2023-03-06-bedtime-news-datasets/">数据集 | 马前卒工作室睡前消息文稿汇总</a></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>


<span class="n">bed_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;bedtime_news.csv&#39;</span><span class="p">,</span> <span class="n">converters</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;date&#39;</span><span class="p">:</span> <span class="nb">str</span><span class="p">})</span>
<span class="n">bed_df</span><span class="o">.</span><span class="n">date</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">bed_df</span><span class="o">.</span><span class="n">date</span><span class="p">)</span>
<span class="n">bed_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/df1.png" alt=""  />
</p>
<Br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#数据集起始日期</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">bed_df</span><span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">())[:</span><span class="mi">10</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">bed_df</span><span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">())[:</span><span class="mi">10</span><span class="p">])</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">2019-07-12
2022-11-29
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#数据集含有的节目数</span>
<span class="nb">len</span><span class="p">(</span><span class="n">bed_df</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">522
</code></pre></div><br>
<br>
<h2 id="二准备工作">二、准备工作</h2>
<h3 id="21-自定义词典">2.1 自定义词典</h3>
<ul>
<li>科学、技术</li>
<li>社会化抚养</li>
<li>债务、独山县</li>
<li>中医、以岭药业</li>
</ul>
<p>将感兴趣的词加入到jieba自定义词典中，防止被错分。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">jieba</span>

<span class="n">diywords</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;科学&#39;</span><span class="p">,</span> <span class="s1">&#39;技术&#39;</span><span class="p">,</span> <span class="s1">&#39;社会化抚养&#39;</span><span class="p">,</span> <span class="s1">&#39;债务&#39;</span><span class="p">,</span> <span class="s1">&#39;独山县&#39;</span><span class="p">,</span> <span class="s1">&#39;毛选&#39;</span><span class="p">,</span> <span class="s1">&#39;唯物&#39;</span><span class="p">,</span> <span class="s1">&#39;社会实验&#39;</span><span class="p">]</span>
<span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">diywords</span><span class="p">:</span>
    <span class="n">jieba</span><span class="o">.</span><span class="n">add_word</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
</code></pre></div><br>
<h3 id="22-word_in_context">2.2 word_in_context</h3>
<p>在这里定义了一个word_in_context函数，可以查看某些关键词上下文环境。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">jieba</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">from</span> <span class="nn">nltk.tokenize</span> <span class="kn">import</span> <span class="n">word_tokenize</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">warnings</span>


<span class="k">def</span> <span class="nf">word_in_context</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">keywords</span><span class="p">,</span> <span class="n">window</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">lang</span><span class="o">=</span><span class="s1">&#39;chinese&#39;</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">lang</span><span class="o">==</span><span class="s1">&#39;chinese&#39;</span><span class="p">:</span>
        <span class="n">words</span> <span class="o">=</span> <span class="n">jieba</span><span class="o">.</span><span class="n">lcut</span><span class="p">(</span><span class="n">text</span><span class="o">.</span><span class="n">lower</span><span class="p">())</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">words</span> <span class="o">=</span> <span class="n">word_tokenize</span><span class="p">(</span><span class="n">text</span><span class="o">.</span><span class="n">lower</span><span class="p">())</span>
        <span class="k">except</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&#34;你应该安装nltk和对应的nltk_data, 请看B站https://www.bilibili.com/video/BV14A411i7DB&#34;</span><span class="p">)</span>
            <span class="n">words</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39; &#39;</span><span class="p">)</span>
    <span class="n">keywords</span> <span class="o">=</span> <span class="p">[</span><span class="n">w</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">keywords</span><span class="p">]</span>
    <span class="n">kw_idxss</span> <span class="o">=</span> <span class="p">[[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">words</span><span class="p">)</span> <span class="k">if</span> <span class="n">x</span> <span class="o">==</span> <span class="n">keyword</span><span class="p">]</span> <span class="k">for</span> <span class="n">keyword</span> <span class="ow">in</span> <span class="n">keywords</span><span class="p">]</span>
    <span class="n">rows</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">keyword</span><span class="p">,</span> <span class="n">kw_idxs</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">keywords</span><span class="p">,</span> <span class="n">kw_idxss</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">kw_idxs</span><span class="p">:</span>
            <span class="n">half</span> <span class="o">=</span> <span class="nb">int</span><span class="p">((</span><span class="n">window</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span>
            <span class="n">start</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">idx</span> <span class="o">-</span> <span class="n">half</span><span class="p">)</span>
            <span class="n">end</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">words</span><span class="p">),</span> <span class="n">idx</span> <span class="o">+</span> <span class="n">half</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">row</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;keyword&#39;</span><span class="p">:</span> <span class="n">keyword</span><span class="p">,</span> 
                   <span class="s1">&#39;context&#39;</span><span class="p">:</span> <span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">words</span><span class="p">[</span><span class="n">start</span><span class="p">:</span> <span class="n">end</span><span class="p">])</span> <span class="k">if</span> <span class="n">lang</span><span class="o">==</span><span class="s1">&#39;chinese&#39;</span> <span class="k">else</span> <span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">words</span><span class="p">[</span><span class="n">start</span><span class="p">:</span> <span class="n">end</span><span class="p">])</span>
                      <span class="p">}</span>
            <span class="n">rows</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">row</span><span class="p">)</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">rows</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">df</span>


<span class="c1">#测试【打算】前后上下文5个单词</span>
<span class="n">word_in_context</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="s1">&#39;根本没打算过真抓到人，当然也不打算付钱。转发推送：还有一个话题&#39;</span><span class="p">,</span> 
                <span class="n">keywords</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;打算&#39;</span><span class="p">],</span> 
                <span class="n">window</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> 
                <span class="n">lang</span><span class="o">=</span><span class="s1">&#39;chinese&#39;</span><span class="p">)</span>
</code></pre></div><br>
<h3 id="23-词云图">2.3 词云图</h3>
<p>pip install pyecharts==2.0.1</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">plot_wordcloud</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">title</span><span class="p">):</span>
    <span class="kn">import</span> <span class="nn">pyecharts.options</span> <span class="k">as</span> <span class="nn">opts</span>
    <span class="kn">from</span> <span class="nn">pyecharts.charts</span> <span class="kn">import</span> <span class="n">WordCloud</span>
    <span class="n">text</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;context&#39;</span><span class="p">])</span>
    <span class="n">text</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">re</span><span class="o">.</span><span class="n">findall</span><span class="p">(</span><span class="s1">&#39;[</span><span class="se">\u4e00</span><span class="s1">-</span><span class="se">\u9fa5</span><span class="s1">]+&#39;</span><span class="p">,</span> <span class="n">text</span><span class="p">))</span>
    <span class="n">words</span> <span class="o">=</span> <span class="n">jieba</span><span class="o">.</span><span class="n">lcut</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
    <span class="n">words</span> <span class="o">=</span> <span class="p">[</span><span class="n">w</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">words</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">w</span><span class="p">)</span><span class="o">&gt;=</span><span class="mi">2</span><span class="p">]</span>
    <span class="n">wordfreqs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="nb">set</span><span class="p">(</span><span class="n">words</span><span class="p">):</span>
        <span class="n">freq</span> <span class="o">=</span> <span class="n">words</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
        <span class="n">wordfreqs</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">word</span><span class="p">,</span> <span class="n">freq</span><span class="p">))</span>
    <span class="n">wordfreqs</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">wordfreqs</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">k</span><span class="p">:</span><span class="n">k</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">wordfreqs</span> <span class="o">=</span> <span class="p">[(</span><span class="n">w</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">f</span><span class="p">))</span> <span class="k">for</span> <span class="n">w</span><span class="p">,</span><span class="n">f</span> <span class="ow">in</span> <span class="n">wordfreqs</span><span class="p">]</span>
    <span class="n">cloud</span> <span class="o">=</span> <span class="n">WordCloud</span><span class="p">()</span>
    <span class="n">cloud</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">series_name</span><span class="o">=</span><span class="s2">&#34;&#34;</span><span class="p">,</span> <span class="n">data_pair</span><span class="o">=</span><span class="n">wordfreqs</span><span class="p">,</span> <span class="n">word_size_range</span><span class="o">=</span><span class="p">[</span><span class="mi">20</span><span class="p">,</span> <span class="mi">100</span><span class="p">])</span>
    <span class="n">cloud</span><span class="o">.</span><span class="n">set_global_opts</span><span class="p">(</span><span class="n">title_opts</span><span class="o">=</span><span class="n">opts</span><span class="o">.</span><span class="n">TitleOpts</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="n">title</span><span class="p">,</span> 
                                                    <span class="n">title_textstyle_opts</span><span class="o">=</span><span class="n">opts</span><span class="o">.</span><span class="n">TextStyleOpts</span><span class="p">(</span><span class="n">font_size</span><span class="o">=</span><span class="mi">23</span><span class="p">)),</span>
                          <span class="n">tooltip_opts</span><span class="o">=</span><span class="n">opts</span><span class="o">.</span><span class="n">TooltipOpts</span><span class="p">(</span><span class="n">is_show</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
    <span class="n">cloud</span><span class="o">.</span><span class="n">render</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">{}</span><span class="s1">.html&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">title</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">cloud</span><span class="o">.</span><span class="n">render_notebook</span><span class="p">()</span>
</code></pre></div><p><br><br></p>
<h2 id="三话题分析">三、话题分析</h2>
<p>相比LDA机器学习算法的晦涩难懂，其实可以用word_in_context对指定关键词进行定位和分析，数据处理的过程清晰透明。</p>
<h3 id="31-topic-社会化抚养">3.1 Topic-社会化抚养</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">dfs</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">bed_df</span><span class="o">.</span><span class="n">iterrows</span><span class="p">():</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">word_in_context</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="n">row</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">],</span> 
                            <span class="n">keywords</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;社会化抚养&#39;</span><span class="p">],</span> 
                            <span class="n">window</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>
    <span class="n">df</span><span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">row</span><span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">]</span>
    <span class="n">dfs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
    
<span class="n">topic_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">dfs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">topic_df</span>
</code></pre></div><p><img loading="lazy" src="img/df2.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#涉及该主题的节目数</span>
<span class="nb">len</span><span class="p">(</span><span class="n">topic_df</span><span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">())</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">65
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#占比</span>
<span class="nb">len</span><span class="p">(</span><span class="n">topic_df</span><span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">())</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">bed_df</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">0.12452107279693486
</code></pre></div><br>
<p>在咱们这个数据集中，睡前消息500多期节目中，有65期谈及社会化抚养的，比例12%。</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">plot_wordcloud</span><span class="p">(</span><span class="n">df</span><span class="o">=</span><span class="n">topic_df</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s1">&#39;社会化抚养&#39;</span><span class="p">)</span>
</code></pre></div><p><img loading="lazy" src="img/%e7%a4%be%e4%bc%9a%e5%8c%96%e6%8a%9a%e5%85%bb.png" alt=""  />
</p>
<br>
<h3 id="32-topic-科学技术">3.2 Topic-科学技术</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">dfs2</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">bed_df</span><span class="o">.</span><span class="n">iterrows</span><span class="p">():</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">word_in_context</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="n">row</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">],</span> 
                            <span class="n">keywords</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;科学&#39;</span><span class="p">,</span> <span class="s1">&#39;技术&#39;</span><span class="p">],</span> 
                            <span class="n">window</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>
    <span class="n">df</span><span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">row</span><span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">]</span>
    <span class="n">dfs2</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
    
<span class="n">topic_df2</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">dfs2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">topic_df2</span>
</code></pre></div><p><img loading="lazy" src="img/df3.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#涉及该主题的节目数</span>
<span class="nb">len</span><span class="p">(</span><span class="n">topic_df2</span><span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">())</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">411
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#占比</span>
<span class="nb">len</span><span class="p">(</span><span class="n">topic_df2</span><span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">())</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">bed_df</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">0.7873563218390804
</code></pre></div><br>
<p>在咱们这个数据集中，睡前消息500多期节目中，有411期谈及社会化抚养的，比例79%。</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">plot_wordcloud</span><span class="p">(</span><span class="n">df</span><span class="o">=</span><span class="n">topic_df</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s1">&#39;科学技术&#39;</span><span class="p">)</span>
</code></pre></div><p><img loading="lazy" src="img/%e7%a7%91%e5%ad%a6%e6%8a%80%e6%9c%af.png" alt=""  />
</p>
<br>
<h2 id="33-科学社会">3.3 科学社会</h2>
<p>面对社会问题，睡前消息倡导科学社会实验， 也喜欢讲毛选语录， 两者所涉及的是唯物的观点，科学社会的观点。放在一起试试</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">dfs3</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">bed_df</span><span class="o">.</span><span class="n">iterrows</span><span class="p">():</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">word_in_context</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="n">row</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">],</span> 
                            <span class="n">keywords</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;毛选&#39;</span><span class="p">,</span> <span class="s1">&#39;唯物&#39;</span><span class="p">,</span> <span class="s1">&#39;社会实验&#39;</span><span class="p">],</span> 
                            <span class="n">window</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
    <span class="n">df</span><span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">row</span><span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">]</span>
    <span class="n">dfs3</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
    
<span class="n">topic_df3</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">dfs3</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">topic_df3</span>
</code></pre></div><p><img loading="lazy" src="img/df4.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#涉及该主题的节目数</span>
<span class="nb">len</span><span class="p">(</span><span class="n">topic_df3</span><span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">())</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">14
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="nb">len</span><span class="p">(</span><span class="n">topic_df3</span><span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">())</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">bed_df</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">0.02681992337164751
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">plot_wordcloud</span><span class="p">(</span><span class="n">df</span><span class="o">=</span><span class="n">topic_df3</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s1">&#39;科学社会&#39;</span><span class="p">)</span>
</code></pre></div><p><img loading="lazy" src="img/%e7%a7%91%e5%ad%a6%e7%a4%be%e4%bc%9a.png" alt=""  />
</p>
<br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>Nature | 通用中英文六维语义情感词典</title>
      <link>https://textdata.cn/blog/2023-03-20-nature-six-semantic-dimension-database/</link>
      <pubDate>Mon, 20 Mar 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-03-20-nature-six-semantic-dimension-database/</guid>
      <description>来自心理学和认知神经科学的证据表明，人类大脑的语义系统包含几个特定的子系统，每个子系统都代表语义信息的特定维度。对这些不同语义维度上的词语评分可以帮助研究语义维度对语言处理的行为和神经影响，并根据人类认知系统的语义空间建立语言含义的计算表示。现有的语义评分数据库提供了数百到数千个词语的评分，但这无法支持对自然文本或语音的全面语义分析。本文报告了一个大型数据库——六维语义数据库（SSDD， 后文「数据库」均用「词典」代替），其中包含对 17,940个常用汉语词语在六个主要语义维度上的主观评分：视觉、运动、社交、情感、时间和空间。此外，使用计算模型学习主观评分和词嵌入之间的映射关系，我们在SSDD中包括了1,427,992个汉语和1,515,633个英语词语的估计语义评分。SSDD将有助于自然语言处理、文本分析和大脑中的语义表示研究。</description>
      <content:encoded><![CDATA[<h2 id="应用价值">应用价值</h2>
<p>对于大量散落在网络中的文本数据， 可以度量用户在视觉、运动、社交、情感、时间和空间等维度上心理、认知、抽象层面的信息。</p>
<br>
<p>Wang, S., Zhang, Y., Shi, W. et al. A large dataset of semantic ratings and its computational extension. Sci Data 10, 106 (2023). <a href="https://doi.org/10.1038/s41597-023-01995-6">https://doi.org/10.1038/s41597-023-01995-6</a></p>
<p><img loading="lazy" src="img/cover.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="一摘要">一、摘要</h2>
<p>来自心理学和认知神经科学的证据表明，人类大脑的语义系统包含几个特定的子系统，每个子系统都代表语义信息的特定维度。对这些不同语义维度上的词语评分可以帮助研究语义维度对语言处理的行为和神经影响，并根据人类认知系统的语义空间建立语言含义的计算表示。现有的语义评分数据库提供了数百到数千个词语的评分，但这无法支持对自然文本或语音的全面语义分析。本文报告了一个大型数据库——<strong>六维语义数据库</strong>（SSDD， 后文「数据库」均用「词典」代替），其中包含对 <strong>17,940</strong> 个常用汉语词语在六个主要语义维度上的主观评分：<strong>视觉、运动、社交、情感、时间和空间</strong>。此外，使用计算模型学习主观评分和词嵌入之间的映射关系，我们在SSDD中包括了1,427,992个汉语和1,515,633个英语词语的估计语义评分。SSDD将有助于自然语言处理、文本分析和大脑中的语义表示研究。</p>
<p><br><br></p>
<h2 id="二背景">二、背景</h2>
<p>大量行为和神经证据表明，单词语义表示分布在不同的神经子系统中， 每个子系统代表着特定的语义信息维度。这些语义子系统和维度为人类语义系统的组织提供了重要线索。为了研究单词在人脑中的 <strong>意义表示</strong> 和 <strong>信息加工</strong>, 许多研究基于心理和神经生物学可行的语义维度，通过人员标准构建了单词的词典。与现有NLP领域的embeddings相比， 基于特定意义维度所构建的词典可以在经验语义纬度上提供量化的评分， 使得研究者可以调查语义维度对语言处理的行为和神经影响， 并建立语言含义的(表示)计算。</p>
<p>然而现有的词典只包含数百、数钱个词，不足以支持自然文本或语音的全面语义分析。该研究提供了一个大型的语义评分语义词典， 名为<strong>六维语义</strong>（Six Semantic Dimension Database，SSDD）词典， <strong>每个中英文词语含六个维度的得分(可以理解为效价valence),分别是视觉、运动、社交、情感、时间、空间</strong>。 其中视觉和运动维度反映了感觉运动体验对语义表示的影响。感觉和运动维度可能是最常研究的语义维度之一，它们对于对象和动作概念的重要性已经得到了很好的确认。在与语义表示相关的多个感官维度中，我们选择了视觉维度，因为视觉是主导的感觉模态。视觉和运动语义对认知处理的行为和神经影响已经被许多研究证实。社交和情感维度反映了社会情感体验对语义表示的影响。<strong>这些维度具有可分离的神经相关性，并且对于心理和抽象概念的表示尤其重要</strong>。Huth等人采用数据驱动方法研究了大脑中的语义表示组织，并发现社交情感和感官运动语义与最重要的数据驱动语义维度的两端相关联。因此，社交和情感维度可以作为视觉和运动维度的重要补充，以反映语义表示。时间和空间维度对于事件和情境的表示尤为重要。神经心理学和神经影像研究也表明这些维度具有可分离的神经相关性。Binder等人对经验语义属性进行了全面的综述，反映了六个维度的代表性。Binder等人总结了属于14个领域的65个语义维度，其中超过2/3的维度属于视觉、运动、社交、情感、时间和空间领域。SSDD将这六个领域作为粗粒度语义维度，并为每个维度提供了一般评分。</p>
<p><br><br></p>
<h2 id="三构建方法">三、构建方法</h2>
<h3 id="31-标准者被试人员">3.1 标准者(被试人员)</h3>
<p>该研究找了85位心理、神经都正常的本硕中国学生， 通过数据质量评估，最终保留了80位学生的数据标注结果。</p>
<br>
<h3 id="32-待标注的17940中文词">3.2 待标注的17940中文词</h3>
<p>待标注中文词，一共有17940个， 是由三种数据源筛选得来</p>
<ol>
<li>中文维基百科12814高频词</li>
<li>fMRI领域研究(发表&amp;未发表)的4915个中文词</li>
<li>最后一组项目是来自Binder等人和Tamir等人的语义评分实验中英文刺激词的211个汉语翻译。</li>
</ol>
<br>
<h3 id="33-标注过程">3.3 标注过程</h3>
<ul>
<li>该研究对17980个词进行了6个标注实验的， 每个实验聚焦于一个语义维度（视觉、运动、社交、情感、时间、空间）。</li>
<li>每个标注实验会分成18个session，每个session含1000个词(最后一个session有940个词)</li>
<li>标准过程使用问卷星</li>
<li>情绪维度标注的时候，使用13-point scale标准标注(-6表示非常负面， 0表示中性， 6表示非常积极)</li>
<li>剩下的5维（视觉、运动、社交、时间、空间）使用7-point scale标准标注(1表示非常低， 7表示非常高)</li>
<li>每次标注前， 标注者需要阅读标注指南，指南会含有一些语义例子。</li>
<li>为了控制标准数据质量， 保证每位标注者与所有标准者的相关性大于0.5，最终拒绝了28个session大概0.87%的数据量。</li>
</ul>
<br>
<h3 id="34-扩充词典">3.4 扩充词典</h3>
<p>标准的17940个中文词的六维度数据，可以认为是标准数据。用机器学习方法，想办法扩充词典。</p>
<p>该团队检验了语义上下文不敏感的词嵌入算法(word2vec/Glove)和 对上下文语义敏感的嵌入算法(GPT2, BERT ERNIE, and MacBERT) ，让这6类嵌入模型分别预测， 确定下表现效果较好的Word2vec和MacBERT算法。</p>
<p>使用Word2vec和MacBERT预测剩下所有的中文词，共扩展出1427992个中文词。</p>
<p>人类在视觉、运动、社交、情感、时间、空间六个维度上是共通的，结合语言嵌入模型可以在不同语言中进行语义空间对齐，该研究根据英文嵌入语言模型，也预测出了1,515,633个词。</p>
<br>
<br>
<h2 id="四ssdd">四、SSDD</h2>
<p>SSDD包含两个数据集：</p>
<ul>
<li>第一个是17,940个常用汉语词语在六个语义维度上的主观评分。</li>
<li>第二个是主观评分数据的计算扩展。我们将主观评分与计算模型相结合，然后估算出1,427,992个汉语和1,515,633个英语单词的语义评分。</li>
</ul>
<p>该研究标准、训练的源代码数据均已开源，https://osf.io/n5vke/</p>
<p><img loading="lazy" src="img/osf.png" alt=""  />
</p>
<p>由于数据量太大， 这里只给大家读取并显示17940个标注的6维语义数据, 其实对于经管社科研究， 标注的 <a href="Rated_semantic_dimensions.csv">17940个词</a> 已经是很大的情感词典了。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;Rated_semantic_dimensions.csv&#39;</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/df1.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#词汇量</span>
<span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">17940
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1"># 计算相关性矩阵</span>
<span class="n">df</span><span class="o">.</span><span class="n">corr</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/df2.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">corr_df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">corr</span><span class="p">()</span>
<span class="n">mark</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">cell</span><span class="p">:</span> <span class="s1">&#39;background-color: </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="s1">&#39;red&#39;</span> <span class="k">if</span> <span class="n">cell</span> <span class="o">&gt;</span> <span class="mf">0.4</span> <span class="k">else</span> <span class="s1">&#39;&#39;</span>
<span class="n">color_matrix</span> <span class="o">=</span> <span class="n">corr_df</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">applymap</span><span class="p">(</span><span class="n">mark</span><span class="p">)</span>
<span class="n">color_matrix</span>
</code></pre></div><p><img loading="lazy" src="img/df3.png" alt=""  />
</p>
<p>相关性最高的单元格是Motor与Vision， 6个维度相关性均小于0.5 ， 六维的选择是很合理。</p>
<p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>word_in_context | 查看某类词的上下文，更好的理解文本数据</title>
      <link>https://textdata.cn/blog/2023-03-19-word-in-context/</link>
      <pubDate>Sun, 19 Mar 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-03-19-word-in-context/</guid>
      <description>通过一个单词所处的语境，我们可以了解该单词的含义。**该谚语源于英国语言学家 J.R. Firth 的理论，他认为单词的含义是由其周围的语境和与之相伴的其他单词所决定的，因此我们需要通过单词出现的上下文来理解其含义。这一理论在语言学、自然语言处理等领域有着广泛的应用。之前分享过 [ 使用正则表达式、文本向量化、线性回归算法从md&amp;amp;a数据中计算 「企业融资约束指标」 ]， 使用的是正则表达式识别融资约束文本。但是正则表达式设计十分复杂且有难度，在此之前，如果能够查看某些融资关键词附近上下文， 可帮助研究者更全面地了解数据集中关键词的使用情况和语境，更好的设计正则表达式，亦或许意外找出新的有价值的线索。</description>
      <content:encoded><![CDATA[<p>Firth（1957）有一句名言，理解一个词要从ta身边入手。</p>
<blockquote>
<p>You shall know a word by the company it keeps</p>
</blockquote>
<p>通过一个单词所处的语境，我们可以了解该单词的含义。<strong>该谚语源于英国语言学家 J.R. Firth 的理论，他认为单词的含义是由其周围的语境和与之相伴的其他单词所决定的，因此我们需要通过单词出现的上下文来理解其含义。这一理论在语言学、自然语言处理等领域有着广泛的应用</strong>。之前分享过</p>
<p><img loading="lazy" src="img/39faq-firth_words.png" alt=""  />
</p>
<p>之前分享过 <a href="https://textdata.cn/blog/2023-12-31-using-regex-to-compute-the-financial_constraints"> 使用正则表达式、文本向量化、线性回归算法从md&amp;a数据中计算 「企业融资约束指标」 </a>， 使用的是正则表达式识别融资约束文本。但是正则表达式设计十分复杂且有难度，在此之前，如果能够查看某些融资关键词附近上下文， 可帮助研究者更全面地了解数据集中关键词的使用情况和语境，更好的设计正则表达式，亦或许意外找出新的有价值的线索。</p>
<br>
<h2 id="代码">代码</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">jieba</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">from</span> <span class="nn">nltk.tokenize</span> <span class="kn">import</span> <span class="n">word_tokenize</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">warnings</span>

<span class="k">def</span> <span class="nf">word_in_context</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">keywords</span><span class="p">,</span> <span class="n">window</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">lang</span><span class="o">=</span><span class="s1">&#39;chinese&#39;</span><span class="p">):</span>
    <span class="s2">&#34;&#34;&#34;
</span><span class="s2">    Given text and keywords, the task is to find the text where the keyword appears
</span><span class="s2">    Args:
</span><span class="s2">        text (str): input document, string format
</span><span class="s2">        keywords (list): keywords
</span><span class="s2">        window (int): return the text where the keyword appears, default is 3, meaning return 3 word.
</span><span class="s2">        lang (str, optional): setting the lang, only support chinese and english. Defaults to &#39;chinese&#39;.
</span><span class="s2">
</span><span class="s2">    Returns:
</span><span class="s2">        list contains multiple dictionaries, where each dictionary contains the sentence, keyword, and the sentence where the keyword appears
</span><span class="s2">    &#34;&#34;&#34;</span>
    <span class="k">if</span> <span class="n">lang</span><span class="o">==</span><span class="s1">&#39;chinese&#39;</span><span class="p">:</span>
        <span class="n">words</span> <span class="o">=</span> <span class="n">jieba</span><span class="o">.</span><span class="n">lcut</span><span class="p">(</span><span class="n">text</span><span class="o">.</span><span class="n">lower</span><span class="p">())</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">words</span> <span class="o">=</span> <span class="n">word_tokenize</span><span class="p">(</span><span class="n">text</span><span class="o">.</span><span class="n">lower</span><span class="p">())</span>
        <span class="k">except</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&#34;你应该安装nltk和对应的nltk_data, 请看B站https://www.bilibili.com/video/BV14A411i7DB&#34;</span><span class="p">)</span>
            <span class="n">words</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39; &#39;</span><span class="p">)</span>
    <span class="n">keywords</span> <span class="o">=</span> <span class="p">[</span><span class="n">w</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">keywords</span><span class="p">]</span>
    <span class="n">kw_idxss</span> <span class="o">=</span> <span class="p">[[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">words</span><span class="p">)</span> <span class="k">if</span> <span class="n">x</span> <span class="o">==</span> <span class="n">keyword</span><span class="p">]</span> <span class="k">for</span> <span class="n">keyword</span> <span class="ow">in</span> <span class="n">keywords</span><span class="p">]</span>
    <span class="n">rows</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">keyword</span><span class="p">,</span> <span class="n">kw_idxs</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">keywords</span><span class="p">,</span> <span class="n">kw_idxss</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">kw_idxs</span><span class="p">:</span>
            <span class="n">half</span> <span class="o">=</span> <span class="nb">int</span><span class="p">((</span><span class="n">window</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span>
            <span class="n">start</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">idx</span> <span class="o">-</span> <span class="n">half</span><span class="p">)</span>
            <span class="n">end</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">words</span><span class="p">),</span> <span class="n">idx</span> <span class="o">+</span> <span class="n">half</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">row</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;keyword&#39;</span><span class="p">:</span> <span class="n">keyword</span><span class="p">,</span> 
                   <span class="s1">&#39;context&#39;</span><span class="p">:</span> <span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">words</span><span class="p">[</span><span class="n">start</span><span class="p">:</span> <span class="n">end</span><span class="p">])</span> <span class="k">if</span> <span class="n">lang</span><span class="o">==</span><span class="s1">&#39;chinese&#39;</span> <span class="k">else</span> <span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">words</span><span class="p">[</span><span class="n">start</span><span class="p">:</span> <span class="n">end</span><span class="p">])</span>
                      <span class="p">}</span>
            <span class="n">rows</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">row</span><span class="p">)</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">rows</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">df</span>


</code></pre></div><p><br><br></p>
<h2 id="练习">练习</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#测试代码，假设zh_text是年报文本，从找找出丝网词相关词的上下文</span>
<span class="n">zh_text</span> <span class="o">=</span> <span class="s2">&#34;&#34;&#34;
</span><span class="s2">【插入一条自家广告】大邓自己家的家，
</span><span class="s2">安平县多隆丝网制品，生产销售不锈钢轧花网、
</span><span class="s2">电焊网、石笼网、刀片刺绳、冲孔网等丝网制品。
</span><span class="s2">联系人 邓颖静 0318-7686899
</span><span class="s2">
</span><span class="s2">人生苦短，我学Python
</span><span class="s2">在社科中，可以用Python做文本分析
</span><span class="s2">Python是一门功能强大的编程语言，广泛应用在经管社科领域。
</span><span class="s2">可以做网络爬虫、文本分析、LDA话题模型、相似度分析等。
</span><span class="s2">
</span><span class="s2">今年经济不景气，形势异常严峻。
</span><span class="s2">由于疫情不景气，静默管理， 产品积压， 公司经营困难。
</span><span class="s2">保就业促就业，任务十分艰巨。
</span><span class="s2">&#34;&#34;&#34;</span>

<span class="c1">#【产品词】上下文</span>
<span class="n">word_in_context</span><span class="p">(</span><span class="n">text</span> <span class="o">=</span> <span class="n">zh_text</span><span class="p">,</span> 
                <span class="n">keywords</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;石笼&#39;</span><span class="p">],</span> 
                <span class="n">window</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> 
                <span class="n">lang</span><span class="o">=</span><span class="s1">&#39;chinese&#39;</span><span class="p">)</span>
</code></pre></div><table>
<thead>
<tr>
<th>keyword</th>
<th>context</th>
</tr>
</thead>
<tbody>
<tr>
<td>石笼</td>
<td>电焊网、石笼网、刀片刺绳</td>
</tr>
</tbody>
</table>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#【经营】上下文</span>
<span class="n">word_in_context</span><span class="p">(</span><span class="n">text</span> <span class="o">=</span> <span class="n">zh_text</span><span class="p">,</span> 
                <span class="n">keywords</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;经营&#39;</span><span class="p">],</span> 
                <span class="n">window</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> 
                <span class="n">lang</span><span class="o">=</span><span class="s1">&#39;chinese&#39;</span><span class="p">)</span>
</code></pre></div><table>
<thead>
<tr>
<th>keyword</th>
<th>context</th>
</tr>
</thead>
<tbody>
<tr>
<td>经营</td>
<td>&gt;积压， 公司经营困难。\n保</td>
</tr>
</tbody>
</table>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#【Python】上下文</span>
<span class="n">word_in_context</span><span class="p">(</span><span class="n">text</span> <span class="o">=</span> <span class="n">zh_text</span><span class="p">,</span> 
                <span class="n">keywords</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;python&#39;</span><span class="p">],</span> 
                <span class="n">window</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> 
                <span class="n">lang</span><span class="o">=</span><span class="s1">&#39;chinese&#39;</span><span class="p">)</span>
</code></pre></div><table>
<thead>
<tr>
<th>keyword</th>
<th>context</th>
</tr>
</thead>
<tbody>
<tr>
<td>python</td>
<td>人生苦短，我学python\n在社科中</td>
</tr>
<tr>
<td>python</td>
<td>中，可以用python做文本分析\n</td>
</tr>
<tr>
<td>python</td>
<td>做文本分析\npython是一门功能强大的</td>
</tr>
</tbody>
</table>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>数据集 | 2001-2021年A股上市公司年报&amp;管理层讨论与分析</title>
      <link>https://textdata.cn/blog/2023-03-23-china-a-share-market-dataset-mda-from-01-to-21/</link>
      <pubDate>Thu, 16 Mar 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-03-23-china-a-share-market-dataset-mda-from-01-to-21/</guid>
      <description>&lt;p&gt;2001-2021年A股年报数据集，含4个文件，共17G&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;年报01年-21年.csv&lt;/li&gt;
&lt;li&gt;MDA01年-21年.csv&lt;/li&gt;
&lt;li&gt;公司基本情况文件.xlsx&lt;/li&gt;
&lt;li&gt;特殊变动处理.xlsx&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/dataset.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;数据获取&#34;&gt;数据获取&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://mp.weixin.qq.com/s/sgv5icnUZUFlP2JKvovEhA&#34;&gt;点击查看数据获取方式&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;一年报数据&#34;&gt;一、年报数据&lt;/h2&gt;
&lt;p&gt;01-21年年报数据&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pandas&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pd&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read_csv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;年报01年-21年.csv&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;converters&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;code&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;str&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;})&lt;/span&gt;
&lt;span class=&#34;c1&#34;&gt;#剔除第一行广告的办法&lt;/span&gt;
&lt;span class=&#34;c1&#34;&gt;#df = df[df.code!=&amp;#39;公众号:大邓和他的Python&amp;#39;]&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;head&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/df1.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;二mda数据&#34;&gt;二、MD&amp;amp;A数据&lt;/h2&gt;
&lt;p&gt;01-21年MD&amp;amp;A数据&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pandas&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pd&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;mda_df&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read_csv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;MDA01年-21年.csv&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;converters&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;code&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;str&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;})&lt;/span&gt;
&lt;span class=&#34;c1&#34;&gt;#剔除第一行广告的办法&lt;/span&gt;
&lt;span class=&#34;c1&#34;&gt;#mda_df = mda_df[mda_df.code!=&amp;#39;公众号:大邓和他的Python&amp;#39;]&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;mda_df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;head&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/df2.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mda_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;50302
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;三公司基本情况文件xlsx&#34;&gt;三、公司基本情况文件.xlsx&lt;/h2&gt;
&lt;p&gt;公司基本情况文件.xlsx&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Stkcd: 证券代码&lt;/li&gt;
&lt;li&gt;Stknme: 证券中文简称&lt;/li&gt;
&lt;li&gt;Stktype: 股票类型&lt;/li&gt;
&lt;li&gt;Crcd: A/B/H股交叉码&lt;/li&gt;
&lt;li&gt;Conme: 公司名称&lt;/li&gt;
&lt;li&gt;Cochsnm: 公司中文简称&lt;/li&gt;
&lt;li&gt;Conmee: 公司英文名称&lt;/li&gt;
&lt;li&gt;Nnindnme: 行业名称C&lt;/li&gt;
&lt;li&gt;Nnindcd: 行业代码C&lt;/li&gt;
&lt;li&gt;Nindnme: 行业名称B&lt;/li&gt;
&lt;li&gt;Nindcd: 行业代码B&lt;/li&gt;
&lt;li&gt;Indnme: 行业名称A&lt;/li&gt;
&lt;li&gt;Indcd: 行业代码A&lt;/li&gt;
&lt;li&gt;Busscope: 经营范围&lt;/li&gt;
&lt;li&gt;Cohisty: 公司沿革&lt;/li&gt;
&lt;li&gt;Regcap: 注册资本&lt;/li&gt;
&lt;li&gt;EstablishDate: 成立日期&lt;/li&gt;
&lt;li&gt;ListedDate: 上市日期&lt;/li&gt;
&lt;li&gt;DelistedDate: 退市日期&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pandas&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pd&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;ind_df&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read_excel&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;公司基本情况文件.xlsx&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;ind_df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;head&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/df3.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;四特殊变动处理xlsx&#34;&gt;四、特殊变动处理.xlsx&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Symbol: 证券代码&lt;/li&gt;
&lt;li&gt;ShortNamebc: 变动前的证券简称&lt;/li&gt;
&lt;li&gt;ShortNameac: 变动后的证券简称&lt;/li&gt;
&lt;li&gt;Chgtype: 变动类型&lt;/li&gt;
&lt;li&gt;Annoudt: 变动发布日期&lt;/li&gt;
&lt;li&gt;Execudt: 执行日期&lt;/li&gt;
&lt;li&gt;Chgreas: 变动原因编码&lt;/li&gt;
&lt;li&gt;Chgrsdis: 变动原因&lt;/li&gt;
&lt;li&gt;Content: 变动公告内容&lt;/li&gt;
&lt;li&gt;TypeAuditOpinbc: 变动前一年审计意见类型&lt;/li&gt;
&lt;li&gt;ISSustManaNonStandExpl: 是否发布可持续经营非标意见&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;st_pt_df&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read_excel&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;特殊变动处理.xlsx&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;st_pt_df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;head&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/df4.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;广而告之&#34;&gt;广而告之&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/call_for_paper/&#34;&gt;长期征稿&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/we_need_you/&#34;&gt;长期招募小伙伴&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/management_python_course/&#34;&gt;付费视频课 | Python实证指标构建与文本分析&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
      <content:encoded><![CDATA[<p>2001-2021年A股年报数据集，含4个文件，共17G</p>
<ul>
<li>年报01年-21年.csv</li>
<li>MDA01年-21年.csv</li>
<li>公司基本情况文件.xlsx</li>
<li>特殊变动处理.xlsx</li>
</ul>
<p><img loading="lazy" src="img/dataset.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="数据获取">数据获取</h2>
<p><a href="https://mp.weixin.qq.com/s/sgv5icnUZUFlP2JKvovEhA">点击查看数据获取方式</a></p>
<p><br><br></p>
<h2 id="一年报数据">一、年报数据</h2>
<p>01-21年年报数据</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;年报01年-21年.csv&#39;</span><span class="p">,</span> <span class="n">converters</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;code&#39;</span><span class="p">:</span> <span class="nb">str</span><span class="p">})</span>
<span class="c1">#剔除第一行广告的办法</span>
<span class="c1">#df = df[df.code!=&#39;公众号:大邓和他的Python&#39;]</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<p><img loading="lazy" src="img/df1.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="二mda数据">二、MD&amp;A数据</h2>
<p>01-21年MD&amp;A数据</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">mda_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;MDA01年-21年.csv&#39;</span><span class="p">,</span> <span class="n">converters</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;code&#39;</span><span class="p">:</span> <span class="nb">str</span><span class="p">})</span>
<span class="c1">#剔除第一行广告的办法</span>
<span class="c1">#mda_df = mda_df[mda_df.code!=&#39;公众号:大邓和他的Python&#39;]</span>
<span class="n">mda_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<p><img loading="lazy" src="img/df2.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="nb">len</span><span class="p">(</span><span class="n">mda_df</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">50302
</code></pre></div><p><br><br></p>
<h2 id="三公司基本情况文件xlsx">三、公司基本情况文件.xlsx</h2>
<p>公司基本情况文件.xlsx</p>
<ul>
<li>Stkcd: 证券代码</li>
<li>Stknme: 证券中文简称</li>
<li>Stktype: 股票类型</li>
<li>Crcd: A/B/H股交叉码</li>
<li>Conme: 公司名称</li>
<li>Cochsnm: 公司中文简称</li>
<li>Conmee: 公司英文名称</li>
<li>Nnindnme: 行业名称C</li>
<li>Nnindcd: 行业代码C</li>
<li>Nindnme: 行业名称B</li>
<li>Nindcd: 行业代码B</li>
<li>Indnme: 行业名称A</li>
<li>Indcd: 行业代码A</li>
<li>Busscope: 经营范围</li>
<li>Cohisty: 公司沿革</li>
<li>Regcap: 注册资本</li>
<li>EstablishDate: 成立日期</li>
<li>ListedDate: 上市日期</li>
<li>DelistedDate: 退市日期</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">ind_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_excel</span><span class="p">(</span><span class="s1">&#39;公司基本情况文件.xlsx&#39;</span><span class="p">)</span>
<span class="n">ind_df</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<p><img loading="lazy" src="img/df3.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="四特殊变动处理xlsx">四、特殊变动处理.xlsx</h2>
<ul>
<li>Symbol: 证券代码</li>
<li>ShortNamebc: 变动前的证券简称</li>
<li>ShortNameac: 变动后的证券简称</li>
<li>Chgtype: 变动类型</li>
<li>Annoudt: 变动发布日期</li>
<li>Execudt: 执行日期</li>
<li>Chgreas: 变动原因编码</li>
<li>Chgrsdis: 变动原因</li>
<li>Content: 变动公告内容</li>
<li>TypeAuditOpinbc: 变动前一年审计意见类型</li>
<li>ISSustManaNonStandExpl: 是否发布可持续经营非标意见</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">st_pt_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_excel</span><span class="p">(</span><span class="s1">&#39;特殊变动处理.xlsx&#39;</span><span class="p">)</span>
<span class="n">st_pt_df</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</code></pre></div><p><img loading="lazy" src="img/df4.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>采购合同数据集 | 政府采购何以牵动企业创新</title>
      <link>https://textdata.cn/blog/2023-03-15-gov-procurement-promote-enterpise-innovation/</link>
      <pubDate>Wed, 15 Mar 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-03-15-gov-procurement-promote-enterpise-innovation/</guid>
      <description>中国地方政府采购合同数据是中国政府采购网中国政府购买服务信息平台披露的政府采购合同信息，主要囊括了采购人（甲方）、采购人所属行政区、供应商（乙方）以及合同金额等关键信息。数据自 2008-06-12 ~ 2021-02-03， 共有 648538 条 。如果某个政府采购合同的以上三项信息中包含关键词库内任意一个关键词，那么该合同就被认定为政府创新采购合同。</description>
      <content:encoded><![CDATA[<h2 id="一数据集概况">一、数据集概况</h2>
<p>中国地方政府采购合同数据是中国政府采购网中国政府购买服务信息平台披露的政府采购合同信息，主要囊括了采购人（甲方）、采购人所属行政区、供应商（乙方）以及合同金额等关键信息。数据自 2008-06-12 ~ 2021-02-03， 共有 648538 条 。</p>
<p>网址: <a href="http://www.cgpnews.cn/">http://www.cgpnews.cn/</a></p>
<br>
<table>
<thead>
<tr>
<th>字段</th>
<th>字段标题</th>
<th>字段说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>purchaser</td>
<td>采购人</td>
<td>采购人（甲方）</td>
</tr>
<tr>
<td>address</td>
<td>所属地域</td>
<td>采购人（甲方）所属地域</td>
</tr>
<tr>
<td>administrative_code</td>
<td>行政区代码</td>
<td>采购人（甲方）所属行政区代码（中华人民共和国 6 位行政区划代码，中华人民共和国民政部 2019 年 6 月版）</td>
</tr>
<tr>
<td>provincial_region</td>
<td>省级行政区</td>
<td>采购人（甲方）所属省级行政区（中华人民共和国的第 一级行政区，中国共计 34 个省级行政区，包括 23 个省、 5 个自治区、4 个直辖市、2 个特别行政区）</td>
</tr>
<tr>
<td>perfecture_division</td>
<td>地级行政区</td>
<td>采购人（甲方）所属地级行政区（中华人民共和国的第 二级行政区，中国大陆共计 333 个地级行政区，包括 293 个地级市、7 个地区、30 个自治州、3 个盟）</td>
</tr>
<tr>
<td>supplier</td>
<td>供应商名称</td>
<td>供应商（乙方）名称</td>
</tr>
<tr>
<td>industry</td>
<td>所属行业</td>
<td>供应商（乙方）名称所属行业</td>
</tr>
<tr>
<td>contract_number</td>
<td>合同编号</td>
<td>合同编号</td>
</tr>
<tr>
<td>contract_name</td>
<td>合同名称</td>
<td>合同名称</td>
</tr>
<tr>
<td>contract_amount</td>
<td>合同金额</td>
<td>合同金额（单位: 万元）</td>
</tr>
<tr>
<td>project_number</td>
<td>项目编号</td>
<td>项目编号</td>
</tr>
<tr>
<td>project_name</td>
<td>项目名称</td>
<td>项目名称</td>
</tr>
<tr>
<td>contract_date</td>
<td>签订日期</td>
<td>签订日期</td>
</tr>
<tr>
<td>announcement_date</td>
<td>公告日期</td>
<td>公告日期</td>
</tr>
<tr>
<td>agency</td>
<td>代理机构</td>
<td>代理机构</td>
</tr>
<tr>
<td>contract_id</td>
<td>合同标识</td>
<td>合同唯一标识符</td>
</tr>
<tr>
<td>if_joint</td>
<td>是否众包</td>
<td>一个采购合同是否对应多家供应商。是记为“1”，否记为 “0”</td>
</tr>
</tbody>
</table>
<p><br><br></p>
<h2 id="二读取数据集">二、读取数据集</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;data/中国地方政府采购合同.csv&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">,</span> <span class="n">low_memory</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/df.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">648538
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df</span><span class="p">[</span><span class="s1">&#39;contract_date&#39;</span><span class="p">]</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">    0        2020-12-02
    1        2020-06-14
    2        2020-05-28
    3        2020-05-14
    4        2020-05-13
                ...    
    648533   2018-11-07
    648534   2018-11-07
    648535   2018-11-07
    648536   2018-11-01
    648537   2018-10-30
    Name: contract_date, Length: 648538, dtype: datetime64[ns]
</code></pre></div><p><br><br></p>
<h2 id="三相关论文">三、相关论文</h2>
<p>孙薇,叶初升.政府采购何以牵动企业创新——兼论需求侧政策“拉力”与供给侧政策“推力”的协同[J].中国工业经济,2023,(01):1-19.</p>
<br>
<h3 id="31-方法">3.1 方法</h3>
<p>通过 <strong>Python爬虫技术</strong> 获取中国政府采购新闻网 2015—2020 年 64 余万条政府采购合同数据，采用 <strong>文本分析方法</strong> 识别出政府创新采购，进而利用政府创新采购合同与中国 A 股上市企业匹配数据，实证检验政府创 新采购的创新效应及其影响机制，并对需求侧的政府创新支持“拉力”和供给侧的政府创新支持“推力”进行异质性分析，进一步探讨了两侧创新支持政策实施中的协同性问题，从而为政府精准施策提供学术依据。</p>
<br>
<h3 id="32-创新">3.2 创新</h3>
<p>本文的边际贡献在于：</p>
<ul>
<li>①<strong>基于政府采购合同数据，使用文本分析方法，从总体的政府采购中识 别出政府创新采购，为准确评估政府采购政策的创新效应创造了前提条件</strong>；</li>
<li>②在一个理论框架内阐 明了政府创新采购影响企业创新的机制，并进行了相应的实证检验，从理论和实证两个方面丰富了 需求侧创新政策激励效应的研究；</li>
<li>③从政策组合的整体视角考察了两侧创新支持政策的协同性问 题，为新发展阶段全面提升中国创新激励政策的实施效果、更好发挥“有为政府”在创新驱动中的作 用提供了重要的政策启示。</li>
</ul>
<br>
<h3 id="33-算法">3.3 算法</h3>
<p><strong>本文将各级国家机关和事业单位对创新产品和服务的采购界定为政府创新采购，并应用文本分析方法从总体的政府采购中加以识别</strong>。</p>
<p>本文使用的政府采购查询系统，对于每一份合同，网站都披露了合同名称、签订日期、合同金额、供应商名称、采购人 名称、所属地区等信息。 由于从 2015 年开始可以查询到较为详细的采购合同信息，因此，本文选取 2015—2020 年作为实证研究的年份区间。</p>
<p>（1）基于文本分析的政府创新采购识别。 本文的文本分析基于 Python 的 jieba分词实现。 为提升分词结果的可靠性，本文构建了行业词库和停用词库，以形成对 Jieba 分词自带词库的有益补充。 基于以上词库，对《重大技术装备自主创新指导目录（2012）》和《战略性新兴产业分类（2018）》中的 “重点产品和服务目录”以及手工收集的各地区创新产品目录进行分词 ，并对分词结果进行精细化的人工筛选，最终得到包含“智能电网” “液相色谱仪” “智能医疗系统” “物联网网关” “旋翼无人机” “管道机器人” 等 3000 余个词汇的政府创新采购关键词库。 随后，对 2015—2020 年 64 余万条政 府采购合同的“合同名称”“ 主要标的名称”和“规格型号或服务要求”进行分词。 <strong>如果某个政府采购合同的以上三项信息中包含关键词库内任意一个关键词，那么该合同就被认定为政府创新采购合同</strong>。</p>
<p>（2）“政府创新采购合同-上市企业”匹配。 在对各企业供应商的名称初步清洗之后，采用 Python 的 levenshtein distance 算法，进行“政府创新采购合同—上市企业”匹配。 为提升匹配精度， 同时开展模糊匹配和精确匹配，并以人工校对的方式汇总匹配结果。  考虑到上市企业往往会有较多子公司参与政府采购的招投标，本文手工整理了分年度的上市企业母、子公司名称，据此匹配，并将匹配结果合并。 最终共有 873 家上市企业匹配到政府创新采购合同，在本文的总样本中，每家上市企业平均获得政府创新采购合同约 1.21 份。</p>
<h2 id="四python技术细节">四、Python技术细节</h2>
<ol>
<li>网络爬虫采集政府采购网数据</li>
<li>jieba分词</li>
</ol>
<ul>
<li>导入创新技术相关词，更新jieba自定义词库</li>
<li>分词</li>
</ul>
<ol start="3">
<li>使用if语句判断是否含某创新词</li>
<li>文本相似度进行采购合同上市公司匹配。levenshtein distance</li>
</ol>
<p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>EDGAR | 25年数据的预训练词向量模型</title>
      <link>https://textdata.cn/blog/2023-03-08-edgar-w2v-and-corpus/</link>
      <pubDate>Wed, 08 Mar 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-03-08-edgar-w2v-and-corpus/</guid>
      <description>EDGAR 是美国证券交易委员会（SEC）的电子数据收集、分析和检索系统。EDGAR系统允许公众通过互联网访问公司提交给SEC的各种文件，例如注册声明、年度报告和其他披露文件。这些文件包括公司的财务信息、业务信息和其他关键信息，对于投资者和研究人员来说非常有用。金融等方向的同学，如果想用 **词嵌入** 技术开展研究， 可以考虑使用这个开源的数据集。EDGAR is an electronic data collection, analysis, and retrieval system of the US Securities and Exchange Commission (SEC). The EDGAR system allows the public to access various documents submitted to the SEC by companies through the internet, such as registration statements, annual reports, and other disclosure documents. These documents include financial information, business information, and other key information of the companies, which is very useful for investors and researchers. Students in finance and related fields who want to conduct research using word embedding techniques may consider using this open-source dataset.</description>
      <content:encoded><![CDATA[<p>EDGAR 是美国证券交易委员会（SEC）的电子数据收集、分析和检索系统。EDGAR系统允许公众通过互联网访问公司提交给SEC的各种文件，例如注册声明、年度报告和其他披露文件。这些文件包括公司的财务信息、业务信息和其他关键信息，对于投资者和研究人员来说非常有用。</p>
<p>金融等方向的同学，如果想用 <strong>词嵌入</strong> 技术开展研究， 可以考虑使用这个开源的数据集。</p>
<br>
<h2 id="一edgar-corpus">一、EDGAR-CORPUS</h2>
<p>在 EMNLP 2021同时举办的经济与自然语言处理研讨会（ECONLP）论文集中， 发布了EDGAR-CORPUS，这是一个新颖的语料库，包括美国所有上市公司超过25年的年报。</p>
<p>所有报告都已下载，拆分为相应的项目（部分），并以清洁、易于使用的JSON格式提供。</p>
<h3 id="11-下载数据">1.1 下载数据</h3>
<p><a href="https://zenodo.org/record/5528490">https://zenodo.org/record/5528490</a></p>
<p><img loading="lazy" src="img/edgar-corpus.png" alt=""  />
</p>
<br>
<h3 id="1-2-引用格式">1. 2 引用格式</h3>
<p>Lefteris Loukas, Manos Fergadiotis, Ion Androutsopoulos, &amp; Prodromos Malakasiotis. (2021). EDGAR-CORPUS [Data set]. Zenodo. <a href="https://doi.org/10.5281/zenodo.5528490">https://doi.org/10.5281/zenodo.5528490</a></p>
<p><br><br></p>
<h2 id="二edgar-w2v-embeddings">二、EDGAR-W2V Embeddings</h2>
<p>EDGAR-W2V 是在 EDGAR-CORPUS 上训练的词嵌入模型。 它是一个200维的模型，包含 10 万个金融词汇。EDGAR-W2V的相关信息可以在题为“EDGAR-CORPUS: Billions of Tokens Make The World Go Round”的论文中找到，该论文发表于2021年EMNLP会议上的经济学和自然语言处理研讨会（ECONLP）。</p>
<h3 id="11-下载模型">1.1 下载模型</h3>
<p><a href="https://zenodo.org/record/5524358">https://zenodo.org/record/5524358</a>
<img loading="lazy" src="img/edgar-w2v.png" alt=""  />
</p>
<br>
<h3 id="1-2-引用格式-1">1. 2 引用格式</h3>
<p>Lefteris Loukas, Manos Fergadiotis, Ion Androutsopoulos, &amp; Prodromos Malakasiotis. (2021). EDGAR-W2V Embeddings. Zenodo. <a href="https://doi.org/10.5281/zenodo.5524358">https://doi.org/10.5281/zenodo.5524358</a></p>
<br>
<h2 id="三代码">三、代码</h2>
<h3 id="31-导入词汇表">3.1 导入词汇表</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">vocab</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;edgar.word.w2v.200.vocab&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">read</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;词汇量: &#39;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">))</span>

<span class="c1">#显示前100个</span>
<span class="nb">print</span><span class="p">(</span><span class="n">vocab</span><span class="p">[:</span><span class="mi">100</span><span class="p">])</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">词汇量:  100000

[&#39;the&#39;,
 &#39;,&#39;,
 &#39;of&#39;,
 &#39;.&#39;,
 &#39;and&#39;,
 &#39;to&#39;,
 &#39;NEWLINETOKEN&#39;,
 &#39;in&#39;,
 &#39;a&#39;,
 &#39;for&#39;,
 ......
 &#39;including&#39;,
 &#39;accounting&#39;,
 &#39;operating&#39;,
 &#39;1&#39;,
 &#39;fair&#39;,
 &#39;also&#39;,
 &#39;credit&#39;,
 &#39;capital&#39;,
 &#39;notes&#39;,
 &#39;securities&#39;,
 &#39;rate&#39;]
</code></pre></div><br>
<h3 id="31-导入w2v模型文件">3.1 导入W2V模型文件</h3>
<p>edgar.word.w2v.200.bin只存储了</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">gensim.models.keyedvectors</span> <span class="kn">import</span> <span class="n">KeyedVectors</span>

<span class="n">edgar_wv</span> <span class="o">=</span> <span class="n">KeyedVectors</span><span class="o">.</span><span class="n">load_word2vec_format</span><span class="p">(</span><span class="s1">&#39;edgar.word.w2v.200.bin&#39;</span><span class="p">,</span> 
                                             <span class="n">binary</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
                                             <span class="n">unicode_errors</span><span class="o">=</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>
</code></pre></div><br>
<p>查看某个词的词向量, 返回长度200维的向量</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="nb">print</span><span class="p">(</span><span class="n">edgar_wv</span><span class="p">[</span><span class="s1">&#39;stock&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">edgar_wv</span><span class="p">[</span><span class="s1">&#39;stock&#39;</span><span class="p">]</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">(200,)

array([ 0.19913645, -0.06109103, -0.20294489, -0.3233174 ,  0.33050874,
        0.4720499 ,  0.1584721 , -0.73845965, -0.320686  , -0.03934   ,
        0.24570467,  0.33919033, -0.42398626, -0.0519694 ,  0.5614962 ,
        0.06250261,  0.12337335,  0.4284085 , -0.18471783,  0.27163157,
       -0.25374356, -0.30515426, -0.53030056,  0.14488244,  0.23602249,
        0.17834061,  0.5282402 ,  0.35811898,  0.02480956, -0.27537134,
        0.46796346,  0.14656937, -0.24058165, -0.02558263,  0.2823333 ,
        0.13227813, -0.35262054, -0.3534915 , -0.08498703,  0.13652588,
        0.19062333, -0.59584695,  0.4724787 ,  0.0899151 , -0.30575767,
        0.0894967 , -0.42695883,  0.14332667,  0.32162446,  0.5205731 ,
       -0.34024504, -0.15563595,  0.09534936, -0.03550521, -0.24585967,
       -0.70967376,  0.23757844,  0.19296522, -0.14549816, -0.34093133,
        0.44992575, -0.31520963, -0.19251363, -0.2664489 ,  0.22087495,
       -0.0226051 ,  0.02213453, -0.31526777,  0.02245333,  0.01845511,
        0.4727852 ,  0.0823371 , -0.28313273, -0.96016574, -0.34687626,
        0.31235287, -0.2581088 , -0.7164211 ,  0.6806588 ,  0.31276935,
       -0.166056  , -0.5558513 ,  0.10650715, -0.34121472,  0.01264491,
        0.3823984 , -0.6213977 ,  0.532256  , -0.11913523,  0.22344823,
        0.3172406 , -0.08887295,  0.14381133,  0.23814514, -0.09513577,
        0.10691381,  0.13318019, -0.10131137,  0.51121044, -0.13446783,
       -0.34249052,  0.21858525, -0.66716367, -0.1002802 ,  0.1822924 ,
       -0.17896068,  0.36693272, -0.26906306,  0.16348957,  0.309529  ,
       -0.5283489 ,  0.38473064, -0.4563293 , -0.36093566,  0.02899153,
       -0.16942917, -0.24810787,  0.04769324,  0.07288674,  0.05372427,
       -0.21368156, -0.2308374 , -0.47956762,  0.26331866,  0.08796341,
        0.0316316 , -0.04519949,  0.03246075, -0.06966034,  0.08757813,
        0.16438614, -0.16775173, -0.10321777,  0.21712255,  0.1252789 ,
       -0.34793332,  0.01499637, -0.32516828,  0.15845637, -0.1023875 ,
       -0.05895114, -0.08138125,  0.08420486, -0.18958494, -0.22417304,
        0.5160968 ,  0.13966903,  0.17438166,  0.13805066, -0.1817818 ,
        0.09644702, -0.34120768,  0.36722133, -0.06767058, -0.3896219 ,
       -0.1555085 , -0.07321457, -0.24285823, -0.23933856,  0.26198393,
       -0.12067977,  0.4152437 , -0.5361226 ,  0.02143142, -0.47723222,
       -0.27638227, -0.272431  ,  0.27474684,  0.02058701,  0.398542  ,
        0.12495182, -0.43948382, -0.41649124, -0.10416509, -0.013862  ,
        0.2630676 ,  0.0534305 ,  0.26379627, -0.33174622,  0.30189517,
        0.13504176, -0.09992695,  0.6300687 , -0.14120325, -0.04877585,
        0.3973992 ,  0.50578755,  0.07440792, -0.10353652, -0.60702443,
       -0.09498709,  0.1284441 , -0.13405691, -0.19467972, -0.09931252,
       -0.28807166, -0.49167937,  0.501096  ,  0.41336802, -0.4281704 ],
      dtype=float32)
</code></pre></div><p><br><br></p>
<h2 id="四相关内容">四、相关内容</h2>
<p>如果想了解更多词嵌入(或词向量)信息，可以阅读:</p>
<ul>
<li><a href="https://textdata.cn/blog/wordembeddingsinsocialscience/">转载 | 大数据时代下社会科学研究方法的拓展——基于词嵌入技术的文本分析的应用</a></li>
<li><a href="https://textdata.cn/blog/from_sysbol_to_embeddings_in_computational_social_science/">转载 | 从符号到嵌入：计算社会科学的两种文本表示</a></li>
<li><a href="https://textdata.cn/blog/2023-03-15-39faq-about-word-embeddings-for-social-science/">词嵌入技术在社会科学领域进行数据挖掘常见39个FAQ汇总</a></li>
<li><a href="https://textdata.cn/blog/embeddingsandattitude/">词嵌入测量不同群体对某概念的态度(偏见)</a></li>
<li><a href="https://textdata.cn/blog/2022-09-07-management-science-disrupt-science-and-technology">Management Science | 使用网络算法识别创新的颠覆性与否</a></li>
<li><a href="https://textdata.cn/blog/2023-03-03-extracts-cognitive-information-and-visualization-with-embedings/">可视化 | 词嵌入模型用于计算社科领域刻板印象等信息（含代码）</a></li>
<li><a href="https://textdata.cn/blog//2022-11-14-pnas_naming_unrelated_words_predicts_creativity/">PNAS | 使用语义距离测量一个人的创新力(发散思维)得分</a></li>
<li><a href="https://textdata.cn/blog/douban_w2v/">豆瓣影评 | 探索词向量妙处</a></li>
<li><a href="https://textdata.cn/blog/whatlies_word2vec/">whatlies库 | 可视化词向量</a></li>
<li><a href="https://textdata.cn/blog/embeddings_resource_usage_method/">中文词向量资源汇总 &amp; 使用方法</a></li>
<li><a href="https://textdata.cn/blog/pretained_nlp_models/">NLP资源 | 汽车、金融等9大领域预训练词向量模型下载资源</a></li>
<li><a href="https://textdata.cn/blog/2022-10-16-aligned-word-vectors/">数据集 | 多语言对齐词向量预训练模型</a></li>
</ul>
<p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://hidadeng.github.io/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://hidadeng.github.io/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://hidadeng.github.io/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>数据集 | 马前卒工作室睡前消息文稿汇总</title>
      <link>https://textdata.cn/blog/2023-03-06-bedtime-news-datasets/</link>
      <pubDate>Mon, 06 Mar 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-03-06-bedtime-news-datasets/</guid>
      <description>一直有观看马前卒工作室睡前消息的习惯， 感觉他的内容很理性， 透露着马列科学社会风。 引爆全网的两个话题独山县债务问题、以岭药业连花清瘟胶囊事件。 **数据可以拿来练习词频统计、词云图制作、情感分析、lda话题建模。已整理为csv文件，留给需要的人**。</description>
      <content:encoded><![CDATA[<p>一直有观看马前卒工作室睡前消息的习惯， 感觉他的内容很理性， 透露着马列科学社会风。 引爆全网的两个话题独山县债务问题、以岭药业连花清瘟胶囊事件。 <strong>数据可以拿来练习词频统计、词云图制作、情感分析、lda话题建模。已整理为csv文件，留给需要的人</strong>。</p>
<p><img loading="lazy" src="img/yilingyaoye.jpg" alt=""  />
</p>
<p><img loading="lazy" src="img/dushanxian.jpeg" alt=""  />
</p>
<br>
<h2 id="一原始数据">一、原始数据</h2>
<p>『睡前消息』截止2023年3月6日，已经更新至559期. 文稿资源来自 <a href="https://archive.bedtime.news/zh/main">https://archive.bedtime.news/zh/main</a></p>
<p>原始数据集下载下来是这个样子</p>
<p><img loading="lazy" src="img/directory.png" alt=""  />
</p>
<p><img loading="lazy" src="img/sub_dir.png" alt=""  />
</p>
<p><img loading="lazy" src="img/filelists.png" alt=""  />
</p>
<br>
<p>数据集文件夹的目录树结构</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">- 睡前消息文本 第1-100期
    |- 001-010期
       |- 2019 07 12 第一期.docx
       |- 2019 07 16 第二期.docx
       |- 2019 07 19 第三期.docx
       |- 2019 07 23 第四期.docx
       |- ...
    |- 011-020期
    |- 021-030期
    |-...
- 睡前消息文本 第101-200期
- 睡前消息文本 第201-300期
- 睡前消息文本 第301-400期
- 睡前消息文本 第401-500期
- 睡前消息文本 第501-最新
- bedtime_news.csv
- code.ipynb
</code></pre></div><br>
<h2 id="一整理数据">一、整理数据</h2>
<p>原始数据docx文件存储，数据集是2层文件夹结构。可以使用glob库提供文件路径识别功能</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-PYTHON" data-lang="PYTHON"><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">glob</span>
<span class="kn">import</span> <span class="nn">csv</span>
<span class="kn">from</span> <span class="nn">pdfdocx</span> <span class="kn">import</span> <span class="n">read_docx</span>

<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;bedtime_news.csv&#39;</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">,</span> <span class="n">newline</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">csvf</span><span class="p">:</span>
    <span class="n">fieldnames</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">,</span> <span class="s1">&#39;name&#39;</span><span class="p">,</span> <span class="s1">&#39;text&#39;</span><span class="p">]</span>
    <span class="n">writer</span> <span class="o">=</span> <span class="n">csv</span><span class="o">.</span><span class="n">DictWriter</span><span class="p">(</span><span class="n">csvf</span><span class="p">,</span> <span class="n">fieldnames</span> <span class="o">=</span> <span class="n">fieldnames</span><span class="p">)</span>
    <span class="n">writer</span><span class="o">.</span><span class="n">writeheader</span><span class="p">()</span>

    <span class="c1"># 使用glob模块查找所有的docx文件路径</span>
    <span class="n">docx_files</span> <span class="o">=</span> <span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="s2">&#34;**/*.docx&#34;</span><span class="p">,</span> <span class="n">recursive</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">docx_files</span> <span class="o">=</span> <span class="p">[</span><span class="n">f</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">docx_files</span> <span class="k">if</span> <span class="s1">&#39;DS&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">f</span><span class="p">]</span>

    <span class="c1"># 输出所有docx文件路径</span>
    <span class="k">for</span> <span class="n">file_path</span> <span class="ow">in</span> <span class="n">docx_files</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">file_path</span><span class="p">)</span>
        <span class="n">file_name</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s1">&#39;\s&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">file_path</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;/&#39;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
        <span class="k">if</span> <span class="n">file_name</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;22&#39;</span><span class="p">):</span>
            <span class="n">file_name</span> <span class="o">=</span> <span class="s1">&#39;2022&#39;</span><span class="o">+</span> <span class="n">file_name</span><span class="p">[</span><span class="mi">2</span><span class="p">:]</span>
        <span class="n">date</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">findall</span><span class="p">(</span><span class="s1">&#39;\d</span><span class="si">{8}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">file_name</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">episode</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s1">&#39;.docx&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">file_name</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">date</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">))</span>
        <span class="n">text</span> <span class="o">=</span> <span class="n">read_docx</span><span class="p">(</span><span class="n">file_path</span><span class="p">)</span>
        <span class="n">data</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&#34;date&#34;</span><span class="p">:</span> <span class="nb">str</span><span class="p">(</span><span class="n">date</span><span class="p">),</span> 
                <span class="s2">&#34;name&#34;</span><span class="p">:</span> <span class="n">file_path</span><span class="p">,</span>
                <span class="s2">&#34;text&#34;</span><span class="p">:</span><span class="n">text</span><span class="p">}</span>
        <span class="n">writer</span><span class="o">.</span><span class="n">writerow</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</code></pre></div><br>
<h2 id="二导入csv">二、导入csv</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&#34;bedtime_news.csv&#34;</span><span class="p">,</span> <span class="n">converters</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;date&#39;</span><span class="p">:</span> <span class="nb">str</span><span class="p">})</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<p><img loading="lazy" src="img/df.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">522
</code></pre></div><br>
<h2 id="获取方式">获取方式</h2>
<p>链接: <a href="https://pan.baidu.com/s/1Qor_FNBnGuTsq4NpF3vzVQ">https://pan.baidu.com/s/1Qor_FNBnGuTsq4NpF3vzVQ</a> 提取码: t8pq</p>
<br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://hidadeng.github.io/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://hidadeng.github.io/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>cctv新闻联播文稿数据集</title>
      <link>https://textdata.cn/blog/2023-02-26-cctv1-news-text-dataset/</link>
      <pubDate>Sun, 26 Feb 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-02-26-cctv1-news-text-dataset/</guid>
      <description>cctv新闻联播文稿数据集，可使用Python对其进行挖掘，借助文本挖掘技术研究鸿观经济政策、社会学、传播学等领域。</description>
      <content:encoded><![CDATA[<br>
<h2 id="安装">安装</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">pip install akshare
</code></pre></div><br>
<h2 id="aknews_cctv参数">ak.news_cctv参数</h2>
<p>查看ak.news_cctv函数的帮助文档，显示该函数<strong>只能采集20160203之后的数据</strong></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">help</span><span class="p">(</span><span class="n">ak</span><span class="o">.</span><span class="n">news_cctv</span><span class="p">)</span>
</code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">Help on function news_cctv in module akshare.news.news_cctv:

news_cctv(date: str = &#39;20130308&#39;) -&gt; pandas.core.frame.DataFrame
    新闻联播文字稿
    https://tv.cctv.com/lm/xwlb/?spm=C52056131267.P4y8I53JvSWE.0.0
    :param date: 需要获取数据的日期; 目前 20160203 年后
    :type date: str
    :return: 新闻联播文字稿
    :rtype: pandas.DataFrame
</code></pre></div><h2 id="获取某日新闻">获取某日新闻</h2>
<p>获取某日期的新闻联播文稿</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">akshare</span> <span class="k">as</span> <span class="nn">ak</span>

<span class="n">news_cctv_df</span> <span class="o">=</span> <span class="n">ak</span><span class="o">.</span><span class="n">news_cctv</span><span class="p">(</span><span class="n">date</span><span class="o">=</span><span class="s2">&#34;20160204&#34;</span><span class="p">)</span>
<span class="n">news_cctv_df</span>
</code></pre></div><p><img loading="lazy" src="img/df1.png" alt=""  />
</p>
<br>
<h2 id="批量存储">批量存储</h2>
<p>批量存储**20160203 - 至今 ** 之间所有的数据，每个日期保存到csv文件中。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">datetime</span> 
<span class="kn">import</span> <span class="nn">akshare</span> <span class="k">as</span> <span class="nn">ak</span>

<span class="c1">#获取【20160203 - 至今】日期字符串的列表</span>
<span class="k">def</span> <span class="nf">date_ranges</span><span class="p">():</span>
    <span class="n">begin</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">datetime</span><span class="p">(</span><span class="mi">2016</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
    <span class="n">now</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">today</span><span class="p">()</span>
    <span class="n">interv</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">timedelta</span><span class="p">(</span><span class="n">days</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">dates</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">date</span> <span class="o">=</span> <span class="n">begin</span>
    <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">date</span> <span class="o">&lt;</span> <span class="n">now</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">date</span> <span class="o">+</span> <span class="n">interv</span> <span class="o">&lt;</span> <span class="n">now</span><span class="p">):</span>
            <span class="n">date</span> <span class="o">=</span> <span class="n">date</span> <span class="o">+</span> <span class="n">interv</span>
            <span class="n">dates</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">date</span><span class="o">.</span><span class="n">strftime</span><span class="p">(</span><span class="s1">&#39;%Y%m</span><span class="si">%d</span><span class="s1">&#39;</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">dates</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">now</span><span class="o">.</span><span class="n">strftime</span><span class="p">(</span><span class="s1">&#39;%Y%m</span><span class="si">%d</span><span class="s1">&#39;</span><span class="p">))</span>
            <span class="k">break</span>
    <span class="k">return</span> <span class="n">dates</span>


<span class="c1">#按 日期依次下载</span>
<span class="k">for</span> <span class="n">date</span> <span class="ow">in</span> <span class="n">date_ranges</span><span class="p">():</span>
    <span class="n">news_cctv_df</span> <span class="o">=</span> <span class="n">ak</span><span class="o">.</span><span class="n">news_cctv</span><span class="p">(</span><span class="n">date</span><span class="o">=</span><span class="n">date</span><span class="p">)</span>
    <span class="n">news_cctv_df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;cctv/</span><span class="si">{}</span><span class="s1">.csv&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">date</span><span class="p">),</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">date</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">20160203
20160204
20160205
......
                                               
20230223
20230224
20230225
</code></pre></div><h2 id="数据集">数据集</h2>
<p>运行了5个小时，共有 2,518 天的新闻联播新闻稿的csv文件。</p>
<p><img loading="lazy" src="img/csvs.png" alt=""  />
</p>
<br>
<h2 id="数据获取">数据获取</h2>
<p>链接: <a href="https://pan.baidu.com/s/1pSdKe53OIZANwRAAZ0TGAg">https://pan.baidu.com/s/1pSdKe53OIZANwRAAZ0TGAg</a> 提取码: uxxs</p>
<br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">支持开票 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>1850万条 | 世界地图POI兴趣点数据集</title>
      <link>https://textdata.cn/blog/2022-12-10-1850w-poi-dataset/</link>
      <pubDate>Sat, 10 Dec 2022 00:00:00 +0000</pubDate>
      
      <guid>/blog/2022-12-10-1850w-poi-dataset/</guid>
      <description>1850万条世界地图POI兴趣点数据集，可用于GIS、区域经济等领域的研究</description>
      <content:encoded><![CDATA[<h2 id="世界地图poi兴趣点数据集">世界地图POI兴趣点数据集</h2>
<p>POI数据集包含全球超过 1850 万个 POI， 数据按国家或地区组织分别以 CSV 文存档中， 数据集每月更新一次。</p>
<br>
<h2 id="数据价值">数据价值</h2>
<p>POI数据集含 区域位置、商业地点、营业时间，运营主体，网站等信息， 可用于GIS、区域经济等领域的研究。
<strong>文末有数据集获取方式</strong> , 数据集中包含的字段有</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">- ID OpenStreetMap ID
- NAME 地名、国际名称
- CATEGORY、SUBCATEGORY POI类目/子类目
- LAT、LON 经度、纬度
- SRID 基于OSM标签的POI分类（14类167子类）
- WKT   WGS84中的geometry (WKT)；
- IMAGE 链接到照片/图像；
- OPENING_HOURS  营业时间
- WIKIPEDIA 链接到维基百科文章；
- LAST_UPDATE 上次更新日期，
- OPERATOR 运营商
- ALTERNATIVE_NAME 备用名称
- INTERNATIONAL_NAME 国际名称（通常为英文或音译为拉丁字符）；
- STREET、HOUSENUMBER 地址（街道、门牌号）
- POSTCODE、CITY、COUNTRY   地址（邮编、城市、国家）；
- DESCRIPTION 完整描述（如果在 OSM 中列出）；
- PHONE、FAX、WEBSITE、EMAIL      联系人（电话号码、传真号码、网站、邮箱）；
- OTHER_TAGS 而其余标记值列在“OTHER_TAGS”列下。
</code></pre></div><br>
<p><img loading="lazy" src="img/world.png" alt=""  />
</p>
<p><img loading="lazy" src="img/asia.png" alt=""  />
</p>
<br>
<h3 id="数据质量对比">数据质量对比</h3>
<p>OpenStreetMap（简称OSM，中文是公开地图）是一个网上地图协作计划，目标是创造一个内容自由且能让所有人编辑的世界地图。OSM的数据有两种来源</p>
<ul>
<li>广大用户的贡献（众包），包括利用 GPS 设备自行测绘和根据卫星影像地图（Bing/Yahoo!/Landsat等）绘制两种，</li>
<li>少数政府部门的测绘机构及商业公司根据相应授权提供。</li>
</ul>
<p>而Google的数据则主要依靠专业测绘商采购（在中国主要是 AutoNavi/高德），以自己采集（街景）、政府部门提供（主要是NASA的Landsat影像）和用户贡献（Google Map Maker）作为补充。据此不难看出，OSM数据的优势主要体现在更新及时，而Google则胜在较强的专业性和准确性。至于数据的覆盖面，这要看OSM贡献者数量和Google财力与测绘商能力的对比。当OSM贡献者的数量和参与热情达到一定水平，其数据的数量和质量完全不逊于Google（请看OSM上德国地图）。维基百科战胜大英百科全书即是侧证。</p>
<br>
<h2 id="导入数据">导入数据</h2>
<p>以中国数据为例</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;china-pois.osm.csv&#39;</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s1">&#39;|&#39;</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/df.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#poi数据量</span>
<span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
</code></pre></div><pre><code>911246
</code></pre>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#poi数据集的字段</span>
<span class="n">df</span><span class="o">.</span><span class="n">columns</span>
</code></pre></div><pre><code>Index(['ID', 'NAME', 'CATEGORY', 'SUBCATEGORY', 'LON', 'LAT', 'SRID', 'WKT',
       'CITY', 'IMAGE', 'EMAIL', 'COUNTRY', 'OPENING_HOURS', 'WIKIPEDIA',
       'OPERATOR', 'DESCRIPTION', 'LAST_UPDATE', 'ALTERNATIVE_NAME',
       'POSTCODE', 'INTERNATIONAL_NAME', 'WEBSITE', 'PHONE', 'NAME_EN',
       'STREET', 'HOUSENUMBER', 'FAX', 'OTHER_TAGS'],
      dtype='object')
</code></pre>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#poi类型分布</span>
<span class="n">df</span><span class="o">.</span><span class="n">CATEGORY</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</code></pre></div><pre><code>SETTLEMENTS      397769
TRANSPORT        198462
EDUCATION         56087
LANDUSE           50161
TOURISM           47618
SHOP              42939
EAT/DRINK         28386
PUBLICSERVICE     22905
AUTOMOTIVE        14809
ACCOMMODATION     13092
BUSINESS          12573
HEALTH            10747
RELIGIOUS          8039
SPORT              7659
Name: CATEGORY, dtype: int64
</code></pre>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#经纬度范围</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;经度(东)&#39;</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">LON</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;经度(西)&#39;</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">LON</span><span class="o">.</span><span class="n">min</span><span class="p">())</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;纬度(北)&#39;</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">LAT</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;纬度(南)&#39;</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">LAT</span><span class="o">.</span><span class="n">min</span><span class="p">())</span>
</code></pre></div><pre><code>经度(东) 135.08528800000002
经度(西) 72.2818637
纬度(北) 53.56513885988782
纬度(南) 15.1251016
</code></pre>
<br>
<h2 id="字段解析">字段解析</h2>
<ul>
<li>ID OpenStreetMap ID</li>
<li>NAME 地名、国际名称</li>
<li>CATEGORY、SUBCATEGORY POI类目/子类目</li>
<li>LAT、LON 经度、纬度</li>
<li>SRID 基于OSM标签的POI分类（14类167子类）</li>
<li>WKT   WGS84中的geometry (WKT)；</li>
<li>IMAGE 链接到照片/图像；</li>
<li>OPENING_HOURS  营业时间</li>
<li>WIKIPEDIA 链接到维基百科文章；</li>
<li>LAST_UPDATE 上次更新日期，</li>
<li>OPERATOR 运营商</li>
<li>ALTERNATIVE_NAME 备用名称</li>
<li>INTERNATIONAL_NAME 国际名称（通常为英文或音译为拉丁字符）；</li>
<li>STREET、HOUSENUMBER 地址（街道、门牌号）</li>
<li>POSTCODE、CITY、COUNTRY   地址（邮编、城市、国家）；</li>
<li>DESCRIPTION 完整描述（如果在 OSM 中列出）；</li>
<li>PHONE、FAX、WEBSITE、EMAIL      联系人（电话号码、传真号码、网站、邮箱）；</li>
<li>OTHER_TAGS 而其余标记值列在“OTHER_TAGS”列下。</li>
</ul>
<br>
<h2 id="下载地址">下载地址</h2>
<p>数据集下载地址</p>
<p><a href="http://download.slipo.eu/results/osm-to-csv/poi/">http://download.slipo.eu/results/osm-to-csv/poi/</a></p>
<br>
<h2 id="参考资料">参考资料</h2>
<ul>
<li><a href="http://slipo.eu/?p=1551">http://slipo.eu/?p=1551</a></li>
<li>OpenStreetMap百度词条</li>
<li><a href="https://www.zhihu.com/question/19993564/answer/14428059">https://www.zhihu.com/question/19993564/answer/14428059</a></li>
<li><a href="http://download.slipo.eu/results/osm-to-csv/poi/">http://download.slipo.eu/results/osm-to-csv/poi/</a></li>
</ul>
<br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>数据集 | 80w知乎用户问答数据</title>
      <link>https://textdata.cn/blog/2023-03-06-zhihurec-dataset/</link>
      <pubDate>Sat, 10 Dec 2022 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-03-06-zhihurec-dataset/</guid>
      <description>ZhihuRec数据集由清华大学信息检索组（THUIR）和知乎公司共同构建，仅供研究使用。ZhihuRec 数据集是从知识共享平台（知乎）收集的，该平台由 10 天内收集的约 100M 交互、798K 用户、165K 问题、554K 答案、240K 作者、70K 主题和超过 501K 用户查询日志组成。 还有用户、答案、问题、作者和主题的描述，这些都是匿名的。 据我们所知，这是用于个性化推荐的最大的真实世界交互数据集。由于ZhihuRec数据集包含约100M的用户回答印象日志，因此也称为ZhihuRec-100M。 还构建了从 ZhihuRec-100M 数据集随机采样的两个较小的数据集，分别称为 ZhihuRec-20M 和 ZhihuRec-1M，以满足各种应用需求。 它们包含大约 20M 和 1M 的用户回答印象日志，可以看作是一个中等大小的数据集和一个相对较小的数据集。</description>
      <content:encoded><![CDATA[<h2 id="一zhihurec介绍">一、ZhihuRec介绍</h2>
<p>ZhihuRec数据集由 <strong>清华大学信息检索组</strong>（THUIR）和  <strong>知乎公司</strong> 共同构建，仅供研究使用。ZhihuRec 数据集是从知识共享平台（知乎）收集的，该平台由 10 天内收集的约 一亿(100M) 次交互、798K 用户、165K 问题、554K 答案、240K 作者、70K 主题和超过 501K 用户查询日志组成。 还有用户、答案、问题、作者和主题的描述，这些都是匿名的。 据我们所知，这是用于个性化推荐的最大的真实世界交互数据集。由于ZhihuRec数据集包含约100M的用户回答印象日志，因此也称为ZhihuRec-100M。 还构建了从 ZhihuRec-100M 数据集随机采样的两个较小的数据集，分别称为 ZhihuRec-20M 和 ZhihuRec-1M，以满足各种应用需求。 它们包含大约 20M 和 1M 的用户回答印象日志，可以看作是一个中等大小的数据集和一个相对较小的数据集。</p>
<br>
<p><strong>ZhihuRec项目及下载地址</strong></p>
<ul>
<li><a href="https://github.com/THUIR/ZhihuRec-Dataset">https://github.com/THUIR/ZhihuRec-Dataset</a></li>
<li><a href="https://cloud.tsinghua.edu.cn/d/d6c045c55aa14bb39ebc/">https://cloud.tsinghua.edu.cn/d/d6c045c55aa14bb39ebc/</a></li>
</ul>
<p><br><br></p>
<h2 id="二数据集详情">二、数据集详情</h2>
<h3 id="21-数据集内的文件">2.1 数据集内的文件</h3>
<table>
<thead>
<tr>
<th style="text-align:left">Filename</th>
<th style="text-align:right">Size</th>
<th style="text-align:left">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><code>inter_impression.csv</code></td>
<td style="text-align:right">2.6GB</td>
<td style="text-align:left">user clicks and impressions</td>
</tr>
<tr>
<td style="text-align:left"><code>inter_query.csv</code></td>
<td style="text-align:right">111MB</td>
<td style="text-align:left">user queries</td>
</tr>
<tr>
<td style="text-align:left"><code>info_user.csv</code></td>
<td style="text-align:right">135MB</td>
<td style="text-align:left">the features of the users occured in the dataset</td>
</tr>
<tr>
<td style="text-align:left"><code>info_answer.csv</code></td>
<td style="text-align:right">917MB</td>
<td style="text-align:left">the features of the answers occured in the dataset</td>
</tr>
<tr>
<td style="text-align:left"><code>info_question.csv</code></td>
<td style="text-align:right">14MB</td>
<td style="text-align:left">the features of the questions occured in the dataset</td>
</tr>
<tr>
<td style="text-align:left"><code>info_author.csv</code></td>
<td style="text-align:right">3.1MB</td>
<td style="text-align:left">the features of the authors occured in the dataset</td>
</tr>
<tr>
<td style="text-align:left"><code>info_topic.csv</code></td>
<td style="text-align:right">413KB</td>
<td style="text-align:left">the IDs of the topics occured in the dataset</td>
</tr>
<tr>
<td style="text-align:left"><code>info_token.csv</code></td>
<td style="text-align:right">409MB</td>
<td style="text-align:left">the features of the tokens occured in the dataset</td>
</tr>
</tbody>
</table>
<br>
<h3 id="22-数据集统计信息">2.2 数据集统计信息</h3>
<table>
<thead>
<tr>
<th style="text-align:left">Dataset</th>
<th style="text-align:right">ZhihuRec-100M</th>
<th style="text-align:right">ZhihuRec-20M</th>
<th style="text-align:right">ZhihuRec-1M</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><strong>#impressions</strong> *</td>
<td style="text-align:right">99,978,523</td>
<td style="text-align:right">19,999,857</td>
<td style="text-align:right">999,970</td>
</tr>
<tr>
<td style="text-align:left">#clicks</td>
<td style="text-align:right">26,981,583</td>
<td style="text-align:right">5,402,345</td>
<td style="text-align:right">268,656</td>
</tr>
<tr>
<td style="text-align:left">#clicks : #non-clicks</td>
<td style="text-align:right">1 : 2.71</td>
<td style="text-align:right">1 : 2.70</td>
<td style="text-align:right">1 : 2.72</td>
</tr>
<tr>
<td style="text-align:left"><strong>#queries</strong> *</td>
<td style="text-align:right">3,899,553</td>
<td style="text-align:right">776,201</td>
<td style="text-align:right">38,422</td>
</tr>
<tr>
<td style="text-align:left"><strong>#users</strong> *</td>
<td style="text-align:right">798,086</td>
<td style="text-align:right">159,642</td>
<td style="text-align:right">7,974</td>
</tr>
<tr>
<td style="text-align:left">avg #impressions per user</td>
<td style="text-align:right">125.27</td>
<td style="text-align:right">125.28</td>
<td style="text-align:right">125.40</td>
</tr>
<tr>
<td style="text-align:left">avg #clicks per user</td>
<td style="text-align:right">33.81</td>
<td style="text-align:right">33.84</td>
<td style="text-align:right">33.69</td>
</tr>
<tr>
<td style="text-align:left">#users with queries</td>
<td style="text-align:right">501,893</td>
<td style="text-align:right">100,271</td>
<td style="text-align:right">5,047</td>
</tr>
<tr>
<td style="text-align:left">avg #queries per user</td>
<td style="text-align:right">7.77</td>
<td style="text-align:right">7.74</td>
<td style="text-align:right">7.61</td>
</tr>
<tr>
<td style="text-align:left"><strong>#answers</strong> *</td>
<td style="text-align:right">554,976</td>
<td style="text-align:right">343,103</td>
<td style="text-align:right">81,563</td>
</tr>
<tr>
<td style="text-align:left"><strong>#questions</strong> *</td>
<td style="text-align:right">165,012</td>
<td style="text-align:right">104,130</td>
<td style="text-align:right">29,340</td>
</tr>
<tr>
<td style="text-align:left"><strong>#authors</strong> *</td>
<td style="text-align:right">240,956</td>
<td style="text-align:right">167,796</td>
<td style="text-align:right">47,888</td>
</tr>
<tr>
<td style="text-align:left"><strong>#topics</strong> *</td>
<td style="text-align:right">72,318</td>
<td style="text-align:right">54,785</td>
<td style="text-align:right">22,897</td>
</tr>
<tr>
<td style="text-align:left"><strong>#tokens</strong> *</td>
<td style="text-align:right">556,546</td>
<td style="text-align:right">428,334</td>
<td style="text-align:right">249,586</td>
</tr>
</tbody>
</table>
<br>
<h3 id="23--数据集字段">2.3  数据集字段</h3>
<blockquote>
<p>Some fields in the data set are null, which are represented by empty strings in the file.</p>
</blockquote>
<h3 id="inter_impressioncsv"><code>inter_impression.csv</code></h3>
<table>
<thead>
<tr>
<th style="text-align:right">Index</th>
<th style="text-align:center">Nullable</th>
<th style="text-align:left">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right">0</td>
<td style="text-align:center"></td>
<td style="text-align:left">user ID</td>
</tr>
<tr>
<td style="text-align:right">1</td>
<td style="text-align:center"></td>
<td style="text-align:left">answer ID</td>
</tr>
<tr>
<td style="text-align:right">2</td>
<td style="text-align:center"></td>
<td style="text-align:left">impression timestamp</td>
</tr>
<tr>
<td style="text-align:right">3</td>
<td style="text-align:center"></td>
<td style="text-align:left">click timestamp (0 for non-click)</td>
</tr>
</tbody>
</table>
<br>
<h3 id="inter_querycsv"><code>inter_query.csv</code></h3>
<table>
<thead>
<tr>
<th style="text-align:right">Index</th>
<th style="text-align:center">Nullable</th>
<th style="text-align:left">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right">0</td>
<td style="text-align:center"></td>
<td style="text-align:left">user ID</td>
</tr>
<tr>
<td style="text-align:right">1</td>
<td style="text-align:center"></td>
<td style="text-align:left">token IDs in the query (separated by spaces)</td>
</tr>
<tr>
<td style="text-align:right">2</td>
<td style="text-align:center"></td>
<td style="text-align:left">query timestamp</td>
</tr>
</tbody>
</table>
<br>
<h3 id="info_usercsv"><code>info_user.csv</code></h3>
<table>
<thead>
<tr>
<th style="text-align:right">Index</th>
<th style="text-align:center">Nullable</th>
<th style="text-align:left">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right">0</td>
<td style="text-align:center"></td>
<td style="text-align:left">user ID</td>
</tr>
<tr>
<td style="text-align:right">1</td>
<td style="text-align:center"></td>
<td style="text-align:left">register timestamp</td>
</tr>
<tr>
<td style="text-align:right">2</td>
<td style="text-align:center"></td>
<td style="text-align:left">gender</td>
</tr>
<tr>
<td style="text-align:right">3</td>
<td style="text-align:center"></td>
<td style="text-align:left">login frequency</td>
</tr>
<tr>
<td style="text-align:right">4</td>
<td style="text-align:center"></td>
<td style="text-align:left">#followers</td>
</tr>
<tr>
<td style="text-align:right">5</td>
<td style="text-align:center"></td>
<td style="text-align:left">#topics followed by this user</td>
</tr>
<tr>
<td style="text-align:right">6</td>
<td style="text-align:center"></td>
<td style="text-align:left">#questions followed by this user</td>
</tr>
<tr>
<td style="text-align:right">7</td>
<td style="text-align:center"></td>
<td style="text-align:left">#answers</td>
</tr>
<tr>
<td style="text-align:right">8</td>
<td style="text-align:center"></td>
<td style="text-align:left">#questions</td>
</tr>
<tr>
<td style="text-align:right">9</td>
<td style="text-align:center"></td>
<td style="text-align:left">#comments</td>
</tr>
<tr>
<td style="text-align:right">10</td>
<td style="text-align:center"></td>
<td style="text-align:left">#thanks received by this user</td>
</tr>
<tr>
<td style="text-align:right">11</td>
<td style="text-align:center"></td>
<td style="text-align:left">#comments received by this user</td>
</tr>
<tr>
<td style="text-align:right">12</td>
<td style="text-align:center"></td>
<td style="text-align:left">#likes received by this user</td>
</tr>
<tr>
<td style="text-align:right">13</td>
<td style="text-align:center"></td>
<td style="text-align:left">#dislikes received by this user</td>
</tr>
<tr>
<td style="text-align:right">14</td>
<td style="text-align:center"></td>
<td style="text-align:left">register type</td>
</tr>
<tr>
<td style="text-align:right">15</td>
<td style="text-align:center"></td>
<td style="text-align:left">register platform</td>
</tr>
<tr>
<td style="text-align:right">16</td>
<td style="text-align:center"></td>
<td style="text-align:left">from android or not</td>
</tr>
<tr>
<td style="text-align:right">17</td>
<td style="text-align:center"></td>
<td style="text-align:left">from iphone or not</td>
</tr>
<tr>
<td style="text-align:right">18</td>
<td style="text-align:center"></td>
<td style="text-align:left">from ipad or not</td>
</tr>
<tr>
<td style="text-align:right">19</td>
<td style="text-align:center"></td>
<td style="text-align:left">from pc or not</td>
</tr>
<tr>
<td style="text-align:right">20</td>
<td style="text-align:center"></td>
<td style="text-align:left">from mobile web or not</td>
</tr>
<tr>
<td style="text-align:right">21</td>
<td style="text-align:center"></td>
<td style="text-align:left">device model</td>
</tr>
<tr>
<td style="text-align:right">22</td>
<td style="text-align:center"></td>
<td style="text-align:left">device brand</td>
</tr>
<tr>
<td style="text-align:right">23</td>
<td style="text-align:center"></td>
<td style="text-align:left">platform</td>
</tr>
<tr>
<td style="text-align:right">24</td>
<td style="text-align:center"></td>
<td style="text-align:left">province</td>
</tr>
<tr>
<td style="text-align:right">25</td>
<td style="text-align:center"></td>
<td style="text-align:left">city</td>
</tr>
<tr>
<td style="text-align:right">26</td>
<td style="text-align:center">$\sqrt{}$</td>
<td style="text-align:left">topic IDs followed by this user (separated by spaces)</td>
</tr>
</tbody>
</table>
<br>
<h3 id="info_answercsv"><code>info_answer.csv</code></h3>
<table>
<thead>
<tr>
<th style="text-align:right">Index</th>
<th style="text-align:center">Nullable</th>
<th style="text-align:left">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right">0</td>
<td style="text-align:center"></td>
<td style="text-align:left">answer ID</td>
</tr>
<tr>
<td style="text-align:right">1</td>
<td style="text-align:center">$\sqrt{}$</td>
<td style="text-align:left">question ID</td>
</tr>
<tr>
<td style="text-align:right">2</td>
<td style="text-align:center"></td>
<td style="text-align:left">anonymous or not</td>
</tr>
<tr>
<td style="text-align:right">3</td>
<td style="text-align:center">$\sqrt{}$</td>
<td style="text-align:left">author ID (null for anonymous)</td>
</tr>
<tr>
<td style="text-align:right">4</td>
<td style="text-align:center"></td>
<td style="text-align:left">labeled high-value answer or not</td>
</tr>
<tr>
<td style="text-align:right">5</td>
<td style="text-align:center"></td>
<td style="text-align:left">recommended by the editor or not</td>
</tr>
<tr>
<td style="text-align:right">6</td>
<td style="text-align:center"></td>
<td style="text-align:left">create timestamp</td>
</tr>
<tr>
<td style="text-align:right">7</td>
<td style="text-align:center"></td>
<td style="text-align:left">contain pictures or not</td>
</tr>
<tr>
<td style="text-align:right">8</td>
<td style="text-align:center"></td>
<td style="text-align:left">contain videos or not</td>
</tr>
<tr>
<td style="text-align:right">9</td>
<td style="text-align:center"></td>
<td style="text-align:left">#thanks</td>
</tr>
<tr>
<td style="text-align:right">10</td>
<td style="text-align:center"></td>
<td style="text-align:left">#likes</td>
</tr>
<tr>
<td style="text-align:right">11</td>
<td style="text-align:center"></td>
<td style="text-align:left">#comments</td>
</tr>
<tr>
<td style="text-align:right">12</td>
<td style="text-align:center"></td>
<td style="text-align:left">#collections</td>
</tr>
<tr>
<td style="text-align:right">13</td>
<td style="text-align:center"></td>
<td style="text-align:left">#dislikes</td>
</tr>
<tr>
<td style="text-align:right">14</td>
<td style="text-align:center"></td>
<td style="text-align:left">#reports</td>
</tr>
<tr>
<td style="text-align:right">15</td>
<td style="text-align:center"></td>
<td style="text-align:left">#helpless</td>
</tr>
<tr>
<td style="text-align:right">16</td>
<td style="text-align:center">$\sqrt{}$</td>
<td style="text-align:left">token IDs in the answer (separated by spaces)</td>
</tr>
<tr>
<td style="text-align:right">17</td>
<td style="text-align:center">$\sqrt{}$</td>
<td style="text-align:left">topic IDs of the answer (separated by spaces)</td>
</tr>
</tbody>
</table>
<br>
<h3 id="info_questioncsv"><code>info_question.csv</code></h3>
<table>
<thead>
<tr>
<th style="text-align:right">Index</th>
<th style="text-align:center">Nullable</th>
<th style="text-align:left">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right">0</td>
<td style="text-align:center"></td>
<td style="text-align:left">question ID</td>
</tr>
<tr>
<td style="text-align:right">1</td>
<td style="text-align:center"></td>
<td style="text-align:left">create timestamp</td>
</tr>
<tr>
<td style="text-align:right">2</td>
<td style="text-align:center"></td>
<td style="text-align:left">#answers</td>
</tr>
<tr>
<td style="text-align:right">3</td>
<td style="text-align:center"></td>
<td style="text-align:left">#followers</td>
</tr>
<tr>
<td style="text-align:right">4</td>
<td style="text-align:center"></td>
<td style="text-align:left">#invitations</td>
</tr>
<tr>
<td style="text-align:right">5</td>
<td style="text-align:center"></td>
<td style="text-align:left">#comments</td>
</tr>
<tr>
<td style="text-align:right">6</td>
<td style="text-align:center">$\sqrt{}$</td>
<td style="text-align:left">token IDs in the question (separated by spaces)</td>
</tr>
<tr>
<td style="text-align:right">7</td>
<td style="text-align:center">$\sqrt{}$</td>
<td style="text-align:left">topic IDs of the queation (separated by spaces)</td>
</tr>
</tbody>
</table>
<br>
<h3 id="info_authorcsv"><code>info_author.csv</code></h3>
<table>
<thead>
<tr>
<th style="text-align:right">Index</th>
<th style="text-align:center">Nullable</th>
<th style="text-align:left">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right">0</td>
<td style="text-align:center"></td>
<td style="text-align:left">author ID</td>
</tr>
<tr>
<td style="text-align:right">1</td>
<td style="text-align:center"></td>
<td style="text-align:left">is excellent author or not</td>
</tr>
<tr>
<td style="text-align:right">2</td>
<td style="text-align:center"></td>
<td style="text-align:left">#followers</td>
</tr>
<tr>
<td style="text-align:right">3</td>
<td style="text-align:center"></td>
<td style="text-align:left">is excellent answerer or not</td>
</tr>
</tbody>
</table>
<br>
<h3 id="info_topiccsv"><code>info_topic.csv</code></h3>
<table>
<thead>
<tr>
<th style="text-align:right">Index</th>
<th style="text-align:center">Nullable</th>
<th style="text-align:left">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right">0</td>
<td style="text-align:center"></td>
<td style="text-align:left">topic ID</td>
</tr>
</tbody>
</table>
<br>
<h3 id="info_tokencsv"><code>info_token.csv</code></h3>
<table>
<thead>
<tr>
<th style="text-align:right">Index</th>
<th style="text-align:center">Nullable</th>
<th style="text-align:left">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right">0</td>
<td style="text-align:center"></td>
<td style="text-align:left">token ID *</td>
</tr>
<tr>
<td style="text-align:right">1</td>
<td style="text-align:center"></td>
<td style="text-align:left">word vector trained by word2vec (64 dimensions, separated by spaces)</td>
</tr>
</tbody>
</table>
<blockquote>
<p>* ZhihuRec can&rsquo;t provide the corresponding text of tokens for privacy reasons. Researchers can use word vectors in the dataset or train word vectors from scratch.</p>
</blockquote>
<p><br><br></p>
<h2 id="引用说明">引用说明</h2>
<p>ZhihuRec dataset can be downloaded from <a href="https://cloud.tsinghua.edu.cn/d/d6c045c55aa14bb39ebc/">here</a>, and it is for the paper:</p>
<p><a href="https://arxiv.org/abs/2106.06467">Bin Hao, Min Zhang, Weizhi Ma, Shaoyun Shi, Xinxing Yu, Houzhi Shan, Yiqun Liu and Shaoping Ma, 2021, A Large-Scale Rich Context Query and Recommendation Dataset in Online Knowledge-Sharing. arXiv preprint arXiv:2106.06467.</a></p>
<p>please cite the paper if you use this dataset:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">@misc{hao2021largescale,
      title={A Large-Scale Rich Context Query and Recommendation Dataset in Online Knowledge-Sharing},
      author={Bin Hao and Min Zhang and Weizhi Ma and Shaoyun Shi and Xinxing Yu and Houzhi Shan and Yiqun Liu and Shaoping Ma},
      year={2021},
      eprint={2106.06467},
      archivePrefix={arXiv},
      primaryClass={cs.IR}
}
</code></pre></div><p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://hidadeng.github.io/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://hidadeng.github.io/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://hidadeng.github.io/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>数据集 | 585w企业工商注册信息</title>
      <link>https://textdata.cn/blog/2022-12-07-585w-chinese-enterprise-registration-data/</link>
      <pubDate>Tue, 06 Dec 2022 00:00:00 +0000</pubDate>
      
      <guid>/blog/2022-12-07-585w-chinese-enterprise-registration-data/</guid>
      <description>585w企业工商注册信息</description>
      <content:encoded><![CDATA[<p>1978-2019.4,  585w中国大陆企业注册信息</p>
<p>文末有 enterprise-registration-data-of-chinese-mainland.csv 数据获取方式。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;enterprise-registration-data-of-chinese-mainland.csv&#39;</span><span class="p">,</span> 
                 <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">,</span> 
                 <span class="c1">#忽略有问题的记录</span>
                 <span class="n">on_bad_lines</span><span class="o">=</span><span class="s1">&#39;skip&#39;</span><span class="p">)</span>

<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<p><img loading="lazy" src="img/df1.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#剔除大邓广告</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;企业类型&#39;</span><span class="p">]</span><span class="o">!=</span><span class="s1">&#39;公众号: 大邓和他的Python&#39;</span><span class="p">]</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<p><img loading="lazy" src="img/df2.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#记录</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;记录数: &#39;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">))</span>

<span class="c1">#</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;字段有: &#39;</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">&#39;记录数: 12756270&#39;

&#39;字段有: [&#39;企业名称&#39;, &#39;统一社会信用代码&#39;, &#39;注册日期&#39;, &#39;企业类型&#39;, &#39;法人代表&#39;, &#39;注册资金&#39;, &#39;经营范围&#39;, &#39;所在省份&#39;,
       &#39;地区&#39;, &#39;注册地址&#39;]&#39;
</code></pre></div><br>
<p>但数据可能会有重复，这里以企业名称作为唯一标识，可以查看真实的数据量</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;真实记录数: &#39;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;企业名称&#39;</span><span class="p">])))</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">&#39;真实记录数: 5888382&#39;
</code></pre></div><br>
<br>
<h2 id="二如何将多个csv汇总到一个csv中">二、如何将多个csv汇总到一个csv中？</h2>
<p>那么这个enterprise-registration-data-of-chinese-mainland.csv怎么来的？</p>
<p>原始的数据集结构</p>
<p><img loading="lazy" src="img/screen-1.png" alt=""  />

<img loading="lazy" src="img/screen-2.png" alt=""  />
</p>
<br>
<p>先局部实验成功后，推广到整体。</p>
<ol>
<li>获取路径列表</li>
<li>尝试读取任意一个csv文件</li>
<li>尝试合并两个df</li>
<li>合并所有csv到一个文件内</li>
</ol>
<br>
<h3 id="21-获取路径列表">2.1 获取路径列表</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">os</span>

<span class="c1">#大邓电脑为Mac</span>
<span class="c1">#Mac容易在文件夹中生成奇怪的.DS_Store</span>
<span class="c1">#该操作为获取文件夹列表，同时剔除.DS_Store</span>
<span class="n">y_dirs</span> <span class="o">=</span> <span class="p">[</span><span class="n">di</span> <span class="k">for</span> <span class="n">di</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="s1">&#39;csv&#39;</span><span class="p">)</span> <span class="k">if</span> <span class="s1">&#39;.DS_Store&#39;</span><span class="o">!=</span><span class="n">di</span><span class="p">]</span>
<span class="k">for</span> <span class="n">y_dir</span> <span class="ow">in</span> <span class="n">y_dirs</span><span class="p">:</span>
    <span class="c1">#在年份文件夹内有很多csv文件</span>
    <span class="n">fs</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;csv/</span><span class="si">{}</span><span class="s1">/</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">y_dir</span><span class="p">,</span> <span class="n">fn</span><span class="p">)</span> 
          <span class="k">for</span> <span class="n">fn</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="s1">&#39;csv/</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">y_dir</span><span class="p">))</span>
          <span class="k">if</span> <span class="s1">&#39;.csv&#39;</span> <span class="ow">in</span> <span class="n">fn</span><span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">fs</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">......
......
[&#39;csv/2013/河南.csv&#39;, &#39;csv/2013/青海.csv&#39;, &#39;csv/2013/河北.csv&#39;, &#39;csv/2013/浙江.csv&#39;, &#39;csv/2013/内蒙古.csv&#39;, &#39;csv/2013/辽宁.csv&#39;, &#39;csv/2013/天津.csv&#39;, &#39;csv/2013/福建.csv&#39;, &#39;csv/2013/吉林.csv&#39;, &#39;csv/2013/西藏.csv&#39;, &#39;csv/2013/四川.csv&#39;, &#39;csv/2013/云南.csv&#39;, &#39;csv/2013/宁夏.csv&#39;, &#39;csv/2013/新疆.csv&#39;, &#39;csv/2013/安徽.csv&#39;, &#39;csv/2013/重庆.csv&#39;, &#39;csv/2013/贵州.csv&#39;, &#39;csv/2013/湖南.csv&#39;, &#39;csv/2013/海南.csv&#39;, &#39;csv/2013/湖北.csv&#39;, &#39;csv/2013/江西.csv&#39;, &#39;csv/2013/广东.csv&#39;, &#39;csv/2013/北京.csv&#39;, &#39;csv/2013/山西.csv&#39;, &#39;csv/2013/上海.csv&#39;, &#39;csv/2013/陕西.csv&#39;, &#39;csv/2013/黑龙江.csv&#39;, &#39;csv/2013/甘肃.csv&#39;, &#39;csv/2013/江苏.csv&#39;, &#39;csv/2013/山东.csv&#39;, &#39;csv/2013/广西.csv&#39;]

[&#39;csv/2014/河南.csv&#39;, &#39;csv/2014/青海.csv&#39;, &#39;csv/2014/河北.csv&#39;, &#39;csv/2014/浙江.csv&#39;, &#39;csv/2014/内蒙古.csv&#39;, &#39;csv/2014/辽宁.csv&#39;, &#39;csv/2014/天津.csv&#39;, &#39;csv/2014/福建.csv&#39;, &#39;csv/2014/吉林.csv&#39;, &#39;csv/2014/西藏.csv&#39;, &#39;csv/2014/四川.csv&#39;, &#39;csv/2014/云南.csv&#39;, &#39;csv/2014/宁夏.csv&#39;, &#39;csv/2014/新疆.csv&#39;, &#39;csv/2014/安徽.csv&#39;, &#39;csv/2014/重庆.csv&#39;, &#39;csv/2014/贵州.csv&#39;, &#39;csv/2014/湖南.csv&#39;, &#39;csv/2014/海南.csv&#39;, &#39;csv/2014/湖北.csv&#39;, &#39;csv/2014/江西.csv&#39;, &#39;csv/2014/广东.csv&#39;, &#39;csv/2014/北京.csv&#39;, &#39;csv/2014/山西.csv&#39;, &#39;csv/2014/上海.csv&#39;, &#39;csv/2014/陕西.csv&#39;, &#39;csv/2014/黑龙江.csv&#39;, &#39;csv/2014/甘肃.csv&#39;, &#39;csv/2014/江苏.csv&#39;, &#39;csv/2014/山东.csv&#39;, &#39;csv/2014/广西.csv&#39;]

[&#39;csv/2015/河南.csv&#39;, &#39;csv/2015/青海.csv&#39;, &#39;csv/2015/河北.csv&#39;, &#39;csv/2015/浙江.csv&#39;, &#39;csv/2015/内蒙古.csv&#39;, &#39;csv/2015/辽宁.csv&#39;, &#39;csv/2015/天津.csv&#39;, &#39;csv/2015/福建.csv&#39;, &#39;csv/2015/吉林.csv&#39;, &#39;csv/2015/西藏.csv&#39;, &#39;csv/2015/四川.csv&#39;, &#39;csv/2015/云南.csv&#39;, &#39;csv/2015/宁夏.csv&#39;, &#39;csv/2015/新疆.csv&#39;, &#39;csv/2015/安徽.csv&#39;, &#39;csv/2015/重庆.csv&#39;, &#39;csv/2015/贵州.csv&#39;, &#39;csv/2015/湖南.csv&#39;, &#39;csv/2015/海南.csv&#39;, &#39;csv/2015/湖北.csv&#39;, &#39;csv/2015/江西.csv&#39;, &#39;csv/2015/广东.csv&#39;, &#39;csv/2015/北京.csv&#39;, &#39;csv/2015/山西.csv&#39;, &#39;csv/2015/上海.csv&#39;, &#39;csv/2015/陕西.csv&#39;, &#39;csv/2015/黑龙江.csv&#39;, &#39;csv/2015/甘肃.csv&#39;, &#39;csv/2015/江苏.csv&#39;, &#39;csv/2015/山东.csv&#39;, &#39;csv/2015/广西.csv&#39;]

.....
.....
</code></pre></div><p><br><br></p>
<h3 id="22-尝试读取任意一个csv文件">2.2 尝试读取任意一个csv文件</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">df1</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;csv/2012/辽宁.csv&#39;</span><span class="p">,</span> 
                  <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">,</span> 
                  <span class="n">on_bad_lines</span><span class="o">=</span><span class="s1">&#39;skip&#39;</span><span class="p">)</span>

<span class="n">df1</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<p><img loading="lazy" src="img/df3.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df2</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;csv/2013/青海.csv&#39;</span><span class="p">,</span> 
                  <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">,</span> 
                  <span class="n">on_bad_lines</span><span class="o">=</span><span class="s1">&#39;skip&#39;</span><span class="p">)</span>

<span class="n">df2</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<p><img loading="lazy" src="img/df4.png" alt=""  />
</p>
<br>
<h3 id="23-尝试合并两个df">2.3 尝试合并两个df</h3>
<p>两个df垂直方向堆积，不增加字段种类，所以选择 pd.concat函数。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df12</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">df1</span><span class="p">,</span> <span class="n">df2</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">df12</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<p><img loading="lazy" src="img/df3.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#检查记录数</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">df1</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">df2</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">df12</span><span class="p">))</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">10246
4417
14663
</code></pre></div><br>
<h3 id="24-合并所有csv到一个文件内">2.4 合并所有csv到一个文件内</h3>
<p>将步骤1、2、3代码整理，汇总</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="c1">#存df列表</span>
<span class="n">dfs</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1">#文件路径列表</span>
<span class="n">y_dirs</span> <span class="o">=</span> <span class="p">[</span><span class="n">di</span> <span class="k">for</span> <span class="n">di</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="s1">&#39;csv&#39;</span><span class="p">)</span> <span class="k">if</span> <span class="s1">&#39;.DS_Store&#39;</span><span class="o">!=</span><span class="n">di</span><span class="p">]</span>
<span class="k">for</span> <span class="n">y_dir</span> <span class="ow">in</span> <span class="n">y_dirs</span><span class="p">:</span>
    <span class="n">csvfs</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;csv/</span><span class="si">{}</span><span class="s1">/</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">y_dir</span><span class="p">,</span> <span class="n">fn</span><span class="p">)</span> 
             <span class="k">for</span> <span class="n">fn</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="s1">&#39;csv/</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">y_dir</span><span class="p">))</span>
             <span class="k">if</span> <span class="s1">&#39;.csv&#39;</span> <span class="ow">in</span> <span class="n">fn</span><span class="p">]</span>
    
    <span class="k">for</span> <span class="n">csvf</span> <span class="ow">in</span> <span class="n">csvfs</span><span class="p">:</span>
        
        <span class="c1">#读取csv，得到df</span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">csvf</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">,</span> <span class="n">on_bad_lines</span><span class="o">=</span><span class="s1">&#39;skip&#39;</span><span class="p">)</span>
        <span class="c1">#存入df列表</span>
        <span class="n">dfs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
        
<span class="c1">#合并dfs为alldf</span>
<span class="n">alldf</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">dfs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1">#导出为data.csv</span>
<span class="n">alldf</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;enterprise-registration-data-of-chinese-mainland.csv&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</code></pre></div><p><br><br></p>
<h2 id="三数据获取">三、数据获取</h2>
<p>转发本文至朋友圈集赞50+， 加微信372335839， 备注【姓名-学校-专业-1200w工商】获取本文数据。</p>
<p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>12G数据集 |  23w条Kickstarter项目信息</title>
      <link>https://textdata.cn/blog/2022-12-04-kickstarters_dataset/</link>
      <pubDate>Sun, 04 Dec 2022 00:00:00 +0000</pubDate>
      
      <guid>/blog/2022-12-04-kickstarters_dataset/</guid>
      <description>2016年3月写好的kickstarter爬虫，每月执行一次。截止2022年11月， 所有压缩文件累积11.42G。文末有数据获取方式</description>
      <content:encoded><![CDATA[<h2 id="kickstarter介绍">Kickstarter介绍</h2>
<p>Kickstarter于2009年4月在美国纽约成立，是一个专为具有创意方案的企业筹资的众筹网站平台。</p>
<p>kickstarter平台的运作方式相对来说比较简单而有效：该平台的用户一方是有创新意渴望进行创作和创造的人，另一方则是愿意为他们出资金的人，然后见证新发明新创作新产品的出现。kickstarter网站的创意性活动包括：<strong>音乐，网页设计，平面设计，动画，作家</strong>以及所有有能力创造以及影响他人的活动。</p>
<p><br><br></p>
<h2 id="12g数据集">12G数据集</h2>
<p><strong>2016年3月</strong> 写好的kickstarter爬虫，每月执行一次。截止<strong>2022年11月</strong>， 所有压缩文件累积11.42G。<strong>文末有数据获取方式</strong></p>
<p><img loading="lazy" src="img/kickstarter_datasets_dir_screen.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="参考论文">参考论文</h2>
<p>该数据集研究价值，可用于研究市场营销、创新创业、信息管理等， 部分使用kickstarter作为研究对象的论文。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">[1]王伟,陈伟,祝效国,王洪伟. 众筹融资成功率与语言风格的说服性-基于Kickstarter的实证研究.*管理世界*.2016;5:81-98.
[2]Dai, Hengchen and Dennis J. Zhang. “Prosocial Goal Pursuit in Crowdfunding: Evidence from Kickstarter.” Journal of Marketing Research 56 (2019): 498 - 517.
[3]Gafni, H., Marom, D.M., Robb, A.M., &amp; Sade, O. (2020). Gender Dynamics in Crowdfunding (Kickstarter): Evidence on Entrepreneurs, Backers, and Taste-Based Discrimination*. Review of Finance.
[4]Jensen, Lasse Skovgaard and Ali Gürcan Özkil. “Identifying challenges in crowdfunded product development: a review of Kickstarter projects.” Design Science 4 (2018): n. pag.
</code></pre></div><br>
<br>
<h2 id="查看数据">查看数据</h2>
<p>任意选择一个zip文件解压会得到json文件，注意 <strong>不同json文件不太一样，所以本文的代码可能要有调整。</strong></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="c1">#读取任意一个zip解压得到的csv文件</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_json</span><span class="p">(</span><span class="s1">&#39;data/Kickstarter_2022-06-09T03_20_03_365Z.json&#39;</span><span class="p">,</span> <span class="n">lines</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<p><img loading="lazy" src="img/df.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">230346
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1"># 选中projects字段</span>
<span class="n">projects</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;data&#39;</span><span class="p">]</span>
<span class="n">projects</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">    0         {&#39;id&#39;: 947118202, &#39;photo&#39;: {&#39;key&#39;: &#39;assets/029...
    1         {&#39;id&#39;: 426094497, &#39;photo&#39;: {&#39;key&#39;: &#39;assets/029...
    2         {&#39;id&#39;: 44835253, &#39;photo&#39;: {&#39;key&#39;: &#39;assets/034/...
    3         {&#39;id&#39;: 1001767271, &#39;photo&#39;: {&#39;key&#39;: &#39;assets/03...
    4         {&#39;id&#39;: 1880345176, &#39;photo&#39;: {&#39;key&#39;: &#39;assets/03...
                                    ...                        
    230341    {&#39;id&#39;: 676753351, &#39;photo&#39;: {&#39;key&#39;: &#39;assets/012...
    230342    {&#39;id&#39;: 1579378115, &#39;photo&#39;: {&#39;key&#39;: &#39;assets/02...
    230343    {&#39;id&#39;: 1281094926, &#39;photo&#39;: {&#39;key&#39;: &#39;assets/02...
    230344    {&#39;id&#39;: 783009016, &#39;photo&#39;: {&#39;key&#39;: &#39;assets/012...
    230345    {&#39;id&#39;: 324368296, &#39;photo&#39;: {&#39;key&#39;: &#39;assets/012...
    Name: data, Length: 230346, dtype: object
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#查看第一行，data列</span>
<span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;data&#39;</span><span class="p">]</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">    {&#39;id&#39;: 947118202,
     &#39;photo&#39;: {&#39;key&#39;: &#39;assets/029/542/393/098b025d0c25cc15e5b5f673b9ec992a_original.png&#39;,
      &#39;full&#39;: &#39;https://ksr-ugc.imgix.net/assets/029/542/393/098b025d0c25cc15e5b5f673b9ec992a_original.png?ixlib=rb-4.0.2&amp;crop=faces&amp;w=560&amp;h=315&amp;fit=crop&amp;v=1592675400&amp;auto=format&amp;frame=1&amp;q=92&amp;s=26209d432871ad2e9cca642527c291d9&#39;,
      &#39;ed&#39;: &#39;https://ksr-ugc.imgix.net/assets/029/542/393/098b025d0c25cc15e5b5f673b9ec992a_original.png?ixlib=rb-4.0.2&amp;crop=faces&amp;w=352&amp;h=198&amp;fit=crop&amp;v=1592675400&amp;auto=format&amp;frame=1&amp;q=92&amp;s=db82255e6639d5951506e0f2ed4d7d8b&#39;,
      &#39;med&#39;: &#39;https://ksr-ugc.imgix.net/assets/029/542/393/098b025d0c25cc15e5b5f673b9ec992a_original.png?ixlib=rb-4.0.2&amp;crop=faces&amp;w=272&amp;h=153&amp;fit=crop&amp;v=1592675400&amp;auto=format&amp;frame=1&amp;q=92&amp;s=f7b43116136000c8efa892bdbdd2d956&#39;,
      &#39;little&#39;: &#39;https://ksr-ugc.imgix.net/assets/029/542/393/098b025d0c25cc15e5b5f673b9ec992a_original.png?ixlib=rb-4.0.2&amp;crop=faces&amp;w=208&amp;h=117&amp;fit=crop&amp;v=1592675400&amp;auto=format&amp;frame=1&amp;q=92&amp;s=a52e3c34066a020e040c517c614a8b36&#39;,
      &#39;small&#39;: &#39;https://ksr-ugc.imgix.net/assets/029/542/393/098b025d0c25cc15e5b5f673b9ec992a_original.png?ixlib=rb-4.0.2&amp;crop=faces&amp;w=160&amp;h=90&amp;fit=crop&amp;v=1592675400&amp;auto=format&amp;frame=1&amp;q=92&amp;s=6c5f1c254119ffe914b50250f8e2899f&#39;,
      &#39;thumb&#39;: &#39;https://ksr-ugc.imgix.net/assets/029/542/393/098b025d0c25cc15e5b5f673b9ec992a_original.png?ixlib=rb-4.0.2&amp;crop=faces&amp;w=48&amp;h=27&amp;fit=crop&amp;v=1592675400&amp;auto=format&amp;frame=1&amp;q=92&amp;s=0222f379ed51059eb73adc7436f07b1e&#39;,
      &#39;1024x576&#39;: &#39;https://ksr-ugc.imgix.net/assets/029/542/393/098b025d0c25cc15e5b5f673b9ec992a_original.png?ixlib=rb-4.0.2&amp;crop=faces&amp;w=1024&amp;h=576&amp;fit=crop&amp;v=1592675400&amp;auto=format&amp;frame=1&amp;q=92&amp;s=d01546c5e88f3f47e0dddc48b5dce9df&#39;,
      &#39;1536x864&#39;: &#39;https://ksr-ugc.imgix.net/assets/029/542/393/098b025d0c25cc15e5b5f673b9ec992a_original.png?ixlib=rb-4.0.2&amp;crop=faces&amp;w=1552&amp;h=873&amp;fit=crop&amp;v=1592675400&amp;auto=format&amp;frame=1&amp;q=92&amp;s=f47505da909a374642906e6d418474e7&#39;},
     &#39;name&#39;: &#39;Paint Rogue&#39;,
     &#39;blurb&#39;: &#39;Roguelike | Platformer | Shooter&#39;,
     &#39;goal&#39;: 5000,
     &#39;pledged&#39;: 5268.22,
     &#39;state&#39;: &#39;successful&#39;,
     &#39;slug&#39;: &#39;paint-rogue&#39;,
     &#39;disable_communication&#39;: False,
     &#39;country&#39;: &#39;AU&#39;,
     &#39;country_displayable_name&#39;: &#39;Australia&#39;,
     &#39;currency&#39;: &#39;AUD&#39;,
     &#39;currency_symbol&#39;: &#39;$&#39;,
     &#39;currency_trailing_code&#39;: True,
     &#39;deadline&#39;: 1594247312,
     &#39;state_changed_at&#39;: 1594247312,
     &#39;created_at&#39;: 1591152439,
     &#39;launched_at&#39;: 1591655312,
     &#39;staff_pick&#39;: False,
     &#39;is_starrable&#39;: False,
     &#39;backers_count&#39;: 42,
     &#39;static_usd_rate&#39;: 0.69681992,
     &#39;usd_pledged&#39;: &#39;3671.0006389424&#39;,
     &#39;converted_pledged_amount&#39;: 3657,
     &#39;fx_rate&#39;: 0.7200616400000001,
     &#39;usd_exchange_rate&#39;: 0.69423473,
     &#39;current_currency&#39;: &#39;USD&#39;,
     &#39;usd_type&#39;: &#39;international&#39;,
     &#39;creator&#39;: {&#39;id&#39;: 1018782761,
      &#39;name&#39;: &#39;Andrew Von Stieglitz&#39;,
      &#39;is_registered&#39;: None,
      &#39;is_email_verified&#39;: None,
      &#39;chosen_currency&#39;: None,
      &#39;is_superbacker&#39;: None,
      &#39;avatar&#39;: {&#39;thumb&#39;: &#39;https://ksr-ugc.imgix.net/assets/024/628/691/39e3fdc8db723302f544f7161e32c4b7_original.png?ixlib=rb-4.0.2&amp;w=40&amp;h=40&amp;fit=crop&amp;v=1554207776&amp;auto=format&amp;frame=1&amp;q=92&amp;s=bf4ce960e83b57310b93c40dda68e213&#39;,
       &#39;small&#39;: &#39;https://ksr-ugc.imgix.net/assets/024/628/691/39e3fdc8db723302f544f7161e32c4b7_original.png?ixlib=rb-4.0.2&amp;w=80&amp;h=80&amp;fit=crop&amp;v=1554207776&amp;auto=format&amp;frame=1&amp;q=92&amp;s=a862ab30490c90cd08186f448884142d&#39;,
       &#39;medium&#39;: &#39;https://ksr-ugc.imgix.net/assets/024/628/691/39e3fdc8db723302f544f7161e32c4b7_original.png?ixlib=rb-4.0.2&amp;w=160&amp;h=160&amp;fit=crop&amp;v=1554207776&amp;auto=format&amp;frame=1&amp;q=92&amp;s=38923ac11699d68a7aae93ce126b97b6&#39;},
      &#39;urls&#39;: {&#39;web&#39;: {&#39;user&#39;: &#39;https://www.kickstarter.com/profile/1018782761&#39;},
       &#39;api&#39;: {&#39;user&#39;: &#39;https://api.kickstarter.com/v1/users/1018782761?signature=1654832212.14f9df54b2643f080ad98cacb07314f94757d9c1&#39;}}},
     &#39;location&#39;: {&#39;id&#39;: 1105779,
      &#39;name&#39;: &#39;Sydney&#39;,
      &#39;slug&#39;: &#39;sydney-au&#39;,
      &#39;short_name&#39;: &#39;Sydney, AU&#39;,
      &#39;displayable_name&#39;: &#39;Sydney, AU&#39;,
      &#39;localized_name&#39;: &#39;Sydney&#39;,
      &#39;country&#39;: &#39;AU&#39;,
      &#39;state&#39;: &#39;NSW&#39;,
      &#39;type&#39;: &#39;Town&#39;,
      &#39;is_root&#39;: False,
      &#39;expanded_country&#39;: &#39;Australia&#39;,
      &#39;urls&#39;: {&#39;web&#39;: {&#39;discover&#39;: &#39;https://www.kickstarter.com/discover/places/sydney-au&#39;,
        &#39;location&#39;: &#39;https://www.kickstarter.com/locations/sydney-au&#39;},
       &#39;api&#39;: {&#39;nearby_projects&#39;: &#39;https://api.kickstarter.com/v1/discover?signature=1654814982.2fcf49a7b611d4414d14b1dbe41ac53623192e6a&amp;woe_id=1105779&#39;}}},
     &#39;category&#39;: {&#39;id&#39;: 35,
      &#39;name&#39;: &#39;Video Games&#39;,
      &#39;analytics_name&#39;: &#39;Video Games&#39;,
      &#39;slug&#39;: &#39;games/video games&#39;,
      &#39;position&#39;: 7,
      &#39;parent_id&#39;: 12,
      &#39;parent_name&#39;: &#39;Games&#39;,
      &#39;color&#39;: 51627,
      &#39;urls&#39;: {&#39;web&#39;: {&#39;discover&#39;: &#39;http://www.kickstarter.com/discover/categories/games/video%20games&#39;}}},
     &#39;profile&#39;: {&#39;id&#39;: 4007060,
      &#39;project_id&#39;: 4007060,
      &#39;state&#39;: &#39;active&#39;,
      &#39;state_changed_at&#39;: 1594267960,
      &#39;name&#39;: &#39;Paint Rogue&#39;,
      &#39;blurb&#39;: &#39;Roguelike | Platformer | Shooter&#39;,
      &#39;background_color&#39;: &#39;&#39;,
      &#39;text_color&#39;: &#39;ffffff&#39;,
      &#39;link_background_color&#39;: &#39;&#39;,
      &#39;link_text_color&#39;: &#39;&#39;,
      &#39;link_text&#39;: &#39;Follow along!&#39;,
      &#39;link_url&#39;: &#39;https://www.kickstarter.com/projects/1018782761/paint-rogue/&#39;,
      &#39;show_feature_image&#39;: True,
      &#39;background_image_opacity&#39;: 0.5700000000000001,
      &#39;background_image_attributes&#39;: {&#39;id&#39;: 29758105,
       &#39;image_urls&#39;: {&#39;default&#39;: &#39;https://ksr-ugc.imgix.net/assets/029/758/105/971e42c0e19ca75fbae0943aa874c3c2_original.png?ixlib=rb-4.0.2&amp;w=1600&amp;fit=max&amp;v=1594267934&amp;auto=format&amp;frame=1&amp;q=92&amp;s=b91907c9e125e206a11a1bcef322c142&#39;,
        &#39;baseball_card&#39;: &#39;https://ksr-ugc.imgix.net/assets/029/758/105/971e42c0e19ca75fbae0943aa874c3c2_original.png?ixlib=rb-4.0.2&amp;w=460&amp;fit=max&amp;v=1594267934&amp;auto=format&amp;frame=1&amp;q=92&amp;s=e7af2286d1f74a51672fbb6060ad43c8&#39;}},
      &#39;should_show_feature_image_section&#39;: False,
      &#39;feature_image_attributes&#39;: {&#39;image_urls&#39;: {&#39;default&#39;: &#39;https://ksr-ugc.imgix.net/assets/029/542/393/098b025d0c25cc15e5b5f673b9ec992a_original.png?ixlib=rb-4.0.2&amp;crop=faces&amp;w=1552&amp;h=873&amp;fit=crop&amp;v=1592675400&amp;auto=format&amp;frame=1&amp;q=92&amp;s=f47505da909a374642906e6d418474e7&#39;,
        &#39;baseball_card&#39;: &#39;https://ksr-ugc.imgix.net/assets/029/542/393/098b025d0c25cc15e5b5f673b9ec992a_original.png?ixlib=rb-4.0.2&amp;crop=faces&amp;w=560&amp;h=315&amp;fit=crop&amp;v=1592675400&amp;auto=format&amp;frame=1&amp;q=92&amp;s=26209d432871ad2e9cca642527c291d9&#39;}}},
     &#39;spotlight&#39;: True,
     &#39;urls&#39;: {&#39;web&#39;: {&#39;project&#39;: &#39;https://www.kickstarter.com/projects/1018782761/paint-rogue?ref=discovery_category_newest&#39;,
       &#39;rewards&#39;: &#39;https://www.kickstarter.com/projects/1018782761/paint-rogue/rewards&#39;}},
     &#39;source_url&#39;: &#39;https://www.kickstarter.com/discover/categories/games/video%20games&#39;}
</code></pre></div><p><br><br></p>
<h2 id="字段">字段</h2>
<p>以第一条为例，查看每条众筹项目数据中的字段，</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;data&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
</code></pre></div><p>Run，运行结果#为后期加入的字段解释</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">    dict_keys([
    &#39;id&#39;, &#39;photo&#39;,  #id、图片链接
    &#39;name&#39;, &#39;blurb&#39;,  #项目名
    &#39;goal&#39;,   #项目筹资目标金额
    &#39;pledged&#39;, 
    &#39;state&#39;,  #项目状态
    &#39;slug&#39;,  
    &#39;disable_communication&#39;, 
    &#39;country&#39;, &#39;country_displayable_name&#39;,   #国家
    &#39;currency&#39;, &#39;currency_symbol&#39;, &#39;currency_trailing_code&#39;,  #货币
    &#39;deadline&#39;, &#39;state_changed_at&#39;,  #项目筹资截止时间(时间戳格式)
    &#39;created_at&#39;,  #项目创建时间(时间戳格式)
    &#39;launched_at&#39;,  #项目上架时间(时间戳格式)
    &#39;staff_pick&#39;, &#39;is_starrable&#39;, 
    &#39;backers_count&#39;,  #资助人数
    &#39;static_usd_rate&#39;, &#39;usd_pledged&#39;, &#39;converted_pledged_amount&#39;, &#39;fx_rate&#39;, &#39;usd_exchange_rate&#39;, &#39;current_currency&#39;, &#39;usd_type&#39;, 
    &#39;creator&#39;,  #项目发起人信息
    &#39;location&#39;,  #地址
    &#39;category&#39;,  #项目所属类目信息
    &#39;profile&#39;,  #项目基本信息
    &#39;spotlight&#39;, 
    &#39;urls&#39;,  #项目链接
    &#39;source_url&#39;])
</code></pre></div><br>
<p>以第一条数据为例，依次查看这几个字段的信息</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#众筹项目具名</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;项目名&#39;</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;data&#39;</span><span class="p">][</span><span class="s1">&#39;name&#39;</span><span class="p">],</span> <span class="n">end</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\n\n</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;项目链接</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;data&#39;</span><span class="p">][</span><span class="s1">&#39;urls&#39;</span><span class="p">],</span> <span class="n">end</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\n\n</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="c1">#众筹项目的目标总金额</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;目标总金额: </span><span class="si">{goal}{currency}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">goal</span><span class="o">=</span><span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;data&#39;</span><span class="p">][</span><span class="s1">&#39;goal&#39;</span><span class="p">],</span> 
                                          <span class="n">currency</span><span class="o">=</span><span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;data&#39;</span><span class="p">][</span><span class="s1">&#39;currency&#39;</span><span class="p">]))</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">    项目名 Paint Rogue
    
    项目链接
     {&#39;web&#39;: {&#39;project&#39;: &#39;https://www.kickstarter.com/projects/1018782761/paint-rogue?ref=discovery_category_newest&#39;, &#39;rewards&#39;: &#39;https://www.kickstarter.com/projects/1018782761/paint-rogue/rewards&#39;}}
    
    目标总金额: 5000AUD
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#众筹项目发起人信息</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;项目发起人信息</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;data&#39;</span><span class="p">][</span><span class="s1">&#39;creator&#39;</span><span class="p">],</span> <span class="n">end</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\n\n</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;项目基本信息</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;data&#39;</span><span class="p">][</span><span class="s1">&#39;profile&#39;</span><span class="p">],</span> <span class="n">end</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\n\n</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="c1">#众筹项目坐标</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;地址: &#39;</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;data&#39;</span><span class="p">][</span><span class="s1">&#39;location&#39;</span><span class="p">],</span> <span class="n">end</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\n\n</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="c1">#众筹项目货币</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;货币:&#39;</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;data&#39;</span><span class="p">][</span><span class="s1">&#39;currency&#39;</span><span class="p">],</span> <span class="n">end</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\n\n</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="c1">#众筹项目所在国家</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;所在国家: &#39;</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;data&#39;</span><span class="p">][</span><span class="s1">&#39;country_displayable_name&#39;</span><span class="p">],</span> <span class="n">end</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\n\n</span><span class="s1">&#39;</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">    项目发起人信息
     {&#39;id&#39;: 1018782761, &#39;name&#39;: &#39;Andrew Von Stieglitz&#39;, &#39;is_registered&#39;: None, &#39;is_email_verified&#39;: None, &#39;chosen_currency&#39;: None, &#39;is_superbacker&#39;: None, &#39;avatar&#39;: {&#39;thumb&#39;: &#39;https://ksr-ugc.imgix.net/assets/024/628/691/39e3fdc8db723302f544f7161e32c4b7_original.png?ixlib=rb-4.0.2&amp;w=40&amp;h=40&amp;fit=crop&amp;v=1554207776&amp;auto=format&amp;frame=1&amp;q=92&amp;s=bf4ce960e83b57310b93c40dda68e213&#39;, &#39;small&#39;: &#39;https://ksr-ugc.imgix.net/assets/024/628/691/39e3fdc8db723302f544f7161e32c4b7_original.png?ixlib=rb-4.0.2&amp;w=80&amp;h=80&amp;fit=crop&amp;v=1554207776&amp;auto=format&amp;frame=1&amp;q=92&amp;s=a862ab30490c90cd08186f448884142d&#39;, &#39;medium&#39;: &#39;https://ksr-ugc.imgix.net/assets/024/628/691/39e3fdc8db723302f544f7161e32c4b7_original.png?ixlib=rb-4.0.2&amp;w=160&amp;h=160&amp;fit=crop&amp;v=1554207776&amp;auto=format&amp;frame=1&amp;q=92&amp;s=38923ac11699d68a7aae93ce126b97b6&#39;}, &#39;urls&#39;: {&#39;web&#39;: {&#39;user&#39;: &#39;https://www.kickstarter.com/profile/1018782761&#39;}, &#39;api&#39;: {&#39;user&#39;: &#39;https://api.kickstarter.com/v1/users/1018782761?signature=1654832212.14f9df54b2643f080ad98cacb07314f94757d9c1&#39;}}}
    
    项目基本信息
     {&#39;id&#39;: 4007060, &#39;project_id&#39;: 4007060, &#39;state&#39;: &#39;active&#39;, &#39;state_changed_at&#39;: 1594267960, &#39;name&#39;: &#39;Paint Rogue&#39;, &#39;blurb&#39;: &#39;Roguelike | Platformer | Shooter&#39;, &#39;background_color&#39;: &#39;&#39;, &#39;text_color&#39;: &#39;ffffff&#39;, &#39;link_background_color&#39;: &#39;&#39;, &#39;link_text_color&#39;: &#39;&#39;, &#39;link_text&#39;: &#39;Follow along!&#39;, &#39;link_url&#39;: &#39;https://www.kickstarter.com/projects/1018782761/paint-rogue/&#39;, &#39;show_feature_image&#39;: True, &#39;background_image_opacity&#39;: 0.5700000000000001, &#39;background_image_attributes&#39;: {&#39;id&#39;: 29758105, &#39;image_urls&#39;: {&#39;default&#39;: &#39;https://ksr-ugc.imgix.net/assets/029/758/105/971e42c0e19ca75fbae0943aa874c3c2_original.png?ixlib=rb-4.0.2&amp;w=1600&amp;fit=max&amp;v=1594267934&amp;auto=format&amp;frame=1&amp;q=92&amp;s=b91907c9e125e206a11a1bcef322c142&#39;, &#39;baseball_card&#39;: &#39;https://ksr-ugc.imgix.net/assets/029/758/105/971e42c0e19ca75fbae0943aa874c3c2_original.png?ixlib=rb-4.0.2&amp;w=460&amp;fit=max&amp;v=1594267934&amp;auto=format&amp;frame=1&amp;q=92&amp;s=e7af2286d1f74a51672fbb6060ad43c8&#39;}}, &#39;should_show_feature_image_section&#39;: False, &#39;feature_image_attributes&#39;: {&#39;image_urls&#39;: {&#39;default&#39;: &#39;https://ksr-ugc.imgix.net/assets/029/542/393/098b025d0c25cc15e5b5f673b9ec992a_original.png?ixlib=rb-4.0.2&amp;crop=faces&amp;w=1552&amp;h=873&amp;fit=crop&amp;v=1592675400&amp;auto=format&amp;frame=1&amp;q=92&amp;s=f47505da909a374642906e6d418474e7&#39;, &#39;baseball_card&#39;: &#39;https://ksr-ugc.imgix.net/assets/029/542/393/098b025d0c25cc15e5b5f673b9ec992a_original.png?ixlib=rb-4.0.2&amp;crop=faces&amp;w=560&amp;h=315&amp;fit=crop&amp;v=1592675400&amp;auto=format&amp;frame=1&amp;q=92&amp;s=26209d432871ad2e9cca642527c291d9&#39;}}}
    
    地址:  {&#39;id&#39;: 1105779, &#39;name&#39;: &#39;Sydney&#39;, &#39;slug&#39;: &#39;sydney-au&#39;, &#39;short_name&#39;: &#39;Sydney, AU&#39;, &#39;displayable_name&#39;: &#39;Sydney, AU&#39;, &#39;localized_name&#39;: &#39;Sydney&#39;, &#39;country&#39;: &#39;AU&#39;, &#39;state&#39;: &#39;NSW&#39;, &#39;type&#39;: &#39;Town&#39;, &#39;is_root&#39;: False, &#39;expanded_country&#39;: &#39;Australia&#39;, &#39;urls&#39;: {&#39;web&#39;: {&#39;discover&#39;: &#39;https://www.kickstarter.com/discover/places/sydney-au&#39;, &#39;location&#39;: &#39;https://www.kickstarter.com/locations/sydney-au&#39;}, &#39;api&#39;: {&#39;nearby_projects&#39;: &#39;https://api.kickstarter.com/v1/discover?signature=1654814982.2fcf49a7b611d4414d14b1dbe41ac53623192e6a&amp;woe_id=1105779&#39;}}}
    
    货币: AUD
    
    所在国家:  Australia
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#众筹项目创建时间</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;项目创建时间: &#39;</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;data&#39;</span><span class="p">][</span><span class="s1">&#39;created_at&#39;</span><span class="p">])</span>

<span class="c1">#众筹项目上架时间</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;项目上架时间: &#39;</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;data&#39;</span><span class="p">][</span><span class="s1">&#39;launched_at&#39;</span><span class="p">])</span>

<span class="c1">#众筹项目截止时间</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;项目截止时间: &#39;</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;data&#39;</span><span class="p">][</span><span class="s1">&#39;deadline&#39;</span><span class="p">])</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">    项目创建时间:  1591152439
    项目上架时间:  1591655312
    项目截止时间:  1594247312
</code></pre></div><br>
<h3 id="时间戳转日期">时间戳转日期</h3>
<p>1591152439是时间戳，以某时间点距1970之间的秒数作为时间。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#时间戳转日期</span>

<span class="kn">import</span> <span class="nn">datetime</span>

<span class="k">def</span> <span class="nf">timestamp2str</span><span class="p">(</span><span class="n">timestamp</span><span class="p">):</span>
    <span class="n">d</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">fromtimestamp</span><span class="p">(</span><span class="n">timestamp</span><span class="p">)</span>
    <span class="k">return</span> <span class="s1">&#39;</span><span class="si">{year}</span><span class="s1">-</span><span class="si">{month}</span><span class="s1">-</span><span class="si">{day}</span><span class="s1"> </span><span class="si">{hour}</span><span class="s1">:</span><span class="si">{minute}</span><span class="s1">:</span><span class="si">{second}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">year</span><span class="o">=</span><span class="n">d</span><span class="o">.</span><span class="n">year</span><span class="p">,</span>
                                                                 <span class="n">month</span><span class="o">=</span><span class="n">d</span><span class="o">.</span><span class="n">month</span><span class="p">,</span>
                                                                 <span class="n">day</span><span class="o">=</span><span class="n">d</span><span class="o">.</span><span class="n">day</span><span class="p">,</span>
                                                                 <span class="n">hour</span><span class="o">=</span><span class="n">d</span><span class="o">.</span><span class="n">hour</span><span class="p">,</span>
                                                                 <span class="n">minute</span><span class="o">=</span><span class="n">d</span><span class="o">.</span><span class="n">minute</span><span class="p">,</span>
                                                                 <span class="n">second</span><span class="o">=</span><span class="n">d</span><span class="o">.</span><span class="n">second</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;创建时间&#39;</span><span class="p">,</span> <span class="n">timestamp2str</span><span class="p">(</span><span class="mi">1591152439</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;上架时间&#39;</span><span class="p">,</span> <span class="n">timestamp2str</span><span class="p">(</span><span class="mi">1591655312</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;截止时间&#39;</span><span class="p">,</span> <span class="n">timestamp2str</span><span class="p">(</span><span class="mi">1594247312</span><span class="p">))</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">创建时间 2020-6-3 10:47:19
上架时间 2020-6-9 6:28:32
截止时间 2020-7-9 6:28:32
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#众筹项目产品 所属类目信息</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;众筹类目:&#39;</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;data&#39;</span><span class="p">][</span><span class="s1">&#39;category&#39;</span><span class="p">],</span> <span class="n">end</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\n\n</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="c1"># 众筹类目根链接</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;众筹类目根链接:&#39;</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;data&#39;</span><span class="p">][</span><span class="s1">&#39;source_url&#39;</span><span class="p">])</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">    众筹类目: {&#39;id&#39;: 35, &#39;name&#39;: &#39;Video Games&#39;, &#39;analytics_name&#39;: &#39;Video Games&#39;, &#39;slug&#39;: &#39;games/video games&#39;, &#39;position&#39;: 7, &#39;parent_id&#39;: 12, &#39;parent_name&#39;: &#39;Games&#39;, &#39;color&#39;: 51627, &#39;urls&#39;: {&#39;web&#39;: {&#39;discover&#39;: &#39;http://www.kickstarter.com/discover/categories/games/video%20games&#39;}}}
    
    众筹类目根链接: https://www.kickstarter.com/discover/categories/games/video%20games
</code></pre></div><p><br><br></p>
<h2 id="数据获取方法">数据获取方法</h2>
<p>转发分享至朋友圈，集赞50+, 加微信 372335839 ， 备注「姓名-学校-专业-Kickstarter」</p>
<p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>JM2022综述 | 黄金领域: 为营销研究(新洞察)采集网络数据</title>
      <link>https://textdata.cn/blog/2022-12-03-scraping-web-data-for-marketing-insights/</link>
      <pubDate>Sat, 03 Dec 2022 00:00:00 +0000</pubDate>
      
      <guid>/blog/2022-12-03-scraping-web-data-for-marketing-insights/</guid>
      <description>Journal of Marketing 2022年一篇关于营销领域网络爬虫的文献综述</description>
      <content:encoded><![CDATA[<p>Boegershausen, Johannes, Hannes Datta, Abhishek Borah, and Andrew Stephen. &ldquo;Fields of gold: Scraping web data for marketing insights.&rdquo; <em>Journal of Marketing</em> (2022).</p>
<p>本文是JM中少有的技术流综述文，阅读起来晦涩难懂，我们就大概知道怎么回事， 查看有没有自己感兴趣的研究(方法)即可。该文作者为该综述专门开发了一个 web-scraping.org 的网站,截图如下</p>
<p><img loading="lazy" src="img/01-web-scraping.png" alt=""  />

<img loading="lazy" src="img/02-web-scraping.png" alt=""  />
</p>

<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
  <iframe src="https://www.youtube.com/embed/KiyFyLEkqNk" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video"></iframe>
</div>

<br>
<h2 id="摘要">摘要</h2>
<p>市场营销学者越来越多使用网络爬虫和API接口，从互联网收集数据。尽管网络数据得到广泛使用，但很少有学者关注收集过程中面临的各种挑战。<strong>研究人员如何确保采集的数据集是有效的？</strong> 虽然现有资源强调提取网络数据的技术细节，<strong>但作者提出了一种新的方法框架，重点是提高其有效性</strong>。特别是，该框架强调解决有效性问题， 需要在数据采集的三个阶段(<strong>选择数据源、设计数据收集和提取数据</strong>)联合考虑技术和法律/伦理问题。作者进一步审查了营销Top5期刊上300 篇使用网络数据的论文，并总结提出了如何使用网络数据促进营销研究。本文最后指出了未来研究的方向，高价值的网络数据源和新方法。</p>
<p><strong>Keywords：</strong></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">- web scraping
- application programming interface, API
- crawling
- validity
- user-generated content
- social media
big data
</code></pre></div><br>
<h2 id="一网络数据的魅力">一、网络数据的魅力</h2>
<p>社会和商业生活的加速数字化创造了数量空前的消费者和企业行为数字痕迹。 每分钟，全球用户在 Google 上进行 570 万次搜索，进行 600 万次商业交易，并在 Instagram 上分享6.5万张照片（Statista 2021）。 由此产生的网络数据——规模庞大、形式多样，而且通常可以在互联网上公开访问——对于那些想要量化消费、深入了解企业行为并跟踪难以或昂贵地观察社会活动的营销学者来说，这是一个潜在的金矿 . 网络数据对营销研究的重要性反映在越来越多的有影响力的出版物中，涵盖消费者文化理论、消费者心理学、实证建模和营销策略等。</p>
<p><img loading="lazy" src="img/fig-1-increased-use-of-web-data-in-marketing.png" alt=""  />
</p>
<p>整理了 <strong>营销领域 top 5 期刊( JM、JMR、JCR、JCP、MS) 的 313 篇论文</strong> ，经过整理绘制图-1（Figure1）， 使用网络数据进行研究的量呈现快速上涨的趋势。使用网络数据的论文占比，从2010年的4%提升到2020年的15%。 者313篇论文，数据的获取方式统计</p>
<ul>
<li>**59% 的论文使用了 <strong>网络爬虫</strong> 采集数据</li>
<li>12% 的论文使用API收集数据</li>
<li>9% 的论文同时使用了网络爬虫和API</li>
<li>20% 使用人工从网站手动复制粘贴数据</li>
</ul>
<p><strong>使用 网络数据 的论文，平均被引用次数 7.55， 远高于 非网络数据 的 3.90</strong>。</p>
<br>
<p>使用网络数据做新研究，大致有4种实现路径</p>
<ol>
<li><strong>研究新现象，新场景</strong>
<ul>
<li>网络世界产生的不同于现实世界的情景，可以研究新现象</li>
</ul>
</li>
<li><strong>繁荣生态价值</strong>
<ul>
<li>比如，对亚马逊评论数据进行研究，研究发现可以帮助亚马逊平台进行改善。</li>
</ul>
</li>
<li><strong>促进方法论进步</strong>
<ul>
<li>文本、图片、音频、视频等</li>
</ul>
</li>
<li><strong>提高测量效果(快、准、好、全)</strong>
<ul>
<li>借助一些API，可以对已有的数据集增加新的信息量。</li>
<li>例如，日期数据，结合HolidayAPI，可以查看日期的节假日信息</li>
<li>给定日期和IP地址，使用Weather Underground可以查看天气信息</li>
</ul>
</li>
</ol>
<p><img loading="lazy" src="img/table-1-four-pathway-of-knowledge-creation-using-web-data.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="二数据采集的方法框架">二、数据采集的方法框架</h2>
<p>在使用 **网络爬虫 和 API ** 自动收集网络数据时，研究人员通常会在 **研究有效性、技术可行性和法律/伦理风险 **1 三者间权衡利弊得失，研究人员如何解决这些权衡，通过增强或破坏 <strong>统计结论有效性、内部有效性、结构有效性和外部有效性</strong> 来塑造研究结果的可信度（Shadish、Cook 和 Campbell 2002）。</p>
<p><img loading="lazy" src="img/fig-2-methodological-framework-for-collecting-web-data.png" alt=""  />
</p>
<p>本文开发了一个方法框架，为使用 网络爬虫 和 API 自动收集网络数据提供指导。图 2（Figure 2） 涵盖三个关键阶段</p>
<ul>
<li><strong>数据源选择</strong></li>
<li><strong>设计方案</strong>
<ul>
<li>从网站中抽取哪些信息</li>
<li>采集频率，即 每天(周/月)重复运行一次爬虫，得到面板数据</li>
</ul>
</li>
<li><strong>执行数据采集</strong>
<ul>
<li>如何改善爬虫运行效率</li>
<li>如何处理原始信息，完整的保存为原始格式html、json，还是只抽取存储当前想要的字段</li>
</ul>
</li>
</ul>
<p>研究人员通常从一组广泛的潜在数据源开始，并根据三个关键考虑因素（有效性、技术可行性和法律/道德风险）剔除其中一些数据源。这三个考虑因素出现在倒金字塔的角落，底部的有效性强调其重要性。鉴于在收集最终数据集之前难以预测其确切特征，研究人员在设计、原型化和完善数据收集时经常重新考虑这些因素。未能解决技术或法律/伦理问题可能意味着网络数据无法有意义地告知研究问题。</p>
<h3 id="21-数据源面临的挑战解决办法">2.1 数据源面临的挑战(解决办法)</h3>
<ol>
<li>探索潜在网络数据源
<ul>
<li>由于网络资源在质量、稳定性和可检索性方面存在巨大差异，研究人员可能倾向于只考虑主要或熟悉的平台。 对数据世界的彻底探索允许令人信服的理论检验和识别可能难以以其他方式注意到的新颖的、新兴的营销现象。</li>
</ul>
</li>
<li>考虑网络爬虫的替代方案
<ul>
<li>由于网络抓取是最流行的网络数据提取方法，研究人员可能会忽视其他提取数据的方法。 API 提供了一种记录和授权的方式来获取许多来源的 Web 数据。 一些来源还提供现成的数据集。 使用此类替代方案可以节省时间并最大限度地减少法律风险。</li>
</ul>
</li>
<li>将数据与场景结合对应起来
<ul>
<li>Web 数据通常没有大量的文档。 尽早识别潜在相关的背景信息对于研究的相关性和有效性至关重要。
<img loading="lazy" src="img/table-2-chanllenges-and-solutions-in-selecting-web-data-sources.png" alt=""  />
</li>
</ul>
</li>
</ol>
<br>
<h3 id="22-设计数据采集方案">2.2 设计数据采集方案</h3>
<ol>
<li>从页面抽取什么信息，从有效性、合法、技术可行性 三个方面论证。</li>
<li>如何进行数据抽样？</li>
<li>以什么频率(每天、周、月)进行数据采集</li>
</ol>
<p><img loading="lazy" src="img/table-3-1-chanllenges-and-solutions-in-selecting-web-data-sources.png" alt=""  />

<img loading="lazy" src="img/table-3-2-chanllenges-and-solutions-in-selecting-web-data-sources.png" alt=""  />
</p>
<br>
<h3 id="23-执行数据采集">2.3 执行数据采集</h3>
<ol>
<li>如何改善爬虫运行效率</li>
<li>如何监控数据质量</li>
<li>整理数据文档(记录)
<img loading="lazy" src="img/table-4-chanllenges-and-solutions-in-selecting-web-data-sources.png" alt=""  />
</li>
</ol>
<br>
<h2 id="部分参考文献">部分参考文献</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">[1]Allard, Thomas, Lea H. Dunn, and Katherine White. &#34;Negative reviews, positive impact: Consumer empathetic responding to unfair word of mouth.&#34; Journal of Marketing 84, no. 4 (2020): 86-108.
[2]Gao, Weihe, Li Ji, Yong Liu, and Qi Sun. &#34;Branding cultural products in international markets: a study of hollywood movies in China.&#34; Journal of Marketing 84, no. 3 (2020): 86-105.
[3]Reich, Taly, and Sam J. Maglio. &#34;Featuring mistakes: The persuasive impact of purchase mistakes in online reviews.&#34; Journal of Marketing 84, no. 1 (2020): 52-65.
[4]Lee, Jeffrey K., and Ann Kronrod. &#34;The strength of weak-tie consensus language.&#34; Journal of Marketing Research 57, no. 2 (2020): 353-374.
[5]Matz, Sandra C., Cristina Segalin, David Stillwell, Sandrine R. Müller, and Maarten W. Bos. &#34;Predicting the personal appeal of marketing images using computational methods.&#34; Journal of Consumer Psychology 29, no. 3 (2019): 370-390.
[6]Dai, Hengchen, and Dennis J. Zhang. &#34;Prosocial goal pursuit in crowdfunding: Evidence from kickstarter.&#34; Journal of Marketing Research 56, no. 3 (2019): 498-517.
[7]Luffarelli, Jonathan, Mudra Mukesh, and Ammara Mahmood. &#34;Let the logo do the talking: The influence of logo descriptiveness on brand equity.&#34; Journal of Marketing Research 56, no. 5 (2019): 862-878.
[8]Bond, Samuel D., Stephen X. He, and Wen Wen. &#34;Speaking for “free”: Word of mouth in free-and paid-product settings.&#34; Journal of Marketing Research 56, no. 2 (2019): 276-290.
[9]Han, Kyuhong, Jihye Jung, Vikas Mittal, Jinyong Daniel Zyung, and Hajo Adam. &#34;Political identity and financial risk taking: Insights from social dominance orientation.&#34; Journal of Marketing Research 56, no. 4 (2019): 581-601.
[10]Netzer, Oded, Alain Lemaire, and Michal Herzenstein. &#34;When words sweat: Identifying signals for loan default in the text of loan applications.&#34; Journal of Marketing Research 56, no. 6 (2019): 960-980.
[11]Toubia, Olivier, Garud Iyengar, Renée Bunnell, and Alain Lemaire. &#34;Extracting features of entertainment products: A guided latent dirichlet allocation approach informed by the psychology of media consumption.&#34; Journal of Marketing Research 56, no. 1 (2019): 18-36.
[12]Van Laer, Tom, Jennifer Edson Escalas, Stephan Ludwig, and Ellis A. Van Den Hende. &#34;What happens in Vegas stays on TripAdvisor? A theory and technique to understand narrativity in consumer reviews.&#34; Journal of Consumer Research 46, no. 2 (2019): 267-285.
[13]Zhong, Ning, and David A. Schweidel. &#34;Capturing changes in social media content: A multiple latent changepoint topic model.&#34; Marketing Science 39, no. 4 (2020): 827-846.
[14]Colicev, Anatoli, Ashwin Malshe, Koen Pauwels, and Peter O&#39;Connor. &#34;Improving consumer mindset metrics and shareholder value through social media: The different roles of owned and earned media.&#34; Journal of Marketing 82, no. 1 (2018): 37-56.
[15]Liu, Xuan, Savannah Wei Shi, Thales Teixeira, and Michel Wedel. &#34;Video content marketing: The making of clips.&#34; Journal of Marketing 82, no. 4 (2018): 86-101.
[16]Liu, Jia, and Olivier Toubia. &#34;A semantic approach for estimating consumer content preferences from online search queries.&#34; Marketing Science 37, no. 6 (2018): 930-952.
[17]Nam, Hyoryung, Yogesh V. Joshi, and P. K. Kannan. &#34;Harvesting brand information from social tags.&#34; Journal of Marketing 81, no. 4 (2017): 88-108.
[18]Packard, Grant, and Jonah Berger. &#34;How language shapes word of mouth&#39;s impact.&#34; Journal of Marketing Research 54, no. 4 (2017): 572-588.
</code></pre></div><br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>魔搭 | 中文AI模型开源社区</title>
      <link>https://textdata.cn/blog/2022-11-09-chinese-modelscope-open-source/</link>
      <pubDate>Wed, 09 Nov 2022 00:00:00 +0000</pubDate>
      
      <guid>/blog/2022-11-09-chinese-modelscope-open-source/</guid>
      <description>ModelScope社区成立于2022 年6月，是一个模型开源社区及创新平台，由阿里巴巴达摩院，联合CCF开源发展委员会，共同作为项目发起方。社区联合国内AI领域合作伙伴与高校机构，致力于通过开放的社区合作，构建深度学习相关的模型开源，并开源相关模型服务创新技术，推动模型应用生态的繁荣发展。</description>
      <content:encoded><![CDATA[<h2 id="关于modelscope">关于ModelScope</h2>
<p>ModelScope社区成立于 2022 年 6 月，是一个模型开源社区及创新平台，由阿里巴巴达摩院，联合CCF开源发展委员会，共同作为项目发起方。</p>
<blockquote>
<p>社区联合国内AI领域合作伙伴与高校机构，致力于通过开放的社区合作，构建深度学习相关的模型开源，并开源相关模型服务创新技术，推动模型应用生态的繁荣发展。</p>
</blockquote>
<p>期待ModelScope会有不一样的表现。</p>
<p>与ModelScope类似的网站有</p>
<ul>
<li>国际 huggingface是较早将AI模型开源的网站，用户群体庞大，社区内有丰富的数据集、模型，文档详实。</li>
<li>国内 百度飞桨是国内AI模型开源较好的网站，用户群体较大，更新活跃，但是文档质量。。。</li>
</ul>
<p>目前ModelScope刚刚上线不久，模型和数据集都不怎么多</p>
<p><img loading="lazy" src="img/model_scope_homepage.png" alt=""  />
</p>
<br>
<h2 id="heading"></h2>
<h1 id="名词解释"><strong>名词解释</strong></h1>
<p>ModelScope平台是以模型为中心的模型开源社区，与模型的使用相关，您需要先了解如下概念。</p>
<table>
<thead>
<tr>
<th><strong>基础概念</strong></th>
<th><strong>定义</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>任务</td>
<td>任务（Task）指某一领域具体的应用，以用于完成特定场景的任务。例如图像分类、文本生成、语音识别等，您可根据任务的输入输出找到适合您的应用场景的任务类型，通过任务的筛选来查找您所需的模型。</td>
</tr>
<tr>
<td>模型</td>
<td>模型（Model）是指一个具体的模型实例，包括模型网络结构和相应参数。ModelScope平台提供丰富的模型信息供用户体验与使用。</td>
</tr>
<tr>
<td>模型库</td>
<td>模型库（Modelhub）是指对模型进行存储、版本管理和相关操作的模型服务，用户上传和共享的模型将存储至ModelScope的模型库中，同时用户也可在Model hub中创建属于自己的模型存储库，并沿用平台提供的模型库管理功能进行模型管理。</td>
</tr>
<tr>
<td>数据集</td>
<td>数据集（Dataset）是方便共享及访问的数据集合，可用于算法训练、测试、验证，通常以表格形式出现。按照模态可划分为文本、图像、音频、视频、多模态等。</td>
</tr>
<tr>
<td>数据集库</td>
<td>数据集库（Datasethub）用于集中管理数据，支持模型进行训练、预测等，使各类型数据具备易访问、易管理、易共享的特点。</td>
</tr>
<tr>
<td>ModelScope Library</td>
<td>ModelScope Library是ModelScope平台自研的一套Python Library框架，通过调用特定的方法，用户可以只写短短的几行代码，就可以完成模型的推理、训练和评估等任务，也可以在此基础上快速进行二次开发，实现自己的创新想法。</td>
</tr>
</tbody>
</table>
<br>
<h2 id="一模型探索">一、模型探索</h2>
<p>首先访问平台网址https://www.modelscope.cn/models， 您将看见平台上已有的所有公开模型，根据任务筛选或者关键词搜索可查找您感兴趣的模型。</p>
<p><img loading="lazy" src="img/1-model_explore.png" alt=""  />
</p>
<br>
<h2 id="二环境准备">二、环境准备</h2>
<h3 id="21-本地开发环境">2.1 本地开发环境</h3>
<p>如果您需要在本地运行模型，需要进行相应的环境安装准备，包括：</p>
<ul>
<li><strong>安装python环境</strong>。支持python3，不支持python2，建议3.7版本及以上。我们推荐您使用Anaconda进行安装。</li>
<li><strong>安装深度学习框架</strong>。ModelScope Library目前支持Tensorflow，Pytorch两大深度学习框架进行模型训练、推理。您可根据模型所需的框架选择适合的框架进行安装。</li>
<li><strong>安装ModelScope Library</strong>。我们提供两种安装方式，您可选择适合的方式进行安装。
<ul>
<li>pip安装。ModelScope提供了根据不同领域的安装包，您可根据对应的模型选择所需的安装包。</li>
<li>使用源码安装。</li>
<li>更完整的安装信息参考：环境安装指南。</li>
</ul>
</li>
</ul>
<h3 id="22-在线notebook">2.2 在线Notebook</h3>
<p>若您觉得本地安装较为复杂， ModelScope平台也提供在线的运行环境，您可直接在Notebook中运行，Notebook中提供官方镜像无需自主进行环境安装，更加方便快捷，推荐大家使用！</p>
<p>注意：该功能需要您登录后使用，新用户注册ModelScope账号并完成阿里云账号绑定后即可获得免费算力资源，详情请参阅免费额度说明 。</p>
<p><img loading="lazy" src="img/model_scode_free_online_notebook.png" alt=""  />
</p>
<p><img loading="lazy" src="img/model_scode_free_online_notebook-2.png" alt=""  />
</p>
<br>
<h2 id="三2分钟跑通模型推理">三、2分钟跑通模型推理</h2>
<p>若您准备好本地环境或者已经打开一个Notebook的预装环境实例，则根据下述代码可对该模型进行推理。 使用modelscope pipeline接口只需要两步，同样以上述中文分词模型（damo/nlp_structbert_word-segmentation_chinese-base）为例简单说明：</p>
<p>首先根据task实例化一个pipeline对象</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">modelscope.pipelines</span> <span class="kn">import</span> <span class="n">pipeline</span>
<span class="n">word_segmentation</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span><span class="s1">&#39;word-segmentation&#39;</span><span class="p">,</span><span class="n">model</span><span class="o">=</span><span class="s1">&#39;damo/nlp_structbert_word-segmentation_chinese-base&#39;</span><span class="p">)</span>
</code></pre></div><p>输入数据，拿到结果</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">input_str</span> <span class="o">=</span> <span class="s1">&#39;今天天气不错，适合出去游玩&#39;</span>
<span class="nb">print</span><span class="p">(</span><span class="n">word_segmentation</span><span class="p">(</span><span class="n">input_str</span><span class="p">))</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">{&#39;output&#39;: &#39;今天 天气 不错 ， 适合 出去 游玩&#39;}
</code></pre></div><br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>十万级 | 多领域因果事件对数据集对外开源</title>
      <link>https://textdata.cn/blog/2022-11-07-chinese-casual-text-datasets/</link>
      <pubDate>Mon, 07 Nov 2022 00:00:00 +0000</pubDate>
      
      <guid>/blog/2022-11-07-chinese-casual-text-datasets/</guid>
      <description>description用于SEO优化</description>
      <content:encoded><![CDATA[<h2 id="作者">作者</h2>
<p>刘焕勇，NLP开源爱好者与践行者，主页：https://liuhuanyong.github.io。</p>
<p>就职于360人工智能研究院、曾就职于中国科学院软件研究所。</p>
<p>老刘说NLP，将定期发布语言资源、工程实践、技术总结等内容，欢迎关注。</p>
<br>
<p>开放文本中蕴含着大量的逻辑性知识，以刻画事物之间逻辑传导关系的逻辑类知识库是推动知识推理发展的重要基础。
因果抽取是一个十分有趣的话题，研发大规模逻辑推理知识库有助于支持实体或事件等传导驱动决策任务，而目前尚未有开源的因果事件对出现，为了弥补这一空缺，本文对外开源一个面向多领域的十万级因果事件对数据集，可以自行转成因果关系图谱，展开更多有趣实验，供大家一起参考。
地址：https://github.com/liuhuanyong/CausalDataset</p>
<h2 id="一因果抽取常用方法">一、因果抽取常用方法</h2>
<p>我们在《<strong>事件图谱技术：因果关系事件对抽取常用方法的解析与动手实践</strong>》中讲述了因果抽取的方法，从传统模式规则、语义分析、依存句法、序列标注四种方式进行实践，并配上实现项目进行讲解，这涵盖了当前因果事件抽取的常用方式。</p>
<p>地址： <a href="https://github.com/liuhuanyong/CausalityEventExtraction">https://github.com/liuhuanyong/CausalityEventExtraction</a></p>
<h3 id="11-基于模式匹配的因果事件对提取">1.1 基于模式匹配的因果事件对提取</h3>
<p>基于模式匹配的方式，是进行因果抽取的入门级以及兜底方式，充分利用好语言学知识，具有显式标记的因果关联词、因果表达句式进行归纳，并配以正则表达式实现，可以有效地提取出大量的因果事件对。</p>
<br>
<h3 id="12-基于语义角色的因果事件抽取">1.2 基于语义角色的因果事件抽取</h3>
<p>基于触发词模式匹配的方法无法捕捉因果事件之间的关联关系，因此可以借助依存句法分析以及语义角色标注的方式进行处理。</p>
<p>以因果关系触发词为核心动作，首先从语义角色方面找寻该触发词动作的实施对象和受事对象，将实施对象作为原因事件，将受事对象作为结果事件，并根据词性过滤事件；</p>
<br>
<h3 id="13-基于依存句法的因果事件抽取">1.3 基于依存句法的因果事件抽取</h3>
<p>由于自然语言处理的复杂性，LTP中未能对一些子句中的因果关系触发词进行语义角色标注，或者只标注了一部分，即A0和A1未同时被标注出来，因此利用依存句法分析来抽取此类情况下的因果事件对。</p>
<br> 
<h3 id="14-基于序列标注的因果抽取">1.4 基于序列标注的因果抽取</h3>
<p>针对基于规则的因果抽取模型中的不足，可以使用基于Bert微调的序列标注模型。在序列标签的设计上，模型的序列标签采用BIO标签体系，标签类型主要为cause、triger、effect。
为了能方便地根据标签结果进行因果三元组组合，在设计标签体系时也对单因果、多因果进行了区分，分别设置为multi-cause、multi-effect。</p>
<p><br><br></p>
<h2 id="二基于多领域文本数据集的因果事件对">二、基于多领域文本数据集的因果事件对</h2>
<p>为了得到多领域因果事件对，我们以清华大学开源的文本分类数据集THUnews，<strong>THUCNews是根据新浪新闻RSS订阅频道2005~2011年间的历史数据筛选过滤生成，包含74万篇新闻文档（2.19 GB），均为UTF-8纯文本格式</strong>。</p>
<p>其在原始新浪新闻分类体系的基础上，重新整合划分出14个候选分类类别：财经、彩票、房产、股票、家居、教育、科技、社会、时尚、时政、体育、星座、游戏、娱乐。满足了多领域性的需求。</p>
<p><strong>数据地址：http://thuctc.thunlp.org/#中文文本分类数据集THUCNews</strong></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">训练因果抽取识别模型，最终去重得到了100,688条因果关系对，通过对频次进行统计，可以过滤出质量较高的因果对，下面显示了格式为原因事件@结构事件\t出现频次格式下的数据样例。
投资风险巨大@本金全部亏损 248
用户友好界面@模式帮助用户选择场景 38
政策消息面和技术面所有信息@交易者预期变 37
磨砂表面处理@触感更佳 31
加上F2大光圈和丰富手动功能@机器推出受到消费者广泛关注 26
金属材质设计@整体造型更具品质感 25
商务机型中并常见@上下边框显得厚 23
顶盖采用工程塑料制成配@笔记本外壳防滑耐磨 19
取消传统曲面过度@iPhone4底部扬声器变得硕大 17
准专业机型GRDIGITALII和GX200电子水平仪功能引进@使用R10拍摄高楼山水 16
镜头位移减震功能以及闪光灯控制系统@低光照下拍摄照片时噪 14
像素触摸式液晶屏幕@操控方面人性化 14
采用直线条形式边框风格@整体看上去大气 14
像素摄像头镶嵌屏幕上方@视频聊天方便 14
</code></pre></div><br>
<h3 id="21-关于地震相关的因果事件对">2.1 关于“地震”相关的因果事件对</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">日本东北部海域发生里氏大地震@重大人员伤亡和财产损失 6
日本东北部海域发生里氏地震@重大人员伤亡和财产损失 5
印尼西爪哇省附近印度洋海域发生里氏地震@人死亡人受伤 4
智利中南部城市康塞普西翁附近发生里氏强烈地震@重大人员伤亡 3
智利发生里氏地震@重大人员伤亡和财产损失 3
东部凡省发生强烈地震@死亡人数 3
上周五地震中受损核反应堆发生爆炸@核工业相关公司股票 3
日本大地震@金融市场动 3
最近地震和海啸灾害中复苏@日元汇率下跌 3
日本东北部大地震@全球关注 2
汶川地震期间捐款数目@高度关注 2
</code></pre></div><br>
<h3 id="22-与贬值相关的因果事件对">2.2 与“贬值”相关的因果事件对</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">虚拟道具贬值@广范围用户付费意愿越来越低 3
流动性过剩加剧@贬值趋势 3
日本核泄露事件@外资产贬值 3
全球性经济复苏以及贬值流动性过剩@全球商品价格出现暴涨 3
朝鲜进行货币贬值@市场经济瘫痪 2
欧洲主权债务危机深化和亚洲国家货币贬值@日本有警惕金融资本市场动荡 2
游戏公司滥发虚拟物品@玩家虚拟物品贬值 2
住房价格贬值@全球经济下滑形势演变成 2
中长期内贬值@资金撤离资产 2
持续贬值和人民币升值预期@中国内地成为资金洼地 2
韩元贬值@进口商品价格上升 2
货币大体上呈贬值趋势@国际油价名义价格走高 2
朱广沪时期大面积召人@国家队贬值 1
</code></pre></div><br>
<h3 id="23-与恋爱相关的因果事件对">2.3 与“恋爱”相关的因果事件对</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">恋爱观婚姻观@观众极大兴趣 2
恋爱问题@学生意外伤害事 2
人相知相惜@恋爱温度始终保持合适系数 1
持人大爆钱包@恋爱故事 1
来美丽密令恋爱线人电影@陆毅闪耀大银幕上 1
李成儒和小演员侯角恋爱往事@媒体关注 1
歌曲转换过渡上显得流畅@听起来实在如男女恋爱中不伦恋 1
抓紧时间南京谈恋爱@台上台下哄笑 1
公司安排工作@没时间恋爱 1
强打精神去面对@恋爱没有兴趣 1
</code></pre></div><br>
<br>
<h2 id="总结">总结</h2>
<p>本文以清华大学开源的文本分类数据集THUnews，对外开源了一个面向多领域的十万级因果事件对数据集，并介绍了常用技术方法。当然，数据的质量也有不足之处，规模不大，可以加以改善。</p>
<br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>1.5G数据集 | 200万条Indiegogo众筹项目信息</title>
      <link>https://textdata.cn/blog/2022-12-08-indiegogo-dataset/</link>
      <pubDate>Sun, 16 Oct 2022 00:00:00 +0000</pubDate>
      
      <guid>/blog/2022-12-08-indiegogo-dataset/</guid>
      <description>1.57G indiegogo-dataset.jpeg</description>
      <content:encoded><![CDATA[<h2 id="indiegogo">Indiegogo</h2>
<p>Indiegogo成立于2008年，全球最大的科创新品首发和众筹平台， 是美国最早的众筹平台之一。</p>
<p><br><br></p>
<h2 id="参考论文">参考论文</h2>
<p>该数据集研究价值，可用于研究市场营销、创新创业、信息管理等， 部分使用众筹数据集作为研究对象的论文。</p>
<blockquote>
<p>[1]王伟,陈伟,祝效国,王洪伟. 众筹融资成功率与语言风格的说服性-基于Kickstarter的实证研究.<em>管理世界</em>.2016;5:81-98.
[2]Dai, Hengchen and Dennis J. Zhang. “Prosocial Goal Pursuit in Crowdfunding: Evidence from Kickstarter.” Journal of Marketing Research 56 (2019): 498 - 517.
[3]Gafni, H., Marom, D.M., Robb, A.M., &amp; Sade, O. (2020). Gender Dynamics in Crowdfunding (Kickstarter): Evidence on Entrepreneurs, Backers, and Taste-Based Discrimination*. Review of Finance.
[4]Jensen, Lasse Skovgaard and Ali Gürcan Özkil. “Identifying challenges in crowdfunded product development: a review of Kickstarter projects.” Design Science 4 (2018): n. pag.</p>
</blockquote>
<p><br><br></p>
<h2 id="indiegogo数据">Indiegogo数据</h2>
<p>2016年4月写好的Indiegogo爬虫，每月执行一次, 最新的数据 可以前往https://webrobots.io/indiegogo-dataset/</p>
<p><img loading="lazy" src="img/web_robot.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="原始数据">‘原始’数据</h2>
<p>Web Robot网上公开的的Indiegogo原始数据几十个 csv文件,</p>
<p><img loading="lazy" src="img/zips.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="整理">整理</h2>
<p>将上图的zip全部合并为一个 Indiegogo_dataset.csv , 该文件 1.57G 。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>

<span class="n">dff</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;Indiegogo_Dataset/Indiegogo_dataset.csv&#39;</span><span class="p">,</span> <span class="n">on_bad_lines</span><span class="o">=</span><span class="s1">&#39;skip&#39;</span><span class="p">)</span>
<span class="n">dff</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<p><img loading="lazy" src="img/df.png" alt=""  />
</p>
<br>
<p>数据集的字段有</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df</span><span class="o">.</span><span class="n">columns</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">Index([&#39;bullet_point&#39;, 
       &#39;category&#39;, &#39;category_url&#39;,  #项目类目及url
       &#39;clickthrough_url&#39;, #进入当前项目经由的某url
       &#39;close_date&#39;,  #项目截止日期
       &#39;currency&#39;,  #货币
       &#39;funds_raised_amount&#39;,  #当前已筹集的资金
       &#39;funds_raised_percent&#39;, #筹集资金进度(当前筹资/项目目标金额)
       &#39;image_url&#39;,  #图片url
       &#39;is_indemand&#39;, 
       &#39;is_pre_launch&#39;, #是否为预演
       &#39;offered_by&#39;,  #项目发起人
       &#39;open_date&#39;, #项目开始日期
       &#39;perk_goal_percentage&#39;, &#39;perks_claimed&#39;, 
       &#39;price_offered&#39;, #众筹价
       &#39;price_retail&#39;, #零售价
       &#39;product_stage&#39;,  #产品阶段
       &#39;project_id&#39;, #项目id
       &#39;project_type&#39;, #项目类型
       &#39;source_url&#39;, #项目url
       &#39;tagline&#39;, &#39;tags&#39;, #标签
       &#39;title&#39; ], #项目标题
      dtype=&#39;object&#39;)
</code></pre></div><p><br><br></p>
<h2 id="数据获取">数据获取</h2>
<ul>
<li>原始数据
<ul>
<li><a href="https://webrobots.io/indiegogo-dataset/">https://webrobots.io/indiegogo-dataset/</a></li>
</ul>
</li>
<li>整理的1.57G csv,
<ul>
<li>链接: <a href="https://pan.baidu.com/s/1j3PtV4GbFsyhjmr0NLbnKg">https://pan.baidu.com/s/1j3PtV4GbFsyhjmr0NLbnKg</a> 提取码: vfyc</li>
</ul>
</li>
</ul>
<p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>14G数据集 | 2007-2021年A股上市公司年度报告（txt文件）</title>
      <link>https://textdata.cn/blog/2022-10-21-2007-2021-a-share-reports-dataset/</link>
      <pubDate>Sun, 16 Oct 2022 00:00:00 +0000</pubDate>
      
      <guid>/blog/2022-10-21-2007-2021-a-share-reports-dataset/</guid>
      <description>2007-2021年A股上市公司年度报告（txt文件）</description>
      <content:encoded><![CDATA[<p>2007-2021年A股上市公司年度报告, 整理不易，请转发分享。</p>
<br>
<h2 id="截图">截图</h2>
<p><img loading="lazy" src="img/07-21.png" alt=""  />

<img loading="lazy" src="img/2007.png" alt=""  />
</p>
<br>
<h2 id="获取">获取</h2>
<blockquote>
<p>链接: <a href="https://pan.baidu.com/s/1jw6VGGAN9cxROoqWN2X4vw">https://pan.baidu.com/s/1jw6VGGAN9cxROoqWN2X4vw</a> 提取码: g3cn</p>
</blockquote>
<br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>数据集 | 多语言对齐词向量预训练模型</title>
      <link>https://textdata.cn/blog/2022-10-16-aligned-word-vectors/</link>
      <pubDate>Sun, 16 Oct 2022 00:00:00 +0000</pubDate>
      
      <guid>/blog/2022-10-16-aligned-word-vectors/</guid>
      <description>借助该预训练模型，应该能做可做跨文化对比分析</description>
      <content:encoded><![CDATA[<h2 id="介绍">介绍</h2>
<p>Facebook研究者使用 fastText 算法，对维基百科(44种语言)语料数据进行了训练，最终生成了 44 种语言的对齐词向量。</p>
<br>
<h2 id="用途">用途</h2>
<p>wiki数据集有个优点，即由于众人分享、翻译，将不同语言的百科词条进行了翻译整理。所以facebook使用wiki训练对齐词向量有助于提升翻译准确性。与此同时，因为翻译者处于不同的语言和文化背景下，词条及词条内容必然蕴含着语言所特有的文化信息线索，有可能有助于我们挖掘跨语言的文化差异。例如中文词条<code>护士</code>和 英文词条<code>nurse</code> ，可以借助对齐词向量，比较护士这个群体在性别、种族等语义上的差异。</p>
<p>之前分享过的内容</p>
<ul>
<li><a href="https://textdata.cn/blog/embeddingsandattitude/">词嵌入测量不同群体对某概念的态度(偏见)</a></li>
<li><a href="https://textdata.cn/blog/wordembeddingsinsocialscience/">转载 | 大数据时代下社会科学研究方法的拓展&mdash;&mdash;基于词嵌入技术的文本分析的应用</a></li>
<li><a href="https://textdata.cn/blog/from_sysbol_to_embeddings_in_computational_social_science/">转载 | 从符号到嵌入：计算社会科学的两种文本表示</a></li>
<li><a href="https://textdata.cn/blog/literatureembeddings/">文献汇总 | 词嵌入 与 社会科学中的偏见(态度)</a></li>
</ul>
<p>不过fastText算法认为词语有不同的大小划分层次，从大到小分别是词语、词缀、字符等，使用 Joulin 等人 (2018) 中描述的 RCSLS 方法进行比对。</p>
<table>
<thead>
<tr>
<th><strong>Code</strong></th>
<th><strong>en-es</strong></th>
<th><strong>es-en</strong></th>
<th><strong>en-fr</strong></th>
<th><strong>fr-en</strong></th>
<th><strong>en-de</strong></th>
<th><strong>de-en</strong></th>
<th><strong>en-ru</strong></th>
<th><strong>ru-en</strong></th>
<th><strong>en-zh</strong></th>
<th><strong>zh-en</strong></th>
<th><strong>avg</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>Joulin et al. [<a href="https://arxiv.org/abs/1804.07745">1</a>]</td>
<td>84.1</td>
<td>86.3</td>
<td>83.3</td>
<td>84.1</td>
<td><strong>79.1</strong></td>
<td>76.3</td>
<td><strong>57.9</strong></td>
<td><strong>67.2</strong></td>
<td>45.9</td>
<td>46.4</td>
<td>71.1</td>
</tr>
<tr>
<td>This implementation (10 epochs)</td>
<td>84.2</td>
<td><strong>86.6</strong></td>
<td><strong>83.9</strong></td>
<td>84.7</td>
<td>78.3</td>
<td>76.6</td>
<td>57.6</td>
<td>66.7</td>
<td><strong>47.6</strong></td>
<td><strong>47.4</strong></td>
<td>71.4</td>
</tr>
<tr>
<td>This implementation (unsup. model selection)</td>
<td><strong>84.3</strong></td>
<td><strong>86.6</strong></td>
<td><strong>83.9</strong></td>
<td><strong>85.0</strong></td>
<td>78.7</td>
<td><strong>76.7</strong></td>
<td>57.6</td>
<td>67.1</td>
<td><strong>47.6</strong></td>
<td><strong>47.4</strong></td>
<td><strong>71.5</strong></td>
</tr>
</tbody>
</table>
<p>算法得出的词向量在西方，尤其是西欧语言之间进行语义对齐，效果可能更好。而中文、日语等汉字语言，是由偏旁部首组成，与西方字母语言还是存在一定差异。上表也可以看出中英语义对齐准确率47%， 而其他语言之间对齐准确率平均为71%。</p>
<br>
<h2 id="模型资源">模型资源</h2>
<p><a href="https://fasttext.cc/docs/en/aligned-vectors.html">https://fasttext.cc/docs/en/aligned-vectors.html</a></p>
<p>对齐预训练向量模型下载链接</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>Afrikaans: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.af.align.vec"><em>text</em></a></td>
<td>Arabic: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.ar.align.vec"><em>text</em></a></td>
<td>Bulgarian: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.bg.align.vec"><em>text</em></a></td>
<td>Bengali: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.bn.align.vec"><em>text</em></a></td>
</tr>
<tr>
<td>Bosnian: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.bs.align.vec"><em>text</em></a></td>
<td>Catalan: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.ca.align.vec"><em>text</em></a></td>
<td>Czech: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.cs.align.vec"><em>text</em></a></td>
<td>Danish: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.da.align.vec"><em>text</em></a></td>
</tr>
<tr>
<td>German: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.de.align.vec"><em>text</em></a></td>
<td>Greek: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.el.align.vec"><em>text</em></a></td>
<td>English: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.en.align.vec"><em>text</em></a></td>
<td>Spanish: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.es.align.vec"><em>text</em></a></td>
</tr>
<tr>
<td>Estonian: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.et.align.vec"><em>text</em></a></td>
<td>Persian: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.fa.align.vec"><em>text</em></a></td>
<td>Finnish: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.fi.align.vec"><em>text</em></a></td>
<td>French: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.fr.align.vec"><em>text</em></a></td>
</tr>
<tr>
<td>Hebrew: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.he.align.vec"><em>text</em></a></td>
<td>Hindi: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.hi.align.vec"><em>text</em></a></td>
<td>Croatian: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.hr.align.vec"><em>text</em></a></td>
<td>Hungarian: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.hu.align.vec"><em>text</em></a></td>
</tr>
<tr>
<td>Indonesian: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.id.align.vec"><em>text</em></a></td>
<td>Italian: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.it.align.vec"><em>text</em></a></td>
<td>Korean: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.ko.align.vec"><em>text</em></a></td>
<td>Lithuanian: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.lt.align.vec"><em>text</em></a></td>
</tr>
<tr>
<td>Latvian: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.lv.align.vec"><em>text</em></a></td>
<td>Macedonian: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.mk.align.vec"><em>text</em></a></td>
<td>Malay: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.ms.align.vec"><em>text</em></a></td>
<td>Dutch: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.nl.align.vec"><em>text</em></a></td>
</tr>
<tr>
<td>Norwegian: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.no.align.vec"><em>text</em></a></td>
<td>Polish: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.pl.align.vec"><em>text</em></a></td>
<td>Portuguese: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.pt.align.vec"><em>text</em></a></td>
<td>Romanian: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.ro.align.vec"><em>text</em></a></td>
</tr>
<tr>
<td>Russian: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.ru.align.vec"><em>text</em></a></td>
<td>Slovak: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.sk.align.vec"><em>text</em></a></td>
<td>Slovenian: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.sl.align.vec"><em>text</em></a></td>
<td>Albanian: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.sq.align.vec"><em>text</em></a></td>
</tr>
<tr>
<td>Swedish: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.sv.align.vec"><em>text</em></a></td>
<td>Tamil: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.ta.align.vec"><em>text</em></a></td>
<td>Thai: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.th.align.vec"><em>text</em></a></td>
<td>Tagalog: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.tl.align.vec"><em>text</em></a></td>
</tr>
<tr>
<td>Turkish: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.tr.align.vec"><em>text</em></a></td>
<td>Ukrainian: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.uk.align.vec"><em>text</em></a></td>
<td>Vietnamese: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.vi.align.vec"><em>text</em></a></td>
<td>Chinese: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.zh.align.vec"><em>text</em></a></td>
</tr>
</tbody>
</table>
<br>
<h2 id="格式">格式</h2>
<p>词向量默认使用的fastText格式</p>
<ul>
<li>第一行给了词向量的维数</li>
<li>从第二行开始，每一行由词语及对应的词向量组成。</li>
<li>数值之间使用空格间隔</li>
</ul>
<br>
<h2 id="代码">代码</h2>
<h3 id="导入模型">导入模型</h3>
<p>使用gensim导入fastText方法训练出的 预训练语言模型</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">gensim.models</span> <span class="kn">import</span> <span class="n">KeyedVectors</span>

<span class="c1">#导入刚刚下载的预训练模型</span>
<span class="c1">#该词向量模型300维</span>
<span class="n">zh_w2v_model</span> <span class="o">=</span> <span class="n">KeyedVectors</span><span class="o">.</span><span class="n">load_word2vec_format</span><span class="p">(</span><span class="s1">&#39;wiki.zh.align.vec&#39;</span><span class="p">,</span> <span class="n">binary</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1">#英文词向量模型5G，太大了。如果内存小于16G不要使用下面命令</span>
<span class="c1">#en_w2v_model = KeyedVectors.load_word2vec_format(&#39;wiki.en.align.vec&#39;, binary=False)</span>
</code></pre></div><p>一旦导入成功，就可以进行向量计算。这里仅进行简单演示</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#获取某词的词向量</span>
<span class="n">zh_w2v_model</span><span class="o">.</span><span class="n">get_vector</span><span class="p">(</span><span class="s1">&#39;护士&#39;</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<pre><code>array([ 0.0733,  0.0782,  0.0188, -0.0027, -0.0052,...,  0.0586,  0.0166,
       -0.1401, -0.0545, -0.0125,  0.0373, -0.0681,  0.063 ],
      dtype=float32)
</code></pre>
<br>
<p>在中文中， 护士职业的主要从业者为女性，反应在词向量相似度上，如下</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="nb">print</span><span class="p">(</span><span class="n">zh_w2v_model</span><span class="o">.</span><span class="n">similarity</span><span class="p">(</span><span class="s1">&#39;护士&#39;</span><span class="p">,</span> <span class="s1">&#39;女性&#39;</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">zh_w2v_model</span><span class="o">.</span><span class="n">similarity</span><span class="p">(</span><span class="s1">&#39;护士&#39;</span><span class="p">,</span> <span class="s1">&#39;男性&#39;</span><span class="p">))</span>
</code></pre></div><p>Run</p>
<pre><code>0.4417011
0.378651
</code></pre>
<br>
<p>更多w2v_model用法可参考 <a href="https://textdata.cn/blog/douban_w2v/">豆瓣影评 | 探索词向量妙处</a></p>
<br>
<h2 id="文献">文献</h2>
<p>如果使用了facebook的预训练词向量，请引用以下两篇文献。</p>
<ul>
<li>Joulin, Armand, Piotr Bojanowski, Tomas Mikolov, Hervé Jégou, and Edouard Grave. &ldquo;Loss in translation: Learning bilingual word mapping with a retrieval criterion.&rdquo; arXiv preprint arXiv:1804.07745 (2018).</li>
<li>Bojanowski, Piotr, Edouard Grave, Armand Joulin, and Tomas Mikolov. &ldquo;Enriching word vectors with subword information.&rdquo; Transactions of the association for computational linguistics 5 (2017): 135-146.</li>
</ul>
<br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>17G数据 | 企业社会责任报告数据集</title>
      <link>https://textdata.cn/blog/coporate_social_responsibility_datasets/</link>
      <pubDate>Thu, 04 Aug 2022 00:00:00 +0000</pubDate>
      
      <guid>/blog/coporate_social_responsibility_datasets/</guid>
      <description>近年来，企业社会责任（csr)已成为全球学术界研究的热点。国内外各大顶刊都先后刊登了多篇关于csr的文章，比如《企业绿色创新实践如何破解“和谐共生”难题？》（发表于管理世界）、《负责任的国际投资：ESG与中国OFDI》（发表于经济研究）、《Is my company really doing good? Factors influencing employees&amp;#39; evaluation of the authenticity of their company&amp;#39;s corporate social responsibility engagement》（发表于JBR）等。这些文章核心变量的构建大都基于对企业社会责任报告的内容分析和挖掘。比如《企业绿色创新实践如何破解“和谐共生”难题？》的被解释变量（绿色创新）以及部分解释变量（二元合法性和伦理型领导）。可见，社会责任报告对于我们研究esg至关重要。因此，接下来小编就带大家爬取深交所上市公司历年的社会责任报告，希望能够给大家带来一些帮助。In recent years, corporate social responsibility (csr) has become a research hotspot in the global academic circles. Major top journals at home and abroad have successively published many articles on CSR, such as How can corporate green innovation practice solve the problem of harmonious symbiosis? (published in Governance World), Responsible International Investment: ESG and China&amp;#39;s OFDI (published in Economic Research), Is my company really doing good? Factors influencing employees&amp;#39; evaluation of the authenticity of their company&amp;#39;s corporate social responsibility engagement (published in JBR) et al. The construction of core variables in these articles is mostly based on the content analysis and mining of corporate social responsibility reports. For example, How can corporate green innovation practice solve the problem of harmonious symbiosis? 》The explained variable (green innovation) and part of the explanatory variables (dual legitimacy and ethical leadership). It can be seen that the social responsibility report is very important for us to study esg. Therefore, the next editor will take you to crawl the social responsibility reports of companies listed on the Shenzhen Stock Exchange over the years, hoping to bring you some help.</description>
      <content:encoded><![CDATA[<blockquote>
<p>作者:张延丰 哈工程在读博士</p>
</blockquote>
<p>近年来，企业社会责任（csr)已成为全球学术界研究的热点。国内外各大顶刊都先后刊登了多篇关于csr的文章，比如《企业绿色创新实践如何破解“和谐共生”难题？》（发表于管理世界）、《负责任的国际投资：ESG与中国OFDI》（发表于经济研究）、《Is my company really doing good? Factors influencing employees' evaluation of the authenticity of their company&rsquo;s corporate social responsibility engagement》（发表于JBR）等。这些文章核心变量的构建大都基于对企业社会责任报告的内容分析和挖掘。比如《企业绿色创新实践如何破解“和谐共生”难题？》的被解释变量（绿色创新）以及部分解释变量（二元合法性和伦理型领导）。可见，社会责任报告对于我们研究esg至关重要。因此，接下来小编就带大家爬取深交所上市公司历年的社会责任报告，希望能够给大家带来一些帮助。</p>
<br>
<h2 id="获取数据集">获取数据集</h2>
<p>采集4000多个pdf文件。经过数据清洗，将20G的pdf数据，汇总整理到170M的csv文件内。</p>
<p><img loading="lazy" src="img/datasets.png" alt=""  />
</p>
<p>数据整理不易，如需获取本数据集，<strong>请转发本文至朋友圈集赞满30+</strong>， 加微信【372335839】，备注【深圳ESG数据集】</p>
<img src="img/wechat.jpg" style="zoom:50%;" />
<p><br><br></p>
<h2 id="一构建网络爬虫">一、构建网络爬虫</h2>
<p>数据采集分为多个步骤</p>
<ol>
<li>找网址规律(GET or POST), 构造url参数</li>
<li>伪装请求，防止被封</li>
<li>构造csv，存储信心</li>
<li>执行整个爬虫</li>
</ol>
<h3 id="11-url">1.1 url</h3>
<p>打开X交所的 <a href="http://www.szse.cn/disclosure/listed/notice/">http://www.szse.cn/disclosure/listed/notice/</a> ，同时打开浏览器开发者工具network面板，在截图左侧输入框输入关键词 『社会责任报告』，按下回车。</p>
<p>此时开发者工具network面板出现很多网络交换信息， 点击检查发现下图</p>
<p><img loading="lazy" src="img/01-%e7%bd%91%e5%9d%80%e8%a7%84%e5%be%8b.png" alt=""  />
</p>
<p>发现该页面数据是<strong>POST</strong>请求，网址为</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">http://www.szse.cn/api/disc/announcement/annList?random=random参数
</code></pre></div><h3 id="12-headers">1.2 headers</h3>
<p>同时也能发现伪装头参数，现将两个重要信息整理为</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">url</span> <span class="o">=</span> <span class="s1">&#39;http://www.szse.cn/api/disc/announcement/annList?random=</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">())</span>

<span class="c1">#伪装头</span>
<span class="n">headers</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;Accept&#39;</span><span class="p">:</span> <span class="s1">&#39;application/json, text/javascript, */*; q=0.01&#39;</span><span class="p">,</span>
           <span class="s1">&#39;Accept-Encoding&#39;</span><span class="p">:</span> <span class="s1">&#39;gzip, deflate&#39;</span><span class="p">,</span>
           <span class="s1">&#39;Accept-Language&#39;</span><span class="p">:</span> <span class="s1">&#39;zh-CN,zh;q=0.9,en;q=0.8&#39;</span><span class="p">,</span>
           <span class="s1">&#39;Content-Type&#39;</span><span class="p">:</span> <span class="s1">&#39;application/json&#39;</span><span class="p">,</span>
           <span class="s1">&#39;Host&#39;</span><span class="p">:</span> <span class="s1">&#39;www.szse.cn&#39;</span><span class="p">,</span>
           <span class="s1">&#39;Origin&#39;</span><span class="p">:</span> <span class="s1">&#39;http://www.szse.cn&#39;</span><span class="p">,</span>
           <span class="s1">&#39;Proxy-Connection&#39;</span><span class="p">:</span> <span class="s1">&#39;close&#39;</span><span class="p">,</span>
           <span class="s1">&#39;Referer&#39;</span><span class="p">:</span> <span class="s1">&#39;http://www.szse.cn/disclosure/listed/fixed/index.html&#39;</span><span class="p">,</span>
           <span class="s1">&#39;User-Agent&#39;</span><span class="p">:</span> <span class="s1">&#39;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.132 Safari/537.36&#39;</span><span class="p">,</span>
           <span class="s1">&#39;X-Request-Type&#39;</span><span class="p">:</span> <span class="s1">&#39;ajax&#39;</span><span class="p">,</span>
           <span class="s1">&#39;X-Requested-With&#39;</span><span class="p">:</span> <span class="s1">&#39;XMLHttpRequest&#39;</span><span class="p">}</span>
</code></pre></div><h3 id="13-data参数">1.3 data参数</h3>
<p>POST请求需要构造data参数，在开发者对应于payload, 整理为Python格式</p>
<p><img loading="lazy" src="img/02-payload.png" alt=""  />
</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">
</code></pre></div><p><br><br></p>
<h3 id="14-preview">1.4 preview</h3>
<p>看到左侧渲染后的数据，同时也能在开发者工具network面板看到肉眼背后的源数据。我们使用preview预览截图再次确认网址规律没有问题。</p>
<p><img loading="lazy" src="img/03-data-preview.jpg" alt=""  />
</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">keyword</span> <span class="o">=</span> <span class="s1">&#39;社会责任报告&#39;</span>
<span class="n">page</span> <span class="o">=</span> <span class="mi">1</span>

<span class="c1">#post方法参数</span>
<span class="n">payload</span> <span class="o">=</span><span class="p">{</span><span class="s2">&#34;seDate&#34;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&#34;&#34;</span><span class="p">,</span><span class="s2">&#34;&#34;</span><span class="p">],</span>
           <span class="s2">&#34;searchKey&#34;</span><span class="p">:</span> <span class="p">[</span><span class="n">keyword</span><span class="p">],</span>
           <span class="s2">&#34;channelCode&#34;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&#34;listedNotice_disc&#34;</span><span class="p">],</span>
           <span class="s2">&#34;pageSize&#34;</span><span class="p">:</span> <span class="mi">50</span><span class="p">,</span>
           <span class="s2">&#34;pageNum&#34;</span><span class="p">:</span> <span class="n">page</span><span class="p">}</span>
</code></pre></div><h3 id="15-csv">1.5 csv</h3>
<p>现在已经把爬虫最重要的工作做完了，剩下的就是想办法构造出csv，并将数据存入csv。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#定义csv字段，存储PDF链接信息至data/esg_links.csv</span>
<span class="n">csvf</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;data/esg_links.csv&#39;</span><span class="p">,</span> <span class="s1">&#39;a+&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">,</span> <span class="n">newline</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
<span class="n">fieldnames</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;id&#39;</span><span class="p">,</span> <span class="s1">&#39;name&#39;</span><span class="p">,</span> <span class="s1">&#39;code&#39;</span><span class="p">,</span> <span class="s1">&#39;date&#39;</span><span class="p">,</span> <span class="s1">&#39;title&#39;</span><span class="p">,</span> <span class="s1">&#39;pdf_link&#39;</span><span class="p">,</span> <span class="s1">&#39;size&#39;</span><span class="p">]</span>
<span class="n">writer</span> <span class="o">=</span> <span class="n">csv</span><span class="o">.</span><span class="n">DictWriter</span><span class="p">(</span><span class="n">csvf</span><span class="p">,</span> <span class="n">fieldnames</span><span class="o">=</span><span class="n">fieldnames</span><span class="p">)</span>
<span class="n">writer</span><span class="o">.</span><span class="n">writeheader</span><span class="p">()</span>

<span class="n">test_data</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;pdf_link&#39;</span><span class="p">:</span> <span class="s1">&#39;测试pdf文件链接&#39;</span><span class="p">,</span>
             <span class="s1">&#39;code&#39;</span><span class="p">:</span> <span class="s1">&#39;测试股票代码&#39;</span><span class="p">,</span>
             <span class="s1">&#39;name&#39;</span><span class="p">:</span> <span class="s1">&#39;股票名称&#39;</span><span class="p">,</span>
             <span class="s1">&#39;title&#39;</span><span class="p">:</span> <span class="s1">&#39;报告名称&#39;</span><span class="p">,</span>
             <span class="s1">&#39;date&#39;</span><span class="p">:</span> <span class="s1">&#39;发布日期&#39;</span><span class="p">,</span>
             <span class="s1">&#39;size&#39;</span><span class="p">:</span> <span class="s1">&#39;pdf文件字节大小&#39;</span><span class="p">,</span>
             <span class="s1">&#39;id&#39;</span><span class="p">:</span> <span class="s1">&#39;数据id&#39;</span><span class="p">}</span>
             
<span class="n">writer</span><span class="o">.</span><span class="n">writerow</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span>

<span class="c1">#关闭csv</span>
<span class="n">csvf</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</code></pre></div><p><br><br></p>
<h2 id="二爬虫代码完整">二、爬虫代码(完整)</h2>
<p>当你看到本文时，该完整代码很有可能会随着网站变化而失效。不要悲伤难过， 按照爬虫思路自己diy即可。如果没有爬虫基础，学习 <a href="https://www.bilibili.com/video/BV1AE411r7ph">大邓的B站爬虫视频</a> ，</p>
<p><img loading="lazy" src="img/%e5%a4%a7%e9%82%93%e7%88%ac%e8%99%ab.jpg" alt=""  />
</p>
<p>自己懂爬虫原理diy代码，比改别人的代码来的更容易。将前面的准备工作组织起来, 就形成了下面的完整代码</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">requests</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">csv</span>

<span class="n">keyword</span> <span class="o">=</span> <span class="s2">&#34;社会责任报告&#34;</span>

<span class="c1">#定义csv字段，存储PDF链接信息至data/esg_links.csv</span>
<span class="n">csvf</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;data/esg_links.csv&#39;</span><span class="p">,</span> <span class="s1">&#39;a+&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">,</span> <span class="n">newline</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
<span class="n">fieldnames</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;id&#39;</span><span class="p">,</span> <span class="s1">&#39;name&#39;</span><span class="p">,</span> <span class="s1">&#39;code&#39;</span><span class="p">,</span> <span class="s1">&#39;date&#39;</span><span class="p">,</span> <span class="s1">&#39;title&#39;</span><span class="p">,</span> <span class="s1">&#39;pdf_link&#39;</span><span class="p">,</span> <span class="s1">&#39;size&#39;</span><span class="p">]</span>
<span class="n">writer</span> <span class="o">=</span> <span class="n">csv</span><span class="o">.</span><span class="n">DictWriter</span><span class="p">(</span><span class="n">csvf</span><span class="p">,</span> <span class="n">fieldnames</span><span class="o">=</span><span class="n">fieldnames</span><span class="p">)</span>
<span class="n">writer</span><span class="o">.</span><span class="n">writeheader</span><span class="p">()</span>

<span class="c1">#伪装头</span>
<span class="n">headers</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;Accept&#39;</span><span class="p">:</span> <span class="s1">&#39;application/json, text/javascript, */*; q=0.01&#39;</span><span class="p">,</span>
           <span class="s1">&#39;Accept-Encoding&#39;</span><span class="p">:</span> <span class="s1">&#39;gzip, deflate&#39;</span><span class="p">,</span>
           <span class="s1">&#39;Accept-Language&#39;</span><span class="p">:</span> <span class="s1">&#39;zh-CN,zh;q=0.9,en;q=0.8&#39;</span><span class="p">,</span>
           <span class="s1">&#39;Content-Type&#39;</span><span class="p">:</span> <span class="s1">&#39;application/json&#39;</span><span class="p">,</span>
           <span class="s1">&#39;Host&#39;</span><span class="p">:</span> <span class="s1">&#39;www.szse.cn&#39;</span><span class="p">,</span>
           <span class="s1">&#39;Origin&#39;</span><span class="p">:</span> <span class="s1">&#39;http://www.szse.cn&#39;</span><span class="p">,</span>
           <span class="s1">&#39;Proxy-Connection&#39;</span><span class="p">:</span> <span class="s1">&#39;close&#39;</span><span class="p">,</span>
           <span class="s1">&#39;Referer&#39;</span><span class="p">:</span> <span class="s1">&#39;http://www.szse.cn/disclosure/listed/fixed/index.html&#39;</span><span class="p">,</span>
           <span class="s1">&#39;User-Agent&#39;</span><span class="p">:</span> <span class="s1">&#39;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.132 Safari/537.36&#39;</span><span class="p">,</span>
           <span class="s1">&#39;X-Request-Type&#39;</span><span class="p">:</span> <span class="s1">&#39;ajax&#39;</span><span class="p">,</span>
           <span class="s1">&#39;X-Requested-With&#39;</span><span class="p">:</span> <span class="s1">&#39;XMLHttpRequest&#39;</span><span class="p">}</span>

<span class="n">page</span> <span class="o">=</span> <span class="mi">1</span>

<span class="c1">#post方法参数</span>
<span class="n">payload</span> <span class="o">=</span><span class="p">{</span><span class="s2">&#34;seDate&#34;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&#34;&#34;</span><span class="p">,</span><span class="s2">&#34;&#34;</span><span class="p">],</span>
           <span class="s2">&#34;searchKey&#34;</span><span class="p">:</span> <span class="p">[</span><span class="n">keyword</span><span class="p">],</span>
           <span class="s2">&#34;channelCode&#34;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&#34;listedNotice_disc&#34;</span><span class="p">],</span>
           <span class="s2">&#34;pageSize&#34;</span><span class="p">:</span> <span class="mi">50</span><span class="p">,</span>
           <span class="s2">&#34;pageNum&#34;</span><span class="p">:</span> <span class="n">page</span><span class="p">}</span>

<span class="c1">#发起请求</span>
<span class="n">url</span> <span class="o">=</span> <span class="s1">&#39;http://www.szse.cn/api/disc/announcement/annList?random=</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">())</span>
<span class="n">resp</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">post</span><span class="p">(</span><span class="n">url</span><span class="p">,</span>
                     <span class="n">headers</span><span class="o">=</span><span class="n">headers</span><span class="p">,</span>
                     <span class="n">data</span><span class="o">=</span><span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">payload</span><span class="p">))</span>

<span class="c1">#当data关键词有对应的非空列表，循环一直进行。</span>
<span class="k">while</span> <span class="n">resp</span><span class="o">.</span><span class="n">json</span><span class="p">()[</span><span class="s1">&#39;data&#39;</span><span class="p">]:</span>
    <span class="n">payload</span><span class="p">[</span><span class="s1">&#39;pageNum&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">page</span>
    <span class="n">resp</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">post</span><span class="p">(</span><span class="n">url</span><span class="p">,</span>
                     <span class="n">headers</span><span class="o">=</span><span class="n">headers</span><span class="p">,</span>
                     <span class="n">data</span><span class="o">=</span><span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">payload</span><span class="p">))</span>
    
    <span class="n">esgs</span> <span class="o">=</span> <span class="n">resp</span><span class="o">.</span><span class="n">json</span><span class="p">()[</span><span class="s1">&#39;data&#39;</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">esg</span> <span class="ow">in</span> <span class="n">esgs</span><span class="p">:</span>
        <span class="c1">#以字典样式写入csv</span>
        <span class="n">data</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;pdf_link&#39;</span><span class="p">:</span> <span class="s1">&#39;http://disc.static.szse.cn/download&#39;</span><span class="o">+</span> <span class="n">esg</span><span class="p">[</span><span class="s1">&#39;attachPath&#39;</span><span class="p">],</span>
                <span class="c1">#为防止股票代码被exel等软件识别为数字，特转为字符串，并加sz标识。</span>
                <span class="s1">&#39;code&#39;</span><span class="p">:</span> <span class="s1">&#39;sz&#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">esg</span><span class="p">[</span><span class="s1">&#39;secCode&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">]),</span> 
                <span class="s1">&#39;name&#39;</span><span class="p">:</span> <span class="n">esg</span><span class="p">[</span><span class="s1">&#39;secName&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span>
                <span class="s1">&#39;title&#39;</span><span class="p">:</span> <span class="n">esg</span><span class="p">[</span><span class="s1">&#39;title&#39;</span><span class="p">],</span>
                <span class="s1">&#39;date&#39;</span><span class="p">:</span> <span class="n">esg</span><span class="p">[</span><span class="s1">&#39;publishTime&#39;</span><span class="p">],</span>
                <span class="s1">&#39;size&#39;</span><span class="p">:</span> <span class="n">esg</span><span class="p">[</span><span class="s1">&#39;attachSize&#39;</span><span class="p">],</span>
                <span class="s1">&#39;id&#39;</span><span class="p">:</span> <span class="n">esg</span><span class="p">[</span><span class="s1">&#39;id&#39;</span><span class="p">]}</span>
        <span class="n">writer</span><span class="o">.</span><span class="n">writerow</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

    <span class="n">page</span> <span class="o">=</span> <span class="n">page</span> <span class="o">+</span> <span class="mi">1</span>
    
<span class="c1">#关闭csv</span>
<span class="n">csvf</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</code></pre></div><p><br><br></p>
<h2 id="三查看csv">三、查看csv</h2>
<p>使用pandas读取 <code>data/esg_links.csv</code>,</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;esg_links.csv&#39;</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/04-df.png" alt=""  />
</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">4392
</code></pre></div><p>一共有4392条 「企业社会责任」 的报告数据。</p>
<p><br><br></p>
<h2 id="四批量下载">四、批量下载</h2>
<p>下载就简单多了， 直接使用定义好的爬虫代码。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">requests</span>

<span class="k">def</span> <span class="nf">download</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">file</span><span class="p">):</span>
    <span class="s2">&#34;&#34;&#34;
</span><span class="s2">    下载多媒体及文件
</span><span class="s2">    url： 多媒体文件链接（结尾有文件格式名）
</span><span class="s2">    file: 存储文件的路径（结尾有文件格式名）
</span><span class="s2">    &#34;&#34;&#34;</span>
    <span class="n">resp</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
    <span class="c1">#获取到二进制数据</span>
    <span class="n">binarydata</span> <span class="o">=</span> <span class="n">resp</span><span class="o">.</span><span class="n">content</span>
    <span class="c1">#以二进制形式将数据流存入fname中</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">file</span><span class="p">,</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">binarydata</span><span class="p">)</span> 
        

<span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>

<span class="k">for</span> <span class="n">link</span><span class="p">,</span> <span class="n">title</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;pdf_link&#39;</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;title&#39;</span><span class="p">]):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">title</span><span class="p">)</span>
    <span class="n">download</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="n">link</span><span class="p">,</span> <span class="n">file</span><span class="o">=</span><span class="s1">&#39;data/</span><span class="si">{}</span><span class="s1">.pdf&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">title</span><span class="p">))</span>
    <span class="n">i</span> <span class="o">=</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">0 山河药辅：山河药辅2021年度社会责任报告
1 新 希 望：2021年企业社会责任报告（英文版）
2 天原股份：宜宾天原集团股份有限公司社会责任报告
3 五 粮 液：2021年度社会责任报告（英文版）
4 中兵红箭：2021年度社会责任报告	
......
......
148 苏宁环球：2021年社会责任报告
149 蓝色光标：2021年度企业社会责任报告
150 开尔新材：2021年度社会责任报告
151 中顺洁柔：2021年社会责任报告
......
......

4391 闽东电力：2006年度社会责任报告
4392  阳光发展：2006年度社会责任报告书
</code></pre></div><p>采集过程中，被封锁在所难免，所以记得每次停止采集的位置，在csv中删除该位置之前的数据。然后重新运行代码即可。</p>
<h3 id="注意">注意</h3>
<p>即时解决以上问题，可能遇到奇怪的问题。比如</p>
<p><img loading="lazy" src="img/07-error.png" alt=""  />
</p>
<p>检查发现相比其他几百kb的pdf，问题文件大小只有几kb。问题可能是被网站封锁或网络不稳定导致，标记好问题pdf的链接，重新批量下载一遍。</p>
<p><img loading="lazy" src="img/06-error.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="汇总至csv">汇总至csv</h2>
<p>很多企业社会责任报告是图片合成的，所以这里的pdf体积很大。将data文件夹中的4000多个pdf汇总至esg_data.csv中，能节约出电脑内存空间，也方便后续数据分析。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">pdfdocx</span> <span class="kn">import</span> <span class="n">read_pdf</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">csv</span>

<span class="n">i</span> <span class="o">=</span> <span class="mi">1</span>

<span class="c1">#新建esg_data.csv，用于存储企业社会责任报告数据</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;esg_data.csv&#39;</span><span class="p">,</span> <span class="s1">&#39;a+&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">,</span> <span class="n">newline</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">csvf</span><span class="p">:</span>
    <span class="n">fieldnames</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;id&#39;</span><span class="p">,</span> <span class="s1">&#39;name&#39;</span><span class="p">,</span> <span class="s1">&#39;code&#39;</span><span class="p">,</span> <span class="s1">&#39;date&#39;</span><span class="p">,</span> <span class="s1">&#39;title&#39;</span><span class="p">,</span> <span class="s1">&#39;pdf_link&#39;</span><span class="p">,</span> <span class="s1">&#39;size&#39;</span><span class="p">,</span> <span class="s1">&#39;report_content&#39;</span><span class="p">]</span>
    <span class="n">writer</span> <span class="o">=</span> <span class="n">csv</span><span class="o">.</span><span class="n">DictWriter</span><span class="p">(</span><span class="n">csvf</span><span class="p">,</span> <span class="n">fieldnames</span><span class="o">=</span><span class="n">fieldnames</span><span class="p">)</span>
    <span class="n">writer</span><span class="o">.</span><span class="n">writeheader</span><span class="p">()</span>

    <span class="n">files</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="s1">&#39;data&#39;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">file</span> <span class="ow">in</span> <span class="n">files</span><span class="p">:</span>
        <span class="n">record_of_df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;title&#39;</span><span class="p">]</span><span class="o">==</span><span class="n">file</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;.pdf&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">)]</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">record_of_df</span><span class="o">.</span><span class="n">to_dict</span><span class="p">()</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">file</span><span class="p">)</span>
        <span class="n">data</span><span class="p">[</span><span class="s1">&#39;report_content&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">read_pdf</span><span class="p">(</span><span class="s1">&#39;data/</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">file</span><span class="p">))</span>
        <span class="n">writer</span><span class="o">.</span><span class="n">writerow</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="n">i</span> <span class="o">=</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span>
</code></pre></div><p>最后，数据从20G的data文件夹(4000多个PDF)压缩为一个170M的esg_data.csv文件。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">esg_reports_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;esg_data.csv&#39;</span><span class="p">)</span>
<span class="n">esg_reports_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/08-esg_reports_df.png" alt=""  />
</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="nb">len</span><span class="p">(</span><span class="n">esg_reports_df</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">4346
</code></pre></div><p><br><br></p>
<h2 id="五相关文献">五、相关文献</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">[1]解学梅, &amp; 朱琪玮. (2021). 企业绿色创新实践如何破解 “和谐共生” 难题?. 管理世界, 37(1), 128-149.
[2]谢红军 &amp; 吕雪.(2022).负责任的国际投资：ESG与中国OFDI. 经济研究(03),83-99.
[3]Schaefer, S. D., Terlutter, R., &amp; Diehl, S. (2019). Is my company really doing good? Factors influencing employees&#39; evaluation of the authenticity of their company&#39;s corporate social responsibility engagement. Journal of business research, 101, 128-143.
</code></pre></div><p><br><br></p>
<h2 id="六其他广告">六、其他(广告)</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>中文金融领域知识图谱的数据集ChainKnowledgeGraph</title>
      <link>https://textdata.cn/blog/chain_knowledge_graph/</link>
      <pubDate>Mon, 06 Dec 2021 16:42:10 +0600</pubDate>
      
      <guid>/blog/chain_knowledge_graph/</guid>
      <description>本文围绕金融领域，推出面向上市公司的产业链图谱。  </description>
      <content:encoded><![CDATA[<p>领域知识图谱的数据集，当前还比较缺失，而作为构建难度最大的产业链图谱领域更为空白。产业链作为产业经济学中的一个概念，是各个产业部门之间基于一定的技术经济关联，并依据特定的逻辑关系和时空布局关系客观形成的链条式关联关系形态。从本质上来说，产业链的本质是用于描述一个具有某种内在联系的企业群结构，产业链中大量存在着上下游关系和相互价值的交换，上游环节向下游环节输送产品或服务，下游环节向上游环节反馈信息。</p>
<p>作者已经先后发布两大领域的实体图谱数据： <br>
1、情报领域【武器装备知识图谱】，地址：https://github.com/liuhuanyong/QAonMilitaryKG<br>
2、医疗领域【医疗知识图谱】，地址： <a href="https://github.com/liuhuanyong/QASystemOnMedicalKG">https://github.com/liuhuanyong/QASystemOnMedicalKG</a></p>
<p>当前，为了进一步推动产业发展，本文围绕金融领域，推出面向上市公司的产业链图谱。</p>
<p>项目地址：</p>

<figure >
    
        <img src="img/1.png" width="800" />
    
    
</figure>

<br>
<h2 id="一项目构成">一、项目构成</h2>
<p>产业链知识图谱包括A股上市公司、行业和产品共3类实体，包括上市公司所属行业关系、行业上级关系、产品上游原材料关系、产品下游产品关系、公司主营产品、产品小类共6大类。</p>
<p>通过数据处理、抽取，最终建成图谱规模数十万，其中包括上市公司4,654家，行业511个，产品95,559条、上游材料56,824条，上级行业480条，下游产品390条，产品小类52,937条，所属行业3,946条。  <br>

<figure >
    
        <img src="img/2.png" width="800" />
    
    
</figure>
</p>
<br>
<h2 id="二项目构建">二、项目构建</h2>
<p>1、实体构建<br>
1）上市公司<br>
目前上市公司已经达到四千多家，是我国重要的公司代表与行业标杆，本图谱选取上市公司作为基础实体之一。通过交易所公开信息中，可以得到上市公司代码、全称、简称、注册地址、挂牌等多个信息。</p>

<figure >
    
        <img src="img/3.png" width="800" />
    
    
</figure>

<p>2）行业分类<br>
行业是产业链图谱中另一个核心内容，也是承载产业、公司及产品的一个媒介，通过这一领携作用，可以生产出大量的行业指数、热点行业等指标。<br>
目前关于行业，已经陆续出现多个行业规范，代表性的有申万三级行业分类、国民经济行业分类等。中国上市公司所属行业的分类准则是依据营业收入等财务数据为主要分类标准和依据，所采用财务数据为经过会计事务所审计并已公开披露的合并报表数据。<br>
2021年6月，申万发布了2021版的行业分类规范，将1级行业从28个调整至31个、2级行业从104个调整至134个、3级行业从227个调整至346个，新增1级行业美容护理等，新增2级行业，并将上市公司进行了归属。本图谱选用申万行业作为基础数据。<br>

<figure >
    
        <img src="img/4.png" width="800" />
    
    
</figure>
</p>
<p>3）业务产品 <br>
业务产品主要指公司主营范围、经营的产品，用于对一个公司的定位。可以从公司的经营范围、年报等文本中进行提取得到。<br>

<figure >
    
        <img src="img/5.png" width="800" />
    
    
</figure>
</p>
<p>2、关系构建 <br>
1）公司所属行业 <br>
通过公开的上市公司行业分类表，可以得到上市公司所对应的行业分类数据。 <br>

<figure >
    
        <img src="img/6.png" width="800" />
    
    
</figure>
</p>
<p>2）行业上级关系 <br>
通过公开的行业三级分类情况，可以通过组合的形式得到行业之间的上级关系数据。 <br>

<figure >
    
        <img src="img/7.png" width="800" />
    
    
</figure>
</p>
<p>3）公司主营产品关系<br>
上市公司的经营产品数据可以从两个方面来获得，一个是从公司简介中的经营范围中结合制定的规则进行提取，另一个是从公司每年发布的半年报、年报中进行提取。这些报告中会有按经营业务、经营产品、经营地域等几个角度对公司的营收占比进行统计，也可以通过制定规则的方式进行提取。第二种方法中，由于已经有统计数据，所以我们可以根据占比数据大小，对主营产品这一关系进行赋值。<br>

<figure >
    
        <img src="img/8.png" width="800" />
    
    
</figure>
</p>
<p>4）产品之间的上下游关系<br>
产品之间的上下游关系，是展示产品之间传导逻辑关系的一个重要方法，包括上游原材料以及下游产品两大类。我们可以多种来获取：<br>
一种是基于规则模式匹配的方式进行抽取，如抽取上游原材料这一关系可以由诸如&quot;a是b的原料/原材料/主要构件/重要原材料/  上游原料&quot;的模式进行抽取&quot;，而下游产品，则同理可以通过&quot;A是B的下游成品/产品&quot;等模式进行提取。<br>
另一种是基于序列标注的提取。还有一种是基于现有结构化知识图谱的提取，例如已经结构化好的百科知识三元组，可以通过设定谓词及其扩展进行过滤。<br>

<figure >
    
        <img src="img/9.png" width="800" />
    
    
</figure>
</p>
<p>5）产品之间的小类关系<br>
对于一个产品而言，其是有大小层级分类的，在缺少大类产品名称的时候，可以通过计算小类产品来得到相应指标。与产品之间的上下游数据类似，可以通过启发式规则的方式进行提取，如“A是一种B”，也可以通过字符之间的组成成分进行匹配生成，如“螺纹钢”是“精细螺纹钢”的一个大类。<br>

<figure >
    
        <img src="img/10.png" width="800" />
    
    
</figure>
</p>
<br>
<h2 id="三项目运行">三、项目运行</h2>
<p>1、data文件夹下包括了本项目的数据信息：<br>
1)company.json:公司实体数据<br>
2)industry.json:行业实体数据 <br>
3)product.json:产品实体数据 <br>
4)company_industry.json:公司-行业关系数据 <br>
5)industry_industry.json:行业-行业关系数据 <br>
6)product_product.json:产品-产品数据 <br>
7)company_product.json:公司-产品数据</p>
<p>2、项目运行:<br>
python build_graph.py</p>
<br>
<h2 id="四项目总结">四、项目总结</h2>
<p>产业链图谱是众多领域知识图谱中较为棘手的一种，本项目通过现有的数据，借助数据处理、结构化提取方式，设计、构建并形成了一个节点100,718，关系边169,153的十万级别产业链图谱。就产业链图谱的构建而言，我们需要至少从以上三个方面加以考虑：</p>
<ul>
<li>其一，产业链的主观性与标准性。产业链的主观性较强，不同的人对产业链的构建、产业链节点、关系的类型，产业链的颗粒度问题都有不同的理解。不同的设定会直接导致不同的应用结果。正如我们所看到的，目前存在不同的行业标准，不同的网站、机构也将公司归为不同的行业。</li>
<li>其二，产业链的动态性和全面性。产业链需要具备足够大的复用性和扩展性，几千家上市公司实际上是冰山一角。国内有几千万家公司，而且不断会有新增，如何将新增的公司融入到这个额产业链中，也是一个很大挑战。此外，产业本身是动态的， 随着行业的发展，不断会有新的行业出现。如何捕捉这种行业的变化，使得整个图谱变得与时俱进，也是需要考量的点。</li>
<li>其三，产业链的定量推理特性。单纯定性的构建产业链知识图谱，如果没有足够的参数，仅有知识表达是无法进行推理的，推理要求知识图谱Schema具备节点间推理传导的必备参数，以及影响推理传导的其他关键参数。对于必备参数来说，从公司到产品必须有主营占比、市场占比、产能占比等数据，从产品到产品必须有成本占比和消耗占比等数据。</li>
</ul>
<br>
<h2 id="参考数据来源">参考数据来源</h2>
<p>1、申万行业：http://www.swsindex.com<br>
2、深交所: <a href="http://www.szse.cn">http://www.szse.cn</a><br>
3、上交所: <a href="http://www.sse.com.cn">http://www.sse.com.cn</a></p>
<p>If any question about the project or me ,see <a href="https://liuhuanyong.github.io/">https://liuhuanyong.github.io/</a></p>
<p>如有自然语言处理、知识图谱、事理图谱、社会计算、语言资源建设等问题或合作，可联系我： <br>
1、我的github项目介绍：https://liuhuanyong.github.io<br>
2、我的csdn博客：https://blog.csdn.net/lhy2014<br>
3、about me:刘焕勇，lhy_<a href="mailto:in_blcu@126.com">in_blcu@126.com</a>.      <br>
4、我的技术公众号:老刘说NLP</p>
<br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>中文语义常用词典ChineseSemanticKB</title>
      <link>https://textdata.cn/blog/chinese_semantic_kb/</link>
      <pubDate>Mon, 06 Dec 2021 16:40:10 +0600</pubDate>
      
      <guid>/blog/chinese_semantic_kb/</guid>
      <description>面向中文处理的12类、百万规模的语义常用词典，包括34万抽象语义库、34万反义语义库、43万同义语义库等，可支持句子扩展、转写、事件抽象与泛化等多种应用场景。</description>
      <content:encoded><![CDATA[<h2 id="chinesesemantickb">ChineseSemanticKB</h2>
<p>ChineseSemanticKB,chinese semantic knowledge base, 面向中文处理的12类、百万规模的语义常用词典，包括34万抽象语义库、34万反义语义库、43万同义语义库等，可支持句子扩展、转写、事件抽象与泛化等多种应用场景。</p>
<br>
<h2 id="项目介绍">项目介绍</h2>
<p>语义知识库是自然语言处理中十分重要的一个基础资源，与学术界追求算法模型不同，工业界的自然语言处理对于底层的词汇知识库、语义知识库等多种资源依赖度很高，具体体现在：<br>
1、具有落地场景的自然语言处理任务都是业务高度相关，一个业务需求刚进去，需要解决的是业务的词汇问题，无基础词库，无项目冷启动；<br>
2、规则和正则启动下的工业级应用，规则的扩展、泛化都需要底层的词汇网络做支撑；<br>
3、目前包括搜索、问答、舆情监控、事件分析等应用，与标签体系的运作关系密切，而这与先验的底层词汇库依赖性很强；<br>
4、自然语言场景越来越关注推理层面，即所谓的“认知”层面，认知背后的各种逻辑关系库，是驱动这一决策的根本途径；<br>
5、当前，面向中文开源词库的工作存在少量、分散的状态，无论从规模，还是质量，都需要进一步聚合；<br>
因此，我从过往的开源工作中进一步抽离和整理，形成了中文处理的12类、百万规模的语义常用词典，包括34万抽象语义库、34万反义语义库、43万同义语义库等，用于相关下游任务。</p>
<p>项目放于dict当中，可直接下载，不建议二次建库共享，尊重开源。</p>
<br>
<h2 id="词库的类别">词库的类别</h2>
<table>
<thead>
<tr>
<th style="text-align:left">词库类型</th>
<th style="text-align:center">词库规模</th>
<th style="text-align:center">词库举例</th>
<th style="text-align:center">词库应用</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">抽象关系库</td>
<td style="text-align:center">346,048</td>
<td style="text-align:center">座椅,抽象,家具</td>
<td style="text-align:center">事件抽象与泛化，人民币贬值到货币贬值，再到美元贬值，可支持查询扩展、推荐等任务</td>
</tr>
<tr>
<td style="text-align:left">反义关系库</td>
<td style="text-align:center">34,380</td>
<td style="text-align:center">开心@苦恼</td>
<td style="text-align:center">可用于句子改写，开心改苦恼，支持数据增强，句子生成</td>
</tr>
<tr>
<td style="text-align:left">同义关系库</td>
<td style="text-align:center">424,826</td>
<td style="text-align:center">开心@高兴</td>
<td style="text-align:center">可用于查询扩展、数据增强，也可结合抽象关系库完成推荐等任务</td>
</tr>
<tr>
<td style="text-align:left">简称关系库</td>
<td style="text-align:center">136,081</td>
<td style="text-align:center">北京大学@北大</td>
<td style="text-align:center">可用于句子标准化、句子改写、实体消歧等任务</td>
</tr>
<tr>
<td style="text-align:left">程度副词</td>
<td style="text-align:center">222</td>
<td style="text-align:center">极其,2.0</td>
<td style="text-align:center">可用于情感强度计算，带情感色彩的句子生成</td>
</tr>
<tr>
<td style="text-align:left">否定词</td>
<td style="text-align:center">586</td>
<td style="text-align:center">不,无,没有</td>
<td style="text-align:center">可用于情感计算等任务</td>
</tr>
<tr>
<td style="text-align:left">节日时间词</td>
<td style="text-align:center">54</td>
<td style="text-align:center">春节、五四节</td>
<td style="text-align:center">可用于时间词识别等任务</td>
</tr>
<tr>
<td style="text-align:left">量比词</td>
<td style="text-align:center">7</td>
<td style="text-align:center">占比、环比、同比</td>
<td style="text-align:center">可用于金融领域指标类数据提取任务</td>
</tr>
<tr>
<td style="text-align:left">数量介词</td>
<td style="text-align:center">24</td>
<td style="text-align:center">大约、达到、超过</td>
<td style="text-align:center">可用于金融事件抽象或主干化的搭配词处理任务</td>
</tr>
<tr>
<td style="text-align:left">停用词</td>
<td style="text-align:center">3,861</td>
<td style="text-align:center">？、的、着</td>
<td style="text-align:center">常规的文本特征提取等任务</td>
</tr>
<tr>
<td style="text-align:left">修饰副词</td>
<td style="text-align:center">222</td>
<td style="text-align:center">所、有所</td>
<td style="text-align:center">可结合程度副词完成情感强度计算等任务</td>
</tr>
<tr>
<td style="text-align:left">情态词</td>
<td style="text-align:center">77</td>
<td style="text-align:center">肯定、应该、大概</td>
<td style="text-align:center">可用于句子主观性计算、舆情与可信度计算</td>
</tr>
</tbody>
</table>
<br>
<h2 id="总结">总结</h2>
<p>1、本项目开源了一个目前可用于事件处理以及工业舆情的12类语义词库，总规模数目一百余万；<br>
2、本项目开源的34万抽象语义库、34万反义语义库、43万同义语义库，在作者的实际工作中【事件处理、事理抽取、事件推理】等有重要用途;<br>
3、中文常用语义常用词典，均来源于公开文本+人工整理+机器抽取形成，其中若有质量不高之处，可积极批评指正;<br>
4、中文开源事业还是要坚持做下去，尽可能地缩短自然语言处理学术界和工业界之间的鸿沟。</p>
<blockquote>
<p>If any question about the project or me ,see <a href="https://liuhuanyong.github.io/">https://liuhuanyong.github.io/</a>.<br>
如有自然语言处理、知识图谱、事理图谱、社会计算、语言资源建设等问题或合作，可联系我：     <br>
1、我的github项目介绍：https://liuhuanyong.github.io  <br>
2、我的csdn技术博客：https://blog.csdn.net/lhy2014 <br>
3、我的联系方式: 刘焕勇，中国科学院软件研究所，lhy_<a href="mailto:in_blcu@126.com">in_blcu@126.com</a>. <br>
4、我的共享知识库项目：刘焕勇，数据地平线，http://www.openkg.cn/organization/datahorizon.<br>
5、我的工业项目：刘焕勇，数据地平线，大规模实时事理学习系统：https://xueji.datahorizon.cn.  <br>
6、我的工业项目：刘焕勇，数据地平线，面向事件和语义的自然语言处理工具箱：https://nlp.datahorizon.cn</p>
</blockquote>
<br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>70G上交所年报数据集</title>
      <link>https://textdata.cn/blog/70g_china_market_anunal_report_datasets/</link>
      <pubDate>Mon, 22 Nov 2021 20:40:10 +0600</pubDate>
      
      <guid>/blog/70g_china_market_anunal_report_datasets/</guid>
      <description>Python网络爬虫与文本分析， 70g会计年报pdf数据集免费下载</description>
      <content:encoded><![CDATA[<h2 id="70g年报pdf数据集">70G年报pdf数据集</h2>
<p><img loading="lazy" src="img/1.gif" alt=""  />
</p>
<h2 id="数据下载说明">数据下载说明</h2>
<p>所有pdf均来自上海证券交易所官网，使用shreport库进行的下载。</p>
<p><img loading="lazy" src="img/2.png" alt=""  />
</p>
<h2 id="报告信息汇总文件">报告信息汇总文件</h2>
<h4 id="heading"></h4>
<p><img loading="lazy" src="img/3.gif" alt=""  />
</p>
<p>summary.xlsx内字段</p>
<ul>
<li>company 上市公司企业名</li>
<li>code 股票代码</li>
<li>type 报告类型</li>
<li>year 报告年份</li>
<li>date 报告发布日期</li>
<li>pdf 报告pdf文件下载链接</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">import pandas as pd
from pathlib import Path


#报告汇总文件summary.xlsx
df = pd.read_excel(&#39;summary.xlsx&#39;)
df.head()
</code></pre></div><p><img loading="lazy" src="img/4.png" alt=""  />
</p>
<p>一共有报告71126份</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">len(df)
71149
</code></pre></div><p>一共有上市公司1486家</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">len(df[&#39;company&#39;].unique())
1486
</code></pre></div><h2 id="summary文件夹">summary文件夹</h2>
<p>summary文件夹内是每家公司的报告披露情况</p>
<p><img loading="lazy" src="img/5.gif" alt=""  />
</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">df1 = pd.read_excel(&#39;summary/600000.xlsx&#39;)
df1.head()
</code></pre></div><p><img loading="lazy" src="img/6.png" alt=""  />
</p>
<p>浦发银行一共有75份定期报告</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">len(df1)
75
</code></pre></div><h2 id="reports文件夹">reports文件夹</h2>
<p>reports文件夹存放着以各各公司股票代码命名的文件夹</p>
<p>文件夹内是该公司所有定期报告</p>
<p><img loading="lazy" src="img/7.gif" alt=""  />
</p>
<h2 id="读取pdf报告">读取pdf报告</h2>
<p>可使用pdfdocx库读取pdf,</p>
<p>pdfdocx文档链接 <a href="https://github.com/thunderhit/pdfdocx">https://github.com/thunderhit/pdfdocx</a></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">from pdfdocx import read_pdf

p_text = read_pdf(&#39;reports/600000/600000_2012_1.pdf&#39;)
p_text
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">上海浦东发展银行股份有限公司 \n\n2012 年第一季度报告 \n\n \n\n \n\n§1 重要提示 \n\n1.1 公司董事会、监事会及其董事、监事、高级管理人员保证本报告所载资料不存在任何虚假记载、\n\n误导性陈述或者重大遗漏，并对其内容的真实性、准确性和完整性承担个别及连带责任。\n\n1.2 公司于 2012 年 4 月 26 日以通讯表决的方式召开第四届董事会第二十六次会议审议通过本报告，\n\n1.4 公司董事长、行长吉晓辉、财务总监刘信义及财务机构负责人傅能声明：保证本季度报告中财务\n\n公司全体董事出席董事会会议并行使表决权。\n\n1.3 公司第一季度财务报告未经审计。\n\n报告的真实、完整。\n\n \n§2 公司基本情况 \n\n2.1 主要会计数据及财务指标 \n\n本报告期末 \n\n上年度期末 \n\n币种:人民币 \n\n本报告期末比上年\n度期末增减(%) \n\n总资产(千元) \n\n归属于上市公司股东的所有者权益(千元) \n\n2,804,646,567\n\n157,055,724\n\n2,684,693,689 \n148,891,235 \n\n归属于上市公司股东的每股净资产(元) \n\n8.420\n\n7.982 \n\n4.47 \n5.48 \n5.49 \n\n经营活动产生的现金流量净额(千元) \n\n每股经营活动产生的现金流\n\n \n\n \n \n母公司现金流量表 \n \n2012 年 1—3 月 \n \n编制单位: 上海浦东发展银行股份有限公司....
</code></pre></div><h2 id="70g数据下载">70G数据下载</h2>
<p>链接:https://pan.baidu.com/s/14PI6MbxunFQ3fZOfR33zkw 密码:osoi</p>
<br>
<br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
  </channel>
</rss>
