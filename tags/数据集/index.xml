<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>数据集 on 大邓和他的PYTHON</title>
    <link>/tags/%E6%95%B0%E6%8D%AE%E9%9B%86/</link>
    <description>Recent content in 数据集 on 大邓和他的PYTHON</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh</language>
    <lastBuildDate>Mon, 13 Feb 2023 00:00:00 +0000</lastBuildDate><atom:link href="/tags/%E6%95%B0%E6%8D%AE%E9%9B%86/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>cctv新闻联播文稿数据集</title>
      <link>https://hidadeng.github.io/blog/2023-02-26-cctv1-news-text-dataset/</link>
      <pubDate>Mon, 13 Feb 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-02-26-cctv1-news-text-dataset/</guid>
      <description>cctv新闻联播文稿数据集，可使用Python对其进行挖掘，借助文本挖掘技术研究鸿观经济政策、社会学、传播学等领域。</description>
      <content:encoded><![CDATA[<br>
<h2 id="安装">安装</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">pip install akshare
</code></pre></div><br>
<h2 id="aknews_cctv参数">ak.news_cctv参数</h2>
<p>查看ak.news_cctv函数的帮助文档，显示该函数<strong>只能采集20160203之后的数据</strong></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">help</span><span class="p">(</span><span class="n">ak</span><span class="o">.</span><span class="n">news_cctv</span><span class="p">)</span>
</code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">Help on function news_cctv in module akshare.news.news_cctv:

news_cctv(date: str = &#39;20130308&#39;) -&gt; pandas.core.frame.DataFrame
    新闻联播文字稿
    https://tv.cctv.com/lm/xwlb/?spm=C52056131267.P4y8I53JvSWE.0.0
    :param date: 需要获取数据的日期; 目前 20160203 年后
    :type date: str
    :return: 新闻联播文字稿
    :rtype: pandas.DataFrame
</code></pre></div><h2 id="获取某日新闻">获取某日新闻</h2>
<p>获取某日期的新闻联播文稿</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">akshare</span> <span class="k">as</span> <span class="nn">ak</span>

<span class="n">news_cctv_df</span> <span class="o">=</span> <span class="n">ak</span><span class="o">.</span><span class="n">news_cctv</span><span class="p">(</span><span class="n">date</span><span class="o">=</span><span class="s2">&#34;20160204&#34;</span><span class="p">)</span>
<span class="n">news_cctv_df</span>
</code></pre></div><p><img loading="lazy" src="img/df1.png" alt=""  />
</p>
<br>
<h2 id="批量存储">批量存储</h2>
<p>批量存储**20160203 - 至今 ** 之间所有的数据，每个日期保存到csv文件中。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">datetime</span> 
<span class="kn">import</span> <span class="nn">akshare</span> <span class="k">as</span> <span class="nn">ak</span>

<span class="c1">#获取【20160203 - 至今】日期字符串的列表</span>
<span class="k">def</span> <span class="nf">date_ranges</span><span class="p">():</span>
    <span class="n">begin</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">datetime</span><span class="p">(</span><span class="mi">2016</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
    <span class="n">now</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">today</span><span class="p">()</span>
    <span class="n">interv</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">timedelta</span><span class="p">(</span><span class="n">days</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">dates</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">date</span> <span class="o">=</span> <span class="n">begin</span>
    <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">date</span> <span class="o">&lt;</span> <span class="n">now</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">date</span> <span class="o">+</span> <span class="n">interv</span> <span class="o">&lt;</span> <span class="n">now</span><span class="p">):</span>
            <span class="n">date</span> <span class="o">=</span> <span class="n">date</span> <span class="o">+</span> <span class="n">interv</span>
            <span class="n">dates</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">date</span><span class="o">.</span><span class="n">strftime</span><span class="p">(</span><span class="s1">&#39;%Y%m</span><span class="si">%d</span><span class="s1">&#39;</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">dates</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">now</span><span class="o">.</span><span class="n">strftime</span><span class="p">(</span><span class="s1">&#39;%Y%m</span><span class="si">%d</span><span class="s1">&#39;</span><span class="p">))</span>
            <span class="k">break</span>
    <span class="k">return</span> <span class="n">dates</span>


<span class="c1">#按 日期依次下载</span>
<span class="k">for</span> <span class="n">date</span> <span class="ow">in</span> <span class="n">date_ranges</span><span class="p">():</span>
    <span class="n">news_cctv_df</span> <span class="o">=</span> <span class="n">ak</span><span class="o">.</span><span class="n">news_cctv</span><span class="p">(</span><span class="n">date</span><span class="o">=</span><span class="n">date</span><span class="p">)</span>
    <span class="n">news_cctv_df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;cctv/</span><span class="si">{}</span><span class="s1">.csv&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">date</span><span class="p">),</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">date</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">20160203
20160204
20160205
......
                                               
20230223
20230224
20230225
</code></pre></div><h2 id="数据集">数据集</h2>
<p>运行了5个小时，共有 2,518 天的新闻联播新闻稿的csv文件。</p>
<p><img loading="lazy" src="img/csvs.png" alt=""  />
</p>
<br>
<h2 id="数据获取">数据获取</h2>
<p>链接: <a href="https://pan.baidu.com/s/1pSdKe53OIZANwRAAZ0TGAg">https://pan.baidu.com/s/1pSdKe53OIZANwRAAZ0TGAg</a> 提取码: uxxs</p>
<br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">支持开票 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>1850万条 | 世界地图POI兴趣点数据集</title>
      <link>https://hidadeng.github.io/blog/2022-12-10-1850w-poi-dataset/</link>
      <pubDate>Sat, 10 Dec 2022 00:00:00 +0000</pubDate>
      
      <guid>/blog/2022-12-10-1850w-poi-dataset/</guid>
      <description>1850万条世界地图POI兴趣点数据集，可用于GIS、区域经济等领域的研究</description>
      <content:encoded><![CDATA[<h2 id="世界地图poi兴趣点数据集">世界地图POI兴趣点数据集</h2>
<p>POI数据集包含全球超过 1850 万个 POI， 数据按国家或地区组织分别以 CSV 文存档中， 数据集每月更新一次。</p>
<br>
<h2 id="数据价值">数据价值</h2>
<p>POI数据集含 区域位置、商业地点、营业时间，运营主体，网站等信息， 可用于GIS、区域经济等领域的研究。
<strong>文末有数据集获取方式</strong> , 数据集中包含的字段有</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">- ID OpenStreetMap ID
- NAME 地名、国际名称
- CATEGORY、SUBCATEGORY POI类目/子类目
- LAT、LON 经度、纬度
- SRID 基于OSM标签的POI分类（14类167子类）
- WKT   WGS84中的geometry (WKT)；
- IMAGE 链接到照片/图像；
- OPENING_HOURS  营业时间
- WIKIPEDIA 链接到维基百科文章；
- LAST_UPDATE 上次更新日期，
- OPERATOR 运营商
- ALTERNATIVE_NAME 备用名称
- INTERNATIONAL_NAME 国际名称（通常为英文或音译为拉丁字符）；
- STREET、HOUSENUMBER 地址（街道、门牌号）
- POSTCODE、CITY、COUNTRY   地址（邮编、城市、国家）；
- DESCRIPTION 完整描述（如果在 OSM 中列出）；
- PHONE、FAX、WEBSITE、EMAIL      联系人（电话号码、传真号码、网站、邮箱）；
- OTHER_TAGS 而其余标记值列在“OTHER_TAGS”列下。
</code></pre></div><br>
<p><img loading="lazy" src="img/world.png" alt=""  />
</p>
<p><img loading="lazy" src="img/asia.png" alt=""  />
</p>
<br>
<h3 id="数据质量对比">数据质量对比</h3>
<p>OpenStreetMap（简称OSM，中文是公开地图）是一个网上地图协作计划，目标是创造一个内容自由且能让所有人编辑的世界地图。OSM的数据有两种来源</p>
<ul>
<li>广大用户的贡献（众包），包括利用 GPS 设备自行测绘和根据卫星影像地图（Bing/Yahoo!/Landsat等）绘制两种，</li>
<li>少数政府部门的测绘机构及商业公司根据相应授权提供。</li>
</ul>
<p>而Google的数据则主要依靠专业测绘商采购（在中国主要是 AutoNavi/高德），以自己采集（街景）、政府部门提供（主要是NASA的Landsat影像）和用户贡献（Google Map Maker）作为补充。据此不难看出，OSM数据的优势主要体现在更新及时，而Google则胜在较强的专业性和准确性。至于数据的覆盖面，这要看OSM贡献者数量和Google财力与测绘商能力的对比。当OSM贡献者的数量和参与热情达到一定水平，其数据的数量和质量完全不逊于Google（请看OSM上德国地图）。维基百科战胜大英百科全书即是侧证。</p>
<br>
<h2 id="导入数据">导入数据</h2>
<p>以中国数据为例</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;china-pois.osm.csv&#39;</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s1">&#39;|&#39;</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/df.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#poi数据量</span>
<span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
</code></pre></div><pre><code>911246
</code></pre>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#poi数据集的字段</span>
<span class="n">df</span><span class="o">.</span><span class="n">columns</span>
</code></pre></div><pre><code>Index(['ID', 'NAME', 'CATEGORY', 'SUBCATEGORY', 'LON', 'LAT', 'SRID', 'WKT',
       'CITY', 'IMAGE', 'EMAIL', 'COUNTRY', 'OPENING_HOURS', 'WIKIPEDIA',
       'OPERATOR', 'DESCRIPTION', 'LAST_UPDATE', 'ALTERNATIVE_NAME',
       'POSTCODE', 'INTERNATIONAL_NAME', 'WEBSITE', 'PHONE', 'NAME_EN',
       'STREET', 'HOUSENUMBER', 'FAX', 'OTHER_TAGS'],
      dtype='object')
</code></pre>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#poi类型分布</span>
<span class="n">df</span><span class="o">.</span><span class="n">CATEGORY</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</code></pre></div><pre><code>SETTLEMENTS      397769
TRANSPORT        198462
EDUCATION         56087
LANDUSE           50161
TOURISM           47618
SHOP              42939
EAT/DRINK         28386
PUBLICSERVICE     22905
AUTOMOTIVE        14809
ACCOMMODATION     13092
BUSINESS          12573
HEALTH            10747
RELIGIOUS          8039
SPORT              7659
Name: CATEGORY, dtype: int64
</code></pre>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#经纬度范围</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;经度(东)&#39;</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">LON</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;经度(西)&#39;</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">LON</span><span class="o">.</span><span class="n">min</span><span class="p">())</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;纬度(北)&#39;</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">LAT</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;纬度(南)&#39;</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">LAT</span><span class="o">.</span><span class="n">min</span><span class="p">())</span>
</code></pre></div><pre><code>经度(东) 135.08528800000002
经度(西) 72.2818637
纬度(北) 53.56513885988782
纬度(南) 15.1251016
</code></pre>
<br>
<h2 id="字段解析">字段解析</h2>
<ul>
<li>ID OpenStreetMap ID</li>
<li>NAME 地名、国际名称</li>
<li>CATEGORY、SUBCATEGORY POI类目/子类目</li>
<li>LAT、LON 经度、纬度</li>
<li>SRID 基于OSM标签的POI分类（14类167子类）</li>
<li>WKT   WGS84中的geometry (WKT)；</li>
<li>IMAGE 链接到照片/图像；</li>
<li>OPENING_HOURS  营业时间</li>
<li>WIKIPEDIA 链接到维基百科文章；</li>
<li>LAST_UPDATE 上次更新日期，</li>
<li>OPERATOR 运营商</li>
<li>ALTERNATIVE_NAME 备用名称</li>
<li>INTERNATIONAL_NAME 国际名称（通常为英文或音译为拉丁字符）；</li>
<li>STREET、HOUSENUMBER 地址（街道、门牌号）</li>
<li>POSTCODE、CITY、COUNTRY   地址（邮编、城市、国家）；</li>
<li>DESCRIPTION 完整描述（如果在 OSM 中列出）；</li>
<li>PHONE、FAX、WEBSITE、EMAIL      联系人（电话号码、传真号码、网站、邮箱）；</li>
<li>OTHER_TAGS 而其余标记值列在“OTHER_TAGS”列下。</li>
</ul>
<br>
<h2 id="下载地址">下载地址</h2>
<p>数据集下载地址</p>
<p><a href="http://download.slipo.eu/results/osm-to-csv/poi/">http://download.slipo.eu/results/osm-to-csv/poi/</a></p>
<br>
<h2 id="参考资料">参考资料</h2>
<ul>
<li><a href="http://slipo.eu/?p=1551">http://slipo.eu/?p=1551</a></li>
<li>OpenStreetMap百度词条</li>
<li><a href="https://www.zhihu.com/question/19993564/answer/14428059">https://www.zhihu.com/question/19993564/answer/14428059</a></li>
<li><a href="http://download.slipo.eu/results/osm-to-csv/poi/">http://download.slipo.eu/results/osm-to-csv/poi/</a></li>
</ul>
<br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>数据集 | 585w企业工商注册信息</title>
      <link>https://hidadeng.github.io/blog/2022-12-07-585w-chinese-enterprise-registration-data/</link>
      <pubDate>Tue, 06 Dec 2022 00:00:00 +0000</pubDate>
      
      <guid>/blog/2022-12-07-585w-chinese-enterprise-registration-data/</guid>
      <description>585w企业工商注册信息</description>
      <content:encoded><![CDATA[<p>1978-2019.4,  585w中国大陆企业注册信息</p>
<p>文末有 enterprise-registration-data-of-chinese-mainland.csv 数据获取方式。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;enterprise-registration-data-of-chinese-mainland.csv&#39;</span><span class="p">,</span> 
                 <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">,</span> 
                 <span class="c1">#忽略有问题的记录</span>
                 <span class="n">on_bad_lines</span><span class="o">=</span><span class="s1">&#39;skip&#39;</span><span class="p">)</span>

<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<p><img loading="lazy" src="img/df1.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#剔除大邓广告</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;企业类型&#39;</span><span class="p">]</span><span class="o">!=</span><span class="s1">&#39;公众号: 大邓和他的Python&#39;</span><span class="p">]</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<p><img loading="lazy" src="img/df2.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#记录</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;记录数: &#39;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">))</span>

<span class="c1">#</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;字段有: &#39;</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">&#39;记录数: 12756270&#39;

&#39;字段有: [&#39;企业名称&#39;, &#39;统一社会信用代码&#39;, &#39;注册日期&#39;, &#39;企业类型&#39;, &#39;法人代表&#39;, &#39;注册资金&#39;, &#39;经营范围&#39;, &#39;所在省份&#39;,
       &#39;地区&#39;, &#39;注册地址&#39;]&#39;
</code></pre></div><br>
<p>但数据可能会有重复，这里以企业名称作为唯一标识，可以查看真实的数据量</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;真实记录数: &#39;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;企业名称&#39;</span><span class="p">])))</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">&#39;真实记录数: 5888382&#39;
</code></pre></div><br>
<br>
<h2 id="二如何将多个csv汇总到一个csv中">二、如何将多个csv汇总到一个csv中？</h2>
<p>那么这个enterprise-registration-data-of-chinese-mainland.csv怎么来的？</p>
<p>原始的数据集结构</p>
<p><img loading="lazy" src="img/screen-1.png" alt=""  />

<img loading="lazy" src="img/screen-2.png" alt=""  />
</p>
<br>
<p>先局部实验成功后，推广到整体。</p>
<ol>
<li>获取路径列表</li>
<li>尝试读取任意一个csv文件</li>
<li>尝试合并两个df</li>
<li>合并所有csv到一个文件内</li>
</ol>
<br>
<h3 id="21-获取路径列表">2.1 获取路径列表</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">os</span>

<span class="c1">#大邓电脑为Mac</span>
<span class="c1">#Mac容易在文件夹中生成奇怪的.DS_Store</span>
<span class="c1">#该操作为获取文件夹列表，同时剔除.DS_Store</span>
<span class="n">y_dirs</span> <span class="o">=</span> <span class="p">[</span><span class="n">di</span> <span class="k">for</span> <span class="n">di</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="s1">&#39;csv&#39;</span><span class="p">)</span> <span class="k">if</span> <span class="s1">&#39;.DS_Store&#39;</span><span class="o">!=</span><span class="n">di</span><span class="p">]</span>
<span class="k">for</span> <span class="n">y_dir</span> <span class="ow">in</span> <span class="n">y_dirs</span><span class="p">:</span>
    <span class="c1">#在年份文件夹内有很多csv文件</span>
    <span class="n">fs</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;csv/</span><span class="si">{}</span><span class="s1">/</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">y_dir</span><span class="p">,</span> <span class="n">fn</span><span class="p">)</span> 
          <span class="k">for</span> <span class="n">fn</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="s1">&#39;csv/</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">y_dir</span><span class="p">))</span>
          <span class="k">if</span> <span class="s1">&#39;.csv&#39;</span> <span class="ow">in</span> <span class="n">fn</span><span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">fs</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">......
......
[&#39;csv/2013/河南.csv&#39;, &#39;csv/2013/青海.csv&#39;, &#39;csv/2013/河北.csv&#39;, &#39;csv/2013/浙江.csv&#39;, &#39;csv/2013/内蒙古.csv&#39;, &#39;csv/2013/辽宁.csv&#39;, &#39;csv/2013/天津.csv&#39;, &#39;csv/2013/福建.csv&#39;, &#39;csv/2013/吉林.csv&#39;, &#39;csv/2013/西藏.csv&#39;, &#39;csv/2013/四川.csv&#39;, &#39;csv/2013/云南.csv&#39;, &#39;csv/2013/宁夏.csv&#39;, &#39;csv/2013/新疆.csv&#39;, &#39;csv/2013/安徽.csv&#39;, &#39;csv/2013/重庆.csv&#39;, &#39;csv/2013/贵州.csv&#39;, &#39;csv/2013/湖南.csv&#39;, &#39;csv/2013/海南.csv&#39;, &#39;csv/2013/湖北.csv&#39;, &#39;csv/2013/江西.csv&#39;, &#39;csv/2013/广东.csv&#39;, &#39;csv/2013/北京.csv&#39;, &#39;csv/2013/山西.csv&#39;, &#39;csv/2013/上海.csv&#39;, &#39;csv/2013/陕西.csv&#39;, &#39;csv/2013/黑龙江.csv&#39;, &#39;csv/2013/甘肃.csv&#39;, &#39;csv/2013/江苏.csv&#39;, &#39;csv/2013/山东.csv&#39;, &#39;csv/2013/广西.csv&#39;]

[&#39;csv/2014/河南.csv&#39;, &#39;csv/2014/青海.csv&#39;, &#39;csv/2014/河北.csv&#39;, &#39;csv/2014/浙江.csv&#39;, &#39;csv/2014/内蒙古.csv&#39;, &#39;csv/2014/辽宁.csv&#39;, &#39;csv/2014/天津.csv&#39;, &#39;csv/2014/福建.csv&#39;, &#39;csv/2014/吉林.csv&#39;, &#39;csv/2014/西藏.csv&#39;, &#39;csv/2014/四川.csv&#39;, &#39;csv/2014/云南.csv&#39;, &#39;csv/2014/宁夏.csv&#39;, &#39;csv/2014/新疆.csv&#39;, &#39;csv/2014/安徽.csv&#39;, &#39;csv/2014/重庆.csv&#39;, &#39;csv/2014/贵州.csv&#39;, &#39;csv/2014/湖南.csv&#39;, &#39;csv/2014/海南.csv&#39;, &#39;csv/2014/湖北.csv&#39;, &#39;csv/2014/江西.csv&#39;, &#39;csv/2014/广东.csv&#39;, &#39;csv/2014/北京.csv&#39;, &#39;csv/2014/山西.csv&#39;, &#39;csv/2014/上海.csv&#39;, &#39;csv/2014/陕西.csv&#39;, &#39;csv/2014/黑龙江.csv&#39;, &#39;csv/2014/甘肃.csv&#39;, &#39;csv/2014/江苏.csv&#39;, &#39;csv/2014/山东.csv&#39;, &#39;csv/2014/广西.csv&#39;]

[&#39;csv/2015/河南.csv&#39;, &#39;csv/2015/青海.csv&#39;, &#39;csv/2015/河北.csv&#39;, &#39;csv/2015/浙江.csv&#39;, &#39;csv/2015/内蒙古.csv&#39;, &#39;csv/2015/辽宁.csv&#39;, &#39;csv/2015/天津.csv&#39;, &#39;csv/2015/福建.csv&#39;, &#39;csv/2015/吉林.csv&#39;, &#39;csv/2015/西藏.csv&#39;, &#39;csv/2015/四川.csv&#39;, &#39;csv/2015/云南.csv&#39;, &#39;csv/2015/宁夏.csv&#39;, &#39;csv/2015/新疆.csv&#39;, &#39;csv/2015/安徽.csv&#39;, &#39;csv/2015/重庆.csv&#39;, &#39;csv/2015/贵州.csv&#39;, &#39;csv/2015/湖南.csv&#39;, &#39;csv/2015/海南.csv&#39;, &#39;csv/2015/湖北.csv&#39;, &#39;csv/2015/江西.csv&#39;, &#39;csv/2015/广东.csv&#39;, &#39;csv/2015/北京.csv&#39;, &#39;csv/2015/山西.csv&#39;, &#39;csv/2015/上海.csv&#39;, &#39;csv/2015/陕西.csv&#39;, &#39;csv/2015/黑龙江.csv&#39;, &#39;csv/2015/甘肃.csv&#39;, &#39;csv/2015/江苏.csv&#39;, &#39;csv/2015/山东.csv&#39;, &#39;csv/2015/广西.csv&#39;]

.....
.....
</code></pre></div><p><br><br></p>
<h3 id="22-尝试读取任意一个csv文件">2.2 尝试读取任意一个csv文件</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">df1</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;csv/2012/辽宁.csv&#39;</span><span class="p">,</span> 
                  <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">,</span> 
                  <span class="n">on_bad_lines</span><span class="o">=</span><span class="s1">&#39;skip&#39;</span><span class="p">)</span>

<span class="n">df1</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<p><img loading="lazy" src="img/df3.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df2</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;csv/2013/青海.csv&#39;</span><span class="p">,</span> 
                  <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">,</span> 
                  <span class="n">on_bad_lines</span><span class="o">=</span><span class="s1">&#39;skip&#39;</span><span class="p">)</span>

<span class="n">df2</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<p><img loading="lazy" src="img/df4.png" alt=""  />
</p>
<br>
<h3 id="23-尝试合并两个df">2.3 尝试合并两个df</h3>
<p>两个df垂直方向堆积，不增加字段种类，所以选择 pd.concat函数。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df12</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">df1</span><span class="p">,</span> <span class="n">df2</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">df12</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<p><img loading="lazy" src="img/df3.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#检查记录数</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">df1</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">df2</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">df12</span><span class="p">))</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">10246
4417
14663
</code></pre></div><br>
<h3 id="24-合并所有csv到一个文件内">2.4 合并所有csv到一个文件内</h3>
<p>将步骤1、2、3代码整理，汇总</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="c1">#存df列表</span>
<span class="n">dfs</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1">#文件路径列表</span>
<span class="n">y_dirs</span> <span class="o">=</span> <span class="p">[</span><span class="n">di</span> <span class="k">for</span> <span class="n">di</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="s1">&#39;csv&#39;</span><span class="p">)</span> <span class="k">if</span> <span class="s1">&#39;.DS_Store&#39;</span><span class="o">!=</span><span class="n">di</span><span class="p">]</span>
<span class="k">for</span> <span class="n">y_dir</span> <span class="ow">in</span> <span class="n">y_dirs</span><span class="p">:</span>
    <span class="n">csvfs</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;csv/</span><span class="si">{}</span><span class="s1">/</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">y_dir</span><span class="p">,</span> <span class="n">fn</span><span class="p">)</span> 
             <span class="k">for</span> <span class="n">fn</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="s1">&#39;csv/</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">y_dir</span><span class="p">))</span>
             <span class="k">if</span> <span class="s1">&#39;.csv&#39;</span> <span class="ow">in</span> <span class="n">fn</span><span class="p">]</span>
    
    <span class="k">for</span> <span class="n">csvf</span> <span class="ow">in</span> <span class="n">csvfs</span><span class="p">:</span>
        
        <span class="c1">#读取csv，得到df</span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">csvf</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">,</span> <span class="n">on_bad_lines</span><span class="o">=</span><span class="s1">&#39;skip&#39;</span><span class="p">)</span>
        <span class="c1">#存入df列表</span>
        <span class="n">dfs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
        
<span class="c1">#合并dfs为alldf</span>
<span class="n">alldf</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">dfs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1">#导出为data.csv</span>
<span class="n">alldf</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;enterprise-registration-data-of-chinese-mainland.csv&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</code></pre></div><p><br><br></p>
<h2 id="三数据获取">三、数据获取</h2>
<p>转发本文至朋友圈集赞50+， 加微信372335839， 备注【姓名-学校-专业-1200w工商】获取本文数据。</p>
<p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>12G数据集 |  23w条Kickstarter项目信息</title>
      <link>https://hidadeng.github.io/blog/2022-12-04-kickstarters_dataset/</link>
      <pubDate>Sun, 04 Dec 2022 00:00:00 +0000</pubDate>
      
      <guid>/blog/2022-12-04-kickstarters_dataset/</guid>
      <description>2016年3月写好的kickstarter爬虫，每月执行一次。截止2022年11月， 所有压缩文件累积11.42G。文末有数据获取方式</description>
      <content:encoded><![CDATA[<h2 id="kickstarter介绍">Kickstarter介绍</h2>
<p>Kickstarter于2009年4月在美国纽约成立，是一个专为具有创意方案的企业筹资的众筹网站平台。</p>
<p>kickstarter平台的运作方式相对来说比较简单而有效：该平台的用户一方是有创新意渴望进行创作和创造的人，另一方则是愿意为他们出资金的人，然后见证新发明新创作新产品的出现。kickstarter网站的创意性活动包括：<strong>音乐，网页设计，平面设计，动画，作家</strong>以及所有有能力创造以及影响他人的活动。</p>
<p><br><br></p>
<h2 id="12g数据集">12G数据集</h2>
<p><strong>2016年3月</strong> 写好的kickstarter爬虫，每月执行一次。截止<strong>2022年11月</strong>， 所有压缩文件累积11.42G。<strong>文末有数据获取方式</strong></p>
<p><img loading="lazy" src="img/kickstarter_datasets_dir_screen.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="参考论文">参考论文</h2>
<p>该数据集研究价值，可用于研究市场营销、创新创业、信息管理等， 部分使用kickstarter作为研究对象的论文。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">[1]王伟,陈伟,祝效国,王洪伟. 众筹融资成功率与语言风格的说服性-基于Kickstarter的实证研究.*管理世界*.2016;5:81-98.
[2]Dai, Hengchen and Dennis J. Zhang. “Prosocial Goal Pursuit in Crowdfunding: Evidence from Kickstarter.” Journal of Marketing Research 56 (2019): 498 - 517.
[3]Gafni, H., Marom, D.M., Robb, A.M., &amp; Sade, O. (2020). Gender Dynamics in Crowdfunding (Kickstarter): Evidence on Entrepreneurs, Backers, and Taste-Based Discrimination*. Review of Finance.
[4]Jensen, Lasse Skovgaard and Ali Gürcan Özkil. “Identifying challenges in crowdfunded product development: a review of Kickstarter projects.” Design Science 4 (2018): n. pag.
</code></pre></div><br>
<br>
<h2 id="查看数据">查看数据</h2>
<p>任意选择一个zip文件解压会得到json文件，注意 <strong>不同json文件不太一样，所以本文的代码可能要有调整。</strong></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="c1">#读取任意一个zip解压得到的csv文件</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_json</span><span class="p">(</span><span class="s1">&#39;data/Kickstarter_2022-06-09T03_20_03_365Z.json&#39;</span><span class="p">,</span> <span class="n">lines</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<p><img loading="lazy" src="img/df.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">230346
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1"># 选中projects字段</span>
<span class="n">projects</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;data&#39;</span><span class="p">]</span>
<span class="n">projects</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">    0         {&#39;id&#39;: 947118202, &#39;photo&#39;: {&#39;key&#39;: &#39;assets/029...
    1         {&#39;id&#39;: 426094497, &#39;photo&#39;: {&#39;key&#39;: &#39;assets/029...
    2         {&#39;id&#39;: 44835253, &#39;photo&#39;: {&#39;key&#39;: &#39;assets/034/...
    3         {&#39;id&#39;: 1001767271, &#39;photo&#39;: {&#39;key&#39;: &#39;assets/03...
    4         {&#39;id&#39;: 1880345176, &#39;photo&#39;: {&#39;key&#39;: &#39;assets/03...
                                    ...                        
    230341    {&#39;id&#39;: 676753351, &#39;photo&#39;: {&#39;key&#39;: &#39;assets/012...
    230342    {&#39;id&#39;: 1579378115, &#39;photo&#39;: {&#39;key&#39;: &#39;assets/02...
    230343    {&#39;id&#39;: 1281094926, &#39;photo&#39;: {&#39;key&#39;: &#39;assets/02...
    230344    {&#39;id&#39;: 783009016, &#39;photo&#39;: {&#39;key&#39;: &#39;assets/012...
    230345    {&#39;id&#39;: 324368296, &#39;photo&#39;: {&#39;key&#39;: &#39;assets/012...
    Name: data, Length: 230346, dtype: object
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#查看第一行，data列</span>
<span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;data&#39;</span><span class="p">]</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">    {&#39;id&#39;: 947118202,
     &#39;photo&#39;: {&#39;key&#39;: &#39;assets/029/542/393/098b025d0c25cc15e5b5f673b9ec992a_original.png&#39;,
      &#39;full&#39;: &#39;https://ksr-ugc.imgix.net/assets/029/542/393/098b025d0c25cc15e5b5f673b9ec992a_original.png?ixlib=rb-4.0.2&amp;crop=faces&amp;w=560&amp;h=315&amp;fit=crop&amp;v=1592675400&amp;auto=format&amp;frame=1&amp;q=92&amp;s=26209d432871ad2e9cca642527c291d9&#39;,
      &#39;ed&#39;: &#39;https://ksr-ugc.imgix.net/assets/029/542/393/098b025d0c25cc15e5b5f673b9ec992a_original.png?ixlib=rb-4.0.2&amp;crop=faces&amp;w=352&amp;h=198&amp;fit=crop&amp;v=1592675400&amp;auto=format&amp;frame=1&amp;q=92&amp;s=db82255e6639d5951506e0f2ed4d7d8b&#39;,
      &#39;med&#39;: &#39;https://ksr-ugc.imgix.net/assets/029/542/393/098b025d0c25cc15e5b5f673b9ec992a_original.png?ixlib=rb-4.0.2&amp;crop=faces&amp;w=272&amp;h=153&amp;fit=crop&amp;v=1592675400&amp;auto=format&amp;frame=1&amp;q=92&amp;s=f7b43116136000c8efa892bdbdd2d956&#39;,
      &#39;little&#39;: &#39;https://ksr-ugc.imgix.net/assets/029/542/393/098b025d0c25cc15e5b5f673b9ec992a_original.png?ixlib=rb-4.0.2&amp;crop=faces&amp;w=208&amp;h=117&amp;fit=crop&amp;v=1592675400&amp;auto=format&amp;frame=1&amp;q=92&amp;s=a52e3c34066a020e040c517c614a8b36&#39;,
      &#39;small&#39;: &#39;https://ksr-ugc.imgix.net/assets/029/542/393/098b025d0c25cc15e5b5f673b9ec992a_original.png?ixlib=rb-4.0.2&amp;crop=faces&amp;w=160&amp;h=90&amp;fit=crop&amp;v=1592675400&amp;auto=format&amp;frame=1&amp;q=92&amp;s=6c5f1c254119ffe914b50250f8e2899f&#39;,
      &#39;thumb&#39;: &#39;https://ksr-ugc.imgix.net/assets/029/542/393/098b025d0c25cc15e5b5f673b9ec992a_original.png?ixlib=rb-4.0.2&amp;crop=faces&amp;w=48&amp;h=27&amp;fit=crop&amp;v=1592675400&amp;auto=format&amp;frame=1&amp;q=92&amp;s=0222f379ed51059eb73adc7436f07b1e&#39;,
      &#39;1024x576&#39;: &#39;https://ksr-ugc.imgix.net/assets/029/542/393/098b025d0c25cc15e5b5f673b9ec992a_original.png?ixlib=rb-4.0.2&amp;crop=faces&amp;w=1024&amp;h=576&amp;fit=crop&amp;v=1592675400&amp;auto=format&amp;frame=1&amp;q=92&amp;s=d01546c5e88f3f47e0dddc48b5dce9df&#39;,
      &#39;1536x864&#39;: &#39;https://ksr-ugc.imgix.net/assets/029/542/393/098b025d0c25cc15e5b5f673b9ec992a_original.png?ixlib=rb-4.0.2&amp;crop=faces&amp;w=1552&amp;h=873&amp;fit=crop&amp;v=1592675400&amp;auto=format&amp;frame=1&amp;q=92&amp;s=f47505da909a374642906e6d418474e7&#39;},
     &#39;name&#39;: &#39;Paint Rogue&#39;,
     &#39;blurb&#39;: &#39;Roguelike | Platformer | Shooter&#39;,
     &#39;goal&#39;: 5000,
     &#39;pledged&#39;: 5268.22,
     &#39;state&#39;: &#39;successful&#39;,
     &#39;slug&#39;: &#39;paint-rogue&#39;,
     &#39;disable_communication&#39;: False,
     &#39;country&#39;: &#39;AU&#39;,
     &#39;country_displayable_name&#39;: &#39;Australia&#39;,
     &#39;currency&#39;: &#39;AUD&#39;,
     &#39;currency_symbol&#39;: &#39;$&#39;,
     &#39;currency_trailing_code&#39;: True,
     &#39;deadline&#39;: 1594247312,
     &#39;state_changed_at&#39;: 1594247312,
     &#39;created_at&#39;: 1591152439,
     &#39;launched_at&#39;: 1591655312,
     &#39;staff_pick&#39;: False,
     &#39;is_starrable&#39;: False,
     &#39;backers_count&#39;: 42,
     &#39;static_usd_rate&#39;: 0.69681992,
     &#39;usd_pledged&#39;: &#39;3671.0006389424&#39;,
     &#39;converted_pledged_amount&#39;: 3657,
     &#39;fx_rate&#39;: 0.7200616400000001,
     &#39;usd_exchange_rate&#39;: 0.69423473,
     &#39;current_currency&#39;: &#39;USD&#39;,
     &#39;usd_type&#39;: &#39;international&#39;,
     &#39;creator&#39;: {&#39;id&#39;: 1018782761,
      &#39;name&#39;: &#39;Andrew Von Stieglitz&#39;,
      &#39;is_registered&#39;: None,
      &#39;is_email_verified&#39;: None,
      &#39;chosen_currency&#39;: None,
      &#39;is_superbacker&#39;: None,
      &#39;avatar&#39;: {&#39;thumb&#39;: &#39;https://ksr-ugc.imgix.net/assets/024/628/691/39e3fdc8db723302f544f7161e32c4b7_original.png?ixlib=rb-4.0.2&amp;w=40&amp;h=40&amp;fit=crop&amp;v=1554207776&amp;auto=format&amp;frame=1&amp;q=92&amp;s=bf4ce960e83b57310b93c40dda68e213&#39;,
       &#39;small&#39;: &#39;https://ksr-ugc.imgix.net/assets/024/628/691/39e3fdc8db723302f544f7161e32c4b7_original.png?ixlib=rb-4.0.2&amp;w=80&amp;h=80&amp;fit=crop&amp;v=1554207776&amp;auto=format&amp;frame=1&amp;q=92&amp;s=a862ab30490c90cd08186f448884142d&#39;,
       &#39;medium&#39;: &#39;https://ksr-ugc.imgix.net/assets/024/628/691/39e3fdc8db723302f544f7161e32c4b7_original.png?ixlib=rb-4.0.2&amp;w=160&amp;h=160&amp;fit=crop&amp;v=1554207776&amp;auto=format&amp;frame=1&amp;q=92&amp;s=38923ac11699d68a7aae93ce126b97b6&#39;},
      &#39;urls&#39;: {&#39;web&#39;: {&#39;user&#39;: &#39;https://www.kickstarter.com/profile/1018782761&#39;},
       &#39;api&#39;: {&#39;user&#39;: &#39;https://api.kickstarter.com/v1/users/1018782761?signature=1654832212.14f9df54b2643f080ad98cacb07314f94757d9c1&#39;}}},
     &#39;location&#39;: {&#39;id&#39;: 1105779,
      &#39;name&#39;: &#39;Sydney&#39;,
      &#39;slug&#39;: &#39;sydney-au&#39;,
      &#39;short_name&#39;: &#39;Sydney, AU&#39;,
      &#39;displayable_name&#39;: &#39;Sydney, AU&#39;,
      &#39;localized_name&#39;: &#39;Sydney&#39;,
      &#39;country&#39;: &#39;AU&#39;,
      &#39;state&#39;: &#39;NSW&#39;,
      &#39;type&#39;: &#39;Town&#39;,
      &#39;is_root&#39;: False,
      &#39;expanded_country&#39;: &#39;Australia&#39;,
      &#39;urls&#39;: {&#39;web&#39;: {&#39;discover&#39;: &#39;https://www.kickstarter.com/discover/places/sydney-au&#39;,
        &#39;location&#39;: &#39;https://www.kickstarter.com/locations/sydney-au&#39;},
       &#39;api&#39;: {&#39;nearby_projects&#39;: &#39;https://api.kickstarter.com/v1/discover?signature=1654814982.2fcf49a7b611d4414d14b1dbe41ac53623192e6a&amp;woe_id=1105779&#39;}}},
     &#39;category&#39;: {&#39;id&#39;: 35,
      &#39;name&#39;: &#39;Video Games&#39;,
      &#39;analytics_name&#39;: &#39;Video Games&#39;,
      &#39;slug&#39;: &#39;games/video games&#39;,
      &#39;position&#39;: 7,
      &#39;parent_id&#39;: 12,
      &#39;parent_name&#39;: &#39;Games&#39;,
      &#39;color&#39;: 51627,
      &#39;urls&#39;: {&#39;web&#39;: {&#39;discover&#39;: &#39;http://www.kickstarter.com/discover/categories/games/video%20games&#39;}}},
     &#39;profile&#39;: {&#39;id&#39;: 4007060,
      &#39;project_id&#39;: 4007060,
      &#39;state&#39;: &#39;active&#39;,
      &#39;state_changed_at&#39;: 1594267960,
      &#39;name&#39;: &#39;Paint Rogue&#39;,
      &#39;blurb&#39;: &#39;Roguelike | Platformer | Shooter&#39;,
      &#39;background_color&#39;: &#39;&#39;,
      &#39;text_color&#39;: &#39;ffffff&#39;,
      &#39;link_background_color&#39;: &#39;&#39;,
      &#39;link_text_color&#39;: &#39;&#39;,
      &#39;link_text&#39;: &#39;Follow along!&#39;,
      &#39;link_url&#39;: &#39;https://www.kickstarter.com/projects/1018782761/paint-rogue/&#39;,
      &#39;show_feature_image&#39;: True,
      &#39;background_image_opacity&#39;: 0.5700000000000001,
      &#39;background_image_attributes&#39;: {&#39;id&#39;: 29758105,
       &#39;image_urls&#39;: {&#39;default&#39;: &#39;https://ksr-ugc.imgix.net/assets/029/758/105/971e42c0e19ca75fbae0943aa874c3c2_original.png?ixlib=rb-4.0.2&amp;w=1600&amp;fit=max&amp;v=1594267934&amp;auto=format&amp;frame=1&amp;q=92&amp;s=b91907c9e125e206a11a1bcef322c142&#39;,
        &#39;baseball_card&#39;: &#39;https://ksr-ugc.imgix.net/assets/029/758/105/971e42c0e19ca75fbae0943aa874c3c2_original.png?ixlib=rb-4.0.2&amp;w=460&amp;fit=max&amp;v=1594267934&amp;auto=format&amp;frame=1&amp;q=92&amp;s=e7af2286d1f74a51672fbb6060ad43c8&#39;}},
      &#39;should_show_feature_image_section&#39;: False,
      &#39;feature_image_attributes&#39;: {&#39;image_urls&#39;: {&#39;default&#39;: &#39;https://ksr-ugc.imgix.net/assets/029/542/393/098b025d0c25cc15e5b5f673b9ec992a_original.png?ixlib=rb-4.0.2&amp;crop=faces&amp;w=1552&amp;h=873&amp;fit=crop&amp;v=1592675400&amp;auto=format&amp;frame=1&amp;q=92&amp;s=f47505da909a374642906e6d418474e7&#39;,
        &#39;baseball_card&#39;: &#39;https://ksr-ugc.imgix.net/assets/029/542/393/098b025d0c25cc15e5b5f673b9ec992a_original.png?ixlib=rb-4.0.2&amp;crop=faces&amp;w=560&amp;h=315&amp;fit=crop&amp;v=1592675400&amp;auto=format&amp;frame=1&amp;q=92&amp;s=26209d432871ad2e9cca642527c291d9&#39;}}},
     &#39;spotlight&#39;: True,
     &#39;urls&#39;: {&#39;web&#39;: {&#39;project&#39;: &#39;https://www.kickstarter.com/projects/1018782761/paint-rogue?ref=discovery_category_newest&#39;,
       &#39;rewards&#39;: &#39;https://www.kickstarter.com/projects/1018782761/paint-rogue/rewards&#39;}},
     &#39;source_url&#39;: &#39;https://www.kickstarter.com/discover/categories/games/video%20games&#39;}
</code></pre></div><p><br><br></p>
<h2 id="字段">字段</h2>
<p>以第一条为例，查看每条众筹项目数据中的字段，</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;data&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
</code></pre></div><p>Run，运行结果#为后期加入的字段解释</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">    dict_keys([
    &#39;id&#39;, &#39;photo&#39;,  #id、图片链接
    &#39;name&#39;, &#39;blurb&#39;,  #项目名
    &#39;goal&#39;,   #项目筹资目标金额
    &#39;pledged&#39;, 
    &#39;state&#39;,  #项目状态
    &#39;slug&#39;,  
    &#39;disable_communication&#39;, 
    &#39;country&#39;, &#39;country_displayable_name&#39;,   #国家
    &#39;currency&#39;, &#39;currency_symbol&#39;, &#39;currency_trailing_code&#39;,  #货币
    &#39;deadline&#39;, &#39;state_changed_at&#39;,  #项目筹资截止时间(时间戳格式)
    &#39;created_at&#39;,  #项目创建时间(时间戳格式)
    &#39;launched_at&#39;,  #项目上架时间(时间戳格式)
    &#39;staff_pick&#39;, &#39;is_starrable&#39;, 
    &#39;backers_count&#39;,  #资助人数
    &#39;static_usd_rate&#39;, &#39;usd_pledged&#39;, &#39;converted_pledged_amount&#39;, &#39;fx_rate&#39;, &#39;usd_exchange_rate&#39;, &#39;current_currency&#39;, &#39;usd_type&#39;, 
    &#39;creator&#39;,  #项目发起人信息
    &#39;location&#39;,  #地址
    &#39;category&#39;,  #项目所属类目信息
    &#39;profile&#39;,  #项目基本信息
    &#39;spotlight&#39;, 
    &#39;urls&#39;,  #项目链接
    &#39;source_url&#39;])
</code></pre></div><br>
<p>以第一条数据为例，依次查看这几个字段的信息</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#众筹项目具名</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;项目名&#39;</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;data&#39;</span><span class="p">][</span><span class="s1">&#39;name&#39;</span><span class="p">],</span> <span class="n">end</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\n\n</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;项目链接</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;data&#39;</span><span class="p">][</span><span class="s1">&#39;urls&#39;</span><span class="p">],</span> <span class="n">end</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\n\n</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="c1">#众筹项目的目标总金额</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;目标总金额: </span><span class="si">{goal}{currency}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">goal</span><span class="o">=</span><span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;data&#39;</span><span class="p">][</span><span class="s1">&#39;goal&#39;</span><span class="p">],</span> 
                                          <span class="n">currency</span><span class="o">=</span><span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;data&#39;</span><span class="p">][</span><span class="s1">&#39;currency&#39;</span><span class="p">]))</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">    项目名 Paint Rogue
    
    项目链接
     {&#39;web&#39;: {&#39;project&#39;: &#39;https://www.kickstarter.com/projects/1018782761/paint-rogue?ref=discovery_category_newest&#39;, &#39;rewards&#39;: &#39;https://www.kickstarter.com/projects/1018782761/paint-rogue/rewards&#39;}}
    
    目标总金额: 5000AUD
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#众筹项目发起人信息</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;项目发起人信息</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;data&#39;</span><span class="p">][</span><span class="s1">&#39;creator&#39;</span><span class="p">],</span> <span class="n">end</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\n\n</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;项目基本信息</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;data&#39;</span><span class="p">][</span><span class="s1">&#39;profile&#39;</span><span class="p">],</span> <span class="n">end</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\n\n</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="c1">#众筹项目坐标</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;地址: &#39;</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;data&#39;</span><span class="p">][</span><span class="s1">&#39;location&#39;</span><span class="p">],</span> <span class="n">end</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\n\n</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="c1">#众筹项目货币</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;货币:&#39;</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;data&#39;</span><span class="p">][</span><span class="s1">&#39;currency&#39;</span><span class="p">],</span> <span class="n">end</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\n\n</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="c1">#众筹项目所在国家</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;所在国家: &#39;</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;data&#39;</span><span class="p">][</span><span class="s1">&#39;country_displayable_name&#39;</span><span class="p">],</span> <span class="n">end</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\n\n</span><span class="s1">&#39;</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">    项目发起人信息
     {&#39;id&#39;: 1018782761, &#39;name&#39;: &#39;Andrew Von Stieglitz&#39;, &#39;is_registered&#39;: None, &#39;is_email_verified&#39;: None, &#39;chosen_currency&#39;: None, &#39;is_superbacker&#39;: None, &#39;avatar&#39;: {&#39;thumb&#39;: &#39;https://ksr-ugc.imgix.net/assets/024/628/691/39e3fdc8db723302f544f7161e32c4b7_original.png?ixlib=rb-4.0.2&amp;w=40&amp;h=40&amp;fit=crop&amp;v=1554207776&amp;auto=format&amp;frame=1&amp;q=92&amp;s=bf4ce960e83b57310b93c40dda68e213&#39;, &#39;small&#39;: &#39;https://ksr-ugc.imgix.net/assets/024/628/691/39e3fdc8db723302f544f7161e32c4b7_original.png?ixlib=rb-4.0.2&amp;w=80&amp;h=80&amp;fit=crop&amp;v=1554207776&amp;auto=format&amp;frame=1&amp;q=92&amp;s=a862ab30490c90cd08186f448884142d&#39;, &#39;medium&#39;: &#39;https://ksr-ugc.imgix.net/assets/024/628/691/39e3fdc8db723302f544f7161e32c4b7_original.png?ixlib=rb-4.0.2&amp;w=160&amp;h=160&amp;fit=crop&amp;v=1554207776&amp;auto=format&amp;frame=1&amp;q=92&amp;s=38923ac11699d68a7aae93ce126b97b6&#39;}, &#39;urls&#39;: {&#39;web&#39;: {&#39;user&#39;: &#39;https://www.kickstarter.com/profile/1018782761&#39;}, &#39;api&#39;: {&#39;user&#39;: &#39;https://api.kickstarter.com/v1/users/1018782761?signature=1654832212.14f9df54b2643f080ad98cacb07314f94757d9c1&#39;}}}
    
    项目基本信息
     {&#39;id&#39;: 4007060, &#39;project_id&#39;: 4007060, &#39;state&#39;: &#39;active&#39;, &#39;state_changed_at&#39;: 1594267960, &#39;name&#39;: &#39;Paint Rogue&#39;, &#39;blurb&#39;: &#39;Roguelike | Platformer | Shooter&#39;, &#39;background_color&#39;: &#39;&#39;, &#39;text_color&#39;: &#39;ffffff&#39;, &#39;link_background_color&#39;: &#39;&#39;, &#39;link_text_color&#39;: &#39;&#39;, &#39;link_text&#39;: &#39;Follow along!&#39;, &#39;link_url&#39;: &#39;https://www.kickstarter.com/projects/1018782761/paint-rogue/&#39;, &#39;show_feature_image&#39;: True, &#39;background_image_opacity&#39;: 0.5700000000000001, &#39;background_image_attributes&#39;: {&#39;id&#39;: 29758105, &#39;image_urls&#39;: {&#39;default&#39;: &#39;https://ksr-ugc.imgix.net/assets/029/758/105/971e42c0e19ca75fbae0943aa874c3c2_original.png?ixlib=rb-4.0.2&amp;w=1600&amp;fit=max&amp;v=1594267934&amp;auto=format&amp;frame=1&amp;q=92&amp;s=b91907c9e125e206a11a1bcef322c142&#39;, &#39;baseball_card&#39;: &#39;https://ksr-ugc.imgix.net/assets/029/758/105/971e42c0e19ca75fbae0943aa874c3c2_original.png?ixlib=rb-4.0.2&amp;w=460&amp;fit=max&amp;v=1594267934&amp;auto=format&amp;frame=1&amp;q=92&amp;s=e7af2286d1f74a51672fbb6060ad43c8&#39;}}, &#39;should_show_feature_image_section&#39;: False, &#39;feature_image_attributes&#39;: {&#39;image_urls&#39;: {&#39;default&#39;: &#39;https://ksr-ugc.imgix.net/assets/029/542/393/098b025d0c25cc15e5b5f673b9ec992a_original.png?ixlib=rb-4.0.2&amp;crop=faces&amp;w=1552&amp;h=873&amp;fit=crop&amp;v=1592675400&amp;auto=format&amp;frame=1&amp;q=92&amp;s=f47505da909a374642906e6d418474e7&#39;, &#39;baseball_card&#39;: &#39;https://ksr-ugc.imgix.net/assets/029/542/393/098b025d0c25cc15e5b5f673b9ec992a_original.png?ixlib=rb-4.0.2&amp;crop=faces&amp;w=560&amp;h=315&amp;fit=crop&amp;v=1592675400&amp;auto=format&amp;frame=1&amp;q=92&amp;s=26209d432871ad2e9cca642527c291d9&#39;}}}
    
    地址:  {&#39;id&#39;: 1105779, &#39;name&#39;: &#39;Sydney&#39;, &#39;slug&#39;: &#39;sydney-au&#39;, &#39;short_name&#39;: &#39;Sydney, AU&#39;, &#39;displayable_name&#39;: &#39;Sydney, AU&#39;, &#39;localized_name&#39;: &#39;Sydney&#39;, &#39;country&#39;: &#39;AU&#39;, &#39;state&#39;: &#39;NSW&#39;, &#39;type&#39;: &#39;Town&#39;, &#39;is_root&#39;: False, &#39;expanded_country&#39;: &#39;Australia&#39;, &#39;urls&#39;: {&#39;web&#39;: {&#39;discover&#39;: &#39;https://www.kickstarter.com/discover/places/sydney-au&#39;, &#39;location&#39;: &#39;https://www.kickstarter.com/locations/sydney-au&#39;}, &#39;api&#39;: {&#39;nearby_projects&#39;: &#39;https://api.kickstarter.com/v1/discover?signature=1654814982.2fcf49a7b611d4414d14b1dbe41ac53623192e6a&amp;woe_id=1105779&#39;}}}
    
    货币: AUD
    
    所在国家:  Australia
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#众筹项目创建时间</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;项目创建时间: &#39;</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;data&#39;</span><span class="p">][</span><span class="s1">&#39;created_at&#39;</span><span class="p">])</span>

<span class="c1">#众筹项目上架时间</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;项目上架时间: &#39;</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;data&#39;</span><span class="p">][</span><span class="s1">&#39;launched_at&#39;</span><span class="p">])</span>

<span class="c1">#众筹项目截止时间</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;项目截止时间: &#39;</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;data&#39;</span><span class="p">][</span><span class="s1">&#39;deadline&#39;</span><span class="p">])</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">    项目创建时间:  1591152439
    项目上架时间:  1591655312
    项目截止时间:  1594247312
</code></pre></div><br>
<h3 id="时间戳转日期">时间戳转日期</h3>
<p>1591152439是时间戳，以某时间点距1970之间的秒数作为时间。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#时间戳转日期</span>

<span class="kn">import</span> <span class="nn">datetime</span>

<span class="k">def</span> <span class="nf">timestamp2str</span><span class="p">(</span><span class="n">timestamp</span><span class="p">):</span>
    <span class="n">d</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">fromtimestamp</span><span class="p">(</span><span class="n">timestamp</span><span class="p">)</span>
    <span class="k">return</span> <span class="s1">&#39;</span><span class="si">{year}</span><span class="s1">-</span><span class="si">{month}</span><span class="s1">-</span><span class="si">{day}</span><span class="s1"> </span><span class="si">{hour}</span><span class="s1">:</span><span class="si">{minute}</span><span class="s1">:</span><span class="si">{second}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">year</span><span class="o">=</span><span class="n">d</span><span class="o">.</span><span class="n">year</span><span class="p">,</span>
                                                                 <span class="n">month</span><span class="o">=</span><span class="n">d</span><span class="o">.</span><span class="n">month</span><span class="p">,</span>
                                                                 <span class="n">day</span><span class="o">=</span><span class="n">d</span><span class="o">.</span><span class="n">day</span><span class="p">,</span>
                                                                 <span class="n">hour</span><span class="o">=</span><span class="n">d</span><span class="o">.</span><span class="n">hour</span><span class="p">,</span>
                                                                 <span class="n">minute</span><span class="o">=</span><span class="n">d</span><span class="o">.</span><span class="n">minute</span><span class="p">,</span>
                                                                 <span class="n">second</span><span class="o">=</span><span class="n">d</span><span class="o">.</span><span class="n">second</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;创建时间&#39;</span><span class="p">,</span> <span class="n">timestamp2str</span><span class="p">(</span><span class="mi">1591152439</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;上架时间&#39;</span><span class="p">,</span> <span class="n">timestamp2str</span><span class="p">(</span><span class="mi">1591655312</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;截止时间&#39;</span><span class="p">,</span> <span class="n">timestamp2str</span><span class="p">(</span><span class="mi">1594247312</span><span class="p">))</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">创建时间 2020-6-3 10:47:19
上架时间 2020-6-9 6:28:32
截止时间 2020-7-9 6:28:32
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#众筹项目产品 所属类目信息</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;众筹类目:&#39;</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;data&#39;</span><span class="p">][</span><span class="s1">&#39;category&#39;</span><span class="p">],</span> <span class="n">end</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\n\n</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="c1"># 众筹类目根链接</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;众筹类目根链接:&#39;</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;data&#39;</span><span class="p">][</span><span class="s1">&#39;source_url&#39;</span><span class="p">])</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">    众筹类目: {&#39;id&#39;: 35, &#39;name&#39;: &#39;Video Games&#39;, &#39;analytics_name&#39;: &#39;Video Games&#39;, &#39;slug&#39;: &#39;games/video games&#39;, &#39;position&#39;: 7, &#39;parent_id&#39;: 12, &#39;parent_name&#39;: &#39;Games&#39;, &#39;color&#39;: 51627, &#39;urls&#39;: {&#39;web&#39;: {&#39;discover&#39;: &#39;http://www.kickstarter.com/discover/categories/games/video%20games&#39;}}}
    
    众筹类目根链接: https://www.kickstarter.com/discover/categories/games/video%20games
</code></pre></div><p><br><br></p>
<h2 id="数据获取方法">数据获取方法</h2>
<p>转发分享至朋友圈，集赞50+, 加微信 372335839 ， 备注「姓名-学校-专业-Kickstarter」</p>
<p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>JM2022综述 | 黄金领域: 为营销研究(新洞察)采集网络数据</title>
      <link>https://hidadeng.github.io/blog/2022-12-03-scraping-web-data-for-marketing-insights/</link>
      <pubDate>Sat, 03 Dec 2022 00:00:00 +0000</pubDate>
      
      <guid>/blog/2022-12-03-scraping-web-data-for-marketing-insights/</guid>
      <description>Journal of Marketing 2022年一篇关于营销领域网络爬虫的文献综述</description>
      <content:encoded><![CDATA[<p>Boegershausen, Johannes, Hannes Datta, Abhishek Borah, and Andrew Stephen. &ldquo;Fields of gold: Scraping web data for marketing insights.&rdquo; <em>Journal of Marketing</em> (2022).</p>
<p>本文是JM中少有的技术流综述文，阅读起来晦涩难懂，我们就大概知道怎么回事， 查看有没有自己感兴趣的研究(方法)即可。该文作者为该综述专门开发了一个 web-scraping.org 的网站,截图如下</p>
<p><img loading="lazy" src="img/01-web-scraping.png" alt=""  />

<img loading="lazy" src="img/02-web-scraping.png" alt=""  />
</p>

<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
  <iframe src="https://www.youtube.com/embed/KiyFyLEkqNk" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video"></iframe>
</div>

<br>
<h2 id="摘要">摘要</h2>
<p>市场营销学者越来越多使用网络爬虫和API接口，从互联网收集数据。尽管网络数据得到广泛使用，但很少有学者关注收集过程中面临的各种挑战。<strong>研究人员如何确保采集的数据集是有效的？</strong> 虽然现有资源强调提取网络数据的技术细节，<strong>但作者提出了一种新的方法框架，重点是提高其有效性</strong>。特别是，该框架强调解决有效性问题， 需要在数据采集的三个阶段(<strong>选择数据源、设计数据收集和提取数据</strong>)联合考虑技术和法律/伦理问题。作者进一步审查了营销Top5期刊上300 篇使用网络数据的论文，并总结提出了如何使用网络数据促进营销研究。本文最后指出了未来研究的方向，高价值的网络数据源和新方法。</p>
<p><strong>Keywords：</strong></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">- web scraping
- application programming interface, API
- crawling
- validity
- user-generated content
- social media
big data
</code></pre></div><br>
<h2 id="一网络数据的魅力">一、网络数据的魅力</h2>
<p>社会和商业生活的加速数字化创造了数量空前的消费者和企业行为数字痕迹。 每分钟，全球用户在 Google 上进行 570 万次搜索，进行 600 万次商业交易，并在 Instagram 上分享6.5万张照片（Statista 2021）。 由此产生的网络数据——规模庞大、形式多样，而且通常可以在互联网上公开访问——对于那些想要量化消费、深入了解企业行为并跟踪难以或昂贵地观察社会活动的营销学者来说，这是一个潜在的金矿 . 网络数据对营销研究的重要性反映在越来越多的有影响力的出版物中，涵盖消费者文化理论、消费者心理学、实证建模和营销策略等。</p>
<p><img loading="lazy" src="img/fig-1-increased-use-of-web-data-in-marketing.png" alt=""  />
</p>
<p>整理了 <strong>营销领域 top 5 期刊( JM、JMR、JCR、JCP、MS) 的 313 篇论文</strong> ，经过整理绘制图-1（Figure1）， 使用网络数据进行研究的量呈现快速上涨的趋势。使用网络数据的论文占比，从2010年的4%提升到2020年的15%。 者313篇论文，数据的获取方式统计</p>
<ul>
<li>**59% 的论文使用了 <strong>网络爬虫</strong> 采集数据</li>
<li>12% 的论文使用API收集数据</li>
<li>9% 的论文同时使用了网络爬虫和API</li>
<li>20% 使用人工从网站手动复制粘贴数据</li>
</ul>
<p><strong>使用 网络数据 的论文，平均被引用次数 7.55， 远高于 非网络数据 的 3.90</strong>。</p>
<br>
<p>使用网络数据做新研究，大致有4种实现路径</p>
<ol>
<li><strong>研究新现象，新场景</strong>
<ul>
<li>网络世界产生的不同于现实世界的情景，可以研究新现象</li>
</ul>
</li>
<li><strong>繁荣生态价值</strong>
<ul>
<li>比如，对亚马逊评论数据进行研究，研究发现可以帮助亚马逊平台进行改善。</li>
</ul>
</li>
<li><strong>促进方法论进步</strong>
<ul>
<li>文本、图片、音频、视频等</li>
</ul>
</li>
<li><strong>提高测量效果(快、准、好、全)</strong>
<ul>
<li>借助一些API，可以对已有的数据集增加新的信息量。</li>
<li>例如，日期数据，结合HolidayAPI，可以查看日期的节假日信息</li>
<li>给定日期和IP地址，使用Weather Underground可以查看天气信息</li>
</ul>
</li>
</ol>
<p><img loading="lazy" src="img/table-1-four-pathway-of-knowledge-creation-using-web-data.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="二数据采集的方法框架">二、数据采集的方法框架</h2>
<p>在使用 **网络爬虫 和 API ** 自动收集网络数据时，研究人员通常会在 **研究有效性、技术可行性和法律/伦理风险 **1 三者间权衡利弊得失，研究人员如何解决这些权衡，通过增强或破坏 <strong>统计结论有效性、内部有效性、结构有效性和外部有效性</strong> 来塑造研究结果的可信度（Shadish、Cook 和 Campbell 2002）。</p>
<p><img loading="lazy" src="img/fig-2-methodological-framework-for-collecting-web-data.png" alt=""  />
</p>
<p>本文开发了一个方法框架，为使用 网络爬虫 和 API 自动收集网络数据提供指导。图 2（Figure 2） 涵盖三个关键阶段</p>
<ul>
<li><strong>数据源选择</strong></li>
<li><strong>设计方案</strong>
<ul>
<li>从网站中抽取哪些信息</li>
<li>采集频率，即 每天(周/月)重复运行一次爬虫，得到面板数据</li>
</ul>
</li>
<li><strong>执行数据采集</strong>
<ul>
<li>如何改善爬虫运行效率</li>
<li>如何处理原始信息，完整的保存为原始格式html、json，还是只抽取存储当前想要的字段</li>
</ul>
</li>
</ul>
<p>研究人员通常从一组广泛的潜在数据源开始，并根据三个关键考虑因素（有效性、技术可行性和法律/道德风险）剔除其中一些数据源。这三个考虑因素出现在倒金字塔的角落，底部的有效性强调其重要性。鉴于在收集最终数据集之前难以预测其确切特征，研究人员在设计、原型化和完善数据收集时经常重新考虑这些因素。未能解决技术或法律/伦理问题可能意味着网络数据无法有意义地告知研究问题。</p>
<h3 id="21-数据源面临的挑战解决办法">2.1 数据源面临的挑战(解决办法)</h3>
<ol>
<li>探索潜在网络数据源
<ul>
<li>由于网络资源在质量、稳定性和可检索性方面存在巨大差异，研究人员可能倾向于只考虑主要或熟悉的平台。 对数据世界的彻底探索允许令人信服的理论检验和识别可能难以以其他方式注意到的新颖的、新兴的营销现象。</li>
</ul>
</li>
<li>考虑网络爬虫的替代方案
<ul>
<li>由于网络抓取是最流行的网络数据提取方法，研究人员可能会忽视其他提取数据的方法。 API 提供了一种记录和授权的方式来获取许多来源的 Web 数据。 一些来源还提供现成的数据集。 使用此类替代方案可以节省时间并最大限度地减少法律风险。</li>
</ul>
</li>
<li>将数据与场景结合对应起来
<ul>
<li>Web 数据通常没有大量的文档。 尽早识别潜在相关的背景信息对于研究的相关性和有效性至关重要。
<img loading="lazy" src="img/table-2-chanllenges-and-solutions-in-selecting-web-data-sources.png" alt=""  />
</li>
</ul>
</li>
</ol>
<br>
<h3 id="22-设计数据采集方案">2.2 设计数据采集方案</h3>
<ol>
<li>从页面抽取什么信息，从有效性、合法、技术可行性 三个方面论证。</li>
<li>如何进行数据抽样？</li>
<li>以什么频率(每天、周、月)进行数据采集</li>
</ol>
<p><img loading="lazy" src="img/table-3-1-chanllenges-and-solutions-in-selecting-web-data-sources.png" alt=""  />

<img loading="lazy" src="img/table-3-2-chanllenges-and-solutions-in-selecting-web-data-sources.png" alt=""  />
</p>
<br>
<h3 id="23-执行数据采集">2.3 执行数据采集</h3>
<ol>
<li>如何改善爬虫运行效率</li>
<li>如何监控数据质量</li>
<li>整理数据文档(记录)
<img loading="lazy" src="img/table-4-chanllenges-and-solutions-in-selecting-web-data-sources.png" alt=""  />
</li>
</ol>
<br>
<h2 id="部分参考文献">部分参考文献</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">[1]Allard, Thomas, Lea H. Dunn, and Katherine White. &#34;Negative reviews, positive impact: Consumer empathetic responding to unfair word of mouth.&#34; Journal of Marketing 84, no. 4 (2020): 86-108.
[2]Gao, Weihe, Li Ji, Yong Liu, and Qi Sun. &#34;Branding cultural products in international markets: a study of hollywood movies in China.&#34; Journal of Marketing 84, no. 3 (2020): 86-105.
[3]Reich, Taly, and Sam J. Maglio. &#34;Featuring mistakes: The persuasive impact of purchase mistakes in online reviews.&#34; Journal of Marketing 84, no. 1 (2020): 52-65.
[4]Lee, Jeffrey K., and Ann Kronrod. &#34;The strength of weak-tie consensus language.&#34; Journal of Marketing Research 57, no. 2 (2020): 353-374.
[5]Matz, Sandra C., Cristina Segalin, David Stillwell, Sandrine R. Müller, and Maarten W. Bos. &#34;Predicting the personal appeal of marketing images using computational methods.&#34; Journal of Consumer Psychology 29, no. 3 (2019): 370-390.
[6]Dai, Hengchen, and Dennis J. Zhang. &#34;Prosocial goal pursuit in crowdfunding: Evidence from kickstarter.&#34; Journal of Marketing Research 56, no. 3 (2019): 498-517.
[7]Luffarelli, Jonathan, Mudra Mukesh, and Ammara Mahmood. &#34;Let the logo do the talking: The influence of logo descriptiveness on brand equity.&#34; Journal of Marketing Research 56, no. 5 (2019): 862-878.
[8]Bond, Samuel D., Stephen X. He, and Wen Wen. &#34;Speaking for “free”: Word of mouth in free-and paid-product settings.&#34; Journal of Marketing Research 56, no. 2 (2019): 276-290.
[9]Han, Kyuhong, Jihye Jung, Vikas Mittal, Jinyong Daniel Zyung, and Hajo Adam. &#34;Political identity and financial risk taking: Insights from social dominance orientation.&#34; Journal of Marketing Research 56, no. 4 (2019): 581-601.
[10]Netzer, Oded, Alain Lemaire, and Michal Herzenstein. &#34;When words sweat: Identifying signals for loan default in the text of loan applications.&#34; Journal of Marketing Research 56, no. 6 (2019): 960-980.
[11]Toubia, Olivier, Garud Iyengar, Renée Bunnell, and Alain Lemaire. &#34;Extracting features of entertainment products: A guided latent dirichlet allocation approach informed by the psychology of media consumption.&#34; Journal of Marketing Research 56, no. 1 (2019): 18-36.
[12]Van Laer, Tom, Jennifer Edson Escalas, Stephan Ludwig, and Ellis A. Van Den Hende. &#34;What happens in Vegas stays on TripAdvisor? A theory and technique to understand narrativity in consumer reviews.&#34; Journal of Consumer Research 46, no. 2 (2019): 267-285.
[13]Zhong, Ning, and David A. Schweidel. &#34;Capturing changes in social media content: A multiple latent changepoint topic model.&#34; Marketing Science 39, no. 4 (2020): 827-846.
[14]Colicev, Anatoli, Ashwin Malshe, Koen Pauwels, and Peter O&#39;Connor. &#34;Improving consumer mindset metrics and shareholder value through social media: The different roles of owned and earned media.&#34; Journal of Marketing 82, no. 1 (2018): 37-56.
[15]Liu, Xuan, Savannah Wei Shi, Thales Teixeira, and Michel Wedel. &#34;Video content marketing: The making of clips.&#34; Journal of Marketing 82, no. 4 (2018): 86-101.
[16]Liu, Jia, and Olivier Toubia. &#34;A semantic approach for estimating consumer content preferences from online search queries.&#34; Marketing Science 37, no. 6 (2018): 930-952.
[17]Nam, Hyoryung, Yogesh V. Joshi, and P. K. Kannan. &#34;Harvesting brand information from social tags.&#34; Journal of Marketing 81, no. 4 (2017): 88-108.
[18]Packard, Grant, and Jonah Berger. &#34;How language shapes word of mouth&#39;s impact.&#34; Journal of Marketing Research 54, no. 4 (2017): 572-588.
</code></pre></div><br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>魔搭 | 中文AI模型开源社区</title>
      <link>https://hidadeng.github.io/blog/2022-11-09-chinese-modelscope-open-source/</link>
      <pubDate>Wed, 09 Nov 2022 00:00:00 +0000</pubDate>
      
      <guid>/blog/2022-11-09-chinese-modelscope-open-source/</guid>
      <description>ModelScope社区成立于2022 年6月，是一个模型开源社区及创新平台，由阿里巴巴达摩院，联合CCF开源发展委员会，共同作为项目发起方。社区联合国内AI领域合作伙伴与高校机构，致力于通过开放的社区合作，构建深度学习相关的模型开源，并开源相关模型服务创新技术，推动模型应用生态的繁荣发展。</description>
      <content:encoded><![CDATA[<h2 id="关于modelscope">关于ModelScope</h2>
<p>ModelScope社区成立于 2022 年 6 月，是一个模型开源社区及创新平台，由阿里巴巴达摩院，联合CCF开源发展委员会，共同作为项目发起方。</p>
<blockquote>
<p>社区联合国内AI领域合作伙伴与高校机构，致力于通过开放的社区合作，构建深度学习相关的模型开源，并开源相关模型服务创新技术，推动模型应用生态的繁荣发展。</p>
</blockquote>
<p>期待ModelScope会有不一样的表现。</p>
<p>与ModelScope类似的网站有</p>
<ul>
<li>国际 huggingface是较早将AI模型开源的网站，用户群体庞大，社区内有丰富的数据集、模型，文档详实。</li>
<li>国内 百度飞桨是国内AI模型开源较好的网站，用户群体较大，更新活跃，但是文档质量。。。</li>
</ul>
<p>目前ModelScope刚刚上线不久，模型和数据集都不怎么多</p>
<p><img loading="lazy" src="img/model_scope_homepage.png" alt=""  />
</p>
<br>
<h2 id="heading"></h2>
<h1 id="名词解释"><strong>名词解释</strong></h1>
<p>ModelScope平台是以模型为中心的模型开源社区，与模型的使用相关，您需要先了解如下概念。</p>
<table>
<thead>
<tr>
<th><strong>基础概念</strong></th>
<th><strong>定义</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>任务</td>
<td>任务（Task）指某一领域具体的应用，以用于完成特定场景的任务。例如图像分类、文本生成、语音识别等，您可根据任务的输入输出找到适合您的应用场景的任务类型，通过任务的筛选来查找您所需的模型。</td>
</tr>
<tr>
<td>模型</td>
<td>模型（Model）是指一个具体的模型实例，包括模型网络结构和相应参数。ModelScope平台提供丰富的模型信息供用户体验与使用。</td>
</tr>
<tr>
<td>模型库</td>
<td>模型库（Modelhub）是指对模型进行存储、版本管理和相关操作的模型服务，用户上传和共享的模型将存储至ModelScope的模型库中，同时用户也可在Model hub中创建属于自己的模型存储库，并沿用平台提供的模型库管理功能进行模型管理。</td>
</tr>
<tr>
<td>数据集</td>
<td>数据集（Dataset）是方便共享及访问的数据集合，可用于算法训练、测试、验证，通常以表格形式出现。按照模态可划分为文本、图像、音频、视频、多模态等。</td>
</tr>
<tr>
<td>数据集库</td>
<td>数据集库（Datasethub）用于集中管理数据，支持模型进行训练、预测等，使各类型数据具备易访问、易管理、易共享的特点。</td>
</tr>
<tr>
<td>ModelScope Library</td>
<td>ModelScope Library是ModelScope平台自研的一套Python Library框架，通过调用特定的方法，用户可以只写短短的几行代码，就可以完成模型的推理、训练和评估等任务，也可以在此基础上快速进行二次开发，实现自己的创新想法。</td>
</tr>
</tbody>
</table>
<br>
<h2 id="一模型探索">一、模型探索</h2>
<p>首先访问平台网址https://www.modelscope.cn/models， 您将看见平台上已有的所有公开模型，根据任务筛选或者关键词搜索可查找您感兴趣的模型。</p>
<p><img loading="lazy" src="img/1-model_explore.png" alt=""  />
</p>
<br>
<h2 id="二环境准备">二、环境准备</h2>
<h3 id="21-本地开发环境">2.1 本地开发环境</h3>
<p>如果您需要在本地运行模型，需要进行相应的环境安装准备，包括：</p>
<ul>
<li><strong>安装python环境</strong>。支持python3，不支持python2，建议3.7版本及以上。我们推荐您使用Anaconda进行安装。</li>
<li><strong>安装深度学习框架</strong>。ModelScope Library目前支持Tensorflow，Pytorch两大深度学习框架进行模型训练、推理。您可根据模型所需的框架选择适合的框架进行安装。</li>
<li><strong>安装ModelScope Library</strong>。我们提供两种安装方式，您可选择适合的方式进行安装。
<ul>
<li>pip安装。ModelScope提供了根据不同领域的安装包，您可根据对应的模型选择所需的安装包。</li>
<li>使用源码安装。</li>
<li>更完整的安装信息参考：环境安装指南。</li>
</ul>
</li>
</ul>
<h3 id="22-在线notebook">2.2 在线Notebook</h3>
<p>若您觉得本地安装较为复杂， ModelScope平台也提供在线的运行环境，您可直接在Notebook中运行，Notebook中提供官方镜像无需自主进行环境安装，更加方便快捷，推荐大家使用！</p>
<p>注意：该功能需要您登录后使用，新用户注册ModelScope账号并完成阿里云账号绑定后即可获得免费算力资源，详情请参阅免费额度说明 。</p>
<p><img loading="lazy" src="img/model_scode_free_online_notebook.png" alt=""  />
</p>
<p><img loading="lazy" src="img/model_scode_free_online_notebook-2.png" alt=""  />
</p>
<br>
<h2 id="三2分钟跑通模型推理">三、2分钟跑通模型推理</h2>
<p>若您准备好本地环境或者已经打开一个Notebook的预装环境实例，则根据下述代码可对该模型进行推理。 使用modelscope pipeline接口只需要两步，同样以上述中文分词模型（damo/nlp_structbert_word-segmentation_chinese-base）为例简单说明：</p>
<p>首先根据task实例化一个pipeline对象</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">modelscope.pipelines</span> <span class="kn">import</span> <span class="n">pipeline</span>
<span class="n">word_segmentation</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span><span class="s1">&#39;word-segmentation&#39;</span><span class="p">,</span><span class="n">model</span><span class="o">=</span><span class="s1">&#39;damo/nlp_structbert_word-segmentation_chinese-base&#39;</span><span class="p">)</span>
</code></pre></div><p>输入数据，拿到结果</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">input_str</span> <span class="o">=</span> <span class="s1">&#39;今天天气不错，适合出去游玩&#39;</span>
<span class="nb">print</span><span class="p">(</span><span class="n">word_segmentation</span><span class="p">(</span><span class="n">input_str</span><span class="p">))</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">{&#39;output&#39;: &#39;今天 天气 不错 ， 适合 出去 游玩&#39;}
</code></pre></div><br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>十万级 | 多领域因果事件对数据集对外开源</title>
      <link>https://hidadeng.github.io/blog/2022-11-07-chinese-casual-text-datasets/</link>
      <pubDate>Mon, 07 Nov 2022 00:00:00 +0000</pubDate>
      
      <guid>/blog/2022-11-07-chinese-casual-text-datasets/</guid>
      <description>description用于SEO优化</description>
      <content:encoded><![CDATA[<h2 id="作者">作者</h2>
<p>刘焕勇，NLP开源爱好者与践行者，主页：https://liuhuanyong.github.io。</p>
<p>就职于360人工智能研究院、曾就职于中国科学院软件研究所。</p>
<p>老刘说NLP，将定期发布语言资源、工程实践、技术总结等内容，欢迎关注。</p>
<br>
<p>开放文本中蕴含着大量的逻辑性知识，以刻画事物之间逻辑传导关系的逻辑类知识库是推动知识推理发展的重要基础。
因果抽取是一个十分有趣的话题，研发大规模逻辑推理知识库有助于支持实体或事件等传导驱动决策任务，而目前尚未有开源的因果事件对出现，为了弥补这一空缺，本文对外开源一个面向多领域的十万级因果事件对数据集，可以自行转成因果关系图谱，展开更多有趣实验，供大家一起参考。
地址：https://github.com/liuhuanyong/CausalDataset</p>
<h2 id="一因果抽取常用方法">一、因果抽取常用方法</h2>
<p>我们在《<strong>事件图谱技术：因果关系事件对抽取常用方法的解析与动手实践</strong>》中讲述了因果抽取的方法，从传统模式规则、语义分析、依存句法、序列标注四种方式进行实践，并配上实现项目进行讲解，这涵盖了当前因果事件抽取的常用方式。</p>
<p>地址： <a href="https://github.com/liuhuanyong/CausalityEventExtraction">https://github.com/liuhuanyong/CausalityEventExtraction</a></p>
<h3 id="11-基于模式匹配的因果事件对提取">1.1 基于模式匹配的因果事件对提取</h3>
<p>基于模式匹配的方式，是进行因果抽取的入门级以及兜底方式，充分利用好语言学知识，具有显式标记的因果关联词、因果表达句式进行归纳，并配以正则表达式实现，可以有效地提取出大量的因果事件对。</p>
<br>
<h3 id="12-基于语义角色的因果事件抽取">1.2 基于语义角色的因果事件抽取</h3>
<p>基于触发词模式匹配的方法无法捕捉因果事件之间的关联关系，因此可以借助依存句法分析以及语义角色标注的方式进行处理。</p>
<p>以因果关系触发词为核心动作，首先从语义角色方面找寻该触发词动作的实施对象和受事对象，将实施对象作为原因事件，将受事对象作为结果事件，并根据词性过滤事件；</p>
<br>
<h3 id="13-基于依存句法的因果事件抽取">1.3 基于依存句法的因果事件抽取</h3>
<p>由于自然语言处理的复杂性，LTP中未能对一些子句中的因果关系触发词进行语义角色标注，或者只标注了一部分，即A0和A1未同时被标注出来，因此利用依存句法分析来抽取此类情况下的因果事件对。</p>
<br> 
<h3 id="14-基于序列标注的因果抽取">1.4 基于序列标注的因果抽取</h3>
<p>针对基于规则的因果抽取模型中的不足，可以使用基于Bert微调的序列标注模型。在序列标签的设计上，模型的序列标签采用BIO标签体系，标签类型主要为cause、triger、effect。
为了能方便地根据标签结果进行因果三元组组合，在设计标签体系时也对单因果、多因果进行了区分，分别设置为multi-cause、multi-effect。</p>
<p><br><br></p>
<h2 id="二基于多领域文本数据集的因果事件对">二、基于多领域文本数据集的因果事件对</h2>
<p>为了得到多领域因果事件对，我们以清华大学开源的文本分类数据集THUnews，<strong>THUCNews是根据新浪新闻RSS订阅频道2005~2011年间的历史数据筛选过滤生成，包含74万篇新闻文档（2.19 GB），均为UTF-8纯文本格式</strong>。</p>
<p>其在原始新浪新闻分类体系的基础上，重新整合划分出14个候选分类类别：财经、彩票、房产、股票、家居、教育、科技、社会、时尚、时政、体育、星座、游戏、娱乐。满足了多领域性的需求。</p>
<p><strong>数据地址：http://thuctc.thunlp.org/#中文文本分类数据集THUCNews</strong></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">训练因果抽取识别模型，最终去重得到了100,688条因果关系对，通过对频次进行统计，可以过滤出质量较高的因果对，下面显示了格式为原因事件@结构事件\t出现频次格式下的数据样例。
投资风险巨大@本金全部亏损 248
用户友好界面@模式帮助用户选择场景 38
政策消息面和技术面所有信息@交易者预期变 37
磨砂表面处理@触感更佳 31
加上F2大光圈和丰富手动功能@机器推出受到消费者广泛关注 26
金属材质设计@整体造型更具品质感 25
商务机型中并常见@上下边框显得厚 23
顶盖采用工程塑料制成配@笔记本外壳防滑耐磨 19
取消传统曲面过度@iPhone4底部扬声器变得硕大 17
准专业机型GRDIGITALII和GX200电子水平仪功能引进@使用R10拍摄高楼山水 16
镜头位移减震功能以及闪光灯控制系统@低光照下拍摄照片时噪 14
像素触摸式液晶屏幕@操控方面人性化 14
采用直线条形式边框风格@整体看上去大气 14
像素摄像头镶嵌屏幕上方@视频聊天方便 14
</code></pre></div><br>
<h3 id="21-关于地震相关的因果事件对">2.1 关于“地震”相关的因果事件对</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">日本东北部海域发生里氏大地震@重大人员伤亡和财产损失 6
日本东北部海域发生里氏地震@重大人员伤亡和财产损失 5
印尼西爪哇省附近印度洋海域发生里氏地震@人死亡人受伤 4
智利中南部城市康塞普西翁附近发生里氏强烈地震@重大人员伤亡 3
智利发生里氏地震@重大人员伤亡和财产损失 3
东部凡省发生强烈地震@死亡人数 3
上周五地震中受损核反应堆发生爆炸@核工业相关公司股票 3
日本大地震@金融市场动 3
最近地震和海啸灾害中复苏@日元汇率下跌 3
日本东北部大地震@全球关注 2
汶川地震期间捐款数目@高度关注 2
</code></pre></div><br>
<h3 id="22-与贬值相关的因果事件对">2.2 与“贬值”相关的因果事件对</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">虚拟道具贬值@广范围用户付费意愿越来越低 3
流动性过剩加剧@贬值趋势 3
日本核泄露事件@外资产贬值 3
全球性经济复苏以及贬值流动性过剩@全球商品价格出现暴涨 3
朝鲜进行货币贬值@市场经济瘫痪 2
欧洲主权债务危机深化和亚洲国家货币贬值@日本有警惕金融资本市场动荡 2
游戏公司滥发虚拟物品@玩家虚拟物品贬值 2
住房价格贬值@全球经济下滑形势演变成 2
中长期内贬值@资金撤离资产 2
持续贬值和人民币升值预期@中国内地成为资金洼地 2
韩元贬值@进口商品价格上升 2
货币大体上呈贬值趋势@国际油价名义价格走高 2
朱广沪时期大面积召人@国家队贬值 1
</code></pre></div><br>
<h3 id="23-与恋爱相关的因果事件对">2.3 与“恋爱”相关的因果事件对</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">恋爱观婚姻观@观众极大兴趣 2
恋爱问题@学生意外伤害事 2
人相知相惜@恋爱温度始终保持合适系数 1
持人大爆钱包@恋爱故事 1
来美丽密令恋爱线人电影@陆毅闪耀大银幕上 1
李成儒和小演员侯角恋爱往事@媒体关注 1
歌曲转换过渡上显得流畅@听起来实在如男女恋爱中不伦恋 1
抓紧时间南京谈恋爱@台上台下哄笑 1
公司安排工作@没时间恋爱 1
强打精神去面对@恋爱没有兴趣 1
</code></pre></div><br>
<br>
<h2 id="总结">总结</h2>
<p>本文以清华大学开源的文本分类数据集THUnews，对外开源了一个面向多领域的十万级因果事件对数据集，并介绍了常用技术方法。当然，数据的质量也有不足之处，规模不大，可以加以改善。</p>
<br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>1.5G数据集 | 200万条Indiegogo众筹项目信息</title>
      <link>https://hidadeng.github.io/blog/2022-12-08-indiegogo-dataset/</link>
      <pubDate>Sun, 16 Oct 2022 00:00:00 +0000</pubDate>
      
      <guid>/blog/2022-12-08-indiegogo-dataset/</guid>
      <description>1.57G indiegogo-dataset.jpeg</description>
      <content:encoded><![CDATA[<h2 id="indiegogo">Indiegogo</h2>
<p>Indiegogo成立于2008年，全球最大的科创新品首发和众筹平台， 是美国最早的众筹平台之一。</p>
<p><br><br></p>
<h2 id="参考论文">参考论文</h2>
<p>该数据集研究价值，可用于研究市场营销、创新创业、信息管理等， 部分使用众筹数据集作为研究对象的论文。</p>
<blockquote>
<p>[1]王伟,陈伟,祝效国,王洪伟. 众筹融资成功率与语言风格的说服性-基于Kickstarter的实证研究.<em>管理世界</em>.2016;5:81-98.
[2]Dai, Hengchen and Dennis J. Zhang. “Prosocial Goal Pursuit in Crowdfunding: Evidence from Kickstarter.” Journal of Marketing Research 56 (2019): 498 - 517.
[3]Gafni, H., Marom, D.M., Robb, A.M., &amp; Sade, O. (2020). Gender Dynamics in Crowdfunding (Kickstarter): Evidence on Entrepreneurs, Backers, and Taste-Based Discrimination*. Review of Finance.
[4]Jensen, Lasse Skovgaard and Ali Gürcan Özkil. “Identifying challenges in crowdfunded product development: a review of Kickstarter projects.” Design Science 4 (2018): n. pag.</p>
</blockquote>
<p><br><br></p>
<h2 id="indiegogo数据">Indiegogo数据</h2>
<p>2016年4月写好的Indiegogo爬虫，每月执行一次, 最新的数据 可以前往https://webrobots.io/indiegogo-dataset/</p>
<p><img loading="lazy" src="img/web_robot.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="原始数据">‘原始’数据</h2>
<p>Web Robot网上公开的的Indiegogo原始数据几十个 csv文件,</p>
<p><img loading="lazy" src="img/zips.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="整理">整理</h2>
<p>将上图的zip全部合并为一个 Indiegogo_dataset.csv , 该文件 1.57G 。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>

<span class="n">dff</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;Indiegogo_Dataset/Indiegogo_dataset.csv&#39;</span><span class="p">,</span> <span class="n">on_bad_lines</span><span class="o">=</span><span class="s1">&#39;skip&#39;</span><span class="p">)</span>
<span class="n">dff</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<p><img loading="lazy" src="img/df.png" alt=""  />
</p>
<br>
<p>数据集的字段有</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df</span><span class="o">.</span><span class="n">columns</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">Index([&#39;bullet_point&#39;, 
       &#39;category&#39;, &#39;category_url&#39;,  #项目类目及url
       &#39;clickthrough_url&#39;, #进入当前项目经由的某url
       &#39;close_date&#39;,  #项目截止日期
       &#39;currency&#39;,  #货币
       &#39;funds_raised_amount&#39;,  #当前已筹集的资金
       &#39;funds_raised_percent&#39;, #筹集资金进度(当前筹资/项目目标金额)
       &#39;image_url&#39;,  #图片url
       &#39;is_indemand&#39;, 
       &#39;is_pre_launch&#39;, #是否为预演
       &#39;offered_by&#39;,  #项目发起人
       &#39;open_date&#39;, #项目开始日期
       &#39;perk_goal_percentage&#39;, &#39;perks_claimed&#39;, 
       &#39;price_offered&#39;, #众筹价
       &#39;price_retail&#39;, #零售价
       &#39;product_stage&#39;,  #产品阶段
       &#39;project_id&#39;, #项目id
       &#39;project_type&#39;, #项目类型
       &#39;source_url&#39;, #项目url
       &#39;tagline&#39;, &#39;tags&#39;, #标签
       &#39;title&#39; ], #项目标题
      dtype=&#39;object&#39;)
</code></pre></div><p><br><br></p>
<h2 id="数据获取">数据获取</h2>
<ul>
<li>原始数据
<ul>
<li><a href="https://webrobots.io/indiegogo-dataset/">https://webrobots.io/indiegogo-dataset/</a></li>
</ul>
</li>
<li>整理的1.57G csv,
<ul>
<li>链接: <a href="https://pan.baidu.com/s/1j3PtV4GbFsyhjmr0NLbnKg">https://pan.baidu.com/s/1j3PtV4GbFsyhjmr0NLbnKg</a> 提取码: vfyc</li>
</ul>
</li>
</ul>
<p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>14G数据集 | 2007-2021年A股上市公司年度报告（txt文件）</title>
      <link>https://hidadeng.github.io/blog/2022-10-21-2007-2021-a-share-reports-dataset/</link>
      <pubDate>Sun, 16 Oct 2022 00:00:00 +0000</pubDate>
      
      <guid>/blog/2022-10-21-2007-2021-a-share-reports-dataset/</guid>
      <description>2007-2021年A股上市公司年度报告（txt文件）</description>
      <content:encoded><![CDATA[<p>2007-2021年A股上市公司年度报告, 整理不易，请转发分享。</p>
<br>
<h2 id="截图">截图</h2>
<p><img loading="lazy" src="img/07-21.png" alt=""  />

<img loading="lazy" src="img/2007.png" alt=""  />
</p>
<br>
<h2 id="获取">获取</h2>
<blockquote>
<p>链接: <a href="https://pan.baidu.com/s/1jw6VGGAN9cxROoqWN2X4vw">https://pan.baidu.com/s/1jw6VGGAN9cxROoqWN2X4vw</a> 提取码: g3cn</p>
</blockquote>
<br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>数据集 | 多语言对齐词向量预训练模型</title>
      <link>https://hidadeng.github.io/blog/2022-10-16-aligned-word-vectors/</link>
      <pubDate>Sun, 16 Oct 2022 00:00:00 +0000</pubDate>
      
      <guid>/blog/2022-10-16-aligned-word-vectors/</guid>
      <description>借助该预训练模型，应该能做可做跨文化对比分析</description>
      <content:encoded><![CDATA[<h2 id="介绍">介绍</h2>
<p>Facebook研究者使用 fastText 算法，对维基百科(44种语言)语料数据进行了训练，最终生成了 44 种语言的对齐词向量。</p>
<br>
<h2 id="用途">用途</h2>
<p>wiki数据集有个优点，即由于众人分享、翻译，将不同语言的百科词条进行了翻译整理。所以facebook使用wiki训练对齐词向量有助于提升翻译准确性。与此同时，因为翻译者处于不同的语言和文化背景下，词条及词条内容必然蕴含着语言所特有的文化信息线索，有可能有助于我们挖掘跨语言的文化差异。例如中文词条<code>护士</code>和 英文词条<code>nurse</code> ，可以借助对齐词向量，比较护士这个群体在性别、种族等语义上的差异。</p>
<p>之前分享过的内容</p>
<ul>
<li><a href="https://textdata.cn/blog/embeddingsandattitude/">词嵌入测量不同群体对某概念的态度(偏见)</a></li>
<li><a href="https://textdata.cn/blog/wordembeddingsinsocialscience/">转载 | 大数据时代下社会科学研究方法的拓展&mdash;&mdash;基于词嵌入技术的文本分析的应用</a></li>
<li><a href="https://textdata.cn/blog/from_sysbol_to_embeddings_in_computational_social_science/">转载 | 从符号到嵌入：计算社会科学的两种文本表示</a></li>
<li><a href="https://textdata.cn/blog/literatureembeddings/">文献汇总 | 词嵌入 与 社会科学中的偏见(态度)</a></li>
</ul>
<p>不过fastText算法认为词语有不同的大小划分层次，从大到小分别是词语、词缀、字符等，使用 Joulin 等人 (2018) 中描述的 RCSLS 方法进行比对。</p>
<table>
<thead>
<tr>
<th><strong>Code</strong></th>
<th><strong>en-es</strong></th>
<th><strong>es-en</strong></th>
<th><strong>en-fr</strong></th>
<th><strong>fr-en</strong></th>
<th><strong>en-de</strong></th>
<th><strong>de-en</strong></th>
<th><strong>en-ru</strong></th>
<th><strong>ru-en</strong></th>
<th><strong>en-zh</strong></th>
<th><strong>zh-en</strong></th>
<th><strong>avg</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>Joulin et al. [<a href="https://arxiv.org/abs/1804.07745">1</a>]</td>
<td>84.1</td>
<td>86.3</td>
<td>83.3</td>
<td>84.1</td>
<td><strong>79.1</strong></td>
<td>76.3</td>
<td><strong>57.9</strong></td>
<td><strong>67.2</strong></td>
<td>45.9</td>
<td>46.4</td>
<td>71.1</td>
</tr>
<tr>
<td>This implementation (10 epochs)</td>
<td>84.2</td>
<td><strong>86.6</strong></td>
<td><strong>83.9</strong></td>
<td>84.7</td>
<td>78.3</td>
<td>76.6</td>
<td>57.6</td>
<td>66.7</td>
<td><strong>47.6</strong></td>
<td><strong>47.4</strong></td>
<td>71.4</td>
</tr>
<tr>
<td>This implementation (unsup. model selection)</td>
<td><strong>84.3</strong></td>
<td><strong>86.6</strong></td>
<td><strong>83.9</strong></td>
<td><strong>85.0</strong></td>
<td>78.7</td>
<td><strong>76.7</strong></td>
<td>57.6</td>
<td>67.1</td>
<td><strong>47.6</strong></td>
<td><strong>47.4</strong></td>
<td><strong>71.5</strong></td>
</tr>
</tbody>
</table>
<p>算法得出的词向量在西方，尤其是西欧语言之间进行语义对齐，效果可能更好。而中文、日语等汉字语言，是由偏旁部首组成，与西方字母语言还是存在一定差异。上表也可以看出中英语义对齐准确率47%， 而其他语言之间对齐准确率平均为71%。</p>
<br>
<h2 id="模型资源">模型资源</h2>
<p><a href="https://fasttext.cc/docs/en/aligned-vectors.html">https://fasttext.cc/docs/en/aligned-vectors.html</a></p>
<p>对齐预训练向量模型下载链接</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>Afrikaans: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.af.align.vec"><em>text</em></a></td>
<td>Arabic: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.ar.align.vec"><em>text</em></a></td>
<td>Bulgarian: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.bg.align.vec"><em>text</em></a></td>
<td>Bengali: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.bn.align.vec"><em>text</em></a></td>
</tr>
<tr>
<td>Bosnian: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.bs.align.vec"><em>text</em></a></td>
<td>Catalan: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.ca.align.vec"><em>text</em></a></td>
<td>Czech: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.cs.align.vec"><em>text</em></a></td>
<td>Danish: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.da.align.vec"><em>text</em></a></td>
</tr>
<tr>
<td>German: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.de.align.vec"><em>text</em></a></td>
<td>Greek: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.el.align.vec"><em>text</em></a></td>
<td>English: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.en.align.vec"><em>text</em></a></td>
<td>Spanish: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.es.align.vec"><em>text</em></a></td>
</tr>
<tr>
<td>Estonian: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.et.align.vec"><em>text</em></a></td>
<td>Persian: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.fa.align.vec"><em>text</em></a></td>
<td>Finnish: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.fi.align.vec"><em>text</em></a></td>
<td>French: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.fr.align.vec"><em>text</em></a></td>
</tr>
<tr>
<td>Hebrew: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.he.align.vec"><em>text</em></a></td>
<td>Hindi: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.hi.align.vec"><em>text</em></a></td>
<td>Croatian: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.hr.align.vec"><em>text</em></a></td>
<td>Hungarian: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.hu.align.vec"><em>text</em></a></td>
</tr>
<tr>
<td>Indonesian: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.id.align.vec"><em>text</em></a></td>
<td>Italian: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.it.align.vec"><em>text</em></a></td>
<td>Korean: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.ko.align.vec"><em>text</em></a></td>
<td>Lithuanian: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.lt.align.vec"><em>text</em></a></td>
</tr>
<tr>
<td>Latvian: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.lv.align.vec"><em>text</em></a></td>
<td>Macedonian: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.mk.align.vec"><em>text</em></a></td>
<td>Malay: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.ms.align.vec"><em>text</em></a></td>
<td>Dutch: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.nl.align.vec"><em>text</em></a></td>
</tr>
<tr>
<td>Norwegian: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.no.align.vec"><em>text</em></a></td>
<td>Polish: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.pl.align.vec"><em>text</em></a></td>
<td>Portuguese: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.pt.align.vec"><em>text</em></a></td>
<td>Romanian: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.ro.align.vec"><em>text</em></a></td>
</tr>
<tr>
<td>Russian: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.ru.align.vec"><em>text</em></a></td>
<td>Slovak: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.sk.align.vec"><em>text</em></a></td>
<td>Slovenian: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.sl.align.vec"><em>text</em></a></td>
<td>Albanian: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.sq.align.vec"><em>text</em></a></td>
</tr>
<tr>
<td>Swedish: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.sv.align.vec"><em>text</em></a></td>
<td>Tamil: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.ta.align.vec"><em>text</em></a></td>
<td>Thai: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.th.align.vec"><em>text</em></a></td>
<td>Tagalog: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.tl.align.vec"><em>text</em></a></td>
</tr>
<tr>
<td>Turkish: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.tr.align.vec"><em>text</em></a></td>
<td>Ukrainian: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.uk.align.vec"><em>text</em></a></td>
<td>Vietnamese: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.vi.align.vec"><em>text</em></a></td>
<td>Chinese: <a href="https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.zh.align.vec"><em>text</em></a></td>
</tr>
</tbody>
</table>
<br>
<h2 id="格式">格式</h2>
<p>词向量默认使用的fastText格式</p>
<ul>
<li>第一行给了词向量的维数</li>
<li>从第二行开始，每一行由词语及对应的词向量组成。</li>
<li>数值之间使用空格间隔</li>
</ul>
<br>
<h2 id="代码">代码</h2>
<h3 id="导入模型">导入模型</h3>
<p>使用gensim导入fastText方法训练出的 预训练语言模型</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">gensim.models</span> <span class="kn">import</span> <span class="n">KeyedVectors</span>

<span class="c1">#导入刚刚下载的预训练模型</span>
<span class="c1">#该词向量模型300维</span>
<span class="n">zh_w2v_model</span> <span class="o">=</span> <span class="n">KeyedVectors</span><span class="o">.</span><span class="n">load_word2vec_format</span><span class="p">(</span><span class="s1">&#39;wiki.zh.align.vec&#39;</span><span class="p">,</span> <span class="n">binary</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1">#英文词向量模型5G，太大了。如果内存小于16G不要使用下面命令</span>
<span class="c1">#en_w2v_model = KeyedVectors.load_word2vec_format(&#39;wiki.en.align.vec&#39;, binary=False)</span>
</code></pre></div><p>一旦导入成功，就可以进行向量计算。这里仅进行简单演示</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#获取某词的词向量</span>
<span class="n">zh_w2v_model</span><span class="o">.</span><span class="n">get_vector</span><span class="p">(</span><span class="s1">&#39;护士&#39;</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<pre><code>array([ 0.0733,  0.0782,  0.0188, -0.0027, -0.0052,...,  0.0586,  0.0166,
       -0.1401, -0.0545, -0.0125,  0.0373, -0.0681,  0.063 ],
      dtype=float32)
</code></pre>
<br>
<p>在中文中， 护士职业的主要从业者为女性，反应在词向量相似度上，如下</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="nb">print</span><span class="p">(</span><span class="n">zh_w2v_model</span><span class="o">.</span><span class="n">similarity</span><span class="p">(</span><span class="s1">&#39;护士&#39;</span><span class="p">,</span> <span class="s1">&#39;女性&#39;</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">zh_w2v_model</span><span class="o">.</span><span class="n">similarity</span><span class="p">(</span><span class="s1">&#39;护士&#39;</span><span class="p">,</span> <span class="s1">&#39;男性&#39;</span><span class="p">))</span>
</code></pre></div><p>Run</p>
<pre><code>0.4417011
0.378651
</code></pre>
<br>
<p>更多w2v_model用法可参考 <a href="https://textdata.cn/blog/douban_w2v/">豆瓣影评 | 探索词向量妙处</a></p>
<br>
<h2 id="文献">文献</h2>
<p>如果使用了facebook的预训练词向量，请引用以下两篇文献。</p>
<ul>
<li>Joulin, Armand, Piotr Bojanowski, Tomas Mikolov, Hervé Jégou, and Edouard Grave. &ldquo;Loss in translation: Learning bilingual word mapping with a retrieval criterion.&rdquo; arXiv preprint arXiv:1804.07745 (2018).</li>
<li>Bojanowski, Piotr, Edouard Grave, Armand Joulin, and Tomas Mikolov. &ldquo;Enriching word vectors with subword information.&rdquo; Transactions of the association for computational linguistics 5 (2017): 135-146.</li>
</ul>
<br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>17G数据 | 企业社会责任报告数据集</title>
      <link>https://hidadeng.github.io/blog/coporate_social_responsibility_datasets/</link>
      <pubDate>Thu, 04 Aug 2022 00:00:00 +0000</pubDate>
      
      <guid>/blog/coporate_social_responsibility_datasets/</guid>
      <description>近年来，企业社会责任（csr)已成为全球学术界研究的热点。国内外各大顶刊都先后刊登了多篇关于csr的文章，比如《企业绿色创新实践如何破解“和谐共生”难题？》（发表于管理世界）、《负责任的国际投资：ESG与中国OFDI》（发表于经济研究）、《Is my company really doing good? Factors influencing employees&amp;#39; evaluation of the authenticity of their company&amp;#39;s corporate social responsibility engagement》（发表于JBR）等。这些文章核心变量的构建大都基于对企业社会责任报告的内容分析和挖掘。比如《企业绿色创新实践如何破解“和谐共生”难题？》的被解释变量（绿色创新）以及部分解释变量（二元合法性和伦理型领导）。可见，社会责任报告对于我们研究esg至关重要。因此，接下来小编就带大家爬取深交所上市公司历年的社会责任报告，希望能够给大家带来一些帮助。In recent years, corporate social responsibility (csr) has become a research hotspot in the global academic circles. Major top journals at home and abroad have successively published many articles on CSR, such as How can corporate green innovation practice solve the problem of harmonious symbiosis? (published in Governance World), Responsible International Investment: ESG and China&amp;#39;s OFDI (published in Economic Research), Is my company really doing good? Factors influencing employees&amp;#39; evaluation of the authenticity of their company&amp;#39;s corporate social responsibility engagement (published in JBR) et al. The construction of core variables in these articles is mostly based on the content analysis and mining of corporate social responsibility reports. For example, How can corporate green innovation practice solve the problem of harmonious symbiosis? 》The explained variable (green innovation) and part of the explanatory variables (dual legitimacy and ethical leadership). It can be seen that the social responsibility report is very important for us to study esg. Therefore, the next editor will take you to crawl the social responsibility reports of companies listed on the Shenzhen Stock Exchange over the years, hoping to bring you some help.</description>
      <content:encoded><![CDATA[<blockquote>
<p>作者:张延丰 哈工程在读博士</p>
</blockquote>
<p>近年来，企业社会责任（csr)已成为全球学术界研究的热点。国内外各大顶刊都先后刊登了多篇关于csr的文章，比如《企业绿色创新实践如何破解“和谐共生”难题？》（发表于管理世界）、《负责任的国际投资：ESG与中国OFDI》（发表于经济研究）、《Is my company really doing good? Factors influencing employees' evaluation of the authenticity of their company&rsquo;s corporate social responsibility engagement》（发表于JBR）等。这些文章核心变量的构建大都基于对企业社会责任报告的内容分析和挖掘。比如《企业绿色创新实践如何破解“和谐共生”难题？》的被解释变量（绿色创新）以及部分解释变量（二元合法性和伦理型领导）。可见，社会责任报告对于我们研究esg至关重要。因此，接下来小编就带大家爬取深交所上市公司历年的社会责任报告，希望能够给大家带来一些帮助。</p>
<br>
<h2 id="获取数据集">获取数据集</h2>
<p>采集4000多个pdf文件。经过数据清洗，将20G的pdf数据，汇总整理到170M的csv文件内。</p>
<p><img loading="lazy" src="img/datasets.png" alt=""  />
</p>
<p>数据整理不易，如需获取本数据集，<strong>请转发本文至朋友圈集赞满30+</strong>， 加微信【372335839】，备注【深圳ESG数据集】</p>
<img src="img/wechat.jpg" style="zoom:50%;" />
<p><br><br></p>
<h2 id="一构建网络爬虫">一、构建网络爬虫</h2>
<p>数据采集分为多个步骤</p>
<ol>
<li>找网址规律(GET or POST), 构造url参数</li>
<li>伪装请求，防止被封</li>
<li>构造csv，存储信心</li>
<li>执行整个爬虫</li>
</ol>
<h3 id="11-url">1.1 url</h3>
<p>打开X交所的 <a href="http://www.szse.cn/disclosure/listed/notice/">http://www.szse.cn/disclosure/listed/notice/</a> ，同时打开浏览器开发者工具network面板，在截图左侧输入框输入关键词 『社会责任报告』，按下回车。</p>
<p>此时开发者工具network面板出现很多网络交换信息， 点击检查发现下图</p>
<p><img loading="lazy" src="img/01-%e7%bd%91%e5%9d%80%e8%a7%84%e5%be%8b.png" alt=""  />
</p>
<p>发现该页面数据是<strong>POST</strong>请求，网址为</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">http://www.szse.cn/api/disc/announcement/annList?random=random参数
</code></pre></div><h3 id="12-headers">1.2 headers</h3>
<p>同时也能发现伪装头参数，现将两个重要信息整理为</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">url</span> <span class="o">=</span> <span class="s1">&#39;http://www.szse.cn/api/disc/announcement/annList?random=</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">())</span>

<span class="c1">#伪装头</span>
<span class="n">headers</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;Accept&#39;</span><span class="p">:</span> <span class="s1">&#39;application/json, text/javascript, */*; q=0.01&#39;</span><span class="p">,</span>
           <span class="s1">&#39;Accept-Encoding&#39;</span><span class="p">:</span> <span class="s1">&#39;gzip, deflate&#39;</span><span class="p">,</span>
           <span class="s1">&#39;Accept-Language&#39;</span><span class="p">:</span> <span class="s1">&#39;zh-CN,zh;q=0.9,en;q=0.8&#39;</span><span class="p">,</span>
           <span class="s1">&#39;Content-Type&#39;</span><span class="p">:</span> <span class="s1">&#39;application/json&#39;</span><span class="p">,</span>
           <span class="s1">&#39;Host&#39;</span><span class="p">:</span> <span class="s1">&#39;www.szse.cn&#39;</span><span class="p">,</span>
           <span class="s1">&#39;Origin&#39;</span><span class="p">:</span> <span class="s1">&#39;http://www.szse.cn&#39;</span><span class="p">,</span>
           <span class="s1">&#39;Proxy-Connection&#39;</span><span class="p">:</span> <span class="s1">&#39;close&#39;</span><span class="p">,</span>
           <span class="s1">&#39;Referer&#39;</span><span class="p">:</span> <span class="s1">&#39;http://www.szse.cn/disclosure/listed/fixed/index.html&#39;</span><span class="p">,</span>
           <span class="s1">&#39;User-Agent&#39;</span><span class="p">:</span> <span class="s1">&#39;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.132 Safari/537.36&#39;</span><span class="p">,</span>
           <span class="s1">&#39;X-Request-Type&#39;</span><span class="p">:</span> <span class="s1">&#39;ajax&#39;</span><span class="p">,</span>
           <span class="s1">&#39;X-Requested-With&#39;</span><span class="p">:</span> <span class="s1">&#39;XMLHttpRequest&#39;</span><span class="p">}</span>
</code></pre></div><h3 id="13-data参数">1.3 data参数</h3>
<p>POST请求需要构造data参数，在开发者对应于payload, 整理为Python格式</p>
<p><img loading="lazy" src="img/02-payload.png" alt=""  />
</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">
</code></pre></div><p><br><br></p>
<h3 id="14-preview">1.4 preview</h3>
<p>看到左侧渲染后的数据，同时也能在开发者工具network面板看到肉眼背后的源数据。我们使用preview预览截图再次确认网址规律没有问题。</p>
<p><img loading="lazy" src="img/03-data-preview.jpg" alt=""  />
</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">keyword</span> <span class="o">=</span> <span class="s1">&#39;社会责任报告&#39;</span>
<span class="n">page</span> <span class="o">=</span> <span class="mi">1</span>

<span class="c1">#post方法参数</span>
<span class="n">payload</span> <span class="o">=</span><span class="p">{</span><span class="s2">&#34;seDate&#34;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&#34;&#34;</span><span class="p">,</span><span class="s2">&#34;&#34;</span><span class="p">],</span>
           <span class="s2">&#34;searchKey&#34;</span><span class="p">:</span> <span class="p">[</span><span class="n">keyword</span><span class="p">],</span>
           <span class="s2">&#34;channelCode&#34;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&#34;listedNotice_disc&#34;</span><span class="p">],</span>
           <span class="s2">&#34;pageSize&#34;</span><span class="p">:</span> <span class="mi">50</span><span class="p">,</span>
           <span class="s2">&#34;pageNum&#34;</span><span class="p">:</span> <span class="n">page</span><span class="p">}</span>
</code></pre></div><h3 id="15-csv">1.5 csv</h3>
<p>现在已经把爬虫最重要的工作做完了，剩下的就是想办法构造出csv，并将数据存入csv。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#定义csv字段，存储PDF链接信息至data/esg_links.csv</span>
<span class="n">csvf</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;data/esg_links.csv&#39;</span><span class="p">,</span> <span class="s1">&#39;a+&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">,</span> <span class="n">newline</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
<span class="n">fieldnames</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;id&#39;</span><span class="p">,</span> <span class="s1">&#39;name&#39;</span><span class="p">,</span> <span class="s1">&#39;code&#39;</span><span class="p">,</span> <span class="s1">&#39;date&#39;</span><span class="p">,</span> <span class="s1">&#39;title&#39;</span><span class="p">,</span> <span class="s1">&#39;pdf_link&#39;</span><span class="p">,</span> <span class="s1">&#39;size&#39;</span><span class="p">]</span>
<span class="n">writer</span> <span class="o">=</span> <span class="n">csv</span><span class="o">.</span><span class="n">DictWriter</span><span class="p">(</span><span class="n">csvf</span><span class="p">,</span> <span class="n">fieldnames</span><span class="o">=</span><span class="n">fieldnames</span><span class="p">)</span>
<span class="n">writer</span><span class="o">.</span><span class="n">writeheader</span><span class="p">()</span>

<span class="n">test_data</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;pdf_link&#39;</span><span class="p">:</span> <span class="s1">&#39;测试pdf文件链接&#39;</span><span class="p">,</span>
             <span class="s1">&#39;code&#39;</span><span class="p">:</span> <span class="s1">&#39;测试股票代码&#39;</span><span class="p">,</span>
             <span class="s1">&#39;name&#39;</span><span class="p">:</span> <span class="s1">&#39;股票名称&#39;</span><span class="p">,</span>
             <span class="s1">&#39;title&#39;</span><span class="p">:</span> <span class="s1">&#39;报告名称&#39;</span><span class="p">,</span>
             <span class="s1">&#39;date&#39;</span><span class="p">:</span> <span class="s1">&#39;发布日期&#39;</span><span class="p">,</span>
             <span class="s1">&#39;size&#39;</span><span class="p">:</span> <span class="s1">&#39;pdf文件字节大小&#39;</span><span class="p">,</span>
             <span class="s1">&#39;id&#39;</span><span class="p">:</span> <span class="s1">&#39;数据id&#39;</span><span class="p">}</span>
             
<span class="n">writer</span><span class="o">.</span><span class="n">writerow</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span>

<span class="c1">#关闭csv</span>
<span class="n">csvf</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</code></pre></div><p><br><br></p>
<h2 id="二爬虫代码完整">二、爬虫代码(完整)</h2>
<p>当你看到本文时，该完整代码很有可能会随着网站变化而失效。不要悲伤难过， 按照爬虫思路自己diy即可。如果没有爬虫基础，学习 <a href="https://www.bilibili.com/video/BV1AE411r7ph">大邓的B站爬虫视频</a> ，</p>
<p><img loading="lazy" src="img/%e5%a4%a7%e9%82%93%e7%88%ac%e8%99%ab.jpg" alt=""  />
</p>
<p>自己懂爬虫原理diy代码，比改别人的代码来的更容易。将前面的准备工作组织起来, 就形成了下面的完整代码</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">requests</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">csv</span>

<span class="n">keyword</span> <span class="o">=</span> <span class="s2">&#34;社会责任报告&#34;</span>

<span class="c1">#定义csv字段，存储PDF链接信息至data/esg_links.csv</span>
<span class="n">csvf</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;data/esg_links.csv&#39;</span><span class="p">,</span> <span class="s1">&#39;a+&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">,</span> <span class="n">newline</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
<span class="n">fieldnames</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;id&#39;</span><span class="p">,</span> <span class="s1">&#39;name&#39;</span><span class="p">,</span> <span class="s1">&#39;code&#39;</span><span class="p">,</span> <span class="s1">&#39;date&#39;</span><span class="p">,</span> <span class="s1">&#39;title&#39;</span><span class="p">,</span> <span class="s1">&#39;pdf_link&#39;</span><span class="p">,</span> <span class="s1">&#39;size&#39;</span><span class="p">]</span>
<span class="n">writer</span> <span class="o">=</span> <span class="n">csv</span><span class="o">.</span><span class="n">DictWriter</span><span class="p">(</span><span class="n">csvf</span><span class="p">,</span> <span class="n">fieldnames</span><span class="o">=</span><span class="n">fieldnames</span><span class="p">)</span>
<span class="n">writer</span><span class="o">.</span><span class="n">writeheader</span><span class="p">()</span>

<span class="c1">#伪装头</span>
<span class="n">headers</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;Accept&#39;</span><span class="p">:</span> <span class="s1">&#39;application/json, text/javascript, */*; q=0.01&#39;</span><span class="p">,</span>
           <span class="s1">&#39;Accept-Encoding&#39;</span><span class="p">:</span> <span class="s1">&#39;gzip, deflate&#39;</span><span class="p">,</span>
           <span class="s1">&#39;Accept-Language&#39;</span><span class="p">:</span> <span class="s1">&#39;zh-CN,zh;q=0.9,en;q=0.8&#39;</span><span class="p">,</span>
           <span class="s1">&#39;Content-Type&#39;</span><span class="p">:</span> <span class="s1">&#39;application/json&#39;</span><span class="p">,</span>
           <span class="s1">&#39;Host&#39;</span><span class="p">:</span> <span class="s1">&#39;www.szse.cn&#39;</span><span class="p">,</span>
           <span class="s1">&#39;Origin&#39;</span><span class="p">:</span> <span class="s1">&#39;http://www.szse.cn&#39;</span><span class="p">,</span>
           <span class="s1">&#39;Proxy-Connection&#39;</span><span class="p">:</span> <span class="s1">&#39;close&#39;</span><span class="p">,</span>
           <span class="s1">&#39;Referer&#39;</span><span class="p">:</span> <span class="s1">&#39;http://www.szse.cn/disclosure/listed/fixed/index.html&#39;</span><span class="p">,</span>
           <span class="s1">&#39;User-Agent&#39;</span><span class="p">:</span> <span class="s1">&#39;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.132 Safari/537.36&#39;</span><span class="p">,</span>
           <span class="s1">&#39;X-Request-Type&#39;</span><span class="p">:</span> <span class="s1">&#39;ajax&#39;</span><span class="p">,</span>
           <span class="s1">&#39;X-Requested-With&#39;</span><span class="p">:</span> <span class="s1">&#39;XMLHttpRequest&#39;</span><span class="p">}</span>

<span class="n">page</span> <span class="o">=</span> <span class="mi">1</span>

<span class="c1">#post方法参数</span>
<span class="n">payload</span> <span class="o">=</span><span class="p">{</span><span class="s2">&#34;seDate&#34;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&#34;&#34;</span><span class="p">,</span><span class="s2">&#34;&#34;</span><span class="p">],</span>
           <span class="s2">&#34;searchKey&#34;</span><span class="p">:</span> <span class="p">[</span><span class="n">keyword</span><span class="p">],</span>
           <span class="s2">&#34;channelCode&#34;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&#34;listedNotice_disc&#34;</span><span class="p">],</span>
           <span class="s2">&#34;pageSize&#34;</span><span class="p">:</span> <span class="mi">50</span><span class="p">,</span>
           <span class="s2">&#34;pageNum&#34;</span><span class="p">:</span> <span class="n">page</span><span class="p">}</span>

<span class="c1">#发起请求</span>
<span class="n">url</span> <span class="o">=</span> <span class="s1">&#39;http://www.szse.cn/api/disc/announcement/annList?random=</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">())</span>
<span class="n">resp</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">post</span><span class="p">(</span><span class="n">url</span><span class="p">,</span>
                     <span class="n">headers</span><span class="o">=</span><span class="n">headers</span><span class="p">,</span>
                     <span class="n">data</span><span class="o">=</span><span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">payload</span><span class="p">))</span>

<span class="c1">#当data关键词有对应的非空列表，循环一直进行。</span>
<span class="k">while</span> <span class="n">resp</span><span class="o">.</span><span class="n">json</span><span class="p">()[</span><span class="s1">&#39;data&#39;</span><span class="p">]:</span>
    <span class="n">payload</span><span class="p">[</span><span class="s1">&#39;pageNum&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">page</span>
    <span class="n">resp</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">post</span><span class="p">(</span><span class="n">url</span><span class="p">,</span>
                     <span class="n">headers</span><span class="o">=</span><span class="n">headers</span><span class="p">,</span>
                     <span class="n">data</span><span class="o">=</span><span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">payload</span><span class="p">))</span>
    
    <span class="n">esgs</span> <span class="o">=</span> <span class="n">resp</span><span class="o">.</span><span class="n">json</span><span class="p">()[</span><span class="s1">&#39;data&#39;</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">esg</span> <span class="ow">in</span> <span class="n">esgs</span><span class="p">:</span>
        <span class="c1">#以字典样式写入csv</span>
        <span class="n">data</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;pdf_link&#39;</span><span class="p">:</span> <span class="s1">&#39;http://disc.static.szse.cn/download&#39;</span><span class="o">+</span> <span class="n">esg</span><span class="p">[</span><span class="s1">&#39;attachPath&#39;</span><span class="p">],</span>
                <span class="c1">#为防止股票代码被exel等软件识别为数字，特转为字符串，并加sz标识。</span>
                <span class="s1">&#39;code&#39;</span><span class="p">:</span> <span class="s1">&#39;sz&#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">esg</span><span class="p">[</span><span class="s1">&#39;secCode&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">]),</span> 
                <span class="s1">&#39;name&#39;</span><span class="p">:</span> <span class="n">esg</span><span class="p">[</span><span class="s1">&#39;secName&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span>
                <span class="s1">&#39;title&#39;</span><span class="p">:</span> <span class="n">esg</span><span class="p">[</span><span class="s1">&#39;title&#39;</span><span class="p">],</span>
                <span class="s1">&#39;date&#39;</span><span class="p">:</span> <span class="n">esg</span><span class="p">[</span><span class="s1">&#39;publishTime&#39;</span><span class="p">],</span>
                <span class="s1">&#39;size&#39;</span><span class="p">:</span> <span class="n">esg</span><span class="p">[</span><span class="s1">&#39;attachSize&#39;</span><span class="p">],</span>
                <span class="s1">&#39;id&#39;</span><span class="p">:</span> <span class="n">esg</span><span class="p">[</span><span class="s1">&#39;id&#39;</span><span class="p">]}</span>
        <span class="n">writer</span><span class="o">.</span><span class="n">writerow</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

    <span class="n">page</span> <span class="o">=</span> <span class="n">page</span> <span class="o">+</span> <span class="mi">1</span>
    
<span class="c1">#关闭csv</span>
<span class="n">csvf</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</code></pre></div><p><br><br></p>
<h2 id="三查看csv">三、查看csv</h2>
<p>使用pandas读取 <code>data/esg_links.csv</code>,</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;esg_links.csv&#39;</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/04-df.png" alt=""  />
</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">4392
</code></pre></div><p>一共有4392条 「企业社会责任」 的报告数据。</p>
<p><br><br></p>
<h2 id="四批量下载">四、批量下载</h2>
<p>下载就简单多了， 直接使用定义好的爬虫代码。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">requests</span>

<span class="k">def</span> <span class="nf">download</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">file</span><span class="p">):</span>
    <span class="s2">&#34;&#34;&#34;
</span><span class="s2">    下载多媒体及文件
</span><span class="s2">    url： 多媒体文件链接（结尾有文件格式名）
</span><span class="s2">    file: 存储文件的路径（结尾有文件格式名）
</span><span class="s2">    &#34;&#34;&#34;</span>
    <span class="n">resp</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
    <span class="c1">#获取到二进制数据</span>
    <span class="n">binarydata</span> <span class="o">=</span> <span class="n">resp</span><span class="o">.</span><span class="n">content</span>
    <span class="c1">#以二进制形式将数据流存入fname中</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">file</span><span class="p">,</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">binarydata</span><span class="p">)</span> 
        

<span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>

<span class="k">for</span> <span class="n">link</span><span class="p">,</span> <span class="n">title</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;pdf_link&#39;</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;title&#39;</span><span class="p">]):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">title</span><span class="p">)</span>
    <span class="n">download</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="n">link</span><span class="p">,</span> <span class="n">file</span><span class="o">=</span><span class="s1">&#39;data/</span><span class="si">{}</span><span class="s1">.pdf&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">title</span><span class="p">))</span>
    <span class="n">i</span> <span class="o">=</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">0 山河药辅：山河药辅2021年度社会责任报告
1 新 希 望：2021年企业社会责任报告（英文版）
2 天原股份：宜宾天原集团股份有限公司社会责任报告
3 五 粮 液：2021年度社会责任报告（英文版）
4 中兵红箭：2021年度社会责任报告	
......
......
148 苏宁环球：2021年社会责任报告
149 蓝色光标：2021年度企业社会责任报告
150 开尔新材：2021年度社会责任报告
151 中顺洁柔：2021年社会责任报告
......
......

4391 闽东电力：2006年度社会责任报告
4392  阳光发展：2006年度社会责任报告书
</code></pre></div><p>采集过程中，被封锁在所难免，所以记得每次停止采集的位置，在csv中删除该位置之前的数据。然后重新运行代码即可。</p>
<h3 id="注意">注意</h3>
<p>即时解决以上问题，可能遇到奇怪的问题。比如</p>
<p><img loading="lazy" src="img/07-error.png" alt=""  />
</p>
<p>检查发现相比其他几百kb的pdf，问题文件大小只有几kb。问题可能是被网站封锁或网络不稳定导致，标记好问题pdf的链接，重新批量下载一遍。</p>
<p><img loading="lazy" src="img/06-error.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="汇总至csv">汇总至csv</h2>
<p>很多企业社会责任报告是图片合成的，所以这里的pdf体积很大。将data文件夹中的4000多个pdf汇总至esg_data.csv中，能节约出电脑内存空间，也方便后续数据分析。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">pdfdocx</span> <span class="kn">import</span> <span class="n">read_pdf</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">csv</span>

<span class="n">i</span> <span class="o">=</span> <span class="mi">1</span>

<span class="c1">#新建esg_data.csv，用于存储企业社会责任报告数据</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;esg_data.csv&#39;</span><span class="p">,</span> <span class="s1">&#39;a+&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">,</span> <span class="n">newline</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">csvf</span><span class="p">:</span>
    <span class="n">fieldnames</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;id&#39;</span><span class="p">,</span> <span class="s1">&#39;name&#39;</span><span class="p">,</span> <span class="s1">&#39;code&#39;</span><span class="p">,</span> <span class="s1">&#39;date&#39;</span><span class="p">,</span> <span class="s1">&#39;title&#39;</span><span class="p">,</span> <span class="s1">&#39;pdf_link&#39;</span><span class="p">,</span> <span class="s1">&#39;size&#39;</span><span class="p">,</span> <span class="s1">&#39;report_content&#39;</span><span class="p">]</span>
    <span class="n">writer</span> <span class="o">=</span> <span class="n">csv</span><span class="o">.</span><span class="n">DictWriter</span><span class="p">(</span><span class="n">csvf</span><span class="p">,</span> <span class="n">fieldnames</span><span class="o">=</span><span class="n">fieldnames</span><span class="p">)</span>
    <span class="n">writer</span><span class="o">.</span><span class="n">writeheader</span><span class="p">()</span>

    <span class="n">files</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="s1">&#39;data&#39;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">file</span> <span class="ow">in</span> <span class="n">files</span><span class="p">:</span>
        <span class="n">record_of_df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;title&#39;</span><span class="p">]</span><span class="o">==</span><span class="n">file</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;.pdf&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">)]</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">record_of_df</span><span class="o">.</span><span class="n">to_dict</span><span class="p">()</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">file</span><span class="p">)</span>
        <span class="n">data</span><span class="p">[</span><span class="s1">&#39;report_content&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">read_pdf</span><span class="p">(</span><span class="s1">&#39;data/</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">file</span><span class="p">))</span>
        <span class="n">writer</span><span class="o">.</span><span class="n">writerow</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="n">i</span> <span class="o">=</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span>
</code></pre></div><p>最后，数据从20G的data文件夹(4000多个PDF)压缩为一个170M的esg_data.csv文件。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">esg_reports_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;esg_data.csv&#39;</span><span class="p">)</span>
<span class="n">esg_reports_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/08-esg_reports_df.png" alt=""  />
</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="nb">len</span><span class="p">(</span><span class="n">esg_reports_df</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">4346
</code></pre></div><p><br><br></p>
<h2 id="五相关文献">五、相关文献</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">[1]解学梅, &amp; 朱琪玮. (2021). 企业绿色创新实践如何破解 “和谐共生” 难题?. 管理世界, 37(1), 128-149.
[2]谢红军 &amp; 吕雪.(2022).负责任的国际投资：ESG与中国OFDI. 经济研究(03),83-99.
[3]Schaefer, S. D., Terlutter, R., &amp; Diehl, S. (2019). Is my company really doing good? Factors influencing employees&#39; evaluation of the authenticity of their company&#39;s corporate social responsibility engagement. Journal of business research, 101, 128-143.
</code></pre></div><p><br><br></p>
<h2 id="六其他广告">六、其他(广告)</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>中文金融领域知识图谱的数据集ChainKnowledgeGraph</title>
      <link>https://hidadeng.github.io/blog/chain_knowledge_graph/</link>
      <pubDate>Mon, 06 Dec 2021 16:42:10 +0600</pubDate>
      
      <guid>/blog/chain_knowledge_graph/</guid>
      <description>本文围绕金融领域，推出面向上市公司的产业链图谱。  </description>
      <content:encoded><![CDATA[<p>领域知识图谱的数据集，当前还比较缺失，而作为构建难度最大的产业链图谱领域更为空白。产业链作为产业经济学中的一个概念，是各个产业部门之间基于一定的技术经济关联，并依据特定的逻辑关系和时空布局关系客观形成的链条式关联关系形态。从本质上来说，产业链的本质是用于描述一个具有某种内在联系的企业群结构，产业链中大量存在着上下游关系和相互价值的交换，上游环节向下游环节输送产品或服务，下游环节向上游环节反馈信息。</p>
<p>作者已经先后发布两大领域的实体图谱数据： <br>
1、情报领域【武器装备知识图谱】，地址：https://github.com/liuhuanyong/QAonMilitaryKG<br>
2、医疗领域【医疗知识图谱】，地址： <a href="https://github.com/liuhuanyong/QASystemOnMedicalKG">https://github.com/liuhuanyong/QASystemOnMedicalKG</a></p>
<p>当前，为了进一步推动产业发展，本文围绕金融领域，推出面向上市公司的产业链图谱。</p>
<p>项目地址：</p>

<figure >
    
        <img src="img/1.png" width="800" />
    
    
</figure>

<br>
<h2 id="一项目构成">一、项目构成</h2>
<p>产业链知识图谱包括A股上市公司、行业和产品共3类实体，包括上市公司所属行业关系、行业上级关系、产品上游原材料关系、产品下游产品关系、公司主营产品、产品小类共6大类。</p>
<p>通过数据处理、抽取，最终建成图谱规模数十万，其中包括上市公司4,654家，行业511个，产品95,559条、上游材料56,824条，上级行业480条，下游产品390条，产品小类52,937条，所属行业3,946条。  <br>

<figure >
    
        <img src="img/2.png" width="800" />
    
    
</figure>
</p>
<br>
<h2 id="二项目构建">二、项目构建</h2>
<p>1、实体构建<br>
1）上市公司<br>
目前上市公司已经达到四千多家，是我国重要的公司代表与行业标杆，本图谱选取上市公司作为基础实体之一。通过交易所公开信息中，可以得到上市公司代码、全称、简称、注册地址、挂牌等多个信息。</p>

<figure >
    
        <img src="img/3.png" width="800" />
    
    
</figure>

<p>2）行业分类<br>
行业是产业链图谱中另一个核心内容，也是承载产业、公司及产品的一个媒介，通过这一领携作用，可以生产出大量的行业指数、热点行业等指标。<br>
目前关于行业，已经陆续出现多个行业规范，代表性的有申万三级行业分类、国民经济行业分类等。中国上市公司所属行业的分类准则是依据营业收入等财务数据为主要分类标准和依据，所采用财务数据为经过会计事务所审计并已公开披露的合并报表数据。<br>
2021年6月，申万发布了2021版的行业分类规范，将1级行业从28个调整至31个、2级行业从104个调整至134个、3级行业从227个调整至346个，新增1级行业美容护理等，新增2级行业，并将上市公司进行了归属。本图谱选用申万行业作为基础数据。<br>

<figure >
    
        <img src="img/4.png" width="800" />
    
    
</figure>
</p>
<p>3）业务产品 <br>
业务产品主要指公司主营范围、经营的产品，用于对一个公司的定位。可以从公司的经营范围、年报等文本中进行提取得到。<br>

<figure >
    
        <img src="img/5.png" width="800" />
    
    
</figure>
</p>
<p>2、关系构建 <br>
1）公司所属行业 <br>
通过公开的上市公司行业分类表，可以得到上市公司所对应的行业分类数据。 <br>

<figure >
    
        <img src="img/6.png" width="800" />
    
    
</figure>
</p>
<p>2）行业上级关系 <br>
通过公开的行业三级分类情况，可以通过组合的形式得到行业之间的上级关系数据。 <br>

<figure >
    
        <img src="img/7.png" width="800" />
    
    
</figure>
</p>
<p>3）公司主营产品关系<br>
上市公司的经营产品数据可以从两个方面来获得，一个是从公司简介中的经营范围中结合制定的规则进行提取，另一个是从公司每年发布的半年报、年报中进行提取。这些报告中会有按经营业务、经营产品、经营地域等几个角度对公司的营收占比进行统计，也可以通过制定规则的方式进行提取。第二种方法中，由于已经有统计数据，所以我们可以根据占比数据大小，对主营产品这一关系进行赋值。<br>

<figure >
    
        <img src="img/8.png" width="800" />
    
    
</figure>
</p>
<p>4）产品之间的上下游关系<br>
产品之间的上下游关系，是展示产品之间传导逻辑关系的一个重要方法，包括上游原材料以及下游产品两大类。我们可以多种来获取：<br>
一种是基于规则模式匹配的方式进行抽取，如抽取上游原材料这一关系可以由诸如&quot;a是b的原料/原材料/主要构件/重要原材料/  上游原料&quot;的模式进行抽取&quot;，而下游产品，则同理可以通过&quot;A是B的下游成品/产品&quot;等模式进行提取。<br>
另一种是基于序列标注的提取。还有一种是基于现有结构化知识图谱的提取，例如已经结构化好的百科知识三元组，可以通过设定谓词及其扩展进行过滤。<br>

<figure >
    
        <img src="img/9.png" width="800" />
    
    
</figure>
</p>
<p>5）产品之间的小类关系<br>
对于一个产品而言，其是有大小层级分类的，在缺少大类产品名称的时候，可以通过计算小类产品来得到相应指标。与产品之间的上下游数据类似，可以通过启发式规则的方式进行提取，如“A是一种B”，也可以通过字符之间的组成成分进行匹配生成，如“螺纹钢”是“精细螺纹钢”的一个大类。<br>

<figure >
    
        <img src="img/10.png" width="800" />
    
    
</figure>
</p>
<br>
<h2 id="三项目运行">三、项目运行</h2>
<p>1、data文件夹下包括了本项目的数据信息：<br>
1)company.json:公司实体数据<br>
2)industry.json:行业实体数据 <br>
3)product.json:产品实体数据 <br>
4)company_industry.json:公司-行业关系数据 <br>
5)industry_industry.json:行业-行业关系数据 <br>
6)product_product.json:产品-产品数据 <br>
7)company_product.json:公司-产品数据</p>
<p>2、项目运行:<br>
python build_graph.py</p>
<br>
<h2 id="四项目总结">四、项目总结</h2>
<p>产业链图谱是众多领域知识图谱中较为棘手的一种，本项目通过现有的数据，借助数据处理、结构化提取方式，设计、构建并形成了一个节点100,718，关系边169,153的十万级别产业链图谱。就产业链图谱的构建而言，我们需要至少从以上三个方面加以考虑：</p>
<ul>
<li>其一，产业链的主观性与标准性。产业链的主观性较强，不同的人对产业链的构建、产业链节点、关系的类型，产业链的颗粒度问题都有不同的理解。不同的设定会直接导致不同的应用结果。正如我们所看到的，目前存在不同的行业标准，不同的网站、机构也将公司归为不同的行业。</li>
<li>其二，产业链的动态性和全面性。产业链需要具备足够大的复用性和扩展性，几千家上市公司实际上是冰山一角。国内有几千万家公司，而且不断会有新增，如何将新增的公司融入到这个额产业链中，也是一个很大挑战。此外，产业本身是动态的， 随着行业的发展，不断会有新的行业出现。如何捕捉这种行业的变化，使得整个图谱变得与时俱进，也是需要考量的点。</li>
<li>其三，产业链的定量推理特性。单纯定性的构建产业链知识图谱，如果没有足够的参数，仅有知识表达是无法进行推理的，推理要求知识图谱Schema具备节点间推理传导的必备参数，以及影响推理传导的其他关键参数。对于必备参数来说，从公司到产品必须有主营占比、市场占比、产能占比等数据，从产品到产品必须有成本占比和消耗占比等数据。</li>
</ul>
<br>
<h2 id="参考数据来源">参考数据来源</h2>
<p>1、申万行业：http://www.swsindex.com<br>
2、深交所: <a href="http://www.szse.cn">http://www.szse.cn</a><br>
3、上交所: <a href="http://www.sse.com.cn">http://www.sse.com.cn</a></p>
<p>If any question about the project or me ,see <a href="https://liuhuanyong.github.io/">https://liuhuanyong.github.io/</a></p>
<p>如有自然语言处理、知识图谱、事理图谱、社会计算、语言资源建设等问题或合作，可联系我： <br>
1、我的github项目介绍：https://liuhuanyong.github.io<br>
2、我的csdn博客：https://blog.csdn.net/lhy2014<br>
3、about me:刘焕勇，lhy_<a href="mailto:in_blcu@126.com">in_blcu@126.com</a>.      <br>
4、我的技术公众号:老刘说NLP</p>
<br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>中文语义常用词典ChineseSemanticKB</title>
      <link>https://hidadeng.github.io/blog/chinese_semantic_kb/</link>
      <pubDate>Mon, 06 Dec 2021 16:40:10 +0600</pubDate>
      
      <guid>/blog/chinese_semantic_kb/</guid>
      <description>面向中文处理的12类、百万规模的语义常用词典，包括34万抽象语义库、34万反义语义库、43万同义语义库等，可支持句子扩展、转写、事件抽象与泛化等多种应用场景。</description>
      <content:encoded><![CDATA[<h2 id="chinesesemantickb">ChineseSemanticKB</h2>
<p>ChineseSemanticKB,chinese semantic knowledge base, 面向中文处理的12类、百万规模的语义常用词典，包括34万抽象语义库、34万反义语义库、43万同义语义库等，可支持句子扩展、转写、事件抽象与泛化等多种应用场景。</p>
<br>
<h2 id="项目介绍">项目介绍</h2>
<p>语义知识库是自然语言处理中十分重要的一个基础资源，与学术界追求算法模型不同，工业界的自然语言处理对于底层的词汇知识库、语义知识库等多种资源依赖度很高，具体体现在：<br>
1、具有落地场景的自然语言处理任务都是业务高度相关，一个业务需求刚进去，需要解决的是业务的词汇问题，无基础词库，无项目冷启动；<br>
2、规则和正则启动下的工业级应用，规则的扩展、泛化都需要底层的词汇网络做支撑；<br>
3、目前包括搜索、问答、舆情监控、事件分析等应用，与标签体系的运作关系密切，而这与先验的底层词汇库依赖性很强；<br>
4、自然语言场景越来越关注推理层面，即所谓的“认知”层面，认知背后的各种逻辑关系库，是驱动这一决策的根本途径；<br>
5、当前，面向中文开源词库的工作存在少量、分散的状态，无论从规模，还是质量，都需要进一步聚合；<br>
因此，我从过往的开源工作中进一步抽离和整理，形成了中文处理的12类、百万规模的语义常用词典，包括34万抽象语义库、34万反义语义库、43万同义语义库等，用于相关下游任务。</p>
<p>项目放于dict当中，可直接下载，不建议二次建库共享，尊重开源。</p>
<br>
<h2 id="词库的类别">词库的类别</h2>
<table>
<thead>
<tr>
<th style="text-align:left">词库类型</th>
<th style="text-align:center">词库规模</th>
<th style="text-align:center">词库举例</th>
<th style="text-align:center">词库应用</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">抽象关系库</td>
<td style="text-align:center">346,048</td>
<td style="text-align:center">座椅,抽象,家具</td>
<td style="text-align:center">事件抽象与泛化，人民币贬值到货币贬值，再到美元贬值，可支持查询扩展、推荐等任务</td>
</tr>
<tr>
<td style="text-align:left">反义关系库</td>
<td style="text-align:center">34,380</td>
<td style="text-align:center">开心@苦恼</td>
<td style="text-align:center">可用于句子改写，开心改苦恼，支持数据增强，句子生成</td>
</tr>
<tr>
<td style="text-align:left">同义关系库</td>
<td style="text-align:center">424,826</td>
<td style="text-align:center">开心@高兴</td>
<td style="text-align:center">可用于查询扩展、数据增强，也可结合抽象关系库完成推荐等任务</td>
</tr>
<tr>
<td style="text-align:left">简称关系库</td>
<td style="text-align:center">136,081</td>
<td style="text-align:center">北京大学@北大</td>
<td style="text-align:center">可用于句子标准化、句子改写、实体消歧等任务</td>
</tr>
<tr>
<td style="text-align:left">程度副词</td>
<td style="text-align:center">222</td>
<td style="text-align:center">极其,2.0</td>
<td style="text-align:center">可用于情感强度计算，带情感色彩的句子生成</td>
</tr>
<tr>
<td style="text-align:left">否定词</td>
<td style="text-align:center">586</td>
<td style="text-align:center">不,无,没有</td>
<td style="text-align:center">可用于情感计算等任务</td>
</tr>
<tr>
<td style="text-align:left">节日时间词</td>
<td style="text-align:center">54</td>
<td style="text-align:center">春节、五四节</td>
<td style="text-align:center">可用于时间词识别等任务</td>
</tr>
<tr>
<td style="text-align:left">量比词</td>
<td style="text-align:center">7</td>
<td style="text-align:center">占比、环比、同比</td>
<td style="text-align:center">可用于金融领域指标类数据提取任务</td>
</tr>
<tr>
<td style="text-align:left">数量介词</td>
<td style="text-align:center">24</td>
<td style="text-align:center">大约、达到、超过</td>
<td style="text-align:center">可用于金融事件抽象或主干化的搭配词处理任务</td>
</tr>
<tr>
<td style="text-align:left">停用词</td>
<td style="text-align:center">3,861</td>
<td style="text-align:center">？、的、着</td>
<td style="text-align:center">常规的文本特征提取等任务</td>
</tr>
<tr>
<td style="text-align:left">修饰副词</td>
<td style="text-align:center">222</td>
<td style="text-align:center">所、有所</td>
<td style="text-align:center">可结合程度副词完成情感强度计算等任务</td>
</tr>
<tr>
<td style="text-align:left">情态词</td>
<td style="text-align:center">77</td>
<td style="text-align:center">肯定、应该、大概</td>
<td style="text-align:center">可用于句子主观性计算、舆情与可信度计算</td>
</tr>
</tbody>
</table>
<br>
<h2 id="总结">总结</h2>
<p>1、本项目开源了一个目前可用于事件处理以及工业舆情的12类语义词库，总规模数目一百余万；<br>
2、本项目开源的34万抽象语义库、34万反义语义库、43万同义语义库，在作者的实际工作中【事件处理、事理抽取、事件推理】等有重要用途;<br>
3、中文常用语义常用词典，均来源于公开文本+人工整理+机器抽取形成，其中若有质量不高之处，可积极批评指正;<br>
4、中文开源事业还是要坚持做下去，尽可能地缩短自然语言处理学术界和工业界之间的鸿沟。</p>
<blockquote>
<p>If any question about the project or me ,see <a href="https://liuhuanyong.github.io/">https://liuhuanyong.github.io/</a>.<br>
如有自然语言处理、知识图谱、事理图谱、社会计算、语言资源建设等问题或合作，可联系我：     <br>
1、我的github项目介绍：https://liuhuanyong.github.io  <br>
2、我的csdn技术博客：https://blog.csdn.net/lhy2014 <br>
3、我的联系方式: 刘焕勇，中国科学院软件研究所，lhy_<a href="mailto:in_blcu@126.com">in_blcu@126.com</a>. <br>
4、我的共享知识库项目：刘焕勇，数据地平线，http://www.openkg.cn/organization/datahorizon.<br>
5、我的工业项目：刘焕勇，数据地平线，大规模实时事理学习系统：https://xueji.datahorizon.cn.  <br>
6、我的工业项目：刘焕勇，数据地平线，面向事件和语义的自然语言处理工具箱：https://nlp.datahorizon.cn</p>
</blockquote>
<br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>70G上交所年报数据集</title>
      <link>https://hidadeng.github.io/blog/70g_china_market_anunal_report_datasets/</link>
      <pubDate>Mon, 22 Nov 2021 20:40:10 +0600</pubDate>
      
      <guid>/blog/70g_china_market_anunal_report_datasets/</guid>
      <description>Python网络爬虫与文本分析， 70g会计年报pdf数据集免费下载</description>
      <content:encoded><![CDATA[<h2 id="70g年报pdf数据集">70G年报pdf数据集</h2>
<p><img loading="lazy" src="img/1.gif" alt=""  />
</p>
<h2 id="数据下载说明">数据下载说明</h2>
<p>所有pdf均来自上海证券交易所官网，使用shreport库进行的下载。</p>
<p><img loading="lazy" src="img/2.png" alt=""  />
</p>
<h2 id="报告信息汇总文件">报告信息汇总文件</h2>
<h4 id="heading"></h4>
<p><img loading="lazy" src="img/3.gif" alt=""  />
</p>
<p>summary.xlsx内字段</p>
<ul>
<li>company 上市公司企业名</li>
<li>code 股票代码</li>
<li>type 报告类型</li>
<li>year 报告年份</li>
<li>date 报告发布日期</li>
<li>pdf 报告pdf文件下载链接</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">import pandas as pd
from pathlib import Path


#报告汇总文件summary.xlsx
df = pd.read_excel(&#39;summary.xlsx&#39;)
df.head()
</code></pre></div><p><img loading="lazy" src="img/4.png" alt=""  />
</p>
<p>一共有报告71126份</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">len(df)
71149
</code></pre></div><p>一共有上市公司1486家</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">len(df[&#39;company&#39;].unique())
1486
</code></pre></div><h2 id="summary文件夹">summary文件夹</h2>
<p>summary文件夹内是每家公司的报告披露情况</p>
<p><img loading="lazy" src="img/5.gif" alt=""  />
</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">df1 = pd.read_excel(&#39;summary/600000.xlsx&#39;)
df1.head()
</code></pre></div><p><img loading="lazy" src="img/6.png" alt=""  />
</p>
<p>浦发银行一共有75份定期报告</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">len(df1)
75
</code></pre></div><h2 id="reports文件夹">reports文件夹</h2>
<p>reports文件夹存放着以各各公司股票代码命名的文件夹</p>
<p>文件夹内是该公司所有定期报告</p>
<p><img loading="lazy" src="img/7.gif" alt=""  />
</p>
<h2 id="读取pdf报告">读取pdf报告</h2>
<p>可使用pdfdocx库读取pdf,</p>
<p>pdfdocx文档链接 <a href="https://github.com/thunderhit/pdfdocx">https://github.com/thunderhit/pdfdocx</a></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">from pdfdocx import read_pdf

p_text = read_pdf(&#39;reports/600000/600000_2012_1.pdf&#39;)
p_text
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">上海浦东发展银行股份有限公司 \n\n2012 年第一季度报告 \n\n \n\n \n\n§1 重要提示 \n\n1.1 公司董事会、监事会及其董事、监事、高级管理人员保证本报告所载资料不存在任何虚假记载、\n\n误导性陈述或者重大遗漏，并对其内容的真实性、准确性和完整性承担个别及连带责任。\n\n1.2 公司于 2012 年 4 月 26 日以通讯表决的方式召开第四届董事会第二十六次会议审议通过本报告，\n\n1.4 公司董事长、行长吉晓辉、财务总监刘信义及财务机构负责人傅能声明：保证本季度报告中财务\n\n公司全体董事出席董事会会议并行使表决权。\n\n1.3 公司第一季度财务报告未经审计。\n\n报告的真实、完整。\n\n \n§2 公司基本情况 \n\n2.1 主要会计数据及财务指标 \n\n本报告期末 \n\n上年度期末 \n\n币种:人民币 \n\n本报告期末比上年\n度期末增减(%) \n\n总资产(千元) \n\n归属于上市公司股东的所有者权益(千元) \n\n2,804,646,567\n\n157,055,724\n\n2,684,693,689 \n148,891,235 \n\n归属于上市公司股东的每股净资产(元) \n\n8.420\n\n7.982 \n\n4.47 \n5.48 \n5.49 \n\n经营活动产生的现金流量净额(千元) \n\n每股经营活动产生的现金流\n\n \n\n \n \n母公司现金流量表 \n \n2012 年 1—3 月 \n \n编制单位: 上海浦东发展银行股份有限公司....
</code></pre></div><h2 id="70g数据下载">70G数据下载</h2>
<p>链接:https://pan.baidu.com/s/14PI6MbxunFQ3fZOfR33zkw 密码:osoi</p>
<br>
<br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
  </channel>
</rss>
