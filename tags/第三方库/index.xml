<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>第三方库 on 大邓和他的PYTHON</title>
    <link>/tags/%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93/</link>
    <description>Recent content in 第三方库 on 大邓和他的PYTHON</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh</language>
    <lastBuildDate>Wed, 16 Nov 2022 00:00:00 +0000</lastBuildDate><atom:link href="/tags/%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>FinBERT | 金融文本BERT模型，可情感分析、识别ESG和FLS类型</title>
      <link>https://hidadeng.github.io/blog/2022-11-17-finbert-finance-bert-model/</link>
      <pubDate>Wed, 16 Nov 2022 00:00:00 +0000</pubDate>
      
      <guid>/blog/2022-11-17-finbert-finance-bert-model/</guid>
      <description>金融语言模型</description>
      <content:encoded><![CDATA[<h2 id="finbert介绍">FinBERT介绍</h2>

<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
  <iframe src="https://www.youtube.com/embed/uj4hm7Lr2Wo" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video"></iframe>
</div>

<br>
<p>FinBERT， 是使用49亿词的英文金融语料库数据，生成的BERT预训练语言模型。语料库上大小为 49亿个词。</p>
<ul>
<li>公司报告 10-K 和 10-Q：25亿个词</li>
<li>电话会议记录：13亿个词</li>
<li>分析师报告：11亿个词</li>
</ul>
<p>FinBERT开发者在多个金融 NLP 任务上对 FinBERT 预训练模型进行了微调，均优于传统机器学习模型、深度学习模型和微调 BERT 模型。 所有经过微调的 FinBERT 模型都公开托管在 Huggingface 🤗。  目前支持包括<strong>情绪分析、ESG 分类、前瞻性陈述 (FLS) 分类</strong>。</p>
<br>
<h3 id="finbert功能">FinBERT功能</h3>
<p>具体来说，FinBERT有以下内容：</p>
<ul>
<li><a href="https://huggingface.co/yiyanghkust/finbert-pretrain">FinBERT-Pretrained</a>： 针对大规模金融文本的预训练 FinBERT 模型。</li>
<li><a href="https://huggingface.co/yiyanghkust/finbert-tone">FinBERT-Sentiment</a>： 用于情感分类任务。</li>
<li><a href="https://huggingface.co/yiyanghkust/finbert-esg">FinBERT-ESG</a>： 用于 ESG 分类任务。</li>
<li><a href="https://huggingface.co/yiyanghkust/finbert-fls">FinBERT-FLS</a>： 用于前瞻性陈述（FLS）分类任务。</li>
</ul>
<br>
<h3 id="环境配置">环境配置</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">pip install transformers==4.18.0
</code></pre></div><p>本次实验使用的transformers版本为</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">import transformers
transformers.__version__
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">4.18.0
</code></pre></div><br>
<h3 id="代码下载">代码下载</h3>
<p><a href="FinBERT.ipynb">点击下载</a></p>
<p><br><br></p>
<h2 id="一情感分析">一、情感分析</h2>
<p>金融文本情绪可以调动管理者、信息中介和投资者的观点和意见, 因此分析金融文本情感(情绪)是有价值的。 FinBERT-Sentiment 是一个 FinBERT 模型，它根据标准普尔 500 家公司的分析师报告中的 10,000 个手动注释的句子进行了Fine-tune(微调)。</p>
<blockquote>
<p>Fine-Tune微调 是 深度学习的一种语言处理技术，可以在前人（已有）的语言模型文件基础上加入少量新场景的文本数据进行更新训练，生成出新场景的语言模型。</p>
</blockquote>
<ul>
<li><strong>输入</strong>：金融文本。</li>
<li><strong>输出</strong>：Positive, Neutral or Negative.</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">BertTokenizer</span><span class="p">,</span> <span class="n">BertForSequenceClassification</span><span class="p">,</span> <span class="n">pipeline</span>

<span class="c1">#首次运行，因为会下载FinBERT模型，耗时会比较久</span>
<span class="n">senti_finbert</span> <span class="o">=</span> <span class="n">BertForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">&#39;yiyanghkust/finbert-tone&#39;</span><span class="p">,</span><span class="n">num_labels</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">senti_tokenizer</span> <span class="o">=</span> <span class="n">BertTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">&#39;yiyanghkust/finbert-tone&#39;</span><span class="p">)</span>
<span class="n">senti_nlp</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span><span class="s2">&#34;text-classification&#34;</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">senti_finbert</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">=</span><span class="n">senti_tokenizer</span><span class="p">)</span>
</code></pre></div><p><br>使用3条测试文本进行测试</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1"># 待分析的文本数据</span>
<span class="n">senti_results</span> <span class="o">=</span> <span class="n">senti_nlp</span><span class="p">([</span><span class="s1">&#39;growth is strong and we have plenty of liquidity.&#39;</span><span class="p">,</span> 
                           <span class="s1">&#39;there is a shortage of capital, and we need extra financing.&#39;</span><span class="p">,</span>
                           <span class="s1">&#39;formulation patents might protect Vasotec to a limited extent.&#39;</span><span class="p">])</span>
<span class="n">senti_results</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">    [{&#39;label&#39;: &#39;Positive&#39;, &#39;score&#39;: 1.0},
     {&#39;label&#39;: &#39;Negative&#39;, &#39;score&#39;: 0.9952379465103149},
     {&#39;label&#39;: &#39;Neutral&#39;, &#39;score&#39;: 0.9979718327522278}]
</code></pre></div><p><br><br></p>
<h2 id="二esg分类">二、ESG分类</h2>
<p>ESG 分析可以帮助投资者确定企业的长期可持续性并识别相关风险。 FinBERT-ESG 是一个 FinBERT 模型，根据来自公司 ESG 报告和年度报告的 2,000 个手动注释句子进行微调。</p>
<ul>
<li><strong>输入</strong>：金融文本。</li>
<li><strong>输出</strong>：Environmental, Social, Governance or None.</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">BertTokenizer</span><span class="p">,</span> <span class="n">BertForSequenceClassification</span><span class="p">,</span> <span class="n">pipeline</span>

<span class="n">esg_finbert</span> <span class="o">=</span> <span class="n">BertForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">&#39;yiyanghkust/finbert-esg&#39;</span><span class="p">,</span><span class="n">num_labels</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="n">esg_tokenizer</span> <span class="o">=</span> <span class="n">BertTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">&#39;yiyanghkust/finbert-esg&#39;</span><span class="p">)</span>
<span class="n">esg_nlp</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span><span class="s2">&#34;text-classification&#34;</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">esg_finbert</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">=</span><span class="n">esg_tokenizer</span><span class="p">)</span>
</code></pre></div><p><br>使用3条测试文本进行测试</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">esg_results</span> <span class="o">=</span> <span class="n">esg_nlp</span><span class="p">([</span><span class="s1">&#39;Managing and working to mitigate the impact our operations have on the environment is a core element of our business.&#39;</span><span class="p">,</span>
                      <span class="s1">&#39;Rhonda has been volunteering for several years for a variety of charitable community programs.&#39;</span><span class="p">,</span>
                      <span class="s1">&#39;Cabot</span><span class="se">\&#39;</span><span class="s1">s annual statements are audited annually by an independent registered public accounting firm.&#39;</span><span class="p">,</span>
                      <span class="s1">&#39;As of December 31, 2012, the 2011 Term Loan had a principal balance of $492.5 million.&#39;</span><span class="p">])</span>

<span class="n">esg_results</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">    [{&#39;label&#39;: &#39;Environmental&#39;, &#39;score&#39;: 0.9805498719215393},
     {&#39;label&#39;: &#39;Social&#39;, &#39;score&#39;: 0.9906041026115417},
     {&#39;label&#39;: &#39;Governance&#39;, &#39;score&#39;: 0.6738430857658386},
     {&#39;label&#39;: &#39;None&#39;, &#39;score&#39;: 0.9960240125656128}]
</code></pre></div><p><br><br></p>
<h2 id="三fls识别">三、FLS识别</h2>
<p><strong>前瞻性陈述 (FLS)</strong> 告知投资者经理人对公司未来事件或结果的信念和意见。 从公司报告中识别前瞻性陈述可以帮助投资者进行财务分析。 FinBERT-FLS 是一个 FinBERT 模型，它基于罗素 3000 家公司年报的管理讨论和分析部分的 3,500 个手动注释的句子进行了微调。</p>
<ul>
<li><strong>输入</strong>：金融文本。</li>
<li><strong>输出</strong>：Specific-FLS(特定 FLS) , Non-specific FLS(非特定 FLS),  Not-FLS(非 FLS)。</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">BertTokenizer</span><span class="p">,</span> <span class="n">BertForSequenceClassification</span><span class="p">,</span> <span class="n">pipeline</span>

<span class="n">fls_finbert</span> <span class="o">=</span> <span class="n">BertForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">&#39;yiyanghkust/finbert-fls&#39;</span><span class="p">,</span><span class="n">num_labels</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">fls_tokenizer</span> <span class="o">=</span> <span class="n">BertTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">&#39;yiyanghkust/finbert-fls&#39;</span><span class="p">)</span>

<span class="n">fls_nlp</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span><span class="s2">&#34;text-classification&#34;</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">fls_finbert</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">=</span><span class="n">fls_tokenizer</span><span class="p">)</span>
</code></pre></div><p><br> 使用3条测试文本进行测试</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">fls_results</span> <span class="o">=</span> <span class="n">fls_nlp</span><span class="p">([</span><span class="s1">&#39;we expect the age of our fleet to enhance availability and reliability due to reduced downtime for repairs.&#39;</span><span class="p">,</span>
                      <span class="s1">&#39;on an equivalent unit of production basis, general and administrative expenses declined 24 percent from 1994 to $.67 per boe.&#39;</span><span class="p">,</span>
                      <span class="s1">&#39;we will continue to assess the need for a valuation allowance against deferred tax assets considering all available evidence obtained in future reporting periods.&#39;</span><span class="p">])</span>


<span class="n">fls_results</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">    [{&#39;label&#39;: &#39;Specific FLS&#39;, &#39;score&#39;: 0.7727874517440796},
     {&#39;label&#39;: &#39;Not FLS&#39;, &#39;score&#39;: 0.9905241131782532},
     {&#39;label&#39;: &#39;Non-specific FLS&#39;, &#39;score&#39;: 0.975904107093811}]
</code></pre></div><p><br><br></p>
<h2 id="文档及引用说明">文档及引用说明</h2>
<ul>
<li>文档github地址 <a href="https://github.com/yya518/FinBERT">https://github.com/yya518/FinBERT</a></li>
</ul>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">@misc{yang2020finbert,
    title={FinBERT: A Pretrained Language Model for Financial Communications},
    author={Yi Yang and Mark Christopher Siy UY and Allen Huang},
    year={2020},
    eprint={2006.08097},
    archivePrefix={arXiv},
    }
</code></pre></div><p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://hidadeng.github.io/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://hidadeng.github.io/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://hidadeng.github.io/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>PNAS | 使用语义距离测量一个人的创新力(发散思维)得分</title>
      <link>https://hidadeng.github.io/blog/2022-11-14-pnas_naming_unrelated_words_predicts_creativity/</link>
      <pubDate>Mon, 14 Nov 2022 00:00:00 +0000</pubDate>
      
      <guid>/blog/2022-11-14-pnas_naming_unrelated_words_predicts_creativity/</guid>
      <description>使用语义距离测量一个人的创新力(发散思维)得分</description>
      <content:encoded><![CDATA[<br>
<p>传统测量 <strong>被试者创造力</strong> 存在耗费时间、主观性太强、缺乏客观性，且所得到的分值是不稳定的，无法跨时间、文化、群体进行分值比较。该研究分析了创新力的两大理论，即联系理论和执行理论，即创新力是包含思维的广度和深度两方面。</p>
<ul>
<li><strong>联系理论(广度)</strong> 负责搜寻所有可能方案的集合，增加集合的规模，体现思维的广度。</li>
<li><strong>执行理论(深度)</strong> 负责寻找最佳方案，并将方案落实执行，体现思维的深度。</li>
</ul>
<p>结合Glove词嵌入技术，将每个词理解为一个技术或知识，两词语语义越相似，发散性越低。</p>
<p>文中让被试按照一定规则，随意填写10个名词，使用其中7个有效词语测量被试的创新力(发散性)思维。可以简单的把7个词理解为知识或者技术，7个词语会形成21种词语对(组合)。最后求均值可以测量出被试词语对的语义距离体现创新发散性的强度。<strong>文末含案例代码</strong></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">Olson, J.A., Nahas, J., Chmoulevitch, D., Cropper, S.J. and Webb, M.E., 2021. Naming unrelated words predicts creativity. Proceedings of the National Academy of Sciences, 118(25), p.e2022340118.
</code></pre></div><p><br><br></p>
<h2 id="一摘要">一、摘要</h2>
<p><strong>一些理论认为，有 创造力 的人能够产生更多 发散性 的想法。如果这是正确的，简单地让被试写 N 个不相关的单词，然后测量这N个词的语义距离， 作为 #发散思维 的客观衡量标准</strong>。为了验证这一假设，我们要求 8,914 名参与者说出 10 个彼此尽可能不同的单词。</p>
<p>然后计算算法估计单词之间的平均语义距离；<strong>相关词（例如 cat 和 dog）比不相关词（例如 cat 和 thimble）的距离更短。我们预测，产生更大语义距离的人也会在传统的创造力测量中得分更高</strong>。</p>
<p>在研究 1 中，我们发现语义距离与两个广泛使用的创造力测量（替代用途任务和桥接关联差距任务）之间存在中度至强相关性。在研究 2 中，参与者来自 98 个国家，语义距离仅因基本人口变量而略有不同。在一系列已知可预测创造力的问题上，语义距离与表现之间也存在正相关关系。</p>
<p>总体而言， <strong>语义距离</strong> 与已建立的 创造力测量 的相关性至少与这些测量彼此之间的相关性一样强。 因此，在我们所说的发散关联任务中命名不相关的词可以作为发散思维的简短、可靠和客观的衡量标准。</p>
<br>
<h2 id="二创新力理论">二、创新力理论</h2>
<p>想出 3 个尽可能不同的词。根据两种主要的创造力理论 (1, 2)，选择这些词依赖于产生 #远程联想 ，同时抑制 #常见联想 。</p>
<p>#联想理论 (Associative Theory)认为，有创造力的人具有语义记忆结构，可以更容易地链接远程元素 (3-6)。</p>
<p>#执行理论 (Executive Theory) 侧重于自上而下的注意力控制；创造性的解决方案来自于监测和抑制共同的联想 (2, 7)。</p>
<p>基于这些理论，我们假设 <strong>填写n个无关单词的任务</strong> 可以可靠地衡量 #语言创造力 。 <strong>创造力有两个主要的心理成分， 收敛思维和发散思维，它们在产生创意输出时协同工作</strong>。收敛性思维任务衡量评估多种刺激并得出最适当响应的能力，例如问题的最佳解决方案 (3, 8-10)。这些任务往往更容易得分，因为只有一小部分正确答案。<strong>相比之下，发散思维任务通常使用开放式问题来衡量一个人产生各种解决方案的能力</strong> (11-13)。它们通常需要更长的回答(文本)，因此更难客观评分。</p>
<br>
<h2 id="三创新力测量">三、创新力测量</h2>
<h3 id="31--替代用途任务">3.1  替代用途任务</h3>
<p>最常见的发散思维测量是 <strong>替代用途任务</strong> Alternative Uses Task (14, 15)，在该任务中，参与者生成常见物体的用途，例如回形针或鞋子。使用常用的评分方法 (16)，评分者然后根据三个组成部分来判断回答：</p>
<ul>
<li>灵活性，产生的不同用途类别的数量；</li>
<li>独创性，每次使用相对于样本的其余部分的稀有程度，这对创造力特别重要（17、18）；和</li>
<li>流畅度，一共产生了多少次使用。</li>
</ul>
<br>
<h3 id="32-离散联系任务">3.2 离散联系任务</h3>
<p>本研究作者开发了 <strong>离散联系任务</strong> (Divergent Association Task， DAT) 的网站， <strong>填写你想到的10个不相关词语， 创造力越丰富的人，填写的词语语义距离往往会更远</strong>。</p>
<p><a href="https://www.datcreativity.com/">https://www.datcreativity.com/</a></p>
<p><img loading="lazy" src="img/1_pnas_divergent_association_task_mainpage.png" alt=""  />
</p>
<h3 id="被试填写10个单词的规则">被试填写10个单词的规则</h3>
<ol>
<li>只能填写英文单词</li>
<li>只能是名词(如事情、物体、概念)</li>
<li>不能填 专有名词（例如，特定的人或地点）</li>
<li>不能填写 专业词（比如技术词）</li>
<li>自己思考这些词，不要只看周围环境的物体。</li>
</ol>
<h3 id="dat算法实现">DAT算法实现</h3>
<ol>
<li>使用Glove预训练模型</li>
<li>选前7个词(一共10个词)， 存在 21个词对（组合）</li>
<li>对21词对， 分别计算词向量的余弦距离，分别乘以100。最终求均值得到DAT得分。</li>
</ol>
<blockquote>
<p>下图是大邓第二次填写得到的DAT得分，第一次只超过了6%的人，这方法第一次准，再测就知道如何提高DAT得分。</p>
</blockquote>
<p><img loading="lazy" src="img/2_pnas_divergent_association_task_result.png" alt=""  />
</p>
<p>DAT得分范围0-200， 得分为0可能是7个有效词之间语义相同，而得分200可能是有效词之间彼此语义完全不相同。实践中，得分大多处于65~90之间，且很少超过100。</p>
<p><img loading="lazy" src="img/pnas_dat_score_low_median_high.jpg" alt=""  />
</p>
<blockquote>
<p>词嵌入技术可以把每个词转化为等长的向量，而不同词语共处于相同的语义空间中。常见的词嵌入技术有word2vec、Glove、flastText等，因为最近有学者在 <strong>替代用途任务</strong>(Alternative Uses Task）中用过Glove算法，本文采用Glove算法。本研究使用的Glove预训练模型来自Common Crawl Corpus项目，该项目拥有数十亿网页文本数据。</p>
<p>为了提供冗余， 只采用 被试者 填写的前7个词作为有效单词(DAT的被试需要填写10个词)。DAT得分是这些词之间的语义距离的平均值，具体计算方法， 7个词两两相关的组合有 42种组合， 选择其中最有可能的 21 个语义组合。</p>
</blockquote>
<br>
<h2 id="四实验">四、实验</h2>
<p>这种发散思维的操作化是基于创造力的联想和执行控制理论。 更高的分数将显示出更大的能力来利用更远程的关联 (3-5) 或抑制过度相关的关联 (2, 7)。</p>
<p>在研究 1 中，我们通过将 DAT 与其他两种创造力测量方法进行比较来检验这一假设：替代用途任务 (15) 和桥接关联差距任务 (36)。
<img loading="lazy" src="img/pnas_dat_aut_algo_valid_num.jpg" alt=""  />
</p>
<p>在研究 2 中，我们测试了这些分数如何随人口统计而变化，以及它们是否与更大数据集中与发散性思维相关的其他测量值相关 (9, 37)。 这些研究评估了语义距离是否可以作为发散思维的可靠指标。
<img loading="lazy" src="img/pnas_dat_gender_age.jpg" alt=""  />
</p>
<br>
<h2 id="五讨论">五、讨论</h2>
<p>研究结果表面， 让被试简单的填写10个不想管单词的任务可以作为 测量发散思维 的可靠衡量标准。在研究中， 将这项任务的表现与已有的两种创造力量表做了比较，具有很高的相关性。</p>
<p>总体而言支持了语义发散性，尽管这种联系背后的确切机制尚不清楚，但在创新力最主要的两个理论，即联想理论或执行理论 的联系网络中衡量网络的范围或效率。</p>
<p><strong>DAT算法表现稳定，方差不随人口统计特征变化出现显著性变化（研究2），可以在跨年龄、跨性别的情况下应用</strong>。</p>
<br>
<h3 id="51-dat的优点">5.1 DAT的优点</h3>
<ul>
<li>操作简单，快捷，客观，节约了大量的人力时间，又能保证客观性。</li>
<li>得分绝对，可比较，可以用于测量不同群体(种族、文化、性别、年龄)的创造力得分。</li>
<li>对被试友好，一般一两分钟即可完成。</li>
</ul>
<h3 id="52-dat的不足">5.2 DAT的不足</h3>
<ul>
<li>创造力有发散性和执行力，发散性负责搜选所有方案集合的规模，而执行力是从方案集中选出最优方案并将其执行。DAT测量的仅仅是发散性思维。</li>
<li>被试可能通过填写稀奇的词语提高DAT得分。</li>
<li>只有短短几分钟，被试可能很难短时间内了解实验规则。</li>
</ul>
<h3 id="53-未来展望">5.3 未来展望</h3>
<p>DAT得分取决于Glove模型、语料库(数据集), 更新词模型或语料库，被试的DAT得分会发生变化。为简单起见，本研究使用免费的预训练模型， 通过一些努力，未来研究者可以对不同时期，不同国家的语料库来训练Glove模型。随着特定单词关联或多或少的联系， 更新的模型将会自动考虑这些变化，这将允许DAT得分跨越文化跨越时代，进行创新力的比较。</p>
<p><br><br></p>
<h2 id="代码">代码</h2>
<p>代码的文档说明请点击 github仓库地址 <a href="https://github.com/jayolson/divergent-association-task">https://github.com/jayolson/divergent-association-task</a> 查看。这里仅粘贴作者源代码，源代码需要配置好才可运行。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">dat</span>

<span class="c1">## 从 https://nlp.stanford.edu/projects/glove/ 下载Glove模型</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">dat</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="s2">&#34;glove.840B.300d.txt&#34;</span><span class="p">,</span> <span class="s2">&#34;words.txt&#34;</span><span class="p">)</span>

<span class="c1"># 验证词语，如输入的是词组，代码会将其转为连线形式的单词</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">validate</span><span class="p">(</span><span class="s2">&#34;cul de sac&#34;</span><span class="p">))</span> 
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">cul-de-sac
</code></pre></div><br>
<p>计算两个词语之间的语义距离</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">distance</span><span class="p">(</span><span class="s2">&#34;cat&#34;</span><span class="p">,</span> <span class="s2">&#34;dog&#34;</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">distance</span><span class="p">(</span><span class="s2">&#34;cat&#34;</span><span class="p">,</span> <span class="s2">&#34;thimble&#34;</span><span class="p">))</span> 
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">0.1983
0.8787
</code></pre></div><br>
<p>计算词对的DAT得分（语义cosine距离*100）</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">dat</span><span class="p">([</span><span class="s2">&#34;cat&#34;</span><span class="p">,</span> <span class="s2">&#34;dog&#34;</span><span class="p">],</span> <span class="mi">2</span><span class="p">))</span> 
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">dat</span><span class="p">([</span><span class="s2">&#34;cat&#34;</span><span class="p">,</span> <span class="s2">&#34;thimble&#34;</span><span class="p">],</span> <span class="mi">2</span><span class="p">))</span> 
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">19.83
87.87
</code></pre></div><br>
<p>假设有三个人分别都填写10个词，选其前7个词作为有效词。有效词如下，</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">low</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&#34;arm&#34;</span><span class="p">,</span> <span class="s2">&#34;eyes&#34;</span><span class="p">,</span> <span class="s2">&#34;feet&#34;</span><span class="p">,</span> <span class="s2">&#34;hand&#34;</span><span class="p">,</span> <span class="s2">&#34;head&#34;</span><span class="p">,</span> <span class="s2">&#34;leg&#34;</span><span class="p">,</span> <span class="s2">&#34;body&#34;</span><span class="p">]</span>
<span class="n">average</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&#34;bag&#34;</span><span class="p">,</span> <span class="s2">&#34;bee&#34;</span><span class="p">,</span> <span class="s2">&#34;burger&#34;</span><span class="p">,</span> <span class="s2">&#34;feast&#34;</span><span class="p">,</span> <span class="s2">&#34;office&#34;</span><span class="p">,</span> <span class="s2">&#34;shoes&#34;</span><span class="p">,</span> <span class="s2">&#34;tree&#34;</span><span class="p">]</span>
<span class="n">high</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&#34;hippo&#34;</span><span class="p">,</span> <span class="s2">&#34;jumper&#34;</span><span class="p">,</span> <span class="s2">&#34;machinery&#34;</span><span class="p">,</span> <span class="s2">&#34;prickle&#34;</span><span class="p">,</span> <span class="s2">&#34;tickets&#34;</span><span class="p">,</span> <span class="s2">&#34;tomato&#34;</span><span class="p">,</span> <span class="s2">&#34;violin&#34;</span><span class="p">]</span>

<span class="c1"># Compute the DAT score (transformed average cosine distance of first 7 valid words)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">dat</span><span class="p">(</span><span class="n">low</span><span class="p">))</span> <span class="c1"># 50</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">dat</span><span class="p">(</span><span class="n">average</span><span class="p">))</span> <span class="c1"># 78</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">dat</span><span class="p">(</span><span class="n">high</span><span class="p">))</span> <span class="c1"># 95</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">50
78
95
</code></pre></div><p>需要注意pnas作者公开的代码只能用在英文，且无法自己训练Glove模型。如果想基于自有数据集（中文、英文），训练自有Glove模型，需要学习</p>
<ul>
<li>如何训练Glove模型</li>
<li>如何导入训练好的Glove模型</li>
<li>如何计算中英文dat得分</li>
</ul>
<p>相关知识点已更新至我的录播课课程 <a href="https://hidadeng.github.io/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></p>
<p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://hidadeng.github.io/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://hidadeng.github.io/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://hidadeng.github.io/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>魔搭 | 中文AI模型开源社区</title>
      <link>https://hidadeng.github.io/blog/2022-11-09-chinese-modelscope-open-source/</link>
      <pubDate>Wed, 09 Nov 2022 00:00:00 +0000</pubDate>
      
      <guid>/blog/2022-11-09-chinese-modelscope-open-source/</guid>
      <description>ModelScope社区成立于2022 年6月，是一个模型开源社区及创新平台，由阿里巴巴达摩院，联合CCF开源发展委员会，共同作为项目发起方。社区联合国内AI领域合作伙伴与高校机构，致力于通过开放的社区合作，构建深度学习相关的模型开源，并开源相关模型服务创新技术，推动模型应用生态的繁荣发展。</description>
      <content:encoded><![CDATA[<h2 id="关于modelscope">关于ModelScope</h2>
<p>ModelScope社区成立于 2022 年 6 月，是一个模型开源社区及创新平台，由阿里巴巴达摩院，联合CCF开源发展委员会，共同作为项目发起方。</p>
<blockquote>
<p>社区联合国内AI领域合作伙伴与高校机构，致力于通过开放的社区合作，构建深度学习相关的模型开源，并开源相关模型服务创新技术，推动模型应用生态的繁荣发展。</p>
</blockquote>
<p>期待ModelScope会有不一样的表现。</p>
<p>与ModelScope类似的网站有</p>
<ul>
<li>国际 huggingface是较早将AI模型开源的网站，用户群体庞大，社区内有丰富的数据集、模型，文档详实。</li>
<li>国内 百度飞桨是国内AI模型开源较好的网站，用户群体较大，更新活跃，但是文档质量。。。</li>
</ul>
<p>目前ModelScope刚刚上线不久，模型和数据集都不怎么多</p>
<p><img loading="lazy" src="img/model_scope_homepage.png" alt=""  />
</p>
<br>
<h2 id="heading"></h2>
<h1 id="名词解释"><strong>名词解释</strong></h1>
<p>ModelScope平台是以模型为中心的模型开源社区，与模型的使用相关，您需要先了解如下概念。</p>
<table>
<thead>
<tr>
<th><strong>基础概念</strong></th>
<th><strong>定义</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>任务</td>
<td>任务（Task）指某一领域具体的应用，以用于完成特定场景的任务。例如图像分类、文本生成、语音识别等，您可根据任务的输入输出找到适合您的应用场景的任务类型，通过任务的筛选来查找您所需的模型。</td>
</tr>
<tr>
<td>模型</td>
<td>模型（Model）是指一个具体的模型实例，包括模型网络结构和相应参数。ModelScope平台提供丰富的模型信息供用户体验与使用。</td>
</tr>
<tr>
<td>模型库</td>
<td>模型库（Modelhub）是指对模型进行存储、版本管理和相关操作的模型服务，用户上传和共享的模型将存储至ModelScope的模型库中，同时用户也可在Model hub中创建属于自己的模型存储库，并沿用平台提供的模型库管理功能进行模型管理。</td>
</tr>
<tr>
<td>数据集</td>
<td>数据集（Dataset）是方便共享及访问的数据集合，可用于算法训练、测试、验证，通常以表格形式出现。按照模态可划分为文本、图像、音频、视频、多模态等。</td>
</tr>
<tr>
<td>数据集库</td>
<td>数据集库（Datasethub）用于集中管理数据，支持模型进行训练、预测等，使各类型数据具备易访问、易管理、易共享的特点。</td>
</tr>
<tr>
<td>ModelScope Library</td>
<td>ModelScope Library是ModelScope平台自研的一套Python Library框架，通过调用特定的方法，用户可以只写短短的几行代码，就可以完成模型的推理、训练和评估等任务，也可以在此基础上快速进行二次开发，实现自己的创新想法。</td>
</tr>
</tbody>
</table>
<br>
<h2 id="一模型探索">一、模型探索</h2>
<p>首先访问平台网址https://www.modelscope.cn/models， 您将看见平台上已有的所有公开模型，根据任务筛选或者关键词搜索可查找您感兴趣的模型。</p>
<p><img loading="lazy" src="img/1-model_explore.png" alt=""  />
</p>
<br>
<h2 id="二环境准备">二、环境准备</h2>
<h3 id="21-本地开发环境">2.1 本地开发环境</h3>
<p>如果您需要在本地运行模型，需要进行相应的环境安装准备，包括：</p>
<ul>
<li><strong>安装python环境</strong>。支持python3，不支持python2，建议3.7版本及以上。我们推荐您使用Anaconda进行安装。</li>
<li><strong>安装深度学习框架</strong>。ModelScope Library目前支持Tensorflow，Pytorch两大深度学习框架进行模型训练、推理。您可根据模型所需的框架选择适合的框架进行安装。</li>
<li><strong>安装ModelScope Library</strong>。我们提供两种安装方式，您可选择适合的方式进行安装。
<ul>
<li>pip安装。ModelScope提供了根据不同领域的安装包，您可根据对应的模型选择所需的安装包。</li>
<li>使用源码安装。</li>
<li>更完整的安装信息参考：环境安装指南。</li>
</ul>
</li>
</ul>
<h3 id="22-在线notebook">2.2 在线Notebook</h3>
<p>若您觉得本地安装较为复杂， ModelScope平台也提供在线的运行环境，您可直接在Notebook中运行，Notebook中提供官方镜像无需自主进行环境安装，更加方便快捷，推荐大家使用！</p>
<p>注意：该功能需要您登录后使用，新用户注册ModelScope账号并完成阿里云账号绑定后即可获得免费算力资源，详情请参阅免费额度说明 。</p>
<p><img loading="lazy" src="img/model_scode_free_online_notebook.png" alt=""  />
</p>
<p><img loading="lazy" src="img/model_scode_free_online_notebook-2.png" alt=""  />
</p>
<br>
<h2 id="三2分钟跑通模型推理">三、2分钟跑通模型推理</h2>
<p>若您准备好本地环境或者已经打开一个Notebook的预装环境实例，则根据下述代码可对该模型进行推理。 使用modelscope pipeline接口只需要两步，同样以上述中文分词模型（damo/nlp_structbert_word-segmentation_chinese-base）为例简单说明：</p>
<p>首先根据task实例化一个pipeline对象</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">modelscope.pipelines</span> <span class="kn">import</span> <span class="n">pipeline</span>
<span class="n">word_segmentation</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span><span class="s1">&#39;word-segmentation&#39;</span><span class="p">,</span><span class="n">model</span><span class="o">=</span><span class="s1">&#39;damo/nlp_structbert_word-segmentation_chinese-base&#39;</span><span class="p">)</span>
</code></pre></div><p>输入数据，拿到结果</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">input_str</span> <span class="o">=</span> <span class="s1">&#39;今天天气不错，适合出去游玩&#39;</span>
<span class="nb">print</span><span class="p">(</span><span class="n">word_segmentation</span><span class="p">(</span><span class="n">input_str</span><span class="p">))</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">{&#39;output&#39;: &#39;今天 天气 不错 ， 适合 出去 游玩&#39;}
</code></pre></div><br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://hidadeng.github.io/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://hidadeng.github.io/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://hidadeng.github.io/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>gdown库 |  从googleDriver下载大体积文件</title>
      <link>https://hidadeng.github.io/blog/2022-10-31-gdown-googledriver/</link>
      <pubDate>Mon, 31 Oct 2022 00:00:00 +0000</pubDate>
      
      <guid>/blog/2022-10-31-gdown-googledriver/</guid>
      <description>如何使用python下载googledriver内的大尺寸文件</description>
      <content:encoded><![CDATA[<p>熟悉IT的同学知道，下载工具有curl和wget。但是这类工具很难成功下载大体积的文件，今天分享的gdown可以帮我们解决这个问题。不过使用该工具的其那题是， 电脑可以科学地上网。</p>
<br>
<h2 id="安装">安装</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">pip3 install gdown
</code></pre></div><br>
<h2 id="使用">使用</h2>
<p>gdown安装后有两种使用方法</p>
<ul>
<li>命令行模式</li>
<li>代码模式</li>
</ul>
<br>
<h3 id="命令行模式">命令行模式</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">$ gdown --help
usage: gdown [-h] [-V] [-O OUTPUT] [-q] [--fuzzy] [--id] [--proxy PROXY]
             [--speed SPEED] [--no-cookies] [--no-check-certificate]
             [--continue] [--folder] [--remaining-ok]
             url_or_id
...

$ # 大文件 (~500MB)
$ gdown https://drive.google.com/uc?id=1l_5RK28JRL19wpT22B-DY9We3TVXnnQQ
$ md5sum fcn8s_from_caffe.npz
256c2a8235c1c65e62e48d3284fbd384
</code></pre></div><br>
<h3 id="代码模式">代码模式</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">gdown</span>

<span class="c1"># 下载 网盘文件</span>
<span class="n">url</span> <span class="o">=</span> <span class="s2">&#34;https://drive.google.com/uc?id=1l_5RK28JRL19wpT22B-DY9We3TVXnnQQ&#34;</span>
<span class="n">output</span> <span class="o">=</span> <span class="s2">&#34;fcn8s_from_caffe.npz&#34;</span>
<span class="n">gdown</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">output</span><span class="p">,</span> <span class="n">quiet</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># 使用文件ID作为文件名</span>
<span class="nb">id</span> <span class="o">=</span> <span class="s2">&#34;0B9P1L--7Wd2vNm9zMTJWOGxobkU&#34;</span>
<span class="n">gdown</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="nb">id</span><span class="o">=</span><span class="nb">id</span><span class="p">,</span> <span class="n">output</span><span class="o">=</span><span class="n">output</span><span class="p">,</span> <span class="n">quiet</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># same as the above, and you can copy-and-paste a URL from Google Drive with fuzzy=True</span>
<span class="n">url</span> <span class="o">=</span> <span class="s2">&#34;https://drive.google.com/file/d/0B9P1L--7Wd2vNm9zMTJWOGxobkU/view?usp=sharing&#34;</span>
<span class="n">gdown</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="n">url</span><span class="p">,</span> <span class="n">output</span><span class="o">=</span><span class="n">output</span><span class="p">,</span> <span class="n">quiet</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">fuzzy</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>


<span class="c1"># 下载 网盘文件夹</span>
<span class="n">url</span> <span class="o">=</span> <span class="s2">&#34;https://drive.google.com/drive/folders/15uNXeRBIhVvZJIhL4yTw4IsStMhUaaxl&#34;</span>
<span class="n">gdown</span><span class="o">.</span><span class="n">download_folder</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">quiet</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">use_cookies</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># 使用文件夹ID作为文件夹名</span>
<span class="nb">id</span> <span class="o">=</span> <span class="s2">&#34;15uNXeRBIhVvZJIhL4yTw4IsStMhUaaxl&#34;</span>
<span class="n">gdown</span><span class="o">.</span><span class="n">download_folder</span><span class="p">(</span><span class="nb">id</span><span class="o">=</span><span class="nb">id</span><span class="p">,</span> <span class="n">quiet</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">use_cookies</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</code></pre></div><br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://hidadeng.github.io/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://hidadeng.github.io/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://hidadeng.github.io/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>Maigret库 | 查询某用户名在各平台网站的使用情况</title>
      <link>https://hidadeng.github.io/blog/2022-10-08-find-sns-account-information-with-maigret/</link>
      <pubDate>Sat, 08 Oct 2022 00:00:00 +0000</pubDate>
      
      <guid>/blog/2022-10-08-find-sns-account-information-with-maigret/</guid>
      <description>Maigret 能检查各网站(应用) 某 **用户名** 是否注册，并从网页收集所有可用信息,  运行过程不需要 API 密钥。目前支持超过 2500 个站点检索（完整列表），默认针对 500 个热门站点按受欢迎程度降序启动搜索。</description>
      <content:encoded><![CDATA[<p>Maigret 能检查各网站(应用) 某 <strong>用户名</strong> 是否注册，并从网页收集所有可用信息,  运行过程不需要 API 密钥。目前支持超过 2500 个站点检索（完整列表），默认针对 500 个热门站点按受欢迎程度降序启动搜索。</p>
<br>
<h2 id="主要功能">主要功能</h2>
<ul>
<li>个人资料页面解析</li>
<li>个人信息提取</li>
<li>其他个人资料链接等。</li>
<li>通过新用户名和找到的其他 id 进行递归搜索</li>
<li>按标签搜索（网站类别、国家/地区）</li>
</ul>
<br>
<h2 id="安装">安装</h2>
<p>命令行中安装maigret包</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">pip3 install maigret
</code></pre></div><br>
<h2 id="使用">使用</h2>
<p>我自己有个账号名是hidadeng，就用hidadeng试试。</p>
<p>为了解用户名hidadeng使用情况，报告结果存储于html和pdf。 在命令行中执行，</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">maigret hidadeng --html --pdf
</code></pre></div><p>命令行运行过程</p>
<p><img loading="lazy" src="img/hidadeng-cmd.png" alt=""  />
</p>
<br>
<h2 id="报告">报告</h2>
<p>maigret查询用户名hidadeng的使用情况、兴趣等结果可以绘制成报告。</p>
<p><a href="report_hidadeng_plain.html">点击查看hidadeng报告</a></p>
<p><img loading="lazy" src="img/hidadeng-report-1.png" alt=""  />
</p>
<p><img loading="lazy" src="img/hidadeng-report-2.png" alt=""  />
</p>
<p>效果挺准的，对hidadeng这个用户兴趣(coding、shopping)拿捏的也挺不错。</p>
<br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://hidadeng.github.io/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://hidadeng.github.io/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://hidadeng.github.io/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>ManagementScience | 使用网络算法识别创新的颠覆性与否</title>
      <link>https://hidadeng.github.io/blog/2022-09-07-management-science-disrupt-science-and-technology/</link>
      <pubDate>Wed, 07 Sep 2022 00:00:00 +0000</pubDate>
      
      <guid>/blog/2022-09-07-management-science-disrupt-science-and-technology/</guid>
      <description>The CD index is a new approach to finding important points in evolving networks. When applied to large-scale data sets like U.S. patent citations, the index is useful for identifying influential innovations and other features of technological change.</description>
      <content:encoded><![CDATA[


<p>颠覆式创新是一个很火的概念，在创新创业、科学学等研究中，每个专利、论文的正文中都会引用关系，而引用关系会构成一个引用网络。</p>
<p>那么创新如何从网络形态进行区分，如何计算网络节点的创新程度，本文列举两篇与此相关的论文，分别是 Management science 和 Science 。</p>
<p><br><br></p>
<div id="文献摘要" class="section level2">
<h2>文献摘要</h2>
<p><strong>Funk, Russell J., and Jason Owen-Smith. “A dynamic network measure of technological change.” <em>Management science</em> 63, no. 3 (2017): 791-817.</strong></p>
<p>该文使用网络分析方法研究技术变革，论文认为 <strong>颠覆性的新发明，通过将发明者的注意力转移到或远离这些发明所依赖的知识，来重塑相互关联的技术网络。即更广的视野或更久远的视角，往往有利于颠覆性创新的产生</strong>。<strong>基于该思路，本文开发了新发明的颠覆性与否的计算指标cdindex</strong>。我们将这些指标应用于大学研究商业化的分析，并发现 <strong>联邦研究资金推动校园产生颠覆性创新，而商业联系会有利于巩固现状的创新</strong>。通过量化新技术，我们提出的指数允许基于专利的创新研究捕捉概念上重要的现象， 这些现象无法通过既定措施检测到。该测量方法提供了支持创新、创业、技术战略、科学政策和社会网络理论研究的理论发展的经验见解。</p>
<blockquote>
<p>Abstract: This article outlines a network approach to the study of technological change. We propose that new inventions reshape networks of interlinked technologies by shifting inventors’ attention to or away from the knowledge on which those inventions build. Using this approach, we develop novel indexes of the extent to which a new invention consolidates or destabilizes existing technology streams. We apply these indexes in analyses of university research commercialization and ﬁnd that, although federal research funding pushes campuses to create inventions that are more destabilizing, deeper commercial ties lead them to produce technologies that consolidate the status quo. By quantifying the eﬀects that new technologies have on their predecessors, the indexes we propose allow patent-based studies of innovation to capture conceptually important phenomena that are not detectable with established measures. The measurement approach presented here oﬀers empirical insights that support theoretical development in studies of innovation, entrepreneurship, technology strategy, science policy, and social network theory.</p>
</blockquote>
<p><br></p>
<p><strong>Wu, Lingfei, Dashun Wang, and James A. Evans. “Large teams develop and small teams disrupt science and technology.” Nature 566, no. 7744 (2019): 378-382.</strong></p>
<p>当今科学和技术最普遍的趋势之一是各个领域的大型团队的增长，因为孤独的研究人员和小型团队的流行程度正在减少 。团队规模的增加归因于科学活动的专业化、通信技术的改进 或需要跨学科解决方案的现代问题的复杂性。团队规模的这种转变引发了一个问题，即大团队所产生的科技特征是否以及如何不同于小团队。分析了 1954-2014 年期间超过 6500 万篇论文、专利和软件产品，证明在此期间，<strong>较小的团队倾向于将拉长到更大的时间尺度，借鉴过去，用新的想法和机会来颠覆科学和技术；而较大的团队倾向于聚焦于当前流行的，完善当前现有的</strong>。不论团队大小，均对于蓬勃发展的科学技术生态至关重要，并表明，为实现这一目标，科学政策应旨在支持团队规模的多样性。</p>
<blockquote>
<p>Abstract: One of the most universal trends in science and technology today is the growth of large teams in all areas, as solitary researchers and small teams diminish in prevalence. Increases in team size have been attributed to the specialization of scientific activities,
improvements in communication technology, or the complexity
of modern problems that require interdisciplinary solutions.This shift in team size raises the question of whether and how the character of the science and technology produced by large teams differs from that of small teams. Here we analyse more than 65 million papers, patents and software products that span the period 1954–2014, and demonstrate that across this period smaller teams have tended to disrupt science and technology with new ideas and opportunities, whereas larger teams have tended to develop existing ones. Work from larger teams builds on morerecent and popular developments, and attention to their work comes
immediately. By contrast, contributions by smaller teams search more deeply into the past, are viewed as disruptive to science and technology and succeed further into the future—if at all. Observed differences between small and large teams are magnified for higherimpact work, with small teams known for disruptive work and large teams for developing work. Differences in topic and research design
account for a small part of the relationship between team size and disruption; most of the effect occurs at the level of the individual, as people move between smaller and larger teams. These results demonstrate that both small and large teams are essential to a flourishing ecology of science and technology, and suggest that, to achieve this, science policies should aim to support a diversity of team sizes.</p>
</blockquote>
<p><br><br></p>
</div>
<div id="算法对比" class="section level2">
<h2>算法对比</h2>
<p>我没阅读两篇论文，仅就颠覆性与否的计算方法和图例，感觉算法实现差不多。</p>
<div class="figure">
<img src="img/cdindex-managent_science_2017.png" alt="" />
<p class="caption">上图为2017年Management Science的插图</p>
</div>
<p><br></p>
<div class="figure">
<img src="img/disruption_nature_2019.png" alt="" />
<p class="caption">上图为2019年Nature的插图</p>
</div>
<p><br><br></p>
</div>
<div id="代码数据" class="section level2">
<h2>代码数据</h2>
<p>下面分别为Management2017和Nature2019的主页，均含数据和代码。</p>
<p><a href="http://russellfunk.org/cdindex/"><img src="img/cdindex-homepage.png" /></a></p>
<p><br></p>
<p><a href="https://lingfeiwu.github.io/smallTeams/"><img src="img/nature2019-disrupt-homepage.png" /></a></p>
<p><br><br></p>
</div>
<div id="算法实现" class="section level2">
<h2>算法实现</h2>
<p>按照时间优先原则，本文就只分享Management2017论文作者Funk, Russell开源了cdindex库 (开发语言C和Python) ，安装</p>
<p><br></p>
<pre><code>pip3 install cdindex</code></pre>
<p>将Management2017 cdindex算法图 标注为如下图， 下图中左右两个网络节点是相同的，只需构造一套节点，两套边数据即可完成实验。</p>
<p><img src="img/cdindex-managent_science_2017_demo.png" /></p>
<p><br></p>
<p>我们就直接上代码</p>
<pre class="python"><code>import cdindex
import datetime

#节点，理解为专利号或者论文doi号；同时节点有先后时间属性
vertices = [{&quot;name&quot;: &quot;x1&quot;, &quot;time&quot;: datetime.datetime(1990, 1, 1)},
           {&quot;name&quot;: &quot;x2&quot;, &quot;time&quot;: datetime.datetime(1990, 1, 1)},
           {&quot;name&quot;: &quot;x3&quot;, &quot;time&quot;: datetime.datetime(1990, 1, 1)},
           {&quot;name&quot;: &quot;x4&quot;, &quot;time&quot;: datetime.datetime(1990, 1, 1)},
        
           {&quot;name&quot;: &quot;y&quot;, &quot;time&quot;: datetime.datetime(1991, 1, 1)},
          
           {&quot;name&quot;: &quot;z1&quot;, &quot;time&quot;: datetime.datetime(1995, 1, 1)},
           {&quot;name&quot;: &quot;z2&quot;, &quot;time&quot;: datetime.datetime(1995, 1, 1)},
           {&quot;name&quot;: &quot;z3&quot;, &quot;time&quot;: datetime.datetime(1995, 1, 1)},
           {&quot;name&quot;: &quot;z4&quot;, &quot;time&quot;: datetime.datetime(1995, 1, 1)},
           {&quot;name&quot;: &quot;z5&quot;, &quot;time&quot;: datetime.datetime(1995, 1, 1)},
           {&quot;name&quot;: &quot;z6&quot;, &quot;time&quot;: datetime.datetime(1995, 1, 1)}]
           
    
#edges_1边关系
#edges_1中的y为颠覆型
edges_1 = [{&quot;source&quot;: &quot;z1&quot;, &quot;target&quot;: &quot;y&quot;},
           {&quot;source&quot;: &quot;z2&quot;, &quot;target&quot;: &quot;y&quot;},
           {&quot;source&quot;: &quot;z3&quot;, &quot;target&quot;: &quot;y&quot;},
           {&quot;source&quot;: &quot;z4&quot;, &quot;target&quot;: &quot;y&quot;},
           {&quot;source&quot;: &quot;z5&quot;, &quot;target&quot;: &quot;y&quot;},
           {&quot;source&quot;: &quot;z6&quot;, &quot;target&quot;: &quot;y&quot;},
           
           {&quot;source&quot;: &quot;y&quot;, &quot;target&quot;: &quot;x1&quot;},
           {&quot;source&quot;: &quot;y&quot;, &quot;target&quot;: &quot;x2&quot;},
           {&quot;source&quot;: &quot;y&quot;, &quot;target&quot;: &quot;x3&quot;},
           {&quot;source&quot;: &quot;y&quot;, &quot;target&quot;: &quot;x4&quot;}]


#edges_2边关系 
#edges_2中的y为巩固型
edges_2 = [{&quot;source&quot;: &quot;z1&quot;, &quot;target&quot;: &quot;y&quot;},
           {&quot;source&quot;: &quot;z2&quot;, &quot;target&quot;: &quot;y&quot;},
           {&quot;source&quot;: &quot;z3&quot;, &quot;target&quot;: &quot;y&quot;},
           {&quot;source&quot;: &quot;z4&quot;, &quot;target&quot;: &quot;y&quot;},
           {&quot;source&quot;: &quot;z5&quot;, &quot;target&quot;: &quot;y&quot;},
           {&quot;source&quot;: &quot;z6&quot;, &quot;target&quot;: &quot;y&quot;},
           
           {&quot;source&quot;: &quot;y&quot;, &quot;target&quot;: &quot;x1&quot;},
           {&quot;source&quot;: &quot;y&quot;, &quot;target&quot;: &quot;x2&quot;},
           {&quot;source&quot;: &quot;y&quot;, &quot;target&quot;: &quot;x3&quot;},
           {&quot;source&quot;: &quot;y&quot;, &quot;target&quot;: &quot;x4&quot;},
          
          {&quot;source&quot;: &quot;z1&quot;, &quot;target&quot;: &quot;x1&quot;},
          {&quot;source&quot;: &quot;z2&quot;, &quot;target&quot;: &quot;x1&quot;},
          {&quot;source&quot;: &quot;z3&quot;, &quot;target&quot;: &quot;x2&quot;},
           
          {&quot;source&quot;: &quot;z4&quot;, &quot;target&quot;: &quot;x3&quot;},
          {&quot;source&quot;: &quot;z5&quot;, &quot;target&quot;: &quot;x3&quot;},
          {&quot;source&quot;: &quot;z5&quot;, &quot;target&quot;: &quot;x4&quot;},
          {&quot;source&quot;: &quot;z6&quot;, &quot;target&quot;: &quot;x4&quot;}]



# 构建两个网络
graph1 = cdindex.Graph() #颠覆型
graph2 = cdindex.Graph() #发展型

# 添加节点
for vertex in vertices:
    graph1.add_vertex(vertex[&quot;name&quot;], cdindex.timestamp_from_datetime(vertex[&quot;time&quot;]))
    graph2.add_vertex(vertex[&quot;name&quot;], cdindex.timestamp_from_datetime(vertex[&quot;time&quot;]))

# 添加引用关系
for edge in edges_1:
    graph1.add_edge(edge[&quot;source&quot;], edge[&quot;target&quot;])
for edge in edges_2:
    graph2.add_edge(edge[&quot;source&quot;], edge[&quot;target&quot;])
    
    
#y研究发布后1825天内，引用y的论文(专利)列入网络。
t_delta = int(datetime.timedelta(days=1825).total_seconds())

#计算cdindex得分
score1 = graph1.cdindex(&quot;y&quot;, t_delta)
score2 = graph2.cdindex(&quot;y&quot;, t_delta)

print(&#39;左侧-网络中的y节点的cdinex得分: {}, 节点y 为颠覆性创新&#39;.format(score1))</code></pre>
<pre><code>## 左侧-网络中的y节点的cdinex得分: 1.0, 节点y 为颠覆性创新</code></pre>
<p><br></p>
<pre class="python"><code>print(&#39;右侧-网络中的y节点的cdinex得分: {}, 节点y 为发展性创新&#39;.format(score2))</code></pre>
<pre><code>## 右侧-网络中的y节点的cdinex得分: -1.0, 节点y 为发展性创新</code></pre>
<p><br><br></p>
</div>
<div id="cdindex" class="section level2">
<h2>cdindex</h2>
<p>对比Python的结果，与论文计算过程，完全一致。cdindex内部实现我不太熟悉，如果想了解cdindex内部实现，可前往 <a href="https://github.com/russellfunk/cdindex" class="uri">https://github.com/russellfunk/cdindex</a> 阅读cdindex库的源码。
<img src="img/cdindex-managent_science_2017.png" /></p>
</div>
]]></content:encoded>
    </item>
    
    <item>
      <title>PyEcharts库 | 绘制社交关系网络图</title>
      <link>https://hidadeng.github.io/blog/pyecharts_graph_vis/</link>
      <pubDate>Sat, 07 May 2022 10:40:10 +0600</pubDate>
      
      <guid>/blog/pyecharts_graph_vis/</guid>
      <description>使用pyecharts绘制社交关系网络图</description>
      <content:encoded><![CDATA[<p>使用pyecharts绘制社交网络关系图，直接上代码。</p>
<h2 id="代码">代码</h2>
<p><a href="pyecharts_graph_vis_code.zip">点击下载代码</a></p>
<br>
<h2 id="base">base</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">pyecharts</span> <span class="kn">import</span> <span class="n">options</span> <span class="k">as</span> <span class="n">opts</span>
<span class="kn">from</span> <span class="nn">pyecharts.charts</span> <span class="kn">import</span> <span class="n">Graph</span>

<span class="n">nodes</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">{</span><span class="s2">&#34;name&#34;</span><span class="p">:</span> <span class="s2">&#34;结点1&#34;</span><span class="p">,</span> <span class="s2">&#34;symbolSize&#34;</span><span class="p">:</span> <span class="mi">10</span><span class="p">},</span>
    <span class="p">{</span><span class="s2">&#34;name&#34;</span><span class="p">:</span> <span class="s2">&#34;结点2&#34;</span><span class="p">,</span> <span class="s2">&#34;symbolSize&#34;</span><span class="p">:</span> <span class="mi">20</span><span class="p">},</span>
    <span class="p">{</span><span class="s2">&#34;name&#34;</span><span class="p">:</span> <span class="s2">&#34;结点3&#34;</span><span class="p">,</span> <span class="s2">&#34;symbolSize&#34;</span><span class="p">:</span> <span class="mi">30</span><span class="p">},</span>
    <span class="p">{</span><span class="s2">&#34;name&#34;</span><span class="p">:</span> <span class="s2">&#34;结点4&#34;</span><span class="p">,</span> <span class="s2">&#34;symbolSize&#34;</span><span class="p">:</span> <span class="mi">40</span><span class="p">},</span>
    <span class="p">{</span><span class="s2">&#34;name&#34;</span><span class="p">:</span> <span class="s2">&#34;结点5&#34;</span><span class="p">,</span> <span class="s2">&#34;symbolSize&#34;</span><span class="p">:</span> <span class="mi">50</span><span class="p">},</span>
    <span class="p">{</span><span class="s2">&#34;name&#34;</span><span class="p">:</span> <span class="s2">&#34;结点6&#34;</span><span class="p">,</span> <span class="s2">&#34;symbolSize&#34;</span><span class="p">:</span> <span class="mi">40</span><span class="p">},</span>
    <span class="p">{</span><span class="s2">&#34;name&#34;</span><span class="p">:</span> <span class="s2">&#34;结点7&#34;</span><span class="p">,</span> <span class="s2">&#34;symbolSize&#34;</span><span class="p">:</span> <span class="mi">30</span><span class="p">},</span>
    <span class="p">{</span><span class="s2">&#34;name&#34;</span><span class="p">:</span> <span class="s2">&#34;结点8&#34;</span><span class="p">,</span> <span class="s2">&#34;symbolSize&#34;</span><span class="p">:</span> <span class="mi">20</span><span class="p">},</span>
<span class="p">]</span>
<span class="n">links</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">nodes</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">nodes</span><span class="p">:</span>
        <span class="n">links</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="s2">&#34;source&#34;</span><span class="p">:</span> <span class="n">i</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&#34;name&#34;</span><span class="p">),</span> <span class="s2">&#34;target&#34;</span><span class="p">:</span> <span class="n">j</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&#34;name&#34;</span><span class="p">)})</span>

        
<span class="p">(</span>
    <span class="n">Graph</span><span class="p">()</span>
    <span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="s2">&#34;&#34;</span><span class="p">,</span> <span class="n">nodes</span><span class="p">,</span> <span class="n">links</span><span class="p">,</span> <span class="n">repulsion</span><span class="o">=</span><span class="mi">8000</span><span class="p">)</span>
    <span class="o">.</span><span class="n">set_global_opts</span><span class="p">(</span><span class="n">title_opts</span><span class="o">=</span><span class="n">opts</span><span class="o">.</span><span class="n">TitleOpts</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s2">&#34;Graph-基本示例&#34;</span><span class="p">))</span>
    <span class="o">.</span><span class="n">render</span><span class="p">(</span><span class="s2">&#34;graph_base.html&#34;</span><span class="p">)</span>
<span class="p">)</span>
</code></pre></div><p>Run</p>
<p><a href="graph_base.html">graph_base</a></p>
<p><img loading="lazy" src="img/base.png" alt=""  />
</p>
<br>
<h2 id="weibo">weibo</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">json</span>
<span class="kn">from</span> <span class="nn">pyecharts</span> <span class="kn">import</span> <span class="n">options</span> <span class="k">as</span> <span class="n">opts</span>
<span class="kn">from</span> <span class="nn">pyecharts.charts</span> <span class="kn">import</span> <span class="n">Graph</span>

<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&#34;data/weibo.json&#34;</span><span class="p">,</span> <span class="s2">&#34;r&#34;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s2">&#34;utf-8&#34;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">j</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
    <span class="n">nodes</span><span class="p">,</span> <span class="n">links</span><span class="p">,</span> <span class="n">categories</span><span class="p">,</span> <span class="n">cont</span><span class="p">,</span> <span class="n">mid</span><span class="p">,</span> <span class="n">userl</span> <span class="o">=</span> <span class="n">j</span>


<span class="p">(</span>
    <span class="n">Graph</span><span class="p">()</span>
    <span class="o">.</span><span class="n">add</span><span class="p">(</span>
        <span class="s2">&#34;&#34;</span><span class="p">,</span>
        <span class="n">nodes</span><span class="p">,</span>
        <span class="n">links</span><span class="p">,</span>
        <span class="n">categories</span><span class="p">,</span>
        <span class="n">repulsion</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
        <span class="n">linestyle_opts</span><span class="o">=</span><span class="n">opts</span><span class="o">.</span><span class="n">LineStyleOpts</span><span class="p">(</span><span class="n">curve</span><span class="o">=</span><span class="mf">0.2</span><span class="p">),</span>
        <span class="n">label_opts</span><span class="o">=</span><span class="n">opts</span><span class="o">.</span><span class="n">LabelOpts</span><span class="p">(</span><span class="n">is_show</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
    <span class="p">)</span>
    <span class="o">.</span><span class="n">set_global_opts</span><span class="p">(</span>
        <span class="n">legend_opts</span><span class="o">=</span><span class="n">opts</span><span class="o">.</span><span class="n">LegendOpts</span><span class="p">(</span><span class="n">is_show</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
        <span class="n">title_opts</span><span class="o">=</span><span class="n">opts</span><span class="o">.</span><span class="n">TitleOpts</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s2">&#34;Graph-微博转发关系图&#34;</span><span class="p">),</span>
    <span class="p">)</span>
    <span class="o">.</span><span class="n">render</span><span class="p">(</span><span class="s2">&#34;graph_weibo.html&#34;</span><span class="p">)</span>
<span class="p">)</span>
</code></pre></div><p>Run</p>
<p><a href="graph_weibo.html">graph_weibo</a></p>
<p><img loading="lazy" src="img/weibo.png" alt=""  />
</p>
<br>
<h2 id="npm">npm</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pyecharts.options</span> <span class="k">as</span> <span class="nn">opts</span>
<span class="kn">from</span> <span class="nn">pyecharts.charts</span> <span class="kn">import</span> <span class="n">Graph</span>

<span class="s2">&#34;&#34;&#34;
</span><span class="s2">Gallery 使用 pyecharts 1.1.0
</span><span class="s2">参考地址: https://echarts.apache.org/examples/editor.html?c=graph-npm
</span><span class="s2">
</span><span class="s2">目前无法实现的功能:
</span><span class="s2">
</span><span class="s2">1、暂无
</span><span class="s2">&#34;&#34;&#34;</span>




<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&#34;data/npmdepgraph.min10.json&#34;</span><span class="p">,</span> <span class="s2">&#34;r&#34;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s2">&#34;utf-8&#34;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>

    
<span class="n">nodes</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">{</span>
        <span class="s2">&#34;x&#34;</span><span class="p">:</span> <span class="n">node</span><span class="p">[</span><span class="s2">&#34;x&#34;</span><span class="p">],</span>
        <span class="s2">&#34;y&#34;</span><span class="p">:</span> <span class="n">node</span><span class="p">[</span><span class="s2">&#34;y&#34;</span><span class="p">],</span>
        <span class="s2">&#34;id&#34;</span><span class="p">:</span> <span class="n">node</span><span class="p">[</span><span class="s2">&#34;id&#34;</span><span class="p">],</span>
        <span class="s2">&#34;name&#34;</span><span class="p">:</span> <span class="n">node</span><span class="p">[</span><span class="s2">&#34;label&#34;</span><span class="p">],</span>
        <span class="s2">&#34;symbolSize&#34;</span><span class="p">:</span> <span class="n">node</span><span class="p">[</span><span class="s2">&#34;size&#34;</span><span class="p">],</span>
        <span class="s2">&#34;itemStyle&#34;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&#34;normal&#34;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&#34;color&#34;</span><span class="p">:</span> <span class="n">node</span><span class="p">[</span><span class="s2">&#34;color&#34;</span><span class="p">]}},</span>
    <span class="p">}</span>
    <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">data</span><span class="p">[</span><span class="s2">&#34;nodes&#34;</span><span class="p">]</span>
<span class="p">]</span>

<span class="n">edges</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">{</span><span class="s2">&#34;source&#34;</span><span class="p">:</span> <span class="n">edge</span><span class="p">[</span><span class="s2">&#34;sourceID&#34;</span><span class="p">],</span> <span class="s2">&#34;target&#34;</span><span class="p">:</span> <span class="n">edge</span><span class="p">[</span><span class="s2">&#34;targetID&#34;</span><span class="p">]}</span> <span class="k">for</span> <span class="n">edge</span> <span class="ow">in</span> <span class="n">data</span><span class="p">[</span><span class="s2">&#34;edges&#34;</span><span class="p">]</span>
<span class="p">]</span>



<span class="p">(</span>
    <span class="n">Graph</span><span class="p">(</span><span class="n">init_opts</span><span class="o">=</span><span class="n">opts</span><span class="o">.</span><span class="n">InitOpts</span><span class="p">(</span><span class="n">width</span><span class="o">=</span><span class="s2">&#34;1600px&#34;</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="s2">&#34;800px&#34;</span><span class="p">))</span>
    <span class="o">.</span><span class="n">add</span><span class="p">(</span>
        <span class="n">series_name</span><span class="o">=</span><span class="s2">&#34;&#34;</span><span class="p">,</span>
        <span class="n">nodes</span><span class="o">=</span><span class="n">nodes</span><span class="p">,</span>
        <span class="n">links</span><span class="o">=</span><span class="n">edges</span><span class="p">,</span>
        <span class="n">layout</span><span class="o">=</span><span class="s2">&#34;none&#34;</span><span class="p">,</span>
        <span class="n">is_roam</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">is_focusnode</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">label_opts</span><span class="o">=</span><span class="n">opts</span><span class="o">.</span><span class="n">LabelOpts</span><span class="p">(</span><span class="n">is_show</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
        <span class="n">linestyle_opts</span><span class="o">=</span><span class="n">opts</span><span class="o">.</span><span class="n">LineStyleOpts</span><span class="p">(</span><span class="n">width</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">curve</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">opacity</span><span class="o">=</span><span class="mf">0.7</span><span class="p">),</span>
    <span class="p">)</span>
    <span class="o">.</span><span class="n">set_global_opts</span><span class="p">(</span><span class="n">title_opts</span><span class="o">=</span><span class="n">opts</span><span class="o">.</span><span class="n">TitleOpts</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s2">&#34;NPM Dependencies&#34;</span><span class="p">))</span>
    <span class="o">.</span><span class="n">render</span><span class="p">(</span><span class="s2">&#34;npm_dependencies.html&#34;</span><span class="p">)</span>
<span class="p">)</span>
</code></pre></div><p>Run</p>
<p><a href="npm_dependencies.html">npm_dependencies</a></p>
<p><img loading="lazy" src="img/npm.png" alt=""  />
</p>
<br>
<br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://hidadeng.github.io/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://hidadeng.github.io/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://hidadeng.github.io/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>SimpleTransformers库 | 使用BERT实现文本向量化</title>
      <link>https://hidadeng.github.io/blog/simple_transformer/</link>
      <pubDate>Thu, 05 May 2022 10:40:10 +0600</pubDate>
      
      <guid>/blog/simple_transformer/</guid>
      <description>基于BERT预训练模型，对文本进行向量化</description>
      <content:encoded><![CDATA[<p><code>Simple Transformers</code> 库基于 HuggingFace 的 <a href="https://github.com/huggingface/transformers">Transformers</a> 库，可让您快速训练和评估 Transformer 模型， <strong>初始化</strong>、<strong>训练</strong>和<strong>评估</strong>模型只需要 3 行代码。</p>
<h2 id="安装">安装</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">pip3 install simpletransformers
</code></pre></div><p><strong>Simple Transformer</strong> 模型在构建时考虑了特定的自然语言处理 (NLP) 任务。 每个这样的模型都配备了旨在最适合它们打算执行的任务的特性和功能。 使用 Simple Transformers 模型的高级过程遵循相同的模式。</p>
<ol>
<li>初始化一个特定于任务的模型
2.用<code>train_model()</code>训练模型</li>
<li>使用 <code>eval_model()</code> 评估模型</li>
<li>使用 <code>predict()</code> 对（未标记的）数据进行预测</li>
</ol>
<p>但是，不同模型之间存在必要的差异，以确保它们非常适合其预期任务。 关键差异通常是输入/输出数据格式和任何任务特定功能/配置选项的差异。 这些都可以在每个任务的文档部分中找到。</p>
<p>当前实现的特定于任务的“Simple Transformer”模型及其任务如下所示。</p>
<table>
<thead>
<tr>
<th>Task</th>
<th>Model</th>
</tr>
</thead>
<tbody>
<tr>
<td>Binary and multi-class text classification文本二分类、多分类</td>
<td><code>ClassificationModel</code></td>
</tr>
<tr>
<td>Conversational AI (chatbot training)对话机器人训练</td>
<td><code>ConvAIModel</code></td>
</tr>
<tr>
<td>Language generation语言生成</td>
<td><code>LanguageGenerationModel</code></td>
</tr>
<tr>
<td>Language model training/fine-tuning语言模型训练、微调</td>
<td><code>LanguageModelingModel</code></td>
</tr>
<tr>
<td>Multi-label text classification多类别文本分类</td>
<td><code>MultiLabelClassificationModel</code></td>
</tr>
<tr>
<td>Multi-modal classification (text and image data combined)多模态分类</td>
<td><code>MultiModalClassificationModel</code></td>
</tr>
<tr>
<td>Named entity recognition命名实体识别</td>
<td><code>NERModel</code></td>
</tr>
<tr>
<td>Question answering问答</td>
<td><code>QuestionAnsweringModel</code></td>
</tr>
<tr>
<td>Regression回归</td>
<td><code>ClassificationModel</code></td>
</tr>
<tr>
<td>Sentence-pair classification句对分类</td>
<td><code>ClassificationModel</code></td>
</tr>
<tr>
<td><strong>Text Representation Generation文本表征生成</strong></td>
<td><strong>RepresentationModel</strong></td>
</tr>
<tr>
<td>Document Retrieval文档抽取</td>
<td><code>RetrievalModel</code></td>
</tr>
</tbody>
</table>
<ul>
<li><strong>有关如何使用这些模型的更多信息，请参阅 <a href="https://simpletransformers.ai/">docs</a> 中的相关部分。</strong></li>
<li>示例脚本可以在 <a href="https://github.com/ThilinaRajapakse/simpletransformers/tree/master/examples">examples</a> 目录中找到。</li>
<li>有关项目的最新更改，请参阅 <a href="https://github.com/ThilinaRajapakse/simpletransformers/blob/master/CHANGELOG.md">Changelog</a>。</li>
</ul>
<h2 id="生成句子嵌入">生成句子嵌入</h2>
<p>使用huggingface网站https://huggingface.co/ 提供的模型</p>
<ul>
<li>英文模型 bert-base-uncased</li>
<li>中文模型 bert-base-chinese</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">simpletransformers.language_representation</span> <span class="kn">import</span> <span class="n">RepresentationModel</span>
<span class="n">sentences</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&#34;Machine Learning and Deep Learning are part of AI&#34;</span><span class="p">,</span> 
             <span class="s2">&#34;Data Science will excel in future&#34;</span><span class="p">]</span> <span class="c1">#it should always be a list</span>


<span class="n">model</span> <span class="o">=</span> <span class="n">RepresentationModel</span><span class="p">(</span>
        <span class="n">model_type</span><span class="o">=</span><span class="s2">&#34;bert&#34;</span><span class="p">,</span>
        <span class="n">model_name</span><span class="o">=</span><span class="s2">&#34;bert-base-uncased&#34;</span><span class="p">,</span> <span class="c1">#英文模型</span>
        <span class="n">use_cuda</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">sentence_vectors</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">encode_sentences</span><span class="p">(</span><span class="n">sentences</span><span class="p">,</span> <span class="n">combine_strategy</span><span class="o">=</span><span class="s2">&#34;mean&#34;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">sentence_vectors</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">sentence_vectors</span><span class="p">)</span>

</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">(2, 768)

array([[-0.10800573,  0.19615649, -0.10756102, ..., -0.26362818,
         0.56403756, -0.30985302],
       [ 0.0201617 , -0.19381572,  0.4360792 , ..., -0.2979438 ,
         0.04984972, -0.702381  ]], dtype=float32)
</code></pre></div><br>
<br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://hidadeng.github.io/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://hidadeng.github.io/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://hidadeng.github.io/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
  </channel>
</rss>
