<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>第三方库 on 大邓和他的PYTHON</title>
    <link>/tags/%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93/</link>
    <description>Recent content in 第三方库 on 大邓和他的PYTHON</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Mon, 24 Mar 2025 00:00:00 +0000</lastBuildDate><atom:link href="/tags/%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>资源 | 不同版本Chrome适配的chromedriver下载链接</title>
      <link>https://textdata.cn/blog/2025-03-24-setting-chromedriver-environment-for-selenium/</link>
      <pubDate>Mon, 24 Mar 2025 00:00:00 +0000</pubDate>
      
      <guid>/blog/2025-03-24-setting-chromedriver-environment-for-selenium/</guid>
      <description>&lt;h2 id=&#34;一chrome版本号&#34;&gt;一、Chrome版本号&lt;/h2&gt;
&lt;p&gt;将Chrome的版本号划分为&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;古代版本 70.0.3538.16 ~ 114.0.5735.90&lt;/li&gt;
&lt;li&gt;现代版本 127.0.6533.88 ~ 134.0.6998.165&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;二chromedriver下载&#34;&gt;二、chromedriver下载&lt;/h2&gt;
&lt;h3 id=&#34;21-古代版本&#34;&gt;2.1 古代版本&lt;/h3&gt;
&lt;p&gt;Chrome版本号在 70.0.3538.16 ~ 114.0.5735.90 之间的， 可以通过如下方式下载&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;平台      下载链接
https://chromedriver.storage.googleapis.com/index.html

Linux64   https://chromedriver.storage.googleapis.com/{版本号}/chromedriver_linux64.zip
Mac       https://chromedriver.storage.googleapis.com/{版本号}/chromedriver_mac64.zip
Win32     https://chromedriver.storage.googleapis.com/{版本号}/chromedriver_win32.zip
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h3 id=&#34;22-近代版本&#34;&gt;2.2 近代版本&lt;/h3&gt;
&lt;p&gt;Chrome版本号在 115.0.5739.0 ~ 127.0.6533.72 之间的， 可以通过如下方式下载chromedriver&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://chromedriver.storage.googleapis.com/115.0.5739.0/chromedriver_linux64.zip&#34;&gt;https://chromedriver.storage.googleapis.com/115.0.5739.0/chromedriver_linux64.zip&lt;/a&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;平台          下载链接

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h3 id=&#34;23-现代版本&#34;&gt;2.3 现代版本&lt;/h3&gt;
&lt;p&gt;Chrome版本号在 127.0.6533.88 ~ 134.0.6998.165 之间的， 可以通过如下方式下载chromedriver&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;
平台          下载链接
Linux64	      https://storage.googleapis.com/chrome-for-testing-public/{版本号}/linux64/chromedriver-linux64.zip

Mac(M芯片)	   https://storage.googleapis.com/chrome-for-testing-public/{版本号}/mac-arm64/chromedriver-mac-arm64.zip

Mac            https://storage.googleapis.com/chrome-for-testing-public/{版本号}/mac-x64/chromedriver-mac-x64.zip

win32	       https://storage.googleapis.com/chrome-for-testing-public/{版本号}/win32/chromedriver-win32.zip

win64	       https://storage.googleapis.com/chrome-for-testing-public/{版本号}/win64/chromedriver-win64.zip
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;p&gt;此外， 更新的开发版可以在此处 &lt;a href=&#34;https://googlechromelabs.github.io/chrome-for-testing/#stable&#34;&gt;https://googlechromelabs.github.io/chrome-for-testing/#stable&lt;/a&gt; 找到下载资源&lt;/p&gt;
&lt;br&gt;
</description>
      <content:encoded><![CDATA[<h2 id="一chrome版本号">一、Chrome版本号</h2>
<p>将Chrome的版本号划分为</p>
<ul>
<li>古代版本 70.0.3538.16 ~ 114.0.5735.90</li>
<li>现代版本 127.0.6533.88 ~ 134.0.6998.165</li>
</ul>
<p><br><br></p>
<h2 id="二chromedriver下载">二、chromedriver下载</h2>
<h3 id="21-古代版本">2.1 古代版本</h3>
<p>Chrome版本号在 70.0.3538.16 ~ 114.0.5735.90 之间的， 可以通过如下方式下载</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">平台      下载链接
https://chromedriver.storage.googleapis.com/index.html

Linux64   https://chromedriver.storage.googleapis.com/{版本号}/chromedriver_linux64.zip
Mac       https://chromedriver.storage.googleapis.com/{版本号}/chromedriver_mac64.zip
Win32     https://chromedriver.storage.googleapis.com/{版本号}/chromedriver_win32.zip
</code></pre></div><br>
<h3 id="22-近代版本">2.2 近代版本</h3>
<p>Chrome版本号在 115.0.5739.0 ~ 127.0.6533.72 之间的， 可以通过如下方式下载chromedriver</p>
<p><a href="https://chromedriver.storage.googleapis.com/115.0.5739.0/chromedriver_linux64.zip">https://chromedriver.storage.googleapis.com/115.0.5739.0/chromedriver_linux64.zip</a></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">平台          下载链接

</code></pre></div><br>
<h3 id="23-现代版本">2.3 现代版本</h3>
<p>Chrome版本号在 127.0.6533.88 ~ 134.0.6998.165 之间的， 可以通过如下方式下载chromedriver</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">
平台          下载链接
Linux64	      https://storage.googleapis.com/chrome-for-testing-public/{版本号}/linux64/chromedriver-linux64.zip

Mac(M芯片)	   https://storage.googleapis.com/chrome-for-testing-public/{版本号}/mac-arm64/chromedriver-mac-arm64.zip

Mac            https://storage.googleapis.com/chrome-for-testing-public/{版本号}/mac-x64/chromedriver-mac-x64.zip

win32	       https://storage.googleapis.com/chrome-for-testing-public/{版本号}/win32/chromedriver-win32.zip

win64	       https://storage.googleapis.com/chrome-for-testing-public/{版本号}/win64/chromedriver-win64.zip
</code></pre></div><br>
<p>此外， 更新的开发版可以在此处 <a href="https://googlechromelabs.github.io/chrome-for-testing/#stable">https://googlechromelabs.github.io/chrome-for-testing/#stable</a> 找到下载资源</p>
<br>
]]></content:encoded>
    </item>
    
    <item>
      <title>推荐 | 文本分析库cntext2.x使用手册</title>
      <link>https://textdata.cn/blog/2024-04-27-cntext2x-usage-tutorial/</link>
      <pubDate>Fri, 14 Mar 2025 00:00:00 +0000</pubDate>
      
      <guid>/blog/2024-04-27-cntext2x-usage-tutorial/</guid>
      <description>&lt;p&gt;&lt;em&gt;&lt;strong&gt;cntext&lt;/strong&gt;&lt;/em&gt; 是大邓开发维护的中英文文本分析库，内置有多重词典和常用函数， 包括&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;免费的 1.x 版， 更新至 1.9。&lt;/li&gt;
&lt;li&gt;收费的 2.x 版， 更新至 2.1.4。 2.1.4 新增 &lt;em&gt;&lt;strong&gt;ct.analysis_by_llm&lt;/strong&gt;&lt;/em&gt;, 可使用大模型LLM进行文本分析。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;加大邓 &lt;em&gt;&lt;strong&gt;WeChat: 372335839&lt;/strong&gt;&lt;/em&gt;， 备注「姓名-学校-专业」， 100元领取  &lt;em&gt;&lt;strong&gt;cntext-2.1.4-py3-none-any.whl&lt;/strong&gt;&lt;/em&gt; 文件。本文出现的cntext，默认均为2.x版本。&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;安装cntext&#34;&gt;安装cntext&lt;/h2&gt;
&lt;p&gt;所有 &lt;em&gt;&lt;strong&gt;cntext2.x&lt;/strong&gt;&lt;/em&gt; 安装方法类似， 以目前 cntext2.1.4 为例，将 &lt;em&gt;&lt;strong&gt;cntext-2.1.4-py3-none-any.whl&lt;/strong&gt;&lt;/em&gt; 放置于桌面，打开 &lt;em&gt;&lt;strong&gt;cmd&lt;/strong&gt;&lt;/em&gt;  (苹果电脑打开terminal)， 输入cd desktop&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;cd desktop
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;p&gt;之后在 &lt;em&gt;&lt;strong&gt;cmd&lt;/strong&gt;&lt;/em&gt;  (苹果电脑打开terminal) 中使用 &lt;em&gt;&lt;strong&gt;pip3&lt;/strong&gt;&lt;/em&gt; 安装&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;pip3 install cntext-2.1.4-py3-none-any.whl
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;p&gt;需要注意， &lt;strong&gt;cntext2.x使用环境为Python3.9 ~ 3.12&lt;/strong&gt;,如安装失败，问题可能出在python版本问题； 文章开头和文章末都有 &lt;em&gt;&lt;strong&gt;cntext-2.1.4-py3-none-any.whl&lt;/strong&gt;&lt;/em&gt;  获取方式说明。&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;功能模块&#34;&gt;功能模块&lt;/h2&gt;
&lt;p&gt;cntext含io、model、stats、mind五个模块&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;导入数据用io&lt;/li&gt;
&lt;li&gt;训练模型扩展词典用model&lt;/li&gt;
&lt;li&gt;统计词频、情感分析、相似度等用stats&lt;/li&gt;
&lt;li&gt;可视化模块plot&lt;/li&gt;
&lt;li&gt;态度认知文化变迁用mind&lt;/li&gt;
&lt;li&gt;大模型LLM&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;函数部分加粗的为常用函数。&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;模块&lt;/th&gt;
&lt;th&gt;函数&lt;/th&gt;
&lt;th&gt;功能&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;io&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;ct.get_cntext_path()&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;查看cntext安装路径&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;io&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;ct.get_dict_list()&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;查看cntext内置词典&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;io&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;ct.get_files(fformat)&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;查看符合fformat路径规则的所有的文件&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;io&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;ct.detect_encoding(file, num_lines=100)&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;诊断txt、csv编码格式&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;io&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;ct.read_yaml_dict(yfile)&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;读取内置yaml词典&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;io&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;ct.read_pdf(file)&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;读取PDF文件&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;io&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;ct.read_docx(file)&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;读取docx文件&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;io&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;ct.read_file(file, encodings)&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;读取文件&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;io&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;ct.read_files(fformat, encoding)&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;读取符合fformat路径规则的所有的文件，返回df&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;io&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;ct.extract_mda(text, kws_pattern)&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;提取A股年报中的MD&amp;amp;A文本内容。如果返回&#39;&#39;,则提取失败。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;io&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;ct.traditional2simple(text)&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;繁体转简体&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;io&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;ct.fix_text(text)&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;将不正常的、混乱编码的文本转化为正常的文本。例如全角转半角&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;io&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;ct.fix_contractions(text)&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;英文缩写(含俚语表达)处理， 如you&amp;rsquo;re -&amp;gt; you are&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;model&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;ct.W2VModel(corpus_file, encoding, lang=&amp;lsquo;chinese&amp;rsquo;)&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;训练Word2Vec&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;model&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;ct.glove2word2vec(glove_file, word2vec_file)&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;将GLoVe模型.txt文件转化为Word2Vec模型.txt文件；注意这里的GLoVe模型.txt是通过&lt;a href=&#34;https://github.com/standfordnlp/GloVe&#34;&gt;Standfordnlp/GloVe&lt;/a&gt; 训练得到的&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;model&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;ct.load_wv(wv_path)&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;读取cntext2.x训练出的word2vec模型文件&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;model&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;ct.expand_dictionary(wv,  seeddict, topn=100)&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;扩展词典,  结果保存到路径[output/Word2Vec]中&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;model&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;ct.Glove(corpus_file, lang=&#39;chinese&#39;)&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;训练GLove模型。 算法运行较慢，吃内存，不推荐！！&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;model&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;ct.SoPmi(corpus_file, seed_file, lang=&#39;chinese&#39;)&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;共现法扩展词典&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;stats&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;ct.term_freq(text, lang=&#39;chinese&#39;)&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;词频统计&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;stats&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;readability(text, lang=&#39;chinese&#39;, syllables=3)&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;文本可读性&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;stats&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;ct.sentiment(text, diction, lang=&amp;lsquo;chinese&amp;rsquo;)&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;无(等)权重词典的情感分析&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;stats&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;ct.sentiment_by_valence(text, diction, lang=&#39;chinese&#39;)&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;带权重的词典的情感分析&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;stats&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;ct.word_in_context(text, keywords, window=3, lang=&amp;lsquo;chinese&amp;rsquo;)&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;在text中查找keywords出现的上下文内容(窗口window)，返回df&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;stats&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;ct.epu()&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;使用新闻文本数据计算经济政策不确定性EPU，返回df&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;stats&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;ct.fepu(text, ep_pattern=&#39;&#39;, u_pattern=&#39;&#39;)&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;使用md&amp;amp;a文本数据计算企业不确定性感知FEPU&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;stats&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;ct.semantic_brand_score(text, brands, lang=&amp;lsquo;chinese&amp;rsquo;)&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;衡量品牌（个体、公司、品牌、关键词等）的重要性&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;stats&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;ct.cosine_sim(text1, text2)&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;余弦相似度&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;stats&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;ct.jaccard_sim(text1, text2)&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Jaccard相似度&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;stats&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;ct.minedit_sim(text1, text2)&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;最小编辑距离&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;stats&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;ct.word_hhi(text)&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;文本的赫芬达尔-赫希曼指数&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;plot&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;ct.matplotlib_chinese()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;支持matplotlib中文绘图&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;plot&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;ct.lexical_dispersion_plot1(text, targets_dict, lang, title, figsize)&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;对某一个文本text， 可视化不同目标类别词targets_dict在文本中出现位置&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;plot&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;ct.lexical_dispersion_plot2(texts_dict, targets, lang, title, figsize)&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;对某几个文本texts_dict， 可视化某些目标词targets在文本中出现相对位置(0~100)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;mind&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;tm = ct.Text2Mind(wv)&lt;/strong&gt;&lt;/em&gt;&lt;br&gt;&lt;/td&gt;
&lt;td&gt;单个word2vec内挖掘潜在的态度偏见、刻板印象等。tm含多重方法&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;mind&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;ct.sematic_projection(wv, words, c_words1, c_words2)&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;测量语义投影&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;mind&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;ct.sematic_distance(wv, words, c_words1, c_words2)&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;测量语义距离&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;mind&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;ct.divergent_association_task(wv, words)&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;测量发散思维(创造力)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;mind&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;ct.discursive_diversity_score(wv, words)&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;测量语言差异性(认知差异性)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;mind&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;ct.procrustes_align(base_wv, other_wv)&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;两个word2vec进行语义对齐，可反应随时间的社会语义变迁&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;LLM&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;analysis_by_llm(text, prompt, base_url, api_key, model_name, temperature, output_format)&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;使用大模型进行文本分析&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;quickstart&#34;&gt;QuickStart&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;cntext&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;ct&lt;/span&gt;

&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;当前cntext版本: &amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ct&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;__version__&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;help&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ct&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span class=&#34;nx&#34;&gt;当前cntext版本&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;2.1.4&lt;/span&gt;

&lt;span class=&#34;nx&#34;&gt;Help&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;on&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;package&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;cntext&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;

&lt;span class=&#34;nx&#34;&gt;NAME&lt;/span&gt;
    &lt;span class=&#34;nx&#34;&gt;cntext&lt;/span&gt;

&lt;span class=&#34;nx&#34;&gt;PACKAGE&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;CONTENTS&lt;/span&gt;
    &lt;span class=&#34;nx&#34;&gt;io&lt;/span&gt;
    &lt;span class=&#34;nx&#34;&gt;mind&lt;/span&gt;
    &lt;span class=&#34;nx&#34;&gt;model&lt;/span&gt;
    &lt;span class=&#34;nx&#34;&gt;stats&lt;/span&gt;
    &lt;span class=&#34;nx&#34;&gt;llm&lt;/span&gt;
&lt;span class=&#34;o&#34;&gt;...&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;br&gt;
&lt;h2 id=&#34;一io模块&#34;&gt;一、IO模块&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;模块&lt;/th&gt;
&lt;th&gt;函数&lt;/th&gt;
&lt;th&gt;功能&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;io&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;ct.get_dict_list()&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;查看cntext内置词典&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;io&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;ct.read_yaml_dict(yfile)&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;读取内置yaml词典&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;io&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;ct.detect_encoding(file, num_lines=100)&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;诊断txt、csv编码格式&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;io&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;ct.get_files(fformat)&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;查看符合fformat路径规则的所有的文件&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;io&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;ct.read_yaml_dict(yfile)&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;读取内置yaml词典&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;io&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;ct.read_pdf(file)&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;读取PDF文件&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;io&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;ct.read_file(file, encoding)&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;读取文件&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;io&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;ct.read_files(fformat, encoding)&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;读取符合fformat路径规则的所有的文件，返回df&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;io&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;ct.extract_mda(text, kws_pattern)&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;提取A股年报中的MD&amp;amp;A文本内容。如果返回&#39;&#39;,则提取失败。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;io&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;ct.traditional2simple(text)&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;繁体转简体&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;io&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;ct.fix_text(text)&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;将不正常的、混乱编码的文本转化为正常的文本。例如全角转半角&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;io&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;ct.fix_contractions(text)&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;英文缩写(含俚语表达)处理， 如you&amp;rsquo;re -&amp;gt; you are&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;11-get_dict_list&#34;&gt;1.1 get_dict_list()&lt;/h3&gt;
&lt;p&gt;查看cntext内置词典&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;cntext&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;ct&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;ct&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;get_dict_list&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;[&amp;#39;zh_common_NTUSD.yaml&amp;#39;,
 &amp;#39;zh_common_DUTIR.yaml&amp;#39;,
 &amp;#39;enzh_common_StopWords.yaml&amp;#39;,
 &amp;#39;en_valence_Concreteness.yaml&amp;#39;,
 &amp;#39;en_common_LoughranMcDonald.yaml&amp;#39;,
 &amp;#39;zh_common_FinanceSenti.yaml&amp;#39;,
 &amp;#39;zh_common_FLS.yaml&amp;#39;,
 &amp;#39;zh_common_TsinghuaPraiseDegrade.yaml&amp;#39;,
 &amp;#39;zh_common_FEPU.yaml&amp;#39;,
 &amp;#39;en_common_ANEW.yaml&amp;#39;,
 &amp;#39;en_common_NRC.yaml&amp;#39;,
 &amp;#39;zh_valence_ChineseEmoBank.yaml&amp;#39;,
 &amp;#39;zh_valence_SixSemanticDimensionDatabase.yaml&amp;#39;,
 &amp;#39;zh_common_FinacialFormalUnformal.yaml&amp;#39;,
 &amp;#39;zh_common_LoughranMcDonald.yaml&amp;#39;,
 &amp;#39;enzh_common_AdvConj.yaml&amp;#39;,
 &amp;#39;en_common_SentiWS.yaml&amp;#39;,
 &amp;#39;zh_common_Digitalization.yaml&amp;#39;,
 &amp;#39;en_common_LSD2015.yaml&amp;#39;,
 &amp;#39;zh_common_HowNet.yaml&amp;#39;,
 &amp;#39;zh_common_EPU.yaml&amp;#39;]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;12-内置yaml词典&#34;&gt;1.2 内置yaml词典&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;pkl文件&lt;/th&gt;
&lt;th&gt;词典&lt;/th&gt;
&lt;th&gt;语言&lt;/th&gt;
&lt;th&gt;功能&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;zh_valence_ChineseEmoBank.yaml&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;中文情感词典，含&lt;code&gt;效价valence&lt;/code&gt;和&lt;code&gt;唤醒度arousal&lt;/code&gt;。在cntext中，我们只使用了CVAW词表(单词)，其他词典如CVAP, CVAS, CVAT没有纳入到ChineseEmoBank.pkl.&lt;/td&gt;
&lt;td&gt;Chinese&lt;/td&gt;
&lt;td&gt;&lt;code&gt;效价valence&lt;/code&gt;和&lt;code&gt;唤醒度arousal&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;zh_common_DUTIR.yaml&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;大连理工大学情感本体库&lt;/td&gt;
&lt;td&gt;中文&lt;/td&gt;
&lt;td&gt;七大类情绪，&lt;code&gt;哀, 好, 惊, 惧, 乐, 怒, 恶&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;zh_common_HowNet.yaml&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;知网Hownet词典&lt;/td&gt;
&lt;td&gt;中文&lt;/td&gt;
&lt;td&gt;正面词、负面词&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;en_common_SentiWS.yaml&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;SentimentWortschatz (SentiWS)&lt;/td&gt;
&lt;td&gt;德文&lt;/td&gt;
&lt;td&gt;正面词、负面词；&lt;br&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;zh_common_FinacialFormalUnformal.yaml&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;金融领域正式、非正式；积极消极&lt;/td&gt;
&lt;td&gt;中文&lt;/td&gt;
&lt;td&gt;formal-pos、&lt;br&gt;formal-neg；&lt;br&gt;unformal-pos、&lt;br&gt;unformal-neg&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;en_common_ANEW.yaml&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;英语单词的情感规范Affective Norms for English Words (ANEW)&lt;/td&gt;
&lt;td&gt;英文&lt;/td&gt;
&lt;td&gt;pleasure, arousal, dominance&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;en_common_LSD2015.yaml&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Lexicoder Sentiment Dictionary (2015)&lt;/td&gt;
&lt;td&gt;英文&lt;/td&gt;
&lt;td&gt;正面词、负面词&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;en_common_NRC.yaml&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;NRC Word-Emotion Association Lexicon&lt;/td&gt;
&lt;td&gt;英文&lt;/td&gt;
&lt;td&gt;细粒度情绪词；&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;zh_valence_SixSemanticDimensionDatabase.yaml&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://textdata.cn/blog/2023-03-20-nature-six-semantic-dimension-database/&#34;&gt;&lt;strong&gt;通用中英文六维语义情感词典&lt;/strong&gt;&lt;/a&gt;, 含17940个中文词的六维度词库， 且每个维度有权重。&lt;/td&gt;
&lt;td&gt;中文&lt;/td&gt;
&lt;td&gt;vision、socialness、emotion、time、space、motor&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;enzh_common_AdvConj.yaml&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;副词连词&lt;/td&gt;
&lt;td&gt;中、英&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;enzh_common_StopWords.yaml&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;中英文停用词&lt;/td&gt;
&lt;td&gt;中、英&lt;/td&gt;
&lt;td&gt;停用词&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;en_valence_Concreteness.yaml&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://textdata.cn/blog/jcr_concreteness_computation/&#34;&gt;英文具体性词典&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;word &amp;amp; concreateness score&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;zh_common_LoughranMcDonald.yaml&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;中文LoughranMcDonald词典&lt;/td&gt;
&lt;td&gt;中文&lt;/td&gt;
&lt;td&gt;正面、负面词&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;zh_common_Digitalization.yaml&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://textdata.cn/blog/2022-11-03-mda-measure-digitalization/&#34;&gt;管理世界|吴非(2021)数字化词典&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;中文&lt;/td&gt;
&lt;td&gt;含人工智能技术、大数据技术、云计算技术、区块链技术、数字技术应用等关键词列表。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;en_common_LoughranMcDonald.yaml&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;英文LoughranMcDonald词典&lt;/td&gt;
&lt;td&gt;英文&lt;/td&gt;
&lt;td&gt;金融LM情绪词典2018年版本，含七个词表，分别是Negative, Positive, Uncertainty, Litigious, StrongModal, WeakModal, Constraining&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;zh_common_FLS.yaml&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://textdata.cn/blog/2023-09-08-earnings-communication-conference-forward-looking-statements-information/&#34;&gt;&lt;strong&gt;业绩说明会前瞻性词典集&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;中文&lt;/td&gt;
&lt;td&gt;含174个词语&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;zh_common_RhetoricalNationalism.yaml&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;修辞民族主义&lt;/td&gt;
&lt;td&gt;中文&lt;/td&gt;
&lt;td&gt;含四个维度，民族自豪感、民族复兴、企业角色、排外主义，每个维度100个词。&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;br&gt;
&lt;h3 id=&#34;13-read_dict_yaml&#34;&gt;1.3 read_dict_yaml()&lt;/h3&gt;
&lt;p&gt;使用 cntext 读取 &lt;em&gt;&lt;strong&gt;.yaml&lt;/strong&gt;&lt;/em&gt; 词典文件；  返回的信息包括&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Name 词典的名字&lt;/li&gt;
&lt;li&gt;Desc 词典的含义、概念解释&lt;/li&gt;
&lt;li&gt;Refer 词典文献出处&lt;/li&gt;
&lt;li&gt;Category 词典Dictionary的关键词&lt;/li&gt;
&lt;li&gt;Dictionary 词典, python字典格式&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;cntext&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;ct&lt;/span&gt;
&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ct&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read_yaml_dict&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;zh_common_Digitalization.yaml&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;{&amp;#39;Name&amp;#39;: &amp;#39;中文数字化词典&amp;#39;, 
&amp;#39;Desc&amp;#39;: &amp;#39;基于这篇论文，构建了中文数字化词典，含人工智能技术、大数据技术、云计算技术、区块链技术、数字技术应用等关键词列表。 &amp;#39;, &amp;#39;Refer&amp;#39;: &amp;#39;吴非,胡慧芷,林慧妍,任晓怡. 企业数字化转型与资本市场表现——来自股票流动性的经验证据[J]. 管理世界,2021,37(07):130-144+10.&amp;#39;, 
&amp;#39;Category&amp;#39;: [&amp;#39;Artificial_Intelligence&amp;#39;, &amp;#39;Big_Data&amp;#39;, &amp;#39;Cloud_Computing&amp;#39;, &amp;#39;Block_Chains&amp;#39;, &amp;#39;Usage_of_Digitalization&amp;#39;], 

&amp;#39;Dictionary&amp;#39;: 
    {&amp;#39;Artificial_Intelligence&amp;#39;: [&amp;#39;人工智能&amp;#39;, &amp;#39;商业智能&amp;#39;, &amp;#39;图像理解&amp;#39;, &amp;#39;投资决策辅助系统&amp;#39;, &amp;#39;智能数据分析&amp;#39;, &amp;#39;智能机器人&amp;#39;, &amp;#39;机器学习&amp;#39;, &amp;#39;深度学习&amp;#39;, &amp;#39;语义搜索&amp;#39;, &amp;#39;生物识别技术&amp;#39;, &amp;#39;人脸识别&amp;#39;, &amp;#39;语音识别&amp;#39;, &amp;#39;身份验证&amp;#39;, &amp;#39;自动驾驶&amp;#39;, &amp;#39;自然语言处理&amp;#39;], 
    &amp;#39;Big_Data&amp;#39;: [&amp;#39;大数据&amp;#39;, &amp;#39;数据挖掘&amp;#39;, &amp;#39;文本挖掘&amp;#39;, &amp;#39;数据可视化&amp;#39;, &amp;#39;异构数据&amp;#39;, &amp;#39;征信&amp;#39;, &amp;#39;增强现实&amp;#39;, &amp;#39;混合现实&amp;#39;, &amp;#39;虚拟现实&amp;#39;], 
    &amp;#39;Cloud_Computing&amp;#39;: [&amp;#39;云计算&amp;#39;, &amp;#39;流计算&amp;#39;, &amp;#39;图计算&amp;#39;, &amp;#39;内存计算&amp;#39;, &amp;#39;多方安全计算&amp;#39;, &amp;#39;类脑计算&amp;#39;, &amp;#39;绿色计算&amp;#39;, &amp;#39;认知计算&amp;#39;, &amp;#39;融合架构&amp;#39;, &amp;#39;亿级并发&amp;#39;, &amp;#39;EB级存储&amp;#39;, &amp;#39;物联网&amp;#39;, &amp;#39;信息物理系统&amp;#39;], 
    &amp;#39;Block_Chains&amp;#39;: [&amp;#39;区块链&amp;#39;, &amp;#39;数字货币&amp;#39;, &amp;#39;分布式计算&amp;#39;, &amp;#39;差分隐私技术&amp;#39;, &amp;#39;智能金融合约&amp;#39;], 
    &amp;#39;Usage_of_Digitalization&amp;#39;: [&amp;#39;移动互联网&amp;#39;, &amp;#39;工业互联网&amp;#39;, &amp;#39;移动互联&amp;#39;, &amp;#39;互联网医疗&amp;#39;, &amp;#39;电子商务&amp;#39;, &amp;#39;移动支付&amp;#39;, &amp;#39;第三方支付&amp;#39;, &amp;#39;NFC支付&amp;#39;, &amp;#39;智能能源&amp;#39;, &amp;#39;B2B&amp;#39;, &amp;#39;B2C&amp;#39;, &amp;#39;C2B&amp;#39;, &amp;#39;C2C&amp;#39;, &amp;#39;O2O&amp;#39;, &amp;#39;网联&amp;#39;, &amp;#39;智能穿戴&amp;#39;, &amp;#39;智慧农业&amp;#39;, &amp;#39;智能交通&amp;#39;, &amp;#39;智能医疗&amp;#39;, &amp;#39;智能客服&amp;#39;, &amp;#39;智能家居&amp;#39;, &amp;#39;智能投顾&amp;#39;, &amp;#39;智能文旅&amp;#39;, &amp;#39;智能环保&amp;#39;, &amp;#39;智能电网&amp;#39;, &amp;#39;智能营销&amp;#39;, &amp;#39;数字营销&amp;#39;, &amp;#39;无人零售&amp;#39;, &amp;#39;互联网金融&amp;#39;, &amp;#39;数字金融&amp;#39;, &amp;#39;Fintech&amp;#39;, &amp;#39;金融科技&amp;#39;, &amp;#39;量化金融&amp;#39;, &amp;#39;开放银行&amp;#39;]}}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h3 id=&#34;14-detect_encoding&#34;&gt;1.4 detect_encoding()&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;ct.detect_encoding(file)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;通过读取前num_lines来识别txt/csv文件的编码格式&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;file&lt;/strong&gt;&lt;/em&gt; 文件路径&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;cntext&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;ct&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;#读取data文件夹下的【三体.txt】&lt;/span&gt;
&lt;span class=&#34;c1&#34;&gt;#识别编码方式&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;ct&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;detect_encoding&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;file&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;data/三体.txt&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;utf-8
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h3 id=&#34;15-get_filesfformat&#34;&gt;1.5 get_files(fformat)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;fformat&lt;/strong&gt;  fformat格式支持 txt/pdf/docx/xlsx/csv等。 &lt;code&gt;*&lt;/code&gt;表示通配符&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;查看符合fformat路径规则的所有的文件， fformat格式支持 txt/pdf/docx/xlsx/csv等。 &lt;code&gt;*&lt;/code&gt;表示通配符&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;fformat格式&lt;/th&gt;
&lt;th&gt;识别的文件&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;*.txt&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;匹配当前代码所在路径内的所有txt&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;*.pdf&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;匹配当前代码所在路径内的所有pdf&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;data/*.txt&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;匹配「文件夹data」内所有的 txt&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;br&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;c1&#34;&gt;#查看【文件夹data】内所有的 txt文件。&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;ct&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;get_files&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fformat&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;data/*.txt&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;[&amp;#39;data/三体.txt&amp;#39;,
 &amp;#39;data/santi.txt&amp;#39;,
 &amp;#39;data/w2v_corpus.txt&amp;#39;,
 &amp;#39;data/sopmi_corpus.txt&amp;#39;,
 &amp;#39;data/brown_corpus.txt&amp;#39;,
 &amp;#39;data/sopmi_seed_words.txt&amp;#39;]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h3 id=&#34;16-read_pdf&#34;&gt;1.6 read_pdf&lt;/h3&gt;
&lt;p&gt;读取PDF，返回文本内容&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;ct&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read_pdf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;file&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;file&lt;/strong&gt;&lt;/em&gt; PDF文件路径&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;点击 &lt;a href=&#34;https://textdata.cn/data/%E6%A0%BC%E5%8A%9B%E7%94%B5%E5%99%A82023.pdf&#34;&gt;&lt;strong&gt;格力电器2023.pdf&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;cntext&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;ct&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;text&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ct&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read_pdf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;格力电器2023.pdf&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;珠海格力电器股份有限公司 2023年年度报告全文  
珠海格力电器股份有限公司  
2023年年度报告  
 
 
二〇二四年四月 
珠海格力电器股份有限公司 2023年年度报告全文  
 第 2 页 共 249 页 第一节 重要提示、目录和释义  
公司董事会、监事会及董事、监事、高级管理人员保证年度报告内容
的真实、准确、完整，不存在虚假记载、误导性陈述或重大遗漏，并承担
个别和连带的法律
......
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h3 id=&#34;17-read_docx&#34;&gt;1.7 read_docx&lt;/h3&gt;
&lt;p&gt;读取docx，返回文本内容&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;ct&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read_docx&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;file&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;file&lt;/strong&gt;&lt;/em&gt; docx文件路径&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;cntext&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;ct&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;text&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ct&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read_docx&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;test.docx&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;text&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;这是来自test.docx里内容
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h3 id=&#34;18-read_file&#34;&gt;1.8 read_file()&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;ct.read_file(file, encoding=&amp;#39;utf-8&amp;#39;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;file&lt;/strong&gt; 待读取的文件路径； 支持txt、pdf、docx、xlsx、xls， 返回 DataFrame(含doc和file两个字段)。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;encoding&lt;/strong&gt; 待读取文件的编码方式&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;以 &lt;code&gt;data/三体.txt&lt;/code&gt; 为例&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;cntext&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;ct&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;#默认encoding=&amp;#39;utf-8&amp;#39;&lt;/span&gt;
&lt;span class=&#34;c1&#34;&gt;#sdf = ct.read_file(file=&amp;#39;data/三体.txt&amp;#39;)&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;sdf&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ct&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read_file&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;file&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;data/三体.txt&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;encoding&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;utf-8&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;sdf&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/01-san_ti_df.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;19-read_files&#34;&gt;1.9 read_files()&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;ct.read_files(fformat, encoding=&amp;#39;utf-8&amp;#39;）
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;批量读取符合fformat格式的所有文件数据，返回DataFrame(含doc和file两个字段)。&lt;/p&gt;
&lt;p&gt;读取[文件夹data里所有txt]&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;cntext&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;ct&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;#默认encoding=&amp;#39;utf-8&amp;#39;&lt;/span&gt;
&lt;span class=&#34;c1&#34;&gt;#ddf = ct.read_files(fformat=&amp;#39;data/*.txt&amp;#39;)&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;ddf&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ct&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read_files&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fformat&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;data/*.txt&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;encoding&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;utf-8&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;ddf&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/02-ddf.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;110-extract_mda&#34;&gt;1.10 extract_mda&lt;/h3&gt;
&lt;p&gt;提取A股年报中的MD&amp;amp;A文本内容。如果返回&#39;&#39;,则提取失败。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;ct.extract_mda(text, kws_pattern=&amp;#39;&amp;#39;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;text 中国A股年报原始文本&lt;/li&gt;
&lt;li&gt;kws_pattern 管理层讨论与分析章节识别关键词的模板。cntext内置的kws_pattern内容如下&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;kws_pattern = &amp;#39;董事会报告|董事会报告与管理讨论|企业运营与管理评述|经营总结与分析|管理层评估与未来展望|董事局报告|管理层讨论与分析|经营情况讨论与分析|经营业绩分析|业务回顾与展望|公司经营分析|管理层评论与分析|执行摘要与业务回顾|业务运营分析&amp;#39;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;cntext&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;ct&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;text&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ct&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read_pdf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;格力电器2023.pdf&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;mda_text&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ct&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;extract_mda&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mda_text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&amp;#39;管理层讨论与分析  \n一、报告期内公司所处行业情况  \n（一）行业发展现状  \n1.消费领域 ——家电行业稳定增长，空调市场恢复明显  \n2023年，中国经济保持了整体恢复向好的态势，激发消费是稳增长的重中之重。国家鼓励和推动消费品以旧换\n新，促进消费经济大循环，加速更新需求释放，推动高能效产品设备销售和出口增长，进一步激发绿色消费潜力。  \n1）家电行业稳定增长  \n2023年，国内经济恢复明显，家电行业稳定增长。根据全国家用电器工业信息中心发布的《 2023年中国家电\n行业年度报告》，家电行业外销明显增长，出口规模为 6,174亿元，同比增长 9.9%；国内市场实现稳步增长，销售\n规模为7&amp;#39;
.......
.......
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;p&gt;以&lt;a href=&#34;https://textdata.cn/blog/2023-03-23-china-a-share-market-dataset-mda-from-01-to-21/&#34;&gt;2001年~2023会计年度报告数据集&lt;/a&gt;为例， 查看 &lt;em&gt;&lt;strong&gt;extract_mda&lt;/strong&gt;&lt;/em&gt; 的抽取mda的能力。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;glob&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;cntext&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;ct&lt;/span&gt;

&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;extract_mda识别能力&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;year&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;range&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2001&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2024&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;num&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;
    &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;file&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;glob&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;glob&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;sa&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;年报txt/&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;year&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;/*.txt&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
        &lt;span class=&#34;n&#34;&gt;mda_text&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ct&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;extract_mda&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;open&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;file&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;())&lt;/span&gt;
        &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;mda_text&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;!=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
            &lt;span class=&#34;n&#34;&gt;num&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;num&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;
               
    &lt;span class=&#34;n&#34;&gt;volume&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;glob&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;glob&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;sa&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;年报txt/&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;year&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;/*.txt&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;     
    &lt;span class=&#34;n&#34;&gt;ratio&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;num&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;volume&lt;/span&gt;
    
    &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;sa&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;year&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;: &lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ratio&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;.2f&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;2001: 0.24
2002: 0.37
2003: 0.43
2004: 0.70
2005: 0.77
2006: 0.78
2007: 0.79
2008: 0.77
2009: 0.79
2010: 0.82
2011: 0.84
2012: 0.96
2013: 0.95
2014: 0.98
2015: 0.98
2016: 0.99
2017: 0.98
2018: 0.98
2019: 0.99
2020: 0.97
2021: 0.98
2022: 0.99
2023: 0.99
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;建议各位用最近10年的年报数据，通过extract_mda提取mda文本，或者直接购买 [数据集 | 2001-2023年A股上市公司年报&amp;amp;管理层讨论与分析](数据集 | 2001-2023年A股上市公司年报&amp;amp;管理层讨论与分析)&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;111-traditional2simple&#34;&gt;1.11 traditional2simple()&lt;/h3&gt;
&lt;p&gt;繁体转简体&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;ct.traditional2simple(text, mode=&amp;#39;t2s&amp;#39;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;text&lt;/strong&gt;&lt;/em&gt; 待转换的文本&lt;/li&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;mode&lt;/strong&gt;&lt;/em&gt; 转换模式， 默认mode=&amp;lsquo;t2s&amp;rsquo;繁转简; mode还支持s2t&lt;/li&gt;
&lt;/ul&gt;
 &lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;cntext&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;ct&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;text&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;簡體漢字&amp;#39;&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;ct&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;traditional2simple&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&amp;#39;简体汉字&amp;#39;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;text&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;简体汉字&amp;#39;&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;ct&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;traditional2simple&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;mode&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;s2t&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&amp;#39;簡體漢字&amp;#39;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h3 id=&#34;112-fix_text&#34;&gt;1.12 fix_text()&lt;/h3&gt;
&lt;p&gt;将不正常的、混乱编码的文本转化为正常的文本。例如全角转半角&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;cntext&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;ct&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;raw_text&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;今日起可中遇到技术问题，可以拨打电话０３７１－６６３２１９９１、６６３２１９７３咨询。&amp;#39;&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;text&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ct&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fix_text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;raw_text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;text&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;今日起可中遇到技术问题，可以拨打电话0371-66321991、66321973咨询。
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h3 id=&#34;113-fix_contractionstext&#34;&gt;1.13 fix_contractions(text)&lt;/h3&gt;
&lt;p&gt;将英文缩写(含俚语表达)转化为完整的表达，如如&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;- you&amp;#39;re -&amp;gt; you are
- yall  -&amp;gt; you all
- gotta  -&amp;gt; got to
...
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;cntext&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;ct&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;raw_text&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;yall&amp;#39;re happy now&amp;#34;&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;text&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ct&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fix_contractions&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;raw_text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;text&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&amp;#34;you all are happy now&amp;#34;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;二stats模块&#34;&gt;二、Stats模块&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;模块&lt;/th&gt;
&lt;th&gt;函数&lt;/th&gt;
&lt;th&gt;功能&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;stats&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;ct.term_freq(text, lang=&#39;chinese&#39;)&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;词频统计&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;stats&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;ct.readability(text, lang=&#39;chinese&#39;)&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;文本可读性&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;stats&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;ct.sentiment(text, diction, lang=&amp;lsquo;chinese&amp;rsquo;)&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;无(等)权重词典的情感分析&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;stats&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;ct.sentiment_by_valence(text, diction, lang=&#39;chinese&#39;)&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;带权重的词典的情感分析&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;stats&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;ct.word_in_context(text, keywords, window=3, lang=&amp;lsquo;chinese&amp;rsquo;)&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;在text中查找keywords出现的上下文内容(窗口window)，返回df&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;stats&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;ct.epu(text, e_pattern, p_pattern, u_pattern)&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;使用新闻文本数据计算经济政策不确定性EPU，返回df&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;stats&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;ct.fepu(text, ep_pattern=&#39;&amp;rsquo;, u_pattern=&#39;&#39;)&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;使用md&amp;amp;a文本数据计算企业不确定性感知FEPU&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;stats&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;ct.semantic_brand_score(text, brands, lang=&amp;lsquo;chinese&amp;rsquo;)&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;衡量品牌（个体、公司、品牌、关键词等）的重要性&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;stats&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;ct.cosine_sim(text1, text2)&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;余弦相似度&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;stats&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;ct.jaccard_sim(text1, text2)&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Jaccard相似度&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;stats&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;ct.minedit_sim(text1, text2)&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;最小编辑距离&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;stats&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;ct.word_hhi(text)&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;文本的赫芬达尔-赫希曼指数&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;br&gt;
&lt;h3 id=&#34;21-term_freq&#34;&gt;2.1 term_freq()&lt;/h3&gt;
&lt;p&gt;统计词频， 返回Counter(类似于python字典) ； 支持中英文&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;term_freq(text, lang=&amp;#39;chinese&amp;#39;, return_df=False)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;text&lt;/strong&gt; 待分析的文本字符串&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;lang&lt;/strong&gt; 文本的语言类型， 中文chinese、英文english，默认中文。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;return_df&lt;/strong&gt; 返回结果是否为dataframe，默认False&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;cntext&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;ct&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;text&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;致力于致力于以零文章处理费或订阅费发布优质研究软件。&amp;#39;&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;#ct.term_freq(text, lang=&amp;#39;chinese&amp;#39;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;ct&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;term_freq&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;Counter({&amp;#39;致力于&amp;#39;: 2,
         &amp;#39;文章&amp;#39;: 1,
         &amp;#39;处理费&amp;#39;: 1,
         &amp;#39;订阅费&amp;#39;: 1,
         &amp;#39;发布&amp;#39;: 1,
         &amp;#39;优质&amp;#39;: 1,
         &amp;#39;研究&amp;#39;: 1,
         &amp;#39;软件&amp;#39;: 1})
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;ct&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;term_freq&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;return_df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/09-term_freq.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;22-readability&#34;&gt;2.2 readability()&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;ct.readability(text, lang=&amp;#39;chinese&amp;#39;, syllables=3, return_series=False)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;计算文本可读性常见指标； 含Gunning Fog Index、 SMOG Index、Coleman Liau Index、 Automated Readability Index(ARI)、Readability Index(Rix)； 指标越大，复杂度越高，文本的可读性越差。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;text&lt;/strong&gt;  待分析的文本字符串&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;lang&lt;/strong&gt; 文本的语言类型， 中文chinese、英文english，默认中文。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;syllables&lt;/strong&gt; 音节数(汉字数)大于等于syllables为复杂词. 默认值为3&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;return_series&lt;/strong&gt;: 计算结果是否输出为pd.Series类型，默认为False&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;Gunning Fog Index = 0.4 * (Total_Words/Total_Sentences + 100 * Complex_Words/Total_Words)
SMOG Index = 1.0430 * sqrt(Complex_Words/Total_Sentences) * 30 + 3.1291
Coleman-Liau Index = 0.0588 * (100*Total_Letters/Total_Words) -0.296*(100*Total_Sentences/Total_Words) - 15.8
Automated Readability Index(ARI) = 4.71 * (Total_Characters/Total_Words) + 0.5*(Total_Words/Total_Sentences) - 21.43
Readability Index(RIX) = Complex_Words * (6 + Total_characters) / Total_Sentences
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;cntext&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;ct&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;text&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;致力于以零文章处理费或订阅费发布优质研究软件。&amp;#39;&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;ct&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;readability&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;lang&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;chinese&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;syllables&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;{&amp;#39;fog_index&amp;#39;: 120.4,
 &amp;#39;flesch_kincaid_grade_level&amp;#39;: 20.2,
 &amp;#39;smog_index&amp;#39;: 57.32,
 &amp;#39;coleman_liau_index&amp;#39;: 83.96,
 &amp;#39;ari&amp;#39;: 87.4,
 &amp;#39;rix&amp;#39;: 87.0}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h3 id=&#34;23-sentimenttext-diction-lang&#34;&gt;2.3 sentiment(text, diction, lang)&lt;/h3&gt;
&lt;p&gt;常见的情感分析默认情绪词无(等)权重， 通过统计词语个数来反应情感信息。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;sentiment(text, diction, lang=&amp;#39;chinese&amp;#39;, return_series=False)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;text&lt;/strong&gt; 待分析的文本字符串&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;diction&lt;/strong&gt;  格式为Python字典类型。形如下面的案例&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;lang&lt;/strong&gt; 文本的语言类型， 中文chinese、英文english，默认中文。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;return_series&lt;/strong&gt;  计算结果是否输出为pd.Series类型，默认为False&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;cntext&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;ct&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;diction&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;pos&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;高兴&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;快乐&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;分享&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;
           &lt;span class=&#34;s1&#34;&gt;&amp;#39;neg&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;难过&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;悲伤&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;
           &lt;span class=&#34;s1&#34;&gt;&amp;#39;adv&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;很&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;特别&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]}&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;text&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;我今天得奖了，很高兴，我要将快乐分享大家。&amp;#39;&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;ct&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sentiment&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
             &lt;span class=&#34;n&#34;&gt;diction&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;diction&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
             &lt;span class=&#34;n&#34;&gt;lang&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;chinese&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;{&amp;#39;pos_num&amp;#39;: 3,
 &amp;#39;neg_num&amp;#39;: 0,
 &amp;#39;adv_num&amp;#39;: 1,
 &amp;#39;stopword_num&amp;#39;: 8,
 &amp;#39;word_num&amp;#39;: 14,
 &amp;#39;sentence_num&amp;#39;: 1}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h3 id=&#34;24-sentiment_by_valence&#34;&gt;2.4 sentiment_by_valence()&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;ct.sentiment_by_valence(text, diction, lang=&amp;#39;chinese&amp;#39;, return_series=False)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;text&lt;/strong&gt; 待分析的文本字符串&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;diction&lt;/strong&gt;  格式为Python字典类型。形如下面的案例&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;lang&lt;/strong&gt; 文本的语言类型， 中文chinese、英文english，默认中文。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;return_series&lt;/strong&gt; 计算结果是否输出为pd.Series类型，默认为False&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;常见的情感分析是无(等)权重, 但实际上不同的词语所携带的情感信息的强度差异是很大的。据此学者们开发出很多带权重的词典，例如&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;英文具体性词典en_valence_Concreteness.yaml， 词典中每个词都有一个concreteness值&lt;/li&gt;
&lt;li&gt;中文六维度语义词典zh_valence_SixSemanticDimensionDatabase.yaml,  每个中文词有六个值。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;以具体性为例， &lt;strong&gt;语言具体性Concreteness&lt;/strong&gt;描述了一个词在多大程度上是指一个实际的、有形的或“真实的”实体，以一种更具体、更熟悉、更容易被眼睛或心灵感知的方式描述对象和行为（即，可想象或生动；Brysbaert, Warriner, and Kuperman 2014; Semin and Fiedler 1988)&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;cntext&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;ct&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pandas&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pd&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;concreteness_dict&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ct&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read_yaml_dict&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;en_valence_Concreteness.yaml&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;Dictionary&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;concreteness_dict&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;{&amp;#39;roadsweeper&amp;#39;: {&amp;#39;concreteness&amp;#39;: 4.85},
 &amp;#39;traindriver&amp;#39;: {&amp;#39;concreteness&amp;#39;: 4.54},
 &amp;#39;tush&amp;#39;: {&amp;#39;concreteness&amp;#39;: 4.45},
 &amp;#39;hairdress&amp;#39;: {&amp;#39;concreteness&amp;#39;: 3.93},
 &amp;#39;pharmaceutics&amp;#39;: {&amp;#39;concreteness&amp;#39;: 3.77},
 &amp;#39;hoover&amp;#39;: {&amp;#39;concreteness&amp;#39;: 3.76},
 &amp;#39;shopkeeping&amp;#39;: {&amp;#39;concreteness&amp;#39;: 3.18},
 &amp;#39;pushiness&amp;#39;: {&amp;#39;concreteness&amp;#39;: 2.48},
 ......
 }
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;可能 &lt;em&gt;&lt;strong&gt;concreteness_dict&lt;/strong&gt;&lt;/em&gt;不够直观， 如果整理转化一下大概类似于&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/11-concreteness_df.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://textdata.cn/blog/jcr_concreteness_computation/&#34;&gt;&lt;strong&gt;JCR2021 | 计算文本的语言具体性&lt;/strong&gt;&lt;/a&gt; 文中提供了一个案例&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;reply&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;I&amp;#39;ll go look for that&amp;#34;&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;score&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ct&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sentiment_by_valence&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;reply&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
                              &lt;span class=&#34;n&#34;&gt;diction&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;concreteness_dict&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
                              &lt;span class=&#34;n&#34;&gt;lang&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;english&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;score&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;{&amp;#39;concreteness&amp;#39;: 9.28, 
&amp;#39;word_num&amp;#39;: 6}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;employee_replys&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;I&amp;#39;ll go look for that&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                   &lt;span class=&#34;s2&#34;&gt;&amp;#34;I&amp;#39;ll go search for that&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                   &lt;span class=&#34;s2&#34;&gt;&amp;#34;I&amp;#39;ll go search for that top&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                   &lt;span class=&#34;s2&#34;&gt;&amp;#34;I&amp;#39;ll go search for that t-shirt&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                   &lt;span class=&#34;s2&#34;&gt;&amp;#34;I&amp;#39;ll go look for that t-shirt in grey&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                   &lt;span class=&#34;s2&#34;&gt;&amp;#34;I&amp;#39;ll go search for that t-shirt in grey&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;

&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;idx&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;reply&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;enumerate&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;employee_replys&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;score&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ct&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sentiment_by_valence&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;reply&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
                                  &lt;span class=&#34;n&#34;&gt;diction&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;concreteness_dict&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
                                  &lt;span class=&#34;n&#34;&gt;lang&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;english&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
    
    &lt;span class=&#34;n&#34;&gt;template&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;Concreteness Score: &lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{score:.2f}&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt; | Example-&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{idx}&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;: &lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{exmaple}&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;
    
    &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;template&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;format&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;score&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;score&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;concreteness&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt; 
                          &lt;span class=&#34;n&#34;&gt;idx&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;idx&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
                          &lt;span class=&#34;n&#34;&gt;exmaple&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;reply&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;Concreteness Score: 9.28 | Example-0: I&amp;#39;ll go look for that
Concreteness Score: 9.32 | Example-1: I&amp;#39;ll go search for that
Concreteness Score: 13.25 | Example-2: I&amp;#39;ll go search for that top
Concreteness Score: 14.25 | Example-3: I&amp;#39;ll go search for that t-shirt
Concreteness Score: 21.32 | Example-4: I&amp;#39;ll go look for that t-shirt in grey
Concreteness Score: 21.36 | Example-5: I&amp;#39;ll go search for that t-shirt in grey
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h3 id=&#34;25-word_in_context&#34;&gt;2.5 word_in_context()&lt;/h3&gt;
&lt;p&gt;You shall know a word by the company it keeps通过一个单词所处的语境，我们可以了解该单词的含义。&lt;/p&gt;
&lt;p&gt;在text中查找keywords出现的上下文内容(窗口window)，返回df。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;ct.word_in_context(text, keywords, window=3, lang=&amp;#39;chinese&amp;#39;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;text&lt;/strong&gt;  待分析文本&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;keywords&lt;/strong&gt;  关键词列表&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;window&lt;/strong&gt;  关键词上下文窗口大小&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;lang&lt;/strong&gt; 文本的语言类型， 中文chinese、英文english，默认中文。&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;cntext&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;ct&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;#测试代码，假设zh_text是年报文本，从找找出丝网词相关词的上下文&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;zh_text&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&amp;#34;
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;【插入一条自家广告】大邓自己家的家，
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;安平县多隆丝网制品，生产销售不锈钢轧花网、
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;电焊网、石笼网、刀片刺绳、冲孔网等丝网制品。
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;联系人 邓颖静 0318-7686899
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;人生苦短，我学Python
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;在社科中，可以用Python做文本分析
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;Python是一门功能强大的编程语言，广泛应用在经管社科领域。
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;可以做网络爬虫、文本分析、LDA话题模型、相似度分析等。
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;今年经济不景气，形势异常严峻。
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;由于疫情不景气，静默管理， 产品积压， 公司经营困难。
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;保就业促就业，任务十分艰巨。
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;#【python】上下文&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;ct&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;word_in_context&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;text&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;zh_text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
                   &lt;span class=&#34;n&#34;&gt;keywords&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;python&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt; 
                   &lt;span class=&#34;n&#34;&gt;window&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
                   &lt;span class=&#34;n&#34;&gt;lang&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;chinese&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/20-word-in-context.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;26-epu&#34;&gt;2.6 epu()&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://textdata.cn/blog/2023-12-20-measure-china-economic-policy-uncertainty/&#34;&gt;&lt;strong&gt;代码  | 使用新闻数据测量经济政策不确定性EPU&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/13-epu-plot.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;epu(df, freq=&amp;#39;Y&amp;#39;, e_pattern=&amp;#39;&amp;#39;, p_pattern=&amp;#39;&amp;#39;, u_pattern=&amp;#39;&amp;#39;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;df&lt;/strong&gt;  新闻数据DataFrame， 含text和date两个字段。 每一行代表一条新闻记录&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;freq&lt;/strong&gt; 字符串； 确定EPU指数的时间颗粒度； 如年Y, 月m, 日d, 默认 freq=&amp;lsquo;Y&amp;rsquo;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;e_pattern&lt;/strong&gt; 字符串；经济类词典，用&lt;code&gt;|&lt;/code&gt;间隔词语，形如 &lt;strong&gt;e_pattern = ‘经济|金融’&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;p_pattern&lt;/strong&gt; 字符串；政策词典，用&lt;code&gt;|&lt;/code&gt;间隔词语，形如 &lt;strong&gt;p_pattern = ‘政策|治理|行政’&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;u_pattern&lt;/strong&gt;  字符串；不确定性词典，用&lt;code&gt;|&lt;/code&gt;间隔词语，形如 &lt;strong&gt;u_pattern = ‘风险|危机|难以预测’&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;准备如下图格式的数据 &lt;em&gt;&lt;strong&gt;news_df&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/12-news-df.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;cntext&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;ct&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;#省略，读取数据得到 news_df&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;epu_df&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ct&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;epu&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;news_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;freq&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;m&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;epu_df&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/13-epu-df.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;27-fepu&#34;&gt;2.7 fepu()&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://textdata.cn/blog/2024-04-25-firm-economic-policy-uncertainty/&#34;&gt;使用管理层讨论与分析文本数据测量「企业感知不确定性」(Subjective perception of economic policy uncertainty, FEPU)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/16-fepu-plot.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;ct.fepu(text, ep_pattern, u_pattern)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;text&lt;/strong&gt;&lt;/em&gt; ；某时期t某企业i的管理层讨论与分析md&amp;amp;a文本&lt;/li&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;ep_pattern&lt;/strong&gt;&lt;/em&gt; 字符串；经济政策类词典，用&lt;code&gt;|&lt;/code&gt;间隔词语，形如 &lt;strong&gt;ep_pattern = ‘经济|金融|政策|治理|行政’&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;u_pattern&lt;/strong&gt;&lt;/em&gt; 字符串；不确定性词典，用&lt;code&gt;|&lt;/code&gt;间隔词语，形如 &lt;strong&gt;u_pattern = ‘风险|危机|难以预测’&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;准备如下图格式的数据 &lt;em&gt;&lt;strong&gt;mda_df&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/14-mdadf.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;cntext&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;ct&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;#省略，读取数据得到 mda_df&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;fepu_df&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;经营讨论与分析内容&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;apply&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ct&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fepu&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;res_df&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;concat&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;([&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;会计年度&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;股票代码&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]],&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;fepu_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;   &lt;span class=&#34;n&#34;&gt;axis&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;res_df&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/15-fepu.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;br&gt;
&lt;h3 id=&#34;28-semantic_brand_score&#34;&gt;2.8 semantic_brand_score()&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://textdata.cn/blog/2024-04-12-semantic-brand-score/&#34;&gt;文献&amp;amp;代码 | 使用Python计算语义品牌评分(Semantic Brand Score, SBS)&lt;/a&gt; ， 通过 SBS 来衡量品牌（个体、公司、品牌、关键词等）的重要性。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;ct.semantic_brand_score(text, brands, lang=&amp;#39;chinese&amp;#39;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;text&lt;/strong&gt;&lt;/em&gt; 待分析文本&lt;/li&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;brands&lt;/strong&gt;&lt;/em&gt; 词语列表；&lt;/li&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;lang&lt;/strong&gt;&lt;/em&gt;  语言类型，&amp;ldquo;chinese&amp;quot;或&amp;quot;english&amp;rdquo;，默认&amp;quot;chinese&amp;quot;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;以三体小说为例，通过测量品牌语义评分SBS来反映小说角色的重要性。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;cntext&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;ct&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;brands&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;汪淼&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;史强&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;罗辑&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;叶文洁&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;伊文斯&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;#准备santi_test_text&lt;/span&gt;
&lt;span class=&#34;c1&#34;&gt;#小说等分20份， 读取第一份得到santi_test_text&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;sbs_df&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ct&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;semantic_brand_score&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;santi_test_text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
                               &lt;span class=&#34;n&#34;&gt;brands&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;brands&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
                               &lt;span class=&#34;n&#34;&gt;lang&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;chinese&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;sbs_df&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/19-1st-sbs.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;如果将三体小说分成20份， 每一份都测算出每个角色的SBS，绘制出折线图如下图所示。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/18-sbs-plot.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;h3 id=&#34;29-文本相似度&#34;&gt;2.9 文本相似度&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;ct.cosine_sim(text1, text2)   cos余弦相似
ct.jaccard_sim(text1, text2)  jaccard相似
ct.minedit_sim(text1, text2)  最小编辑距离相似度； 
ct.simple_sim(text1, text2)   更改变动算法
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;算法实现参考自 &lt;code&gt;Cohen, Lauren, Christopher Malloy, and Quoc Nguyen. Lazy prices. No. w25084. National Bureau of Economic Research, 2018.&lt;/code&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;cntext&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;ct&lt;/span&gt; 


&lt;span class=&#34;n&#34;&gt;text1&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;编程真好玩编程真好玩&amp;#39;&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;text2&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;游戏真好玩编程真好玩&amp;#39;&lt;/span&gt;

&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;cosine: &amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ct&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;cosine_sim&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;text1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;text2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;jaccard&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ct&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;jaccard_sim&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;text1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;text2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;minedit&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ct&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;minedit_sim&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;text1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;text2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;simple&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ct&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;simple_sim&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;text1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;text2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;cosine:  0.82
jaccard: 0.67
minedit: 1.00
simple:  0.84
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h3 id=&#34;210-ctword_hhi&#34;&gt;2.10 ct.word_hhi&lt;/h3&gt;
&lt;p&gt;文本的赫芬达尔-赫希曼指数。ct.word_hhi(text, lang=&amp;lsquo;chinese&amp;rsquo;)&lt;/p&gt;
&lt;br&gt;
&lt;p&gt;&lt;strong&gt;赫芬达尔-赫希曼指数&lt;/strong&gt;(&lt;strong&gt;Herfindahl-Hirschman Index&lt;/strong&gt;)作为一种衡量市场集中度的经济指标，通常用于分析产业或市场中企业份额的分布情况。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/word-hhi-algo.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;前人类比市场集中程度，用于测量专利质量(知识宽度)。 那放在文本语言中，我们是否可能利用HHI来量化某个语料库中不同词汇的使用频率分布，以此来分析个人、群体或时代的语言风格、词汇丰富度、或是语言标准化与变化的趋势。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如果词汇分布非常均匀，表明语言使用中的词汇多样性高，HHI值就会较低；&lt;/li&gt;
&lt;li&gt;反之，如果少数词汇占据了大部分文本空间，表明词汇使用集中，HHI值则较高。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;结合其他语言学指标一起使用，比如TTR（Type-Token Ratio，类型-标记比率）、Shannon entropy（香农熵）等，共同评估语言表达的复杂度和多样性。不过，这类研究的文献相对较少，因为语言学领域有自己一套成熟且专业的分析工具和方法，HHI更多地被视为跨学科应用的一个创新尝试。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;cntext&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;ct&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;personA&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;这场音乐会太嗨了&amp;#39;&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;personB&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;这场音乐会说出来令你不敢相信，主办方策划有方，群众激情满满，我印象深刻，体验感拉满&amp;#39;&lt;/span&gt;


&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;A-hhi&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ct&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;word_hhi&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;personA&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;B-hhi&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ct&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;word_hhi&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;personB&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;

&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;A词汇多样性&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ct&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;word_hhi&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;personA&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;B词汇多样性&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ct&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;word_hhi&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;personB&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;A-hhi 0.20000000000000004
B-hhi 0.07024793388429751

A词汇多样性 0.7999999999999999
B词汇多样性 0.9297520661157025
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;br&gt;
&lt;h2 id=&#34;三plot模块&#34;&gt;三、Plot模块&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;模块&lt;/th&gt;
&lt;th&gt;函数&lt;/th&gt;
&lt;th&gt;功能&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;plot&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;ct.matplotlib_chinese()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;支持matplotlib中文绘图&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;plot&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;ct.lexical_dispersion_plot1(text, targets_dict, lang, title, figsize)&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;对某一个文本text， 可视化不同目标类别词targets_dict在文本中出现位置&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;plot&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;ct.lexical_dispersion_plot2(texts_dict, targets, lang, title, figsize)&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;对某几个文本texts_dict， 可视化某些目标词targets在文本中出现相对位置(0~100)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;br&gt;
&lt;h3 id=&#34;31-matplotlib_chinese&#34;&gt;3.1 matplotlib_chinese()&lt;/h3&gt;
&lt;p&gt;matplotlib默认不支持中文可视化， cntext新增该函数，可以解决中文可视化问题&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;cntext&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;ct&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;plt&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ct&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;matplotlib_chinese&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;plt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;figure&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;figsize&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;7&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;plt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;plot&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;([&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;9&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;16&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;plt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;title&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;中文图表&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;fontsize&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;plt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;show&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/27-chinese-matplotlib.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;32-lexical_dispersion_plot1&#34;&gt;3.2 lexical_dispersion_plot1()&lt;/h3&gt;
&lt;p&gt;词汇分散图可视化， 对某一个文本text， 可视化不同目标类别词targets_dict在文本中出现位置&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;ct&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;lexical_dispersion_plot1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;targets_dict&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;lang&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;chinese&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;figsize&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;12&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;6&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;title&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;特定词汇在不同文本来源的相对离散图&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;prop&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;text&lt;/strong&gt;&lt;/em&gt;: 文本数据&lt;/li&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;targets_dict&lt;/strong&gt;&lt;/em&gt;:  目标类别词字典； targets_dict={&amp;lsquo;pos&amp;rsquo;: [&amp;lsquo;开心&amp;rsquo;, &amp;lsquo;快乐&amp;rsquo;], &amp;lsquo;neg&amp;rsquo;: [&amp;lsquo;悲伤&amp;rsquo;, &amp;lsquo;难过&amp;rsquo;]}&lt;/li&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;lang&lt;/strong&gt;&lt;/em&gt;: 文本数据texts_dict的语言类型，默认&amp;rsquo;chinese&#39;.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;figsize&lt;/strong&gt;&lt;/em&gt;: 图的长宽尺寸. 默认 (8, 5).&lt;/li&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;title&lt;/strong&gt;&lt;/em&gt; : 图的标题；&lt;/li&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;prop&lt;/strong&gt;&lt;/em&gt;: 横坐标字符位置是否为相对位置. 默认True，横坐标索引值取值范围0 ~ 100&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
&lt;p&gt;点击下载 &lt;a href=&#34;https://textdata.cn/data/%E4%B8%89%E4%BD%93.txt&#34;&gt;&lt;strong&gt;三体.txt&lt;/strong&gt;&lt;/a&gt;、&lt;a href=&#34;https://textdata.cn/data/%E5%9F%BA%E5%9C%B0.txt&#34;&gt;&lt;strong&gt;基地.txt&lt;/strong&gt;&lt;/a&gt;两本小说文件。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;cntext&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;ct&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;roles_dict&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
    &lt;span class=&#34;s2&#34;&gt;&amp;#34;汪淼&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;汪淼&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;
    &lt;span class=&#34;s2&#34;&gt;&amp;#34;叶文洁&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;叶文洁&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;
    &lt;span class=&#34;s2&#34;&gt;&amp;#34;罗辑&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;罗辑&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;santi_text&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;open&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;三体.txt&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;encoding&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;utf-8&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;ax&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ct&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;lexical_dispersion_plot1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;text&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;santi_text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;#文本数据&lt;/span&gt;
                            &lt;span class=&#34;n&#34;&gt;targets_dict&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;roles_dict&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;#角色&lt;/span&gt;
                            &lt;span class=&#34;n&#34;&gt;figsize&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;#尺寸大小&lt;/span&gt;
                            &lt;span class=&#34;n&#34;&gt;lang&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;chinese&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;#中文数据&lt;/span&gt;
                            &lt;span class=&#34;n&#34;&gt;title&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;《三体》小说角色出现位置&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;#标题&lt;/span&gt;
                            &lt;span class=&#34;n&#34;&gt;prop&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;    &lt;span class=&#34;c1&#34;&gt;#相对位置(横坐标轴取值范围0-100)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;ax&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/23-lexical_dispersion_plot1-relative.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;ct&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;lexical_dispersion_plot1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;text&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;santi_text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;#文本数据&lt;/span&gt;
                            &lt;span class=&#34;n&#34;&gt;targets_dict&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;roles_dict&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;#角色&lt;/span&gt;
                            &lt;span class=&#34;n&#34;&gt;figsize&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;#尺寸大小&lt;/span&gt;
                            &lt;span class=&#34;n&#34;&gt;lang&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;chinese&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;#中文数据&lt;/span&gt;
                            &lt;span class=&#34;n&#34;&gt;title&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;《三体》小说角色出现位置&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;#标题&lt;/span&gt;
                            &lt;span class=&#34;n&#34;&gt;prop&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;False&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;    &lt;span class=&#34;c1&#34;&gt;#绝对位置(横坐标轴取值范围与小说文本长度有关)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/24-lexical_dispersion_plot1-absolute.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;cntext&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;ct&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;#diy了一个小词典&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;senti_dict&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
    &lt;span class=&#34;s1&#34;&gt;&amp;#39;pos&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;开心&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;幸福&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;快乐&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;安宁&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;希望&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;
    &lt;span class=&#34;s1&#34;&gt;&amp;#39;neg&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;紧张&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;恐惧&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;害怕&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;绝望&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;santi_text&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;open&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;三体.txt&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;encoding&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;utf-8&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;ax&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ct&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;lexical_dispersion_plot1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;text&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;santi_text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
                            &lt;span class=&#34;n&#34;&gt;targets_dict&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;senti_dict&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
                            &lt;span class=&#34;n&#34;&gt;figsize&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; 
                            &lt;span class=&#34;n&#34;&gt;lang&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;chinese&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
                            &lt;span class=&#34;n&#34;&gt;title&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;《三体》情绪词出现位置&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                            &lt;span class=&#34;n&#34;&gt;prop&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;ax&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/25-santi_sentiment.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;33-lexical_dispersion_plot2&#34;&gt;3.3 lexical_dispersion_plot2()&lt;/h3&gt;
&lt;p&gt;词汇分散图可视化， 对某几个文本texts_dict， 可视化某些目标词targets在文本中出现相对位置(0~100)&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;ct&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;lexical_dispersion_plot2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;texts_dict&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;targets&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;lang&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;chinese&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;figsize&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;12&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;6&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;title&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;特定词汇在不同文本来源的相对离散图&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;texts_dict&lt;/strong&gt;&lt;/em&gt;: 多个文本的字典数据。形如{&amp;lsquo;source1&amp;rsquo;: &amp;lsquo;source1的文本内容&amp;rsquo;, &amp;lsquo;source2&amp;rsquo;: &amp;lsquo;source2的文本内容&amp;rsquo;}&lt;/li&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;targets&lt;/strong&gt;&lt;/em&gt;: 目标词列表&lt;/li&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;lang&lt;/strong&gt;&lt;/em&gt;: 文本数据texts_dict的语言类型，默认&amp;rsquo;chinese&#39;.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;figsize&lt;/strong&gt;&lt;/em&gt;: 图的长宽尺寸. 默认 (8, 5).&lt;/li&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;title&lt;/strong&gt;&lt;/em&gt; : 图的标题；&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;targets&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;太空&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;宇宙&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;texts_dict&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;三体&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;open&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;三体.txt&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;encoding&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;utf-8&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(),&lt;/span&gt;
              &lt;span class=&#34;s1&#34;&gt;&amp;#39;基地&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;open&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;基地.txt&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;encoding&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;utf-8&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()}&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;ax&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ct&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;lexical_dispersion_plot2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;texts_dict&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;texts_dict&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                            &lt;span class=&#34;n&#34;&gt;targets&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;targets&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
                            &lt;span class=&#34;n&#34;&gt;figsize&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; 
                            &lt;span class=&#34;n&#34;&gt;title&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;&amp;#34;太空/宇宙&amp;#34;词语出现位置&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                            &lt;span class=&#34;n&#34;&gt;lang&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;chinese&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;ax&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/26-santi_base.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;四model模块&#34;&gt;四、Model模块&lt;/h2&gt;
&lt;p&gt;本部分主要内容是词嵌入模型相关技术， 包括Word2Vec(GLove)的训练、读取、扩展词典。&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;模块&lt;/th&gt;
&lt;th&gt;函数(类)&lt;/th&gt;
&lt;th&gt;功能&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;model&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;ct.W2VModel(corpus_file, encoding, lang=&amp;lsquo;chinese&amp;rsquo;)&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;训练Word2Vec&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;model&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;ct.load_wv(wv_path)&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;读取cntext2.x训练出的word2vec模型文件&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;model&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;ct.glove2word2vec(glove_file, word2vec_file)&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;将GLoVe模型.txt文件转化为Word2Vec模型.txt文件；注意这里的GLoVe模型.txt是通过&lt;a href=&#34;https://github.com/standfordnlp/GloVe&#34;&gt;Standfordnlp/GloVe&lt;/a&gt; 训练得到的&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;model&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;ct.expand_dictionary(wv,  seeddict, topn=100)&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;扩展词典,  结果保存到路径[output/Word2Vec]中&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;model&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;ct.Glove(corpus_file, lang=&#39;chinese&#39;)&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;训练GLove模型。 算法运行较慢，吃内存，不推荐！！&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;model&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;ct.SoPmi(corpus_file, seed_file, lang=&#39;chinese&#39;)&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;共现法扩展词典&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;41-w2vmodel&#34;&gt;4.1 W2VModel()&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;model = ct.W2VModel(corpus_file,  encoding=&amp;#39;utf-8&amp;#39;, lang=&amp;#39;chinese&amp;#39;) 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;corpus_file&lt;/strong&gt; 语料txt文件路径&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;encoding&lt;/strong&gt; 语料txt文件编码方式&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;lang&lt;/strong&gt; 语料的语言类型， 中文chinese、英文english，默认中文。&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;model.train()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;cntext&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;ct&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;#训练模型&lt;/span&gt;
&lt;span class=&#34;c1&#34;&gt;#[data/三体.txt]体积2.7M&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;w2v&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ct&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;W2VModel&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;corpus_file&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;data/三体.txt&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;#语料txt文件路径&lt;/span&gt;
                  &lt;span class=&#34;n&#34;&gt;encoding&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;utf-8&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;#语料txt文件编码方式&lt;/span&gt;
                  &lt;span class=&#34;n&#34;&gt;lang&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;chinese&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;#英文传english&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;w2v&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;train&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;#设置存储&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;Start Training! This may take a while. Please be patient...

Training word2vec model took 5 seconds

Note: The Word2Vec model has been saved to output/Word2Vec
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;[data/三体.txt]体积2.7M，  训练时间5s， 模型文件存储于 &lt;em&gt;&lt;strong&gt;output/Word2Vec/三体.100.6.bin&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/03-word2vec.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;42-glove&#34;&gt;4.2 Glove()&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;ct.Glove(corpus_file, lang=&amp;#39;chinese&amp;#39;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;corpus_file&lt;/strong&gt; 语料txt文件路径&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;lang&lt;/strong&gt; 语料的语言类型， 中文chinese、英文english，默认中文&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;GLove算法的运算速度非常慢， cntext并没有对此进行优化，强烈不建议百兆以上语料使用本算法。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;cntext&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;ct&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;os&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;model&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ct&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Glove&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;corpus_file&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;data/三体.txt&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
                 &lt;span class=&#34;n&#34;&gt;lang&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;chinese&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;model&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;train&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;Create vocabulary for Glove.

Create cooccurrence matrix.

Create cooccurrence matrix.
To complete this task, the code may take a significant amount of time, ranging from several minutes to potentially hours. Please be patient while the process runs.

Iteration 20: error 10541294.8481
Finish training! Used 22.38 s

Save the glove embeddings to a binary file
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/05-glove.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;训练生成的 &lt;code&gt;output/Glove/glove.三体.50.bin&lt;/code&gt; 也可用 &lt;em&gt;&lt;strong&gt;ct.load_w2v&lt;/strong&gt;&lt;/em&gt; 读取，这里就不展示了。&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;43-sopm&#34;&gt;4.3 SoPm()&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;ct.SoPmi(corpus_file, seed_file)       #人工标注的初始种子词
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;corpus_file&lt;/strong&gt;  语料txt文件路径&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;seed_file&lt;/strong&gt; 初始种子词txt文件路径&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;共现法&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;cntext&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;ct&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;sopmier&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ct&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;SoPmi&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;corpus_file&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;data/sopmi_corpus.txt&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;   
                   &lt;span class=&#34;n&#34;&gt;seed_file&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;data/sopmi_seed.txt&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;       &lt;span class=&#34;c1&#34;&gt;#人工标注的初始种子词&lt;/span&gt;
                     

&lt;span class=&#34;n&#34;&gt;sopmier&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;train&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;Step 1/4:...Preprocess   Corpus ...
Step 2/4:...Collect co-occurrency information ...
Step 3/4:...Calculate   mutual information ...
Step 4/4:...Save    candidate words ...
Finish! used 19.74 s
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/06-sopmi.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;44-load_wv&#34;&gt;4.4 load_wv()&lt;/h3&gt;
&lt;p&gt;导入cntext2.x 预训练的word2vec模型 .txt文件&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;ct.load_wv(wv_path, binary=False)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;wv_path&lt;/strong&gt; 模型文件路径&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;读取  &lt;em&gt;&lt;strong&gt;output/Word2Vec/三体.100.6.txt&lt;/strong&gt;&lt;/em&gt; 模型文件,  返回 &lt;code&gt;gensim.models.word2vec.Word2Vec&lt;/code&gt; 类型。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;cntext&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;ct&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;# 使用gensim也可读取训练的模型&lt;/span&gt;
&lt;span class=&#34;c1&#34;&gt;# from gensim.models import KeyedVectors&lt;/span&gt;
&lt;span class=&#34;c1&#34;&gt;# santi_wv = KeyedVectors.load_word2vec_format(&amp;#39;output/Word2Vec/三体.100.6.txt&amp;#39;, binary=False)&lt;/span&gt;
&lt;span class=&#34;c1&#34;&gt;# santi_wv = KeyedVectors.load_word2vec_format(&amp;#39;output/Word2Vec/三体.100.6.bin&amp;#39;, binary=True)&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;santi_wv&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ct&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;load_wv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv_path&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;output/Word2Vec/三体.100.6.txt&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;c1&#34;&gt;# santi_wv = ct.load_wv(wv_path=&amp;#39;output/Word2Vec/三体.100.6.bin&amp;#39;, binary=True)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;santi_wv&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;Loading word2vec model txt file...
&amp;lt;gensim.models.word2vec.KeyedVectors at 0x33f535640&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h3 id=&#34;45-glove2word2vec&#34;&gt;4.5 glove2word2vec()&lt;/h3&gt;
&lt;p&gt;将GLoVe模型.txt文件转化为Word2Vec模型.txt文件；&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;ct&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;glove2word2vec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;glove_file&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;word2vec_file&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;glove_file&lt;/strong&gt;&lt;/em&gt;: GLoVe模型.txt文件路径&lt;/li&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;word2vec_file&lt;/strong&gt;&lt;/em&gt;: Word2Vec模型.txt文件路径&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
&lt;p&gt;注意这里的GLoVe模型.txt是通过&lt;a href=&#34;https://github.com/standfordnlp/GloVe&#34;&gt;Standfordnlp/GloVe&lt;/a&gt; 训练得到的&lt;/p&gt;
&lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;cntext&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;ct&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;ct&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;glove2word2vec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;glove_file&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;data/GloVe.6B.50d.txt&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                  &lt;span class=&#34;n&#34;&gt;word2vec_file&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;output/word2vec_format_GloVe.6B.50d.txt&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h3 id=&#34;注意&#34;&gt;注意&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;ct.load_wv()&lt;/strong&gt;&lt;/em&gt; 导入后得到的数据类型是 &lt;em&gt;&lt;strong&gt;gensim.models.keyedvectors.KeyedVectors&lt;/strong&gt;&lt;/em&gt; 。&lt;/li&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;gensim.models.word2vec.Word2Vec&lt;/strong&gt;&lt;/em&gt; 可以转化为  &lt;em&gt;&lt;strong&gt;gensim.models.keyedvectors.KeyedVectors&lt;/strong&gt;&lt;/em&gt; ，&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;例如&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;santi_w2v.wv
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&amp;lt;gensim.models.keyedvectors.KeyedVectors at 0x319f4a090&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h3 id=&#34;46-expand_dictionary&#34;&gt;4.6 expand_dictionary()&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;ct.expand_dictionary(wv,  seeddict, topn=100)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;wv&lt;/strong&gt;  预训练模型，数据类型为 gensim.models.keyedvectors.KeyedVectors。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;seeddict&lt;/strong&gt;  参数类似于种子词；格式为PYTHON字典；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;topn&lt;/strong&gt; 返回topn个语义最接近seeddict的词&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;根据设置的seeddict,  可按类别扩展并生成对应的词典txt文件， txt文件位于[output/Word2Vec]中。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;seeddict&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
    &lt;span class=&#34;s1&#34;&gt;&amp;#39;人物&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;叶文洁&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;史强&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;罗辑&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt; 
    &lt;span class=&#34;s1&#34;&gt;&amp;#39;物体&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;飞船&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;车辆&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;


&lt;span class=&#34;n&#34;&gt;ct&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;expand_dictionary&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;santi_w2v&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;  
                     &lt;span class=&#34;n&#34;&gt;seeddict&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;seeddict&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
                     &lt;span class=&#34;n&#34;&gt;topn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/04-expand.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;br&gt;
&lt;h2 id=&#34;五mind模块&#34;&gt;五、Mind模块&lt;/h2&gt;
&lt;p&gt;词嵌入中蕴含着人类的认知信息，以往的词嵌入大多是比较一个概念中两组反义词与某对象的距离计算认知信息。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;多个对象与某概念的语义远近&lt;/strong&gt;，职业与性别，某个职业是否存在亲近男性，而排斥女性&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;多个对象在某概念向量投影的大小， 人类语言中留存着对不同动物体积的认知记忆，如小鼠大象。动物词在词向量空间中是否能留存着这种大小的记忆&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;本模块主要是利用已训练出的word2vec模型，挖掘潜在的态度偏见、刻板印象等。 这部分难度较大， 建议有精力且电脑性能好的同学可以用 cntext 训练模型， 再来实验Mind模块。&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;模块&lt;/th&gt;
&lt;th&gt;函数(类)&lt;/th&gt;
&lt;th&gt;功能&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;mind&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;ct.sematic_projection(wv, words, c_words1, c_words2)&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;测量语义投影&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;mind&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;ct.sematic_distance(wv, words, c_words1, c_words2)&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;测量语义距离&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;mind&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;ct.divergent_association_task(wv, words)&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;测量发散思维(创造力)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;mind&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;ct.discursive_diversity_score(wv, words)&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;测量语言差异性(认知差异性)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;mind&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;ct.procrustes_align(base_wv, other_wv)&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;两个word2vec进行语义对齐，可反应随时间的社会语义变迁&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;br&gt;
&lt;h3 id=&#34;51-sematic_distance&#34;&gt;5.1 sematic_distance()&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;多个对象与某概念的语义远近&lt;/strong&gt;，例如成功与性别，成功是否存在亲近男性，而排斥女性&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/21-music-success-genderbias.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;ct.sematic_distance(wv, words, c_words1, c_words2) 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;wv&lt;/strong&gt;&lt;/em&gt;   模型数据， 数据类型为 gensim.models.keyedvectors.KeyedVectors。&lt;/li&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;words&lt;/strong&gt;&lt;/em&gt;、&lt;em&gt;&lt;strong&gt;c_words2&lt;/strong&gt;&lt;/em&gt;、&lt;em&gt;&lt;strong&gt;c_words2&lt;/strong&gt;&lt;/em&gt; 均为词语列表&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;分别计算 &lt;em&gt;&lt;strong&gt;words&lt;/strong&gt;&lt;/em&gt; 与  &lt;em&gt;&lt;strong&gt;c_words1&lt;/strong&gt;&lt;/em&gt; 、&lt;em&gt;&lt;strong&gt;c_words2&lt;/strong&gt;&lt;/em&gt; 语义距离，返回距离差值。例如&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;male_concept = [&amp;#39;male&amp;#39;, &amp;#39;man&amp;#39;, &amp;#39;he&amp;#39;, &amp;#39;him&amp;#39;]
female_concept = [&amp;#39;female&amp;#39;, &amp;#39;woman&amp;#39;, &amp;#39;she&amp;#39;, &amp;#39;her&amp;#39;]
software_engineer_concept  = [&amp;#39;engineer&amp;#39;,  &amp;#39;programming&amp;#39;,  &amp;#39;software&amp;#39;]
d1 = distance(male_concept,  software_engineer_concept)
d2 = distance(female_concept,  software_engineer_concept)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;如果 &lt;em&gt;&lt;strong&gt;d1-d2&amp;lt;0&lt;/strong&gt;&lt;/em&gt;，说明在语义空间中，&lt;em&gt;&lt;strong&gt;software_engineer_concept&lt;/strong&gt;&lt;/em&gt; 更接近 &lt;em&gt;&lt;strong&gt;male_concept&lt;/strong&gt;&lt;/em&gt; ，更远离 &lt;em&gt;&lt;strong&gt;female_concept&lt;/strong&gt;&lt;/em&gt; 。&lt;/p&gt;
&lt;p&gt;换言之，在该语料中，人们对软件工程师这一类工作，对女性存在刻板印象(偏见)。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;cntext&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;ct&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;# glove_w2v.6B.100d.txt链接: https://pan.baidu.com/s/1MMfQ7M0YCzL9Klp4zrlHBw 提取码: 72l0 &lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;g_wv&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;KeyedVectors&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;load_word2vec_format&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;glove_w2v.6B.100d.txt&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;no_header&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;False&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;c1&#34;&gt;#g_wv是gensim.models.keyedvectors.KeyedVectors&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;engineer&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;program&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;software&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;computer&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;man_words&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;  &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;man&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;he&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;him&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;woman_words&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;woman&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;she&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;her&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;#在语义空间中，工程师更接近于男人，而不是女人。&lt;/span&gt;
&lt;span class=&#34;c1&#34;&gt;#in semantic space, engineer is closer to man, other than woman.&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;ct&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sematic_distance&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;g_wv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                    &lt;span class=&#34;n&#34;&gt;words&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;engineer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
                    &lt;span class=&#34;n&#34;&gt;c_words1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;man_words&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
                    &lt;span class=&#34;n&#34;&gt;c_words2&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;woman_words&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;-0.38
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h3 id=&#34;52-sematic_projection&#34;&gt;5.2 sematic_projection()&lt;/h3&gt;
&lt;p&gt;多个对象在某概念向量投影的大小&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;ct.sematic_projection(wv, words, c_words1, c_words2) 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;wv&lt;/strong&gt;&lt;/em&gt;   模型数据， 数据类型为gensim.models.keyedvectors.KeyedVectors。&lt;/li&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;words&lt;/strong&gt;&lt;/em&gt;、&lt;em&gt;&lt;strong&gt;c_words2&lt;/strong&gt;&lt;/em&gt;、&lt;em&gt;&lt;strong&gt;c_words2&lt;/strong&gt;&lt;/em&gt; 均为词语列表&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;为了解释词向量模型的语义投影，我使用了 2022 年 Nature 论文中的图片[@Grand2022SemanticPR]。 关于动物的名字，人类对动物大小的认知信息隐藏在语料库文本中。 通过将&lt;strong&gt;LARGE WORDS&lt;/strong&gt; 和&lt;strong&gt;SMALL WORDS&lt;/strong&gt;的含义用不同的&lt;strong&gt;animals&lt;/strong&gt;的向量投影，动物在&lt;strong&gt;size向量&lt;/strong&gt;上的投影（就像下图中的红线 ) 得到，因此可以通过计算比较动物的大小。&lt;/p&gt;
&lt;p&gt;根据两组反义词 &lt;em&gt;&lt;strong&gt;c_words1&lt;/strong&gt;&lt;/em&gt; ,    &lt;em&gt;&lt;strong&gt;c_words2&lt;/strong&gt;&lt;/em&gt; 构建一个概念(认知)向量, words中的每个词向量在概念向量中投影，即可得到认知信息。&lt;/p&gt;
&lt;p&gt;分值越大，&lt;em&gt;&lt;strong&gt;words&lt;/strong&gt;&lt;/em&gt; 越位于 &lt;em&gt;&lt;strong&gt;c_words2&lt;/strong&gt;&lt;/em&gt; 一侧。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Grand, G., Blank, I.A., Pereira, F. and Fedorenko, E., 2022. Semantic projection recovers rich human knowledge of multiple object features from word embeddings. &lt;em&gt;Nature Human Behaviour&lt;/em&gt;, pp.1-13.&amp;quot;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/22-semantic_projection.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;例如，人类的语言中，存在尺寸、性别、年龄、政治、速度、财富等不同的概念。每个概念可以由两组反义词确定概念的向量方向。&lt;/p&gt;
&lt;p&gt;以尺寸为例，动物在人类认知中可能存在体积尺寸大小差异。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;animals&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;mouse&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;cat&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;horse&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;  &lt;span class=&#34;s1&#34;&gt;&amp;#39;pig&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;whale&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;small_words&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;small&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;little&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;tiny&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;large_words&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;large&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;big&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;huge&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;#wiki_wv = 导入wiki的模型。&lt;/span&gt;
&lt;span class=&#34;c1&#34;&gt;#wiki_wv&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;# In size conception, mouse is smallest, horse is biggest.&lt;/span&gt;
&lt;span class=&#34;c1&#34;&gt;# 在大小概念上，老鼠最小，马是最大的。&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;ct&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sematic_projection&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wiki_wv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                      &lt;span class=&#34;n&#34;&gt;words&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;animals&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
                      &lt;span class=&#34;n&#34;&gt;c_words1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;small_words&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
                      &lt;span class=&#34;n&#34;&gt;c_words2&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;large_words&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;[(&amp;#39;mouse&amp;#39;, -1.68),
 (&amp;#39;cat&amp;#39;, -0.92),
 (&amp;#39;pig&amp;#39;, -0.46),
 (&amp;#39;whale&amp;#39;, -0.24),
 (&amp;#39;horse&amp;#39;, 0.4)]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;关于尺寸的认知，人类在文本中隐含着老鼠较小，马较大。&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;53-divergent_association_task&#34;&gt;5.3 divergent_association_task()&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://textdata.cn/blog/2022-11-14-pnas_naming_unrelated_words_predicts_creativity/&#34;&gt;PNAS | 使用语义距离测量一个人的创新力(发散思维)得分&lt;/a&gt;。一些理论认为，有 创造力 的人能够产生更多 发散性 的想法。如果这是正确的，简单地让被试写 N 个不相关的单词，然后测量这N个词的语义距离， 作为发散思维的客观衡量标准。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;ct.divergent_association_task(wv, words)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;wv&lt;/strong&gt;&lt;/em&gt;   模型数据， 数据类型为 gensim.models.keyedvectors.KeyedVectors。&lt;/li&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;words&lt;/strong&gt;&lt;/em&gt;词语列表&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;low_words = [&amp;#34;arm&amp;#34;, &amp;#34;eyes&amp;#34;, &amp;#34;feet&amp;#34;, &amp;#34;hand&amp;#34;, &amp;#34;head&amp;#34;, &amp;#34;leg&amp;#34;, &amp;#34;body&amp;#34;]
average_words = [&amp;#34;bag&amp;#34;, &amp;#34;bee&amp;#34;, &amp;#34;burger&amp;#34;, &amp;#34;feast&amp;#34;, &amp;#34;office&amp;#34;, &amp;#34;shoes&amp;#34;, &amp;#34;tree&amp;#34;]
high_words = [&amp;#34;hippo&amp;#34;, &amp;#34;jumper&amp;#34;, &amp;#34;machinery&amp;#34;, &amp;#34;prickle&amp;#34;, &amp;#34;tickets&amp;#34;, &amp;#34;tomato&amp;#34;, &amp;#34;violin&amp;#34;]

# 导入模型，得到wv。
# wv为gensim.models.keyedvectors.KeyedVectors类型

print(ct.divergent_association_task(wv, low_words)) # 50
print(ct.divergent_association_task(wv, average_words)) # 78
print(ct.divergent_association_task(wv, high_words)) # 95
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;50
78
95
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h3 id=&#34;54-discursive_diversity_score&#34;&gt;5.4 discursive_diversity_score()&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://textdata.cn/blog/2023-11-02-measure-cognitive-diversity-through-language-discursive-diversity/&#34;&gt;MS2022 | 使用语言差异性测量团队认知差异性&lt;/a&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;ct.discursive_diversity_score(wv, words)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;wv&lt;/strong&gt;&lt;/em&gt;   模型数据， 数据类型为 gensim.models.keyedvectors.KeyedVectors。&lt;/li&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;words&lt;/strong&gt;&lt;/em&gt;词语列表&lt;/li&gt;
&lt;li&gt;返回一个数值&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/23-low-and-high-examples-of-discursive-diversity.jpeg&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;高绩效团队是那些具有调节共享认知以适应不断变化的任务要求的集体能力的团队：在进行构思任务时，它们表现出更高的话语多样性，在执行协调任务时，表现出较低的话语多样性。&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;55-procrustes_align&#34;&gt;5.5 procrustes_align()&lt;/h3&gt;
&lt;p&gt;该函数主要用于反映同一研究对象随着时间推进的社会文化变迁，或者同一时间范围内两个被研究主体间的差异。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;ct.procrustes_align(base_wv, other_wv, words=None)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;base_wv (gensim.models.keyedvectors.KeyedVectors): 基准语言模型&lt;/li&gt;
&lt;li&gt;other_wv (gensim.models.keyedvectors.KeyedVectors): 其他语言模型&lt;/li&gt;
&lt;li&gt;words (list, optional): 是否根据词典words对模型进行对齐， 对齐结束后的模型中含有的词不会超出words的范围； 默认None.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;由于不同语料训练的Word2Vec模型无法直接比较， 需要先选定一个基准模型 &lt;em&gt;&lt;strong&gt;base_embed&lt;/strong&gt;&lt;/em&gt;， 之后根据 &lt;em&gt;&lt;strong&gt;base_embed&lt;/strong&gt;&lt;/em&gt; 对其他模型 &lt;em&gt;&lt;strong&gt;other_embed&lt;/strong&gt;&lt;/em&gt; 进行调整，调整后的模型就可以使用前面的语义距离函数或者语义投影函数。 这一过程用到的算法叫做 procrustes正交算法。&lt;/p&gt;
&lt;p&gt;这里推荐一篇 &lt;a href=&#34;https://textdata.cn/blog/2023-12-28-visualize-the-culture-change-using-people-daily-dataset/&#34;&gt;可视化 | 人民日报语料反映七十年文化演变&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;六llm模块&#34;&gt;六、LLM模块&lt;/h2&gt;
&lt;p&gt;目前大模型本地化使用越来越方便，&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;模块&lt;/th&gt;
&lt;th&gt;函数(类)&lt;/th&gt;
&lt;th&gt;功能&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;LLM&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;text_analysis_by_llm(text, prompt, base_url, api_key, model_name, temperature, output_format)&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;使用大模型进行文本分析&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;61-analysis_by_llm&#34;&gt;6.1 analysis_by_llm()&lt;/h3&gt;
&lt;p&gt;使用大模型（本地或API）进行文本分析，从非结构化的文本数据中识别模式、提取关键信息、理解语义，并将其转化为结构化数据以便进一步分析和应用。&lt;/p&gt;
&lt;br&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;analysis_by_llm(text, prompt, base_url, api_key, model_name, output_format, max_retries, return_df)&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;text&lt;/strong&gt;&lt;/em&gt;: 待分析的文本&lt;/li&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;prompt&lt;/strong&gt;&lt;/em&gt; 提示Prompt, 默认 prompt=&amp;ldquo;根据评论内容，返回文本的情感类别(pos、neg)&amp;rdquo;, 可判断文本pos或neg&lt;/li&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;base_url&lt;/strong&gt;&lt;/em&gt;: 大模型API接口， 默认base_url=&#39;&#39;， 默认使用的本地Ollama搭建服务的API接口；&lt;/li&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;api_key&lt;/strong&gt;&lt;/em&gt;: 大模型API对应的KEY， 默认api_key=&#39;&#39; 表示使用的本地Ollama搭建服务&lt;/li&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;model_name&lt;/strong&gt;&lt;/em&gt;: 模型名；默认使用 model_name=&amp;ldquo;qwen2.5:3b&amp;rdquo;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;temperature&lt;/strong&gt;&lt;/em&gt;:  控制模型输出结果的随机性，取值范围0到无穷, 常用的范围[0, 1]。虽然理论上可以设置大于 1 的值，但这样会导致输出过于随机，通常不推荐这样做。需要结合任务确定取值
&lt;ul&gt;
&lt;li&gt;高准确性一致性任务，如情感分析、文本分类、事实性回答， 建议temperature=0&lt;/li&gt;
&lt;li&gt;高创造性和多样性任务， 如故事写作、头脑风暴等， 建议temperature=0.7&lt;/li&gt;
&lt;li&gt;实验性或探索性任务，较高的 &lt;code&gt;temperature&lt;/code&gt; 值（如 1.0 以上，但一般不推荐超过 2.0）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;output_format&lt;/strong&gt;&lt;/em&gt;: 设置分析结果的输出格式; 默认output_format = {&amp;lsquo;label&amp;rsquo;: str, &amp;lsquo;score&amp;rsquo;: float},   输出结果为字典， 含字段类别字段label和数值字段score&lt;/li&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;max_retries&lt;/strong&gt;&lt;/em&gt;: 最大失败次数， 默认max_retries=3&lt;/li&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;return_df&lt;/strong&gt;&lt;/em&gt;: 返回结果是否为dataframe， 默认False&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
&lt;p&gt;&lt;strong&gt;实验数据为外卖评论， 今天咱们做个有难度的文本分析任务，从不同维度(味道、速度、服务)对外卖评论进行打分(-1.0~1.0)&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/28-llm-analysis.png&#34; alt=&#34;&#34;  /&gt;
&lt;br&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;cntext&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;ct&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;PROMPT&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;从口味taste、速度speed、服务service三个维度， 对外卖评论内容进行文本分析， 分别返回不同维度的分值(分值范围-1.0 ~ 1.0)&amp;#39;&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;BASE_URL&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;https://dashscope.aliyuncs.com/compatible-mode/v1&amp;#39;&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;API_KEY&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;你的API-KEY&amp;#39;&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;MODEL_NAME&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;qwen-max&amp;#39;&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;#味道、速度、服务&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;OUTPUT_FORMAT&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;taste&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;float&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;speed&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;float&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;service&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;float&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;COMMENT_CONTENT&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;太难吃了&amp;#39;&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;#使用&lt;/span&gt;
&lt;span class=&#34;c1&#34;&gt;#result = ct.analysis_by_llm(text=COMMENT_CONTENT, &lt;/span&gt;
&lt;span class=&#34;c1&#34;&gt;#或&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;result&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ct&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;text_analysis_by_llm&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;COMMENT_CONTENT&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
                                 &lt;span class=&#34;n&#34;&gt;prompt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;PROMPT&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                                 &lt;span class=&#34;n&#34;&gt;base_url&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;BASE_URL&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
                                 &lt;span class=&#34;n&#34;&gt;api_key&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;API_KEY&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
                                 &lt;span class=&#34;n&#34;&gt;model_name&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;MODEL_NAME&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
                                 &lt;span class=&#34;n&#34;&gt;temperature&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                                 &lt;span class=&#34;n&#34;&gt;output_format&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;OUTPUT_FORMAT&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
                                 &lt;span class=&#34;n&#34;&gt;max_retries&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;  
                                 &lt;span class=&#34;n&#34;&gt;return_df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;False&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;result&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;{&amp;#39;taste&amp;#39;: -1.0, &amp;#39;speed&amp;#39;: 0.0, &amp;#39;service&amp;#39;: 0.0}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;p&gt;批量运算&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;import pandas as pd
import cntext as ct


#构造实验数据
data = [&amp;#39;速度非常快，口味非常好， 服务非常棒！&amp;#39;, 
        &amp;#39;送餐时间还是比较久&amp;#39;,
        &amp;#39;送单很快，菜也不错赞&amp;#39;,
        &amp;#39;太难吃了&amp;#39;]
df = pd.DataFrame(data, columns=[&amp;#39;comment&amp;#39;])


#分析函数
def llm_analysis(text):
    result = ct.analysis_by_llm(text=text, 
                                prompt= &amp;#39;从口味taste、速度speed、服务service三个维度， 对外卖评论内容进行文本分析， 分别返回不同维度的分值(分值范围-1.0 ~ 1.0)&amp;#39;,
                                base_url=&amp;#39;https://dashscope.aliyuncs.com/compatible-mode/v1&amp;#39;, 
                                api_key=&amp;#39;你的API-KEY&amp;#39;, 
                                model_name=&amp;#39;qwen-max&amp;#39;, 
                                output_format={&amp;#39;taste&amp;#39;: float, &amp;#39;speed&amp;#39;: float, &amp;#39;service&amp;#39;: float}
                               )
    return pd.Series(result)
    

#批量运算
df2 = df[&amp;#39;comment&amp;#39;].apply(llm_analysis)
res_df = pd.concat([df, df2], axis=1)
#保存分析结果
res_df.to_csv(&amp;#39;result.csv&amp;#39;, index=False)
res_df
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/28-llm-analysis.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;p&gt;LLM更多详细内容，请阅读  &lt;a href=&#34;https://textdata.cn/blog/2025-02-14-using-online-large-model-api-to-transform-text-data-into-structured-data/&#34;&gt;&lt;strong&gt;教程 | 使用在线大模型将文本数据转化为结构化数据&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;获取cntext2x&#34;&gt;获取cntext2.x&lt;/h2&gt;
&lt;p&gt;加大邓 &lt;em&gt;&lt;strong&gt;WeChat: 372335839&lt;/strong&gt;&lt;/em&gt;， 备注「姓名-学校-专业」， 100元领取  &lt;em&gt;&lt;strong&gt;cntext-2.1.4-py3-none-any.whl&lt;/strong&gt;&lt;/em&gt; 文件。本文出现的cntext，默认均为2.x版本。&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;使用声明&#34;&gt;使用声明&lt;/h2&gt;
&lt;p&gt;如果再研究或项目中使用到 &lt;strong&gt;cntext&lt;/strong&gt; ，请声明出处。&lt;/p&gt;
&lt;h3 id=&#34;apalike&#34;&gt;apalike&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;Deng X., Nan P. (2022). cntext: a Python tool for text mining. DOI: 10.5281/zenodo.7063523 URL: https://github.com/hiDaDeng/cntext
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;bibtex&#34;&gt;bibtex&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;@misc{YourReferenceHere,
author = {Deng, Xudong and Nan, Peng},
doi = {10.5281/zenodo.7063523},
month = {9},
title = {cntext: a Python tool for text mining},
url = {https://github.com/hiDaDeng/cntext},
year = {2022}
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;endnote&#34;&gt;endnote&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;%0 Generic
%A Deng, Xudong
%A Nan, Peng
%D 2022
%K text mining
%K text analysi
%K social science
%K management science
%K semantic analysis
%R 10.5281/zenodo.7063523
%T cntext: a Python tool for text mining
%U https://github.com/hiDaDeng/cntext
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
</description>
      <content:encoded><![CDATA[<p><em><strong>cntext</strong></em> 是大邓开发维护的中英文文本分析库，内置有多重词典和常用函数， 包括</p>
<ul>
<li>免费的 1.x 版， 更新至 1.9。</li>
<li>收费的 2.x 版， 更新至 2.1.4。 2.1.4 新增 <em><strong>ct.analysis_by_llm</strong></em>, 可使用大模型LLM进行文本分析。</li>
</ul>
<p>加大邓 <em><strong>WeChat: 372335839</strong></em>， 备注「姓名-学校-专业」， 100元领取  <em><strong>cntext-2.1.4-py3-none-any.whl</strong></em> 文件。本文出现的cntext，默认均为2.x版本。</p>
<p><br><br></p>
<h2 id="安装cntext">安装cntext</h2>
<p>所有 <em><strong>cntext2.x</strong></em> 安装方法类似， 以目前 cntext2.1.4 为例，将 <em><strong>cntext-2.1.4-py3-none-any.whl</strong></em> 放置于桌面，打开 <em><strong>cmd</strong></em>  (苹果电脑打开terminal)， 输入cd desktop</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">cd desktop
</code></pre></div><br>
<p>之后在 <em><strong>cmd</strong></em>  (苹果电脑打开terminal) 中使用 <em><strong>pip3</strong></em> 安装</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">pip3 install cntext-2.1.4-py3-none-any.whl
</code></pre></div><br>
<p>需要注意， <strong>cntext2.x使用环境为Python3.9 ~ 3.12</strong>,如安装失败，问题可能出在python版本问题； 文章开头和文章末都有 <em><strong>cntext-2.1.4-py3-none-any.whl</strong></em>  获取方式说明。</p>
<p><br><br></p>
<h2 id="功能模块">功能模块</h2>
<p>cntext含io、model、stats、mind五个模块</p>
<ol>
<li>导入数据用io</li>
<li>训练模型扩展词典用model</li>
<li>统计词频、情感分析、相似度等用stats</li>
<li>可视化模块plot</li>
<li>态度认知文化变迁用mind</li>
<li>大模型LLM</li>
</ol>
<p>函数部分加粗的为常用函数。</p>
<table>
<thead>
<tr>
<th>模块</th>
<th>函数</th>
<th>功能</th>
</tr>
</thead>
<tbody>
<tr>
<td><em><strong>io</strong></em></td>
<td><em><strong>ct.get_cntext_path()</strong></em></td>
<td>查看cntext安装路径</td>
</tr>
<tr>
<td><em><strong>io</strong></em></td>
<td><em><strong>ct.get_dict_list()</strong></em></td>
<td>查看cntext内置词典</td>
</tr>
<tr>
<td><em><strong>io</strong></em></td>
<td><code>ct.get_files(fformat)</code></td>
<td>查看符合fformat路径规则的所有的文件</td>
</tr>
<tr>
<td><em><strong>io</strong></em></td>
<td><code>ct.detect_encoding(file, num_lines=100)</code></td>
<td>诊断txt、csv编码格式</td>
</tr>
<tr>
<td><em><strong>io</strong></em></td>
<td><em><strong>ct.read_yaml_dict(yfile)</strong></em></td>
<td>读取内置yaml词典</td>
</tr>
<tr>
<td><em><strong>io</strong></em></td>
<td><em><strong>ct.read_pdf(file)</strong></em></td>
<td>读取PDF文件</td>
</tr>
<tr>
<td><em><strong>io</strong></em></td>
<td><em><strong>ct.read_docx(file)</strong></em></td>
<td>读取docx文件</td>
</tr>
<tr>
<td><em><strong>io</strong></em></td>
<td><em><strong>ct.read_file(file, encodings)</strong></em></td>
<td>读取文件</td>
</tr>
<tr>
<td><em><strong>io</strong></em></td>
<td><em><strong>ct.read_files(fformat, encoding)</strong></em></td>
<td>读取符合fformat路径规则的所有的文件，返回df</td>
</tr>
<tr>
<td><em><strong>io</strong></em></td>
<td><em><strong>ct.extract_mda(text, kws_pattern)</strong></em></td>
<td>提取A股年报中的MD&amp;A文本内容。如果返回'',则提取失败。</td>
</tr>
<tr>
<td><em><strong>io</strong></em></td>
<td><em><strong>ct.traditional2simple(text)</strong></em></td>
<td>繁体转简体</td>
</tr>
<tr>
<td><em><strong>io</strong></em></td>
<td><em><strong>ct.fix_text(text)</strong></em></td>
<td>将不正常的、混乱编码的文本转化为正常的文本。例如全角转半角</td>
</tr>
<tr>
<td><em><strong>io</strong></em></td>
<td><code>ct.fix_contractions(text)</code></td>
<td>英文缩写(含俚语表达)处理， 如you&rsquo;re -&gt; you are</td>
</tr>
<tr>
<td><em><strong>model</strong></em></td>
<td><em><strong>ct.W2VModel(corpus_file, encoding, lang=&lsquo;chinese&rsquo;)</strong></em></td>
<td>训练Word2Vec</td>
</tr>
<tr>
<td><em><strong>model</strong></em></td>
<td><em><strong>ct.glove2word2vec(glove_file, word2vec_file)</strong></em></td>
<td>将GLoVe模型.txt文件转化为Word2Vec模型.txt文件；注意这里的GLoVe模型.txt是通过<a href="https://github.com/standfordnlp/GloVe">Standfordnlp/GloVe</a> 训练得到的</td>
</tr>
<tr>
<td><em><strong>model</strong></em></td>
<td><em><strong>ct.load_wv(wv_path)</strong></em></td>
<td>读取cntext2.x训练出的word2vec模型文件</td>
</tr>
<tr>
<td><em><strong>model</strong></em></td>
<td><em><strong>ct.expand_dictionary(wv,  seeddict, topn=100)</strong></em></td>
<td>扩展词典,  结果保存到路径[output/Word2Vec]中</td>
</tr>
<tr>
<td><em><strong>model</strong></em></td>
<td><code>ct.Glove(corpus_file, lang='chinese')</code></td>
<td>训练GLove模型。 算法运行较慢，吃内存，不推荐！！</td>
</tr>
<tr>
<td><em><strong>model</strong></em></td>
<td><code>ct.SoPmi(corpus_file, seed_file, lang='chinese')</code></td>
<td>共现法扩展词典</td>
</tr>
<tr>
<td><em><strong>stats</strong></em></td>
<td><code>ct.term_freq(text, lang='chinese')</code></td>
<td>词频统计</td>
</tr>
<tr>
<td><em><strong>stats</strong></em></td>
<td><code>readability(text, lang='chinese', syllables=3)</code></td>
<td>文本可读性</td>
</tr>
<tr>
<td><em><strong>stats</strong></em></td>
<td><em><strong>ct.sentiment(text, diction, lang=&lsquo;chinese&rsquo;)</strong></em></td>
<td>无(等)权重词典的情感分析</td>
</tr>
<tr>
<td><em><strong>stats</strong></em></td>
<td><code>ct.sentiment_by_valence(text, diction, lang='chinese')</code></td>
<td>带权重的词典的情感分析</td>
</tr>
<tr>
<td><em><strong>stats</strong></em></td>
<td><em><strong>ct.word_in_context(text, keywords, window=3, lang=&lsquo;chinese&rsquo;)</strong></em></td>
<td>在text中查找keywords出现的上下文内容(窗口window)，返回df</td>
</tr>
<tr>
<td><em><strong>stats</strong></em></td>
<td><em><strong>ct.epu()</strong></em></td>
<td>使用新闻文本数据计算经济政策不确定性EPU，返回df</td>
</tr>
<tr>
<td><em><strong>stats</strong></em></td>
<td><em><strong>ct.fepu(text, ep_pattern='', u_pattern='')</strong></em></td>
<td>使用md&amp;a文本数据计算企业不确定性感知FEPU</td>
</tr>
<tr>
<td><em><strong>stats</strong></em></td>
<td><em><strong>ct.semantic_brand_score(text, brands, lang=&lsquo;chinese&rsquo;)</strong></em></td>
<td>衡量品牌（个体、公司、品牌、关键词等）的重要性</td>
</tr>
<tr>
<td><em><strong>stats</strong></em></td>
<td><em><strong>ct.cosine_sim(text1, text2)</strong></em></td>
<td>余弦相似度</td>
</tr>
<tr>
<td><em><strong>stats</strong></em></td>
<td><code>ct.jaccard_sim(text1, text2)</code></td>
<td>Jaccard相似度</td>
</tr>
<tr>
<td><em><strong>stats</strong></em></td>
<td><code>ct.minedit_sim(text1, text2)</code></td>
<td>最小编辑距离</td>
</tr>
<tr>
<td><em><strong>stats</strong></em></td>
<td><code>ct.word_hhi(text)</code></td>
<td>文本的赫芬达尔-赫希曼指数</td>
</tr>
<tr>
<td><em><strong>plot</strong></em></td>
<td><code>ct.matplotlib_chinese()</code></td>
<td>支持matplotlib中文绘图</td>
</tr>
<tr>
<td><em><strong>plot</strong></em></td>
<td><code>ct.lexical_dispersion_plot1(text, targets_dict, lang, title, figsize)</code></td>
<td>对某一个文本text， 可视化不同目标类别词targets_dict在文本中出现位置</td>
</tr>
<tr>
<td><em><strong>plot</strong></em></td>
<td><code>ct.lexical_dispersion_plot2(texts_dict, targets, lang, title, figsize)</code></td>
<td>对某几个文本texts_dict， 可视化某些目标词targets在文本中出现相对位置(0~100)</td>
</tr>
<tr>
<td><em><strong>mind</strong></em></td>
<td><em><strong>tm = ct.Text2Mind(wv)</strong></em><br></td>
<td>单个word2vec内挖掘潜在的态度偏见、刻板印象等。tm含多重方法</td>
</tr>
<tr>
<td><em><strong>mind</strong></em></td>
<td><code>ct.sematic_projection(wv, words, c_words1, c_words2)</code></td>
<td>测量语义投影</td>
</tr>
<tr>
<td><em><strong>mind</strong></em></td>
<td><code>ct.sematic_distance(wv, words, c_words1, c_words2)</code></td>
<td>测量语义距离</td>
</tr>
<tr>
<td><em><strong>mind</strong></em></td>
<td><code>ct.divergent_association_task(wv, words)</code></td>
<td>测量发散思维(创造力)</td>
</tr>
<tr>
<td><em><strong>mind</strong></em></td>
<td><code>ct.discursive_diversity_score(wv, words)</code></td>
<td>测量语言差异性(认知差异性)</td>
</tr>
<tr>
<td><em><strong>mind</strong></em></td>
<td><em><strong>ct.procrustes_align(base_wv, other_wv)</strong></em></td>
<td>两个word2vec进行语义对齐，可反应随时间的社会语义变迁</td>
</tr>
<tr>
<td><em><strong>LLM</strong></em></td>
<td><em><strong>analysis_by_llm(text, prompt, base_url, api_key, model_name, temperature, output_format)</strong></em></td>
<td>使用大模型进行文本分析</td>
</tr>
</tbody>
</table>
<p><br><br></p>
<h2 id="quickstart">QuickStart</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;当前cntext版本: &#39;</span><span class="p">,</span> <span class="n">ct</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span>
<span class="n">help</span><span class="p">(</span><span class="n">ct</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-go" data-lang="go"><span class="nx">当前cntext版本</span><span class="p">:</span> <span class="mf">2.1.4</span>

<span class="nx">Help</span> <span class="nx">on</span> <span class="kn">package</span> <span class="nx">cntext</span><span class="p">:</span>

<span class="nx">NAME</span>
    <span class="nx">cntext</span>

<span class="nx">PACKAGE</span> <span class="nx">CONTENTS</span>
    <span class="nx">io</span>
    <span class="nx">mind</span>
    <span class="nx">model</span>
    <span class="nx">stats</span>
    <span class="nx">llm</span>
<span class="o">...</span>
</code></pre></div><br>
<br>
<h2 id="一io模块">一、IO模块</h2>
<table>
<thead>
<tr>
<th>模块</th>
<th>函数</th>
<th>功能</th>
</tr>
</thead>
<tbody>
<tr>
<td><em><strong>io</strong></em></td>
<td><em><strong>ct.get_dict_list()</strong></em></td>
<td>查看cntext内置词典</td>
</tr>
<tr>
<td><em><strong>io</strong></em></td>
<td><em><strong>ct.read_yaml_dict(yfile)</strong></em></td>
<td>读取内置yaml词典</td>
</tr>
<tr>
<td><em><strong>io</strong></em></td>
<td><code>ct.detect_encoding(file, num_lines=100)</code></td>
<td>诊断txt、csv编码格式</td>
</tr>
<tr>
<td><em><strong>io</strong></em></td>
<td><code>ct.get_files(fformat)</code></td>
<td>查看符合fformat路径规则的所有的文件</td>
</tr>
<tr>
<td><em><strong>io</strong></em></td>
<td><em><strong>ct.read_yaml_dict(yfile)</strong></em></td>
<td>读取内置yaml词典</td>
</tr>
<tr>
<td><em><strong>io</strong></em></td>
<td><em><strong>ct.read_pdf(file)</strong></em></td>
<td>读取PDF文件</td>
</tr>
<tr>
<td><em><strong>io</strong></em></td>
<td><em><strong>ct.read_file(file, encoding)</strong></em></td>
<td>读取文件</td>
</tr>
<tr>
<td><em><strong>io</strong></em></td>
<td><em><strong>ct.read_files(fformat, encoding)</strong></em></td>
<td>读取符合fformat路径规则的所有的文件，返回df</td>
</tr>
<tr>
<td><em><strong>io</strong></em></td>
<td><em><strong>ct.extract_mda(text, kws_pattern)</strong></em></td>
<td>提取A股年报中的MD&amp;A文本内容。如果返回'',则提取失败。</td>
</tr>
<tr>
<td><em><strong>io</strong></em></td>
<td><em><strong>ct.traditional2simple(text)</strong></em></td>
<td>繁体转简体</td>
</tr>
<tr>
<td><em><strong>io</strong></em></td>
<td><em><strong>ct.fix_text(text)</strong></em></td>
<td>将不正常的、混乱编码的文本转化为正常的文本。例如全角转半角</td>
</tr>
<tr>
<td><em><strong>io</strong></em></td>
<td><code>ct.fix_contractions(text)</code></td>
<td>英文缩写(含俚语表达)处理， 如you&rsquo;re -&gt; you are</td>
</tr>
</tbody>
</table>
<h3 id="11-get_dict_list">1.1 get_dict_list()</h3>
<p>查看cntext内置词典</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>

<span class="n">ct</span><span class="o">.</span><span class="n">get_dict_list</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">[&#39;zh_common_NTUSD.yaml&#39;,
 &#39;zh_common_DUTIR.yaml&#39;,
 &#39;enzh_common_StopWords.yaml&#39;,
 &#39;en_valence_Concreteness.yaml&#39;,
 &#39;en_common_LoughranMcDonald.yaml&#39;,
 &#39;zh_common_FinanceSenti.yaml&#39;,
 &#39;zh_common_FLS.yaml&#39;,
 &#39;zh_common_TsinghuaPraiseDegrade.yaml&#39;,
 &#39;zh_common_FEPU.yaml&#39;,
 &#39;en_common_ANEW.yaml&#39;,
 &#39;en_common_NRC.yaml&#39;,
 &#39;zh_valence_ChineseEmoBank.yaml&#39;,
 &#39;zh_valence_SixSemanticDimensionDatabase.yaml&#39;,
 &#39;zh_common_FinacialFormalUnformal.yaml&#39;,
 &#39;zh_common_LoughranMcDonald.yaml&#39;,
 &#39;enzh_common_AdvConj.yaml&#39;,
 &#39;en_common_SentiWS.yaml&#39;,
 &#39;zh_common_Digitalization.yaml&#39;,
 &#39;en_common_LSD2015.yaml&#39;,
 &#39;zh_common_HowNet.yaml&#39;,
 &#39;zh_common_EPU.yaml&#39;]
</code></pre></div><h3 id="12-内置yaml词典">1.2 内置yaml词典</h3>
<table>
<thead>
<tr>
<th>pkl文件</th>
<th>词典</th>
<th>语言</th>
<th>功能</th>
</tr>
</thead>
<tbody>
<tr>
<td><em><strong>zh_valence_ChineseEmoBank.yaml</strong></em></td>
<td>中文情感词典，含<code>效价valence</code>和<code>唤醒度arousal</code>。在cntext中，我们只使用了CVAW词表(单词)，其他词典如CVAP, CVAS, CVAT没有纳入到ChineseEmoBank.pkl.</td>
<td>Chinese</td>
<td><code>效价valence</code>和<code>唤醒度arousal</code></td>
</tr>
<tr>
<td><em><strong>zh_common_DUTIR.yaml</strong></em></td>
<td>大连理工大学情感本体库</td>
<td>中文</td>
<td>七大类情绪，<code>哀, 好, 惊, 惧, 乐, 怒, 恶</code></td>
</tr>
<tr>
<td><em><strong>zh_common_HowNet.yaml</strong></em></td>
<td>知网Hownet词典</td>
<td>中文</td>
<td>正面词、负面词</td>
</tr>
<tr>
<td><code>en_common_SentiWS.yaml</code></td>
<td>SentimentWortschatz (SentiWS)</td>
<td>德文</td>
<td>正面词、负面词；<br></td>
</tr>
<tr>
<td><em><strong>zh_common_FinacialFormalUnformal.yaml</strong></em></td>
<td>金融领域正式、非正式；积极消极</td>
<td>中文</td>
<td>formal-pos、<br>formal-neg；<br>unformal-pos、<br>unformal-neg</td>
</tr>
<tr>
<td><code>en_common_ANEW.yaml</code></td>
<td>英语单词的情感规范Affective Norms for English Words (ANEW)</td>
<td>英文</td>
<td>pleasure, arousal, dominance</td>
</tr>
<tr>
<td><code>en_common_LSD2015.yaml</code></td>
<td>Lexicoder Sentiment Dictionary (2015)</td>
<td>英文</td>
<td>正面词、负面词</td>
</tr>
<tr>
<td><code>en_common_NRC.yaml</code></td>
<td>NRC Word-Emotion Association Lexicon</td>
<td>英文</td>
<td>细粒度情绪词；</td>
</tr>
<tr>
<td><em><strong>zh_valence_SixSemanticDimensionDatabase.yaml</strong></em></td>
<td><a href="https://textdata.cn/blog/2023-03-20-nature-six-semantic-dimension-database/"><strong>通用中英文六维语义情感词典</strong></a>, 含17940个中文词的六维度词库， 且每个维度有权重。</td>
<td>中文</td>
<td>vision、socialness、emotion、time、space、motor</td>
</tr>
<tr>
<td><code>enzh_common_AdvConj.yaml</code></td>
<td>副词连词</td>
<td>中、英</td>
<td></td>
</tr>
<tr>
<td><em><strong>enzh_common_StopWords.yaml</strong></em></td>
<td>中英文停用词</td>
<td>中、英</td>
<td>停用词</td>
</tr>
<tr>
<td><em><strong>en_valence_Concreteness.yaml</strong></em></td>
<td><a href="https://textdata.cn/blog/jcr_concreteness_computation/">英文具体性词典</a></td>
<td>English</td>
<td>word &amp; concreateness score</td>
</tr>
<tr>
<td><em><strong>zh_common_LoughranMcDonald.yaml</strong></em></td>
<td>中文LoughranMcDonald词典</td>
<td>中文</td>
<td>正面、负面词</td>
</tr>
<tr>
<td><em><strong>zh_common_Digitalization.yaml</strong></em></td>
<td><a href="https://textdata.cn/blog/2022-11-03-mda-measure-digitalization/">管理世界|吴非(2021)数字化词典</a></td>
<td>中文</td>
<td>含人工智能技术、大数据技术、云计算技术、区块链技术、数字技术应用等关键词列表。</td>
</tr>
<tr>
<td><em><strong>en_common_LoughranMcDonald.yaml</strong></em></td>
<td>英文LoughranMcDonald词典</td>
<td>英文</td>
<td>金融LM情绪词典2018年版本，含七个词表，分别是Negative, Positive, Uncertainty, Litigious, StrongModal, WeakModal, Constraining</td>
</tr>
<tr>
<td><em><strong>zh_common_FLS.yaml</strong></em></td>
<td><a href="https://textdata.cn/blog/2023-09-08-earnings-communication-conference-forward-looking-statements-information/"><strong>业绩说明会前瞻性词典集</strong></a></td>
<td>中文</td>
<td>含174个词语</td>
</tr>
<tr>
<td><em><strong>zh_common_RhetoricalNationalism.yaml</strong></em></td>
<td>修辞民族主义</td>
<td>中文</td>
<td>含四个维度，民族自豪感、民族复兴、企业角色、排外主义，每个维度100个词。</td>
</tr>
</tbody>
</table>
<br>
<h3 id="13-read_dict_yaml">1.3 read_dict_yaml()</h3>
<p>使用 cntext 读取 <em><strong>.yaml</strong></em> 词典文件；  返回的信息包括</p>
<ul>
<li>Name 词典的名字</li>
<li>Desc 词典的含义、概念解释</li>
<li>Refer 词典文献出处</li>
<li>Category 词典Dictionary的关键词</li>
<li>Dictionary 词典, python字典格式</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>
<span class="nb">print</span><span class="p">(</span><span class="n">ct</span><span class="o">.</span><span class="n">read_yaml_dict</span><span class="p">(</span><span class="s1">&#39;zh_common_Digitalization.yaml&#39;</span><span class="p">))</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">{&#39;Name&#39;: &#39;中文数字化词典&#39;, 
&#39;Desc&#39;: &#39;基于这篇论文，构建了中文数字化词典，含人工智能技术、大数据技术、云计算技术、区块链技术、数字技术应用等关键词列表。 &#39;, &#39;Refer&#39;: &#39;吴非,胡慧芷,林慧妍,任晓怡. 企业数字化转型与资本市场表现——来自股票流动性的经验证据[J]. 管理世界,2021,37(07):130-144+10.&#39;, 
&#39;Category&#39;: [&#39;Artificial_Intelligence&#39;, &#39;Big_Data&#39;, &#39;Cloud_Computing&#39;, &#39;Block_Chains&#39;, &#39;Usage_of_Digitalization&#39;], 

&#39;Dictionary&#39;: 
    {&#39;Artificial_Intelligence&#39;: [&#39;人工智能&#39;, &#39;商业智能&#39;, &#39;图像理解&#39;, &#39;投资决策辅助系统&#39;, &#39;智能数据分析&#39;, &#39;智能机器人&#39;, &#39;机器学习&#39;, &#39;深度学习&#39;, &#39;语义搜索&#39;, &#39;生物识别技术&#39;, &#39;人脸识别&#39;, &#39;语音识别&#39;, &#39;身份验证&#39;, &#39;自动驾驶&#39;, &#39;自然语言处理&#39;], 
    &#39;Big_Data&#39;: [&#39;大数据&#39;, &#39;数据挖掘&#39;, &#39;文本挖掘&#39;, &#39;数据可视化&#39;, &#39;异构数据&#39;, &#39;征信&#39;, &#39;增强现实&#39;, &#39;混合现实&#39;, &#39;虚拟现实&#39;], 
    &#39;Cloud_Computing&#39;: [&#39;云计算&#39;, &#39;流计算&#39;, &#39;图计算&#39;, &#39;内存计算&#39;, &#39;多方安全计算&#39;, &#39;类脑计算&#39;, &#39;绿色计算&#39;, &#39;认知计算&#39;, &#39;融合架构&#39;, &#39;亿级并发&#39;, &#39;EB级存储&#39;, &#39;物联网&#39;, &#39;信息物理系统&#39;], 
    &#39;Block_Chains&#39;: [&#39;区块链&#39;, &#39;数字货币&#39;, &#39;分布式计算&#39;, &#39;差分隐私技术&#39;, &#39;智能金融合约&#39;], 
    &#39;Usage_of_Digitalization&#39;: [&#39;移动互联网&#39;, &#39;工业互联网&#39;, &#39;移动互联&#39;, &#39;互联网医疗&#39;, &#39;电子商务&#39;, &#39;移动支付&#39;, &#39;第三方支付&#39;, &#39;NFC支付&#39;, &#39;智能能源&#39;, &#39;B2B&#39;, &#39;B2C&#39;, &#39;C2B&#39;, &#39;C2C&#39;, &#39;O2O&#39;, &#39;网联&#39;, &#39;智能穿戴&#39;, &#39;智慧农业&#39;, &#39;智能交通&#39;, &#39;智能医疗&#39;, &#39;智能客服&#39;, &#39;智能家居&#39;, &#39;智能投顾&#39;, &#39;智能文旅&#39;, &#39;智能环保&#39;, &#39;智能电网&#39;, &#39;智能营销&#39;, &#39;数字营销&#39;, &#39;无人零售&#39;, &#39;互联网金融&#39;, &#39;数字金融&#39;, &#39;Fintech&#39;, &#39;金融科技&#39;, &#39;量化金融&#39;, &#39;开放银行&#39;]}}
</code></pre></div><br>
<h3 id="14-detect_encoding">1.4 detect_encoding()</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">ct.detect_encoding(file)
</code></pre></div><p>通过读取前num_lines来识别txt/csv文件的编码格式</p>
<ul>
<li><em><strong>file</strong></em> 文件路径</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>

<span class="c1">#读取data文件夹下的【三体.txt】</span>
<span class="c1">#识别编码方式</span>
<span class="n">ct</span><span class="o">.</span><span class="n">detect_encoding</span><span class="p">(</span><span class="n">file</span><span class="o">=</span><span class="s1">&#39;data/三体.txt&#39;</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">utf-8
</code></pre></div><br>
<h3 id="15-get_filesfformat">1.5 get_files(fformat)</h3>
<ul>
<li><strong>fformat</strong>  fformat格式支持 txt/pdf/docx/xlsx/csv等。 <code>*</code>表示通配符</li>
</ul>
<p>查看符合fformat路径规则的所有的文件， fformat格式支持 txt/pdf/docx/xlsx/csv等。 <code>*</code>表示通配符</p>
<table>
<thead>
<tr>
<th>fformat格式</th>
<th>识别的文件</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>*.txt</code></td>
<td>匹配当前代码所在路径内的所有txt</td>
</tr>
<tr>
<td><code>*.pdf</code></td>
<td>匹配当前代码所在路径内的所有pdf</td>
</tr>
<tr>
<td><code>data/*.txt</code></td>
<td>匹配「文件夹data」内所有的 txt</td>
</tr>
<tr>
<td><br></td>
<td></td>
</tr>
</tbody>
</table>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#查看【文件夹data】内所有的 txt文件。</span>
<span class="n">ct</span><span class="o">.</span><span class="n">get_files</span><span class="p">(</span><span class="n">fformat</span><span class="o">=</span><span class="s1">&#39;data/*.txt&#39;</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">[&#39;data/三体.txt&#39;,
 &#39;data/santi.txt&#39;,
 &#39;data/w2v_corpus.txt&#39;,
 &#39;data/sopmi_corpus.txt&#39;,
 &#39;data/brown_corpus.txt&#39;,
 &#39;data/sopmi_seed_words.txt&#39;]
</code></pre></div><br>
<h3 id="16-read_pdf">1.6 read_pdf</h3>
<p>读取PDF，返回文本内容</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">ct</span><span class="o">.</span><span class="n">read_pdf</span><span class="p">(</span><span class="n">file</span><span class="p">)</span>
</code></pre></div><ul>
<li><em><strong>file</strong></em> PDF文件路径</li>
</ul>
<p>点击 <a href="https://textdata.cn/data/%E6%A0%BC%E5%8A%9B%E7%94%B5%E5%99%A82023.pdf"><strong>格力电器2023.pdf</strong></a></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>

<span class="n">text</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">read_pdf</span><span class="p">(</span><span class="s1">&#39;格力电器2023.pdf&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">text</span><span class="p">)</span> 
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">珠海格力电器股份有限公司 2023年年度报告全文  
珠海格力电器股份有限公司  
2023年年度报告  
 
 
二〇二四年四月 
珠海格力电器股份有限公司 2023年年度报告全文  
 第 2 页 共 249 页 第一节 重要提示、目录和释义  
公司董事会、监事会及董事、监事、高级管理人员保证年度报告内容
的真实、准确、完整，不存在虚假记载、误导性陈述或重大遗漏，并承担
个别和连带的法律
......
</code></pre></div><br>
<h3 id="17-read_docx">1.7 read_docx</h3>
<p>读取docx，返回文本内容</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">ct</span><span class="o">.</span><span class="n">read_docx</span><span class="p">(</span><span class="n">file</span><span class="p">)</span>
</code></pre></div><ul>
<li><em><strong>file</strong></em> docx文件路径</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>

<span class="n">text</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">read_docx</span><span class="p">(</span><span class="s1">&#39;test.docx&#39;</span><span class="p">)</span>
<span class="n">text</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">这是来自test.docx里内容
</code></pre></div><br>
<h3 id="18-read_file">1.8 read_file()</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">ct.read_file(file, encoding=&#39;utf-8&#39;)
</code></pre></div><ul>
<li><strong>file</strong> 待读取的文件路径； 支持txt、pdf、docx、xlsx、xls， 返回 DataFrame(含doc和file两个字段)。</li>
<li><strong>encoding</strong> 待读取文件的编码方式</li>
</ul>
<p>以 <code>data/三体.txt</code> 为例</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>

<span class="c1">#默认encoding=&#39;utf-8&#39;</span>
<span class="c1">#sdf = ct.read_file(file=&#39;data/三体.txt&#39;)</span>

<span class="n">sdf</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">read_file</span><span class="p">(</span><span class="n">file</span><span class="o">=</span><span class="s1">&#39;data/三体.txt&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span>
<span class="n">sdf</span>
</code></pre></div><p><img loading="lazy" src="img/01-san_ti_df.png" alt=""  />
</p>
<br>
<h3 id="19-read_files">1.9 read_files()</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">ct.read_files(fformat, encoding=&#39;utf-8&#39;）
</code></pre></div><p>批量读取符合fformat格式的所有文件数据，返回DataFrame(含doc和file两个字段)。</p>
<p>读取[文件夹data里所有txt]</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>

<span class="c1">#默认encoding=&#39;utf-8&#39;</span>
<span class="c1">#ddf = ct.read_files(fformat=&#39;data/*.txt&#39;)</span>

<span class="n">ddf</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">read_files</span><span class="p">(</span><span class="n">fformat</span><span class="o">=</span><span class="s1">&#39;data/*.txt&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span>
<span class="n">ddf</span>
</code></pre></div><p><img loading="lazy" src="img/02-ddf.png" alt=""  />
</p>
<br>
<h3 id="110-extract_mda">1.10 extract_mda</h3>
<p>提取A股年报中的MD&amp;A文本内容。如果返回'',则提取失败。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">ct.extract_mda(text, kws_pattern=&#39;&#39;)
</code></pre></div><ul>
<li>text 中国A股年报原始文本</li>
<li>kws_pattern 管理层讨论与分析章节识别关键词的模板。cntext内置的kws_pattern内容如下</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">kws_pattern = &#39;董事会报告|董事会报告与管理讨论|企业运营与管理评述|经营总结与分析|管理层评估与未来展望|董事局报告|管理层讨论与分析|经营情况讨论与分析|经营业绩分析|业务回顾与展望|公司经营分析|管理层评论与分析|执行摘要与业务回顾|业务运营分析&#39;
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>

<span class="n">text</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">read_pdf</span><span class="p">(</span><span class="s1">&#39;格力电器2023.pdf&#39;</span><span class="p">)</span>
<span class="n">mda_text</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">extract_mda</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">mda_text</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">&#39;管理层讨论与分析  \n一、报告期内公司所处行业情况  \n（一）行业发展现状  \n1.消费领域 ——家电行业稳定增长，空调市场恢复明显  \n2023年，中国经济保持了整体恢复向好的态势，激发消费是稳增长的重中之重。国家鼓励和推动消费品以旧换\n新，促进消费经济大循环，加速更新需求释放，推动高能效产品设备销售和出口增长，进一步激发绿色消费潜力。  \n1）家电行业稳定增长  \n2023年，国内经济恢复明显，家电行业稳定增长。根据全国家用电器工业信息中心发布的《 2023年中国家电\n行业年度报告》，家电行业外销明显增长，出口规模为 6,174亿元，同比增长 9.9%；国内市场实现稳步增长，销售\n规模为7&#39;
.......
.......
</code></pre></div><br>
<p>以<a href="https://textdata.cn/blog/2023-03-23-china-a-share-market-dataset-mda-from-01-to-21/">2001年~2023会计年度报告数据集</a>为例， 查看 <em><strong>extract_mda</strong></em> 的抽取mda的能力。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">glob</span>
<span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;extract_mda识别能力&#39;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">year</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2001</span><span class="p">,</span> <span class="mi">2024</span><span class="p">):</span>
    <span class="n">num</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">file</span> <span class="ow">in</span> <span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;年报txt/</span><span class="si">{</span><span class="n">year</span><span class="si">}</span><span class="s1">/*.txt&#39;</span><span class="p">):</span>
        <span class="n">mda_text</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">extract_mda</span><span class="p">(</span><span class="nb">open</span><span class="p">(</span><span class="n">file</span><span class="p">)</span><span class="o">.</span><span class="n">read</span><span class="p">())</span>
        <span class="k">if</span> <span class="n">mda_text</span><span class="o">!=</span><span class="s1">&#39;&#39;</span><span class="p">:</span>
            <span class="n">num</span> <span class="o">=</span> <span class="n">num</span> <span class="o">+</span> <span class="mi">1</span>
               
    <span class="n">volume</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;年报txt/</span><span class="si">{</span><span class="n">year</span><span class="si">}</span><span class="s1">/*.txt&#39;</span><span class="p">))</span>     
    <span class="n">ratio</span> <span class="o">=</span> <span class="n">num</span><span class="o">/</span><span class="n">volume</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">year</span><span class="si">}</span><span class="s1">: </span><span class="si">{</span><span class="n">ratio</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">2001: 0.24
2002: 0.37
2003: 0.43
2004: 0.70
2005: 0.77
2006: 0.78
2007: 0.79
2008: 0.77
2009: 0.79
2010: 0.82
2011: 0.84
2012: 0.96
2013: 0.95
2014: 0.98
2015: 0.98
2016: 0.99
2017: 0.98
2018: 0.98
2019: 0.99
2020: 0.97
2021: 0.98
2022: 0.99
2023: 0.99
</code></pre></div><p>建议各位用最近10年的年报数据，通过extract_mda提取mda文本，或者直接购买 [数据集 | 2001-2023年A股上市公司年报&amp;管理层讨论与分析](数据集 | 2001-2023年A股上市公司年报&amp;管理层讨论与分析)</p>
<br>
<h3 id="111-traditional2simple">1.11 traditional2simple()</h3>
<p>繁体转简体</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">ct.traditional2simple(text, mode=&#39;t2s&#39;)
</code></pre></div><ul>
<li><em><strong>text</strong></em> 待转换的文本</li>
<li><em><strong>mode</strong></em> 转换模式， 默认mode=&lsquo;t2s&rsquo;繁转简; mode还支持s2t</li>
</ul>
 <br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>

<span class="n">text</span> <span class="o">=</span> <span class="s1">&#39;簡體漢字&#39;</span>
<span class="n">ct</span><span class="o">.</span><span class="n">traditional2simple</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">&#39;简体汉字&#39;
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">text</span> <span class="o">=</span> <span class="s1">&#39;简体汉字&#39;</span>
<span class="n">ct</span><span class="o">.</span><span class="n">traditional2simple</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;s2t&#39;</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">&#39;簡體漢字&#39;
</code></pre></div><br>
<h3 id="112-fix_text">1.12 fix_text()</h3>
<p>将不正常的、混乱编码的文本转化为正常的文本。例如全角转半角</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>

<span class="n">raw_text</span> <span class="o">=</span> <span class="s1">&#39;今日起可中遇到技术问题，可以拨打电话０３７１－６６３２１９９１、６６３２１９７３咨询。&#39;</span>

<span class="n">text</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">fix_text</span><span class="p">(</span><span class="n">raw_text</span><span class="p">)</span>
<span class="n">text</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">今日起可中遇到技术问题，可以拨打电话0371-66321991、66321973咨询。
</code></pre></div><br>
<h3 id="113-fix_contractionstext">1.13 fix_contractions(text)</h3>
<p>将英文缩写(含俚语表达)转化为完整的表达，如如</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">- you&#39;re -&gt; you are
- yall  -&gt; you all
- gotta  -&gt; got to
...
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>

<span class="n">raw_text</span> <span class="o">=</span> <span class="s2">&#34;yall&#39;re happy now&#34;</span>

<span class="n">text</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">fix_contractions</span><span class="p">(</span><span class="n">raw_text</span><span class="p">)</span>
<span class="n">text</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">&#34;you all are happy now&#34;
</code></pre></div><br>
<p><br><br></p>
<h2 id="二stats模块">二、Stats模块</h2>
<table>
<thead>
<tr>
<th>模块</th>
<th>函数</th>
<th>功能</th>
</tr>
</thead>
<tbody>
<tr>
<td><em><strong>stats</strong></em></td>
<td><code>ct.term_freq(text, lang='chinese')</code></td>
<td>词频统计</td>
</tr>
<tr>
<td><em><strong>stats</strong></em></td>
<td><code>ct.readability(text, lang='chinese')</code></td>
<td>文本可读性</td>
</tr>
<tr>
<td><em><strong>stats</strong></em></td>
<td><em><strong>ct.sentiment(text, diction, lang=&lsquo;chinese&rsquo;)</strong></em></td>
<td>无(等)权重词典的情感分析</td>
</tr>
<tr>
<td><em><strong>stats</strong></em></td>
<td><code>ct.sentiment_by_valence(text, diction, lang='chinese')</code></td>
<td>带权重的词典的情感分析</td>
</tr>
<tr>
<td><em><strong>stats</strong></em></td>
<td><em><strong>ct.word_in_context(text, keywords, window=3, lang=&lsquo;chinese&rsquo;)</strong></em></td>
<td>在text中查找keywords出现的上下文内容(窗口window)，返回df</td>
</tr>
<tr>
<td><em><strong>stats</strong></em></td>
<td><em><strong>ct.epu(text, e_pattern, p_pattern, u_pattern)</strong></em></td>
<td>使用新闻文本数据计算经济政策不确定性EPU，返回df</td>
</tr>
<tr>
<td><em><strong>stats</strong></em></td>
<td><em><strong>ct.fepu(text, ep_pattern='&rsquo;, u_pattern='')</strong></em></td>
<td>使用md&amp;a文本数据计算企业不确定性感知FEPU</td>
</tr>
<tr>
<td><em><strong>stats</strong></em></td>
<td><em><strong>ct.semantic_brand_score(text, brands, lang=&lsquo;chinese&rsquo;)</strong></em></td>
<td>衡量品牌（个体、公司、品牌、关键词等）的重要性</td>
</tr>
<tr>
<td><em><strong>stats</strong></em></td>
<td><em><strong>ct.cosine_sim(text1, text2)</strong></em></td>
<td>余弦相似度</td>
</tr>
<tr>
<td><em><strong>stats</strong></em></td>
<td><code>ct.jaccard_sim(text1, text2)</code></td>
<td>Jaccard相似度</td>
</tr>
<tr>
<td><em><strong>stats</strong></em></td>
<td><code>ct.minedit_sim(text1, text2)</code></td>
<td>最小编辑距离</td>
</tr>
<tr>
<td><em><strong>stats</strong></em></td>
<td><code>ct.word_hhi(text)</code></td>
<td>文本的赫芬达尔-赫希曼指数</td>
</tr>
</tbody>
</table>
<br>
<h3 id="21-term_freq">2.1 term_freq()</h3>
<p>统计词频， 返回Counter(类似于python字典) ； 支持中英文</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">term_freq(text, lang=&#39;chinese&#39;, return_df=False)
</code></pre></div><ul>
<li><strong>text</strong> 待分析的文本字符串</li>
<li><strong>lang</strong> 文本的语言类型， 中文chinese、英文english，默认中文。</li>
<li><strong>return_df</strong> 返回结果是否为dataframe，默认False</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>

<span class="n">text</span> <span class="o">=</span> <span class="s1">&#39;致力于致力于以零文章处理费或订阅费发布优质研究软件。&#39;</span>

<span class="c1">#ct.term_freq(text, lang=&#39;chinese&#39;)</span>
<span class="n">ct</span><span class="o">.</span><span class="n">term_freq</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">Counter({&#39;致力于&#39;: 2,
         &#39;文章&#39;: 1,
         &#39;处理费&#39;: 1,
         &#39;订阅费&#39;: 1,
         &#39;发布&#39;: 1,
         &#39;优质&#39;: 1,
         &#39;研究&#39;: 1,
         &#39;软件&#39;: 1})
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">ct</span><span class="o">.</span><span class="n">term_freq</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">return_df</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</code></pre></div><p><img loading="lazy" src="img/09-term_freq.png" alt=""  />
</p>
<br>
<h3 id="22-readability">2.2 readability()</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">ct.readability(text, lang=&#39;chinese&#39;, syllables=3, return_series=False)
</code></pre></div><p>计算文本可读性常见指标； 含Gunning Fog Index、 SMOG Index、Coleman Liau Index、 Automated Readability Index(ARI)、Readability Index(Rix)； 指标越大，复杂度越高，文本的可读性越差。</p>
<ul>
<li><strong>text</strong>  待分析的文本字符串</li>
<li><strong>lang</strong> 文本的语言类型， 中文chinese、英文english，默认中文。</li>
<li><strong>syllables</strong> 音节数(汉字数)大于等于syllables为复杂词. 默认值为3</li>
<li><strong>return_series</strong>: 计算结果是否输出为pd.Series类型，默认为False</li>
</ul>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">Gunning Fog Index = 0.4 * (Total_Words/Total_Sentences + 100 * Complex_Words/Total_Words)
SMOG Index = 1.0430 * sqrt(Complex_Words/Total_Sentences) * 30 + 3.1291
Coleman-Liau Index = 0.0588 * (100*Total_Letters/Total_Words) -0.296*(100*Total_Sentences/Total_Words) - 15.8
Automated Readability Index(ARI) = 4.71 * (Total_Characters/Total_Words) + 0.5*(Total_Words/Total_Sentences) - 21.43
Readability Index(RIX) = Complex_Words * (6 + Total_characters) / Total_Sentences
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>

<span class="n">text</span> <span class="o">=</span> <span class="s1">&#39;致力于以零文章处理费或订阅费发布优质研究软件。&#39;</span>

<span class="n">ct</span><span class="o">.</span><span class="n">readability</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">lang</span><span class="o">=</span><span class="s1">&#39;chinese&#39;</span><span class="p">,</span> <span class="n">syllables</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">{&#39;fog_index&#39;: 120.4,
 &#39;flesch_kincaid_grade_level&#39;: 20.2,
 &#39;smog_index&#39;: 57.32,
 &#39;coleman_liau_index&#39;: 83.96,
 &#39;ari&#39;: 87.4,
 &#39;rix&#39;: 87.0}
</code></pre></div><br>
<h3 id="23-sentimenttext-diction-lang">2.3 sentiment(text, diction, lang)</h3>
<p>常见的情感分析默认情绪词无(等)权重， 通过统计词语个数来反应情感信息。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">sentiment(text, diction, lang=&#39;chinese&#39;, return_series=False)
</code></pre></div><ul>
<li><strong>text</strong> 待分析的文本字符串</li>
<li><strong>diction</strong>  格式为Python字典类型。形如下面的案例</li>
<li><strong>lang</strong> 文本的语言类型， 中文chinese、英文english，默认中文。</li>
<li><strong>return_series</strong>  计算结果是否输出为pd.Series类型，默认为False</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>

<span class="n">diction</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;pos&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;高兴&#39;</span><span class="p">,</span> <span class="s1">&#39;快乐&#39;</span><span class="p">,</span> <span class="s1">&#39;分享&#39;</span><span class="p">],</span>
           <span class="s1">&#39;neg&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;难过&#39;</span><span class="p">,</span> <span class="s1">&#39;悲伤&#39;</span><span class="p">],</span>
           <span class="s1">&#39;adv&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;很&#39;</span><span class="p">,</span> <span class="s1">&#39;特别&#39;</span><span class="p">]}</span>

<span class="n">text</span> <span class="o">=</span> <span class="s1">&#39;我今天得奖了，很高兴，我要将快乐分享大家。&#39;</span>
<span class="n">ct</span><span class="o">.</span><span class="n">sentiment</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="n">text</span><span class="p">,</span> 
             <span class="n">diction</span><span class="o">=</span><span class="n">diction</span><span class="p">,</span> 
             <span class="n">lang</span><span class="o">=</span><span class="s1">&#39;chinese&#39;</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">{&#39;pos_num&#39;: 3,
 &#39;neg_num&#39;: 0,
 &#39;adv_num&#39;: 1,
 &#39;stopword_num&#39;: 8,
 &#39;word_num&#39;: 14,
 &#39;sentence_num&#39;: 1}
</code></pre></div><br>
<h3 id="24-sentiment_by_valence">2.4 sentiment_by_valence()</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">ct.sentiment_by_valence(text, diction, lang=&#39;chinese&#39;, return_series=False)
</code></pre></div><ul>
<li><strong>text</strong> 待分析的文本字符串</li>
<li><strong>diction</strong>  格式为Python字典类型。形如下面的案例</li>
<li><strong>lang</strong> 文本的语言类型， 中文chinese、英文english，默认中文。</li>
<li><strong>return_series</strong> 计算结果是否输出为pd.Series类型，默认为False</li>
</ul>
<p>常见的情感分析是无(等)权重, 但实际上不同的词语所携带的情感信息的强度差异是很大的。据此学者们开发出很多带权重的词典，例如</p>
<ul>
<li>英文具体性词典en_valence_Concreteness.yaml， 词典中每个词都有一个concreteness值</li>
<li>中文六维度语义词典zh_valence_SixSemanticDimensionDatabase.yaml,  每个中文词有六个值。</li>
</ul>
<p>以具体性为例， <strong>语言具体性Concreteness</strong>描述了一个词在多大程度上是指一个实际的、有形的或“真实的”实体，以一种更具体、更熟悉、更容易被眼睛或心灵感知的方式描述对象和行为（即，可想象或生动；Brysbaert, Warriner, and Kuperman 2014; Semin and Fiedler 1988)</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">concreteness_dict</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">read_yaml_dict</span><span class="p">(</span><span class="s1">&#39;en_valence_Concreteness.yaml&#39;</span><span class="p">)[</span><span class="s1">&#39;Dictionary&#39;</span><span class="p">]</span>
<span class="n">concreteness_dict</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">{&#39;roadsweeper&#39;: {&#39;concreteness&#39;: 4.85},
 &#39;traindriver&#39;: {&#39;concreteness&#39;: 4.54},
 &#39;tush&#39;: {&#39;concreteness&#39;: 4.45},
 &#39;hairdress&#39;: {&#39;concreteness&#39;: 3.93},
 &#39;pharmaceutics&#39;: {&#39;concreteness&#39;: 3.77},
 &#39;hoover&#39;: {&#39;concreteness&#39;: 3.76},
 &#39;shopkeeping&#39;: {&#39;concreteness&#39;: 3.18},
 &#39;pushiness&#39;: {&#39;concreteness&#39;: 2.48},
 ......
 }
</code></pre></div><p>可能 <em><strong>concreteness_dict</strong></em>不够直观， 如果整理转化一下大概类似于</p>
<p><img loading="lazy" src="img/11-concreteness_df.png" alt=""  />
</p>
<p><a href="https://textdata.cn/blog/jcr_concreteness_computation/"><strong>JCR2021 | 计算文本的语言具体性</strong></a> 文中提供了一个案例</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">reply</span> <span class="o">=</span> <span class="s2">&#34;I&#39;ll go look for that&#34;</span>

<span class="n">score</span><span class="o">=</span><span class="n">ct</span><span class="o">.</span><span class="n">sentiment_by_valence</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="n">reply</span><span class="p">,</span> 
                              <span class="n">diction</span><span class="o">=</span><span class="n">concreteness_dict</span><span class="p">,</span> 
                              <span class="n">lang</span><span class="o">=</span><span class="s1">&#39;english&#39;</span><span class="p">)</span>

<span class="n">score</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">{&#39;concreteness&#39;: 9.28, 
&#39;word_num&#39;: 6}
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">employee_replys</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&#34;I&#39;ll go look for that&#34;</span><span class="p">,</span>
                   <span class="s2">&#34;I&#39;ll go search for that&#34;</span><span class="p">,</span>
                   <span class="s2">&#34;I&#39;ll go search for that top&#34;</span><span class="p">,</span>
                   <span class="s2">&#34;I&#39;ll go search for that t-shirt&#34;</span><span class="p">,</span>
                   <span class="s2">&#34;I&#39;ll go look for that t-shirt in grey&#34;</span><span class="p">,</span>
                   <span class="s2">&#34;I&#39;ll go search for that t-shirt in grey&#34;</span><span class="p">]</span>

<span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">reply</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">employee_replys</span><span class="p">):</span>
    <span class="n">score</span><span class="o">=</span><span class="n">ct</span><span class="o">.</span><span class="n">sentiment_by_valence</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="n">reply</span><span class="p">,</span> 
                                  <span class="n">diction</span><span class="o">=</span><span class="n">concreteness_dict</span><span class="p">,</span> 
                                  <span class="n">lang</span><span class="o">=</span><span class="s1">&#39;english&#39;</span><span class="p">)</span>
    
    <span class="n">template</span> <span class="o">=</span> <span class="s2">&#34;Concreteness Score: </span><span class="si">{score:.2f}</span><span class="s2"> | Example-</span><span class="si">{idx}</span><span class="s2">: </span><span class="si">{exmaple}</span><span class="s2">&#34;</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="n">template</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">score</span><span class="o">=</span><span class="n">score</span><span class="p">[</span><span class="s1">&#39;concreteness&#39;</span><span class="p">],</span> 
                          <span class="n">idx</span><span class="o">=</span><span class="n">idx</span><span class="p">,</span> 
                          <span class="n">exmaple</span><span class="o">=</span><span class="n">reply</span><span class="p">))</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">Concreteness Score: 9.28 | Example-0: I&#39;ll go look for that
Concreteness Score: 9.32 | Example-1: I&#39;ll go search for that
Concreteness Score: 13.25 | Example-2: I&#39;ll go search for that top
Concreteness Score: 14.25 | Example-3: I&#39;ll go search for that t-shirt
Concreteness Score: 21.32 | Example-4: I&#39;ll go look for that t-shirt in grey
Concreteness Score: 21.36 | Example-5: I&#39;ll go search for that t-shirt in grey
</code></pre></div><br>
<h3 id="25-word_in_context">2.5 word_in_context()</h3>
<p>You shall know a word by the company it keeps通过一个单词所处的语境，我们可以了解该单词的含义。</p>
<p>在text中查找keywords出现的上下文内容(窗口window)，返回df。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">ct.word_in_context(text, keywords, window=3, lang=&#39;chinese&#39;)
</code></pre></div><ul>
<li><strong>text</strong>  待分析文本</li>
<li><strong>keywords</strong>  关键词列表</li>
<li><strong>window</strong>  关键词上下文窗口大小</li>
<li><strong>lang</strong> 文本的语言类型， 中文chinese、英文english，默认中文。</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>

<span class="c1">#测试代码，假设zh_text是年报文本，从找找出丝网词相关词的上下文</span>
<span class="n">zh_text</span> <span class="o">=</span> <span class="s2">&#34;&#34;&#34;
</span><span class="s2">【插入一条自家广告】大邓自己家的家，
</span><span class="s2">安平县多隆丝网制品，生产销售不锈钢轧花网、
</span><span class="s2">电焊网、石笼网、刀片刺绳、冲孔网等丝网制品。
</span><span class="s2">联系人 邓颖静 0318-7686899
</span><span class="s2">
</span><span class="s2">人生苦短，我学Python
</span><span class="s2">在社科中，可以用Python做文本分析
</span><span class="s2">Python是一门功能强大的编程语言，广泛应用在经管社科领域。
</span><span class="s2">可以做网络爬虫、文本分析、LDA话题模型、相似度分析等。
</span><span class="s2">
</span><span class="s2">今年经济不景气，形势异常严峻。
</span><span class="s2">由于疫情不景气，静默管理， 产品积压， 公司经营困难。
</span><span class="s2">保就业促就业，任务十分艰巨。
</span><span class="s2">&#34;&#34;&#34;</span>

<span class="c1">#【python】上下文</span>
<span class="n">ct</span><span class="o">.</span><span class="n">word_in_context</span><span class="p">(</span><span class="n">text</span> <span class="o">=</span> <span class="n">zh_text</span><span class="p">,</span> 
                   <span class="n">keywords</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;python&#39;</span><span class="p">],</span> 
                   <span class="n">window</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> 
                   <span class="n">lang</span><span class="o">=</span><span class="s1">&#39;chinese&#39;</span><span class="p">)</span>
</code></pre></div><p><img loading="lazy" src="img/20-word-in-context.png" alt=""  />
</p>
<br>
<h3 id="26-epu">2.6 epu()</h3>
<p><a href="https://textdata.cn/blog/2023-12-20-measure-china-economic-policy-uncertainty/"><strong>代码  | 使用新闻数据测量经济政策不确定性EPU</strong></a></p>
<p><img loading="lazy" src="img/13-epu-plot.png" alt=""  />
</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">epu(df, freq=&#39;Y&#39;, e_pattern=&#39;&#39;, p_pattern=&#39;&#39;, u_pattern=&#39;&#39;)
</code></pre></div><ul>
<li><strong>df</strong>  新闻数据DataFrame， 含text和date两个字段。 每一行代表一条新闻记录</li>
<li><strong>freq</strong> 字符串； 确定EPU指数的时间颗粒度； 如年Y, 月m, 日d, 默认 freq=&lsquo;Y&rsquo;</li>
<li><strong>e_pattern</strong> 字符串；经济类词典，用<code>|</code>间隔词语，形如 <strong>e_pattern = ‘经济|金融’</strong></li>
<li><strong>p_pattern</strong> 字符串；政策词典，用<code>|</code>间隔词语，形如 <strong>p_pattern = ‘政策|治理|行政’</strong></li>
<li><strong>u_pattern</strong>  字符串；不确定性词典，用<code>|</code>间隔词语，形如 <strong>u_pattern = ‘风险|危机|难以预测’</strong></li>
</ul>
<p>准备如下图格式的数据 <em><strong>news_df</strong></em></p>
<p><img loading="lazy" src="img/12-news-df.png" alt=""  />
</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>

<span class="c1">#省略，读取数据得到 news_df</span>

<span class="n">epu_df</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">epu</span><span class="p">(</span><span class="n">df</span><span class="o">=</span><span class="n">news_df</span><span class="p">,</span> <span class="n">freq</span><span class="o">=</span><span class="s1">&#39;m&#39;</span><span class="p">)</span>
<span class="n">epu_df</span>
</code></pre></div><p><img loading="lazy" src="img/13-epu-df.png" alt=""  />
</p>
<br>
<h3 id="27-fepu">2.7 fepu()</h3>
<p><a href="https://textdata.cn/blog/2024-04-25-firm-economic-policy-uncertainty/">使用管理层讨论与分析文本数据测量「企业感知不确定性」(Subjective perception of economic policy uncertainty, FEPU)</a></p>
<p><img loading="lazy" src="img/16-fepu-plot.png" alt=""  />
</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">ct.fepu(text, ep_pattern, u_pattern)
</code></pre></div><ul>
<li><em><strong>text</strong></em> ；某时期t某企业i的管理层讨论与分析md&amp;a文本</li>
<li><em><strong>ep_pattern</strong></em> 字符串；经济政策类词典，用<code>|</code>间隔词语，形如 <strong>ep_pattern = ‘经济|金融|政策|治理|行政’</strong></li>
<li><em><strong>u_pattern</strong></em> 字符串；不确定性词典，用<code>|</code>间隔词语，形如 <strong>u_pattern = ‘风险|危机|难以预测’</strong></li>
</ul>
<p>准备如下图格式的数据 <em><strong>mda_df</strong></em></p>
<p><img loading="lazy" src="img/14-mdadf.png" alt=""  />
</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>

<span class="c1">#省略，读取数据得到 mda_df</span>

<span class="n">fepu_df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;经营讨论与分析内容&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">ct</span><span class="o">.</span><span class="n">fepu</span><span class="p">)</span>
<span class="n">res_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">df</span><span class="p">[[</span><span class="s1">&#39;会计年度&#39;</span><span class="p">,</span> <span class="s1">&#39;股票代码&#39;</span><span class="p">]],</span> <span class="n">fepu_df</span><span class="p">],</span>   <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">res_df</span>
</code></pre></div><p><img loading="lazy" src="img/15-fepu.png" alt=""  />
</p>
<br>
<br>
<h3 id="28-semantic_brand_score">2.8 semantic_brand_score()</h3>
<p><a href="https://textdata.cn/blog/2024-04-12-semantic-brand-score/">文献&amp;代码 | 使用Python计算语义品牌评分(Semantic Brand Score, SBS)</a> ， 通过 SBS 来衡量品牌（个体、公司、品牌、关键词等）的重要性。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">ct.semantic_brand_score(text, brands, lang=&#39;chinese&#39;)
</code></pre></div><ul>
<li><em><strong>text</strong></em> 待分析文本</li>
<li><em><strong>brands</strong></em> 词语列表；</li>
<li><em><strong>lang</strong></em>  语言类型，&ldquo;chinese&quot;或&quot;english&rdquo;，默认&quot;chinese&quot;</li>
</ul>
<p>以三体小说为例，通过测量品牌语义评分SBS来反映小说角色的重要性。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>

<span class="n">brands</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;汪淼&#39;</span><span class="p">,</span> <span class="s1">&#39;史强&#39;</span><span class="p">,</span> <span class="s1">&#39;罗辑&#39;</span><span class="p">,</span> <span class="s1">&#39;叶文洁&#39;</span><span class="p">,</span> <span class="s1">&#39;伊文斯&#39;</span><span class="p">]</span>

<span class="c1">#准备santi_test_text</span>
<span class="c1">#小说等分20份， 读取第一份得到santi_test_text</span>

<span class="n">sbs_df</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">semantic_brand_score</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="n">santi_test_text</span><span class="p">,</span> 
                               <span class="n">brands</span><span class="o">=</span><span class="n">brands</span><span class="p">,</span> 
                               <span class="n">lang</span><span class="o">=</span><span class="s1">&#39;chinese&#39;</span><span class="p">)</span>
<span class="n">sbs_df</span>
</code></pre></div><p><img loading="lazy" src="img/19-1st-sbs.png" alt=""  />
</p>
<p>如果将三体小说分成20份， 每一份都测算出每个角色的SBS，绘制出折线图如下图所示。</p>
<p><img loading="lazy" src="img/18-sbs-plot.png" alt=""  />
</p>
<h3 id="29-文本相似度">2.9 文本相似度</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">ct.cosine_sim(text1, text2)   cos余弦相似
ct.jaccard_sim(text1, text2)  jaccard相似
ct.minedit_sim(text1, text2)  最小编辑距离相似度； 
ct.simple_sim(text1, text2)   更改变动算法
</code></pre></div><p>算法实现参考自 <code>Cohen, Lauren, Christopher Malloy, and Quoc Nguyen. Lazy prices. No. w25084. National Bureau of Economic Research, 2018.</code></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span> 


<span class="n">text1</span> <span class="o">=</span> <span class="s1">&#39;编程真好玩编程真好玩&#39;</span>
<span class="n">text2</span> <span class="o">=</span> <span class="s1">&#39;游戏真好玩编程真好玩&#39;</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;cosine: &#39;</span><span class="p">,</span> <span class="n">ct</span><span class="o">.</span><span class="n">cosine_sim</span><span class="p">(</span><span class="n">text1</span><span class="p">,</span> <span class="n">text2</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;jaccard&#39;</span><span class="p">,</span> <span class="n">ct</span><span class="o">.</span><span class="n">jaccard_sim</span><span class="p">(</span><span class="n">text1</span><span class="p">,</span> <span class="n">text2</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;minedit&#39;</span><span class="p">,</span> <span class="n">ct</span><span class="o">.</span><span class="n">minedit_sim</span><span class="p">(</span><span class="n">text1</span><span class="p">,</span> <span class="n">text2</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;simple&#39;</span><span class="p">,</span> <span class="n">ct</span><span class="o">.</span><span class="n">simple_sim</span><span class="p">(</span><span class="n">text1</span><span class="p">,</span> <span class="n">text2</span><span class="p">))</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">cosine:  0.82
jaccard: 0.67
minedit: 1.00
simple:  0.84
</code></pre></div><br>
<h3 id="210-ctword_hhi">2.10 ct.word_hhi</h3>
<p>文本的赫芬达尔-赫希曼指数。ct.word_hhi(text, lang=&lsquo;chinese&rsquo;)</p>
<br>
<p><strong>赫芬达尔-赫希曼指数</strong>(<strong>Herfindahl-Hirschman Index</strong>)作为一种衡量市场集中度的经济指标，通常用于分析产业或市场中企业份额的分布情况。</p>
<p><img loading="lazy" src="img/word-hhi-algo.png" alt=""  />
</p>
<p>前人类比市场集中程度，用于测量专利质量(知识宽度)。 那放在文本语言中，我们是否可能利用HHI来量化某个语料库中不同词汇的使用频率分布，以此来分析个人、群体或时代的语言风格、词汇丰富度、或是语言标准化与变化的趋势。</p>
<ul>
<li>如果词汇分布非常均匀，表明语言使用中的词汇多样性高，HHI值就会较低；</li>
<li>反之，如果少数词汇占据了大部分文本空间，表明词汇使用集中，HHI值则较高。</li>
</ul>
<p>结合其他语言学指标一起使用，比如TTR（Type-Token Ratio，类型-标记比率）、Shannon entropy（香农熵）等，共同评估语言表达的复杂度和多样性。不过，这类研究的文献相对较少，因为语言学领域有自己一套成熟且专业的分析工具和方法，HHI更多地被视为跨学科应用的一个创新尝试。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>

<span class="n">personA</span> <span class="o">=</span> <span class="s1">&#39;这场音乐会太嗨了&#39;</span>
<span class="n">personB</span> <span class="o">=</span> <span class="s1">&#39;这场音乐会说出来令你不敢相信，主办方策划有方，群众激情满满，我印象深刻，体验感拉满&#39;</span>


<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;A-hhi&#39;</span><span class="p">,</span> <span class="n">ct</span><span class="o">.</span><span class="n">word_hhi</span><span class="p">(</span><span class="n">personA</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;B-hhi&#39;</span><span class="p">,</span> <span class="n">ct</span><span class="o">.</span><span class="n">word_hhi</span><span class="p">(</span><span class="n">personB</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;A词汇多样性&#39;</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">ct</span><span class="o">.</span><span class="n">word_hhi</span><span class="p">(</span><span class="n">personA</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;B词汇多样性&#39;</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">ct</span><span class="o">.</span><span class="n">word_hhi</span><span class="p">(</span><span class="n">personB</span><span class="p">))</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">A-hhi 0.20000000000000004
B-hhi 0.07024793388429751

A词汇多样性 0.7999999999999999
B词汇多样性 0.9297520661157025
</code></pre></div><br>
<br>
<h2 id="三plot模块">三、Plot模块</h2>
<table>
<thead>
<tr>
<th>模块</th>
<th>函数</th>
<th>功能</th>
</tr>
</thead>
<tbody>
<tr>
<td><em><strong>plot</strong></em></td>
<td><code>ct.matplotlib_chinese()</code></td>
<td>支持matplotlib中文绘图</td>
</tr>
<tr>
<td><em><strong>plot</strong></em></td>
<td><code>ct.lexical_dispersion_plot1(text, targets_dict, lang, title, figsize)</code></td>
<td>对某一个文本text， 可视化不同目标类别词targets_dict在文本中出现位置</td>
</tr>
<tr>
<td><em><strong>plot</strong></em></td>
<td><code>ct.lexical_dispersion_plot2(texts_dict, targets, lang, title, figsize)</code></td>
<td>对某几个文本texts_dict， 可视化某些目标词targets在文本中出现相对位置(0~100)</td>
</tr>
</tbody>
</table>
<br>
<h3 id="31-matplotlib_chinese">3.1 matplotlib_chinese()</h3>
<p>matplotlib默认不支持中文可视化， cntext新增该函数，可以解决中文可视化问题</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>

<span class="n">plt</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">matplotlib_chinese</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">16</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;中文图表&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/27-chinese-matplotlib.png" alt=""  />
</p>
<br>
<h3 id="32-lexical_dispersion_plot1">3.2 lexical_dispersion_plot1()</h3>
<p>词汇分散图可视化， 对某一个文本text， 可视化不同目标类别词targets_dict在文本中出现位置</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">ct</span><span class="o">.</span><span class="n">lexical_dispersion_plot1</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">targets_dict</span><span class="p">,</span> <span class="n">lang</span><span class="o">=</span><span class="s1">&#39;chinese&#39;</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span> <span class="n">title</span><span class="o">=</span><span class="s1">&#39;特定词汇在不同文本来源的相对离散图&#39;</span><span class="p">,</span> <span class="n">prop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</code></pre></div><ul>
<li><em><strong>text</strong></em>: 文本数据</li>
<li><em><strong>targets_dict</strong></em>:  目标类别词字典； targets_dict={&lsquo;pos&rsquo;: [&lsquo;开心&rsquo;, &lsquo;快乐&rsquo;], &lsquo;neg&rsquo;: [&lsquo;悲伤&rsquo;, &lsquo;难过&rsquo;]}</li>
<li><em><strong>lang</strong></em>: 文本数据texts_dict的语言类型，默认&rsquo;chinese'.</li>
<li><em><strong>figsize</strong></em>: 图的长宽尺寸. 默认 (8, 5).</li>
<li><em><strong>title</strong></em> : 图的标题；</li>
<li><em><strong>prop</strong></em>: 横坐标字符位置是否为相对位置. 默认True，横坐标索引值取值范围0 ~ 100</li>
</ul>
<br>
<p>点击下载 <a href="https://textdata.cn/data/%E4%B8%89%E4%BD%93.txt"><strong>三体.txt</strong></a>、<a href="https://textdata.cn/data/%E5%9F%BA%E5%9C%B0.txt"><strong>基地.txt</strong></a>两本小说文件。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>

<span class="n">roles_dict</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&#34;汪淼&#34;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;汪淼&#39;</span><span class="p">],</span>
    <span class="s2">&#34;叶文洁&#34;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;叶文洁&#39;</span><span class="p">],</span>
    <span class="s2">&#34;罗辑&#34;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;罗辑&#39;</span><span class="p">]</span>
<span class="p">}</span>

<span class="n">santi_text</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;三体.txt&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">lexical_dispersion_plot1</span><span class="p">(</span><span class="n">text</span> <span class="o">=</span> <span class="n">santi_text</span><span class="p">,</span>  <span class="c1">#文本数据</span>
                            <span class="n">targets_dict</span> <span class="o">=</span> <span class="n">roles_dict</span><span class="p">,</span> <span class="c1">#角色</span>
                            <span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span>  <span class="c1">#尺寸大小</span>
                            <span class="n">lang</span> <span class="o">=</span> <span class="s1">&#39;chinese&#39;</span><span class="p">,</span>  <span class="c1">#中文数据</span>
                            <span class="n">title</span> <span class="o">=</span> <span class="s1">&#39;《三体》小说角色出现位置&#39;</span><span class="p">,</span> <span class="c1">#标题</span>
                            <span class="n">prop</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>    <span class="c1">#相对位置(横坐标轴取值范围0-100)</span>
<span class="n">ax</span>
</code></pre></div><p><img loading="lazy" src="img/23-lexical_dispersion_plot1-relative.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">ct</span><span class="o">.</span><span class="n">lexical_dispersion_plot1</span><span class="p">(</span><span class="n">text</span> <span class="o">=</span> <span class="n">santi_text</span><span class="p">,</span>  <span class="c1">#文本数据</span>
                            <span class="n">targets_dict</span> <span class="o">=</span> <span class="n">roles_dict</span><span class="p">,</span> <span class="c1">#角色</span>
                            <span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span>  <span class="c1">#尺寸大小</span>
                            <span class="n">lang</span> <span class="o">=</span> <span class="s1">&#39;chinese&#39;</span><span class="p">,</span>  <span class="c1">#中文数据</span>
                            <span class="n">title</span> <span class="o">=</span> <span class="s1">&#39;《三体》小说角色出现位置&#39;</span><span class="p">,</span> <span class="c1">#标题</span>
                            <span class="n">prop</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>    <span class="c1">#绝对位置(横坐标轴取值范围与小说文本长度有关)</span>
</code></pre></div><p><img loading="lazy" src="img/24-lexical_dispersion_plot1-absolute.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>

<span class="c1">#diy了一个小词典</span>
<span class="n">senti_dict</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;pos&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;开心&#39;</span><span class="p">,</span> <span class="s1">&#39;幸福&#39;</span><span class="p">,</span> <span class="s1">&#39;快乐&#39;</span><span class="p">,</span> <span class="s1">&#39;安宁&#39;</span><span class="p">,</span> <span class="s1">&#39;希望&#39;</span><span class="p">],</span>
    <span class="s1">&#39;neg&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;紧张&#39;</span><span class="p">,</span> <span class="s1">&#39;恐惧&#39;</span><span class="p">,</span> <span class="s1">&#39;害怕&#39;</span><span class="p">,</span> <span class="s1">&#39;绝望&#39;</span><span class="p">]</span>
<span class="p">}</span>

<span class="n">santi_text</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;三体.txt&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">lexical_dispersion_plot1</span><span class="p">(</span><span class="n">text</span> <span class="o">=</span> <span class="n">santi_text</span><span class="p">,</span> 
                            <span class="n">targets_dict</span> <span class="o">=</span> <span class="n">senti_dict</span><span class="p">,</span> 
                            <span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> 
                            <span class="n">lang</span> <span class="o">=</span> <span class="s1">&#39;chinese&#39;</span><span class="p">,</span> 
                            <span class="n">title</span> <span class="o">=</span> <span class="s1">&#39;《三体》情绪词出现位置&#39;</span><span class="p">,</span>
                            <span class="n">prop</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
<span class="n">ax</span>
</code></pre></div><p><img loading="lazy" src="img/25-santi_sentiment.png" alt=""  />
</p>
<br>
<h3 id="33-lexical_dispersion_plot2">3.3 lexical_dispersion_plot2()</h3>
<p>词汇分散图可视化， 对某几个文本texts_dict， 可视化某些目标词targets在文本中出现相对位置(0~100)</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">ct</span><span class="o">.</span><span class="n">lexical_dispersion_plot2</span><span class="p">(</span><span class="n">texts_dict</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">lang</span><span class="o">=</span><span class="s1">&#39;chinese&#39;</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span> <span class="n">title</span><span class="o">=</span><span class="s1">&#39;特定词汇在不同文本来源的相对离散图&#39;</span><span class="p">)</span>
</code></pre></div><ul>
<li><em><strong>texts_dict</strong></em>: 多个文本的字典数据。形如{&lsquo;source1&rsquo;: &lsquo;source1的文本内容&rsquo;, &lsquo;source2&rsquo;: &lsquo;source2的文本内容&rsquo;}</li>
<li><em><strong>targets</strong></em>: 目标词列表</li>
<li><em><strong>lang</strong></em>: 文本数据texts_dict的语言类型，默认&rsquo;chinese'.</li>
<li><em><strong>figsize</strong></em>: 图的长宽尺寸. 默认 (8, 5).</li>
<li><em><strong>title</strong></em> : 图的标题；</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">targets</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;太空&#39;</span><span class="p">,</span> <span class="s1">&#39;宇宙&#39;</span><span class="p">]</span>

<span class="n">texts_dict</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;三体&#39;</span><span class="p">:</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;三体.txt&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">read</span><span class="p">(),</span>
              <span class="s1">&#39;基地&#39;</span><span class="p">:</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;基地.txt&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">read</span><span class="p">()}</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">lexical_dispersion_plot2</span><span class="p">(</span><span class="n">texts_dict</span> <span class="o">=</span> <span class="n">texts_dict</span><span class="p">,</span>
                            <span class="n">targets</span> <span class="o">=</span> <span class="n">targets</span><span class="p">,</span> 
                            <span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> 
                            <span class="n">title</span> <span class="o">=</span> <span class="s1">&#39;&#34;太空/宇宙&#34;词语出现位置&#39;</span><span class="p">,</span>
                            <span class="n">lang</span> <span class="o">=</span> <span class="s1">&#39;chinese&#39;</span><span class="p">)</span>
<span class="n">ax</span>
</code></pre></div><p><img loading="lazy" src="img/26-santi_base.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="四model模块">四、Model模块</h2>
<p>本部分主要内容是词嵌入模型相关技术， 包括Word2Vec(GLove)的训练、读取、扩展词典。</p>
<table>
<thead>
<tr>
<th>模块</th>
<th>函数(类)</th>
<th>功能</th>
</tr>
</thead>
<tbody>
<tr>
<td><em><strong>model</strong></em></td>
<td><em><strong>ct.W2VModel(corpus_file, encoding, lang=&lsquo;chinese&rsquo;)</strong></em></td>
<td>训练Word2Vec</td>
</tr>
<tr>
<td><em><strong>model</strong></em></td>
<td><em><strong>ct.load_wv(wv_path)</strong></em></td>
<td>读取cntext2.x训练出的word2vec模型文件</td>
</tr>
<tr>
<td><em><strong>model</strong></em></td>
<td><em><strong>ct.glove2word2vec(glove_file, word2vec_file)</strong></em></td>
<td>将GLoVe模型.txt文件转化为Word2Vec模型.txt文件；注意这里的GLoVe模型.txt是通过<a href="https://github.com/standfordnlp/GloVe">Standfordnlp/GloVe</a> 训练得到的</td>
</tr>
<tr>
<td><em><strong>model</strong></em></td>
<td><em><strong>ct.expand_dictionary(wv,  seeddict, topn=100)</strong></em></td>
<td>扩展词典,  结果保存到路径[output/Word2Vec]中</td>
</tr>
<tr>
<td><em><strong>model</strong></em></td>
<td><code>ct.Glove(corpus_file, lang='chinese')</code></td>
<td>训练GLove模型。 算法运行较慢，吃内存，不推荐！！</td>
</tr>
<tr>
<td><em><strong>model</strong></em></td>
<td><code>ct.SoPmi(corpus_file, seed_file, lang='chinese')</code></td>
<td>共现法扩展词典</td>
</tr>
</tbody>
</table>
<h3 id="41-w2vmodel">4.1 W2VModel()</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">model = ct.W2VModel(corpus_file,  encoding=&#39;utf-8&#39;, lang=&#39;chinese&#39;) 
</code></pre></div><ul>
<li><strong>corpus_file</strong> 语料txt文件路径</li>
<li><strong>encoding</strong> 语料txt文件编码方式</li>
<li><strong>lang</strong> 语料的语言类型， 中文chinese、英文english，默认中文。</li>
</ul>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">model.train()
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>

<span class="c1">#训练模型</span>
<span class="c1">#[data/三体.txt]体积2.7M</span>
<span class="n">w2v</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">W2VModel</span><span class="p">(</span><span class="n">corpus_file</span><span class="o">=</span><span class="s1">&#39;data/三体.txt&#39;</span><span class="p">,</span>  <span class="c1">#语料txt文件路径</span>
                  <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">,</span><span class="c1">#语料txt文件编码方式</span>
                  <span class="n">lang</span><span class="o">=</span><span class="s1">&#39;chinese&#39;</span><span class="p">)</span> <span class="c1">#英文传english</span>

<span class="n">w2v</span><span class="o">.</span><span class="n">train</span><span class="p">()</span> <span class="c1">#设置存储</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">Start Training! This may take a while. Please be patient...

Training word2vec model took 5 seconds

Note: The Word2Vec model has been saved to output/Word2Vec
</code></pre></div><p>[data/三体.txt]体积2.7M，  训练时间5s， 模型文件存储于 <em><strong>output/Word2Vec/三体.100.6.bin</strong></em></p>
<p><img loading="lazy" src="img/03-word2vec.png" alt=""  />
</p>
<br>
<h3 id="42-glove">4.2 Glove()</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">ct.Glove(corpus_file, lang=&#39;chinese&#39;)
</code></pre></div><ul>
<li><strong>corpus_file</strong> 语料txt文件路径</li>
<li><strong>lang</strong> 语料的语言类型， 中文chinese、英文english，默认中文</li>
</ul>
<p>GLove算法的运算速度非常慢， cntext并没有对此进行优化，强烈不建议百兆以上语料使用本算法。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>
<span class="kn">import</span> <span class="nn">os</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">Glove</span><span class="p">(</span><span class="n">corpus_file</span><span class="o">=</span><span class="s1">&#39;data/三体.txt&#39;</span><span class="p">,</span> 
                 <span class="n">lang</span><span class="o">=</span><span class="s1">&#39;chinese&#39;</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">Create vocabulary for Glove.

Create cooccurrence matrix.

Create cooccurrence matrix.
To complete this task, the code may take a significant amount of time, ranging from several minutes to potentially hours. Please be patient while the process runs.

Iteration 20: error 10541294.8481
Finish training! Used 22.38 s

Save the glove embeddings to a binary file
</code></pre></div><p><img loading="lazy" src="img/05-glove.png" alt=""  />
</p>
<p>训练生成的 <code>output/Glove/glove.三体.50.bin</code> 也可用 <em><strong>ct.load_w2v</strong></em> 读取，这里就不展示了。</p>
<br>
<h3 id="43-sopm">4.3 SoPm()</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">ct.SoPmi(corpus_file, seed_file)       #人工标注的初始种子词
</code></pre></div><ul>
<li><strong>corpus_file</strong>  语料txt文件路径</li>
<li><strong>seed_file</strong> 初始种子词txt文件路径</li>
</ul>
<p>共现法</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>

<span class="n">sopmier</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">SoPmi</span><span class="p">(</span><span class="n">corpus_file</span><span class="o">=</span><span class="s1">&#39;data/sopmi_corpus.txt&#39;</span><span class="p">,</span>   
                   <span class="n">seed_file</span><span class="o">=</span><span class="s1">&#39;data/sopmi_seed.txt&#39;</span><span class="p">)</span>       <span class="c1">#人工标注的初始种子词</span>
                     

<span class="n">sopmier</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">Step 1/4:...Preprocess   Corpus ...
Step 2/4:...Collect co-occurrency information ...
Step 3/4:...Calculate   mutual information ...
Step 4/4:...Save    candidate words ...
Finish! used 19.74 s
</code></pre></div><p><img loading="lazy" src="img/06-sopmi.png" alt=""  />
</p>
<br>
<h3 id="44-load_wv">4.4 load_wv()</h3>
<p>导入cntext2.x 预训练的word2vec模型 .txt文件</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">ct.load_wv(wv_path, binary=False)
</code></pre></div><ul>
<li><strong>wv_path</strong> 模型文件路径</li>
</ul>
<p>读取  <em><strong>output/Word2Vec/三体.100.6.txt</strong></em> 模型文件,  返回 <code>gensim.models.word2vec.Word2Vec</code> 类型。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>

<span class="c1"># 使用gensim也可读取训练的模型</span>
<span class="c1"># from gensim.models import KeyedVectors</span>
<span class="c1"># santi_wv = KeyedVectors.load_word2vec_format(&#39;output/Word2Vec/三体.100.6.txt&#39;, binary=False)</span>
<span class="c1"># santi_wv = KeyedVectors.load_word2vec_format(&#39;output/Word2Vec/三体.100.6.bin&#39;, binary=True)</span>

<span class="n">santi_wv</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">load_wv</span><span class="p">(</span><span class="n">wv_path</span><span class="o">=</span><span class="s1">&#39;output/Word2Vec/三体.100.6.txt&#39;</span><span class="p">)</span>
<span class="c1"># santi_wv = ct.load_wv(wv_path=&#39;output/Word2Vec/三体.100.6.bin&#39;, binary=True)</span>
<span class="n">santi_wv</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">Loading word2vec model txt file...
&lt;gensim.models.word2vec.KeyedVectors at 0x33f535640&gt;
</code></pre></div><br>
<h3 id="45-glove2word2vec">4.5 glove2word2vec()</h3>
<p>将GLoVe模型.txt文件转化为Word2Vec模型.txt文件；</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">ct</span><span class="o">.</span><span class="n">glove2word2vec</span><span class="p">(</span><span class="n">glove_file</span><span class="p">,</span> <span class="n">word2vec_file</span><span class="p">)</span>
</code></pre></div><ul>
<li><em><strong>glove_file</strong></em>: GLoVe模型.txt文件路径</li>
<li><em><strong>word2vec_file</strong></em>: Word2Vec模型.txt文件路径</li>
</ul>
<br>
<p>注意这里的GLoVe模型.txt是通过<a href="https://github.com/standfordnlp/GloVe">Standfordnlp/GloVe</a> 训练得到的</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>
<span class="n">ct</span><span class="o">.</span><span class="n">glove2word2vec</span><span class="p">(</span><span class="n">glove_file</span><span class="o">=</span><span class="s1">&#39;data/GloVe.6B.50d.txt&#39;</span><span class="p">,</span>
                  <span class="n">word2vec_file</span><span class="o">=</span><span class="s1">&#39;output/word2vec_format_GloVe.6B.50d.txt&#39;</span><span class="p">)</span>
</code></pre></div><br>
<h3 id="注意">注意</h3>
<ul>
<li><em><strong>ct.load_wv()</strong></em> 导入后得到的数据类型是 <em><strong>gensim.models.keyedvectors.KeyedVectors</strong></em> 。</li>
<li><em><strong>gensim.models.word2vec.Word2Vec</strong></em> 可以转化为  <em><strong>gensim.models.keyedvectors.KeyedVectors</strong></em> ，</li>
</ul>
<p>例如</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">santi_w2v.wv
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">&lt;gensim.models.keyedvectors.KeyedVectors at 0x319f4a090&gt;
</code></pre></div><br>
<h3 id="46-expand_dictionary">4.6 expand_dictionary()</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">ct.expand_dictionary(wv,  seeddict, topn=100)
</code></pre></div><ul>
<li><strong>wv</strong>  预训练模型，数据类型为 gensim.models.keyedvectors.KeyedVectors。</li>
<li><strong>seeddict</strong>  参数类似于种子词；格式为PYTHON字典；</li>
<li><strong>topn</strong> 返回topn个语义最接近seeddict的词</li>
</ul>
<p>根据设置的seeddict,  可按类别扩展并生成对应的词典txt文件， txt文件位于[output/Word2Vec]中。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">seeddict</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;人物&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;叶文洁&#39;</span><span class="p">,</span> <span class="s1">&#39;史强&#39;</span><span class="p">,</span> <span class="s1">&#39;罗辑&#39;</span><span class="p">],</span> 
    <span class="s1">&#39;物体&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;飞船&#39;</span><span class="p">,</span> <span class="s1">&#39;车辆&#39;</span><span class="p">]</span>
<span class="p">}</span>


<span class="n">ct</span><span class="o">.</span><span class="n">expand_dictionary</span><span class="p">(</span><span class="n">wv</span><span class="o">=</span><span class="n">santi_w2v</span><span class="o">.</span><span class="n">wv</span><span class="p">,</span>  
                     <span class="n">seeddict</span><span class="o">=</span><span class="n">seeddict</span><span class="p">,</span> 
                     <span class="n">topn</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</code></pre></div><p><img loading="lazy" src="img/04-expand.png" alt=""  />
</p>
<br>
<br>
<h2 id="五mind模块">五、Mind模块</h2>
<p>词嵌入中蕴含着人类的认知信息，以往的词嵌入大多是比较一个概念中两组反义词与某对象的距离计算认知信息。</p>
<ul>
<li>
<p><strong>多个对象与某概念的语义远近</strong>，职业与性别，某个职业是否存在亲近男性，而排斥女性</p>
</li>
<li>
<p>多个对象在某概念向量投影的大小， 人类语言中留存着对不同动物体积的认知记忆，如小鼠大象。动物词在词向量空间中是否能留存着这种大小的记忆</p>
</li>
</ul>
<p>本模块主要是利用已训练出的word2vec模型，挖掘潜在的态度偏见、刻板印象等。 这部分难度较大， 建议有精力且电脑性能好的同学可以用 cntext 训练模型， 再来实验Mind模块。</p>
<table>
<thead>
<tr>
<th>模块</th>
<th>函数(类)</th>
<th>功能</th>
</tr>
</thead>
<tbody>
<tr>
<td><em><strong>mind</strong></em></td>
<td><code>ct.sematic_projection(wv, words, c_words1, c_words2)</code></td>
<td>测量语义投影</td>
</tr>
<tr>
<td><em><strong>mind</strong></em></td>
<td><code>ct.sematic_distance(wv, words, c_words1, c_words2)</code></td>
<td>测量语义距离</td>
</tr>
<tr>
<td><em><strong>mind</strong></em></td>
<td><code>ct.divergent_association_task(wv, words)</code></td>
<td>测量发散思维(创造力)</td>
</tr>
<tr>
<td><em><strong>mind</strong></em></td>
<td><code>ct.discursive_diversity_score(wv, words)</code></td>
<td>测量语言差异性(认知差异性)</td>
</tr>
<tr>
<td><em><strong>mind</strong></em></td>
<td><em><strong>ct.procrustes_align(base_wv, other_wv)</strong></em></td>
<td>两个word2vec进行语义对齐，可反应随时间的社会语义变迁</td>
</tr>
</tbody>
</table>
<br>
<h3 id="51-sematic_distance">5.1 sematic_distance()</h3>
<p><strong>多个对象与某概念的语义远近</strong>，例如成功与性别，成功是否存在亲近男性，而排斥女性</p>
<p><img loading="lazy" src="img/21-music-success-genderbias.png" alt=""  />
</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">ct.sematic_distance(wv, words, c_words1, c_words2) 
</code></pre></div><ul>
<li><em><strong>wv</strong></em>   模型数据， 数据类型为 gensim.models.keyedvectors.KeyedVectors。</li>
<li><em><strong>words</strong></em>、<em><strong>c_words2</strong></em>、<em><strong>c_words2</strong></em> 均为词语列表</li>
</ul>
<p>分别计算 <em><strong>words</strong></em> 与  <em><strong>c_words1</strong></em> 、<em><strong>c_words2</strong></em> 语义距离，返回距离差值。例如</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">male_concept = [&#39;male&#39;, &#39;man&#39;, &#39;he&#39;, &#39;him&#39;]
female_concept = [&#39;female&#39;, &#39;woman&#39;, &#39;she&#39;, &#39;her&#39;]
software_engineer_concept  = [&#39;engineer&#39;,  &#39;programming&#39;,  &#39;software&#39;]
d1 = distance(male_concept,  software_engineer_concept)
d2 = distance(female_concept,  software_engineer_concept)
</code></pre></div><p>如果 <em><strong>d1-d2&lt;0</strong></em>，说明在语义空间中，<em><strong>software_engineer_concept</strong></em> 更接近 <em><strong>male_concept</strong></em> ，更远离 <em><strong>female_concept</strong></em> 。</p>
<p>换言之，在该语料中，人们对软件工程师这一类工作，对女性存在刻板印象(偏见)。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>

<span class="c1"># glove_w2v.6B.100d.txt链接: https://pan.baidu.com/s/1MMfQ7M0YCzL9Klp4zrlHBw 提取码: 72l0 </span>
<span class="n">g_wv</span> <span class="o">=</span> <span class="n">KeyedVectors</span><span class="o">.</span><span class="n">load_word2vec_format</span><span class="p">(</span><span class="s1">&#39;glove_w2v.6B.100d.txt&#39;</span><span class="p">,</span> <span class="n">no_header</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="c1">#g_wv是gensim.models.keyedvectors.KeyedVectors</span>

<span class="n">engineer</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;program&#39;</span><span class="p">,</span> <span class="s1">&#39;software&#39;</span><span class="p">,</span> <span class="s1">&#39;computer&#39;</span><span class="p">]</span>
<span class="n">man_words</span> <span class="o">=</span>  <span class="p">[</span><span class="s2">&#34;man&#34;</span><span class="p">,</span> <span class="s2">&#34;he&#34;</span><span class="p">,</span> <span class="s2">&#34;him&#34;</span><span class="p">]</span>
<span class="n">woman_words</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&#34;woman&#34;</span><span class="p">,</span> <span class="s2">&#34;she&#34;</span><span class="p">,</span> <span class="s2">&#34;her&#34;</span><span class="p">]</span>

<span class="c1">#在语义空间中，工程师更接近于男人，而不是女人。</span>
<span class="c1">#in semantic space, engineer is closer to man, other than woman.</span>
<span class="n">ct</span><span class="o">.</span><span class="n">sematic_distance</span><span class="p">(</span><span class="n">wv</span><span class="o">=</span><span class="n">g_wv</span><span class="p">,</span>
                    <span class="n">words</span><span class="o">=</span><span class="n">engineer</span><span class="p">,</span> 
                    <span class="n">c_words1</span><span class="o">=</span><span class="n">man_words</span><span class="p">,</span> 
                    <span class="n">c_words2</span><span class="o">=</span><span class="n">woman_words</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">-0.38
</code></pre></div><br>
<h3 id="52-sematic_projection">5.2 sematic_projection()</h3>
<p>多个对象在某概念向量投影的大小</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">ct.sematic_projection(wv, words, c_words1, c_words2) 
</code></pre></div><ul>
<li><em><strong>wv</strong></em>   模型数据， 数据类型为gensim.models.keyedvectors.KeyedVectors。</li>
<li><em><strong>words</strong></em>、<em><strong>c_words2</strong></em>、<em><strong>c_words2</strong></em> 均为词语列表</li>
</ul>
<p>为了解释词向量模型的语义投影，我使用了 2022 年 Nature 论文中的图片[@Grand2022SemanticPR]。 关于动物的名字，人类对动物大小的认知信息隐藏在语料库文本中。 通过将<strong>LARGE WORDS</strong> 和<strong>SMALL WORDS</strong>的含义用不同的<strong>animals</strong>的向量投影，动物在<strong>size向量</strong>上的投影（就像下图中的红线 ) 得到，因此可以通过计算比较动物的大小。</p>
<p>根据两组反义词 <em><strong>c_words1</strong></em> ,    <em><strong>c_words2</strong></em> 构建一个概念(认知)向量, words中的每个词向量在概念向量中投影，即可得到认知信息。</p>
<p>分值越大，<em><strong>words</strong></em> 越位于 <em><strong>c_words2</strong></em> 一侧。</p>
<blockquote>
<p>Grand, G., Blank, I.A., Pereira, F. and Fedorenko, E., 2022. Semantic projection recovers rich human knowledge of multiple object features from word embeddings. <em>Nature Human Behaviour</em>, pp.1-13.&quot;</p>
</blockquote>
<p><img loading="lazy" src="img/22-semantic_projection.png" alt=""  />
</p>
<p>例如，人类的语言中，存在尺寸、性别、年龄、政治、速度、财富等不同的概念。每个概念可以由两组反义词确定概念的向量方向。</p>
<p>以尺寸为例，动物在人类认知中可能存在体积尺寸大小差异。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">animals</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;mouse&#39;</span><span class="p">,</span> <span class="s1">&#39;cat&#39;</span><span class="p">,</span> <span class="s1">&#39;horse&#39;</span><span class="p">,</span>  <span class="s1">&#39;pig&#39;</span><span class="p">,</span> <span class="s1">&#39;whale&#39;</span><span class="p">]</span>
<span class="n">small_words</span><span class="o">=</span> <span class="p">[</span><span class="s2">&#34;small&#34;</span><span class="p">,</span> <span class="s2">&#34;little&#34;</span><span class="p">,</span> <span class="s2">&#34;tiny&#34;</span><span class="p">]</span>
<span class="n">large_words</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&#34;large&#34;</span><span class="p">,</span> <span class="s2">&#34;big&#34;</span><span class="p">,</span> <span class="s2">&#34;huge&#34;</span><span class="p">]</span>

<span class="c1">#wiki_wv = 导入wiki的模型。</span>
<span class="c1">#wiki_wv</span>

<span class="c1"># In size conception, mouse is smallest, horse is biggest.</span>
<span class="c1"># 在大小概念上，老鼠最小，马是最大的。</span>
<span class="n">ct</span><span class="o">.</span><span class="n">sematic_projection</span><span class="p">(</span><span class="n">wv</span><span class="o">=</span><span class="n">wiki_wv</span><span class="p">,</span>
                      <span class="n">words</span><span class="o">=</span><span class="n">animals</span><span class="p">,</span> 
                      <span class="n">c_words1</span><span class="o">=</span><span class="n">small_words</span><span class="p">,</span> 
                      <span class="n">c_words2</span><span class="o">=</span><span class="n">large_words</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">[(&#39;mouse&#39;, -1.68),
 (&#39;cat&#39;, -0.92),
 (&#39;pig&#39;, -0.46),
 (&#39;whale&#39;, -0.24),
 (&#39;horse&#39;, 0.4)]
</code></pre></div><p>关于尺寸的认知，人类在文本中隐含着老鼠较小，马较大。</p>
<br>
<h3 id="53-divergent_association_task">5.3 divergent_association_task()</h3>
<p><a href="https://textdata.cn/blog/2022-11-14-pnas_naming_unrelated_words_predicts_creativity/">PNAS | 使用语义距离测量一个人的创新力(发散思维)得分</a>。一些理论认为，有 创造力 的人能够产生更多 发散性 的想法。如果这是正确的，简单地让被试写 N 个不相关的单词，然后测量这N个词的语义距离， 作为发散思维的客观衡量标准。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">ct.divergent_association_task(wv, words)
</code></pre></div><ul>
<li><em><strong>wv</strong></em>   模型数据， 数据类型为 gensim.models.keyedvectors.KeyedVectors。</li>
<li><em><strong>words</strong></em>词语列表</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">low_words = [&#34;arm&#34;, &#34;eyes&#34;, &#34;feet&#34;, &#34;hand&#34;, &#34;head&#34;, &#34;leg&#34;, &#34;body&#34;]
average_words = [&#34;bag&#34;, &#34;bee&#34;, &#34;burger&#34;, &#34;feast&#34;, &#34;office&#34;, &#34;shoes&#34;, &#34;tree&#34;]
high_words = [&#34;hippo&#34;, &#34;jumper&#34;, &#34;machinery&#34;, &#34;prickle&#34;, &#34;tickets&#34;, &#34;tomato&#34;, &#34;violin&#34;]

# 导入模型，得到wv。
# wv为gensim.models.keyedvectors.KeyedVectors类型

print(ct.divergent_association_task(wv, low_words)) # 50
print(ct.divergent_association_task(wv, average_words)) # 78
print(ct.divergent_association_task(wv, high_words)) # 95
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">50
78
95
</code></pre></div><br>
<h3 id="54-discursive_diversity_score">5.4 discursive_diversity_score()</h3>
<p><a href="https://textdata.cn/blog/2023-11-02-measure-cognitive-diversity-through-language-discursive-diversity/">MS2022 | 使用语言差异性测量团队认知差异性</a></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">ct.discursive_diversity_score(wv, words)
</code></pre></div><ul>
<li><em><strong>wv</strong></em>   模型数据， 数据类型为 gensim.models.keyedvectors.KeyedVectors。</li>
<li><em><strong>words</strong></em>词语列表</li>
<li>返回一个数值</li>
</ul>
<p><img loading="lazy" src="img/23-low-and-high-examples-of-discursive-diversity.jpeg" alt=""  />
</p>
<p>高绩效团队是那些具有调节共享认知以适应不断变化的任务要求的集体能力的团队：在进行构思任务时，它们表现出更高的话语多样性，在执行协调任务时，表现出较低的话语多样性。</p>
<br>
<h3 id="55-procrustes_align">5.5 procrustes_align()</h3>
<p>该函数主要用于反映同一研究对象随着时间推进的社会文化变迁，或者同一时间范围内两个被研究主体间的差异。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">ct.procrustes_align(base_wv, other_wv, words=None)
</code></pre></div><ul>
<li>base_wv (gensim.models.keyedvectors.KeyedVectors): 基准语言模型</li>
<li>other_wv (gensim.models.keyedvectors.KeyedVectors): 其他语言模型</li>
<li>words (list, optional): 是否根据词典words对模型进行对齐， 对齐结束后的模型中含有的词不会超出words的范围； 默认None.</li>
</ul>
<p>由于不同语料训练的Word2Vec模型无法直接比较， 需要先选定一个基准模型 <em><strong>base_embed</strong></em>， 之后根据 <em><strong>base_embed</strong></em> 对其他模型 <em><strong>other_embed</strong></em> 进行调整，调整后的模型就可以使用前面的语义距离函数或者语义投影函数。 这一过程用到的算法叫做 procrustes正交算法。</p>
<p>这里推荐一篇 <a href="https://textdata.cn/blog/2023-12-28-visualize-the-culture-change-using-people-daily-dataset/">可视化 | 人民日报语料反映七十年文化演变</a></p>
<p><br><br></p>
<h2 id="六llm模块">六、LLM模块</h2>
<p>目前大模型本地化使用越来越方便，</p>
<table>
<thead>
<tr>
<th>模块</th>
<th>函数(类)</th>
<th>功能</th>
</tr>
</thead>
<tbody>
<tr>
<td><em><strong>LLM</strong></em></td>
<td><em><strong>text_analysis_by_llm(text, prompt, base_url, api_key, model_name, temperature, output_format)</strong></em></td>
<td>使用大模型进行文本分析</td>
</tr>
</tbody>
</table>
<h3 id="61-analysis_by_llm">6.1 analysis_by_llm()</h3>
<p>使用大模型（本地或API）进行文本分析，从非结构化的文本数据中识别模式、提取关键信息、理解语义，并将其转化为结构化数据以便进一步分析和应用。</p>
<br>
<p><em><strong>analysis_by_llm(text, prompt, base_url, api_key, model_name, output_format, max_retries, return_df)</strong></em></p>
<ul>
<li><em><strong>text</strong></em>: 待分析的文本</li>
<li><em><strong>prompt</strong></em> 提示Prompt, 默认 prompt=&ldquo;根据评论内容，返回文本的情感类别(pos、neg)&rdquo;, 可判断文本pos或neg</li>
<li><em><strong>base_url</strong></em>: 大模型API接口， 默认base_url=''， 默认使用的本地Ollama搭建服务的API接口；</li>
<li><em><strong>api_key</strong></em>: 大模型API对应的KEY， 默认api_key='' 表示使用的本地Ollama搭建服务</li>
<li><em><strong>model_name</strong></em>: 模型名；默认使用 model_name=&ldquo;qwen2.5:3b&rdquo;</li>
<li><em><strong>temperature</strong></em>:  控制模型输出结果的随机性，取值范围0到无穷, 常用的范围[0, 1]。虽然理论上可以设置大于 1 的值，但这样会导致输出过于随机，通常不推荐这样做。需要结合任务确定取值
<ul>
<li>高准确性一致性任务，如情感分析、文本分类、事实性回答， 建议temperature=0</li>
<li>高创造性和多样性任务， 如故事写作、头脑风暴等， 建议temperature=0.7</li>
<li>实验性或探索性任务，较高的 <code>temperature</code> 值（如 1.0 以上，但一般不推荐超过 2.0）</li>
</ul>
</li>
<li><em><strong>output_format</strong></em>: 设置分析结果的输出格式; 默认output_format = {&lsquo;label&rsquo;: str, &lsquo;score&rsquo;: float},   输出结果为字典， 含字段类别字段label和数值字段score</li>
<li><em><strong>max_retries</strong></em>: 最大失败次数， 默认max_retries=3</li>
<li><em><strong>return_df</strong></em>: 返回结果是否为dataframe， 默认False</li>
</ul>
<br>
<p><strong>实验数据为外卖评论， 今天咱们做个有难度的文本分析任务，从不同维度(味道、速度、服务)对外卖评论进行打分(-1.0~1.0)</strong>。</p>
<p><img loading="lazy" src="img/28-llm-analysis.png" alt=""  />
<br></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>

<span class="n">PROMPT</span> <span class="o">=</span> <span class="s1">&#39;从口味taste、速度speed、服务service三个维度， 对外卖评论内容进行文本分析， 分别返回不同维度的分值(分值范围-1.0 ~ 1.0)&#39;</span>
<span class="n">BASE_URL</span> <span class="o">=</span> <span class="s1">&#39;https://dashscope.aliyuncs.com/compatible-mode/v1&#39;</span>
<span class="n">API_KEY</span> <span class="o">=</span> <span class="s1">&#39;你的API-KEY&#39;</span>
<span class="n">MODEL_NAME</span> <span class="o">=</span> <span class="s1">&#39;qwen-max&#39;</span>

<span class="c1">#味道、速度、服务</span>
<span class="n">OUTPUT_FORMAT</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;taste&#39;</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="s1">&#39;speed&#39;</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="s1">&#39;service&#39;</span><span class="p">:</span> <span class="nb">float</span><span class="p">}</span>

<span class="n">COMMENT_CONTENT</span> <span class="o">=</span> <span class="s1">&#39;太难吃了&#39;</span>

<span class="c1">#使用</span>
<span class="c1">#result = ct.analysis_by_llm(text=COMMENT_CONTENT, </span>
<span class="c1">#或</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">text_analysis_by_llm</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="n">COMMENT_CONTENT</span><span class="p">,</span> 
                                 <span class="n">prompt</span><span class="o">=</span><span class="n">PROMPT</span><span class="p">,</span>
                                 <span class="n">base_url</span><span class="o">=</span><span class="n">BASE_URL</span><span class="p">,</span> 
                                 <span class="n">api_key</span><span class="o">=</span><span class="n">API_KEY</span><span class="p">,</span> 
                                 <span class="n">model_name</span><span class="o">=</span><span class="n">MODEL_NAME</span><span class="p">,</span> 
                                 <span class="n">temperature</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                                 <span class="n">output_format</span><span class="o">=</span><span class="n">OUTPUT_FORMAT</span><span class="p">,</span> 
                                 <span class="n">max_retries</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>  
                                 <span class="n">return_df</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">result</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">{&#39;taste&#39;: -1.0, &#39;speed&#39;: 0.0, &#39;service&#39;: 0.0}
</code></pre></div><br>
<p>批量运算</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">import pandas as pd
import cntext as ct


#构造实验数据
data = [&#39;速度非常快，口味非常好， 服务非常棒！&#39;, 
        &#39;送餐时间还是比较久&#39;,
        &#39;送单很快，菜也不错赞&#39;,
        &#39;太难吃了&#39;]
df = pd.DataFrame(data, columns=[&#39;comment&#39;])


#分析函数
def llm_analysis(text):
    result = ct.analysis_by_llm(text=text, 
                                prompt= &#39;从口味taste、速度speed、服务service三个维度， 对外卖评论内容进行文本分析， 分别返回不同维度的分值(分值范围-1.0 ~ 1.0)&#39;,
                                base_url=&#39;https://dashscope.aliyuncs.com/compatible-mode/v1&#39;, 
                                api_key=&#39;你的API-KEY&#39;, 
                                model_name=&#39;qwen-max&#39;, 
                                output_format={&#39;taste&#39;: float, &#39;speed&#39;: float, &#39;service&#39;: float}
                               )
    return pd.Series(result)
    

#批量运算
df2 = df[&#39;comment&#39;].apply(llm_analysis)
res_df = pd.concat([df, df2], axis=1)
#保存分析结果
res_df.to_csv(&#39;result.csv&#39;, index=False)
res_df
</code></pre></div><p><img loading="lazy" src="img/28-llm-analysis.png" alt=""  />
</p>
<br>
<p>LLM更多详细内容，请阅读  <a href="https://textdata.cn/blog/2025-02-14-using-online-large-model-api-to-transform-text-data-into-structured-data/"><strong>教程 | 使用在线大模型将文本数据转化为结构化数据</strong></a></p>
<p><br><br></p>
<h2 id="获取cntext2x">获取cntext2.x</h2>
<p>加大邓 <em><strong>WeChat: 372335839</strong></em>， 备注「姓名-学校-专业」， 100元领取  <em><strong>cntext-2.1.4-py3-none-any.whl</strong></em> 文件。本文出现的cntext，默认均为2.x版本。</p>
<p><br><br></p>
<h2 id="使用声明">使用声明</h2>
<p>如果再研究或项目中使用到 <strong>cntext</strong> ，请声明出处。</p>
<h3 id="apalike">apalike</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">Deng X., Nan P. (2022). cntext: a Python tool for text mining. DOI: 10.5281/zenodo.7063523 URL: https://github.com/hiDaDeng/cntext
</code></pre></div><h3 id="bibtex">bibtex</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">@misc{YourReferenceHere,
author = {Deng, Xudong and Nan, Peng},
doi = {10.5281/zenodo.7063523},
month = {9},
title = {cntext: a Python tool for text mining},
url = {https://github.com/hiDaDeng/cntext},
year = {2022}
}
</code></pre></div><h3 id="endnote">endnote</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">%0 Generic
%A Deng, Xudong
%A Nan, Peng
%D 2022
%K text mining
%K text analysi
%K social science
%K management science
%K semantic analysis
%R 10.5281/zenodo.7063523
%T cntext: a Python tool for text mining
%U https://github.com/hiDaDeng/cntext
</code></pre></div><p><br><br></p>
]]></content:encoded>
    </item>
    
    <item>
      <title>ANCW | 4030词的中文情感词典(效价、唤醒度、主导度、具体性)</title>
      <link>https://textdata.cn/blog/2024-02-27-ancw-affective-norms-for-4030-chinese-words/</link>
      <pubDate>Tue, 27 Feb 2024 00:00:00 +0000</pubDate>
      
      <guid>/blog/2024-02-27-ancw-affective-norms-for-4030-chinese-words/</guid>
      <description>&lt;p&gt;Ying, Lv, Ye Ruyang, Ni Chuanbin, Wang Yeqing, Liu Qing, Zhou Yufan, and Gao Fei. &amp;ldquo;ANCW: Affective norms for 4030 Chinese words.&amp;rdquo; &lt;em&gt;Behavior Research Methods&lt;/em&gt; (2023): 1-16.&lt;/p&gt;
&lt;br&gt;
&lt;br&gt;
&lt;h2 id=&#34;一摘要&#34;&gt;一、摘要&lt;/h2&gt;
&lt;p&gt;单词中包含的情感信息越来越受到世界各地神经语言学家和心理语言学家的关注。本研究建立了情感词典ANCW(Affective Norms for Chinese Words)，对 4030 个词语进行了&lt;strong&gt;效价valence&lt;/strong&gt;、&lt;strong&gt;唤醒度arousal&lt;/strong&gt;、&lt;strong&gt;主导度dominance&lt;/strong&gt;和&lt;strong&gt;具体性concreteness&lt;/strong&gt; 打分，这些词语是根据 CET-4（国家大学英语四级考试）官方大纲进行中文改编的。尽管现有的中文情感词典CAWS(Chinese Affective Words System)，ANCW 提供了更多、更丰富的中文词汇。通过在程序中使用 7 级李克特量表（范围从 1 到 7），我们获得了 3717 名中国本科生对所有变量的评分。词典ANCW具有良好的响应信度，并且与中文先前的规范研究相兼容。成对相关分析揭示了效价与唤醒、唤醒与支配性以及效价与具体性之间的二次关系。此外，效价和支配性、唤醒性和具体性均呈现线性相关，具体性和支配性相关。ANCW 为涉及情感语言处理的进一步研究提供可靠且标准化的刺激材料。&lt;/p&gt;
&lt;br&gt;
&lt;br&gt;
&lt;h2 id=&#34;二文献梳理&#34;&gt;二、文献梳理&lt;/h2&gt;
&lt;p&gt;语言和情感是人类生活不可分割的一部分。在过去的二十年里，词语的情感评级受到了极大的关注。研究人员建立了许多标准化数据库，从不同维度对不同语言的单词进行评级。传统上，情感的概念是情感观，被视为多个维度的连续体（Ćoso et al., 2019；Rubin &amp;amp; Talarico, 2009），所有情感都具有两个或三个维度的特征（Duffy, 1934)；奥斯古德等人，1957）。根据卡罗尔、奥斯古德、苏西和坦南鲍姆（ 1959）的情感理论，对词语进行了大量的情感评级，&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;效价valence&lt;/strong&gt; 是指令人愉快的程度，范围从不愉快到愉快；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;唤醒度arousal&lt;/strong&gt; 是生理激活程度的指标，范围从平静到兴奋；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;支配性dominance&lt;/strong&gt; 描述了个人所感受到的控制程度，从失控到受控。近年来，心理语言学变量具体性的研究引起了人们的浓厚兴趣。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;根据 Gilhooly 和 Logie（1980）的观点，&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;具体性concreteness&lt;/strong&gt; 代表了形成单词心理形象的难度程度，范围从抽象（难以形成）到具体（易于形成）。&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
&lt;p&gt;构建具有单词情感评级的数据库的需求很大，因为它们至少有助于四个方面的研究，包括针对情绪本身的研究、情绪特征对单词处理和记忆的影响、整个消息表达的情绪或文本，以及通过将新词与已验证词进行比较来了解新词的情感价值（有关评论，请参阅 Warriner 等人，2013 年）。到目前为止，已经用多种语言构建了各种数据库，并为进一步的研究提供了丰富的刺激和可靠测量的情绪特征。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/01-old-dicts.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;p&gt;从上述文献中，我们可以看到针对不同语言建立了各种各样的包含情感评级的数据库，以满足日益增长的情感研究需求。然而，据我们所知，该领域还存在一些有待进一步研究的地方：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;大多数数据库是由西方国家建立的，并且已经证实，一些研究发现情感评级因文化而异。因此，建立中国本土情感规范数据库迫在眉睫。&lt;/li&gt;
&lt;li&gt;国内以往的研究在制定标准化的情绪刺激上付出了很大的努力，并且使用了多样化的刺激。在这些刺激中，言语刺激可以得到更严格的控制，并且与其他刺激具有可比性，例如需要在复杂性、亮度、颜色和对比度上进行控制的图片(Soares et al., 2012 &lt;a href=&#34;https://link.springer.com/article/10.3758/s13428-023-02226-x#ref-CR60&#34;&gt;)&lt;/a&gt;。&lt;/li&gt;
&lt;li&gt;最重要的是，以往的研究限制了汉字的数量。例如，AANC（Liu et al., 2021）由四个汉字单词组成，而Yao等人建立的另一个数据库则由四个汉字组成。( 2016)仅包含两个字符的单词。众所周知，汉字非常复杂。例如，一个汉字可以组成一个词，如“书”、“美”、“杀”。两个或多个汉字也可以组成一个词，如“生活”、“白日梦”、“色彩斑美丽”。特别是，日常使用的词语非常灵活，不仅限于二字词或四字词。在这种情况下，汉字数量的限制在一定程度上限制了表达的丰富性和灵活性。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;鉴于这些局限性，本研究旨在建立一个标准化、多维、不限制字数的汉语词语情感规范数据库。此外，本研究将采用多种方法检验ANCW的可靠性，为进一步研究情感和心理语言变量之间的关系提供更多证据。总体而言，本研究在一定程度上弥补了上述局限性。&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;三-方法&#34;&gt;三、 方法&lt;/h2&gt;
&lt;h3 id=&#34;31-参与者&#34;&gt;3.1 参与者&lt;/h3&gt;
&lt;p&gt;共有 3717 名母语为中文的人参与了这项研究。所有参与者均为中国 41 所大学除英语专业以外的其他专业本科生（女性 2346 名，男性 1258 名，无性别信息 113 名；M年龄= 19.91，范围 16-25，SD = 1.21）。&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;32-确定词语列表&#34;&gt;3.2 确定词语列表&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;从英语四级CET-4的教学大纲中找出4030个英语单词&lt;/strong&gt;，大学英语四级大纲中的词汇出现频率较高，且与学员的日常生活密切相关。&lt;/p&gt;
&lt;p&gt;翻译经过三道严格的程序完成。第一轮翻译依据的是牛津高阶英汉词典（第9版 *）*和英国国家语料库（BNC）。该研究采用《牛津高级英汉词典（第9版 *）》*中的首个中文释义，将词表翻译成中文。有些词有多个词性。例如，“stem”可以是名词和动词。名词“茎”的意思是“植物在地面上长出叶子或花朵的主要长而薄的部分；从中生长出来并支撑花朵或叶子的较小部分”（Stem，2018），动词的意思是“阻止某些正在流动或增加的东西”（Stem，2018）。在本例中，我们根据英国国家语料库选择了词频较高的词性。在此过程之后，研究发现了 672 个单词的一致翻译。&lt;/p&gt;
&lt;p&gt;在第二个翻译阶段，本研究采用了德尔菲法。我们邀请了五位精通英语文化和中国文化的专业翻译人员来进行这项工作。翻译过程中，五位专业人士未经讨论就翻译了这672个一致词。然后，研究对他们的翻译进行了比较，并找出了五位译者意见不一致的词语。经过四轮匿名讨论，我们获得了唯一不重复的汉译本553个单词。&lt;/p&gt;
&lt;p&gt;经过这一步，剩下了 186 个与中文翻译一致的单词。为了确保每个翻译不重复，研究在中文翻译后标记了原始英文单词或该单词的词性。最终获得了英语四级英语单词大纲的翻译版，包含4030个中文单词。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;我们将 4030 个中文单词的列表随机分为 20 个子列表，每个子列表包含 201 或 202 个单词。根据该研究的设计，每个单词的每个维度（唤醒度、效价、支配性和具体性）都会被评估至少 45 次。&lt;/strong&gt;&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;33-设计问卷&#34;&gt;3.3 设计问卷&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;每份试卷均包含一个信息部分、说明和评分表。本研究采用7点李克特自评量表进行打分&lt;/strong&gt;。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;效价描述了刺激引起愉悦感的程度（Russell，1980；Bradley &amp;amp; Lang，1999）。数字1表示非常不愉快，4表示一般，7表示非常愉快。&lt;/li&gt;
&lt;li&gt;唤醒，也称为激活、强度或能量水平（Montefinese 等，2014），用于描述身体被激活或唤醒的程度（Duffy，1934）。该研究用1表示极度平静，4表示中性，7表示极度兴奋。&lt;/li&gt;
&lt;li&gt;支配性被定义为个体对刺激的控制或影响程度，范围从完全失控到完全控制（Russell &amp;amp; Mehrabian，1977）。研究用1代表受试者感觉自己完全被这个词控制（这个词是“盛行”），4代表中立，7代表受试者感觉能够完全控制这个词（这个词是“弱”）。 ”）。&lt;/li&gt;
&lt;li&gt;具体性是指形成单词物理所指的心理图像的困难程度。该研究使用1表示极端抽象，4表示中性，7表示极端具体。&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
&lt;h3 id=&#34;34-步骤&#34;&gt;3.4 步骤&lt;/h3&gt;
&lt;p&gt;本研究采用&lt;strong&gt;纸笔评分法&lt;/strong&gt;(paper-pencil rating method) 。每个参与者随机收到一个单词子列表。在试卷的第一页，该研究为每个维度（效价、唤醒度、支配性和具体性）提供了清晰的中文说明和生动的例子。参与者收到试卷后，研究口头提供了清晰的说明解释。试卷的第二页和第三页是A4纸上打印的中文单词和等级量表。每个参与者在安静的教室里对一张试卷进行评分。由于所有单词都是汉语，而且四级单词在社会生活中广泛使用，因此没有参与者对单词的含义有疑问。&lt;/p&gt;
&lt;p&gt;鉴于之前的研究（谢，2020；张，2020），数据修剪规则如下所示，如果试卷满足其中一条规则，则将被视为无效。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;70%以上的评级结果缺失；&lt;/li&gt;
&lt;li&gt;70%以上的评级结果相同；&lt;/li&gt;
&lt;li&gt;试卷表现出明显的敌意。例如，一些参与者在试卷上留下侮辱性的评论，例如“我只是随意圈出数字来欺骗你们，傻瓜”。&lt;/li&gt;
&lt;li&gt;此外，答案是在一系列之字形中随机选择的。在这种情况下，调查问卷将被视为敌对调查问卷。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;最终我们共收集到3304份试卷。在所有试卷中，效价评分为 858 份，唤醒评分为 803 份，支配性评分为 777 份，具体性评分为 866 份。每个维度中的几个缺失评级均由平均值代替。删除无效数据后的最终数据库共包含4030个单词，每个单词的效价评分为42.9，唤醒评分为40.2，具体性评分为43.3，支配性评分为38.9。&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;四ancw词典&#34;&gt;四、ANCW词典&lt;/h2&gt;
&lt;p&gt;ancw下载链接:https://pan.baidu.com/s/1UfbmVQh9XM77eoGmMsZ2-w?pwd=bp63  提取码:bp63&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/02-ancw.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/03-ancw.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;相关文献&#34;&gt;相关文献&lt;/h2&gt;
&lt;p&gt;Xu, X., Li, J., &amp;amp; Chen, H. (2021). Valence and arousal ratings for 11,310 simplified Chinese words. &lt;em&gt;Behavior Research Methods, 54&lt;/em&gt;(1), 26–41. &lt;a href=&#34;https://doi.org/10.3758/s13428-021-01607-4&#34;&gt;https://doi.org/10.3758/s13428-021-01607-4&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Yao, Z., Wu, J., Zhang, Y., &amp;amp; Wang, Z. (2016). Norms of valence, arousal, concreteness, familiarity, imageability, and context availability for 1,100 Chinese words. &lt;em&gt;Behavior Research Methods, 49&lt;/em&gt;(4), 1374–1385. &lt;a href=&#34;https://doi.org/10.3758/s13428-016-0793-2&#34;&gt;https://doi.org/10.3758/s13428-016-0793-2&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Yuan, J., Zhang, Y., Chen, S., Luo, L., &amp;amp; Ru, Y. (2021). The establishment of Chinese Emotion Regulation Word System (CERWS) and its pilot test. &lt;em&gt;Acta Psychologica Sinica, 53&lt;/em&gt;(&lt;em&gt;5&lt;/em&gt;), 445. &lt;a href=&#34;https://doi.org/10.3724/sp.j.1041.2021.00445&#34;&gt;https://doi.org/10.3724/sp.j.1041.2021.00445&lt;/a&gt;&lt;/p&gt;
&lt;br&gt;
&lt;br&gt;
</description>
      <content:encoded><![CDATA[<p>Ying, Lv, Ye Ruyang, Ni Chuanbin, Wang Yeqing, Liu Qing, Zhou Yufan, and Gao Fei. &ldquo;ANCW: Affective norms for 4030 Chinese words.&rdquo; <em>Behavior Research Methods</em> (2023): 1-16.</p>
<br>
<br>
<h2 id="一摘要">一、摘要</h2>
<p>单词中包含的情感信息越来越受到世界各地神经语言学家和心理语言学家的关注。本研究建立了情感词典ANCW(Affective Norms for Chinese Words)，对 4030 个词语进行了<strong>效价valence</strong>、<strong>唤醒度arousal</strong>、<strong>主导度dominance</strong>和<strong>具体性concreteness</strong> 打分，这些词语是根据 CET-4（国家大学英语四级考试）官方大纲进行中文改编的。尽管现有的中文情感词典CAWS(Chinese Affective Words System)，ANCW 提供了更多、更丰富的中文词汇。通过在程序中使用 7 级李克特量表（范围从 1 到 7），我们获得了 3717 名中国本科生对所有变量的评分。词典ANCW具有良好的响应信度，并且与中文先前的规范研究相兼容。成对相关分析揭示了效价与唤醒、唤醒与支配性以及效价与具体性之间的二次关系。此外，效价和支配性、唤醒性和具体性均呈现线性相关，具体性和支配性相关。ANCW 为涉及情感语言处理的进一步研究提供可靠且标准化的刺激材料。</p>
<br>
<br>
<h2 id="二文献梳理">二、文献梳理</h2>
<p>语言和情感是人类生活不可分割的一部分。在过去的二十年里，词语的情感评级受到了极大的关注。研究人员建立了许多标准化数据库，从不同维度对不同语言的单词进行评级。传统上，情感的概念是情感观，被视为多个维度的连续体（Ćoso et al., 2019；Rubin &amp; Talarico, 2009），所有情感都具有两个或三个维度的特征（Duffy, 1934)；奥斯古德等人，1957）。根据卡罗尔、奥斯古德、苏西和坦南鲍姆（ 1959）的情感理论，对词语进行了大量的情感评级，</p>
<ul>
<li><strong>效价valence</strong> 是指令人愉快的程度，范围从不愉快到愉快；</li>
<li><strong>唤醒度arousal</strong> 是生理激活程度的指标，范围从平静到兴奋；</li>
<li><strong>支配性dominance</strong> 描述了个人所感受到的控制程度，从失控到受控。近年来，心理语言学变量具体性的研究引起了人们的浓厚兴趣。</li>
</ul>
<p>根据 Gilhooly 和 Logie（1980）的观点，</p>
<ul>
<li><strong>具体性concreteness</strong> 代表了形成单词心理形象的难度程度，范围从抽象（难以形成）到具体（易于形成）。</li>
</ul>
<br>
<p>构建具有单词情感评级的数据库的需求很大，因为它们至少有助于四个方面的研究，包括针对情绪本身的研究、情绪特征对单词处理和记忆的影响、整个消息表达的情绪或文本，以及通过将新词与已验证词进行比较来了解新词的情感价值（有关评论，请参阅 Warriner 等人，2013 年）。到目前为止，已经用多种语言构建了各种数据库，并为进一步的研究提供了丰富的刺激和可靠测量的情绪特征。</p>
<p><img loading="lazy" src="img/01-old-dicts.png" alt=""  />
</p>
<br>
<p>从上述文献中，我们可以看到针对不同语言建立了各种各样的包含情感评级的数据库，以满足日益增长的情感研究需求。然而，据我们所知，该领域还存在一些有待进一步研究的地方：</p>
<ul>
<li>大多数数据库是由西方国家建立的，并且已经证实，一些研究发现情感评级因文化而异。因此，建立中国本土情感规范数据库迫在眉睫。</li>
<li>国内以往的研究在制定标准化的情绪刺激上付出了很大的努力，并且使用了多样化的刺激。在这些刺激中，言语刺激可以得到更严格的控制，并且与其他刺激具有可比性，例如需要在复杂性、亮度、颜色和对比度上进行控制的图片(Soares et al., 2012 <a href="https://link.springer.com/article/10.3758/s13428-023-02226-x#ref-CR60">)</a>。</li>
<li>最重要的是，以往的研究限制了汉字的数量。例如，AANC（Liu et al., 2021）由四个汉字单词组成，而Yao等人建立的另一个数据库则由四个汉字组成。( 2016)仅包含两个字符的单词。众所周知，汉字非常复杂。例如，一个汉字可以组成一个词，如“书”、“美”、“杀”。两个或多个汉字也可以组成一个词，如“生活”、“白日梦”、“色彩斑美丽”。特别是，日常使用的词语非常灵活，不仅限于二字词或四字词。在这种情况下，汉字数量的限制在一定程度上限制了表达的丰富性和灵活性。</li>
</ul>
<p>鉴于这些局限性，本研究旨在建立一个标准化、多维、不限制字数的汉语词语情感规范数据库。此外，本研究将采用多种方法检验ANCW的可靠性，为进一步研究情感和心理语言变量之间的关系提供更多证据。总体而言，本研究在一定程度上弥补了上述局限性。</p>
<p><br><br></p>
<h2 id="三-方法">三、 方法</h2>
<h3 id="31-参与者">3.1 参与者</h3>
<p>共有 3717 名母语为中文的人参与了这项研究。所有参与者均为中国 41 所大学除英语专业以外的其他专业本科生（女性 2346 名，男性 1258 名，无性别信息 113 名；M年龄= 19.91，范围 16-25，SD = 1.21）。</p>
<br>
<h3 id="32-确定词语列表">3.2 确定词语列表</h3>
<p><strong>从英语四级CET-4的教学大纲中找出4030个英语单词</strong>，大学英语四级大纲中的词汇出现频率较高，且与学员的日常生活密切相关。</p>
<p>翻译经过三道严格的程序完成。第一轮翻译依据的是牛津高阶英汉词典（第9版 *）*和英国国家语料库（BNC）。该研究采用《牛津高级英汉词典（第9版 *）》*中的首个中文释义，将词表翻译成中文。有些词有多个词性。例如，“stem”可以是名词和动词。名词“茎”的意思是“植物在地面上长出叶子或花朵的主要长而薄的部分；从中生长出来并支撑花朵或叶子的较小部分”（Stem，2018），动词的意思是“阻止某些正在流动或增加的东西”（Stem，2018）。在本例中，我们根据英国国家语料库选择了词频较高的词性。在此过程之后，研究发现了 672 个单词的一致翻译。</p>
<p>在第二个翻译阶段，本研究采用了德尔菲法。我们邀请了五位精通英语文化和中国文化的专业翻译人员来进行这项工作。翻译过程中，五位专业人士未经讨论就翻译了这672个一致词。然后，研究对他们的翻译进行了比较，并找出了五位译者意见不一致的词语。经过四轮匿名讨论，我们获得了唯一不重复的汉译本553个单词。</p>
<p>经过这一步，剩下了 186 个与中文翻译一致的单词。为了确保每个翻译不重复，研究在中文翻译后标记了原始英文单词或该单词的词性。最终获得了英语四级英语单词大纲的翻译版，包含4030个中文单词。</p>
<p><strong>我们将 4030 个中文单词的列表随机分为 20 个子列表，每个子列表包含 201 或 202 个单词。根据该研究的设计，每个单词的每个维度（唤醒度、效价、支配性和具体性）都会被评估至少 45 次。</strong></p>
<br>
<h3 id="33-设计问卷">3.3 设计问卷</h3>
<p><strong>每份试卷均包含一个信息部分、说明和评分表。本研究采用7点李克特自评量表进行打分</strong>。</p>
<ul>
<li>效价描述了刺激引起愉悦感的程度（Russell，1980；Bradley &amp; Lang，1999）。数字1表示非常不愉快，4表示一般，7表示非常愉快。</li>
<li>唤醒，也称为激活、强度或能量水平（Montefinese 等，2014），用于描述身体被激活或唤醒的程度（Duffy，1934）。该研究用1表示极度平静，4表示中性，7表示极度兴奋。</li>
<li>支配性被定义为个体对刺激的控制或影响程度，范围从完全失控到完全控制（Russell &amp; Mehrabian，1977）。研究用1代表受试者感觉自己完全被这个词控制（这个词是“盛行”），4代表中立，7代表受试者感觉能够完全控制这个词（这个词是“弱”）。 ”）。</li>
<li>具体性是指形成单词物理所指的心理图像的困难程度。该研究使用1表示极端抽象，4表示中性，7表示极端具体。</li>
</ul>
<br>
<h3 id="34-步骤">3.4 步骤</h3>
<p>本研究采用<strong>纸笔评分法</strong>(paper-pencil rating method) 。每个参与者随机收到一个单词子列表。在试卷的第一页，该研究为每个维度（效价、唤醒度、支配性和具体性）提供了清晰的中文说明和生动的例子。参与者收到试卷后，研究口头提供了清晰的说明解释。试卷的第二页和第三页是A4纸上打印的中文单词和等级量表。每个参与者在安静的教室里对一张试卷进行评分。由于所有单词都是汉语，而且四级单词在社会生活中广泛使用，因此没有参与者对单词的含义有疑问。</p>
<p>鉴于之前的研究（谢，2020；张，2020），数据修剪规则如下所示，如果试卷满足其中一条规则，则将被视为无效。</p>
<ul>
<li>70%以上的评级结果缺失；</li>
<li>70%以上的评级结果相同；</li>
<li>试卷表现出明显的敌意。例如，一些参与者在试卷上留下侮辱性的评论，例如“我只是随意圈出数字来欺骗你们，傻瓜”。</li>
<li>此外，答案是在一系列之字形中随机选择的。在这种情况下，调查问卷将被视为敌对调查问卷。</li>
</ul>
<p>最终我们共收集到3304份试卷。在所有试卷中，效价评分为 858 份，唤醒评分为 803 份，支配性评分为 777 份，具体性评分为 866 份。每个维度中的几个缺失评级均由平均值代替。删除无效数据后的最终数据库共包含4030个单词，每个单词的效价评分为42.9，唤醒评分为40.2，具体性评分为43.3，支配性评分为38.9。</p>
<p><br><br></p>
<h2 id="四ancw词典">四、ANCW词典</h2>
<p>ancw下载链接:https://pan.baidu.com/s/1UfbmVQh9XM77eoGmMsZ2-w?pwd=bp63  提取码:bp63</p>
<p><img loading="lazy" src="img/02-ancw.png" alt=""  />
</p>
<p><img loading="lazy" src="img/03-ancw.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="相关文献">相关文献</h2>
<p>Xu, X., Li, J., &amp; Chen, H. (2021). Valence and arousal ratings for 11,310 simplified Chinese words. <em>Behavior Research Methods, 54</em>(1), 26–41. <a href="https://doi.org/10.3758/s13428-021-01607-4">https://doi.org/10.3758/s13428-021-01607-4</a></p>
<p>Yao, Z., Wu, J., Zhang, Y., &amp; Wang, Z. (2016). Norms of valence, arousal, concreteness, familiarity, imageability, and context availability for 1,100 Chinese words. <em>Behavior Research Methods, 49</em>(4), 1374–1385. <a href="https://doi.org/10.3758/s13428-016-0793-2">https://doi.org/10.3758/s13428-016-0793-2</a></p>
<p>Yuan, J., Zhang, Y., Chen, S., Luo, L., &amp; Ru, Y. (2021). The establishment of Chinese Emotion Regulation Word System (CERWS) and its pilot test. <em>Acta Psychologica Sinica, 53</em>(<em>5</em>), 445. <a href="https://doi.org/10.3724/sp.j.1041.2021.00445">https://doi.org/10.3724/sp.j.1041.2021.00445</a></p>
<br>
<br>
]]></content:encoded>
    </item>
    
    <item>
      <title>可视化 | 使用umap对200维词向量的进行降维和可视化</title>
      <link>https://textdata.cn/blog/2024-01-23-umap/</link>
      <pubDate>Tue, 23 Jan 2024 00:00:00 +0000</pubDate>
      
      <guid>/blog/2024-01-23-umap/</guid>
      <description>&lt;h2 id=&#34;一介绍&#34;&gt;一、介绍&lt;/h2&gt;
&lt;p&gt;UMAP（Uniform Manifold Approximation and Projection for Dimension Reduction）是一种非线性降维技术，类似于t-SNE、PCA，可用于可视化。在降维应用中， 相比于t-SNE，umap既快又准。&lt;/p&gt;
&lt;p&gt;如果对 UMAP算法感兴趣，可以阅读论文&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;McInnes, L, Healy, J, UMAP: Uniform Manifold Approximation and Projection for Dimension Reduction, ArXiv &lt;a href=&#34;https://www.zhihu.com/search?q=e-prints&amp;amp;search_source=Entity&amp;amp;hybrid_search_source=Entity&amp;amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22109584077%22%7D&#34;&gt;e-prints&lt;/a&gt; 1802.03426, 2018&lt;/p&gt;
&lt;/blockquote&gt;
&lt;br&gt;
&lt;br&gt;
&lt;h2 id=&#34;二准备数据&#34;&gt;二、准备数据&lt;/h2&gt;
&lt;h3 id=&#34;21-读取数据&#34;&gt;2.1 读取数据&lt;/h3&gt;
&lt;p&gt;我从 &lt;a href=&#34;https://textdata.cn/blog/2023-12-14-daily-news-dataset/&#34;&gt;&lt;strong&gt;人民日报(1946-2023.12.18)&lt;/strong&gt;&lt;/a&gt; 训练的 word2vec模型 中， 选出了100个词的词向量，构建得到了 &lt;a href=&#34;data.csv.gz&#34;&gt;&lt;strong&gt;data.csv.gz&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;word:  词语，一共有100个&lt;/li&gt;
&lt;li&gt;category: 词语的类别， 一共五种(亲人、环保、研发、国王、数字化)&lt;/li&gt;
&lt;li&gt;f1,f2,f3,&amp;hellip;,f200  词向量的200维（每个词语的词向量是200维的向量）&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pandas&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pd&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read_csv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;data.csv.gz&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;compression&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;gzip&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/01-df.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;22-查看词语对应类别&#34;&gt;2.2 查看词语&amp;amp;对应类别&lt;/h3&gt;
&lt;p&gt;大邓准备了五类词， 每类词20个词， 词语类别按顺序依次是 &lt;strong&gt;亲人、环保、研发、国王、数字&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;word&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;tolist&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;[&amp;#39;爸爸&amp;#39;, &amp;#39;姐姐&amp;#39;, &amp;#39;奶奶&amp;#39;, &amp;#39;女儿&amp;#39;, &amp;#39;外公&amp;#39;, &amp;#39;哥哥&amp;#39;, &amp;#39;儿子&amp;#39;, &amp;#39;祖母&amp;#39;, &amp;#39;父母亲&amp;#39;, &amp;#39;外婆&amp;#39;, &amp;#39;妹妹&amp;#39;, &amp;#39;孙女&amp;#39;, &amp;#39;姥爷&amp;#39;, &amp;#39;小女儿&amp;#39;, &amp;#39;姥姥&amp;#39;, &amp;#39;二姐&amp;#39;, &amp;#39;姑姑&amp;#39;, &amp;#39;弟弟&amp;#39;, &amp;#39;弟弟妹妹&amp;#39;, &amp;#39;爸爸妈妈&amp;#39;, &amp;#39;低碳&amp;#39;, &amp;#39;节能&amp;#39;, &amp;#39;环境保护&amp;#39;, &amp;#39;绿色环保&amp;#39;, &amp;#39;节能降耗&amp;#39;, &amp;#39;环保节能&amp;#39;, &amp;#39;生态环保&amp;#39;, &amp;#39;节能环保&amp;#39;, &amp;#39;节能低碳&amp;#39;, &amp;#39;绿色低碳&amp;#39;, &amp;#39;减排&amp;#39;, &amp;#39;绿色发展&amp;#39;, &amp;#39;保护环境&amp;#39;, &amp;#39;清洁生产&amp;#39;, &amp;#39;建筑节能&amp;#39;, &amp;#39;环境治理&amp;#39;, &amp;#39;减碳&amp;#39;, &amp;#39;循环经济&amp;#39;, &amp;#39;低碳环保&amp;#39;, &amp;#39;治理污染&amp;#39;, &amp;#39;科研开发&amp;#39;, &amp;#39;科技研发&amp;#39;, &amp;#39;科研创新&amp;#39;, &amp;#39;研发创新&amp;#39;, &amp;#39;技术创新&amp;#39;, &amp;#39;技术开发&amp;#39;, &amp;#39;技术研发&amp;#39;, &amp;#39;产品开发&amp;#39;, &amp;#39;产品研发&amp;#39;, &amp;#39;原始创新&amp;#39;, &amp;#39;科技创新&amp;#39;, &amp;#39;研究开发&amp;#39;, &amp;#39;新药研发&amp;#39;, &amp;#39;核心技术研发&amp;#39;, &amp;#39;产学研结合&amp;#39;, &amp;#39;科技开发&amp;#39;, &amp;#39;基础研究&amp;#39;, &amp;#39;新产品开发&amp;#39;, &amp;#39;研发成果&amp;#39;, &amp;#39;科研成果产业化&amp;#39;, &amp;#39;二世&amp;#39;, &amp;#39;王储&amp;#39;, &amp;#39;公主&amp;#39;, &amp;#39;女王&amp;#39;, &amp;#39;王妃&amp;#39;, &amp;#39;陛下&amp;#39;, &amp;#39;王宫&amp;#39;, &amp;#39;王室&amp;#39;, &amp;#39;王室成员&amp;#39;, &amp;#39;皇室成员&amp;#39;, &amp;#39;登基&amp;#39;, &amp;#39;六世&amp;#39;, &amp;#39;继承王位&amp;#39;, &amp;#39;五世&amp;#39;, &amp;#39;摄政王&amp;#39;, &amp;#39;七世&amp;#39;, &amp;#39;英国女王&amp;#39;, &amp;#39;三世&amp;#39;, &amp;#39;四世&amp;#39;, &amp;#39;继位&amp;#39;, &amp;#39;人工智能技术&amp;#39;, &amp;#39;AI&amp;#39;, &amp;#39;数字技术&amp;#39;, &amp;#39;虚拟现实&amp;#39;, &amp;#39;云计算&amp;#39;, &amp;#39;万物互联&amp;#39;, &amp;#39;信息技术&amp;#39;, &amp;#39;语音技术&amp;#39;, &amp;#39;物联网&amp;#39;, &amp;#39;智能硬件&amp;#39;, &amp;#39;5G技术&amp;#39;, &amp;#39;IoT&amp;#39;, &amp;#39;智能应用&amp;#39;, &amp;#39;软件技术&amp;#39;, &amp;#39;融合应用&amp;#39;, &amp;#39;6G&amp;#39;, &amp;#39;人工智能机器人&amp;#39;, &amp;#39;数据应用&amp;#39;, &amp;#39;人工智能应用&amp;#39;, &amp;#39;智能&amp;#39;]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;p&gt;词语对应的类别&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;category&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;tolist&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;())&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;亲人&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;亲人&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;亲人&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;亲人&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;亲人&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;亲人&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;亲人&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;亲人&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;亲人&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;亲人&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;亲人&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;亲人&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;亲人&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;亲人&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;亲人&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;亲人&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;亲人&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;亲人&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;亲人&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;亲人&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;环保&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;环保&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;环保&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;环保&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;环保&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;环保&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;环保&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;环保&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;环保&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;环保&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;环保&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;环保&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;环保&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;环保&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;环保&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;环保&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;环保&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;环保&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;环保&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;环保&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;研发&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;研发&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;研发&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;研发&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;研发&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;研发&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;研发&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;研发&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;研发&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;研发&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;研发&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;研发&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;研发&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;研发&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;研发&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;研发&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;研发&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;研发&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;研发&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;研发&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;国王&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;国王&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;国王&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;国王&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;国王&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;国王&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;国王&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;国王&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;国王&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;国王&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;国王&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;国王&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;国王&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;国王&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;国王&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;国王&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;国王&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;国王&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;国王&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;国王&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;数字化&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;数字化&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;数字化&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;数字化&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;数字化&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;数字化&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;数字化&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;数字化&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;数字化&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;数字化&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;数字化&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;数字化&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;数字化&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;数字化&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;数字化&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;数字化&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;数字化&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;数字化&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;数字化&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;数字化&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;三实验代码&#34;&gt;三、实验代码&lt;/h2&gt;
&lt;h3 id=&#34;31-环境准备&#34;&gt;3.1 环境准备&lt;/h3&gt;
&lt;p&gt;在 &lt;em&gt;&lt;strong&gt;cmd(terminal)&lt;/strong&gt;&lt;/em&gt; 安装本文需要的库&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;pip3 install umap-learn
pip3 install datashader,bokeh,holoviews  #可视化可能会用到的库
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h3 id=&#34;32-降维&#34;&gt;3.2 降维&lt;/h3&gt;
&lt;p&gt;将 100 个词的词向量数据从 200 维压缩到 2 维&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;umap&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;word_emb_redution_data&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;umap&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;UMAP&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;n_neighbors&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;15&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;#默认，不需要理解&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;min_dist&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;0.1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;#默认，不需要理解&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;n_components&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;#2维&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;random_state&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;666&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;#默认， 保证任意时空代码运行结果的随机状态是一致的&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fit&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;iloc&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[:,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:])&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;word_emb_redution_data&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/02-umap.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;33-静态可视化&#34;&gt;3.3 静态可视化&lt;/h3&gt;
&lt;p&gt;绘制静态的图(没有鼠标交互)， 底层应该是调用了 &lt;em&gt;&lt;strong&gt;matplotlib&lt;/strong&gt;&lt;/em&gt; 。 因为实验数据是中文词语， 可视化可能绘乱码。为避免问题， 提前运行代码&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;plt&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;matplotlib&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;matplotlib_inline&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;matplotlib_inline&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;backend_inline&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;set_matplotlib_formats&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;png&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;svg&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;scienceplots&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;platform&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;plt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;style&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;use&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;([&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;science&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;no-latex&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;cjk-sc-font&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;system&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;platform&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;system&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;# 获取操作系统类型&lt;/span&gt;

&lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;system&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;Windows&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;font&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;family&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;SimHei&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;span class=&#34;k&#34;&gt;elif&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;system&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;Darwin&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;font&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;family&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;Arial Unicode MS&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;span class=&#34;k&#34;&gt;else&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;font&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;family&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;sans-serif&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;matplotlib&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;rc&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;font&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;font&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;# 设置全局字体&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;p&gt;绘制 &lt;strong&gt;五类词的词向量投射到2维空间中的可视化&lt;/strong&gt; 的静态图(没有鼠标交互)&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;umap.plot&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;umap&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;plot&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;points&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;word_emb_redution_data&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;labels&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;category&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;width&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;800&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;height&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;500&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;plt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;title&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;五类词的词向量投射到2维空间中的可视化&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/03-plot.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;34-动态交互可视化&#34;&gt;3.4 动态交互可视化&lt;/h3&gt;
&lt;p&gt;umap.plot 内置了bokeh的动态交互功能， 需要先构造鼠标交互悬浮的信息&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;mapper&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;亲人&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;环保&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;研发&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;国王&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;数字化&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;


&lt;span class=&#34;n&#34;&gt;hover_data&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;DataFrame&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;({&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;index&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;index&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                           &lt;span class=&#34;s1&#34;&gt;&amp;#39;item&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;category&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt; 
                           &lt;span class=&#34;s1&#34;&gt;&amp;#39;label&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;category&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;map&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mapper&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)})&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;hover_data&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/04-df.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;p&gt;接下来的代码将会生成一个 html 文件， 因为是动态效果，在博客(公众号)都无法完全显示， 大家如果想查看，可以点击链接下载&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://textdata.cn/blog/2024-01-23-umap/umap_interactive.html&#34;&gt;https://textdata.cn/blog/2024-01-23-umap/umap_interactive.html&lt;/a&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;p&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;umap&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;plot&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;interactive&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;clusterable_embedding&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
                          &lt;span class=&#34;n&#34;&gt;labels&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;category&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
                          &lt;span class=&#34;n&#34;&gt;hover_data&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;hover_data&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
                          &lt;span class=&#34;n&#34;&gt;point_size&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
                          &lt;span class=&#34;n&#34;&gt;width&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;800&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
                          &lt;span class=&#34;n&#34;&gt;height&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;500&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;umap&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;plot&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;show&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;p&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/05-interactive.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;br&gt;
&lt;h2 id=&#34;四下载资料&#34;&gt;四、下载资料&lt;/h2&gt;
&lt;p&gt;点击下载实验数据  &lt;a href=&#34;data.csv.gz&#34;&gt;&lt;strong&gt;data.csv.gz&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;br&gt;
&lt;br&gt;
</description>
      <content:encoded><![CDATA[<h2 id="一介绍">一、介绍</h2>
<p>UMAP（Uniform Manifold Approximation and Projection for Dimension Reduction）是一种非线性降维技术，类似于t-SNE、PCA，可用于可视化。在降维应用中， 相比于t-SNE，umap既快又准。</p>
<p>如果对 UMAP算法感兴趣，可以阅读论文</p>
<blockquote>
<p>McInnes, L, Healy, J, UMAP: Uniform Manifold Approximation and Projection for Dimension Reduction, ArXiv <a href="https://www.zhihu.com/search?q=e-prints&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22109584077%22%7D">e-prints</a> 1802.03426, 2018</p>
</blockquote>
<br>
<br>
<h2 id="二准备数据">二、准备数据</h2>
<h3 id="21-读取数据">2.1 读取数据</h3>
<p>我从 <a href="https://textdata.cn/blog/2023-12-14-daily-news-dataset/"><strong>人民日报(1946-2023.12.18)</strong></a> 训练的 word2vec模型 中， 选出了100个词的词向量，构建得到了 <a href="data.csv.gz"><strong>data.csv.gz</strong></a></p>
<ul>
<li>word:  词语，一共有100个</li>
<li>category: 词语的类别， 一共五种(亲人、环保、研发、国王、数字化)</li>
<li>f1,f2,f3,&hellip;,f200  词向量的200维（每个词语的词向量是200维的向量）</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;data.csv.gz&#39;</span><span class="p">,</span> <span class="n">compression</span><span class="o">=</span><span class="s1">&#39;gzip&#39;</span><span class="p">)</span>
<span class="n">df</span>
</code></pre></div><p><img loading="lazy" src="img/01-df.png" alt=""  />
</p>
<br>
<h3 id="22-查看词语对应类别">2.2 查看词语&amp;对应类别</h3>
<p>大邓准备了五类词， 每类词20个词， 词语类别按顺序依次是 <strong>亲人、环保、研发、国王、数字</strong></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df</span><span class="p">[</span><span class="s1">&#39;word&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">[&#39;爸爸&#39;, &#39;姐姐&#39;, &#39;奶奶&#39;, &#39;女儿&#39;, &#39;外公&#39;, &#39;哥哥&#39;, &#39;儿子&#39;, &#39;祖母&#39;, &#39;父母亲&#39;, &#39;外婆&#39;, &#39;妹妹&#39;, &#39;孙女&#39;, &#39;姥爷&#39;, &#39;小女儿&#39;, &#39;姥姥&#39;, &#39;二姐&#39;, &#39;姑姑&#39;, &#39;弟弟&#39;, &#39;弟弟妹妹&#39;, &#39;爸爸妈妈&#39;, &#39;低碳&#39;, &#39;节能&#39;, &#39;环境保护&#39;, &#39;绿色环保&#39;, &#39;节能降耗&#39;, &#39;环保节能&#39;, &#39;生态环保&#39;, &#39;节能环保&#39;, &#39;节能低碳&#39;, &#39;绿色低碳&#39;, &#39;减排&#39;, &#39;绿色发展&#39;, &#39;保护环境&#39;, &#39;清洁生产&#39;, &#39;建筑节能&#39;, &#39;环境治理&#39;, &#39;减碳&#39;, &#39;循环经济&#39;, &#39;低碳环保&#39;, &#39;治理污染&#39;, &#39;科研开发&#39;, &#39;科技研发&#39;, &#39;科研创新&#39;, &#39;研发创新&#39;, &#39;技术创新&#39;, &#39;技术开发&#39;, &#39;技术研发&#39;, &#39;产品开发&#39;, &#39;产品研发&#39;, &#39;原始创新&#39;, &#39;科技创新&#39;, &#39;研究开发&#39;, &#39;新药研发&#39;, &#39;核心技术研发&#39;, &#39;产学研结合&#39;, &#39;科技开发&#39;, &#39;基础研究&#39;, &#39;新产品开发&#39;, &#39;研发成果&#39;, &#39;科研成果产业化&#39;, &#39;二世&#39;, &#39;王储&#39;, &#39;公主&#39;, &#39;女王&#39;, &#39;王妃&#39;, &#39;陛下&#39;, &#39;王宫&#39;, &#39;王室&#39;, &#39;王室成员&#39;, &#39;皇室成员&#39;, &#39;登基&#39;, &#39;六世&#39;, &#39;继承王位&#39;, &#39;五世&#39;, &#39;摄政王&#39;, &#39;七世&#39;, &#39;英国女王&#39;, &#39;三世&#39;, &#39;四世&#39;, &#39;继位&#39;, &#39;人工智能技术&#39;, &#39;AI&#39;, &#39;数字技术&#39;, &#39;虚拟现实&#39;, &#39;云计算&#39;, &#39;万物互联&#39;, &#39;信息技术&#39;, &#39;语音技术&#39;, &#39;物联网&#39;, &#39;智能硬件&#39;, &#39;5G技术&#39;, &#39;IoT&#39;, &#39;智能应用&#39;, &#39;软件技术&#39;, &#39;融合应用&#39;, &#39;6G&#39;, &#39;人工智能机器人&#39;, &#39;数据应用&#39;, &#39;人工智能应用&#39;, &#39;智能&#39;]
</code></pre></div><br>
<p>词语对应的类别</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;category&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="p">[</span><span class="s1">&#39;亲人&#39;</span><span class="p">,</span> <span class="s1">&#39;亲人&#39;</span><span class="p">,</span> <span class="s1">&#39;亲人&#39;</span><span class="p">,</span> <span class="s1">&#39;亲人&#39;</span><span class="p">,</span> <span class="s1">&#39;亲人&#39;</span><span class="p">,</span> <span class="s1">&#39;亲人&#39;</span><span class="p">,</span> <span class="s1">&#39;亲人&#39;</span><span class="p">,</span> <span class="s1">&#39;亲人&#39;</span><span class="p">,</span> <span class="s1">&#39;亲人&#39;</span><span class="p">,</span> <span class="s1">&#39;亲人&#39;</span><span class="p">,</span> <span class="s1">&#39;亲人&#39;</span><span class="p">,</span> <span class="s1">&#39;亲人&#39;</span><span class="p">,</span> <span class="s1">&#39;亲人&#39;</span><span class="p">,</span> <span class="s1">&#39;亲人&#39;</span><span class="p">,</span> <span class="s1">&#39;亲人&#39;</span><span class="p">,</span> <span class="s1">&#39;亲人&#39;</span><span class="p">,</span> <span class="s1">&#39;亲人&#39;</span><span class="p">,</span> <span class="s1">&#39;亲人&#39;</span><span class="p">,</span> <span class="s1">&#39;亲人&#39;</span><span class="p">,</span> <span class="s1">&#39;亲人&#39;</span><span class="p">,</span> <span class="s1">&#39;环保&#39;</span><span class="p">,</span> <span class="s1">&#39;环保&#39;</span><span class="p">,</span> <span class="s1">&#39;环保&#39;</span><span class="p">,</span> <span class="s1">&#39;环保&#39;</span><span class="p">,</span> <span class="s1">&#39;环保&#39;</span><span class="p">,</span> <span class="s1">&#39;环保&#39;</span><span class="p">,</span> <span class="s1">&#39;环保&#39;</span><span class="p">,</span> <span class="s1">&#39;环保&#39;</span><span class="p">,</span> <span class="s1">&#39;环保&#39;</span><span class="p">,</span> <span class="s1">&#39;环保&#39;</span><span class="p">,</span> <span class="s1">&#39;环保&#39;</span><span class="p">,</span> <span class="s1">&#39;环保&#39;</span><span class="p">,</span> <span class="s1">&#39;环保&#39;</span><span class="p">,</span> <span class="s1">&#39;环保&#39;</span><span class="p">,</span> <span class="s1">&#39;环保&#39;</span><span class="p">,</span> <span class="s1">&#39;环保&#39;</span><span class="p">,</span> <span class="s1">&#39;环保&#39;</span><span class="p">,</span> <span class="s1">&#39;环保&#39;</span><span class="p">,</span> <span class="s1">&#39;环保&#39;</span><span class="p">,</span> <span class="s1">&#39;环保&#39;</span><span class="p">,</span> <span class="s1">&#39;研发&#39;</span><span class="p">,</span> <span class="s1">&#39;研发&#39;</span><span class="p">,</span> <span class="s1">&#39;研发&#39;</span><span class="p">,</span> <span class="s1">&#39;研发&#39;</span><span class="p">,</span> <span class="s1">&#39;研发&#39;</span><span class="p">,</span> <span class="s1">&#39;研发&#39;</span><span class="p">,</span> <span class="s1">&#39;研发&#39;</span><span class="p">,</span> <span class="s1">&#39;研发&#39;</span><span class="p">,</span> <span class="s1">&#39;研发&#39;</span><span class="p">,</span> <span class="s1">&#39;研发&#39;</span><span class="p">,</span> <span class="s1">&#39;研发&#39;</span><span class="p">,</span> <span class="s1">&#39;研发&#39;</span><span class="p">,</span> <span class="s1">&#39;研发&#39;</span><span class="p">,</span> <span class="s1">&#39;研发&#39;</span><span class="p">,</span> <span class="s1">&#39;研发&#39;</span><span class="p">,</span> <span class="s1">&#39;研发&#39;</span><span class="p">,</span> <span class="s1">&#39;研发&#39;</span><span class="p">,</span> <span class="s1">&#39;研发&#39;</span><span class="p">,</span> <span class="s1">&#39;研发&#39;</span><span class="p">,</span> <span class="s1">&#39;研发&#39;</span><span class="p">,</span> <span class="s1">&#39;国王&#39;</span><span class="p">,</span> <span class="s1">&#39;国王&#39;</span><span class="p">,</span> <span class="s1">&#39;国王&#39;</span><span class="p">,</span> <span class="s1">&#39;国王&#39;</span><span class="p">,</span> <span class="s1">&#39;国王&#39;</span><span class="p">,</span> <span class="s1">&#39;国王&#39;</span><span class="p">,</span> <span class="s1">&#39;国王&#39;</span><span class="p">,</span> <span class="s1">&#39;国王&#39;</span><span class="p">,</span> <span class="s1">&#39;国王&#39;</span><span class="p">,</span> <span class="s1">&#39;国王&#39;</span><span class="p">,</span> <span class="s1">&#39;国王&#39;</span><span class="p">,</span> <span class="s1">&#39;国王&#39;</span><span class="p">,</span> <span class="s1">&#39;国王&#39;</span><span class="p">,</span> <span class="s1">&#39;国王&#39;</span><span class="p">,</span> <span class="s1">&#39;国王&#39;</span><span class="p">,</span> <span class="s1">&#39;国王&#39;</span><span class="p">,</span> <span class="s1">&#39;国王&#39;</span><span class="p">,</span> <span class="s1">&#39;国王&#39;</span><span class="p">,</span> <span class="s1">&#39;国王&#39;</span><span class="p">,</span> <span class="s1">&#39;国王&#39;</span><span class="p">,</span> <span class="s1">&#39;数字化&#39;</span><span class="p">,</span> <span class="s1">&#39;数字化&#39;</span><span class="p">,</span> <span class="s1">&#39;数字化&#39;</span><span class="p">,</span> <span class="s1">&#39;数字化&#39;</span><span class="p">,</span> <span class="s1">&#39;数字化&#39;</span><span class="p">,</span> <span class="s1">&#39;数字化&#39;</span><span class="p">,</span> <span class="s1">&#39;数字化&#39;</span><span class="p">,</span> <span class="s1">&#39;数字化&#39;</span><span class="p">,</span> <span class="s1">&#39;数字化&#39;</span><span class="p">,</span> <span class="s1">&#39;数字化&#39;</span><span class="p">,</span> <span class="s1">&#39;数字化&#39;</span><span class="p">,</span> <span class="s1">&#39;数字化&#39;</span><span class="p">,</span> <span class="s1">&#39;数字化&#39;</span><span class="p">,</span> <span class="s1">&#39;数字化&#39;</span><span class="p">,</span> <span class="s1">&#39;数字化&#39;</span><span class="p">,</span> <span class="s1">&#39;数字化&#39;</span><span class="p">,</span> <span class="s1">&#39;数字化&#39;</span><span class="p">,</span> <span class="s1">&#39;数字化&#39;</span><span class="p">,</span> <span class="s1">&#39;数字化&#39;</span><span class="p">,</span> <span class="s1">&#39;数字化&#39;</span><span class="p">]</span>
</code></pre></div><p><br><br></p>
<h2 id="三实验代码">三、实验代码</h2>
<h3 id="31-环境准备">3.1 环境准备</h3>
<p>在 <em><strong>cmd(terminal)</strong></em> 安装本文需要的库</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">pip3 install umap-learn
pip3 install datashader,bokeh,holoviews  #可视化可能会用到的库
</code></pre></div><br>
<h3 id="32-降维">3.2 降维</h3>
<p>将 100 个词的词向量数据从 200 维压缩到 2 维</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">umap</span>

<span class="n">word_emb_redution_data</span> <span class="o">=</span> <span class="n">umap</span><span class="o">.</span><span class="n">UMAP</span><span class="p">(</span>
    <span class="n">n_neighbors</span> <span class="o">=</span> <span class="mi">15</span><span class="p">,</span>  <span class="c1">#默认，不需要理解</span>
    <span class="n">min_dist</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span> <span class="c1">#默认，不需要理解</span>
    <span class="n">n_components</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="c1">#2维</span>
    <span class="n">random_state</span> <span class="o">=</span> <span class="mi">666</span><span class="p">,</span> <span class="c1">#默认， 保证任意时空代码运行结果的随机状态是一致的</span>
<span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">:])</span>

<span class="n">word_emb_redution_data</span>
</code></pre></div><p><img loading="lazy" src="img/02-umap.png" alt=""  />
</p>
<br>
<h3 id="33-静态可视化">3.3 静态可视化</h3>
<p>绘制静态的图(没有鼠标交互)， 底层应该是调用了 <em><strong>matplotlib</strong></em> 。 因为实验数据是中文词语， 可视化可能绘乱码。为避免问题， 提前运行代码</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">matplotlib</span>
<span class="kn">import</span> <span class="nn">matplotlib_inline</span>
<span class="n">matplotlib_inline</span><span class="o">.</span><span class="n">backend_inline</span><span class="o">.</span><span class="n">set_matplotlib_formats</span><span class="p">(</span><span class="s1">&#39;png&#39;</span><span class="p">,</span> <span class="s1">&#39;svg&#39;</span><span class="p">)</span>
<span class="kn">import</span> <span class="nn">scienceplots</span>
<span class="kn">import</span> <span class="nn">platform</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">([</span><span class="s1">&#39;science&#39;</span><span class="p">,</span> <span class="s1">&#39;no-latex&#39;</span><span class="p">,</span> <span class="s1">&#39;cjk-sc-font&#39;</span><span class="p">])</span>
<span class="n">system</span> <span class="o">=</span> <span class="n">platform</span><span class="o">.</span><span class="n">system</span><span class="p">()</span>  <span class="c1"># 获取操作系统类型</span>

<span class="k">if</span> <span class="n">system</span> <span class="o">==</span> <span class="s1">&#39;Windows&#39;</span><span class="p">:</span>
    <span class="n">font</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;family&#39;</span><span class="p">:</span> <span class="s1">&#39;SimHei&#39;</span><span class="p">}</span>
<span class="k">elif</span> <span class="n">system</span> <span class="o">==</span> <span class="s1">&#39;Darwin&#39;</span><span class="p">:</span>
    <span class="n">font</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;family&#39;</span><span class="p">:</span> <span class="s1">&#39;Arial Unicode MS&#39;</span><span class="p">}</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">font</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;family&#39;</span><span class="p">:</span> <span class="s1">&#39;sans-serif&#39;</span><span class="p">}</span>
<span class="n">matplotlib</span><span class="o">.</span><span class="n">rc</span><span class="p">(</span><span class="s1">&#39;font&#39;</span><span class="p">,</span> <span class="o">**</span><span class="n">font</span><span class="p">)</span>  <span class="c1"># 设置全局字体</span>
</code></pre></div><br>
<p>绘制 <strong>五类词的词向量投射到2维空间中的可视化</strong> 的静态图(没有鼠标交互)</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">umap.plot</span>

<span class="n">umap</span><span class="o">.</span><span class="n">plot</span><span class="o">.</span><span class="n">points</span><span class="p">(</span><span class="n">word_emb_redution_data</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">df</span><span class="o">.</span><span class="n">category</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">800</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;五类词的词向量投射到2维空间中的可视化&#39;</span><span class="p">)</span>
</code></pre></div><p><img loading="lazy" src="img/03-plot.png" alt=""  />
</p>
<br>
<h3 id="34-动态交互可视化">3.4 动态交互可视化</h3>
<p>umap.plot 内置了bokeh的动态交互功能， 需要先构造鼠标交互悬浮的信息</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">mapper</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;亲人&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;环保&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">&#39;研发&#39;</span><span class="p">:</span><span class="mi">3</span><span class="p">,</span> <span class="s1">&#39;国王&#39;</span><span class="p">:</span><span class="mi">4</span><span class="p">,</span> <span class="s1">&#39;数字化&#39;</span><span class="p">:</span><span class="mi">5</span> <span class="p">}</span>


<span class="n">hover_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;index&#39;</span><span class="p">:</span><span class="n">df</span><span class="o">.</span><span class="n">index</span><span class="p">,</span>
                           <span class="s1">&#39;item&#39;</span><span class="p">:</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;category&#39;</span><span class="p">],</span> 
                           <span class="s1">&#39;label&#39;</span><span class="p">:</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;category&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">mapper</span><span class="p">)})</span>

<span class="n">hover_data</span>
</code></pre></div><p><img loading="lazy" src="img/04-df.png" alt=""  />
</p>
<br>
<p>接下来的代码将会生成一个 html 文件， 因为是动态效果，在博客(公众号)都无法完全显示， 大家如果想查看，可以点击链接下载</p>
<p><a href="https://textdata.cn/blog/2024-01-23-umap/umap_interactive.html">https://textdata.cn/blog/2024-01-23-umap/umap_interactive.html</a></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">p</span> <span class="o">=</span> <span class="n">umap</span><span class="o">.</span><span class="n">plot</span><span class="o">.</span><span class="n">interactive</span><span class="p">(</span><span class="n">clusterable_embedding</span><span class="p">,</span> 
                          <span class="n">labels</span><span class="o">=</span><span class="n">df</span><span class="o">.</span><span class="n">category</span><span class="p">,</span> 
                          <span class="n">hover_data</span><span class="o">=</span><span class="n">hover_data</span><span class="p">,</span> 
                          <span class="n">point_size</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> 
                          <span class="n">width</span><span class="o">=</span><span class="mi">800</span><span class="p">,</span> 
                          <span class="n">height</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span>
<span class="n">umap</span><span class="o">.</span><span class="n">plot</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
</code></pre></div><p><img loading="lazy" src="img/05-interactive.png" alt=""  />
</p>
<br>
<br>
<h2 id="四下载资料">四、下载资料</h2>
<p>点击下载实验数据  <a href="data.csv.gz"><strong>data.csv.gz</strong></a></p>
<br>
<br>
]]></content:encoded>
    </item>
    
    <item>
      <title>可视化 | 使用 DataMapPlot 绘制数据地图</title>
      <link>https://textdata.cn/blog/2024-01-21-datamapplot/</link>
      <pubDate>Sun, 21 Jan 2024 00:00:00 +0000</pubDate>
      
      <guid>/blog/2024-01-21-datamapplot/</guid>
      <description>&lt;p&gt;DataMapPlot库可绘制漂亮的数据地图，以便应用于演示文稿、海报和论文中。重点是用尽可能少的工作量生成美观的静态图， 您只需在数据地图中标记点簇。虽然这涉及到大多数美学选择的自动化，但该库提供了多种方法来根据您的需求定制结果图。&lt;/p&gt;
&lt;br&gt;
&lt;h2 id=&#34;一安装&#34;&gt;一、安装&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;pip3&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;install&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;datamapplot&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;二准备数据&#34;&gt;二、准备数据&lt;/h2&gt;
&lt;h3 id=&#34;21-读取arxivcsvgz&#34;&gt;2.1 读取arxiv.csv.gz&lt;/h3&gt;
&lt;p&gt;点击下载 &lt;a href=&#34;arxiv.csv.gz&#34;&gt;&lt;strong&gt;arxiv.csv.gz&lt;/strong&gt;&lt;/a&gt; , 该数据有 &lt;em&gt;&lt;strong&gt;x1&lt;/strong&gt;&lt;/em&gt;、 &lt;em&gt;&lt;strong&gt;x2&lt;/strong&gt;&lt;/em&gt;、 &lt;em&gt;&lt;strong&gt;label&lt;/strong&gt;&lt;/em&gt; 三个字段，其中&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;x1、x2是降维后的特征信息，常见的降维算法有pca、UMAP, t-SNE等&lt;/li&gt;
&lt;li&gt;label是标注(类别)信息&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read_csv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;arxiv.csv.gz&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;compression&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;gzip&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/01-df.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;22-录入logo&#34;&gt;2.2 录入logo&lt;/h3&gt;
&lt;p&gt;使用PIL读取 &lt;a href=&#34;arxiv_logo.png&#34;&gt;&lt;em&gt;&lt;strong&gt;arxiv_logo.png(点击下载该图片)&lt;/strong&gt;&lt;/em&gt;&lt;/a&gt;，并转化为array数组型数据。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/arxiv_logo.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;PIL&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;numpy&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;np&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;arxiv_logo&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;np&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;asarray&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;PIL&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Image&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;open&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;arxiv_logo.png&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h3 id=&#34;三绘图&#34;&gt;三、绘图&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pandas&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pd&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;numpy&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;np&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;plt&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;matplotlib_inline&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;matplotlib_inline&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;backend_inline&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;set_matplotlib_formats&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;png&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;svg&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;PIL&lt;/span&gt;



&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read_csv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;arxiv.csv.gz&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;compression&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;gzip&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;data_map_coords&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;labels&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;np&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;array&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;x1&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;x2&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]]),&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;label&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;arxiv_logo&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;np&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;asarray&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;PIL&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Image&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;open&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;arxiv.png&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;highlight_labels&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;  &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Clustering&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                     &lt;span class=&#34;s2&#34;&gt;&amp;#34;Manifold learning and dimension reduction&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                     &lt;span class=&#34;s2&#34;&gt;&amp;#34;Active learning&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                     &lt;span class=&#34;s2&#34;&gt;&amp;#34;Topic modelling and text classification&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;


&lt;span class=&#34;n&#34;&gt;datamapplot&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;create_plot&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;data_map_coords&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
    &lt;span class=&#34;n&#34;&gt;labels&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;title&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;ArXiv ML Landscape&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;sub_title&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;A data map of papers from the Machine Learning section of ArXiv&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;highlight_labels&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;highlight_labels&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;label_font_size&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;8&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;highlight_label_keywords&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
        &lt;span class=&#34;s2&#34;&gt;&amp;#34;fontsize&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;12&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;fontweight&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;bold&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;bbox&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:{&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;boxstyle&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;circle&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;pad&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;0.75&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
    &lt;span class=&#34;p&#34;&gt;},&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;logo&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;arxiv_logo&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;plt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;savefig&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;arxiv_white.png&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;dpi&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;200&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/arxiv_white.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;三gallery&#34;&gt;三、Gallery&lt;/h2&gt;
&lt;p&gt;更多内容，可阅读文档  &lt;a href=&#34;https://github.com/TutteInstitute/datamapplot&#34;&gt;DataMapPlot: &lt;/a&gt;  &lt;a href=&#34;https://github.com/TutteInstitute/datamapplot&#34;&gt;https://github.com/TutteInstitute/datamapplot&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/plot_arxiv_ml.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/plot_wikipedia.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
</description>
      <content:encoded><![CDATA[<p>DataMapPlot库可绘制漂亮的数据地图，以便应用于演示文稿、海报和论文中。重点是用尽可能少的工作量生成美观的静态图， 您只需在数据地图中标记点簇。虽然这涉及到大多数美学选择的自动化，但该库提供了多种方法来根据您的需求定制结果图。</p>
<br>
<h2 id="一安装">一、安装</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">pip3</span> <span class="n">install</span> <span class="n">datamapplot</span>
</code></pre></div><p><br><br></p>
<h2 id="二准备数据">二、准备数据</h2>
<h3 id="21-读取arxivcsvgz">2.1 读取arxiv.csv.gz</h3>
<p>点击下载 <a href="arxiv.csv.gz"><strong>arxiv.csv.gz</strong></a> , 该数据有 <em><strong>x1</strong></em>、 <em><strong>x2</strong></em>、 <em><strong>label</strong></em> 三个字段，其中</p>
<ul>
<li>x1、x2是降维后的特征信息，常见的降维算法有pca、UMAP, t-SNE等</li>
<li>label是标注(类别)信息</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;arxiv.csv.gz&#39;</span><span class="p">,</span> <span class="n">compression</span><span class="o">=</span><span class="s1">&#39;gzip&#39;</span><span class="p">)</span>
<span class="n">df</span>
</code></pre></div><p><img loading="lazy" src="img/01-df.png" alt=""  />
</p>
<br>
<h3 id="22-录入logo">2.2 录入logo</h3>
<p>使用PIL读取 <a href="arxiv_logo.png"><em><strong>arxiv_logo.png(点击下载该图片)</strong></em></a>，并转化为array数组型数据。</p>
<p><img loading="lazy" src="img/arxiv_logo.png" alt=""  />
</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">PIL</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">arxiv_logo</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">PIL</span><span class="o">.</span><span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s1">&#39;arxiv_logo.png&#39;</span><span class="p">))</span>
</code></pre></div><p><br><br></p>
<h3 id="三绘图">三、绘图</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">matplotlib_inline</span>
<span class="n">matplotlib_inline</span><span class="o">.</span><span class="n">backend_inline</span><span class="o">.</span><span class="n">set_matplotlib_formats</span><span class="p">(</span><span class="s1">&#39;png&#39;</span><span class="p">,</span> <span class="s1">&#39;svg&#39;</span><span class="p">)</span>
<span class="kn">import</span> <span class="nn">PIL</span>



<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;arxiv.csv.gz&#39;</span><span class="p">,</span> <span class="n">compression</span><span class="o">=</span><span class="s1">&#39;gzip&#39;</span><span class="p">)</span>
<span class="n">data_map_coords</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">df</span><span class="p">[[</span><span class="s1">&#39;x1&#39;</span><span class="p">,</span> <span class="s1">&#39;x2&#39;</span><span class="p">]]),</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">]</span>
<span class="n">arxiv_logo</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">PIL</span><span class="o">.</span><span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s1">&#39;arxiv.png&#39;</span><span class="p">))</span>
<span class="n">highlight_labels</span> <span class="o">=</span>  <span class="p">[</span><span class="s2">&#34;Clustering&#34;</span><span class="p">,</span>
                     <span class="s2">&#34;Manifold learning and dimension reduction&#34;</span><span class="p">,</span>
                     <span class="s2">&#34;Active learning&#34;</span><span class="p">,</span>
                     <span class="s2">&#34;Topic modelling and text classification&#34;</span><span class="p">]</span>


<span class="n">datamapplot</span><span class="o">.</span><span class="n">create_plot</span><span class="p">(</span>
    <span class="n">data_map_coords</span><span class="p">,</span> 
    <span class="n">labels</span><span class="p">,</span>
    <span class="n">title</span> <span class="o">=</span> <span class="s2">&#34;ArXiv ML Landscape&#34;</span><span class="p">,</span>
    <span class="n">sub_title</span> <span class="o">=</span> <span class="s2">&#34;A data map of papers from the Machine Learning section of ArXiv&#34;</span><span class="p">,</span>
    <span class="n">highlight_labels</span> <span class="o">=</span> <span class="n">highlight_labels</span><span class="p">,</span>
    <span class="n">label_font_size</span> <span class="o">=</span> <span class="mi">8</span><span class="p">,</span>
    <span class="n">highlight_label_keywords</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&#34;fontsize&#34;</span><span class="p">:</span> <span class="mi">12</span><span class="p">,</span> <span class="s2">&#34;fontweight&#34;</span><span class="p">:</span> <span class="s2">&#34;bold&#34;</span><span class="p">,</span> <span class="s2">&#34;bbox&#34;</span><span class="p">:{</span><span class="s2">&#34;boxstyle&#34;</span><span class="p">:</span><span class="s2">&#34;circle&#34;</span><span class="p">,</span> <span class="s2">&#34;pad&#34;</span><span class="p">:</span><span class="mf">0.75</span><span class="p">}</span>
    <span class="p">},</span>
    <span class="n">logo</span><span class="o">=</span><span class="n">arxiv_logo</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;arxiv_white.png&#39;</span><span class="p">,</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">200</span><span class="p">)</span>
</code></pre></div><p><img loading="lazy" src="img/arxiv_white.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="三gallery">三、Gallery</h2>
<p>更多内容，可阅读文档  <a href="https://github.com/TutteInstitute/datamapplot">DataMapPlot: </a>  <a href="https://github.com/TutteInstitute/datamapplot">https://github.com/TutteInstitute/datamapplot</a></p>
<p><img loading="lazy" src="img/plot_arxiv_ml.png" alt=""  />
</p>
<br>
<p><img loading="lazy" src="img/plot_wikipedia.png" alt=""  />
</p>
<p><br><br></p>
]]></content:encoded>
    </item>
    
    <item>
      <title>mercury | 在jupyter notebook中创建Web应用程序</title>
      <link>https://textdata.cn/blog/2023-06-12-mercury-fast-webapp/</link>
      <pubDate>Mon, 12 Jun 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-06-12-mercury-fast-webapp/</guid>
      <description>&lt;h2 id=&#34;一介绍&#34;&gt;一、介绍&lt;/h2&gt;
&lt;p&gt;Mercury允许您在Python笔记本中添加交互式小部件，因此您可以将笔记本共享为Web应用程序。&lt;/p&gt;
&lt;h3 id=&#34;11-功能&#34;&gt;1.1 功能&lt;/h3&gt;
&lt;p&gt;Mercury提供了一套带有简单单元格重新执行的小部件,您可以使用Mercury构建以下内容：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;将您的笔记本转化为漂亮的Web应用程序，&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;创建带有小部件的交互式演示文稿，您可以在展示过程中重新计算幻灯片，&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;将笔记本作为静态网站进行共享，&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;使用小部件构建数据丰富的仪表板，&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;创建具有PDF导出、自动调度和电子邮件通知功能的报告（即将推出），&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;将Python笔记本作为REST API端点提供服务（即将推出）。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
&lt;h3 id=&#34;12-特点&#34;&gt;1.2 特点&lt;/h3&gt;
&lt;p&gt;Mercury的特点包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;使用Python代码添加小部件-无需前端经验！&lt;/li&gt;
&lt;li&gt;隐藏或显示笔记本的代码，&lt;/li&gt;
&lt;li&gt;将已执行的笔记本导出为PDF或HTML，&lt;/li&gt;
&lt;li&gt;共享多个笔记本-没有限制！&lt;/li&gt;
&lt;li&gt;将笔记本嵌入到任何网站中，&lt;/li&gt;
&lt;li&gt;轻松在笔记本中上传和下载文件，&lt;/li&gt;
&lt;li&gt;为笔记本添加身份验证（即将推出），&lt;/li&gt;
&lt;li&gt;计划自动笔记本执行（即将推出）。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h3 id=&#34;13-安装&#34;&gt;1.3 安装&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;pip&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;install&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;mercury&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h3 id=&#34;14-运行&#34;&gt;1.4 运行&lt;/h3&gt;
&lt;p&gt;命令行执行&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;mercury&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;run&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;请访问 &lt;strong&gt;127.0.0.1:8000&lt;/strong&gt; 查看演示笔记本。&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;二示例&#34;&gt;二、示例&lt;/h2&gt;
&lt;p&gt;下面是一个简单的代码示例，创建一个小部件并显示其值。您可以在Jupyter Notebook中与小部件进行交互。小部件的值将会被更新。但是，要在其他单元格中看到更新，您需要手动执行它们。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;mercury&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;mr&lt;/span&gt; 

&lt;span class=&#34;c1&#34;&gt;#创建一个文本小部件：&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;name&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;mr&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;value&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Piotr&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;label&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;What is your name?&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; 



&lt;span class=&#34;c1&#34;&gt;# 打印小部件的值：&lt;/span&gt;

&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;sa&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Hello &lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;value&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Jupyter Notebook中的代码截图&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/hello-world-notebook-ola.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;三mercury-应用程序&#34;&gt;三、Mercury 应用程序&lt;/h2&gt;
&lt;p&gt;使用 Mercury 将笔记本作为 Web 应用程序运行。小部件更改后，单元格会自动重新执行。Mercury 仅重新执行具有小部件定义及其下方的单元格。在示例中，小部件更新后，单元格 2 和 3 会被重新执行。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/hello-world-app-ola.gif&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
</description>
      <content:encoded><![CDATA[<h2 id="一介绍">一、介绍</h2>
<p>Mercury允许您在Python笔记本中添加交互式小部件，因此您可以将笔记本共享为Web应用程序。</p>
<h3 id="11-功能">1.1 功能</h3>
<p>Mercury提供了一套带有简单单元格重新执行的小部件,您可以使用Mercury构建以下内容：</p>
<ul>
<li>
<p>将您的笔记本转化为漂亮的Web应用程序，</p>
</li>
<li>
<p>创建带有小部件的交互式演示文稿，您可以在展示过程中重新计算幻灯片，</p>
</li>
<li>
<p>将笔记本作为静态网站进行共享，</p>
</li>
<li>
<p>使用小部件构建数据丰富的仪表板，</p>
</li>
<li>
<p>创建具有PDF导出、自动调度和电子邮件通知功能的报告（即将推出），</p>
</li>
<li>
<p>将Python笔记本作为REST API端点提供服务（即将推出）。</p>
</li>
</ul>
<br>
<h3 id="12-特点">1.2 特点</h3>
<p>Mercury的特点包括：</p>
<ul>
<li>使用Python代码添加小部件-无需前端经验！</li>
<li>隐藏或显示笔记本的代码，</li>
<li>将已执行的笔记本导出为PDF或HTML，</li>
<li>共享多个笔记本-没有限制！</li>
<li>将笔记本嵌入到任何网站中，</li>
<li>轻松在笔记本中上传和下载文件，</li>
<li>为笔记本添加身份验证（即将推出），</li>
<li>计划自动笔记本执行（即将推出）。</li>
</ul>
<p><br><br></p>
<h3 id="13-安装">1.3 安装</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">pip</span> <span class="n">install</span> <span class="n">mercury</span>
</code></pre></div><br>
<h3 id="14-运行">1.4 运行</h3>
<p>命令行执行</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">mercury</span> <span class="n">run</span>
</code></pre></div><p>请访问 <strong>127.0.0.1:8000</strong> 查看演示笔记本。</p>
<p><br><br></p>
<h2 id="二示例">二、示例</h2>
<p>下面是一个简单的代码示例，创建一个小部件并显示其值。您可以在Jupyter Notebook中与小部件进行交互。小部件的值将会被更新。但是，要在其他单元格中看到更新，您需要手动执行它们。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">mercury</span> <span class="k">as</span> <span class="nn">mr</span> 

<span class="c1">#创建一个文本小部件：</span>

<span class="n">name</span> <span class="o">=</span> <span class="n">mr</span><span class="o">.</span><span class="n">Text</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="s2">&#34;Piotr&#34;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&#34;What is your name?&#34;</span><span class="p">)</span> 



<span class="c1"># 打印小部件的值：</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;Hello </span><span class="si">{</span><span class="n">name</span><span class="o">.</span><span class="n">value</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span> 
</code></pre></div><p>Jupyter Notebook中的代码截图</p>
<p><img loading="lazy" src="img/hello-world-notebook-ola.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="三mercury-应用程序">三、Mercury 应用程序</h2>
<p>使用 Mercury 将笔记本作为 Web 应用程序运行。小部件更改后，单元格会自动重新执行。Mercury 仅重新执行具有小部件定义及其下方的单元格。在示例中，小部件更新后，单元格 2 和 3 会被重新执行。</p>
<p><img loading="lazy" src="img/hello-world-app-ola.gif" alt=""  />
</p>
<p><br><br></p>
]]></content:encoded>
    </item>
    
    <item>
      <title>prettymaps库 | 绘制绝美地图</title>
      <link>https://textdata.cn/blog/2023-04-13-prettymaps/</link>
      <pubDate>Thu, 13 Apr 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-04-13-prettymaps/</guid>
      <description>&lt;p&gt;prettymaps库是用于从 OpenStreetMap 数据绘制漂亮的地图， 基于 osmnx、matplotlib 和 shapely 库开发而来。&lt;/p&gt;
&lt;br&gt;
&lt;h2 id=&#34;gallery&#34;&gt;Gallery&lt;/h2&gt;
&lt;p&gt;下面是prettymaps绘制的样例，&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/palmanova.png&#34; alt=&#34;&#34;  /&gt;

&lt;img loading=&#34;lazy&#34; src=&#34;img/macao.png&#34; alt=&#34;&#34;  /&gt;

&lt;img loading=&#34;lazy&#34; src=&#34;img/heerhugowaard.png&#34; alt=&#34;&#34;  /&gt;

&lt;img loading=&#34;lazy&#34; src=&#34;img/barcelona.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;h2 id=&#34;安装&#34;&gt;安装&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;err&#34;&gt;!&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;pip3&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;install&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;prettymaps&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h2 id=&#34;快速上手&#34;&gt;快速上手&lt;/h2&gt;
&lt;p&gt;使用 prettymaps 库绘制可视化地图很简单，只需要使用&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;prettymaps.plot(your_query)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;your_query有以下三种方式&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;地址 (Example: &amp;ldquo;Porto Alegre&amp;rdquo;),&lt;/li&gt;
&lt;li&gt;纬度/经度 (Example: (-30.0324999, -51.2303767))&lt;/li&gt;
&lt;li&gt;GeoDataFrame格式数据&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这里以哈工大科学园地图为例， 使用 &lt;strong&gt;维度/经度&lt;/strong&gt; 坐标绘制。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/hit-science-park.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;prettymaps&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;plt&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;#哈工大科学园2H栋&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;plot&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;prettymaps&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;plot&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
   &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;45.73022857604175&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;126.63157734342359&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;preset&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;heerhugowaard&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;plt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;show&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/output_3_0.png&#34; alt=&#34;png&#34;  /&gt;
&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;prettymaps&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;matplotlib&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pyplot&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;plt&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;plot&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;prettymaps&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;plot&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
    &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;41.39491&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;2.17557&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;preset&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;barcelona&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;# Change background color&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;plot&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fig&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;patch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;set_facecolor&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;#F2F4CB&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;c1&#34;&gt;# Add title&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;plot&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ax&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;set_title&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;Barcelona&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;plt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;savefig&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fname&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;barcelona.png&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;dpi&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;100&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;plt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;show&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/barcelona.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
</description>
      <content:encoded><![CDATA[<p>prettymaps库是用于从 OpenStreetMap 数据绘制漂亮的地图， 基于 osmnx、matplotlib 和 shapely 库开发而来。</p>
<br>
<h2 id="gallery">Gallery</h2>
<p>下面是prettymaps绘制的样例，</p>
<p><img loading="lazy" src="img/palmanova.png" alt=""  />

<img loading="lazy" src="img/macao.png" alt=""  />

<img loading="lazy" src="img/heerhugowaard.png" alt=""  />

<img loading="lazy" src="img/barcelona.png" alt=""  />
</p>
<br>
<h2 id="安装">安装</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="err">!</span><span class="n">pip3</span> <span class="n">install</span> <span class="n">prettymaps</span>
</code></pre></div><br>
<h2 id="快速上手">快速上手</h2>
<p>使用 prettymaps 库绘制可视化地图很简单，只需要使用</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">prettymaps.plot(your_query)
</code></pre></div><p>your_query有以下三种方式</p>
<ul>
<li>地址 (Example: &ldquo;Porto Alegre&rdquo;),</li>
<li>纬度/经度 (Example: (-30.0324999, -51.2303767))</li>
<li>GeoDataFrame格式数据</li>
</ul>
<p>这里以哈工大科学园地图为例， 使用 <strong>维度/经度</strong> 坐标绘制。</p>
<p><img loading="lazy" src="img/hit-science-park.png" alt=""  />
</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">prettymaps</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="c1">#哈工大科学园2H栋</span>
<span class="n">plot</span> <span class="o">=</span> <span class="n">prettymaps</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
   <span class="p">(</span><span class="mf">45.73022857604175</span><span class="p">,</span> <span class="mf">126.63157734342359</span><span class="p">),</span>
    <span class="n">preset</span> <span class="o">=</span> <span class="s1">&#39;heerhugowaard&#39;</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/output_3_0.png" alt="png"  />
</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">prettymaps</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="n">plot</span> <span class="o">=</span> <span class="n">prettymaps</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
    <span class="p">(</span><span class="mf">41.39491</span><span class="p">,</span><span class="mf">2.17557</span><span class="p">),</span>
    <span class="n">preset</span> <span class="o">=</span> <span class="s1">&#39;barcelona&#39;</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># Change background color</span>
<span class="n">plot</span><span class="o">.</span><span class="n">fig</span><span class="o">.</span><span class="n">patch</span><span class="o">.</span><span class="n">set_facecolor</span><span class="p">(</span><span class="s1">&#39;#F2F4CB&#39;</span><span class="p">)</span>
<span class="c1"># Add title</span>
<span class="n">plot</span><span class="o">.</span><span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Barcelona&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">fname</span><span class="o">=</span><span class="s1">&#39;barcelona.png&#39;</span><span class="p">,</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/barcelona.png" alt=""  />
</p>
<br>
]]></content:encoded>
    </item>
    
    <item>
      <title>硬核 | 使用Poetry发布Python库到PyPi的方法</title>
      <link>https://textdata.cn/blog/2023-03-31-using-poetry-to-manage-your-project-env/</link>
      <pubDate>Fri, 31 Mar 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-03-31-using-poetry-to-manage-your-project-env/</guid>
      <description>如何使用poetry打包python库</description>
      <content:encoded><![CDATA[<h2 id="一介绍">一、介绍</h2>
<p>Poetry 是一个用于管理 Python 项目的工具，它的主要用途包括以下几个方面：</p>
<ul>
<li>依赖管理：Poetry 可以帮助您管理项目的依赖项。您可以使用 Poetry 来定义项目的依赖项，包括 Python 版本和其他 Python 包，然后 Poetry 会自动安装和管理这些依赖项。这有助于确保项目在不同环境中具有一致的依赖项。</li>
<li>包管理：Poetry 可以帮助您构建和发布 Python 包。它能够生成标准的分发文件，如 wheel 和 sdist（源分发文件），以便您可以轻松地分享和分发您的包。此外，Poetry 还支持发布包到 PyPI（Python 包索引）等包仓库。</li>
<li>虚拟环境管理：Poetry 可以自动创建和管理虚拟环境，以确保项目的依赖项不会干扰全局 Python 环境或其他项目的环境。这有助于隔离项目之间的依赖关系，使项目更加稳定和可维护。</li>
<li>项目配置：Poetry 使用一个易于编辑的配置文件（pyproject.toml）来定义项目的元信息、依赖关系和其他配置。这使得项目配置变得更加直观和可读。</li>
<li>版本管理：Poetry 支持版本控制，可以帮助您管理项目的版本号。您可以在项目配置中指定版本号，并根据项目的进展逐渐升级版本。</li>
<li>脚本管理：Poetry 允许您定义和运行自定义脚本，以简化项目的常见任务，如测试、构建、文档生成等。</li>
<li>依赖解析：Poetry 使用一种智能的依赖解析算法来确保项目的依赖项解析不会导致冲突或不一致性，同时尽量满足依赖项的约束条件。</li>
</ul>
<p>总之，Poetry 是一个功能强大的 Python 项目管理工具，可以帮助开发人员更轻松地管理项目的依赖项、构建和发布 Python 包，以及管理项目的配置和版本。它提供了一种现代化的方式来处理 Python 项目的工程化和依赖管理。</p>
<p>今天主要分享</p>
<ul>
<li>如何使用poetry创建项目环境</li>
<li>如何使用poetry打包自己的python库</li>
</ul>
<p><br><br></p>
<h2 id="二创建项目环境">二、创建项目环境</h2>
<p>创建一个项目(或库)的虚拟环境，现在用poetry从0开始配置。首先安装poetry，在cmd执行</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">pip3 install poetry
</code></pre></div><br>
<h3 id="21-创建新项目">2.1 创建新项目</h3>
<p>打开cmd， 切换至桌面(大邓喜欢在桌面做事，也简单好记)</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">cd desktop
poetry new myproject
</code></pre></div><p>这样在桌面新生成了一个cntext项目文件夹， 该项目的文件目录树结构</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">myproject
   |--- __init__.py
poetry.lock
pyproject.toml
README.md
tests
   |--- __init__.py
</code></pre></div><p><img loading="lazy" src="img/myproject.png" alt=""  />
</p>
<br>
<h3 id="22-切换至项目目录">2.2 切换至项目目录</h3>
<p>在cmd中将当前工作目录切换至myproject项目内</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">cd myproject
</code></pre></div><br>
<h3 id="23-创建虚拟环境">2.3 创建虚拟环境</h3>
<p>在myproject项目内创建python3虚拟环境，cmd中的执行命令如下</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">poetry env use python3
</code></pre></div><p>这会创建一个名为 <code>python3</code> 的虚拟环境并激活它。 例如大邓的Python是3.11.5，则pyproject.toml内会有</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">[tool.poetry.dependencies]
python = &#34;^3.11&#34;
</code></pre></div><p>表示poetry依赖于大邓电脑中的python3.11环境。</p>
<br>
<h3 id="24-定义依赖项">2.4 定义依赖项</h3>
<p>项目myproject是要做一些事的，假设myproject是要做与cntext库类似的事情，需要依赖的包有</p>
<p>jieba、numpy 、mittens、scikit-learn、matplotlib、pyecharts、gensim、nltk、pandas、 chardet、 h5py 。</p>
<p>这时候我们需要在 <strong>myproject.toml</strong> 中加入</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">[dependencies]
python = &#34;^3.5&#34;
jieba = &#34;^0.4.1&#34;
numpy = &#34;^1.21.0&#34;
mittens = &#34;^0.2&#34;
scikit-learn = &#34;^1.3.0&#34;
matplotlib = &#34;^3.6.0&#34;
pyecharts = &#34;2.0.0&#34;
gensim = &#34;^4.2.0&#34;
nltk = &#34;^3.8&#34;
pandas = &#34;^1.5.0&#34;
chardet = &#34;^5.0.0&#34;
h5py = &#34;^3.9.0&#34;
</code></pre></div><p>表示如果其他用户使用myproject这个项目，至少要保证python是3.5及以上版本， 依赖的库有jieba、numpy 、mittens、scikit-learn、matplotlib、pyecharts、gensim、nltk、pandas、 chardet、 h5py ， 以jieba为例， jieba要满足0.4.1及以上版本。</p>
<br>
<h3 id="25-安装依赖项">2.5 安装依赖项</h3>
<p>在虚拟环境中，使用以下命令安装项目的依赖性。在cmd中执行命令</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">poetry install
</code></pre></div><p>Poetry 会根据 <code>pyproject.toml</code> 文件中的定义自动下载和安装依赖项。</p>
<p>需要注意，有时候也可以在虚拟环境中使用</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">poetry add &#39;依赖包名&#39;
poetry remove &#39;依赖包名&#39;
</code></pre></div><p>来增加或移除依赖包</p>
<br>
<h3 id="26-使用虚拟环境">2.6 使用虚拟环境</h3>
<p>现在，您的项目已经创建并配置好了虚拟环境。您可以使用以下命令激活虚拟环境：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">poetry shell
</code></pre></div><p>一旦虚拟环境被激活，您可以在其中运行 Python 解释器和项目依赖的命令。</p>
<br>
<h3 id="27-退出虚拟环境">2.7 退出虚拟环境</h3>
<p>要退出虚拟环境，只需在虚拟环境中运行以下命令：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">exit
</code></pre></div><p>这会将您带回到全局 Python 环境。</p>
<p>以上是一个基本的 Poetry 虚拟环境的创建和使用教程。</p>
<p><br><br></p>
<h2 id="三打包python库">三、打包Python库</h2>
<p>「打包Python库」的步骤与 「创建项目环境」 有很多类似的地方</p>
<h3 id="31-创建新项目">3.1 创建新项目</h3>
<p>首先，创建一个新的 Python 库项目或使用现有的项目。确保项目的根目录中包含一个 <code>pyproject.toml</code> 文件来配置项目和依赖项。</p>
<br>
<h3 id="32-添加项目元信息">3.2 添加项目元信息</h3>
<p>在 <code>pyproject.toml</code> 文件中，确保包含了项目的元信息，包括名称、版本、作者、许可证等。以下是一个示例：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">[tool.poetry]
name = &#34;my-library&#34;
version = &#34;1.0.0&#34;
description = &#34;My Python library&#34;
authors = [&#34;Your Name &lt;your@email.com&gt;&#34;]
license = &#34;MIT&#34;
readme = &#34;README.md&#34;
</code></pre></div><p>请根据您的项目需求修改这些元信息。<br></p>
<h3 id="32-定义依赖项">3.2 定义依赖项</h3>
<p>使用 <code>[tool.poetry.dependencies]</code> 部分来定义您的库项目的依赖项。确保列出所有依赖项及其版本约束。</p>
<br>
<h3 id="33-创建库代码">3.3 创建库代码</h3>
<p>编写您的库代码并将其组织到适当的目录中。通常，库代码会位于项目根目录下的一个包目录中。<br></p>
<h3 id="34-测试您的库">3.4 测试您的库</h3>
<p>编写测试用例来验证您的库的功能。测试文件通常会位于一个独立的测试目录中，并使用测试框架（如 <code>pytest</code>）来运行测试。<br></p>
<h3 id="35-构建和验证">3.5 构建和验证</h3>
<p>在项目根目录中运行以下命令来构建您的库：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">poetry build
</code></pre></div><p>这将生成一个 dist 目录，并在其中包含库的分发文件，包括 wheel 和 sdist（源分发文件）。<br></p>
<h3 id="36-发布到-pypi">3.6 发布到 PyPI</h3>
<ol>
<li>
<p><strong>注册 PyPI 帐户</strong>：如果您还没有 PyPI 帐户，请先注册一个。</p>
</li>
<li>
<p><strong>在poetry中设置PyPi的api-token信息</strong>：首先登录PyPi， 点击Accounting settings, 如截图所示创建你的api-token。</p>
<p><img loading="lazy" src="img/api-token.png" alt=""  />
</p>
<p>在终端中运行以下命令，使用您的 PyPI 帐户登录：</p>
</li>
</ol>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">poetry config pypi-token.pypi your-api-token
</code></pre></div><p>这将要求您输入 PyPI 用户名和密码。</p>
<ol start="3">
<li><strong>发布到 PyPI</strong>：运行以下命令来发布您的库到 PyPI：</li>
</ol>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">poetry publish
</code></pre></div><p>这会自动构建您的库并将其发布到 PyPI。请注意，不要随便发布， 先检查所有代码是否能正常运行，之后再发布。</p>
<br>
<h3 id="37-分享您的库">3.7 分享您的库</h3>
<p>现在，您的库已经发布到 PyPI，其他人可以使用 <code>pip install</code> 命令来安装它。您可以分享您的库的 PyPI 链接，以便其他人找到和使用它。</p>
<p>这些步骤简要介绍了使用 Poetry 打包和发布 Python 库的过程。确保在发布之前测试您的库，并在 README.md 中提供必要的文档和示例，以帮助其他人使用您的库。</p>
<p><br><br></p>
]]></content:encoded>
    </item>
    
    <item>
      <title>Faker库 | 生成实验数据</title>
      <link>https://textdata.cn/blog/2022-11-25-faker-generate-test-data/</link>
      <pubDate>Fri, 25 Nov 2022 00:00:00 +0000</pubDate>
      
      <guid>/blog/2022-11-25-faker-generate-test-data/</guid>
      <description>生成实验数据</description>
      <content:encoded><![CDATA[


<p>有时候学习新的数据分析方法时，需要构造一些小样本的实验数据，手动构造比较麻烦，这时候可以使用<a href="https://github.com/joke2k/faker">faker库</a>。</p>
<p><br></p>
<div id="安装" class="section level2">
<h2>安装</h2>
<pre><code>pip install Faker</code></pre>
<p><br></p>
</div>
<div id="快速上手" class="section level2">
<h2>快速上手</h2>
<pre class="python"><code>from faker import Faker

#设定语言，默认生成的是英文数据
#fake = Faker()
fake = Faker(locale=&#39;zh_CN&#39;)

#伪造姓名
fake.name()</code></pre>
<pre><code>## &#39;罗辉&#39;</code></pre>
<p><br></p>
<p>生成地址数据</p>
<pre class="python"><code>fake.address()</code></pre>
<pre><code>## &#39;湖北省张家港市大东王街v座 601815&#39;</code></pre>
<p><br></p>
<p>生成公司数据</p>
<pre class="python"><code>fake.company_prefix()</code></pre>
<pre><code>## &#39;银嘉&#39;</code></pre>
<p><br></p>
</div>
<div id="自定义" class="section level2">
<h2>自定义</h2>
<p>例如生成一个工作经历的实验数据，可以自定义公司名集合，从中随机抽取。</p>
<pre class="python"><code>from faker import Faker
fake = Faker()

my_word_list = [
&#39;华为&#39;,&#39;小米&#39;,&#39;三星&#39;,
&#39;海尔&#39;,&#39;宝马&#39;,&#39;保洁&#39;,
&#39;中铁&#39;,&#39;中通&#39;,&#39;京东&#39;,
&#39;阿里&#39;,&#39;百度&#39;,&#39;腾讯&#39;]

work_experiences = fake.sentence(ext_word_list=my_word_list, nb_words=5)
work_experiences</code></pre>
<pre><code>## &#39;京东 华为 中通.&#39;</code></pre>
<p><br></p>
</div>
<div id="设定随机性" class="section level2">
<h2>设定随机性</h2>
<p>由于faker属于随机生成数据的包，如果不限定状态， 每次运行相同的代码，随机生成的数据是不一样的。</p>
<pre class="python"><code>from faker import Faker
fake = Faker(&#39;zh_CN&#39;)

#设定随机状态
Faker.seed(4321)

print(fake.name())</code></pre>
<pre><code>## 王鑫</code></pre>
<p><br></p>
<p><br></p>
</div>
<div id="广而告之" class="section level2">
<h2>广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
</div>
]]></content:encoded>
    </item>
    
    <item>
      <title>ManagementScience | 使用网络算法识别创新的颠覆性与否</title>
      <link>https://textdata.cn/blog/2022-09-07-management-science-disrupt-science-and-technology/</link>
      <pubDate>Wed, 07 Sep 2022 00:00:00 +0000</pubDate>
      
      <guid>/blog/2022-09-07-management-science-disrupt-science-and-technology/</guid>
      <description>The CD index is a new approach to finding important points in evolving networks. When applied to large-scale data sets like U.S. patent citations, the index is useful for identifying influential innovations and other features of technological change.</description>
      <content:encoded><![CDATA[


<p>颠覆式创新是一个很火的概念，在创新创业、科学学等研究中，每个专利、论文的正文中都会引用关系，而引用关系会构成一个引用网络。</p>
<p>那么创新如何从网络形态进行区分，如何计算网络节点的创新程度，本文列举两篇与此相关的论文，分别是 Management science 和 Science 。</p>
<p><br><br></p>
<div id="文献摘要" class="section level2">
<h2>文献摘要</h2>
<p><strong>Funk, Russell J., and Jason Owen-Smith. “A dynamic network measure of technological change.” <em>Management science</em> 63, no. 3 (2017): 791-817.</strong></p>
<p>该文使用网络分析方法研究技术变革，论文认为 <strong>颠覆性的新发明，通过将发明者的注意力转移到或远离这些发明所依赖的知识，来重塑相互关联的技术网络。即更广的视野或更久远的视角，往往有利于颠覆性创新的产生</strong>。<strong>基于该思路，本文开发了新发明的颠覆性与否的计算指标cdindex</strong>。我们将这些指标应用于大学研究商业化的分析，并发现 <strong>联邦研究资金推动校园产生颠覆性创新，而商业联系会有利于巩固现状的创新</strong>。通过量化新技术，我们提出的指数允许基于专利的创新研究捕捉概念上重要的现象， 这些现象无法通过既定措施检测到。该测量方法提供了支持创新、创业、技术战略、科学政策和社会网络理论研究的理论发展的经验见解。</p>
<blockquote>
<p>Abstract: This article outlines a network approach to the study of technological change. We propose that new inventions reshape networks of interlinked technologies by shifting inventors’ attention to or away from the knowledge on which those inventions build. Using this approach, we develop novel indexes of the extent to which a new invention consolidates or destabilizes existing technology streams. We apply these indexes in analyses of university research commercialization and ﬁnd that, although federal research funding pushes campuses to create inventions that are more destabilizing, deeper commercial ties lead them to produce technologies that consolidate the status quo. By quantifying the eﬀects that new technologies have on their predecessors, the indexes we propose allow patent-based studies of innovation to capture conceptually important phenomena that are not detectable with established measures. The measurement approach presented here oﬀers empirical insights that support theoretical development in studies of innovation, entrepreneurship, technology strategy, science policy, and social network theory.</p>
</blockquote>
<p><br></p>
<p><strong>Wu, Lingfei, Dashun Wang, and James A. Evans. “Large teams develop and small teams disrupt science and technology.” Nature 566, no. 7744 (2019): 378-382.</strong></p>
<p>当今科学和技术最普遍的趋势之一是各个领域的大型团队的增长，因为孤独的研究人员和小型团队的流行程度正在减少 。团队规模的增加归因于科学活动的专业化、通信技术的改进 或需要跨学科解决方案的现代问题的复杂性。团队规模的这种转变引发了一个问题，即大团队所产生的科技特征是否以及如何不同于小团队。分析了 1954-2014 年期间超过 6500 万篇论文、专利和软件产品，证明在此期间，<strong>较小的团队倾向于将拉长到更大的时间尺度，借鉴过去，用新的想法和机会来颠覆科学和技术；而较大的团队倾向于聚焦于当前流行的，完善当前现有的</strong>。不论团队大小，均对于蓬勃发展的科学技术生态至关重要，并表明，为实现这一目标，科学政策应旨在支持团队规模的多样性。</p>
<blockquote>
<p>Abstract: One of the most universal trends in science and technology today is the growth of large teams in all areas, as solitary researchers and small teams diminish in prevalence. Increases in team size have been attributed to the specialization of scientific activities,
improvements in communication technology, or the complexity
of modern problems that require interdisciplinary solutions.This shift in team size raises the question of whether and how the character of the science and technology produced by large teams differs from that of small teams. Here we analyse more than 65 million papers, patents and software products that span the period 1954–2014, and demonstrate that across this period smaller teams have tended to disrupt science and technology with new ideas and opportunities, whereas larger teams have tended to develop existing ones. Work from larger teams builds on morerecent and popular developments, and attention to their work comes
immediately. By contrast, contributions by smaller teams search more deeply into the past, are viewed as disruptive to science and technology and succeed further into the future—if at all. Observed differences between small and large teams are magnified for higherimpact work, with small teams known for disruptive work and large teams for developing work. Differences in topic and research design
account for a small part of the relationship between team size and disruption; most of the effect occurs at the level of the individual, as people move between smaller and larger teams. These results demonstrate that both small and large teams are essential to a flourishing ecology of science and technology, and suggest that, to achieve this, science policies should aim to support a diversity of team sizes.</p>
</blockquote>
<p><br><br></p>
</div>
<div id="算法对比" class="section level2">
<h2>算法对比</h2>
<p>我没阅读两篇论文，仅就颠覆性与否的计算方法和图例，感觉算法实现差不多。</p>
<div class="figure">
<img src="img/cdindex-managent_science_2017.png" alt="" />
<p class="caption">上图为2017年Management Science的插图</p>
</div>
<p><br></p>
<div class="figure">
<img src="img/disruption_nature_2019.png" alt="" />
<p class="caption">上图为2019年Nature的插图</p>
</div>
<p><br><br></p>
</div>
<div id="代码数据" class="section level2">
<h2>代码数据</h2>
<p>下面分别为Management2017和Nature2019的主页，均含数据和代码。</p>
<p><a href="http://russellfunk.org/cdindex/"><img src="img/cdindex-homepage.png" /></a></p>
<p><br></p>
<p><a href="https://lingfeiwu.github.io/smallTeams/"><img src="img/nature2019-disrupt-homepage.png" /></a></p>
<p><br><br></p>
</div>
<div id="算法实现" class="section level2">
<h2>算法实现</h2>
<p>按照时间优先原则，本文就只分享Management2017论文作者Funk, Russell开源了cdindex库 (开发语言C和Python) ，安装</p>
<p><br></p>
<pre><code>pip3 install cdindex</code></pre>
<p>将Management2017 cdindex算法图 标注为如下图， 下图中左右两个网络节点是相同的，只需构造一套节点，两套边数据即可完成实验。</p>
<p><img src="img/cdindex-managent_science_2017_demo.png" /></p>
<p><br></p>
<p>我们就直接上代码</p>
<pre class="python"><code>import cdindex
import datetime

#节点，理解为专利号或者论文doi号；同时节点有先后时间属性
vertices = [{&quot;name&quot;: &quot;x1&quot;, &quot;time&quot;: datetime.datetime(1990, 1, 1)},
           {&quot;name&quot;: &quot;x2&quot;, &quot;time&quot;: datetime.datetime(1990, 1, 1)},
           {&quot;name&quot;: &quot;x3&quot;, &quot;time&quot;: datetime.datetime(1990, 1, 1)},
           {&quot;name&quot;: &quot;x4&quot;, &quot;time&quot;: datetime.datetime(1990, 1, 1)},
        
           {&quot;name&quot;: &quot;y&quot;, &quot;time&quot;: datetime.datetime(1991, 1, 1)},
          
           {&quot;name&quot;: &quot;z1&quot;, &quot;time&quot;: datetime.datetime(1995, 1, 1)},
           {&quot;name&quot;: &quot;z2&quot;, &quot;time&quot;: datetime.datetime(1995, 1, 1)},
           {&quot;name&quot;: &quot;z3&quot;, &quot;time&quot;: datetime.datetime(1995, 1, 1)},
           {&quot;name&quot;: &quot;z4&quot;, &quot;time&quot;: datetime.datetime(1995, 1, 1)},
           {&quot;name&quot;: &quot;z5&quot;, &quot;time&quot;: datetime.datetime(1995, 1, 1)},
           {&quot;name&quot;: &quot;z6&quot;, &quot;time&quot;: datetime.datetime(1995, 1, 1)}]
           
    
#edges_1边关系
#edges_1中的y为颠覆型
edges_1 = [{&quot;source&quot;: &quot;z1&quot;, &quot;target&quot;: &quot;y&quot;},
           {&quot;source&quot;: &quot;z2&quot;, &quot;target&quot;: &quot;y&quot;},
           {&quot;source&quot;: &quot;z3&quot;, &quot;target&quot;: &quot;y&quot;},
           {&quot;source&quot;: &quot;z4&quot;, &quot;target&quot;: &quot;y&quot;},
           {&quot;source&quot;: &quot;z5&quot;, &quot;target&quot;: &quot;y&quot;},
           {&quot;source&quot;: &quot;z6&quot;, &quot;target&quot;: &quot;y&quot;},
           
           {&quot;source&quot;: &quot;y&quot;, &quot;target&quot;: &quot;x1&quot;},
           {&quot;source&quot;: &quot;y&quot;, &quot;target&quot;: &quot;x2&quot;},
           {&quot;source&quot;: &quot;y&quot;, &quot;target&quot;: &quot;x3&quot;},
           {&quot;source&quot;: &quot;y&quot;, &quot;target&quot;: &quot;x4&quot;}]


#edges_2边关系 
#edges_2中的y为巩固型
edges_2 = [{&quot;source&quot;: &quot;z1&quot;, &quot;target&quot;: &quot;y&quot;},
           {&quot;source&quot;: &quot;z2&quot;, &quot;target&quot;: &quot;y&quot;},
           {&quot;source&quot;: &quot;z3&quot;, &quot;target&quot;: &quot;y&quot;},
           {&quot;source&quot;: &quot;z4&quot;, &quot;target&quot;: &quot;y&quot;},
           {&quot;source&quot;: &quot;z5&quot;, &quot;target&quot;: &quot;y&quot;},
           {&quot;source&quot;: &quot;z6&quot;, &quot;target&quot;: &quot;y&quot;},
           
           {&quot;source&quot;: &quot;y&quot;, &quot;target&quot;: &quot;x1&quot;},
           {&quot;source&quot;: &quot;y&quot;, &quot;target&quot;: &quot;x2&quot;},
           {&quot;source&quot;: &quot;y&quot;, &quot;target&quot;: &quot;x3&quot;},
           {&quot;source&quot;: &quot;y&quot;, &quot;target&quot;: &quot;x4&quot;},
          
          {&quot;source&quot;: &quot;z1&quot;, &quot;target&quot;: &quot;x1&quot;},
          {&quot;source&quot;: &quot;z2&quot;, &quot;target&quot;: &quot;x1&quot;},
          {&quot;source&quot;: &quot;z3&quot;, &quot;target&quot;: &quot;x2&quot;},
           
          {&quot;source&quot;: &quot;z4&quot;, &quot;target&quot;: &quot;x3&quot;},
          {&quot;source&quot;: &quot;z5&quot;, &quot;target&quot;: &quot;x3&quot;},
          {&quot;source&quot;: &quot;z5&quot;, &quot;target&quot;: &quot;x4&quot;},
          {&quot;source&quot;: &quot;z6&quot;, &quot;target&quot;: &quot;x4&quot;}]



# 构建两个网络
graph1 = cdindex.Graph() #颠覆型
graph2 = cdindex.Graph() #发展型

# 添加节点
for vertex in vertices:
    graph1.add_vertex(vertex[&quot;name&quot;], cdindex.timestamp_from_datetime(vertex[&quot;time&quot;]))
    graph2.add_vertex(vertex[&quot;name&quot;], cdindex.timestamp_from_datetime(vertex[&quot;time&quot;]))

# 添加引用关系
for edge in edges_1:
    graph1.add_edge(edge[&quot;source&quot;], edge[&quot;target&quot;])
for edge in edges_2:
    graph2.add_edge(edge[&quot;source&quot;], edge[&quot;target&quot;])
    
    
#y研究发布后1825天内，引用y的论文(专利)列入网络。
t_delta = int(datetime.timedelta(days=1825).total_seconds())

#计算cdindex得分
score1 = graph1.cdindex(&quot;y&quot;, t_delta)
score2 = graph2.cdindex(&quot;y&quot;, t_delta)

print(&#39;左侧-网络中的y节点的cdinex得分: {}, 节点y 为颠覆性创新&#39;.format(score1))</code></pre>
<pre><code>## 左侧-网络中的y节点的cdinex得分: 1.0, 节点y 为颠覆性创新</code></pre>
<p><br></p>
<pre class="python"><code>print(&#39;右侧-网络中的y节点的cdinex得分: {}, 节点y 为发展性创新&#39;.format(score2))</code></pre>
<pre><code>## 右侧-网络中的y节点的cdinex得分: -1.0, 节点y 为发展性创新</code></pre>
<p><br><br></p>
</div>
<div id="cdindex" class="section level2">
<h2>cdindex</h2>
<p>对比Python的结果，与论文计算过程，完全一致。cdindex内部实现我不太熟悉，如果想了解cdindex内部实现，可前往 <a href="https://github.com/russellfunk/cdindex" class="uri">https://github.com/russellfunk/cdindex</a> 阅读cdindex库的源码。
<img src="img/cdindex-managent_science_2017.png" /></p>
</div>
]]></content:encoded>
    </item>
    
    <item>
      <title>geopy库 | 地理编码计算距离</title>
      <link>https://textdata.cn/blog/geopy_distance_calculate/</link>
      <pubDate>Thu, 28 Apr 2022 00:00:00 +0000</pubDate>
      
      <guid>/blog/geopy_distance_calculate/</guid>
      <description>地理信息数据分析，经纬度距离计算</description>
      <content:encoded><![CDATA[<h1 id="geopy">geopy</h1>
<p>geopy 是几个流行的地理编码网络服务的 Python 客户端。</p>
<p>geopy 使 Python 开发人员可以使用第三方地理编码器和其他数据源轻松定位全球地址、城市、国家和地标的坐标。</p>
<p>geopy 包括用于 <a href="https://nominatim.org/">OpenStreetMap Nominatim</a>、<a href="https://developers.google.com/maps/documentation/geocoding/">Google Geocoding API (V3)</a> 的地理编码器类和许多 其他地理编码服务。 完整列表可在 <a href="https://geopy.readthedocs.io/en/latest/#geocoders">Geocoders 文档部分</a> 上找到。 地理编码器类位于 <a href="https://github.com/geopy/geopy/tree/master/geopy/geocoders">geopy.geocoders</a>。</p>
<p>geopy 针对 CPython（版本 3.5、3.6、3.7、3.8、3.9）和 PyPy3 进行了测试。 geopy 1.x 系列还支持 CPython 2.7、3.4 和 PyPy2。</p>
<h2 id="安装">安装</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">pip3 install geopy
</code></pre></div><h2 id="geocoding">Geocoding</h2>
<p>要将查询地理定位到地址和坐标：</p>
<p>首先需要在https://www.openstreetmap.org/注册账号，注册一个app名。注册好的app名用于填充user_agent</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">geopy.geocoders</span> <span class="kn">import</span> <span class="n">Nominatim</span>

<span class="n">geolocator</span> <span class="o">=</span> <span class="n">Nominatim</span><span class="p">(</span><span class="n">user_agent</span><span class="o">=</span><span class="s2">&#34;specify_your_app_name_here&#34;</span><span class="p">)</span>
<span class="n">location</span> <span class="o">=</span> <span class="n">geolocator</span><span class="o">.</span><span class="n">geocode</span><span class="p">(</span><span class="s2">&#34;175 5th Avenue NYC&#34;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">location</span><span class="o">.</span><span class="n">address</span><span class="p">)</span>
<span class="nb">print</span><span class="p">((</span><span class="n">location</span><span class="o">.</span><span class="n">latitude</span><span class="p">,</span> <span class="n">location</span><span class="o">.</span><span class="n">longitude</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">location</span><span class="o">.</span><span class="n">raw</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">Flatiron Building, 175, 5th Avenue, Flatiron, New York, NYC, New York, ...
(40.7410861, -73.9896297241625)
{&#39;place_id&#39;: &#39;9167009604&#39;, &#39;type&#39;: &#39;attraction&#39;, ...}
</code></pre></div><p><br><br></p>
<p>为了找到地址对应的经纬度</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">geopy.geocoders</span> <span class="kn">import</span> <span class="n">Nominatim</span>

<span class="n">geolocator</span> <span class="o">=</span> <span class="n">Nominatim</span><span class="p">(</span><span class="n">user_agent</span><span class="o">=</span><span class="s2">&#34;specify_your_app_name_here&#34;</span><span class="p">)</span>
<span class="n">location</span> <span class="o">=</span> <span class="n">geolocator</span><span class="o">.</span><span class="n">reverse</span><span class="p">(</span><span class="s2">&#34;52.509669, 13.376294&#34;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">location</span><span class="o">.</span><span class="n">address</span><span class="p">)</span>
<span class="nb">print</span><span class="p">((</span><span class="n">location</span><span class="o">.</span><span class="n">latitude</span><span class="p">,</span> <span class="n">location</span><span class="o">.</span><span class="n">longitude</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">location</span><span class="o">.</span><span class="n">raw</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">Potsdamer Platz, Mitte, Berlin, 10117, Deutschland, European Union
(52.5094982, 13.3765983)
{&#39;place_id&#39;: &#39;654513&#39;, &#39;osm_type&#39;: &#39;node&#39;, ...}
</code></pre></div><p><br><br></p>
<h2 id="测量距离">测量距离</h2>
<p>Geopy 可以使用 <a href="https://en.wikipedia.org/wiki/Geodesics_on_an_ellipsoid">geodesic distance</a> 或 <a href="https://en.wikipedia.org/wiki/">great-circle distance</a> 计算两点之间的测地线距离 Great-circle_distance），默认的测地线距离可用作函数 geopy.distance.distance。</p>
<p>这是测地线距离的示例用法，采用一对 <code>(lat, lon)</code> 元组：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">geopy.distance</span> <span class="kn">import</span> <span class="n">geodesic</span>
<span class="n">newport_ri</span> <span class="o">=</span> <span class="p">(</span><span class="mf">41.49008</span><span class="p">,</span> <span class="o">-</span><span class="mf">71.312796</span><span class="p">)</span>
<span class="n">cleveland_oh</span> <span class="o">=</span> <span class="p">(</span><span class="mf">41.499498</span><span class="p">,</span> <span class="o">-</span><span class="mf">81.695391</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">geodesic</span><span class="p">(</span><span class="n">newport_ri</span><span class="p">,</span> <span class="n">cleveland_oh</span><span class="p">)</span><span class="o">.</span><span class="n">miles</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">538.390445368
</code></pre></div><br>
<p>使用great-cricle距离算法，同时采用一对 <code>(lat, lon)</code> 元组：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">geopy.distance</span> <span class="kn">import</span> <span class="n">great_circle</span>
<span class="n">newport_ri</span> <span class="o">=</span> <span class="p">(</span><span class="mf">41.49008</span><span class="p">,</span> <span class="o">-</span><span class="mf">71.312796</span><span class="p">)</span>
<span class="n">cleveland_oh</span> <span class="o">=</span> <span class="p">(</span><span class="mf">41.499498</span><span class="p">,</span> <span class="o">-</span><span class="mf">81.695391</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">great_circle</span><span class="p">(</span><span class="n">newport_ri</span><span class="p">,</span> <span class="n">cleveland_oh</span><span class="p">)</span><span class="o">.</span><span class="n">miles</span><span class="p">)</span>

</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">536.997990696
</code></pre></div><br>
<br>
]]></content:encoded>
    </item>
    
    <item>
      <title>Bloxs包 | 可在notebook中使用的交互可视化包</title>
      <link>https://textdata.cn/blog/bloxs_interactive_visualization/</link>
      <pubDate>Fri, 01 Apr 2022 00:00:00 +0000</pubDate>
      
      <guid>/blog/bloxs_interactive_visualization/</guid>
      <description>Bloxs是一个简单的 python 可交互的可视化包，可以帮助您以一种有吸引力的方式（以块形式）显示信息。 非常适合在笔记本中构建仪表板、报告和应用程序。</description>
      <content:encoded><![CDATA[<p>Bloxs是一个简单的 python 可交互的可视化包，可以帮助您以一种有吸引力的方式（以块形式）显示信息。 非常适合在笔记本中构建仪表板、报告和应用程序。</p>
<p>它适用于：Jupyter Notebook、Google Colab、Deepnote、Kaggle Notebook、<a href="https://github.com/mljar/mercury">Mercury</a>。</p>
<p><img loading="lazy" src="img/bloxs_demo.gif" alt=""  />
</p>
<br>
<h2 id="安装">安装</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">pip3 install bloxs
</code></pre></div><br>
<h2 id="快速上手">快速上手</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">from bloxs import B
B(1234, &#34;Bloxs in notebook!&#34;)
</code></pre></div><p><img loading="lazy" src="img/test_bloxs.png" alt=""  />
</p>
<br>
<h2 id="案例">案例</h2>
<table>
<thead>
<tr>
<th>Bloxs</th>
<th>Code</th>
</tr>
</thead>
<tbody>
<tr>
<td><img loading="lazy" src="img/number.png" alt=""  />
</td>
<td><code>B(1234, &quot;Bloxs in notebook!&quot;)</code></td>
</tr>
<tr>
<td><img loading="lazy" src="img/percent.png" alt=""  />
</td>
<td><code>B(1999, &quot;Percent change!&quot;, percent_change=10)</code></td>
</tr>
<tr>
<td><img loading="lazy" src="img/emojis.png" alt=""  />
</td>
<td><code>B(&quot;🎉🎉🎉&quot;, &quot;Works with emojis&quot;)</code></td>
</tr>
<tr>
<td><img loading="lazy" src="img/progress.png" alt=""  />
</td>
<td><code>B(&quot;68%&quot;, &quot;Loading progress&quot;, progress=68)</code></td>
</tr>
<tr>
<td><img loading="lazy" src="img/progress_color.png" alt=""  />
</td>
<td><code>B(&quot;68%&quot;, &quot;Loading progress&quot;, progress=68, color=&quot;green&quot;)</code> 颜色color参数可以设为&quot;blue&quot;, &ldquo;red&rdquo;, &ldquo;green&rdquo; 或十六进制表示 (例如&quot;#fa33fa&quot;)</td>
</tr>
<tr>
<td><img loading="lazy" src="img/line_chart.png" alt=""  />
</td>
<td><code>B(&quot;123&quot;, &quot;Display line chart&quot;, points=[1,4,2,3,5,6])</code></td>
</tr>
<tr>
<td><img loading="lazy" src="img/line_chart_color.png" alt=""  />
</td>
<td><code>B(&quot;123&quot;, &quot;Display line chart&quot;, points=[1,4,2,3,5,6], color=&quot;red&quot;)</code></td>
</tr>
<tr>
<td><img loading="lazy" src="img/stepped.png" alt=""  />
</td>
<td><code>B(&quot;123&quot;, &quot;Display stepped chart&quot;, points=[1,4,2,3,5,6], chart_type=&quot;stepped&quot;)</code></td>
</tr>
<tr>
<td><img loading="lazy" src="img/bar_chart.png" alt=""  />
</td>
<td><code>B(&quot;123&quot;, &quot;Display bar chart&quot;, points=[1,4,2,3,5,6], chart_type=&quot;bar&quot;)</code></td>
</tr>
<tr>
<td><img loading="lazy" src="img/bar_chart_color.png" alt=""  />
</td>
<td><code>B(&quot;123&quot;, &quot;Display bar chart&quot;, points=[1,4,2,3,5,6], chart_type=&quot;bar&quot;, color=&quot;green&quot;)</code></td>
</tr>
</tbody>
</table>
<br>
<p>可以在一行内整合多个图</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">B([
    B(1999, &#34;Percent change!&#34;, percent_change=10),
    B(&#34;🎉🎉🎉&#34;, &#34;Works with emojis&#34;),
    B(&#34;68%&#34;, &#34;Loading progress&#34;, progress=68),
    B(1234, &#34;Bloxs in notebook!&#34;)
])
</code></pre></div><p><img loading="lazy" src="img/several_bloxs_2.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">B([
    B(&#34;786&#34;, &#34;Display bar chart&#34;, points=[1,4,2,3,5,6], chart_type=&#34;bar&#34;, color=&#34;green&#34;),
    B(&#34;123&#34;, &#34;Display line chart&#34;, points=[1,4,2,3,5,6], color=&#34;red&#34;),
    B(&#34;123&#34;, &#34;Display stepped chart&#34;, points=[1,4,2,3,5,6], chart_type=&#34;stepped&#34;)
])
</code></pre></div><p><img loading="lazy" src="img/several_bloxs.png" alt=""  />
</p>
<br>
<p>如果想在自己电脑中实验上述代码，可以点击 <a href="https://deepnote.com/project/bloxs-ZNGnsap0R7ea8LeZY0uarQ/%2Fnotebook.ipynb">notebook</a> 下载。</p>
<br>
<h2 id="结合mercury用bloxs">结合Mercury用Bloxs</h2>
<p><a href="https://github.com/mljar/mercury">Mercury</a> 是一个用于将笔记本转换为交互式网络应用程序的框架。 它基于 YAML 配置将小部件添加到笔记本中。 下面展示了一个带有 bloxs 的笔记本，以及作为 Mercury 的 Web 应用程序的同一笔记本。</p>
<p><img loading="lazy" src="img/bloxs_notebook.gif" alt=""  />
</p>
<br>
<h2 id="mercury网页应用">Mercury网页应用</h2>
<p><a href="https://mercury.mljar.com/app/5">Demo</a></p>
<p><img loading="lazy" src="img/bloxs_mercury.gif" alt=""  />
</p>
<br>
<br>
]]></content:encoded>
    </item>
    
    <item>
      <title>科研绘图SciencePlots库</title>
      <link>https://textdata.cn/blog/scienceplots/</link>
      <pubDate>Tue, 23 Nov 2021 18:40:10 +0600</pubDate>
      
      <guid>/blog/scienceplots/</guid>
      <description>科研可视化绘图包</description>
      <content:encoded><![CDATA[<h2 id="代码下载">代码下载</h2>
<p><a href="https://github.com/hidadeng/DaDengAndHisPython/blob/master/SciencePlot%E7%A7%91%E7%A0%94%E7%BB%98%E5%9B%BE.zip">https://github.com/hidadeng/DaDengAndHisPython/blob/master/SciencePlot科研绘图.zip</a></p>
<h2 id="安装">安装</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python">
<span class="err">!</span><span class="n">pip3</span> <span class="n">install</span> <span class="n">SciencePlots</span>

</code></pre></div><pre><code>Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple/
Collecting SciencePlots
  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/c2/44/7b5c0ecd6f2862671a076425546f86ac540bc48c1a618a82d6faa3b26f58/SciencePlots-1.0.9.tar.gz (10 kB)
  Installing build dependencies ... [?25l/
</code></pre>
<p><strong>tips</strong>:</p>
<p>SciencePlots库需要电脑安装LaTex，其中</p>
<ul>
<li>MacOS电脑安装MacTex  <a href="https://www.tug.org/mactex/">https://www.tug.org/mactex/</a></li>
<li>Windows电脑安装MikTex  <a href="https://miktex.org/">https://miktex.org/</a></li>
</ul>
<h2 id="初始化绘图样式">初始化绘图样式</h2>
<p>在SciencePlots库中科研绘图样式都是用的science</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;science&#39;</span><span class="p">)</span>
</code></pre></div><p>当然你也可以同时设置多个样式</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">([</span><span class="s1">&#39;science&#39;</span><span class="p">,</span> <span class="s1">&#39;ieee&#39;</span><span class="p">])</span>
</code></pre></div><p>在上面的代码中， <strong>ieee</strong> 会覆盖掉 <strong>science</strong> 中的某些参数（列宽、字号等）， 以达到符合 <strong>IEEE</strong>论文的绘图要求</p>
<p>如果要临时使用某种绘图样式，科研使用如下语法</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#注意，此处是语法示例，</span>
<span class="c1">#如要运行， 请提前准备好x和y的数据</span>
<span class="k">with</span> <span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">context</span><span class="p">([</span><span class="s1">&#39;science&#39;</span><span class="p">,</span> <span class="s1">&#39;ieee&#39;</span><span class="p">]):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div><h2 id="案例">案例</h2>
<p>定义函数曲线， 准备数据</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="k">def</span> <span class="nf">function</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">p</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">x</span> <span class="o">**</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">p</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">x</span> <span class="o">**</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">p</span><span class="p">))</span>

<span class="n">pparam</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;Voltage (mV)&#39;</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;Current ($\mu$A)&#39;</span><span class="p">)</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.75</span><span class="p">,</span> <span class="mf">1.25</span><span class="p">,</span> <span class="mi">201</span><span class="p">)</span>
</code></pre></div><h3 id="science样式">science样式</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="k">with</span> <span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">context</span><span class="p">([</span><span class="s1">&#39;science&#39;</span><span class="p">]):</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">]:</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">function</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">p</span><span class="p">),</span> <span class="n">label</span><span class="o">=</span><span class="n">p</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s1">&#39;Order&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">autoscale</span><span class="p">(</span><span class="n">tight</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="o">**</span><span class="n">pparam</span><span class="p">)</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;figures/fig1.pdf&#39;</span><span class="p">)</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;figures/fig1.jpg&#39;</span><span class="p">,</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">300</span><span class="p">)</span>
</code></pre></div>
<figure >
    
        <img src="img/output_12_0.png" width="800" />
    
    
</figure>

<h3 id="scienceieee样式">science+ieee样式</h3>
<p>针对IEEE论文准备的<strong>science+ieee</strong>样式</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="k">with</span> <span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">context</span><span class="p">([</span><span class="s1">&#39;science&#39;</span><span class="p">,</span> <span class="s1">&#39;ieee&#39;</span><span class="p">]):</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">40</span><span class="p">,</span> <span class="mi">100</span><span class="p">]:</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">function</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">p</span><span class="p">),</span> <span class="n">label</span><span class="o">=</span><span class="n">p</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s1">&#39;Order&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">autoscale</span><span class="p">(</span><span class="n">tight</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="o">**</span><span class="n">pparam</span><span class="p">)</span>
    <span class="c1"># Note: $\mu$ doesn&#39;t work with Times font (used by ieee style)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;Current (\textmu A)&#39;</span><span class="p">)</span>  
    <span class="n">fig</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;figures/fig2a.pdf&#39;</span><span class="p">)</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;figures/fig2a.jpg&#39;</span><span class="p">,</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">300</span><span class="p">)</span>
</code></pre></div>
<figure >
    
        <img src="img/output_14_0.png" width="800" />
    
    
</figure>

<h3 id="sciencescatter样式">science+scatter样式</h3>
<p><strong>IEEE</strong> 要求图形以黑白打印时必须可读。 <strong>ieee</strong> 样式还可以将图形宽度设置为适合IEEE论文的一列。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="k">with</span> <span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">context</span><span class="p">([</span><span class="s1">&#39;science&#39;</span><span class="p">,</span> <span class="s1">&#39;scatter&#39;</span><span class="p">]):</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="s1">&#39;k--&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">fill_between</span><span class="p">([</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mf">2.2</span><span class="p">,</span> <span class="mf">1.8</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mf">1.8</span><span class="p">,</span> <span class="mf">2.2</span><span class="p">],</span>
                    <span class="n">color</span><span class="o">=</span><span class="s1">&#39;dodgerblue&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">7</span><span class="p">):</span>
        <span class="n">x1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
        <span class="n">y1</span> <span class="o">=</span> <span class="n">x1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">y1</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s2">&#34;$^\#$</span><span class="si">{}</span><span class="s2">&#34;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s1">&#39;Sample&#39;</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">xlbl</span> <span class="o">=</span> <span class="sa">r</span><span class="s2">&#34;$\log_</span><span class="si">{10}</span><span class="s2">\left(\frac{L_\mathrm</span><span class="si">{IR}</span><span class="s2">}{\mathrm</span><span class="si">{L}</span><span class="s2">_\odot}\right)$&#34;</span>
    <span class="n">ylbl</span> <span class="o">=</span> <span class="sa">r</span><span class="s2">&#34;$\log_</span><span class="si">{10}</span><span class="s2">\left(\frac{L_\mathrm</span><span class="si">{6.2}</span><span class="s2">}{\mathrm</span><span class="si">{L}</span><span class="s2">_\odot}\right)$&#34;</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="n">xlbl</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="n">ylbl</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">([</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;figures/fig3.pdf&#39;</span><span class="p">)</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;figures/fig3.jpg&#39;</span><span class="p">,</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">300</span><span class="p">)</span>
</code></pre></div>
<figure >
    
        <img src="img/output_16_0.png" width="800" />
    
    
</figure>

<h3 id="dark_background-sciencehigh-vis">dark_background +science+high-vis</h3>
<p>您还可以将这些样式与Matplotlib随附的其他样式结合使用。 例如，dark_background +science+high-vis样式：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="k">with</span> <span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">context</span><span class="p">([</span><span class="s1">&#39;dark_background&#39;</span><span class="p">,</span> <span class="s1">&#39;science&#39;</span><span class="p">,</span> <span class="s1">&#39;high-vis&#39;</span><span class="p">]):</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">]:</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">function</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">p</span><span class="p">),</span> <span class="n">label</span><span class="o">=</span><span class="n">p</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s1">&#39;Order&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">autoscale</span><span class="p">(</span><span class="n">tight</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="o">**</span><span class="n">pparam</span><span class="p">)</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;figures/fig5.pdf&#39;</span><span class="p">)</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;figures/fig5.jpg&#39;</span><span class="p">,</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">300</span><span class="p">)</span>
</code></pre></div>
<figure >
    
        <img src="img/output_18_0.png" width="800" />
    
    
</figure>

<br>
]]></content:encoded>
    </item>
    
  </channel>
</rss>
