<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>学术研究 on 大邓和他的PYTHON</title>
    <link>/tags/%E5%AD%A6%E6%9C%AF%E7%A0%94%E7%A9%B6/</link>
    <description>Recent content in 学术研究 on 大邓和他的PYTHON</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh</language>
    <lastBuildDate>Wed, 07 Sep 2022 00:00:00 +0000</lastBuildDate><atom:link href="/tags/%E5%AD%A6%E6%9C%AF%E7%A0%94%E7%A9%B6/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>ManagementScience | 使用网络算法识别创新的颠覆性与否</title>
      <link>https://hidadeng.github.io/blog/2022-09-07-management-science/</link>
      <pubDate>Wed, 07 Sep 2022 00:00:00 +0000</pubDate>
      
      <guid>/blog/2022-09-07-management-science/</guid>
      <description>The CD index is a new approach to finding important points in evolving networks. When applied to large-scale data sets like U.S. patent citations, the index is useful for identifying influential innovations and other features of technological change.</description>
      <content:encoded><![CDATA[


<p>颠覆式创新是一个很火的概念，在创新创业、科学学等研究中，每个专利、论文的正文中都会引用关系，而引用关系会构成一个引用网络。</p>
<p>那么创新如何从网络形态进行区分，如何计算网络节点的创新程度，本文列举两篇与此相关的论文，分别是 Management science 和 Science 。</p>
<p><br><br></p>
<div id="文献摘要" class="section level2">
<h2>文献摘要</h2>
<p><strong>Funk, Russell J., and Jason Owen-Smith. “A dynamic network measure of technological change.” <em>Management science</em> 63, no. 3 (2017): 791-817.</strong></p>
<p>该文使用网络分析方法研究技术变革，论文认为 <strong>颠覆性的新发明，通过将发明者的注意力转移到或远离这些发明所依赖的知识，来重塑相互关联的技术网络。即更广的视野或更久远的视角，往往有利于颠覆性创新的产生</strong>。<strong>基于该思路，本文开发了新发明的颠覆性与否的计算指标cdindex</strong>。我们将这些指标应用于大学研究商业化的分析，并发现 <strong>联邦研究资金推动校园产生颠覆性创新，而商业联系会有利于巩固现状的创新</strong>。通过量化新技术，我们提出的指数允许基于专利的创新研究捕捉概念上重要的现象， 这些现象无法通过既定措施检测到。该测量方法提供了支持创新、创业、技术战略、科学政策和社会网络理论研究的理论发展的经验见解。</p>
<blockquote>
<p>Abstract: This article outlines a network approach to the study of technological change. We propose that new inventions reshape networks of interlinked technologies by shifting inventors’ attention to or away from the knowledge on which those inventions build. Using this approach, we develop novel indexes of the extent to which a new invention consolidates or destabilizes existing technology streams. We apply these indexes in analyses of university research commercialization and ﬁnd that, although federal research funding pushes campuses to create inventions that are more destabilizing, deeper commercial ties lead them to produce technologies that consolidate the status quo. By quantifying the eﬀects that new technologies have on their predecessors, the indexes we propose allow patent-based studies of innovation to capture conceptually important phenomena that are not detectable with established measures. The measurement approach presented here oﬀers empirical insights that support theoretical development in studies of innovation, entrepreneurship, technology strategy, science policy, and social network theory.</p>
</blockquote>
<p><br></p>
<p><strong>Wu, Lingfei, Dashun Wang, and James A. Evans. “Large teams develop and small teams disrupt science and technology.” Nature 566, no. 7744 (2019): 378-382.</strong></p>
<p>当今科学和技术最普遍的趋势之一是各个领域的大型团队的增长，因为孤独的研究人员和小型团队的流行程度正在减少 。团队规模的增加归因于科学活动的专业化、通信技术的改进 或需要跨学科解决方案的现代问题的复杂性。团队规模的这种转变引发了一个问题，即大团队所产生的科技特征是否以及如何不同于小团队。分析了 1954-2014 年期间超过 6500 万篇论文、专利和软件产品，证明在此期间，<strong>较小的团队倾向于将拉长到更大的时间尺度，借鉴过去，用新的想法和机会来颠覆科学和技术；而较大的团队倾向于聚焦于当前流行的，完善当前现有的</strong>。不论团队大小，均对于蓬勃发展的科学技术生态至关重要，并表明，为实现这一目标，科学政策应旨在支持团队规模的多样性。</p>
<blockquote>
<p>Abstract: One of the most universal trends in science and technology today is the growth of large teams in all areas, as solitary researchers and small teams diminish in prevalence. Increases in team size have been attributed to the specialization of scientific activities,
improvements in communication technology, or the complexity
of modern problems that require interdisciplinary solutions.This shift in team size raises the question of whether and how the character of the science and technology produced by large teams differs from that of small teams. Here we analyse more than 65 million papers, patents and software products that span the period 1954–2014, and demonstrate that across this period smaller teams have tended to disrupt science and technology with new ideas and opportunities, whereas larger teams have tended to develop existing ones. Work from larger teams builds on morerecent and popular developments, and attention to their work comes
immediately. By contrast, contributions by smaller teams search more deeply into the past, are viewed as disruptive to science and technology and succeed further into the future—if at all. Observed differences between small and large teams are magnified for higherimpact work, with small teams known for disruptive work and large teams for developing work. Differences in topic and research design
account for a small part of the relationship between team size and disruption; most of the effect occurs at the level of the individual, as people move between smaller and larger teams. These results demonstrate that both small and large teams are essential to a flourishing ecology of science and technology, and suggest that, to achieve this, science policies should aim to support a diversity of team sizes.</p>
</blockquote>
<p><br><br></p>
</div>
<div id="算法对比" class="section level2">
<h2>算法对比</h2>
<p>我没阅读两篇论文，仅就颠覆性与否的计算方法和图例，感觉算法实现差不多。</p>
<div class="figure">
<img src="img/cdindex-managent_science_2017.png" alt="" />
<p class="caption">上图为2017年Management Science的插图</p>
</div>
<p><br></p>
<div class="figure">
<img src="img/disruption_nature_2019.png" alt="" />
<p class="caption">上图为2019年Nature的插图</p>
</div>
<p><br><br></p>
</div>
<div id="代码数据" class="section level2">
<h2>代码数据</h2>
<p>下面分别为Management2017和Nature2019的主页，均含数据和代码。</p>
<p><a href="http://russellfunk.org/cdindex/"><img src="img/cdindex-homepage.png" /></a></p>
<p><br></p>
<p><a href="https://lingfeiwu.github.io/smallTeams/"><img src="img/nature2019-disrupt-homepage.png" /></a></p>
<p><br><br></p>
</div>
<div id="算法实现" class="section level2">
<h2>算法实现</h2>
<p>按照时间优先原则，本文就只分享Management2017论文作者Funk, Russell开源了cdindex库 (开发语言C和Python) ，安装</p>
<p><br></p>
<pre><code>pip3 install cdindex</code></pre>
<p>将Management2017 cdindex算法图 标注为如下图， 下图中左右两个网络节点是相同的，只需构造一套节点，两套边数据即可完成实验。</p>
<p><img src="img/cdindex-managent_science_2017_demo.png" /></p>
<p><br></p>
<p>我们就直接上代码</p>
<pre class="python"><code>import cdindex
import datetime

#节点，理解为专利号或者论文doi号；同时节点有先后时间属性
vertices = [{&quot;name&quot;: &quot;x1&quot;, &quot;time&quot;: datetime.datetime(1990, 1, 1)},
           {&quot;name&quot;: &quot;x2&quot;, &quot;time&quot;: datetime.datetime(1990, 1, 1)},
           {&quot;name&quot;: &quot;x3&quot;, &quot;time&quot;: datetime.datetime(1990, 1, 1)},
           {&quot;name&quot;: &quot;x4&quot;, &quot;time&quot;: datetime.datetime(1990, 1, 1)},
        
           {&quot;name&quot;: &quot;y&quot;, &quot;time&quot;: datetime.datetime(1991, 1, 1)},
          
           {&quot;name&quot;: &quot;z1&quot;, &quot;time&quot;: datetime.datetime(1995, 1, 1)},
           {&quot;name&quot;: &quot;z2&quot;, &quot;time&quot;: datetime.datetime(1995, 1, 1)},
           {&quot;name&quot;: &quot;z3&quot;, &quot;time&quot;: datetime.datetime(1995, 1, 1)},
           {&quot;name&quot;: &quot;z4&quot;, &quot;time&quot;: datetime.datetime(1995, 1, 1)},
           {&quot;name&quot;: &quot;z5&quot;, &quot;time&quot;: datetime.datetime(1995, 1, 1)},
           {&quot;name&quot;: &quot;z6&quot;, &quot;time&quot;: datetime.datetime(1995, 1, 1)}]
           
    
#edges_1边关系
#edges_1中的y为颠覆型
edges_1 = [{&quot;source&quot;: &quot;z1&quot;, &quot;target&quot;: &quot;y&quot;},
           {&quot;source&quot;: &quot;z2&quot;, &quot;target&quot;: &quot;y&quot;},
           {&quot;source&quot;: &quot;z3&quot;, &quot;target&quot;: &quot;y&quot;},
           {&quot;source&quot;: &quot;z4&quot;, &quot;target&quot;: &quot;y&quot;},
           {&quot;source&quot;: &quot;z5&quot;, &quot;target&quot;: &quot;y&quot;},
           {&quot;source&quot;: &quot;z6&quot;, &quot;target&quot;: &quot;y&quot;},
           
           {&quot;source&quot;: &quot;y&quot;, &quot;target&quot;: &quot;x1&quot;},
           {&quot;source&quot;: &quot;y&quot;, &quot;target&quot;: &quot;x2&quot;},
           {&quot;source&quot;: &quot;y&quot;, &quot;target&quot;: &quot;x3&quot;},
           {&quot;source&quot;: &quot;y&quot;, &quot;target&quot;: &quot;x4&quot;}]


#edges_2边关系 
#edges_2中的y为巩固型
edges_2 = [{&quot;source&quot;: &quot;z1&quot;, &quot;target&quot;: &quot;y&quot;},
           {&quot;source&quot;: &quot;z2&quot;, &quot;target&quot;: &quot;y&quot;},
           {&quot;source&quot;: &quot;z3&quot;, &quot;target&quot;: &quot;y&quot;},
           {&quot;source&quot;: &quot;z4&quot;, &quot;target&quot;: &quot;y&quot;},
           {&quot;source&quot;: &quot;z5&quot;, &quot;target&quot;: &quot;y&quot;},
           {&quot;source&quot;: &quot;z6&quot;, &quot;target&quot;: &quot;y&quot;},
           
           {&quot;source&quot;: &quot;y&quot;, &quot;target&quot;: &quot;x1&quot;},
           {&quot;source&quot;: &quot;y&quot;, &quot;target&quot;: &quot;x2&quot;},
           {&quot;source&quot;: &quot;y&quot;, &quot;target&quot;: &quot;x3&quot;},
           {&quot;source&quot;: &quot;y&quot;, &quot;target&quot;: &quot;x4&quot;},
          
          {&quot;source&quot;: &quot;z1&quot;, &quot;target&quot;: &quot;x1&quot;},
          {&quot;source&quot;: &quot;z2&quot;, &quot;target&quot;: &quot;x1&quot;},
          {&quot;source&quot;: &quot;z3&quot;, &quot;target&quot;: &quot;x2&quot;},
           
          {&quot;source&quot;: &quot;z4&quot;, &quot;target&quot;: &quot;x3&quot;},
          {&quot;source&quot;: &quot;z5&quot;, &quot;target&quot;: &quot;x3&quot;},
          {&quot;source&quot;: &quot;z5&quot;, &quot;target&quot;: &quot;x4&quot;},
          {&quot;source&quot;: &quot;z6&quot;, &quot;target&quot;: &quot;x4&quot;}]



# 构建两个网络
graph1 = cdindex.Graph() #颠覆型
graph2 = cdindex.Graph() #发展型

# 添加节点
for vertex in vertices:
    graph1.add_vertex(vertex[&quot;name&quot;], cdindex.timestamp_from_datetime(vertex[&quot;time&quot;]))
    graph2.add_vertex(vertex[&quot;name&quot;], cdindex.timestamp_from_datetime(vertex[&quot;time&quot;]))

# 添加引用关系
for edge in edges_1:
    graph1.add_edge(edge[&quot;source&quot;], edge[&quot;target&quot;])
for edge in edges_2:
    graph2.add_edge(edge[&quot;source&quot;], edge[&quot;target&quot;])
    
    
#y研究发布后1825天内，引用y的论文(专利)列入网络。
t_delta = int(datetime.timedelta(days=1825).total_seconds())

#计算cdindex得分
score1 = graph1.cdindex(&quot;y&quot;, t_delta)
score2 = graph2.cdindex(&quot;y&quot;, t_delta)

print(&#39;左侧-网络中的y节点的cdinex得分: {}, 节点y 为颠覆性创新&#39;.format(score1))</code></pre>
<pre><code>## 左侧-网络中的y节点的cdinex得分: 1.0, 节点y 为颠覆性创新</code></pre>
<p><br></p>
<pre class="python"><code>print(&#39;右侧-网络中的y节点的cdinex得分: {}, 节点y 为发展性创新&#39;.format(score2))</code></pre>
<pre><code>## 右侧-网络中的y节点的cdinex得分: -1.0, 节点y 为发展性创新</code></pre>
<p><br><br></p>
</div>
<div id="cdindex" class="section level2">
<h2>cdindex</h2>
<p>对比Python的结果，与论文计算过程，完全一致。cdindex内部实现我不太熟悉，如果想了解cdindex内部实现，可前往 <a href="https://github.com/russellfunk/cdindex" class="uri">https://github.com/russellfunk/cdindex</a> 阅读cdindex库的源码。
<img src="img/cdindex-managent_science_2017.png" /></p>
</div>
]]></content:encoded>
    </item>
    
    <item>
      <title>17G数据 | 企业社会责任报告数据集</title>
      <link>https://hidadeng.github.io/blog/coporate_social_responsibility_datasets/</link>
      <pubDate>Thu, 04 Aug 2022 00:00:00 +0000</pubDate>
      
      <guid>/blog/coporate_social_responsibility_datasets/</guid>
      <description>近年来，企业社会责任（csr)已成为全球学术界研究的热点。国内外各大顶刊都先后刊登了多篇关于csr的文章，比如《企业绿色创新实践如何破解“和谐共生”难题？》（发表于管理世界）、《负责任的国际投资：ESG与中国OFDI》（发表于经济研究）、《Is my company really doing good? Factors influencing employees&amp;#39; evaluation of the authenticity of their company&amp;#39;s corporate social responsibility engagement》（发表于JBR）等。这些文章核心变量的构建大都基于对企业社会责任报告的内容分析和挖掘。比如《企业绿色创新实践如何破解“和谐共生”难题？》的被解释变量（绿色创新）以及部分解释变量（二元合法性和伦理型领导）。可见，社会责任报告对于我们研究esg至关重要。因此，接下来小编就带大家爬取深交所上市公司历年的社会责任报告，希望能够给大家带来一些帮助。</description>
      <content:encoded><![CDATA[<blockquote>
<p>作者:张延丰 哈工程在读博士</p>
</blockquote>
<p>近年来，企业社会责任（csr)已成为全球学术界研究的热点。国内外各大顶刊都先后刊登了多篇关于csr的文章，比如《企业绿色创新实践如何破解“和谐共生”难题？》（发表于管理世界）、《负责任的国际投资：ESG与中国OFDI》（发表于经济研究）、《Is my company really doing good? Factors influencing employees' evaluation of the authenticity of their company&rsquo;s corporate social responsibility engagement》（发表于JBR）等。这些文章核心变量的构建大都基于对企业社会责任报告的内容分析和挖掘。比如《企业绿色创新实践如何破解“和谐共生”难题？》的被解释变量（绿色创新）以及部分解释变量（二元合法性和伦理型领导）。可见，社会责任报告对于我们研究esg至关重要。因此，接下来小编就带大家爬取深交所上市公司历年的社会责任报告，希望能够给大家带来一些帮助。</p>
<br>
<h2 id="获取数据集">获取数据集</h2>
<p>采集4000多个pdf文件。经过数据清洗，将20G的pdf数据，汇总整理到170M的csv文件内。</p>
<p><img loading="lazy" src="img/datasets.png" alt=""  />
</p>
<p>数据整理不易，如需获取本数据集，<strong>请转发本文至朋友圈集赞满30+</strong>， 加微信【372335839】，备注【深圳ESG数据集】</p>
<img src="img/wechat.jpg" style="zoom:50%;" />
<p><br><br></p>
<h2 id="一构建网络爬虫">一、构建网络爬虫</h2>
<p>数据采集分为多个步骤</p>
<ol>
<li>找网址规律(GET or POST), 构造url参数</li>
<li>伪装请求，防止被封</li>
<li>构造csv，存储信心</li>
<li>执行整个爬虫</li>
</ol>
<h3 id="11-url">1.1 url</h3>
<p>打开X交所的 <a href="http://www.szse.cn/disclosure/listed/notice/">http://www.szse.cn/disclosure/listed/notice/</a> ，同时打开浏览器开发者工具network面板，在截图左侧输入框输入关键词 『社会责任报告』，按下回车。</p>
<p>此时开发者工具network面板出现很多网络交换信息， 点击检查发现下图</p>
<p><img loading="lazy" src="img/01-%e7%bd%91%e5%9d%80%e8%a7%84%e5%be%8b.png" alt=""  />
</p>
<p>发现该页面数据是<strong>POST</strong>请求，网址为</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">http://www.szse.cn/api/disc/announcement/annList?random=random参数
</code></pre></div><h3 id="12-headers">1.2 headers</h3>
<p>同时也能发现伪装头参数，现将两个重要信息整理为</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">url</span> <span class="o">=</span> <span class="s1">&#39;http://www.szse.cn/api/disc/announcement/annList?random=</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">())</span>

<span class="c1">#伪装头</span>
<span class="n">headers</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;Accept&#39;</span><span class="p">:</span> <span class="s1">&#39;application/json, text/javascript, */*; q=0.01&#39;</span><span class="p">,</span>
           <span class="s1">&#39;Accept-Encoding&#39;</span><span class="p">:</span> <span class="s1">&#39;gzip, deflate&#39;</span><span class="p">,</span>
           <span class="s1">&#39;Accept-Language&#39;</span><span class="p">:</span> <span class="s1">&#39;zh-CN,zh;q=0.9,en;q=0.8&#39;</span><span class="p">,</span>
           <span class="s1">&#39;Content-Type&#39;</span><span class="p">:</span> <span class="s1">&#39;application/json&#39;</span><span class="p">,</span>
           <span class="s1">&#39;Host&#39;</span><span class="p">:</span> <span class="s1">&#39;www.szse.cn&#39;</span><span class="p">,</span>
           <span class="s1">&#39;Origin&#39;</span><span class="p">:</span> <span class="s1">&#39;http://www.szse.cn&#39;</span><span class="p">,</span>
           <span class="s1">&#39;Proxy-Connection&#39;</span><span class="p">:</span> <span class="s1">&#39;close&#39;</span><span class="p">,</span>
           <span class="s1">&#39;Referer&#39;</span><span class="p">:</span> <span class="s1">&#39;http://www.szse.cn/disclosure/listed/fixed/index.html&#39;</span><span class="p">,</span>
           <span class="s1">&#39;User-Agent&#39;</span><span class="p">:</span> <span class="s1">&#39;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.132 Safari/537.36&#39;</span><span class="p">,</span>
           <span class="s1">&#39;X-Request-Type&#39;</span><span class="p">:</span> <span class="s1">&#39;ajax&#39;</span><span class="p">,</span>
           <span class="s1">&#39;X-Requested-With&#39;</span><span class="p">:</span> <span class="s1">&#39;XMLHttpRequest&#39;</span><span class="p">}</span>
</code></pre></div><h3 id="13-data参数">1.3 data参数</h3>
<p>POST请求需要构造data参数，在开发者对应于payload, 整理为Python格式</p>
<p><img loading="lazy" src="img/02-payload.png" alt=""  />
</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">
</code></pre></div><p><br><br></p>
<h3 id="14-preview">1.4 preview</h3>
<p>看到左侧渲染后的数据，同时也能在开发者工具network面板看到肉眼背后的源数据。我们使用preview预览截图再次确认网址规律没有问题。</p>
<p><img loading="lazy" src="img/03-data-preview.jpg" alt=""  />
</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">keyword</span> <span class="o">=</span> <span class="s1">&#39;社会责任报告&#39;</span>
<span class="n">page</span> <span class="o">=</span> <span class="mi">1</span>

<span class="c1">#post方法参数</span>
<span class="n">payload</span> <span class="o">=</span><span class="p">{</span><span class="s2">&#34;seDate&#34;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&#34;&#34;</span><span class="p">,</span><span class="s2">&#34;&#34;</span><span class="p">],</span>
           <span class="s2">&#34;searchKey&#34;</span><span class="p">:</span> <span class="p">[</span><span class="n">keyword</span><span class="p">],</span>
           <span class="s2">&#34;channelCode&#34;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&#34;listedNotice_disc&#34;</span><span class="p">],</span>
           <span class="s2">&#34;pageSize&#34;</span><span class="p">:</span> <span class="mi">50</span><span class="p">,</span>
           <span class="s2">&#34;pageNum&#34;</span><span class="p">:</span> <span class="n">page</span><span class="p">}</span>
</code></pre></div><h3 id="15-csv">1.5 csv</h3>
<p>现在已经把爬虫最重要的工作做完了，剩下的就是想办法构造出csv，并将数据存入csv。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#定义csv字段，存储PDF链接信息至data/esg_links.csv</span>
<span class="n">csvf</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;data/esg_links.csv&#39;</span><span class="p">,</span> <span class="s1">&#39;a+&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">,</span> <span class="n">newline</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
<span class="n">fieldnames</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;id&#39;</span><span class="p">,</span> <span class="s1">&#39;name&#39;</span><span class="p">,</span> <span class="s1">&#39;code&#39;</span><span class="p">,</span> <span class="s1">&#39;date&#39;</span><span class="p">,</span> <span class="s1">&#39;title&#39;</span><span class="p">,</span> <span class="s1">&#39;pdf_link&#39;</span><span class="p">,</span> <span class="s1">&#39;size&#39;</span><span class="p">]</span>
<span class="n">writer</span> <span class="o">=</span> <span class="n">csv</span><span class="o">.</span><span class="n">DictWriter</span><span class="p">(</span><span class="n">csvf</span><span class="p">,</span> <span class="n">fieldnames</span><span class="o">=</span><span class="n">fieldnames</span><span class="p">)</span>
<span class="n">writer</span><span class="o">.</span><span class="n">writeheader</span><span class="p">()</span>

<span class="n">test_data</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;pdf_link&#39;</span><span class="p">:</span> <span class="s1">&#39;测试pdf文件链接&#39;</span><span class="p">,</span>
             <span class="s1">&#39;code&#39;</span><span class="p">:</span> <span class="s1">&#39;测试股票代码&#39;</span><span class="p">,</span>
             <span class="s1">&#39;name&#39;</span><span class="p">:</span> <span class="s1">&#39;股票名称&#39;</span><span class="p">,</span>
             <span class="s1">&#39;title&#39;</span><span class="p">:</span> <span class="s1">&#39;报告名称&#39;</span><span class="p">,</span>
             <span class="s1">&#39;date&#39;</span><span class="p">:</span> <span class="s1">&#39;发布日期&#39;</span><span class="p">,</span>
             <span class="s1">&#39;size&#39;</span><span class="p">:</span> <span class="s1">&#39;pdf文件字节大小&#39;</span><span class="p">,</span>
             <span class="s1">&#39;id&#39;</span><span class="p">:</span> <span class="s1">&#39;数据id&#39;</span><span class="p">}</span>
             
<span class="n">writer</span><span class="o">.</span><span class="n">writerow</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span>

<span class="c1">#关闭csv</span>
<span class="n">csvf</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</code></pre></div><p><br><br></p>
<h2 id="二爬虫代码完整">二、爬虫代码(完整)</h2>
<p>当你看到本文时，该完整代码很有可能会随着网站变化而失效。不要悲伤难过， 按照爬虫思路自己diy即可。如果没有爬虫基础，学习 <a href="https://www.bilibili.com/video/BV1AE411r7ph">大邓的B站爬虫视频</a> ，</p>
<p><img loading="lazy" src="img/%e5%a4%a7%e9%82%93%e7%88%ac%e8%99%ab.jpg" alt=""  />
</p>
<p>自己懂爬虫原理diy代码，比改别人的代码来的更容易。将前面的准备工作组织起来, 就形成了下面的完整代码</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">requests</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">csv</span>

<span class="n">keyword</span> <span class="o">=</span> <span class="s2">&#34;社会责任报告&#34;</span>

<span class="c1">#定义csv字段，存储PDF链接信息至data/esg_links.csv</span>
<span class="n">csvf</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;data/esg_links.csv&#39;</span><span class="p">,</span> <span class="s1">&#39;a+&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">,</span> <span class="n">newline</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
<span class="n">fieldnames</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;id&#39;</span><span class="p">,</span> <span class="s1">&#39;name&#39;</span><span class="p">,</span> <span class="s1">&#39;code&#39;</span><span class="p">,</span> <span class="s1">&#39;date&#39;</span><span class="p">,</span> <span class="s1">&#39;title&#39;</span><span class="p">,</span> <span class="s1">&#39;pdf_link&#39;</span><span class="p">,</span> <span class="s1">&#39;size&#39;</span><span class="p">]</span>
<span class="n">writer</span> <span class="o">=</span> <span class="n">csv</span><span class="o">.</span><span class="n">DictWriter</span><span class="p">(</span><span class="n">csvf</span><span class="p">,</span> <span class="n">fieldnames</span><span class="o">=</span><span class="n">fieldnames</span><span class="p">)</span>
<span class="n">writer</span><span class="o">.</span><span class="n">writeheader</span><span class="p">()</span>

<span class="c1">#伪装头</span>
<span class="n">headers</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;Accept&#39;</span><span class="p">:</span> <span class="s1">&#39;application/json, text/javascript, */*; q=0.01&#39;</span><span class="p">,</span>
           <span class="s1">&#39;Accept-Encoding&#39;</span><span class="p">:</span> <span class="s1">&#39;gzip, deflate&#39;</span><span class="p">,</span>
           <span class="s1">&#39;Accept-Language&#39;</span><span class="p">:</span> <span class="s1">&#39;zh-CN,zh;q=0.9,en;q=0.8&#39;</span><span class="p">,</span>
           <span class="s1">&#39;Content-Type&#39;</span><span class="p">:</span> <span class="s1">&#39;application/json&#39;</span><span class="p">,</span>
           <span class="s1">&#39;Host&#39;</span><span class="p">:</span> <span class="s1">&#39;www.szse.cn&#39;</span><span class="p">,</span>
           <span class="s1">&#39;Origin&#39;</span><span class="p">:</span> <span class="s1">&#39;http://www.szse.cn&#39;</span><span class="p">,</span>
           <span class="s1">&#39;Proxy-Connection&#39;</span><span class="p">:</span> <span class="s1">&#39;close&#39;</span><span class="p">,</span>
           <span class="s1">&#39;Referer&#39;</span><span class="p">:</span> <span class="s1">&#39;http://www.szse.cn/disclosure/listed/fixed/index.html&#39;</span><span class="p">,</span>
           <span class="s1">&#39;User-Agent&#39;</span><span class="p">:</span> <span class="s1">&#39;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.132 Safari/537.36&#39;</span><span class="p">,</span>
           <span class="s1">&#39;X-Request-Type&#39;</span><span class="p">:</span> <span class="s1">&#39;ajax&#39;</span><span class="p">,</span>
           <span class="s1">&#39;X-Requested-With&#39;</span><span class="p">:</span> <span class="s1">&#39;XMLHttpRequest&#39;</span><span class="p">}</span>

<span class="n">page</span> <span class="o">=</span> <span class="mi">1</span>

<span class="c1">#post方法参数</span>
<span class="n">payload</span> <span class="o">=</span><span class="p">{</span><span class="s2">&#34;seDate&#34;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&#34;&#34;</span><span class="p">,</span><span class="s2">&#34;&#34;</span><span class="p">],</span>
           <span class="s2">&#34;searchKey&#34;</span><span class="p">:</span> <span class="p">[</span><span class="n">keyword</span><span class="p">],</span>
           <span class="s2">&#34;channelCode&#34;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&#34;listedNotice_disc&#34;</span><span class="p">],</span>
           <span class="s2">&#34;pageSize&#34;</span><span class="p">:</span> <span class="mi">50</span><span class="p">,</span>
           <span class="s2">&#34;pageNum&#34;</span><span class="p">:</span> <span class="n">page</span><span class="p">}</span>

<span class="c1">#发起请求</span>
<span class="n">url</span> <span class="o">=</span> <span class="s1">&#39;http://www.szse.cn/api/disc/announcement/annList?random=</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">())</span>
<span class="n">resp</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">post</span><span class="p">(</span><span class="n">url</span><span class="p">,</span>
                     <span class="n">headers</span><span class="o">=</span><span class="n">headers</span><span class="p">,</span>
                     <span class="n">data</span><span class="o">=</span><span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">payload</span><span class="p">))</span>

<span class="c1">#当data关键词有对应的非空列表，循环一直进行。</span>
<span class="k">while</span> <span class="n">resp</span><span class="o">.</span><span class="n">json</span><span class="p">()[</span><span class="s1">&#39;data&#39;</span><span class="p">]:</span>
    <span class="n">payload</span><span class="p">[</span><span class="s1">&#39;pageNum&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">page</span>
    <span class="n">resp</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">post</span><span class="p">(</span><span class="n">url</span><span class="p">,</span>
                     <span class="n">headers</span><span class="o">=</span><span class="n">headers</span><span class="p">,</span>
                     <span class="n">data</span><span class="o">=</span><span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">payload</span><span class="p">))</span>
    
    <span class="n">esgs</span> <span class="o">=</span> <span class="n">resp</span><span class="o">.</span><span class="n">json</span><span class="p">()[</span><span class="s1">&#39;data&#39;</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">esg</span> <span class="ow">in</span> <span class="n">esgs</span><span class="p">:</span>
        <span class="c1">#以字典样式写入csv</span>
        <span class="n">data</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;pdf_link&#39;</span><span class="p">:</span> <span class="s1">&#39;http://disc.static.szse.cn/download&#39;</span><span class="o">+</span> <span class="n">esg</span><span class="p">[</span><span class="s1">&#39;attachPath&#39;</span><span class="p">],</span>
                <span class="c1">#为防止股票代码被exel等软件识别为数字，特转为字符串，并加sz标识。</span>
                <span class="s1">&#39;code&#39;</span><span class="p">:</span> <span class="s1">&#39;sz&#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">esg</span><span class="p">[</span><span class="s1">&#39;secCode&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">]),</span> 
                <span class="s1">&#39;name&#39;</span><span class="p">:</span> <span class="n">esg</span><span class="p">[</span><span class="s1">&#39;secName&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span>
                <span class="s1">&#39;title&#39;</span><span class="p">:</span> <span class="n">esg</span><span class="p">[</span><span class="s1">&#39;title&#39;</span><span class="p">],</span>
                <span class="s1">&#39;date&#39;</span><span class="p">:</span> <span class="n">esg</span><span class="p">[</span><span class="s1">&#39;publishTime&#39;</span><span class="p">],</span>
                <span class="s1">&#39;size&#39;</span><span class="p">:</span> <span class="n">esg</span><span class="p">[</span><span class="s1">&#39;attachSize&#39;</span><span class="p">],</span>
                <span class="s1">&#39;id&#39;</span><span class="p">:</span> <span class="n">esg</span><span class="p">[</span><span class="s1">&#39;id&#39;</span><span class="p">]}</span>
        <span class="n">writer</span><span class="o">.</span><span class="n">writerow</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

    <span class="n">page</span> <span class="o">=</span> <span class="n">page</span> <span class="o">+</span> <span class="mi">1</span>
    
<span class="c1">#关闭csv</span>
<span class="n">csvf</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</code></pre></div><p><br><br></p>
<h2 id="三查看csv">三、查看csv</h2>
<p>使用pandas读取 <code>data/esg_links.csv</code>,</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;esg_links.csv&#39;</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/04-df.png" alt=""  />
</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">4392
</code></pre></div><p>一共有4392条 「企业社会责任」 的报告数据。</p>
<p><br><br></p>
<h2 id="四批量下载">四、批量下载</h2>
<p>下载就简单多了， 直接使用定义好的爬虫代码。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">requests</span>

<span class="k">def</span> <span class="nf">download</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">file</span><span class="p">):</span>
    <span class="s2">&#34;&#34;&#34;
</span><span class="s2">    下载多媒体及文件
</span><span class="s2">    url： 多媒体文件链接（结尾有文件格式名）
</span><span class="s2">    file: 存储文件的路径（结尾有文件格式名）
</span><span class="s2">    &#34;&#34;&#34;</span>
    <span class="n">resp</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
    <span class="c1">#获取到二进制数据</span>
    <span class="n">binarydata</span> <span class="o">=</span> <span class="n">resp</span><span class="o">.</span><span class="n">content</span>
    <span class="c1">#以二进制形式将数据流存入fname中</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">file</span><span class="p">,</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">binarydata</span><span class="p">)</span> 
        

<span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>

<span class="k">for</span> <span class="n">link</span><span class="p">,</span> <span class="n">title</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;pdf_link&#39;</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;title&#39;</span><span class="p">]):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">title</span><span class="p">)</span>
    <span class="n">download</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="n">link</span><span class="p">,</span> <span class="n">file</span><span class="o">=</span><span class="s1">&#39;data/</span><span class="si">{}</span><span class="s1">.pdf&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">title</span><span class="p">))</span>
    <span class="n">i</span> <span class="o">=</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">0 山河药辅：山河药辅2021年度社会责任报告
1 新 希 望：2021年企业社会责任报告（英文版）
2 天原股份：宜宾天原集团股份有限公司社会责任报告
3 五 粮 液：2021年度社会责任报告（英文版）
4 中兵红箭：2021年度社会责任报告	
......
......
148 苏宁环球：2021年社会责任报告
149 蓝色光标：2021年度企业社会责任报告
150 开尔新材：2021年度社会责任报告
151 中顺洁柔：2021年社会责任报告
......
......

4391 闽东电力：2006年度社会责任报告
4392  阳光发展：2006年度社会责任报告书
</code></pre></div><p>采集过程中，被封锁在所难免，所以记得每次停止采集的位置，在csv中删除该位置之前的数据。然后重新运行代码即可。</p>
<h3 id="注意">注意</h3>
<p>即时解决以上问题，可能遇到奇怪的问题。比如</p>
<p><img loading="lazy" src="img/07-error.png" alt=""  />
</p>
<p>检查发现相比其他几百kb的pdf，问题文件大小只有几kb。问题可能是被网站封锁或网络不稳定导致，标记好问题pdf的链接，重新批量下载一遍。</p>
<p><img loading="lazy" src="img/06-error.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="汇总至csv">汇总至csv</h2>
<p>很多企业社会责任报告是图片合成的，所以这里的pdf体积很大。将data文件夹中的4000多个pdf汇总至esg_data.csv中，能节约出电脑内存空间，也方便后续数据分析。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">pdfdocx</span> <span class="kn">import</span> <span class="n">read_pdf</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">csv</span>

<span class="n">i</span> <span class="o">=</span> <span class="mi">1</span>

<span class="c1">#新建esg_data.csv，用于存储企业社会责任报告数据</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;esg_data.csv&#39;</span><span class="p">,</span> <span class="s1">&#39;a+&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">,</span> <span class="n">newline</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">csvf</span><span class="p">:</span>
    <span class="n">fieldnames</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;id&#39;</span><span class="p">,</span> <span class="s1">&#39;name&#39;</span><span class="p">,</span> <span class="s1">&#39;code&#39;</span><span class="p">,</span> <span class="s1">&#39;date&#39;</span><span class="p">,</span> <span class="s1">&#39;title&#39;</span><span class="p">,</span> <span class="s1">&#39;pdf_link&#39;</span><span class="p">,</span> <span class="s1">&#39;size&#39;</span><span class="p">,</span> <span class="s1">&#39;report_content&#39;</span><span class="p">]</span>
    <span class="n">writer</span> <span class="o">=</span> <span class="n">csv</span><span class="o">.</span><span class="n">DictWriter</span><span class="p">(</span><span class="n">csvf</span><span class="p">,</span> <span class="n">fieldnames</span><span class="o">=</span><span class="n">fieldnames</span><span class="p">)</span>
    <span class="n">writer</span><span class="o">.</span><span class="n">writeheader</span><span class="p">()</span>

    <span class="n">files</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="s1">&#39;data&#39;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">file</span> <span class="ow">in</span> <span class="n">files</span><span class="p">:</span>
        <span class="n">record_of_df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;title&#39;</span><span class="p">]</span><span class="o">==</span><span class="n">file</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;.pdf&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">)]</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">record_of_df</span><span class="o">.</span><span class="n">to_dict</span><span class="p">()</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">file</span><span class="p">)</span>
        <span class="n">data</span><span class="p">[</span><span class="s1">&#39;report_content&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">read_pdf</span><span class="p">(</span><span class="s1">&#39;data/</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">file</span><span class="p">))</span>
        <span class="n">writer</span><span class="o">.</span><span class="n">writerow</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="n">i</span> <span class="o">=</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span>
</code></pre></div><p>最后，数据从20G的data文件夹(4000多个PDF)压缩为一个170M的esg_data.csv文件。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">esg_reports_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;esg_data.csv&#39;</span><span class="p">)</span>
<span class="n">esg_reports_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/08-esg_reports_df.png" alt=""  />
</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="nb">len</span><span class="p">(</span><span class="n">esg_reports_df</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">4346
</code></pre></div><p><br><br></p>
<h2 id="五相关文献">五、相关文献</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">[1]解学梅, &amp; 朱琪玮. (2021). 企业绿色创新实践如何破解 “和谐共生” 难题?. 管理世界, 37(1), 128-149.
[2]谢红军 &amp; 吕雪.(2022).负责任的国际投资：ESG与中国OFDI. 经济研究(03),83-99.
[3]Schaefer, S. D., Terlutter, R., &amp; Diehl, S. (2019). Is my company really doing good? Factors influencing employees&#39; evaluation of the authenticity of their company&#39;s corporate social responsibility engagement. Journal of business research, 101, 128-143.
</code></pre></div><p><br><br></p>
<h2 id="六其他广告">六、其他(广告)</h2>
<ul>
<li><a href="https://hidadeng.github.io/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://hidadeng.github.io/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://hidadeng.github.io/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
  </channel>
</rss>
