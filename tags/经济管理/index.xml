<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>经济管理 on 大邓和他的PYTHON</title>
    <link>/tags/%E7%BB%8F%E6%B5%8E%E7%AE%A1%E7%90%86/</link>
    <description>Recent content in 经济管理 on 大邓和他的PYTHON</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh</language>
    <lastBuildDate>Thu, 30 May 2024 00:00:00 +0000</lastBuildDate><atom:link href="/tags/%E7%BB%8F%E6%B5%8E%E7%AE%A1%E7%90%86/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>2023 | 文本分析在经管研究中的应用</title>
      <link>https://textdata.cn/blog/2023-11-05-xjtu-text-mining-in-ms/</link>
      <pubDate>Sun, 05 Nov 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-11-05-xjtu-text-mining-in-ms/</guid>
      <description>报告以文本分析方法为例，围绕着文本产生、作用、算法、编程四个方面展开。报告人结合自己的最新研究对大数据时代文本分析方法在管理领域的应用展开讨论，介绍文本编码常见算法，诸如词典法、文档向量化、词向量等，分享此类研究的过程和要点。Application of Text Analysis in Economics and Management Research 西安交通大学管理学院孙少龙老师。</description>
      <content:encoded><![CDATA[<h2 id="摘要">摘要</h2>
<p>从信息流视角看，使用文本数据做研究，要先确认自己研究问题中文本涉及的角色(Sender/Receiver)、了解文本作用方向(Reflect/Impact)。</p>
<p>报告以文本分析为主题，结合最新研究，对当前文本分析在管理领域的应用展开讨论，介绍文本编码常见算法，诸如词典法、文档向量化、词向量等，分享此类研究过程和要点。<br><br></p>
<h2 id="slideshttpstextdatacnblog2023-11-05-xjtu-text-mining-in-msslideshtml"><a href="https://textdata.cn/blog/2023-11-05-xjtu-text-mining-in-ms/slides.html">Slides</a></h2>
<iframe
    src="//player.bilibili.com/player.html?bvid=BV1se4y1C7MV&page=1"
    scrolling="no"
    height="500px"
    width="800px"
    frameborder="no"
    framespacing="0"
    allowfullscreen="true"
>
</iframe>

<p><br><br></p>
<h2 id="背景">背景</h2>
<p><img loading="lazy" src="img/multitudes-of-content-illustration.jpeg" alt=""  />
</p>
<p>维根特斯坦曾言“<strong>语言的界限就是思想的界限</strong>” ， 语言为代表的文本信息充斥在我们日常生活中， 信息潜移默化影响人， 人同时也在产生信息影响着这个世界。 在经管研究中，往往会涉及很多文本数据的编码。但是做研究面临两个问题:</p>
<h3 id="难题1--数据量大">难题1- 数据量大</h3>
<p>量太大，以至于废人力所能及。</p>
<p>时代发展，体现在数据上的特点就是数据大爆炸，过去做经管研究，使用访谈等研究方法，收录的文本内容，规模大多停留在M级。但是现在大数据时代，研究对象相关的文本数据，G级的数据量也是很常见的。</p>
<h3 id="难题2--格式乱">难题2- 格式乱</h3>
<p>信息存储技术发展，有应用不同场景的不同数据存储格式。数据可能是pdf、txt、docx，也可能是音频、视频等转录的文件。如果快捷整理，这也是个难点。</p>
<h3 id="难题3-难编码">难题3-难编码</h3>
<p>数据量少，可以人工阅读对数据进行理解和编码。但是当数据量大到无法处理的级别后，选择何种算法、各种算法技术的优缺点如何把握，对经管学者也是一个需要攻克的的技术难题。</p>
<p><img loading="lazy" src="img/consumer_org_society.png" alt=""  />
</p>
<p>难度大，但因为文本涉及的主体错综复杂，千丝万缕，所以可以研究很多对象。如个人、组织、社会之间的交互。</p>
<p><br><br></p>
<h2 id="编码解码理论">编码解码理论</h2>
<p>斯图亚特·霍尔在《电视话语的编码和解码》提出 <strong>编码-解码理论</strong>。该理论形成于70年代冷战时期，冷战中不两大阵营为了维护各自的社会稳定，为了在意识形态宣传中取胜，都在宣传工作中投入了重金。</p>
<p>当时的宣传工具是单向的广播模式，媒体作为统治阶级的喉舌，要将统治阶级的偏好、价值观等进行加工，生产相应意识形态内容。</p>
<p>而普罗大众，作为内容的接受者， 一成长于该特定意识形态的社会，同时又有一定的自我意识，所以对于一个宣传内容可能会有三种反应，表里都认同、表认同里不认同、表里都不认同。</p>
<p><img loading="lazy" src="img/SenderReceiver.png" alt=""  />
</p>
<h3 id="使用文本想清楚两个问题">使用文本想清楚两个问题</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">- How text reflects its Sender？
- How text impacts its Receiver？
</code></pre></div><h3 id="使用文本明晰三个角度">使用文本明晰三个角度</h3>
<p>我做的研究使用的文本数据，涉及哪些角色、作用力方向、感兴趣的内容。</p>
<ul>
<li><strong>角色</strong>: Sender or Receiver</li>
<li><strong>方向</strong>: Reflect or Impact</li>
<li><strong>内容</strong>: Sender的意识(认知、偏好、&hellip;)   vs  Receiver的意识(认知、偏好、&hellip;)</li>
</ul>
<p>下面是经管领域研究部分汇总，每个学者根据自己学科研究对象，应该能在4*4的矩阵中找到自己对应的位置</p>
<p><img loading="lazy" src="img/%e7%94%9f%e4%ba%a7%e4%b8%8e%e6%b6%88%e8%b4%b9.png" alt=""  />
</p>
<blockquote>
<p>Berger, Jonah, Ashlee Humphreys, Stephan Ludwig, Wendy W. Moe, Oded Netzer, and David A. Schweidel. &ldquo;Uniting the tribes: Using text for marketing insight.&rdquo; Journal of Marketing 84, no. 1 (2020): 1-25.</p>
</blockquote>
<p><br><br></p>
<h2 id="人工编码与机器编码">人工编码与机器编码</h2>
<p><img loading="lazy" src="img/unstructrueddata.png" alt=""  />
</p>
<p>做研究需要有干净的数据做实证分析，最为理想的是表数据，例如excel文件，每一行代表一条记录，每一列代表一个字段。编码的作用就是将非机构化的、脏乱的数据整理为干净整洁的表数据。</p>
<p>要明确编码方法的优点和缺点，在合理的适用范围使用。对于文本数据的编码，需要理解人工和机器两种编码方式的优缺点</p>
<table>
<thead>
<tr>
<th style="text-align:left"></th>
<th>分析方法</th>
<th>优点</th>
<th>缺点</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">人工编码</td>
<td>质性（扎根）</td>
<td>少量数据，深刻洞见。</td>
<td>难以应对大数据；<br/>编码标准不统一；</td>
</tr>
<tr>
<td style="text-align:left">机器编码</td>
<td>词频、向量相似度、向量距离</td>
<td>适合大规模文本挖掘<br/>编码标准是统一的;</td>
<td>需要破坏文本的结构，<br>丧失了部分信息量</td>
</tr>
</tbody>
</table>
<p><br><br></p>
<h2 id="机器编码-将文本转为数字或向量">机器编码-将文本转为数字或向量</h2>
<ul>
<li>
<p>符号法(每个词对应一个数字)</p>
<ul>
<li>词典(词频)法</li>
<li>词袋法、TF-IDF</li>
</ul>
</li>
<li>
<p>词嵌入</p>
<ul>
<li>Word2Vec</li>
<li>GloVe</li>
<li>FastText</li>
</ul>
</li>
</ul>
<p>符号法算法假设词语彼此是语义不相关的，目的是把 <strong>文本</strong> 转为某个数字或<strong>向量</strong>。</p>
<p>而词嵌入算法假设不同的词语是由n维个语义组成的线性组合，目的是把 <strong>词语</strong> 转为<strong>向量</strong>。</p>
<br>
<h3 id="符号法">符号法</h3>
<p>符号法就是数某个词或某类词的出现次数(或占比)。符合法是计算机NLP领域的专业叫法，在经管社科领域，最常见的文本分析软件<a href="https://textdata.cn/blog/liwc_python_text_mining/">LIWC</a>其实也是符号法。而LIWC全(Linguistic Inquiry and Word Count，即语义查询与词频统计。</p>
<p><img loading="lazy" src="img/analysis-process.png" alt=""  />
</p>
<h3 id="符号法的应用">符号法的应用</h3>
<table>
<thead>
<tr>
<th>概念指标</th>
<th>测量方法</th>
</tr>
</thead>
<tbody>
<tr>
<td>认真(努力)</td>
<td>测量文本中词语的个数</td>
</tr>
<tr>
<td>情感</td>
<td>使用情感词典，统计文本中正面词占比</td>
</tr>
<tr>
<td>可读性</td>
<td>文本中高难度(或专业性)词占比</td>
</tr>
<tr>
<td>客观性</td>
<td>文本中某个值的方差，如情感<br>- A<code>产品不错， 包装破损， 态度很好， 综合还是推荐大家购买!</code> [5, 1, 5, 4]<br>- B<code>产品垃圾，使用垃圾， 包装破损， 差评!!</code> [1,  1,  1,  1]<br>A的方差更大，更客观</td>
</tr>
<tr>
<td><a href="https://textdata.cn/blog/jcr_concreteness_computation/"><font color='blue'>具体性</font></a></td>
<td>使用具体性词典， 将文本中出现的具体词权重累加，除以总词数，求得具体性得分</td>
</tr>
<tr>
<td>短视主义</td>
<td>统计短视相关词在年报管理层讨论与分析中出现的占比</td>
</tr>
<tr>
<td><a href="https://textdata.cn/blog/2023-01-10-similarity_of_cental_bank_monetary_policy/"><font color='blue'>相似性(政策稳定性)</font></a></td>
<td>cosine(text_vector1, text_vector2)</td>
</tr>
<tr>
<td>&hellip;</td>
<td>&hellip;</td>
</tr>
</tbody>
</table>
<br>
<h3 id="词嵌入">词嵌入</h3>
<p>词嵌入技术有 Word2Vec、Glove，这类技术是挖掘出每个词的上下文语境，通俗的说法就是让计算机，对同样的文章数据，做千万次、上亿次完形填空。这样每个词语都有独特的上下文语义，并以n维向量形式表示，所以词嵌入也可以称之为词向量。</p>
<p><strong>向量模型有近义词相近、概念类似的平行两个特点</strong>。分别举几个例子，方便大家理解。</p>
<p>语义空间是n维，为了便于理解，将其压缩至二维空间。中学的向量大家都比较熟悉，在二维坐标中空间中，两个点的连线可以组成新的向量，相同的向量是平行的。</p>
<p>而在下图的2维语义空间中，good、best语义更接近，所以空间距离更近。同理bad、worst更近。</p>
<p>而vector(good, best)、vector(bad, worst)这两个向量均表示<code>原形-&gt;最高级</code>, 语义向量会近似平行。</p>
<p>同理， vector(good, bad)、 vector(best, worst)两个向量表示 <code>好-&gt;差</code>，语义向量也会近似平行。</p>
<p><img loading="lazy" src="img/embeddings-based.png" alt=""  />
</p>
<br>
<h3 id="词嵌入与认知">词嵌入与认知</h3>
<p>刚刚词嵌入的语义空间中的几个例子，其实就体现了语言的记忆。语义记录了使用该语言的人的记忆。不同的组织，对于同一种概念，会有不同的偏好。例如， Nature2022使用大规模语料数据训练出的词向量，发现语言中残存着人类的某些认知记忆。</p>
<p>通过构建概念词组对儿，在空间中投影，就可以挖掘出词语的在该概念中的分值。例如，使用</p>
<ul>
<li>SMALL = [small, tiny, little&hellip;]</li>
<li>BIG = [big, mega, large&hellip;]</li>
</ul>
<p>每个词都是一个n维的向量，SMALL或BIG都能计算出一个均值向量。大家记得中学的向量投影不，Nature2022就使用这个朴素的方法测量每个动物名称所蕴含的人类尺寸认知。</p>
<p><img loading="lazy" src="img/Concept_Words_Project.png" alt=""  />
</p>
<blockquote>
<p>Grand, G., Blank, I.A., Pereira, F. and Fedorenko, E., 2022. Semantic projection recovers rich human knowledge of multiple object features from word embeddings. Nature Human Behaviour, pp.1-13.</p>
</blockquote>
<br>
<h3 id="机器编码总结">机器编码总结</h3>
<p>这里做个表格对比，大家自己感受下三种技术的异同。</p>
<table>
<thead>
<tr>
<th>器编码方式</th>
<th>计算方法</th>
<th>维度类比</th>
<th>任务</th>
<th>例子</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>符号法-字典</strong>（词频）</td>
<td>数个数</td>
<td>原子</td>
<td>统计每句话里的名词个数</td>
<td>sent_num1 = 2<br>sent_num2 = 1</td>
</tr>
<tr>
<td><strong>符号法-词袋</strong></td>
<td>bag of words<br>one-hot<br>Tf-idf</td>
<td>分子</td>
<td>转化为词向量, 计算两个句子相似度。</td>
<td>vec1 = [1, 1, 1, 1, 1, 0]<br>vec2 = [0, 1, 0, 1, 0, 1]<br>similarity = cosine(vec1, vec2)</td>
</tr>
<tr>
<td><strong>词嵌入</strong></td>
<td>word2vec、<br>glove等</td>
<td>中子、质子、电子</td>
<td>词语相似度。(语义上大小相近，方向相反; 态度、偏见)</td>
<td>mom = [0.2, 0.7, 0.1]<br/>dad   = [0.3, 0.5, -0.2]</td>
</tr>
</tbody>
</table>
<p><br><br></p>
<h2 id="经管-文本分析-文献">经管-文本分析-文献</h2>
<p>在这里我把技术细分为词频、词袋、w2v建词典、w2v认知变迁四个维度，整理了经管6篇论文。大家可以阅读这6篇论文，掌握文本分析的应用场景。</p>
<table>
<thead>
<tr>
<th>文献</th>
<th>定性</th>
<th>词频</th>
<th>词袋</th>
<th>W2V建词典</th>
<th>W2V认知变迁</th>
</tr>
</thead>
<tbody>
<tr>
<td>王伟, 陈伟, 祝效国 and 王洪伟, 2016. 众筹融资成功率与语言风格的说服性&ndash;基于 Kickstarter 的实证研究. <em>管理世界</em>, (5), pp.81-98.</td>
<td>Y</td>
<td>Y</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><a href="https://textdata.cn/blog/jcr_concreteness_computation/"><font color='blue'>语言具体性如何影响顾客满意度</font></a><br>Packard, Grant, and Jonah Berger. “How concrete language shapes customer satisfaction.” <em>Journal of Consumer Research</em> 47, no. 5 (2021): 787-806.</td>
<td></td>
<td>Y</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Wang, Quan, Beibei Li, and Param Vir Singh. &ldquo;Copycats vs. original mobile apps: A machine learning copycat-detection method and empirical analysis.&rdquo; Information Systems Research 29, no. 2 (2018): 273-291.</td>
<td></td>
<td></td>
<td>Y</td>
<td></td>
<td></td>
</tr>
<tr>
<td><a href="https://textdata.cn/blog/2019-12-08-lazy-prices/"><font color='blue'>文本相似度</font></a><br>Cohen, L., Malloy, C. and Nguyen, Q., 2020. Lazy prices. <em>The Journal of Finance</em>, <em>75</em>(3), pp.1371-1415.</td>
<td></td>
<td></td>
<td>Y</td>
<td></td>
<td></td>
</tr>
<tr>
<td>胡楠,薛付婧,王昊楠. <strong>管理者短视主义</strong>影响企业长期投资吗？——基于文本分析和机器学习[J].管理世界,2021,37(05):139-156+11+19-21.</td>
<td></td>
<td></td>
<td>Y</td>
<td>Y</td>
<td></td>
</tr>
<tr>
<td><a href="https://textdata.cn/blog/2023-11-02-measure-cognitive-diversity-through-language-discursive-diversity/"><font color='blue'>计算团队的话语多样性衡量团队的认知多样性</font></a><br>Lix, Katharina, Amir Goldberg, Sameer B. Srivastava, and Melissa A. Valentine. “Aligning differences: Discursive diversity and team performance.” Management Science 68, no. 11 (2022): 8430-8448.</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>Y</td>
</tr>
</tbody>
</table>
<p><br><br></p>
<h2 id="案例">案例</h2>
<h3 id="案例1-众筹语言风格">案例1-众筹语言风格</h3>
<p>王伟, 陈伟, 祝效国 and 王洪伟, 2016. 众筹融资成功率与语言风格的说服性&ndash;基于 Kickstarter 的实证研究. <em>管理世界</em>, (5), pp.81-98.</p>
<blockquote>
<p>众筹融资效果决定着众筹平台的兴衰。 众筹行为很大程度上是由投资者的主观因素决定的，而影响主观判断的一个重要因素就是语言的说服性。 而这又是一种典型的用 户产生内容（UGC），项目发起者可以采用任意类型的语言风格对项目进行描述。 不同的语 言风格会改变投资者对项目前景的感知，进而影响他们的投资意愿。 首先，依据 Aristotle 修 辞三元组以及 Hovland 说服模型，采用扎根理论，将众筹项目的语言说服风格分为 5 类：诉诸可信、诉诸情感、诉诸逻辑、诉诸回报和诉诸夸张。</p>
<p>然后，<strong>借助文本挖掘方法，构建说服风格语料库，并对项目摘要进行分类。</strong></p>
<p>最后，建立语言说服风格对项目筹资影响的计量模型，并对 <strong>Kickstarter 平台上的 128345 个项目进行实证分析</strong>。 总体来说，由于项目性质的差异，不同 的项目类别对应于不同的最佳说服风格。</p>
</blockquote>
<p><img loading="lazy" src="img/%e4%bc%97%e7%ad%b9-%e7%a7%8d%e5%ad%90%e8%af%8d.png" alt=""  />

<img loading="lazy" src="img/%e4%bc%97%e7%ad%b9-%e6%b5%81%e7%a8%8b%e5%9b%be.png" alt=""  />
</p>
<br>
<h3 id="案例2-lazy-prices文本相似性">案例2 Lazy prices文本相似性</h3>
<p>Cohen, L., Malloy, C. and Nguyen, Q., 2020. <a href="https://textdata.cn/blog/2019-12-08-lazy-prices/">Lazy prices</a>. <em>The Journal of Finance</em>, <em>75</em>(3), pp.1371-1415.</p>
<blockquote>
<p>之前的研究认为，尽管投资者一次对包含重大变化的财务报表的发布作出了迅时反应，但随着时间的流逝，这种公告作用是会减弱的(Brown and Tucker, 2011 and Feldman et al., 2010)。这表示10-K报告会随着时间推移，信息价值大打折扣。尽管我们复现了这个事实，即与常规文件的变更没有重大的公告效应，但我们认为，前人的研究忽略了更重要部分(如MD&amp;A)对对资产价格的影响。</p>
</blockquote>
<blockquote>
<p>确切的说，<strong>并不是报告的披露效应的信息价值变低了，而是投资者越来越难以发现报告中微妙的信息变化， 比如因为报告变得越来越冗杂。投资者只有看到某些新闻后，才会逐渐意识到之前公司报告内容变化的的真正价值</strong>。</p>
<p>使用1995年-2014年所有美国公司季度和年度申报的完整历史记录，研究发现当公司对<strong>报告进行积极更改</strong>时，这种行为<strong>蕴含着</strong>公司未来运营的<strong>重要信号</strong>。</p>
<p><strong>财务报告的语言和结构的变化也对公司的未来收益产生重大影响</strong>：做空&quot;变化&quot;的公司（持有的公司，如果其报告发生变化的，做空该公司股票），买入“不变化”的公司，使用这样的投资组合策略，在2006年的每月alpha值高达1.88%的收益（每年超过22％）。报告中涉及执行官（CEO和CFO）团队的话语风格的变化，或者有关诉讼(风险部分)的话语的变化，都对投资的未来收益有重要作用。</p>
</blockquote>
<p><img loading="lazy" src="img/lazy-prices-1.png" alt=""  />

<img loading="lazy" src="img/lazy-prices-2.png" alt=""  />
</p>
<br>
<h3 id="案例3-山寨-vs-原创">案例3 山寨 vs 原创</h3>
<p>Wang, Quan, Beibei Li, and Param Vir Singh. &ldquo;Copycats vs. original mobile apps: A machine learning copycat-detection method and empirical analysis.&rdquo; Information Systems Research 29, no. 2 (2018): 273-291.</p>
<blockquote>
<p><strong>进行此类研究的主要威慑因素是缺乏一种客观的方法来识别应用程序是模仿者还是原创者。通过结合自然语言处理，潜在语义分析，基于网络的聚类和图像分析等机器学习技术，我们提出了一种将应用识别为原创app或模仿app，可检测两种模仿者的方法：欺骗性和非欺骗性。</strong></p>
<p>根据检测结果，我们进行了经济计量分析，以确定五年间在iOS App Store中发布的<strong>5,141个开发人员的10,100个动作游戏应用程序</strong>样本中，模仿app对原创app需求的影响。我们的结果表明，特定模仿者对原始应用需求的影响取决于模仿者的质量和欺骗程度。高质量的非欺骗性复制品会对原件产生负面影响。相比之下，低质量，欺骗性的模仿者正面影响了对原创app的需求。</p>
<p>结果表明，从总体上讲，模仿app对原创app需求的影响在统计上是微不足道的。<strong>我们的研究通过提供一种识别模仿app的方法</strong>，并提供模仿app对原创app需求影响的证据，为越来越多的移动应用消费文献做出了贡献。</p>
</blockquote>
<p><img loading="lazy" src="img/copycat.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>50G新闻数据集 | 含 人民日报/光明日报/参考消息/经济日报 等 60&#43; 家媒体(更新至2024.05)</title>
      <link>https://textdata.cn/blog/2023-12-14-daily-news-dataset/</link>
      <pubDate>Thu, 30 May 2024 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-12-14-daily-news-dataset/</guid>
      <description>日报数据集研究价值大， 您可从中提取丰富的指标，包括但不限于经济政策不确定性指数EPU 、 媒体关注度指数、文本相似度、情感分析。而且可训练词向量，构建新的词典，开发新的指标指数。计算机自然语言处理、经济学、管理学、新闻传播学、公共管理等领域均可使用。</description>
      <content:encoded><![CDATA[<h2 id="购买数据">购买数据</h2>
<ul>
<li>单买无优惠</li>
<li>整体打包购买， 原价 5050 元，现特价 3000 元。</li>
<li>支持开票，需要的请加微信372335839，备注【姓名-学校-专业-news】</li>
</ul>
<p><span style="font-size: 18px;color: green;">数据是虚拟产品，一经售出，不再退还！</span></p>
<br>
<h2 id="一数据用途">一、数据用途</h2>
<p>新闻报刊类数据集 可提取丰富的指标，包括但不限于 **经济政策不确定性指数 **、<strong>环境政策不确定性</strong>、 <strong>媒体关注度指数</strong>、<strong>文本相似度</strong>、<strong>情感分析</strong>。此外， 可训练词向量，开发新的概念词典。数据带时间， 参照前面指标， 依主体、日期、指标进行计算， 可构造面板数据，构建新的指标指数。因此在经济学、管理学、新闻传播学、公共管理、社会学等领域均有较高的研究价值。</p>
<p>相关参考文献</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">[1]洪永淼,刘俸奇,薛涧坡.政府与市场心理因素的经济影响及其测度[J].管理世界,2023,39(03):30-51.
[2]刘景江,郑畅然,洪永淼.机器学习如何赋能管理学研究？——国内外前沿综述和未来展望[J].管理世界,2023,39(09):191-216.
[3]张一帆,林建浩,樊嘉诚.新闻文本大数据与消费增速实时预测——基于叙事经济学的视角[J].金融研究,2023,(05):152-169.
[4]Huang, Yun, and Paul Luk. &#34;Measuring economic policy uncertainty in China.&#34; China Economic Review 59 (2020): 101367
[5]欧阳资生,陈世丽,杨希特,刘凤根,周学伟.经济政策不确定性、网络舆情与金融机构系统性风险[J].管理科学学报,2023,26(04):62-86.
[6]逯东,宋昕倍.媒体报道、上市公司年报可读性与融资约束[J].管理科学学报,2021,24(12):45-61.
[7]彭涛,黄福广,孙凌霞.经济政策不确定性与风险承担:基于风险投资的证据[J].管理科学学报,2021,24(03):98-114.
[8]庞锐.采纳与内化：多重制度压力如何影响河长制创新扩散——基于省级政府的定向配对事件史分析[J].公共管理学报,2023,20(02):25-37+165-166.
</code></pre></div><p><br><br></p>
<h2 id="二新闻报刊数据集概况">二、「新闻报刊数据集」概况</h2>
<p>本数据集，媒体源超60+家，</p>
<ul>
<li>
<p>33家国级，如 人民日报、光明日报、经济日报、人民政协报、中国青年报等</p>
</li>
<li>
<p>23个省级，如河北日报、天津日报、海南日报等</p>
</li>
<li>
<p>4个市级， 如宁波日报、青岛日报等</p>
</li>
</ul>
<p>文件格式为压缩文件csv.gz(双击可解压为csv)， 数据集总体积 50+G。</p>
<p><img loading="lazy" src="img/01-screen.jpg" alt=""  />
</p>
<h3 id="21-国级">2.1 国级</h3>
<table>
<thead>
<tr>
<th>编号</th>
<th>媒体</th>
<th>起止日期</th>
<th>所含字段</th>
<th style="text-align:left">记录数</th>
<th style="text-align:left">参考价格</th>
</tr>
</thead>
<tbody>
<tr>
<td>N100</td>
<td><a href="https://tv.cctv.com/lm/xwlb/">新闻联播</a></td>
<td>2016-02-04 ~ 2024-05-24</td>
<td>date、title、content</td>
<td style="text-align:left">44623</td>
<td style="text-align:left">50元</td>
</tr>
<tr>
<td>N101</td>
<td><a href="https://www.cankaoxiaoxi.com/#/index">参考消息</a></td>
<td>1957-03-09 ~ 2002-12-31</td>
<td>date、 title、 content</td>
<td style="text-align:left">528545</td>
<td style="text-align:left">500元</td>
</tr>
<tr>
<td>N102</td>
<td><a href="https://xh.xhby.net/pc/layout/202112/01/node_1.html">新华日报</a></td>
<td>2021-12-01 ~ 2024-05-24</td>
<td>date、 title、 content</td>
<td style="text-align:left">72515</td>
<td style="text-align:left">50元</td>
</tr>
<tr>
<td>N103</td>
<td><a href="http://paper.people.com.cn/rmrb/html/2024-05/23/nbs.D110000renmrb_01.htm">人民日报</a></td>
<td>1946-05-15 ~ 2024-05-24</td>
<td>date、 title、 content</td>
<td style="text-align:left"><strong>2025280</strong></td>
<td style="text-align:left">2000元</td>
</tr>
<tr>
<td>N104</td>
<td><a href="https://epaper.gmw.cn/gmrb/html/2008-01/01/nbs.D110000gmrb_01.htm">光明日报</a></td>
<td>1985-01-01 ~ 2024-05-24</td>
<td>date、 content</td>
<td style="text-align:left">861458</td>
<td style="text-align:left">200元</td>
</tr>
<tr>
<td>N105</td>
<td><a href="http://rmfyb.chinacourt.org/paper/html/2010-01/01/node_2.htm">人民法院报</a></td>
<td>2010-01-01 ~ 2024-05-24</td>
<td>date、 title、 content</td>
<td style="text-align:left">157167</td>
<td style="text-align:left">100元</td>
</tr>
<tr>
<td>N106</td>
<td><a href="http://dzb.rmzxb.com/rmzxbPaper/pc/layout/202101/12/node_01B.html">人民政协报</a></td>
<td>2008-01-02 ~ 2024-05-24</td>
<td>date、 content</td>
<td style="text-align:left">346525</td>
<td style="text-align:left">100元</td>
</tr>
<tr>
<td>N107</td>
<td><a href="https://zxb.ccn.com.cn/html/zxb/20100101/index.html">中国消费者报</a></td>
<td>2010-01-01 ~ 2024-05-24</td>
<td>date、 title、 content</td>
<td style="text-align:left">106170</td>
<td style="text-align:left">200元</td>
</tr>
<tr>
<td>N108</td>
<td><a href="https://epaper.cnwomen.com.cn/html/2021-01/20/nbs.D110000zgfnb_1.htm">中国妇女报</a></td>
<td>2021-01-20 ~ 2024-05-24</td>
<td>date、 title、 content</td>
<td style="text-align:left">29202</td>
<td style="text-align:left">50元</td>
</tr>
<tr>
<td>N109</td>
<td><a href="https://www.workercn.cn/papers/grrb/2014/01/01/1/page.html">工人日报</a></td>
<td>2014-01-01 ~ 2024-05-24</td>
<td>date、 title、 content</td>
<td style="text-align:left">191691</td>
<td style="text-align:left">100元</td>
</tr>
<tr>
<td>N110</td>
<td><a href="https://szb.farmer.com.cn/2011/20110101/20110101_001/20110101_001.html">农民日报</a></td>
<td>2011-01-01 ~ 2024-05-24</td>
<td>date、 title、 content</td>
<td style="text-align:left">214136</td>
<td style="text-align:left">100元</td>
</tr>
<tr>
<td>N111</td>
<td><a href="https://newspaper.jcrb.com/2022/20220101/20220101_001/20220101_001.html">检察日报</a></td>
<td>2022-01-01 ~ 2024-05-24</td>
<td>date、 title、 content</td>
<td style="text-align:left">34825</td>
<td style="text-align:left">50元</td>
</tr>
<tr>
<td>N112</td>
<td><a href="http://epaper.legaldaily.com.cn/fzrb/content/20210101/Page01TB.htm">法制日报</a></td>
<td>2021-01-01 ~ 2024-05-24</td>
<td>date、 title、 content</td>
<td style="text-align:left">59586</td>
<td style="text-align:left">50元</td>
</tr>
<tr>
<td>N113</td>
<td><a href="http://www.81.cn/szb_223187/szblb/index.html?paperName=jfjb&amp;paperDate=2018-01-01&amp;paperNumber01">解放军报</a></td>
<td>2018-01-01 ~ 2024-05-24</td>
<td>date、 title、 content</td>
<td style="text-align:left">112484</td>
<td style="text-align:left">100元</td>
</tr>
<tr>
<td>N114</td>
<td><a href="http://epaper.zgqxb.com.cn/">中国气象报</a></td>
<td>1989-01-16 ~ 2024-05-24</td>
<td>date、 title、 content</td>
<td style="text-align:left">228910</td>
<td style="text-align:left">100元</td>
</tr>
<tr>
<td>N115</td>
<td><a href="http://www.81.cn/szb_223187/gfbszblb/index.html?paperName=zggfb&amp;paperDate=2018-01-02&amp;paperNumber01">中国国防报</a></td>
<td>2018-01-02 ~ 2024-05-24</td>
<td>date、 title、 content</td>
<td style="text-align:left">29942</td>
<td style="text-align:left">50元</td>
</tr>
<tr>
<td>N116</td>
<td><a href="http://paper.people.com.cn/zgcsb/html/2019-01/07/node_2591.htm">中国城市报</a></td>
<td>2021-01-04 ~ 2024-05-20</td>
<td>date、 title、 content</td>
<td style="text-align:left">7197</td>
<td style="text-align:left">50元</td>
</tr>
<tr>
<td>N117</td>
<td><a href="http://paper.people.com.cn/zgnyb/html/2019-01/07/node_2222.htm">中国能源报</a></td>
<td>2019-01-07 ~ 2024-05-20</td>
<td>date、 title、 content</td>
<td style="text-align:left">19306</td>
<td style="text-align:left">50元</td>
</tr>
<tr>
<td>N118</td>
<td><a href="https://www.chinafilmnews.cn/Html/2019-01-16/Qpaper.html">中国电影报</a></td>
<td>2019-05-29 ~ 2024-05-22</td>
<td>date、 title、 content</td>
<td style="text-align:left">12288</td>
<td style="text-align:left">50元</td>
</tr>
<tr>
<td>N119</td>
<td><a href="http://114.118.9.73:81/zcb/epaper/">中国政府采购报</a></td>
<td>2017-11-17 ~ 2024-05-24</td>
<td>date、 title、 content</td>
<td style="text-align:left">22721</td>
<td style="text-align:left">50元</td>
</tr>
<tr>
<td>N120</td>
<td><a href="http://114.118.9.73/epaper/">中国财经报</a></td>
<td>2017-11-11 ~ 2024-05-23</td>
<td>date、 title、 content</td>
<td style="text-align:left">48131</td>
<td style="text-align:left">50元</td>
</tr>
<tr>
<td>N121</td>
<td><a href="http://www.ceh.com.cn/epaper/uniflows/html/2012/09/01/A01/default.htm">中国经济导报</a></td>
<td>2012-09-01 ~ 2024-05-23</td>
<td>date、 title、 content</td>
<td style="text-align:left">49405</td>
<td style="text-align:left">50元</td>
</tr>
<tr>
<td>N122</td>
<td><a href="https://www.chnfund.com/epaper?publishDate=2014-03-03">中国基金报</a></td>
<td>2014-03-03  ~ 2024-05-20</td>
<td>date、content</td>
<td style="text-align:left">5671</td>
<td style="text-align:left">50元</td>
</tr>
<tr>
<td>N123</td>
<td><a href="http://dz.jjckb.cn/www/pages/webpage2009/html/2015-01/05/node_2.htm">经济参考报</a></td>
<td>2015-01-05 ~ 2024-05-24</td>
<td>date、 title、 content</td>
<td style="text-align:left">90847</td>
<td style="text-align:left">100元</td>
</tr>
<tr>
<td>N124</td>
<td><a href="https://epaper.mrjjxw.com/shtml/mrjjxw/20180201/138059.shtml">每日经济新闻</a></td>
<td>2018-02-01 ~ 2024-05-24</td>
<td>date、 title、 content</td>
<td style="text-align:left">43070</td>
<td style="text-align:left">50元</td>
</tr>
<tr>
<td>N125</td>
<td><a href="http://paper.ce.cn/pc/layout/202101/01/node_01.html">经济日报</a></td>
<td>2008-01-27 ~ 2024-05-24</td>
<td>date、 content</td>
<td style="text-align:left">427386</td>
<td style="text-align:left">200元</td>
</tr>
<tr>
<td>N126</td>
<td><a href="https://www.chinatradenews.com.cn/epaper/content/2011-01/25/node_2.htm">中国贸易报</a></td>
<td>2011-01-25 ~ 2024-05-23</td>
<td>date、 title、 content</td>
<td style="text-align:left">73992</td>
<td style="text-align:left">100元</td>
</tr>
<tr>
<td>N127</td>
<td><a href="http://pc.cmrnn.com.cn/shtml/zggsb/20160105/index.shtml">中国工商报</a></td>
<td>2016-01-05 ~ 2024-05-24</td>
<td>date、 title、 content</td>
<td style="text-align:left">70673</td>
<td style="text-align:left">100元</td>
</tr>
<tr>
<td>N128</td>
<td><a href="http://dzb.cinn.cn/shtml/zggyb/20110223/index.shtml">中国工业报</a></td>
<td>2012-02-23 ~ 2024-05-24</td>
<td>date、 title、 content</td>
<td style="text-align:left">90987</td>
<td style="text-align:left">100元</td>
</tr>
<tr>
<td>N129</td>
<td><a href="http://epaper.zqcn.com.cn/content/2011-04/01/node_2.htm">中国企业报</a></td>
<td>2011-04-01 ~ 2024-05-21</td>
<td>date、 title、 content</td>
<td style="text-align:left">48290</td>
<td style="text-align:left">100元</td>
</tr>
<tr>
<td>N131</td>
<td><a href="http://paper.jyb.cn/zgjyb/html/2021-01/01/node_2.htm">中国教育报</a></td>
<td>2021-01-01 ~ 2024-05-24</td>
<td>date、 title、 content</td>
<td style="text-align:left">22383</td>
<td style="text-align:left">50元</td>
</tr>
<tr>
<td>N132</td>
<td><a href="https://zqb.cyol.com/node/2005-05/01/zgqnb.htm">中国青年报</a></td>
<td>2005-01-01 ~ 2024-05-24</td>
<td>date、 content</td>
<td style="text-align:left">327806</td>
<td style="text-align:left">200元</td>
</tr>
<tr>
<td>&hellip;</td>
<td>&hellip;</td>
<td>&hellip;</td>
<td>&hellip;</td>
<td style="text-align:left">&hellip;</td>
<td></td>
</tr>
</tbody>
</table>
<b>
<h3 id="22-省级">2.2 省级</h3>
<table>
<thead>
<tr>
<th>编号</th>
<th>媒体</th>
<th>起止日期</th>
<th>所含字段</th>
<th style="text-align:left">记录数</th>
<th style="text-align:left">价格</th>
</tr>
</thead>
<tbody>
<tr>
<td>N201</td>
<td><a href="https://bjrbdzb.bjd.com.cn/bjrb/mobile/2021/20210101/20210101_m.html">北京日报</a></td>
<td>2021-01-01 ~ 2024-05-24</td>
<td>date、 title、 content</td>
<td style="text-align:left">73810</td>
<td style="text-align:left">50元</td>
</tr>
<tr>
<td>N202</td>
<td><a href="http://epaper.tianjinwe.com/tjrb/html/2022-09/01/node_1.htm">天津日报</a></td>
<td>2022-09-01 ~ 2024-05-24</td>
<td>date、 title、 content</td>
<td style="text-align:left">41775</td>
<td style="text-align:left">50元</td>
</tr>
<tr>
<td>N203</td>
<td><a href="https://epaper.cqrb.cn/cqrb/2022-01/01/001/node.htm">重庆日报</a></td>
<td>2022-01-01 ~ 2024-05-24</td>
<td>date、 title、 content</td>
<td style="text-align:left">37255</td>
<td style="text-align:left">50元</td>
</tr>
<tr>
<td>N204</td>
<td><a href="http://epaper.sxrb.com/shtml/sxrb/20220801/index.shtml">山西日报</a></td>
<td>2022-08-01 ~ 2024-05-24</td>
<td>date、 title、 content</td>
<td style="text-align:left">35662</td>
<td style="text-align:left">50元</td>
</tr>
<tr>
<td>N205</td>
<td><a href="https://hbrb.hebnews.cn/pc/paper/layout/201801/02/node_01.html">河北日报</a></td>
<td>2018-01-02 ~ 2024-05-23</td>
<td>date、 title、 content</td>
<td style="text-align:left">141332</td>
<td style="text-align:left">50元</td>
</tr>
<tr>
<td>N206</td>
<td><a href="https://esb.sxdaily.com.cn/pc/layout/202201/01/node_01.html">陕西日报</a></td>
<td>2022-01-01 ~ 2024-05-24</td>
<td>date、 title、 content</td>
<td style="text-align:left">42831</td>
<td style="text-align:left">50元</td>
</tr>
<tr>
<td>N207</td>
<td><a href="https://epaper.scdaily.cn/shtml/scrb/20220101/index.shtml">四川日报</a></td>
<td>2022-01-01 ~ 2024-05-24</td>
<td>date、 title、 content</td>
<td style="text-align:left">30568</td>
<td style="text-align:left">50元</td>
</tr>
<tr>
<td>N208</td>
<td><a href="https://zjrb.zjol.com.cn/html/2006-01/01/node_18.htm">浙江日报</a></td>
<td><strong>2006-01-01 ~ 2024-05-24</strong></td>
<td>date、 title、 content</td>
<td style="text-align:left">444705</td>
<td style="text-align:left">100元</td>
</tr>
<tr>
<td>N209</td>
<td><a href="https://fjrb.fjdaily.com/pc/col/202304/01/node_01.html">福建日报</a></td>
<td>2023-04-01 ~ 2024-05-24</td>
<td>date、 title、 content</td>
<td style="text-align:left">21331</td>
<td style="text-align:left">50元</td>
</tr>
<tr>
<td>N210</td>
<td><a href="http://epaper.hljnews.cn/hljrb/pc/layout/202012/06/node_01.html">黑龙江日报</a></td>
<td>2020-12-06 ~ 2024-05-24</td>
<td>date、 title、 content</td>
<td style="text-align:left">44274</td>
<td style="text-align:left">50元</td>
</tr>
<tr>
<td>N211</td>
<td><a href="https://gxrb.gxrb.com.cn/?name=gxrb&amp;date=2020-01-01&amp;code=001">广西日报</a></td>
<td>2020-01-01 ~ 2024-05-24</td>
<td>date、 title、 content</td>
<td style="text-align:left">170532</td>
<td style="text-align:left">50元</td>
</tr>
<tr>
<td>N212</td>
<td><a href="https://yndaily.yunnan.cn/202105/15/node_01.html">云南日报</a></td>
<td>2021-05-15 ~ 2024-05-24</td>
<td>date、 title、 content</td>
<td style="text-align:left">59092</td>
<td style="text-align:left">50元</td>
</tr>
<tr>
<td>N213</td>
<td><a href="https://xjrb.ts.cn/xjrb/20180101/1.html">新疆日报</a></td>
<td>2018-01-01 ~ 2024-05-24</td>
<td>date、 title、 content</td>
<td style="text-align:left">88757</td>
<td style="text-align:left">50元</td>
</tr>
<tr>
<td>N214</td>
<td><a href="https://szb.northnews.cn/nmgrb/html/2017-01/01/node_1.htm">内蒙古日报</a></td>
<td>2017-01-01 ~ 2024-05-24</td>
<td>date、 title、 content</td>
<td style="text-align:left">105112</td>
<td style="text-align:left">50元</td>
</tr>
<tr>
<td>N215</td>
<td><a href="https://epaper.tibet3.com/qhrb/html/202201/01/node_1.html">青海日报</a></td>
<td>2022-01-01 ~ 2024-05-24</td>
<td>date、 title、 content</td>
<td style="text-align:left">37609</td>
<td style="text-align:left">50元</td>
</tr>
<tr>
<td>N216</td>
<td><a href="https://epaper.lnd.com.cn/lnrbepaper/pc/layout/201901/01/node_01.html">辽宁日报</a></td>
<td>2019-01-01 ~ 2024-05-24</td>
<td>date、 title、 content</td>
<td style="text-align:left">103454</td>
<td style="text-align:left">50元</td>
</tr>
<tr>
<td>N217</td>
<td><a href="http://jlrbszb.dajilin.com/pc/paper/layout/202201/01/node_01.html">吉林日报</a></td>
<td>2022-01-01 ~ 2024-05-24</td>
<td>date、 title、 content</td>
<td style="text-align:left">28373</td>
<td style="text-align:left">50元</td>
</tr>
<tr>
<td>N218</td>
<td><a href="https://epaper.hubeidaily.net/pc/column/202301/01/node_01.html">湖北日报</a></td>
<td>2023-01-01 ~ 2024-05-24</td>
<td>date、 title、 content</td>
<td style="text-align:left">26338</td>
<td style="text-align:left">50元</td>
</tr>
<tr>
<td>N219</td>
<td><a href="http://news.hndaily.cn/html/2008-03/01/node_1.htm">海南日报</a></td>
<td><strong>2008-03-01 ~ 2024-05-24</strong></td>
<td>date、 title、 content</td>
<td style="text-align:left"><strong>516119</strong></td>
<td style="text-align:left">100元</td>
</tr>
<tr>
<td>N220</td>
<td><a href="http://szb.eyesnews.cn/pc/layout/202201/01/node_01.html">贵州日报</a></td>
<td>2022-01-01 ~ 2024-05-24</td>
<td>date、 title、 content</td>
<td style="text-align:left">64168</td>
<td style="text-align:left">50元</td>
</tr>
<tr>
<td>N221</td>
<td><a href="http://epaper.jxxw.com.cn/html/2018-09/01/node_1.htm">江西新闻</a></td>
<td>2018-09-01 ~ 2024-05-24</td>
<td>date、 title、 content</td>
<td style="text-align:left">122594</td>
<td style="text-align:left">50元</td>
</tr>
<tr>
<td>N222</td>
<td><a href="https://szb.nxrb.cn/nxrb/pc/layout/202202/01/node_01.html">宁夏日报</a></td>
<td>2022-02-01 ~ 2024-05-24</td>
<td>date、 title、 content</td>
<td style="text-align:left">36418</td>
<td style="text-align:left">50元</td>
</tr>
<tr>
<td>N223</td>
<td><a href="https://szb.gansudaily.com.cn/gsrb/201801/01/col01.html">甘肃日报</a></td>
<td>2018-01-01 ~ 2022-08-31</td>
<td>date、 title、 content</td>
<td style="text-align:left">88844</td>
<td style="text-align:left">50元</td>
</tr>
<tr>
<td>&hellip;</td>
<td>&hellip;</td>
<td>&hellip;</td>
<td>&hellip;</td>
<td style="text-align:left">&hellip;</td>
<td></td>
</tr>
</tbody>
</table>
<p>覆盖时期最久的省级日报是浙江日报(2006-01-01~至今) ，其次是海南日报(2008-03-01),   点赞！！</p>
<b>
<h3 id="23-地级">2.3 地级</h3>
<table>
<thead>
<tr>
<th>编号</th>
<th>媒体</th>
<th>起止日期</th>
<th>所含字段</th>
<th style="text-align:left">记录数</th>
<th>价格</th>
</tr>
</thead>
<tbody>
<tr>
<td>N301</td>
<td><a href="https://gzdaily.dayoo.com/pc/html/2021-01/01/node_1.htm">广州日报</a></td>
<td>2022-05-29 ~ 2023-08-14</td>
<td>date、 title、 content</td>
<td style="text-align:left">33159</td>
<td>50元</td>
</tr>
<tr>
<td>N302</td>
<td><a href="http://daily.cnnb.com.cn/nbrb/html/2014-01/01/node_2.htm">宁波日报</a></td>
<td>2014-01-01 ~ 2024-03-31</td>
<td>date、 title、 content</td>
<td style="text-align:left">160124</td>
<td>100元</td>
</tr>
<tr>
<td>N303</td>
<td><a href="https://epaper.guanhai.com.cn/conpaper/qdrb/html/2022-05/29/node_1.htm">青岛日报(只能读近2年)</a></td>
<td>2022-05-29 ~ 2024-05-24</td>
<td>date、 title、 content</td>
<td style="text-align:left">30781</td>
<td>50元</td>
</tr>
<tr>
<td>N304</td>
<td><a href="http://epaper.bjnews.com.cn/html/2012-01/01/node_1.htm">新京报</a></td>
<td>2012-01-01 ~ 2024-05-24</td>
<td>date、 title、 content</td>
<td style="text-align:left">121652</td>
<td>50元</td>
</tr>
<tr>
<td>&hellip;</td>
<td>&hellip;</td>
<td>&hellip;</td>
<td>&hellip;</td>
<td style="text-align:left">&hellip;</td>
<td></td>
</tr>
</tbody>
</table>
<b>
<h3 id="24-其他">2.4 其他</h3>
<table>
<thead>
<tr>
<th>编号</th>
<th>媒体</th>
<th>起止日期</th>
<th>所含字段</th>
<th style="text-align:left">记录数</th>
<th>价格</th>
</tr>
</thead>
<tbody>
<tr>
<td>N401</td>
<td><a href="http://digitalpaper.stdaily.com/http_www.kjrb.com/kjrb/html/2021-01/04/node_2.htm">科技日报</a></td>
<td>2021-01-04 ~ 2024-05-24</td>
<td>date、 title、 content</td>
<td style="text-align:left">31421</td>
<td>50元</td>
</tr>
<tr>
<td>N402</td>
<td><a href="http://digitalpaper.stdaily.com/http_www.kjrb.com/kjwzb/html/2018-01/05/node_121.htm">科普时报</a></td>
<td>2018-01-05 ~ 2024-05-24</td>
<td>date、 title、 content</td>
<td style="text-align:left">12654</td>
<td>50元</td>
</tr>
<tr>
<td>N403</td>
<td><a href="http://dzb.xfrb.com.cn/Html/2012-01-02/Qpaper.html">消费日报</a></td>
<td>2019-10-08 ~ 2024-05-24</td>
<td>date、content</td>
<td style="text-align:left">6328</td>
<td>50元</td>
</tr>
<tr>
<td>N404</td>
<td><a href="https://www.infzm.com/">南方周末</a></td>
<td>2008-01-02 ~ 2023-05-31</td>
<td>date、 title、content</td>
<td style="text-align:left">75734</td>
<td>50元</td>
</tr>
<tr>
<td>&hellip;</td>
<td>&hellip;</td>
<td>&hellip;</td>
<td>&hellip;</td>
<td style="text-align:left">&hellip;</td>
<td></td>
</tr>
</tbody>
</table>
<p><br><br></p>
<h2 id="三实验代码">三、实验代码</h2>
<h3 id="31-数据集统计信息">3.1 数据集统计信息</h3>
<p>上述表格的基本信息是通过程序自动统计出来的， 代码如下</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">glob</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">prettytable</span> <span class="kn">import</span> <span class="n">PrettyTable</span>


<span class="n">table</span> <span class="o">=</span> <span class="n">PrettyTable</span><span class="p">()</span>
<span class="n">table</span><span class="o">.</span><span class="n">field_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&#34;编号&#34;</span><span class="p">,</span>  <span class="s2">&#34;媒体&#34;</span><span class="p">,</span>  <span class="s2">&#34;起止日期&#34;</span><span class="p">,</span> <span class="s2">&#34;所含字段&#34;</span><span class="p">,</span> <span class="s2">&#34;记录数&#34;</span><span class="p">,</span>  <span class="s2">&#34;体积&#34;</span><span class="p">]</span>

<span class="n">csvfs</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="s1">&#39;*/*.csv.gz&#39;</span><span class="p">))</span>


<span class="k">for</span> <span class="n">csvf</span> <span class="ow">in</span> <span class="n">csvfs</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">csvf</span><span class="p">)</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">csvf</span><span class="p">,</span> <span class="n">compression</span><span class="o">=</span><span class="s1">&#39;gzip&#39;</span><span class="p">)</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="o">.</span><span class="n">date</span><span class="o">!=</span><span class="s1">&#39;date&#39;</span><span class="p">]</span>
    <span class="n">df</span><span class="o">.</span><span class="n">drop_duplicates</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">df</span><span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">])</span>

    <span class="n">code</span> <span class="o">=</span> <span class="n">csvf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;/&#39;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;-&#39;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">media_name</span> <span class="o">=</span> <span class="n">csvf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;/&#39;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;-&#39;</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">start_date</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">()</span><span class="o">.</span><span class="n">strftime</span><span class="p">(</span><span class="s1">&#39;%Y-%m-</span><span class="si">%d</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">end_date</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">.</span><span class="n">strftime</span><span class="p">(</span><span class="s1">&#39;%Y-%m-</span><span class="si">%d</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">date_range</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">start_date</span><span class="si">}</span><span class="s1"> ~ </span><span class="si">{</span><span class="n">end_date</span><span class="si">}</span><span class="s1">&#39;</span>
    <span class="n">fields</span> <span class="o">=</span> <span class="s1">&#39;、 &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
    <span class="c1">#数据占用内存的体积，该体积一般小于文件体积。 </span>
    <span class="n">memeory_size</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">memory_usage</span><span class="p">(</span><span class="n">deep</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">/</span><span class="p">(</span><span class="mi">1024</span><span class="o">*</span><span class="mi">1024</span><span class="p">)</span> 
    <span class="n">memeory_size</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">memeory_size</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">table</span><span class="o">.</span><span class="n">add_row</span><span class="p">([</span><span class="n">code</span><span class="p">,</span> <span class="n">media_name</span><span class="p">,</span> <span class="n">date_range</span><span class="p">,</span> <span class="n">fields</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">),</span> <span class="nb">str</span><span class="p">(</span><span class="n">memeory_size</span><span class="p">)</span><span class="o">+</span><span class="s1">&#39; M&#39;</span><span class="p">])</span>


<span class="c1"># 打印表格</span>
<span class="nb">print</span><span class="p">(</span><span class="n">table</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">+-------+----------------+-------------------------+------------------------+---------+-----------+
|  编号 |      媒体      |         起止日期        |        所含字段        |  记录数 |    体积   |
+-------+----------------+-------------------------+------------------------+---------+-----------+
|  N100 |    新闻联播    | 2016-02-04 ~ 2024-05-24 | date、 title、 content |  44623  |  52.62 M  |
|  N101 |    参考消息    | 1957-03-09 ~ 2002-12-31 | date、 title、 content |  528545 |  649.28 M |
|  N102 |    新华日报    | 2021-12-01 ~ 2024-05-24 | date、 title、 content |  72515  |  183.75 M |
|  N103 |    人民日报    | 1946-05-15 ~ 2024-05-24 | date、 title、 content | 2025280 | 3984.24 M |
|  N104 |    光明日报    | 1985-01-01 ~ 2024-05-24 |     date、 content     |  861458 | 4038.08 M |
|  N105 |   人民法院报   | 2010-01-01 ~ 2024-05-24 | date、 title、 content |  157167 |  404.78 M |
|  N106 |   人民政协报   | 2008-01-02 ~ 2024-05-24 |     date、 content     |  346525 |  739.89 M |
|  N107 |  中国消费者报  | 2010-01-01 ~ 2024-05-24 | date、 title、 content |  106170 |  702.11 M |
|  N108 |   中国妇女报   | 2021-01-20 ~ 2024-05-24 | date、 title、 content |  29202  |  81.07 M  |
|  N109 |    工人日报    | 2014-01-01 ~ 2024-05-24 | date、 title、 content |  191691 |  375.84 M |
|  N110 |    农民日报    | 2011-01-01 ~ 2024-05-24 | date、 title、 content |  214136 | 1016.16 M |
|  N111 |    检察日报    | 2022-01-01 ~ 2024-05-24 | date、 title、 content |  34825  |  95.25 M  |
|  N112 |    法制日报    | 2021-01-01 ~ 2024-05-24 | date、 title、 content |  59586  |  198.63 M |
|  N113 |    解放军报    | 2018-01-01 ~ 2024-05-24 | date、 title、 content |  112484 |  263.91 M |
|  N114 |   中国气象报   | 1989-01-16 ~ 2024-05-24 | date、 title、 content |  228910 |  349.75 M |
|  N115 |   中国国防报   | 2018-01-02 ~ 2024-05-24 | date、 title、 content |  29942  |  61.96 M  |
|  N116 |   中国城市报   | 2021-01-04 ~ 2024-05-20 | date、 title、 content |   7197  |  27.37 M  |
|  N117 |   中国能源报   | 2019-01-07 ~ 2024-05-20 | date、 title、 content |  19306  |  57.83 M  |
|  N118 |   中国电影报   | 2019-05-29 ~ 2024-05-22 | date、 title、 content |  12288  |  36.75 M  |
|  N119 | 中国政府采购报 | 2017-11-17 ~ 2024-05-24 | date、 title、 content |  22721  |  54.94 M  |
|  N120 |   中国财经报   | 2017-11-11 ~ 2024-05-23 | date、 title、 content |  48131  |  125.61 M |
|  N121 |  中国经济导报  | 2012-09-01 ~ 2024-05-23 | date、 title、 content |  49405  |  296.83 M |
|  N122 |   中国基金报   | 2014-03-03 ~ 2024-05-20 |     date、 content     |   4376  |  24.26 M  |
| N123  |   经济参考报   | 2015-01-05 ~ 2024-05-24 | date、 title、 content |  90847  |  604.59 M |
|  N124 |  每日经济新闻  | 2018-02-01 ~ 2024-05-24 | date、 title、 content |  43070  |  162.33 M |
|  N125 |    经济日报    | 2008-01-27 ~ 2024-05-24 |     date、 content     |  427386 |  926.97 M |
|  N126 |   中国贸易报   | 2011-01-25 ~ 2024-05-23 | date、 title、 content |  73992  |  140.71 M |
|  N127 |   中国工商报   | 2016-01-05 ~ 2024-05-24 | date、 title、 content |  70673  |  128.41 M |
|  N128 |   中国工业报   | 2012-02-23 ~ 2024-05-24 | date、 title、 content |  90987  |  172.77 M |
|  N129 |   中国企业报   | 2011-04-01 ~ 2024-05-21 | date、 title、 content |  48290  |  119.78 M |
|  N131 |   中国教育报   | 2021-01-01 ~ 2024-05-24 | date、 title、 content |  22383  |  85.14 M  |
|  N132 |   中国青年报   | 2005-01-01 ~ 2024-05-24 |     date、 content     |  327806 | 1080.73 M |
|  N201 |    北京日报    | 2021-01-01 ~ 2024-05-24 | date、 title、 content |  73810  |  189.82 M |
|  N202 |    天津日报    | 2022-09-01 ~ 2024-05-24 | date、 title、 content |  41775  |  76.68 M  |
|  N203 |    重庆日报    | 2022-01-01 ~ 2024-05-24 | date、 title、 content |  37255  |  108.59 M |
|  N204 |    山西日报    | 2022-08-01 ~ 2024-05-24 | date、 title、 content |  35662  |  51.59 M  |
|  N205 |    河北日报    | 2018-01-02 ~ 2024-05-23 | date、 title、 content |  141332 |  341.24 M |
|  N206 |    陕西日报    | 2022-01-01 ~ 2024-05-24 | date、 title、 content |  42831  |  95.52 M  |
|  N207 |    四川日报    | 2022-01-01 ~ 2024-05-24 | date、 title、 content |  30568  |  72.35 M  |
|  N208 |    浙江日报    | 2006-01-01 ~ 2024-05-24 | date、 title、 content |  444705 |  830.16 M |
|  N209 |    福建日报    | 2023-04-01 ~ 2024-05-24 | date、 title、 content |  21331  |  47.97 M  |
|  N210 |   黑龙江日报   | 2020-12-06 ~ 2024-05-24 | date、 title、 content |  44274  |  99.31 M  |
|  N211 |    广西日报    | 2020-01-01 ~ 2024-05-24 | date、 title、 content |  170532 |  268.33 M |
|  N212 |    云南日报    | 2021-05-15 ~ 2024-05-24 | date、 title、 content |  59092  |  110.71 M |
|  N213 |    新疆日报    | 2018-01-01 ~ 2024-05-24 | date、 title、 content |  88757  |  207.45 M |
|  N214 |   内蒙古日报   | 2017-01-01 ~ 2024-05-24 | date、 title、 content |  105112 |  215.55 M |
|  N215 |    青海日报    | 2022-01-01 ~ 2024-05-24 | date、 title、 content |  37609  |  90.48 M  |
|  N216 |    辽宁日报    | 2019-01-01 ~ 2024-05-24 | date、 title、 content |  103454 |  179.79 M |
|  N217 |    吉林日报    | 2022-01-01 ~ 2024-05-24 | date、 title、 content |  28373  |  63.85 M  |
|  N218 |    湖北日报    | 2023-01-01 ~ 2024-05-24 | date、 title、 content |  26338  |  60.13 M  |
|  N219 |    海南日报    | 2008-03-01 ~ 2024-05-24 | date、 title、 content |  516119 |  850.93 M |
|  N220 |    贵州日报    | 2022-01-01 ~ 2024-05-24 | date、 title、 content |  64168  |  129.32 M |
|  N221 |    江西新闻    | 2018-09-01 ~ 2024-05-24 | date、 title、 content |  122594 |  232.49 M |
|  N222 |    宁夏日报    | 2022-02-01 ~ 2024-05-24 | date、 title、 content |  36418  |  77.93 M  |
|  N223 |    甘肃日报    | 2018-01-01 ~ 2022-08-31 | date、 title、 content |  88844  |  186.6 M  |
|  N301 |    广州日报    | 2022-05-29 ~ 2023-08-14 | date、 title、 content |  33159  |   75.9 M  |
|  N302 |    宁波日报    | 2014-01-01 ~ 2024-03-31 | date、 title、 content |  160124 |  305.98 M |
|  N303 |    青岛日报    | 2022-05-29 ~ 2024-05-24 | date、 title、 content |  30781  |  77.66 M  |
|  N304 |     新京报     | 2012-01-01 ~ 2024-05-24 | date、 title、 content |  121652 |  311.77 M |
|  N401 |    科技日报    | 2021-01-04 ~ 2024-05-24 | date、 title、 content |  31421  |   84.7 M  |
|  N402 |    科普时报    | 2018-01-05 ~ 2024-05-24 | date、 title、 content |  12654  |   31.1 M  |
|  N403 |    消费日报    | 2019-10-08 ~ 2024-05-24 |     date、 content     |   6321  |  94.94 M  |
|  N404 |    南方周末    | 2008-01-02 ~ 2023-05-31 | date、 title、 content |  75734  |  872.59 M |
+-------+----------------+-------------------------+------------------------+---------+-----------+
</code></pre></div><br>
<h3 id="32-查看部分数据">3.2 查看部分数据</h3>
<h4 id="321-参考消息">3.2.1 参考消息</h4>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;N101-参考消息/参考消息.csv.gz&#39;</span><span class="p">)</span>
<span class="n">memeory_size</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">memory_usage</span><span class="p">(</span><span class="n">deep</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">/</span><span class="p">(</span><span class="mi">1024</span><span class="o">*</span><span class="mi">1024</span><span class="p">)</span> 
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;数据占用内存: </span><span class="si">{</span><span class="n">memeory_size</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1"> M&#39;</span><span class="p">)</span>

<span class="n">df</span>
</code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">数据占用内存: 675.02 M
</code></pre></div><p><img loading="lazy" src="img/02-ckxx.png" alt=""  />
</p>
<br>
<h4 id="322-人民法院报">3.2.2 人民法院报</h4>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;N105-人民法院报/人民法院报.csv.gz&#39;</span><span class="p">)</span>
<span class="n">memeory_size</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">memory_usage</span><span class="p">(</span><span class="n">deep</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">/</span><span class="p">(</span><span class="mi">1024</span><span class="o">*</span><span class="mi">1024</span><span class="p">)</span> 
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;数据占用内存: </span><span class="si">{</span><span class="n">memeory_size</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1"> M&#39;</span><span class="p">)</span>
<span class="n">df</span>
</code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">数据占用内存: 413.62 M
</code></pre></div><p><img loading="lazy" src="img/03-rmfy.png" alt=""  />
</p>
<br>
<h4 id="323-中国企业报">3.2.3 中国企业报</h4>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;N129-中国企业报/中国企业报.csv.gz&#39;</span><span class="p">)</span>
<span class="n">memeory_size</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">memory_usage</span><span class="p">(</span><span class="n">deep</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">/</span><span class="p">(</span><span class="mi">1024</span><span class="o">*</span><span class="mi">1024</span><span class="p">)</span> 
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;数据占用内存: </span><span class="si">{</span><span class="n">memeory_size</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1"> M&#39;</span><span class="p">)</span>
<span class="n">df</span>
</code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">数据占用内存: 120.14 M
</code></pre></div><p><img loading="lazy" src="img/04-zgqyb.png" alt=""  />
</p>
<br>
<h4 id="325-农民日报">3.2.5 农民日报</h4>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;N219-海南日报/海南日报.csv.gz&#39;</span><span class="p">)</span>
<span class="n">memeory_size</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">memory_usage</span><span class="p">(</span><span class="n">deep</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">/</span><span class="p">(</span><span class="mi">1024</span><span class="o">*</span><span class="mi">1024</span><span class="p">)</span> 
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;数据占用内存: </span><span class="si">{</span><span class="n">memeory_size</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1"> M&#39;</span><span class="p">)</span>
<span class="n">df</span>
</code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">数据占用内存</span><span class="p">:</span> <span class="mf">452.16</span> <span class="n">M</span>
</code></pre></div><p><img loading="lazy" src="img/05-farmers.png" alt=""  />
</p>
<br>
<h4 id="326-海南日报">3.2.6 海南日报</h4>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;N219-海南日报/海南日报.csv.gz&#39;</span><span class="p">)</span>
<span class="n">memeory_size</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">memory_usage</span><span class="p">(</span><span class="n">deep</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">/</span><span class="p">(</span><span class="mi">1024</span><span class="o">*</span><span class="mi">1024</span><span class="p">)</span> 
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;数据占用内存: </span><span class="si">{</span><span class="n">memeory_size</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1"> M&#39;</span><span class="p">)</span>
<span class="n">df</span>
</code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">数据占用内存: 879.97 M
</code></pre></div><p><img loading="lazy" src="img/06-hnrb.png" alt=""  />
</p>
<br>
<br>
<h2 id="三购买数据">三、购买数据</h2>
<ul>
<li>单买无优惠</li>
<li>整体打包购买， 原价 5050 元，现特价 3000 元。</li>
<li>支持开票，需要的请加微信372335839，备注【姓名-学校-专业-news】</li>
</ul>
<p><span style="font-size: 18px;color: green;">数据是虚拟产品，一经售出，不再退还！</span></p>
<br>
<p>更多数据集，请查看 <a href="https://textdata.cn/blog/datasets_available_for_management_science/"><strong>LIST | 可供社科(经管)领域使用的数据集汇总</strong></a></p>
<p><br><br></p>
<h2 id="四相关内容">四、相关内容</h2>
<ul>
<li>
<p><a href="https://textdata.cn/blog/2023-11-17-how-handle-mega-csv-that-far-exceed-memory/">代码 | 如何处理远超电脑内存的csv文件</a></p>
</li>
<li>
<p><a href="https://textdata.cn/blog/2023-12-18-how-to-generate-panel-data-from-daily-news-dataset/"><strong>代码 | 使用「新闻数据」构造概念词提及量「面板数据」</strong></a></p>
</li>
<li>
<p><a href="https://textdata.cn/blog/2023-12-28-visualize-the-culture-change-using-people-daily-dataset/"><strong>可视化 | 人民日报语料反映七十年文化演变</strong></a></p>
</li>
<li>
<p><a href="https://textdata.cn/blog/2023-12-20-measure-china-economic-policy-uncertainty/">代码 | 使用「新闻数据」测量 「经济政策不确定性EPU」指标</a></p>
</li>
</ul>
<p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>数据集 | 2001-2023年A股上市公司年报&amp;管理层讨论与分析</title>
      <link>https://textdata.cn/blog/2023-03-23-china-a-share-market-dataset-mda-from-01-to-21/</link>
      <pubDate>Wed, 08 May 2024 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-03-23-china-a-share-market-dataset-mda-from-01-to-21/</guid>
      <description>&lt;h2 id=&#34;一数据集介绍&#34;&gt;一、数据集介绍&lt;/h2&gt;
&lt;p&gt;2001-2023年A股年报数据集，含 4 个文件，约 15G。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;- 管理层讨论与分析txt.zip
- 年报txt.zip
- A01-23.csv.gz
- mda01-23.csv.gz
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/a-mda.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;p&gt;注意&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;zip文件夹是原始数据， 解压后内部为 txt 文件。&lt;/li&gt;
&lt;li&gt;gz文件为汇总数据， 解压后是csv文件。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;二年报数据&#34;&gt;二、年报数据&lt;/h2&gt;
&lt;p&gt;2001-2023年年报数据。数据中只有year、code、text三个字段， 如果想增加诸如公司简称、行业等信息， 可以使用 &lt;a href=&#34;https://textdata.cn/blog/2024-04-16-china-listed-company-information-dataset/&#34;&gt;&lt;strong&gt;数据集 | A股上市公司基本信息&lt;/strong&gt;&lt;/a&gt;   进行并表。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pandas&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pd&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;anual_report_df&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read_csv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;A01-23.csv.gz&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;compression&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;gzip&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;anual_report_df&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/df1.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;p&gt;年报记录数&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;anual_report_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;61980
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;p&gt;上市公司总数&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;anual_report_df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;code&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;nunique&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;5629
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;br&gt;
&lt;h2 id=&#34;三mda数据&#34;&gt;三、MD&amp;amp;A数据&lt;/h2&gt;
&lt;p&gt;2001-2023年MD&amp;amp;A数据， 数据中只有year、code、text三个字段， 如果想增加诸如公司简称、行业等信息， 可以使用 &lt;a href=&#34;https://textdata.cn/blog/2024-04-16-china-listed-company-information-dataset/&#34;&gt;&lt;strong&gt;数据集 | A股上市公司基本信息&lt;/strong&gt;&lt;/a&gt;   进行并表。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;mda_df&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read_csv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;mda01-23.csv.gz&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;compression&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;gzip&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;mda_df&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/df2.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mda_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;60079
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;p&gt;上市公司总数&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;mda_df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;code&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;nunique&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;5606
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;四说明&#34;&gt;四、说明&lt;/h2&gt;
&lt;p&gt;从代码运行发现， md&amp;amp;a记录量少于年报记录量。这是由于 mda01-23.csv.gz 是从 A01-23.csv.gz 中生成的， 由于上市公司的年报不是一套模板生成的， 每个公司模板不同，甚至每个公司前后年度报告的排版也会发生变化。在编程提取md&amp;amp;a的过程中， 会因排版规则不能穷举， 导致md&amp;amp;a样本量略微小于年报的样本量。 提取md&amp;amp;a的工具是 &lt;a href=&#34;https://textdata.cn/blog/2024-04-27-cntext2x-tutorial/&#34;&gt;大邓开发的cntext2.1.1库&lt;/a&gt; ，使用的内置函数 &lt;code&gt;mda=ct.extract_mda(text) &lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;我们这里不展示提取过程，仅展示说明md&amp;amp;a记录量与年报记录量之比。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;anual_report_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;year&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;anual_report_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;year&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;astype&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;int&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;mda_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;year&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;mda_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;year&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;astype&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;int&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;

&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;查看每年mda记录量与年报记录量之比&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;year&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;range&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2001&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2024&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;mda_record_num&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mda_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mda_df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;year&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;==&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;year&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;anual_report_record_num&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;anual_report_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;anual_report_df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;year&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;==&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;year&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
    &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;sa&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;year&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt; :&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;mda_record_num&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;anual_report_record_num&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;查看每年mda记录量与年报记录量之比
2001 : 0.6546700942587832
2002 : 0.8569105691056911
2003 : 0.9287925696594427
2004 : 0.9550398839738942
2005 : 0.9707602339181286
2006 : 0.9745879120879121
2007 : 0.9821882951653944
2008 : 0.9846153846153847
2009 : 0.9859075535512966
2010 : 0.9868544600938968
2011 : 0.9894291754756871
2012 : 0.9891696750902527
2013 : 0.9901458415451321
2014 : 0.9905767056162834
2015 : 0.9922616953921913
2016 : 0.9926681542875359
2017 : 0.9934528892684316
2018 : 0.9892384105960265
2019 : 0.9639227642276422
2020 : 0.9642857142857143
2021 : 0.9310064935064936
2022 : 0.9838492597577388
2023 : 0.9901137847416527
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;五相关内容&#34;&gt;五、相关内容&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/2024-01-21-hk-stock-market-anual-report/&#34;&gt;&lt;strong&gt;数据集 | 港股年报文本数据集(2007 ~ 2023.12)&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/2024-01-18-neeq-china-listed-on-nation-equities-exchange-and-quotation-system-anunal-year-report/&#34;&gt;&lt;strong&gt;数据集(付费) | 三板上市公司年报2002-2023.12&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/2024-01-14-usa-sec-10k-report-dataset/&#34;&gt;&lt;strong&gt;数据集 | 美股年报10-K、20-F数据(2000-2023.12)&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/2023-03-24-load-w2v-and-expand-your-concpet-dicitonary/&#34;&gt;&lt;strong&gt;词向量(付费) | 使用MD&amp;amp;A2001-2022语料训练Word2Vec模型&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/2023-01-06-mda_informative_content/&#34;&gt;中国工业经济 | MD&amp;amp;A信息含量指标构建代码实现&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/2023-01-13-information-content-of-critical-audit/&#34;&gt;金融研究 | 使用Python构建「关键审计事项信息含量」&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/2023-09-08-earnings-communication-conference-forward-looking-statements-information/&#34;&gt;中国管理科学 | 使用业绩说明会文本数据测量上市公司前瞻性信息&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/2024-04-25-firm-economic-policy-uncertainty/&#34;&gt;代码 | 使用 MD&amp;amp;A文本测量「企业不确定性感知FEPU」&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/2024-04-16-china-listed-company-information-dataset/&#34;&gt;&lt;strong&gt;数据集 | A股上市公司基本信息&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;六获取数据&#34;&gt;六、获取数据&lt;/h2&gt;
&lt;p&gt;数据集 100 元，&lt;strong&gt;加微信 372335839， 备注「姓名-学校-专业」&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;广而告之&#34;&gt;广而告之&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/call_for_paper/&#34;&gt;长期征稿&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/we_need_you/&#34;&gt;长期招募小伙伴&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/management_python_course/&#34;&gt;付费视频课 | Python实证指标构建与文本分析&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
      <content:encoded><![CDATA[<h2 id="一数据集介绍">一、数据集介绍</h2>
<p>2001-2023年A股年报数据集，含 4 个文件，约 15G。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">- 管理层讨论与分析txt.zip
- 年报txt.zip
- A01-23.csv.gz
- mda01-23.csv.gz
</code></pre></div><p><img loading="lazy" src="img/a-mda.png" alt=""  />
</p>
<br>
<p>注意</p>
<ul>
<li>zip文件夹是原始数据， 解压后内部为 txt 文件。</li>
<li>gz文件为汇总数据， 解压后是csv文件。</li>
</ul>
<p><br><br></p>
<h2 id="二年报数据">二、年报数据</h2>
<p>2001-2023年年报数据。数据中只有year、code、text三个字段， 如果想增加诸如公司简称、行业等信息， 可以使用 <a href="https://textdata.cn/blog/2024-04-16-china-listed-company-information-dataset/"><strong>数据集 | A股上市公司基本信息</strong></a>   进行并表。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">anual_report_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;A01-23.csv.gz&#39;</span><span class="p">,</span> <span class="n">compression</span><span class="o">=</span><span class="s1">&#39;gzip&#39;</span><span class="p">)</span>
<span class="n">anual_report_df</span>
</code></pre></div><p><img loading="lazy" src="img/df1.png" alt=""  />
</p>
<br>
<p>年报记录数</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="nb">len</span><span class="p">(</span><span class="n">anual_report_df</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">61980
</code></pre></div><br>
<p>上市公司总数</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">anual_report_df</span><span class="o">.</span><span class="n">code</span><span class="o">.</span><span class="n">nunique</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">5629
</code></pre></div><br>
<br>
<h2 id="三mda数据">三、MD&amp;A数据</h2>
<p>2001-2023年MD&amp;A数据， 数据中只有year、code、text三个字段， 如果想增加诸如公司简称、行业等信息， 可以使用 <a href="https://textdata.cn/blog/2024-04-16-china-listed-company-information-dataset/"><strong>数据集 | A股上市公司基本信息</strong></a>   进行并表。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">mda_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;mda01-23.csv.gz&#39;</span><span class="p">,</span> <span class="n">compression</span><span class="o">=</span><span class="s1">&#39;gzip&#39;</span><span class="p">)</span>
<span class="n">mda_df</span>
</code></pre></div><p><img loading="lazy" src="img/df2.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="nb">len</span><span class="p">(</span><span class="n">mda_df</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">60079
</code></pre></div><br>
<p>上市公司总数</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">mda_df</span><span class="o">.</span><span class="n">code</span><span class="o">.</span><span class="n">nunique</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">5606
</code></pre></div><p><br><br></p>
<h2 id="四说明">四、说明</h2>
<p>从代码运行发现， md&amp;a记录量少于年报记录量。这是由于 mda01-23.csv.gz 是从 A01-23.csv.gz 中生成的， 由于上市公司的年报不是一套模板生成的， 每个公司模板不同，甚至每个公司前后年度报告的排版也会发生变化。在编程提取md&amp;a的过程中， 会因排版规则不能穷举， 导致md&amp;a样本量略微小于年报的样本量。 提取md&amp;a的工具是 <a href="https://textdata.cn/blog/2024-04-27-cntext2x-tutorial/">大邓开发的cntext2.1.1库</a> ，使用的内置函数 <code>mda=ct.extract_mda(text) </code>。</p>
<p>我们这里不展示提取过程，仅展示说明md&amp;a记录量与年报记录量之比。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">anual_report_df</span><span class="p">[</span><span class="s1">&#39;year&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">anual_report_df</span><span class="p">[</span><span class="s1">&#39;year&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="n">mda_df</span><span class="p">[</span><span class="s1">&#39;year&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">mda_df</span><span class="p">[</span><span class="s1">&#39;year&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;查看每年mda记录量与年报记录量之比&#39;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">year</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2001</span><span class="p">,</span> <span class="mi">2024</span><span class="p">):</span>
    <span class="n">mda_record_num</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">mda_df</span><span class="p">[</span><span class="n">mda_df</span><span class="o">.</span><span class="n">year</span><span class="o">==</span><span class="n">year</span><span class="p">])</span>
    <span class="n">anual_report_record_num</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">anual_report_df</span><span class="p">[</span><span class="n">anual_report_df</span><span class="o">.</span><span class="n">year</span><span class="o">==</span><span class="n">year</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">year</span><span class="si">}</span><span class="s1"> :&#39;</span><span class="p">,</span> <span class="n">mda_record_num</span><span class="o">/</span><span class="n">anual_report_record_num</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">查看每年mda记录量与年报记录量之比
2001 : 0.6546700942587832
2002 : 0.8569105691056911
2003 : 0.9287925696594427
2004 : 0.9550398839738942
2005 : 0.9707602339181286
2006 : 0.9745879120879121
2007 : 0.9821882951653944
2008 : 0.9846153846153847
2009 : 0.9859075535512966
2010 : 0.9868544600938968
2011 : 0.9894291754756871
2012 : 0.9891696750902527
2013 : 0.9901458415451321
2014 : 0.9905767056162834
2015 : 0.9922616953921913
2016 : 0.9926681542875359
2017 : 0.9934528892684316
2018 : 0.9892384105960265
2019 : 0.9639227642276422
2020 : 0.9642857142857143
2021 : 0.9310064935064936
2022 : 0.9838492597577388
2023 : 0.9901137847416527
</code></pre></div><p><br><br></p>
<h2 id="五相关内容">五、相关内容</h2>
<ul>
<li><a href="https://textdata.cn/blog/2024-01-21-hk-stock-market-anual-report/"><strong>数据集 | 港股年报文本数据集(2007 ~ 2023.12)</strong></a></li>
<li><a href="https://textdata.cn/blog/2024-01-18-neeq-china-listed-on-nation-equities-exchange-and-quotation-system-anunal-year-report/"><strong>数据集(付费) | 三板上市公司年报2002-2023.12</strong></a></li>
<li><a href="https://textdata.cn/blog/2024-01-14-usa-sec-10k-report-dataset/"><strong>数据集 | 美股年报10-K、20-F数据(2000-2023.12)</strong></a></li>
<li><a href="https://textdata.cn/blog/2023-03-24-load-w2v-and-expand-your-concpet-dicitonary/"><strong>词向量(付费) | 使用MD&amp;A2001-2022语料训练Word2Vec模型</strong></a></li>
<li><a href="https://textdata.cn/blog/2023-01-06-mda_informative_content/">中国工业经济 | MD&amp;A信息含量指标构建代码实现</a></li>
<li><a href="https://textdata.cn/blog/2023-01-13-information-content-of-critical-audit/">金融研究 | 使用Python构建「关键审计事项信息含量」</a></li>
<li><a href="https://textdata.cn/blog/2023-09-08-earnings-communication-conference-forward-looking-statements-information/">中国管理科学 | 使用业绩说明会文本数据测量上市公司前瞻性信息</a></li>
<li><a href="https://textdata.cn/blog/2024-04-25-firm-economic-policy-uncertainty/">代码 | 使用 MD&amp;A文本测量「企业不确定性感知FEPU」</a></li>
<li><a href="https://textdata.cn/blog/2024-04-16-china-listed-company-information-dataset/"><strong>数据集 | A股上市公司基本信息</strong></a></li>
</ul>
<p><br><br></p>
<h2 id="六获取数据">六、获取数据</h2>
<p>数据集 100 元，<strong>加微信 372335839， 备注「姓名-学校-专业」</strong>。</p>
<p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>数据集 | 2006年-2023年A股企业社会责任报告</title>
      <link>https://textdata.cn/blog/2023-08-11-china-a-market-corporate-social-responsibility-dataste/</link>
      <pubDate>Wed, 08 May 2024 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-08-11-china-a-market-corporate-social-responsibility-dataste/</guid>
      <description>企业社会责任（csr)已成为全球学术界研究的热点，</description>
      <content:encoded><![CDATA[<p>近年来，企业社会责任（csr)已成为全球学术界研究的热点，</p>
<p><br><br></p>
<h2 id="一csr相关论文">一、CSR相关论文</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">[1]解学梅,朱琪玮.企业绿色创新实践如何破解“和谐共生”难题？[J].管理世界,2021,37(01):128-149+9.
[2]谢红军,吕雪.负责任的国际投资：ESG与中国OFDI[J].经济研究,2022,57(03):83-99.
[3]Schaefer, Sarah Desirée, Ralf Terlutter, and Sandra Diehl. &#34;Is my company really doing good? Factors influencing employees&#39; evaluation of the authenticity of their company&#39;s corporate social responsibility engagement.&#34; Journal of business research 101 (2019): 128-143.
</code></pre></div><p><br><br></p>
<p>CSR数据多为非结构文本数据，可以做词频统计、情感分析、话题模型等文本分析任务。今天给大家奉上A股CSR数据集， <strong>对文本分析感兴趣的同学， 欢迎报名视频课「Python实证指标构建与文本分析」</strong>。 本文仅展示A股企业社会责任数据集，并作简单分析。</p>
<p><br><br></p>
<h2 id="二csr数据集">二、CSR数据集</h2>
<p>目前这是市面上最全最完整的原始数据，数据已整理到csv压缩文件（大小308M）。</p>
<p><strong>A股企业社会责任报告数据集</strong>基本信息</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">- 记录数14043
- 沪深2337家公司
- 年度2006-2023
- 公布日期2007-03-14 ~ 2024-04-30
- txt、pdf、csv
- 体积
</code></pre></div><p><img loading="lazy" src="img/cover.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="三实验">三、实验</h2>
<h3 id="31-读取数据">3.1 读取数据</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;CSR2006-2023.csv.gz&#39;</span><span class="p">,</span> <span class="n">compression</span><span class="o">=</span><span class="s1">&#39;gzip&#39;</span><span class="p">)</span>
<span class="n">df</span>
</code></pre></div><p><img loading="lazy" src="img/df1.png" alt=""  />
</p>
<br>
<h3 id="32-字段">3.2 字段</h3>
<p><em><strong>CSR2006-2023.csv.gz</strong></em> 含字段</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">- code 股票代码
- name 公司简称
- year 会计年度
- pub_date 发布日期
- type 报告类型， 有三种CSR、ESG、CSRESG； 有的公司发布的报告即是CSR，也是ESG，所以标注类型为CSRESG。 实际使用，可以将字段type中含CSR的看做企业社会责任报告
</code></pre></div><p>查看CSR、ESG、CSRESG记录数</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df</span><span class="o">.</span><span class="n">type</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">type
CSR       11926
ESG        1884
CSRESG      233
Name: count, dtype: int64
</code></pre></div><br>
<h3 id="33-记录数">3.3 记录数</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#ESG报告数</span>
<span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<pre><code>14043
</code></pre>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#发布ESG报告的公司数</span>
<span class="n">df</span><span class="o">.</span><span class="n">code</span><span class="o">.</span><span class="n">nunique</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<pre><code>2337
</code></pre>
<br>
<h3 id="34-会计年度">3.4 会计年度</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#有ESG报告的年份</span>

<span class="c1">#sorted(df[&#39;year&#39;].unique())</span>
<span class="nb">sorted</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">year</span><span class="o">.</span><span class="n">unique</span><span class="p">())</span>
</code></pre></div><p>Run</p>
<pre><code>[2006,
 2007,
 2008,
 2009,
 2010,
 2011,
 2012,
 2013,
 2014,
 2015,
 2016,
 2017,
 2018,
 2019,
 2020,
 2021,
 2022,
 2023]
</code></pre>
<br>
<h3 id="35-发布日期">3.5 发布日期</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df</span><span class="p">[</span><span class="s1">&#39;pub_date&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;pub_date&#39;</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;pub_date&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;pub_date&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">2007-03-14 00:00:00
2024-04-30 00:00:00
</code></pre></div><p><br><br></p>
<h2 id="四esg年度发布量">四、ESG年度发布量</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;year&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="nb">len</span><span class="p">)</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s1">&#39;bar&#39;</span><span class="p">)</span>  
</code></pre></div><p><img loading="lazy" src="img/output_6_1.png" alt=""  />
</p>
<p>​</p>
<p><br><br></p>
<h2 id="五沪深发布量">五、沪深发布量</h2>
<p>大邓记得深圳交易所大多数股票以0开头，上海交易所股票则大多以6开头。 可以简单通过第一位数字来判断两个交易所发布量</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#切片，选取股票代码字符串第二个位置的数字</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;code&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">slice</span><span class="p">(</span><span class="n">start</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">stop</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<pre><code>code
6    7835
0    4962
3    1199
8      18
9      17
2      10
4       2
Name: count, dtype: int64
</code></pre>
<br>
<p>运行结果，除了0和6还出现了2、3/9。综上，股票代码</p>
<ul>
<li>
<p>0 深交所</p>
</li>
<li>
<p>3 创业板</p>
</li>
<li>
<p>6 上交所</p>
</li>
<li>
<p>其他</p>
</li>
</ul>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;code&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;A6&#39;</span><span class="p">)]</span>
</code></pre></div><p><img loading="lazy" src="img/df2.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;code&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;A0&#39;</span><span class="p">)]</span>
</code></pre></div><p><img loading="lazy" src="img/df3.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#股票代码第一位出现2或者9的股票</span>
<span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;code&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">match</span><span class="p">(</span><span class="s1">&#39;A2|A9&#39;</span><span class="p">)]</span>
</code></pre></div><p><img loading="lazy" src="img/df4.png" alt=""  />
</p>
<p>​</p>
<p><br><br></p>
<h2 id="数据集获取">数据集获取</h2>
<p>数据整理不易， 100元， 加微信 372335839， 备注「姓名-学校-专业-CSR」</p>
<p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>金融研究 | 使用Python测量关键审计事项的「信息含量」</title>
      <link>https://textdata.cn/blog/2023-01-13-information-content-of-critical-audit/</link>
      <pubDate>Tue, 30 Apr 2024 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-01-13-information-content-of-critical-audit/</guid>
      <description>关键审计事项是来自审计师视角的信息， 其蕴含的特质性信息对实现沟通价值至关重要。本文采用文本 分析方法计算的文本相似度衡量关键审计事项特质性信息含量，考察其对公司债券发行定价的影响。 结果发现， 以较低文本相似度代表的较高关键审计事项信息含量能够降低公司债券发行定价。 较高的审计师专业胜任能力 和独立性能够增强关键审计事项信息含量对公司债券发行定价的降低作用。 信息不对称的缓解是关键审计事项 信息含量降低公司债券发行定价的具体影响渠道。考虑关键审计事项类型后发现， 关联交易类关键审计事项信 息含量对公司债券发行定价的降低作用更强。本文研究结论有助于未来改进关键审计事项的披露要求。</description>
      <content:encoded><![CDATA[<p>今日分享「信息含量」的第二种算法， 不同于之前 <a href="https://textdata.cn/blog/2023-01-06-mda_informative_content/">中国工业经济 | MD&amp;A信息含量指标构建代码实现</a> ， 金日分享的「信息含量」算法更简单易懂，运行速度更快。</p>
<p><br><br></p>
<h2 id="一信息含量">一、信息含量</h2>
<h3 id="11-文献">1.1 文献</h3>
<p>宋建波,冯晓晴.关键审计事项信息含量与公司债券发行定价——基于文本相似度视角[J].会计研究,2022,(03):174-191.
<img loading="lazy" src="img/key-audit_cover.png" alt=""  />
</p>
<br>
<h3 id="12-信息的分类">1.2 信息的分类</h3>
<ul>
<li><strong>标准信息</strong>，将关键审计事项段中与同行业其他公司重复或相似的信息定义为不具有信息含量的内容 ( 标准信息)。</li>
<li><strong>特质性信息</strong> 将区别于同行业其他公司的信息定义为真正具有信息含量的内容 ( 特质性信息) 。 与标准信息相比， 特质性信息才是缓解公司与投资者之间信息不对称的关键。</li>
</ul>
<p><br><br></p>
<h2 id="二算法">二、算法</h2>
<p>该文基于 <strong>向量空间模型</strong> (VSM) ， 采用某家公司关键审计事项文本内容与同行业其他公司关键审计事项文本内容之间的余弦相似度来衡量关键审计事项的特质性信息含量。</p>
<p>要测量信息含量的数学表达大概这样</p>
<ul>
<li>
<p><strong>文本向量化</strong>。</p>
<ul>
<li>使用TF-IDF将公司审计文本向量化 <em><strong>Corp_Vec_it</strong></em></li>
<li>公司所在行业众多的 <em><strong>Corp_Vec_jt</strong></em> 的均值向量 <em><strong>Industry_Vec_t</strong></em> 。注意计算均值向量时要剔除概公司。</li>
</ul>
</li>
<li>
<p><strong>余弦相似度cosine(Corp_Vec_it, Industry_Vec_t)</strong></p>
</li>
<li>
<p><code>信息含量 = -cosine(Corp_Vec_it, Industry_Vec_t)</code></p>
</li>
</ul>
<p><br><br></p>
<h2 id="三代码实现">三、代码实现</h2>
<h3 id="31-文件结构">3.1 文件结构</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">- 金融研究2022信息含量文件夹
    - 代码.ipynb                                    #代码文件
    
    - data                                         #数据文件夹
       - mda01-22.csv.gz                           #md&amp;a
       - 行业代码00-22.xlsx                          #股票行业信息
       
    - 信息含量.csv                                   #计算结果
</code></pre></div><br>
<h3 id="32-读取数据">3.2 读取数据</h3>
<p>原文数据描述</p>
<blockquote>
<p>对于全部 A 股公司而言，新准则要求在针对 2017 财年 会计报表的审计报告中首次包含关键审计事项。 由于针对 2017 财年会计报表的审计报告于 2018 年发布， 债券投资者在 2018 年方能获取 2017 财年的关键审计事项信息， 进而在 2018 年进行债券投资时考虑关键审计事项信息。 因此，本文实证检验 2017－2018 会计年度审计报告中的关键审计事项信息对 2018－2019 年度非金融业上市公司发行的 357 只公司债券定价的影响。 关键审计事项信息含量数据通过 Python 编程语言进行文本分析计算得到; 公司债券限制性契约条款数据通过手工整理得到; 其他数据来自于 CSMAＲ 数据库。所有连续变量均进行 1%和 99%分位数的缩尾处理。</p>
</blockquote>
<br>
<p>大邓这里没有「<strong>审计报告文本</strong>」数据集， 用「<strong>管理层讨论与分析</strong>」代替。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;data/mda01-22.csv.gz&#39;</span><span class="p">,</span> <span class="n">compression</span><span class="o">=</span><span class="s1">&#39;gzip&#39;</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;会计年度&#39;</span><span class="p">,</span> <span class="s1">&#39;股票代码&#39;</span><span class="p">,</span> <span class="s1">&#39;经营讨论与分析内容&#39;</span><span class="p">]</span>

<span class="c1">#上市公司行业信息</span>
<span class="n">ind_info_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_excel</span><span class="p">(</span><span class="s1">&#39;data/行业代码00-22.xlsx&#39;</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">ind_info_df</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;股票代码&#39;</span><span class="p">,</span> <span class="s1">&#39;会计年度&#39;</span><span class="p">],</span> <span class="n">how</span><span class="o">=</span><span class="s1">&#39;inner&#39;</span><span class="p">)</span>


<span class="c1"># 剔除金融行业处理</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="o">~</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;行业代码&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="s2">&#34;J&#34;</span><span class="p">)]</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;会计年度&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;会计年度&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">str</span><span class="p">)</span>

<span class="c1">#行业内企业数量过少，会导致行业向量与某个或某几个企业向量相关性增大，极端情况下，一个企业就是一个行业。剔除掉企业数较少的行业，这里只保留大于20的行业。</span>
<span class="n">ind_codes</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;行业代码&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
<span class="n">ind_codes</span> <span class="o">=</span> <span class="n">ind_codes</span><span class="p">[</span><span class="n">ind_codes</span><span class="o">&gt;</span><span class="mi">20</span><span class="p">]</span><span class="o">.</span><span class="n">index</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;行业代码&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="n">ind_codes</span><span class="p">)]</span>
<span class="n">df</span>
</code></pre></div><p><img loading="lazy" src="img/01-df.png" alt=""  />
</p>
<br>
<h3 id="33-文本向量化">3.3 文本向量化</h3>
<p>使用sklearn，将该企业文本(审计报告文本)转为TF-IDF的企业向量。步骤</p>
<ol>
<li>分词整理</li>
<li><code>tf-idf</code>文本向量化</li>
<li>合并多个字段为新的df</li>
</ol>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="o">%%</span><span class="n">time</span>
<span class="kn">from</span> <span class="nn">pandarallel</span> <span class="kn">import</span> <span class="n">pandarallel</span>
<span class="n">pandarallel</span><span class="o">.</span><span class="n">initialize</span><span class="p">()</span> <span class="c1">#并行加速</span>


<span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="kn">import</span> <span class="nn">jieba</span>
    <span class="kn">import</span> <span class="nn">re</span>
    <span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>
    
    <span class="c1">#cntext1.x</span>
    <span class="c1">#stopwords = ct.load_pkl_dict(&#39;STOPWORDS.pkl&#39;)[&#39;STOPWORDS&#39;][&#39;chinese&#39;]</span>

    <span class="c1">##cntext2.x</span>
    <span class="n">stopwords</span><span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">read_yaml_dict</span><span class="p">(</span><span class="s1">&#39;enzh_common_StopWords.yaml&#39;</span><span class="p">)[</span><span class="s1">&#39;Dictionary&#39;</span><span class="p">][</span><span class="s1">&#39;chinese&#39;</span><span class="p">]</span>
    
    <span class="c1">#只保留md&amp;a中的中文内容</span>
    <span class="n">text</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">re</span><span class="o">.</span><span class="n">findall</span><span class="p">(</span><span class="s1">&#39;[</span><span class="se">\u4e00</span><span class="s1">-</span><span class="se">\u9fa5</span><span class="s1">]+&#39;</span><span class="p">,</span> <span class="n">text</span><span class="p">))</span>
    <span class="c1">#剔除停用词</span>
    <span class="n">words</span> <span class="o">=</span> <span class="p">[</span><span class="n">w</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">jieba</span><span class="o">.</span><span class="n">cut</span><span class="p">(</span><span class="n">text</span><span class="p">)</span> <span class="k">if</span> <span class="n">w</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">stopwords</span><span class="p">]</span>
    <span class="c1">#整理为用空格间隔的字符串(类西方语言文本格式)</span>
    <span class="k">return</span> <span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">words</span><span class="p">)</span>

<span class="n">df</span><span class="p">[</span><span class="s1">&#39;clean_text&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;经营讨论与分析内容&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">parallel_apply</span><span class="p">(</span><span class="n">transform</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">CPU times: user 2.63 s, sys: 5.07 s, total: 7.7 s
Wall time: 10min 47s
</code></pre></div><p><img loading="lazy" src="img/02-df.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="o">%%</span><span class="n">time</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">TfidfVectorizer</span>

<span class="n">cv</span> <span class="o">=</span> <span class="n">TfidfVectorizer</span><span class="p">(</span><span class="n">min_df</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span> <span class="n">max_df</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span> 
<span class="c1"># 生成稀疏bow矩阵</span>
<span class="c1">#dtm 文档-词频-矩阵</span>
<span class="n">dtm_df</span> <span class="o">=</span> <span class="n">cv</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;clean_text&#39;</span><span class="p">])</span> 
<span class="c1">#保证新生成的dtm_df.index 与 df.index 完全相同</span>
<span class="n">dtm_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">dtm_df</span><span class="o">.</span><span class="n">toarray</span><span class="p">(),</span> <span class="n">index</span><span class="o">=</span><span class="n">df</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
<span class="n">dtm_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">CPU times: user 53.1 s, sys: 1.27 s, total: 54.3 s
Wall time: 54.4 s
</code></pre></div><p><img loading="lazy" src="img/03-df.png" alt=""  />
</p>
<br>
<h3 id="36-小实验">3.6 小实验</h3>
<p>指定某年份，某公司，某行业， 尝试着分别得到公司向量、行业向量、信息含量。</p>
<ul>
<li>
<p>使用TF-IDF将公司审计文本向量化 <em><strong>Corp_Vec_it</strong></em></p>
</li>
<li>
<p>公司所在行业众多的 <em><strong>Corp_Vec_jt</strong></em> 的均值向量 <em><strong>Industry_Vec_t</strong></em> 。注意计算均值向量时要剔除概公司。</p>
</li>
<li>
<p><strong>余弦相似度cosine(Corp_Vec_it, Industry_Vec_t)</strong></p>
</li>
<li>
<p><code>信息含量 = -cosine(Corp_Vec_it, Industry_Vec_t)</code></p>
</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics.pairwise</span> <span class="kn">import</span> <span class="n">cosine_similarity</span>

<span class="c1">#小实验</span>
<span class="n">year</span> <span class="o">=</span> <span class="s1">&#39;2020&#39;</span>
<span class="n">ind</span> <span class="o">=</span> <span class="s1">&#39;K70&#39;</span>
<span class="n">code</span> <span class="o">=</span> <span class="s1">&#39;A000002&#39;</span>

<span class="c1">#筛选条件</span>
<span class="n">year_mask</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;会计年度&#39;</span><span class="p">]</span><span class="o">==</span><span class="n">year</span>
<span class="n">ind_mask</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;行业代码&#39;</span><span class="p">]</span><span class="o">==</span><span class="n">ind</span>
<span class="n">corp_mask</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;股票代码&#39;</span><span class="p">]</span><span class="o">==</span><span class="n">code</span>

<span class="c1">#提取公司向量</span>
<span class="n">selected_corp_index</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">year_mask</span> <span class="o">&amp;</span> <span class="n">ind_mask</span> <span class="o">&amp;</span> <span class="n">corp_mask</span><span class="p">]</span><span class="o">.</span><span class="n">index</span>
<span class="n">corp_vec</span> <span class="o">=</span> <span class="n">dtm_df</span><span class="p">[</span><span class="n">dtm_df</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="n">selected_corp_index</span><span class="p">)]</span><span class="o">.</span><span class="n">values</span>
<span class="n">corp_arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">corp_vec</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;公司向量: &#39;</span><span class="p">,</span> <span class="n">corp_arr</span><span class="p">)</span>

<span class="c1">#计算行业均值向量</span>
<span class="n">selected_ind_df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">ind_mask</span> <span class="o">&amp;</span> <span class="n">year_mask</span><span class="p">]</span>
<span class="n">selected_indexs</span> <span class="o">=</span> <span class="n">selected_ind_df</span><span class="p">[</span><span class="n">selected_ind_df</span><span class="p">[</span><span class="s1">&#39;股票代码&#39;</span><span class="p">]</span><span class="o">!=</span><span class="n">code</span><span class="p">]</span><span class="o">.</span><span class="n">index</span>
<span class="n">ind_vec</span> <span class="o">=</span> <span class="n">dtm_df</span><span class="p">[</span><span class="n">dtm_df</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="n">selected_indexs</span><span class="p">)]</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">values</span>
<span class="n">ind_arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">ind_vec</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;公司向量: &#39;</span><span class="p">,</span> <span class="n">corp_arr</span><span class="p">)</span>

<span class="c1">#计算信息含量</span>
<span class="n">special_info</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span> <span class="o">*</span> <span class="n">cosine_similarity</span><span class="p">(</span><span class="n">corp_arr</span><span class="p">,</span> <span class="n">ind_arr</span><span class="p">)[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;信息含量: &#39;</span><span class="p">,</span> <span class="n">special_info</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">公司向量:  [[0.        0.0025099 0.        ... 0.        0.        0.       ]]
行业向量:  [[0.00246526 0.00218646 0.00744848 ... 0.00038973 0.00219886 0.00180851]]
信息含量:  -0.5444361165694909
</code></pre></div><br>
<h3 id="25-批量计算信息含量">2.5 批量计算信息含量</h3>
<ol>
<li>新建 <em><strong>信息含量.csv</strong></em> ， 含字段 <code>['股票代码', '会计年度', '行业代码', '信息含量']</code></li>
<li>先按年份对 <em><strong>df</strong></em> 进行分组，得到很多个 <em><strong>y_df</strong></em>；而 <em><strong>y_df</strong></em> 含一年很多条企业mda记录</li>
<li>双层 <em><strong>for</strong></em>循环逐年(<em><strong>y_df</strong></em>)内每条企业mda记录， 构建公司向量、行业向量、信息含量</li>
<li>将相关计算结果写入到csv中。</li>
</ol>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="o">%%</span><span class="n">time</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">csv</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics.pairwise</span> <span class="kn">import</span> <span class="n">cosine_similarity</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>



<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;信息含量.csv&#39;</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">,</span> <span class="n">newline</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">csvf</span><span class="p">:</span>
    <span class="n">fieldnames</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;股票代码&#39;</span><span class="p">,</span> <span class="s1">&#39;会计年度&#39;</span><span class="p">,</span> <span class="s1">&#39;行业代码&#39;</span><span class="p">,</span> <span class="s1">&#39;信息含量&#39;</span><span class="p">]</span>
    <span class="n">writer</span> <span class="o">=</span> <span class="n">csv</span><span class="o">.</span><span class="n">DictWriter</span><span class="p">(</span><span class="n">csvf</span><span class="p">,</span> <span class="n">fieldnames</span><span class="o">=</span><span class="n">fieldnames</span><span class="p">)</span>
    <span class="n">writer</span><span class="o">.</span><span class="n">writeheader</span><span class="p">()</span>
    
    <span class="k">for</span> <span class="n">year</span><span class="p">,</span> <span class="n">y_df</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;会计年度&#39;</span><span class="p">),</span> <span class="n">desc</span><span class="o">=</span><span class="s1">&#39;分析进度&#39;</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">y_df</span><span class="o">.</span><span class="n">index</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">data</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
                <span class="n">data</span><span class="p">[</span><span class="s1">&#39;会计年度&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">year</span>
                <span class="n">code</span> <span class="o">=</span> <span class="n">y_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="s1">&#39;股票代码&#39;</span><span class="p">]</span>
                <span class="n">data</span><span class="p">[</span><span class="s1">&#39;股票代码&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">code</span>
                <span class="n">industry</span> <span class="o">=</span> <span class="n">y_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="s1">&#39;行业代码&#39;</span><span class="p">]</span>
                <span class="n">data</span><span class="p">[</span><span class="s1">&#39;行业代码&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">industry</span>

                <span class="c1">#筛选条件mask</span>
                <span class="n">ind_mask</span> <span class="o">=</span> <span class="n">y_df</span><span class="p">[</span><span class="s1">&#39;行业代码&#39;</span><span class="p">]</span><span class="o">==</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">industry</span><span class="si">}</span><span class="s1">&#39;</span>
                <span class="n">corp_mask</span> <span class="o">=</span> <span class="n">y_df</span><span class="p">[</span><span class="s1">&#39;股票代码&#39;</span><span class="p">]</span><span class="o">==</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">code</span><span class="si">}</span><span class="s1">&#39;</span>
                <span class="n">year_mask</span> <span class="o">=</span> <span class="n">y_df</span><span class="p">[</span><span class="s1">&#39;会计年度&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">year</span><span class="si">}</span><span class="s1">&#39;</span>
                
                
                <span class="c1">#某年某公司a</span>
                <span class="n">selected_corp_index</span> <span class="o">=</span> <span class="n">y_df</span><span class="p">[</span><span class="n">ind_mask</span> <span class="o">&amp;</span> <span class="n">corp_mask</span> <span class="o">&amp;</span> <span class="n">year_mask</span><span class="p">]</span><span class="o">.</span><span class="n">index</span>
                <span class="n">corp_vec</span> <span class="o">=</span> <span class="n">dtm_df</span><span class="p">[</span><span class="n">dtm_df</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="n">selected_corp_index</span><span class="p">)]</span><span class="o">.</span><span class="n">values</span>
                <span class="n">corp_arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">corp_vec</span><span class="p">)</span>

                <span class="c1">#某year，某行业(排除公司a)</span>
                <span class="n">selected_ind_df</span> <span class="o">=</span> <span class="n">y_df</span><span class="p">[</span><span class="n">ind_mask</span> <span class="o">&amp;</span> <span class="n">year_mask</span><span class="p">]</span>
                <span class="n">selected_indexs</span> <span class="o">=</span> <span class="n">selected_ind_df</span><span class="p">[</span><span class="n">selected_ind_df</span><span class="p">[</span><span class="s1">&#39;股票代码&#39;</span><span class="p">]</span><span class="o">!=</span><span class="n">code</span><span class="p">]</span><span class="o">.</span><span class="n">index</span>
                <span class="n">ind_vec</span> <span class="o">=</span> <span class="n">dtm_df</span><span class="p">[</span><span class="n">dtm_df</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="n">selected_indexs</span><span class="p">)]</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">values</span>
                <span class="n">ind_arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">ind_vec</span><span class="p">])</span>

                <span class="c1">#信息含量</span>
                <span class="n">special_info</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span> <span class="o">*</span> <span class="n">cosine_similarity</span><span class="p">(</span><span class="n">corp_arr</span><span class="p">,</span> <span class="n">ind_arr</span><span class="p">)[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
                <span class="n">data</span><span class="p">[</span><span class="s1">&#39;信息含量&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">special_info</span>
                <span class="n">writer</span><span class="o">.</span><span class="n">writerow</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
            <span class="k">except</span><span class="p">:</span>
                <span class="k">pass</span>
            
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">分析进度: 100%|█████████████████████████████████| 22/22 [01:58&lt;00:00,  5.37s/it]
CPU times: user 1min 55s, sys: 2.91 s, total: 1min 57s
Wall time: 1min 58s
</code></pre></div><p><br><br></p>
<h2 id="四查看结果">四、查看结果</h2>
<p>欣赏一下计算结果 <em><strong>信息含量.csv</strong></em></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">idf</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;信息含量.csv&#39;</span><span class="p">)</span>
<span class="n">idf</span>
</code></pre></div><p><img loading="lazy" src="img/04-df.png" alt=""  />
</p>
<br>
<br>
<h2 id="五相关内容">五、相关内容</h2>
<p>最近陆续分享了几篇<strong>文本相似度</strong>、<strong>信息含量</strong>的论文</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">[1]姜富伟,胡逸驰,黄楠.央行货币政策报告文本信息、宏观经济与股票市场[J].金融研究,2021,(06):95-113.
[2]宋建波,冯晓晴.关键审计事项信息含量与公司债券发行定价——基于文本相似度视角[J].会计研究,2022,(03):174-191.
[3]孟庆斌,杨俊华,鲁冰.管理层讨论与分析披露的信息含量与股价崩盘风险——基于文本向量化方法的研究[J].中国工业经济,2017,(12):132-150. 
</code></pre></div><br>
<p>比较一下,三者均先使用了文本向量化，将本文数据转为向量。每篇论文的算法</p>
<br>
<table>
<thead>
<tr>
<th>论文</th>
<th>指标</th>
<th>算法</th>
</tr>
</thead>
<tbody>
<tr>
<td>[1]</td>
<td><a href="https://textdata.cn/blog/2023-01-10-similarity_of_cental_bank_monetary_policy/">文本相似度</a></td>
<td>将央行货币政策报告向量化， 临近的两个报告文本向量计算相似度，相似度越高，金融市场波动性越小。</td>
</tr>
<tr>
<td>[2]</td>
<td>信息含量（本文)</td>
<td>将同行业内所有企业向量Corp求均值得到行业向量Ind，求Corp与Ind的余弦相似度，并将结果乘以(-1),所得结果定义为信息向量。</td>
</tr>
<tr>
<td>[3]</td>
<td><a href="https://textdata.cn/blog/2023-01-06-mda_informative_content/">信息含量</a></td>
<td>文本向量化+计量建模，认为md&amp;a中的信息向量Norm可以由市场Norm_Market、行业Norm_Industry、企业异质性μ三种信息向量组成，通过计算 <br><code>Norm = a0 + a1*Norm_Industry +  a2*Norm_Market + μ</code> <br>，将μ 向量的绝对值和作为信息含量，而a1+a2看标准信息。</td>
</tr>
</tbody>
</table>
<br>
<p>从中可以看到两个向量的余弦相似度，在不同场景，解读含义是不同的。</p>
<ul>
<li>在货币政策中，相似度越高，表示越政策稳定，金融市场波动星越小。</li>
<li>而在关键审计场景中，特质性信息是缓解公司与投资者信息不对称的关键，公司向量Corp与行业向量Ind相似度越高，表示公司审计报告文本特质性信息越少。</li>
</ul>
<p><br><br></p>
<h2 id="六资料获取">六、资料获取</h2>
<p>数据&amp;代码创作不易， 200元， 如果需要源代码和数据， 加微信372335839， 备注「姓名-学校-专业」</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">打包价 200元
  1. 管理层讨论与分析(mda01-22.csv.gz)、年报(A01-22.csv.gz)
  2. cntext2安装文件(cntext-2.1.1-py3-none-any.whl)
  3. 计算结果(信息含量.csv)
  
零卖价
- 100元  管理层讨论与分析(mda01-22.csv.gz)、年报(A01-22.csv.gz)
- 100元  cntext2安装文件(cntext-2.1.1-py3-none-any.whl)
- 50元   计算结果(信息含量.csv)
</code></pre></div><br>
<br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>管理世界2024 | 使用管理层讨论与分析测量「企业人工智能指标」</title>
      <link>https://textdata.cn/blog/2024-04-19-ai-improve-firm-productivity/</link>
      <pubDate>Mon, 29 Apr 2024 00:00:00 +0000</pubDate>
      
      <guid>/blog/2024-04-19-ai-improve-firm-productivity/</guid>
      <description>&lt;h2 id=&#34;一案例&#34;&gt;一、案例&lt;/h2&gt;
&lt;h3 id=&#34;11-文献&#34;&gt;1.1 文献&lt;/h3&gt;
&lt;p&gt;姚加权, 张锟澎, 郭李鹏, 冯绪. 人工智能如何提升企业生产效率？——基于劳动力技能结构调整的视角[J]. 管理世界, 2024, 40 (02): 101-116+133+117-122.&lt;/p&gt;
&lt;p&gt;摘要:人工智能技术对实现经济的高质量发展具有重要意义。现有研究多聚焦于人工智能对宏观经济的影响，本文从企业层面考察了人工智能技术如何影响生产效率和劳动力技能结构。&lt;strong&gt;本文运用机器学习方法生成了「人工智能词典」，并对上市公司的年报和专利进行「文本分析」，进而构建了企业层面的「人工智能指标」&lt;/strong&gt;。研究发现，人工智能显著提升了中国上市公司的生产率，并且该结论在一系列稳健性检验后依旧成立。在影响机制方面，人工智能通过促使企业减少常规低技能劳动力需求、增加非常规高技能劳动力需求的方式提升企业的生产率，这体现了企业劳动力技能结构的调整。异质性分析表明，产权性质、人才获得方式、劳动力保障、治理结构等企业层面因素对人工智能的生产率效应有较大影响。此外，企业所处的行业和地区层面因素也影响了人工智能的生产率效应。最后，本文发现人工智能提高了企业价值。本文加深了对微观企业层面人工智能在生产过程中所扮演角色的认知和理解，并为在微观企业层面推动人工智能技术发展提供了建议。&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;12-指标构建步骤&#34;&gt;1.2 指标构建步骤&lt;/h3&gt;
&lt;p&gt;下图是论文中「人工智能指标」构建的流程图&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/01-steps.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;我们将步骤分成三步&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Step1. 训练Word2Vec模型构建「人工智能AI词典」, 共54个词&lt;/li&gt;
&lt;li&gt;Step2. 统计上市公司 「年报」中AI词词频m，采用自然对数处理得到指标Ln(m+1)&lt;/li&gt;
&lt;li&gt;Step3. 统计上市公司「MD&amp;amp;A」数据中AI词词频n，采用自然对数处理得到指标Ln(n+1)&lt;/li&gt;
&lt;li&gt;Step4. 根据上市公司申请专利的名称和摘要是否含AI词，统计上市公司AI专利申请数量p，采用自然对数处理得到指标Ln(p+1)&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;企业申请的人工智能专利代表企业已经拥有的人工智能技术，反映了企业人工智能技术的产出情况，能够与年报相互印证企业的人工智能技术水平&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;为了减轻阅读压力，也为了减轻制作本文的工作量， 本文仅实现 Step1 、Step2 、Step3， 覆盖截图中的红色框范围内的内容。&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;13-项目结构&#34;&gt;1.3 项目结构&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;- 管理世界2024企业人工智能文件夹
    - 代码.ipynb                                    #代码文件
    
    - data                                         #数据文件夹
       - A01-22.csv.gz                             #年报
       - mda01-22.csv.gz                           #md&amp;amp;a
       - 上市公司基本信息2000-2022.csv                #基本信息
       
    - A股人工智能指标2001-2022(mda).xlsx              #计算结果
    
    - Word2Vec                                     #模型文件夹
       - mda01-22.200.6.bin
       - mda01-22.200.6.bin.syn1neg.npy
       - mda01-22.200.6.bin.wv.vectors.npy
       - 1000w专利摘要文本.100.6.bin
       - 1000w专利摘要文本.100.6.bin.syn1neg.npy
       - 1000w专利摘要文本.100.6.bin.wv.vectors.npy
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;二准备ai词典&#34;&gt;二、准备AI词典&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;构造专利摘要语料、管理层讨论与分析语料，分别训练Word2Vec模型&lt;/li&gt;
&lt;li&gt;构建人工智能种子词， 使用Word2Vec模型扩展并构建「人工智能词典」&lt;/li&gt;
&lt;/ol&gt;
&lt;br&gt;
&lt;h3 id=&#34;21-训练word2vec模型&#34;&gt;2.1 训练Word2Vec模型&lt;/h3&gt;
&lt;p&gt;刚好之前分享过使用cntext库(2.0以上版本)训练Word2Vec， 相关推文&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/2023-03-24-load-w2v-and-expand-your-concpet-dicitonary/&#34;&gt;词向量(付费) | 使用MD&amp;amp;A2001-2022语料训练Word2Vec模型&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/2023-11-10-training-word2vec-model-using-china-3751w-patent-application-dataset/&#34;&gt;词向量(付费) | 使用1985年-2022年专利申请摘要训练word2vec模型&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;分别对应 &lt;em&gt;&lt;strong&gt;cntext-2.1.1-py3-none-any.whl&lt;/strong&gt;&lt;/em&gt;、 &lt;em&gt;&lt;strong&gt;mda01-22.200.6.bin&lt;/strong&gt;&lt;/em&gt; 、 &lt;em&gt;&lt;strong&gt;1000w专利摘要文本.100.6.bin&lt;/strong&gt;&lt;/em&gt; 两个模型文件。&lt;strong&gt;文末有模型获取方式&lt;/strong&gt;。&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;22-导入word2vec&#34;&gt;2.2 导入Word2Vec&lt;/h3&gt;
&lt;p&gt;以 mda01-22.200.6.bin 为例， 使用cntext2读取模型， cntext安装和使用请参考 &lt;a href=&#34;https://textdata.cn/blog/2024-04-27-cntext2x-tutorial/&#34;&gt;文本分析库cntext2.x使用说明文档&lt;/a&gt;。 &lt;strong&gt;文末有cntext获取方式&lt;/strong&gt;。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;cntext&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;ct&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;#查看cntext版本&lt;/span&gt;
&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ct&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;__version__&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;#导入管理层讨论与分析的Word2Vec模型&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;mda_w2v_m&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ct&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;load_w2v&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;Word2Vec/mda01-22.200.6.bin&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;c1&#34;&gt;#导入专利摘要Word2Vec模型&lt;/span&gt;
&lt;span class=&#34;c1&#34;&gt;#pat_w2v_m = ct.load_w2v(&amp;#39;Word2Vec/1000w专利摘要文本.100.6.bin&amp;#39;)&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;mda_w2v_m&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;2.1.1

Loading word2vec model...
&amp;lt;gensim.models.word2vec.Word2Vec at 0x7dbf9afd0&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;p&gt;查看某个词的词向量&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;mda_w2v_m.wv.get_vector(&amp;#39;人工智能&amp;#39;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;array([-3.8744571 , -0.5923845 , -1.8126943 ,  1.660894  ,  1.4194168 ,
        1.0365077 , -0.21333796, -0.60481924,  1.5012817 , -0.24060927,
       -1.7463511 , -2.1997519 , -0.66537315, -1.2665682 ,  0.14333063,
       -0.1268099 ,  2.005481  , -1.4638793 ,  3.7950375 ,  0.20866613,
        1.0281029 , -1.5495429 , -0.2518896 ,  1.4159175 ,  3.178865  ,
        .............................#省略展示..........................
       -1.2206184 ,  1.6766415 , -0.1082068 ,  0.62580353,  1.4639648 ,
        2.2743094 , -0.48386717,  1.3510187 ,  1.1698194 ,  0.72390413,
       -0.4855997 ,  1.0688399 ,  0.77217335, -1.4559731 ,  1.4391305 ,
        0.8412411 ,  2.359447  , -1.1504242 ,  1.3677332 , -0.92123735,
        1.281644  ,  0.67157453,  2.159804  ,  1.7593136 , -0.53061306,
       -0.77395666,  0.5912517 ,  1.9448034 ,  0.13023153,  0.6798518 ],
      dtype=float32)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h3 id=&#34;23-扩展词典&#34;&gt;2.3 扩展词典&lt;/h3&gt;
&lt;p&gt;我们每个人对人工智能都有所了解，脑海里首先能想到的词可以当做 「初始种子词」， 例如词语 &lt;code&gt;人工智能|人机对话|&lt;/code&gt; 等。 本部分主要展示Word2Vec模型的近义词联想能力，&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;mda_w2v_m&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;most_similar&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;([&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;人工智能&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;人机对话&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;topn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;100&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;[(&amp;#39;自然语言处理&amp;#39;, 0.8055953979492188),
 (&amp;#39;AI&amp;#39;, 0.8050345778465271),
 (&amp;#39;语音识别&amp;#39;, 0.804234504699707),
 (&amp;#39;NLP&amp;#39;, 0.7967724800109863),
 (&amp;#39;交互技术&amp;#39;, 0.7902386784553528),
 (&amp;#39;智能语音&amp;#39;, 0.7870553731918335),
 ..........#省略展示..........
 (&amp;#39;智能识别&amp;#39;, 0.6703209280967712),
 (&amp;#39;结合人工智能&amp;#39;, 0.6701650619506836),
 (&amp;#39;VR技术&amp;#39;, 0.6699633002281189),
 (&amp;#39;人工智能芯片&amp;#39;, 0.6690542101860046),
 (&amp;#39;人工智能数据分析&amp;#39;, 0.6689168214797974),
 (&amp;#39;AR技术&amp;#39;, 0.6688560843467712)]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;br&gt;之后Word2Vec可以根据初始种子词进行扩充，再经过人工检查，最终构建「&lt;strong&gt;人工智能词典&lt;/strong&gt;」(论文附表3截图), 我将其整理为 &lt;em&gt;&lt;strong&gt;AI-Words&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/02-ai-words.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;AI_Words&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;机器翻译|机器学习|计算机视觉|人机交互|深度学习|神经网络|生物识别|数据挖掘|特征识别|语音合成|语音识别|知识图谱|智慧银行|智能保险|人机协同|智能监管|智能教育|智能客服|智能零售|智能农业|智能投顾|增强现实|虚拟现实|智能医疗|智能语音|智能政务|自动驾驶|智能运输|卷积神经网络|声纹识别|特征提取|无人驾驶|人脸识别|商业智能|循环神经网络|大数据营销|大数据分析|大数据处理|支持向量机|长短期记忆|机器人流程|自然语言|分布式计算|可穿戴产品|大数据管理|智能传感器|模式识别|边缘计算|大数据平台|语音交互|智能环保|人机对话|深度神经网络|大数据运营&amp;#39;&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;AI_Words&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;三准备数据&#34;&gt;三、准备数据&lt;/h2&gt;
&lt;p&gt;为了保证数据质量， 论文对样本进行的操作&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;1. 剔除金融行业公司；
2. 剔除信息传输、软件和信息技术 服务业以及科学研究和技术服务行业，原因在于这些行业天生使用云计算、大数据以及人工智能技术并披露 相关信息，可能无法清楚判断这些企业应用人工智能技术对其生产效率的影响；
3. 剔除当年处于 ST 和*ST 状 态的样本；
4. 剔除数据缺失的样本
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;p&gt;大邓这里有几个数据文件，经过一些操作(字段名统一、 整理会计年度、合并多源数据)，就能实现论文中的样本操作。&lt;strong&gt;文末有数据获取方式&lt;/strong&gt; 。&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;数据&lt;/th&gt;
&lt;th&gt;文件名&lt;/th&gt;
&lt;th&gt;所含字段&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://textdata.cn/blog/2023-03-23-china-a-share-market-dataset-mda-from-01-to-21/&#34;&gt;2001-2022年A股上市公司年报&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;A01-22.csv.gz&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;仅含&lt;em&gt;&lt;strong&gt;code&lt;/strong&gt;&lt;/em&gt; 、 &lt;em&gt;&lt;strong&gt;year&lt;/strong&gt;&lt;/em&gt; 、 &lt;em&gt;&lt;strong&gt;text&lt;/strong&gt;&lt;/em&gt; 三个字段&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://textdata.cn/blog/2023-03-23-china-a-share-market-dataset-mda-from-01-to-21/&#34;&gt;2001-2022年A股上市公司管理层讨论与分析&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;mda01-22.csv.gz&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;仅含&lt;em&gt;&lt;strong&gt;code&lt;/strong&gt;&lt;/em&gt; 、 &lt;em&gt;&lt;strong&gt;year&lt;/strong&gt;&lt;/em&gt; 、 &lt;em&gt;&lt;strong&gt;text&lt;/strong&gt;&lt;/em&gt; 三个字段&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://textdata.cn/blog/2024-04-16-china-listed-company-information-dataset/&#34;&gt;2000-2022年A股上市公司基本信息&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;上市公司基本信息2000-2022.csv&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;含&lt;em&gt;&lt;strong&gt;Symbol&lt;/strong&gt;&lt;/em&gt;、&lt;em&gt;&lt;strong&gt;FullName&lt;/strong&gt;&lt;/em&gt;、&lt;em&gt;&lt;strong&gt;ShortName&lt;/strong&gt;&lt;/em&gt;、&lt;em&gt;&lt;strong&gt;IndustryName&lt;/strong&gt;&lt;/em&gt;、&lt;em&gt;&lt;strong&gt;EndDate&lt;/strong&gt;&lt;/em&gt;等 39 个字段。&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;字段含义&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;[年报、管理层讨论与分析数据]
- year 会计年度
- text 年报文本 或 管理层讨论与分析文本
- code 股票代码

[A股基本信息]
- Symbol 股票代码
- ShortName 股票简称， 一般ST字符会出现在这里
- FullName 中文全称
- EndDate 统计截止日期
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;br&gt;
&lt;h3 id=&#34;31-读取数据&#34;&gt;3.1 读取数据&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://textdata.cn/blog/2023-03-23-china-a-share-market-dataset-mda-from-01-to-21/&#34;&gt;2001-2022年A股上市公司管理层讨论与分析&lt;/a&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pandas&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pd&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;#读取数据&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;mda_df&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read_csv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;data/mda01-22.csv.gz&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;compression&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;gzip&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;c1&#34;&gt;#将year更改为字符串格式&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;mda_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;year&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;mda_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;year&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;astype&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;str&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;mda_df&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/03-mda-df.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;p&gt;&lt;a href=&#34;https://textdata.cn/blog/2024-04-16-china-listed-company-information-dataset/&#34;&gt;2000-2022年A股上市公司基本信息&lt;/a&gt; 含 行业信息、公司简称里ST等信息， 可以按条件筛选记录。同时，也要构造出 year、code字段，方便后续与mda_df 交集并表。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;ind_df&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read_csv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;data/上市公司基本信息2000-2022.csv&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;ind_df&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ind_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ind_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;Symbol&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;!=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;股票代码&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;ind_df&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/04-ind_df.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;32-筛选样本&#34;&gt;3.2 筛选样本&lt;/h3&gt;
&lt;p&gt;为了保证数据质量， 论文对样本进行的操作&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;1. 剔除金融行业公司；
2. 剔除信息传输、软件和信息技术 服务业以及科学研究和技术服务行业，原因在于这些行业天生使用云计算、大数据以及人工智能技术并披露 相关信息，可能无法清楚判断这些企业应用人工智能技术对其生产效率的影响；
3. 剔除当年处于 ST 和 ``*ST`` 状态的样本；
4. 剔除数据缺失的样本
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;p&gt;筛选记录的代码&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;c1&#34;&gt;#mask1筛选出金融、信息、科学研究、技术服务等上市公司&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;mask1&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ind_df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;IndustryName&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;str&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;contains&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;金融|信息|科学研究|技术服务&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;c1&#34;&gt;#mask2筛选出ST和*ST的企业。&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;mask2&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ind_df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ShortName&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;str&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;contains&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;ST&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;c1&#34;&gt;#剔除掉符合mask1和mask2条件的企业&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;ind_df&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ind_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mask1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mask2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)]&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;#将ind_df中年份、股票代码相关字段改名为【year】【code】，方便与 mda_df并表&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;ind_df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;rename&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;columns&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;Symbol&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;code&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;},&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;inplace&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;ind_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;year&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ind_df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;EndDate&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;apply&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;lambda&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;date&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;date&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[:&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;ind_df&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ind_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;year&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;code&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;FullName&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]]&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;ind_df&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/05-ind_df.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;p&gt;以 &lt;em&gt;&lt;strong&gt;交集(inner)&lt;/strong&gt;&lt;/em&gt; 方式合并 &lt;em&gt;&lt;strong&gt;mda_df&lt;/strong&gt;&lt;/em&gt;  和  &lt;em&gt;&lt;strong&gt;ind_df&lt;/strong&gt;&lt;/em&gt;，  相当于剔除了mda数据中金融、信息、科学研究、技术服务、ST、&lt;code&gt;*ST&lt;/code&gt; 公司&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;mda_df2 = pd.merge(mda_df, ind_df, on=[&amp;#39;code&amp;#39;, &amp;#39;year&amp;#39;], how=&amp;#39;inner&amp;#39;)
mda_df2 = mda_df2[[&amp;#39;FullName&amp;#39;, &amp;#39;year&amp;#39;, &amp;#39;code&amp;#39;, &amp;#39;text&amp;#39;]]
mda_df2
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/06-mda-df2.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;h2 id=&#34;四测量ai指标&#34;&gt;四、测量AI指标&lt;/h2&gt;
&lt;p&gt;测量人工智能指标代码比较简单，&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;选中 &lt;em&gt;&lt;strong&gt;text&lt;/strong&gt;&lt;/em&gt;字段, 利用字符串属性 &lt;em&gt;&lt;strong&gt;.str.count()&lt;/strong&gt;&lt;/em&gt; 测量 &lt;em&gt;&lt;strong&gt;AI-Words&lt;/strong&gt;&lt;/em&gt; 出现次数，&lt;/li&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;np.log&lt;/strong&gt;&lt;/em&gt; 自然对数处理&lt;/li&gt;
&lt;li&gt;选择必要的字段&lt;em&gt;&lt;strong&gt;year&lt;/strong&gt;&lt;/em&gt;、&lt;em&gt;&lt;strong&gt;code&lt;/strong&gt;&lt;/em&gt;、&lt;em&gt;&lt;strong&gt;AI&lt;/strong&gt;&lt;/em&gt; 进行保存和展示&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;numpy&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;np&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;#测量企业人工智能指数&lt;/span&gt;
&lt;span class=&#34;c1&#34;&gt;#计算结果保存为字段AI&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;mda_df2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;AI&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;np&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;log&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mda_df2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;text&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;str&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;count&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;AI_Words&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;mda_df3&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;mda_df2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;year&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;code&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;AI&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]]&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;#保存为csv/xlsx&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;mda_df3&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;to_csv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;A股人工智能指标2001-2022(mda).csv&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;index&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;False&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;mda_df3&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;to_excel&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;A股人工智能指标2001-2022(mda).xlsx&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;index&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;False&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;#展示结果&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;mda_df3&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/07-ai-index.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;br&gt;
&lt;h2 id=&#34;五获取资料&#34;&gt;五、获取资料&lt;/h2&gt;
&lt;h3 id=&#34;51-免费说明&#34;&gt;5.1 免费说明&lt;/h3&gt;
&lt;p&gt;阅读是免费的， 推文内的相关模型、安装包、数据是付费获取。&lt;/p&gt;
&lt;p&gt;今日推文最核心的python代码只有2行， 看到就赚到！今日推文要计算「&lt;em&gt;&lt;strong&gt;企业人工智能指数&lt;/strong&gt;&lt;/em&gt;」，&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;c1&#34;&gt;#AI相关词&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;AI_Words&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;机器翻译|机器学习|计算机视觉|人机交互|深度学习|神经网络|生物识别|数据挖掘|特征识别|语音合成|语音识别|知识图谱|智慧银行|智能保险|人机协同|智能监管|智能教育|智能客服|智能零售|智能农业|智能投顾|增强现实|虚拟现实|智能医疗|智能语音|智能政务|自动驾驶|智能运输|卷积神经网络|声纹识别|特征提取|无人驾驶|人脸识别|商业智能|循环神经网络|大数据营销|大数据分析|大数据处理|支持向量机|长短期记忆|机器人流程|自然语言|分布式计算|可穿戴产品|大数据管理|智能传感器|模式识别|边缘计算|大数据平台|语音交互|智能环保|人机对话|深度神经网络|大数据运营&amp;#39;&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;#企业人工智能指数，保存为字段AI&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;mda_df2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;AI&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;np&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;log&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mda_df2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;text&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;str&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;count&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;AI_Words&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h3 id=&#34;52-付费说明&#34;&gt;5.2 付费说明&lt;/h3&gt;
&lt;p&gt;内容整理不易， 想尽快复现本文的同学可以购买对应的数据、安装包、Word2Vec模型。加 &lt;em&gt;&lt;strong&gt;WeChat: 372335839&lt;/strong&gt;&lt;/em&gt; ， 备注 「&lt;strong&gt;姓名-学校-专业&lt;/strong&gt;」。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;- 打包价300元, 资料含
   1. 专利摘要Word2Vec模型文件(1000w专利摘要文本.100.6.bin)
   2. 管理层讨论与分析Word2Vec模型文件(mda01-22.200.6.bin)
   3. cntext2安装文件(cntext-2.1.1-py3-none-any.whl)
   4. 管理层讨论与分析(mda01-22.csv.gz)、年报(A01-22.csv.gz)
   5. 上市公司基本信息2000-2022.csv
   6. A股人工智能指标2001-2022(mda).xlsx


- 零卖价格明细
- 100元  cntext2安装文件(cntext-2.1.1-py3-none-any.whl)
- 100元  管理层讨论与分析(mda01-22.csv.gz)、年报(A01-22.csv.gz)
- 100元  管理层讨论与分析Word2Vec模型文件(mda01-22.200.6.bin)
- 100元  专利摘要Word2Vec模型文件(1000w专利摘要文本.100.6.bin)
- 50元   上市公司基本信息2000-2022.csv
- 50元   A股人工智能指标2001-2022(mda).xlsx
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h3 id=&#34;项目结构&#34;&gt;项目结构&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;- 管理世界2024企业人工智能文件夹
    - 代码.ipynb                                    #代码文件
    
    - data                                         #数据文件夹
       - A01-22.csv.gz                             #年报
       - mda01-22.csv.gz                           #md&amp;amp;a
       - 上市公司基本信息2000-2022.csv                #基本信息
       
    - A股人工智能指标2001-2022(mda).xlsx              #计算结果
    
    - Word2Vec                                     #模型文件夹
       - mda01-22.200.6.bin
       - mda01-22.200.6.bin.syn1neg.npy
       - mda01-22.200.6.bin.wv.vectors.npy
       - 1000w专利摘要文本.100.6.bin
       - 1000w专利摘要文本.100.6.bin.syn1neg.npy
       - 1000w专利摘要文本.100.6.bin.wv.vectors.npy
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;p&gt;相关内容请阅读&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://textdata.cn/blog/2024-04-27-cntext2x-tutorial/&#34;&gt;文本分析库cntext2.x使用说明文档&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://textdata.cn/blog/2023-03-23-china-a-share-market-dataset-mda-from-01-to-21/&#34;&gt;数据集 | 2001-2022年A股上市公司年报&amp;amp;管理层讨论与分析&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://textdata.cn/blog/2024-04-16-china-listed-company-information-dataset/&#34;&gt;数据集 | 2000-2022年A股上市公司基本信息&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://textdata.cn/blog/2023-03-24-load-w2v-and-expand-your-concpet-dicitonary/&#34;&gt;词向量 | 使用MD&amp;amp;A2001-2022语料训练Word2Vec模型&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://textdata.cn/blog/2023-11-10-training-word2vec-model-using-china-3751w-patent-application-dataset/&#34;&gt;词向量 | 使用1985年-2022年专利申请摘要训练word2vec模型&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
&lt;br&gt;
&lt;h2 id=&#34;广而告之&#34;&gt;广而告之&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/call_for_paper/&#34;&gt;长期征稿&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/we_need_you/&#34;&gt;长期招募小伙伴&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/management_python_course/&#34;&gt;付费视频课 | Python实证指标构建与文本分析&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
      <content:encoded><![CDATA[<h2 id="一案例">一、案例</h2>
<h3 id="11-文献">1.1 文献</h3>
<p>姚加权, 张锟澎, 郭李鹏, 冯绪. 人工智能如何提升企业生产效率？——基于劳动力技能结构调整的视角[J]. 管理世界, 2024, 40 (02): 101-116+133+117-122.</p>
<p>摘要:人工智能技术对实现经济的高质量发展具有重要意义。现有研究多聚焦于人工智能对宏观经济的影响，本文从企业层面考察了人工智能技术如何影响生产效率和劳动力技能结构。<strong>本文运用机器学习方法生成了「人工智能词典」，并对上市公司的年报和专利进行「文本分析」，进而构建了企业层面的「人工智能指标」</strong>。研究发现，人工智能显著提升了中国上市公司的生产率，并且该结论在一系列稳健性检验后依旧成立。在影响机制方面，人工智能通过促使企业减少常规低技能劳动力需求、增加非常规高技能劳动力需求的方式提升企业的生产率，这体现了企业劳动力技能结构的调整。异质性分析表明，产权性质、人才获得方式、劳动力保障、治理结构等企业层面因素对人工智能的生产率效应有较大影响。此外，企业所处的行业和地区层面因素也影响了人工智能的生产率效应。最后，本文发现人工智能提高了企业价值。本文加深了对微观企业层面人工智能在生产过程中所扮演角色的认知和理解，并为在微观企业层面推动人工智能技术发展提供了建议。</p>
<br>
<h3 id="12-指标构建步骤">1.2 指标构建步骤</h3>
<p>下图是论文中「人工智能指标」构建的流程图</p>
<p><img loading="lazy" src="img/01-steps.png" alt=""  />
</p>
<p>我们将步骤分成三步</p>
<ul>
<li>Step1. 训练Word2Vec模型构建「人工智能AI词典」, 共54个词</li>
<li>Step2. 统计上市公司 「年报」中AI词词频m，采用自然对数处理得到指标Ln(m+1)</li>
<li>Step3. 统计上市公司「MD&amp;A」数据中AI词词频n，采用自然对数处理得到指标Ln(n+1)</li>
<li>Step4. 根据上市公司申请专利的名称和摘要是否含AI词，统计上市公司AI专利申请数量p，采用自然对数处理得到指标Ln(p+1)</li>
</ul>
<blockquote>
<p>企业申请的人工智能专利代表企业已经拥有的人工智能技术，反映了企业人工智能技术的产出情况，能够与年报相互印证企业的人工智能技术水平</p>
</blockquote>
<p>为了减轻阅读压力，也为了减轻制作本文的工作量， 本文仅实现 Step1 、Step2 、Step3， 覆盖截图中的红色框范围内的内容。</p>
<br>
<h3 id="13-项目结构">1.3 项目结构</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">- 管理世界2024企业人工智能文件夹
    - 代码.ipynb                                    #代码文件
    
    - data                                         #数据文件夹
       - A01-22.csv.gz                             #年报
       - mda01-22.csv.gz                           #md&amp;a
       - 上市公司基本信息2000-2022.csv                #基本信息
       
    - A股人工智能指标2001-2022(mda).xlsx              #计算结果
    
    - Word2Vec                                     #模型文件夹
       - mda01-22.200.6.bin
       - mda01-22.200.6.bin.syn1neg.npy
       - mda01-22.200.6.bin.wv.vectors.npy
       - 1000w专利摘要文本.100.6.bin
       - 1000w专利摘要文本.100.6.bin.syn1neg.npy
       - 1000w专利摘要文本.100.6.bin.wv.vectors.npy
</code></pre></div><p><br><br></p>
<h2 id="二准备ai词典">二、准备AI词典</h2>
<ol>
<li>构造专利摘要语料、管理层讨论与分析语料，分别训练Word2Vec模型</li>
<li>构建人工智能种子词， 使用Word2Vec模型扩展并构建「人工智能词典」</li>
</ol>
<br>
<h3 id="21-训练word2vec模型">2.1 训练Word2Vec模型</h3>
<p>刚好之前分享过使用cntext库(2.0以上版本)训练Word2Vec， 相关推文</p>
<ul>
<li><a href="https://textdata.cn/blog/2023-03-24-load-w2v-and-expand-your-concpet-dicitonary/">词向量(付费) | 使用MD&amp;A2001-2022语料训练Word2Vec模型</a></li>
<li><a href="https://textdata.cn/blog/2023-11-10-training-word2vec-model-using-china-3751w-patent-application-dataset/">词向量(付费) | 使用1985年-2022年专利申请摘要训练word2vec模型</a></li>
</ul>
<p>分别对应 <em><strong>cntext-2.1.1-py3-none-any.whl</strong></em>、 <em><strong>mda01-22.200.6.bin</strong></em> 、 <em><strong>1000w专利摘要文本.100.6.bin</strong></em> 两个模型文件。<strong>文末有模型获取方式</strong>。</p>
<br>
<h3 id="22-导入word2vec">2.2 导入Word2Vec</h3>
<p>以 mda01-22.200.6.bin 为例， 使用cntext2读取模型， cntext安装和使用请参考 <a href="https://textdata.cn/blog/2024-04-27-cntext2x-tutorial/">文本分析库cntext2.x使用说明文档</a>。 <strong>文末有cntext获取方式</strong>。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>

<span class="c1">#查看cntext版本</span>
<span class="nb">print</span><span class="p">(</span><span class="n">ct</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span>

<span class="c1">#导入管理层讨论与分析的Word2Vec模型</span>
<span class="n">mda_w2v_m</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">load_w2v</span><span class="p">(</span><span class="s1">&#39;Word2Vec/mda01-22.200.6.bin&#39;</span><span class="p">)</span>
<span class="c1">#导入专利摘要Word2Vec模型</span>
<span class="c1">#pat_w2v_m = ct.load_w2v(&#39;Word2Vec/1000w专利摘要文本.100.6.bin&#39;)</span>

<span class="n">mda_w2v_m</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">2.1.1

Loading word2vec model...
&lt;gensim.models.word2vec.Word2Vec at 0x7dbf9afd0&gt;
</code></pre></div><br>
<p>查看某个词的词向量</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">mda_w2v_m.wv.get_vector(&#39;人工智能&#39;)
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">array([-3.8744571 , -0.5923845 , -1.8126943 ,  1.660894  ,  1.4194168 ,
        1.0365077 , -0.21333796, -0.60481924,  1.5012817 , -0.24060927,
       -1.7463511 , -2.1997519 , -0.66537315, -1.2665682 ,  0.14333063,
       -0.1268099 ,  2.005481  , -1.4638793 ,  3.7950375 ,  0.20866613,
        1.0281029 , -1.5495429 , -0.2518896 ,  1.4159175 ,  3.178865  ,
        .............................#省略展示..........................
       -1.2206184 ,  1.6766415 , -0.1082068 ,  0.62580353,  1.4639648 ,
        2.2743094 , -0.48386717,  1.3510187 ,  1.1698194 ,  0.72390413,
       -0.4855997 ,  1.0688399 ,  0.77217335, -1.4559731 ,  1.4391305 ,
        0.8412411 ,  2.359447  , -1.1504242 ,  1.3677332 , -0.92123735,
        1.281644  ,  0.67157453,  2.159804  ,  1.7593136 , -0.53061306,
       -0.77395666,  0.5912517 ,  1.9448034 ,  0.13023153,  0.6798518 ],
      dtype=float32)
</code></pre></div><br>
<h3 id="23-扩展词典">2.3 扩展词典</h3>
<p>我们每个人对人工智能都有所了解，脑海里首先能想到的词可以当做 「初始种子词」， 例如词语 <code>人工智能|人机对话|</code> 等。 本部分主要展示Word2Vec模型的近义词联想能力，</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">mda_w2v_m</span><span class="o">.</span><span class="n">wv</span><span class="o">.</span><span class="n">most_similar</span><span class="p">([</span><span class="s1">&#39;人工智能&#39;</span><span class="p">,</span> <span class="s1">&#39;人机对话&#39;</span><span class="p">],</span> <span class="n">topn</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">[(&#39;自然语言处理&#39;, 0.8055953979492188),
 (&#39;AI&#39;, 0.8050345778465271),
 (&#39;语音识别&#39;, 0.804234504699707),
 (&#39;NLP&#39;, 0.7967724800109863),
 (&#39;交互技术&#39;, 0.7902386784553528),
 (&#39;智能语音&#39;, 0.7870553731918335),
 ..........#省略展示..........
 (&#39;智能识别&#39;, 0.6703209280967712),
 (&#39;结合人工智能&#39;, 0.6701650619506836),
 (&#39;VR技术&#39;, 0.6699633002281189),
 (&#39;人工智能芯片&#39;, 0.6690542101860046),
 (&#39;人工智能数据分析&#39;, 0.6689168214797974),
 (&#39;AR技术&#39;, 0.6688560843467712)]
</code></pre></div><p><br>之后Word2Vec可以根据初始种子词进行扩充，再经过人工检查，最终构建「<strong>人工智能词典</strong>」(论文附表3截图), 我将其整理为 <em><strong>AI-Words</strong></em></p>
<p><img loading="lazy" src="img/02-ai-words.png" alt=""  />
</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">AI_Words</span> <span class="o">=</span> <span class="s1">&#39;机器翻译|机器学习|计算机视觉|人机交互|深度学习|神经网络|生物识别|数据挖掘|特征识别|语音合成|语音识别|知识图谱|智慧银行|智能保险|人机协同|智能监管|智能教育|智能客服|智能零售|智能农业|智能投顾|增强现实|虚拟现实|智能医疗|智能语音|智能政务|自动驾驶|智能运输|卷积神经网络|声纹识别|特征提取|无人驾驶|人脸识别|商业智能|循环神经网络|大数据营销|大数据分析|大数据处理|支持向量机|长短期记忆|机器人流程|自然语言|分布式计算|可穿戴产品|大数据管理|智能传感器|模式识别|边缘计算|大数据平台|语音交互|智能环保|人机对话|深度神经网络|大数据运营&#39;</span>
<span class="n">AI_Words</span>
</code></pre></div><p><br><br></p>
<h2 id="三准备数据">三、准备数据</h2>
<p>为了保证数据质量， 论文对样本进行的操作</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">1. 剔除金融行业公司；
2. 剔除信息传输、软件和信息技术 服务业以及科学研究和技术服务行业，原因在于这些行业天生使用云计算、大数据以及人工智能技术并披露 相关信息，可能无法清楚判断这些企业应用人工智能技术对其生产效率的影响；
3. 剔除当年处于 ST 和*ST 状 态的样本；
4. 剔除数据缺失的样本
</code></pre></div><br>
<p>大邓这里有几个数据文件，经过一些操作(字段名统一、 整理会计年度、合并多源数据)，就能实现论文中的样本操作。<strong>文末有数据获取方式</strong> 。</p>
<table>
<thead>
<tr>
<th>数据</th>
<th>文件名</th>
<th>所含字段</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://textdata.cn/blog/2023-03-23-china-a-share-market-dataset-mda-from-01-to-21/">2001-2022年A股上市公司年报</a></td>
<td><em><strong>A01-22.csv.gz</strong></em></td>
<td>仅含<em><strong>code</strong></em> 、 <em><strong>year</strong></em> 、 <em><strong>text</strong></em> 三个字段</td>
</tr>
<tr>
<td><a href="https://textdata.cn/blog/2023-03-23-china-a-share-market-dataset-mda-from-01-to-21/">2001-2022年A股上市公司管理层讨论与分析</a></td>
<td><em><strong>mda01-22.csv.gz</strong></em></td>
<td>仅含<em><strong>code</strong></em> 、 <em><strong>year</strong></em> 、 <em><strong>text</strong></em> 三个字段</td>
</tr>
<tr>
<td><a href="https://textdata.cn/blog/2024-04-16-china-listed-company-information-dataset/">2000-2022年A股上市公司基本信息</a></td>
<td><em><strong>上市公司基本信息2000-2022.csv</strong></em></td>
<td>含<em><strong>Symbol</strong></em>、<em><strong>FullName</strong></em>、<em><strong>ShortName</strong></em>、<em><strong>IndustryName</strong></em>、<em><strong>EndDate</strong></em>等 39 个字段。</td>
</tr>
</tbody>
</table>
<p>字段含义</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">[年报、管理层讨论与分析数据]
- year 会计年度
- text 年报文本 或 管理层讨论与分析文本
- code 股票代码

[A股基本信息]
- Symbol 股票代码
- ShortName 股票简称， 一般ST字符会出现在这里
- FullName 中文全称
- EndDate 统计截止日期
</code></pre></div><br>
<br>
<h3 id="31-读取数据">3.1 读取数据</h3>
<p><a href="https://textdata.cn/blog/2023-03-23-china-a-share-market-dataset-mda-from-01-to-21/">2001-2022年A股上市公司管理层讨论与分析</a></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="c1">#读取数据</span>
<span class="n">mda_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;data/mda01-22.csv.gz&#39;</span><span class="p">,</span> <span class="n">compression</span><span class="o">=</span><span class="s1">&#39;gzip&#39;</span><span class="p">)</span>
<span class="c1">#将year更改为字符串格式</span>
<span class="n">mda_df</span><span class="p">[</span><span class="s1">&#39;year&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">mda_df</span><span class="p">[</span><span class="s1">&#39;year&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">str</span><span class="p">)</span>
<span class="n">mda_df</span>
</code></pre></div><p><img loading="lazy" src="img/03-mda-df.png" alt=""  />
</p>
<br>
<p><a href="https://textdata.cn/blog/2024-04-16-china-listed-company-information-dataset/">2000-2022年A股上市公司基本信息</a> 含 行业信息、公司简称里ST等信息， 可以按条件筛选记录。同时，也要构造出 year、code字段，方便后续与mda_df 交集并表。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">ind_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;data/上市公司基本信息2000-2022.csv&#39;</span><span class="p">)</span>
<span class="n">ind_df</span> <span class="o">=</span> <span class="n">ind_df</span><span class="p">[</span><span class="n">ind_df</span><span class="p">[</span><span class="s1">&#39;Symbol&#39;</span><span class="p">]</span><span class="o">!=</span><span class="s1">&#39;股票代码&#39;</span><span class="p">]</span>
<span class="n">ind_df</span>
</code></pre></div><p><img loading="lazy" src="img/04-ind_df.png" alt=""  />
</p>
<br>
<h3 id="32-筛选样本">3.2 筛选样本</h3>
<p>为了保证数据质量， 论文对样本进行的操作</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">1. 剔除金融行业公司；
2. 剔除信息传输、软件和信息技术 服务业以及科学研究和技术服务行业，原因在于这些行业天生使用云计算、大数据以及人工智能技术并披露 相关信息，可能无法清楚判断这些企业应用人工智能技术对其生产效率的影响；
3. 剔除当年处于 ST 和 ``*ST`` 状态的样本；
4. 剔除数据缺失的样本
</code></pre></div><br>
<p>筛选记录的代码</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#mask1筛选出金融、信息、科学研究、技术服务等上市公司</span>
<span class="n">mask1</span> <span class="o">=</span> <span class="n">ind_df</span><span class="o">.</span><span class="n">IndustryName</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="s1">&#39;金融|信息|科学研究|技术服务&#39;</span><span class="p">)</span>
<span class="c1">#mask2筛选出ST和*ST的企业。</span>
<span class="n">mask2</span> <span class="o">=</span> <span class="n">ind_df</span><span class="o">.</span><span class="n">ShortName</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="s1">&#39;ST&#39;</span><span class="p">)</span>
<span class="c1">#剔除掉符合mask1和mask2条件的企业</span>
<span class="n">ind_df</span> <span class="o">=</span> <span class="n">ind_df</span><span class="p">[(</span><span class="o">-</span><span class="n">mask1</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="o">-</span><span class="n">mask2</span><span class="p">)]</span>

<span class="c1">#将ind_df中年份、股票代码相关字段改名为【year】【code】，方便与 mda_df并表</span>
<span class="n">ind_df</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;Symbol&#39;</span><span class="p">:</span> <span class="s1">&#39;code&#39;</span><span class="p">},</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">ind_df</span><span class="p">[</span><span class="s1">&#39;year&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">ind_df</span><span class="o">.</span><span class="n">EndDate</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">date</span><span class="p">:</span> <span class="n">date</span><span class="p">[:</span><span class="mi">4</span><span class="p">])</span>
<span class="n">ind_df</span> <span class="o">=</span> <span class="n">ind_df</span><span class="p">[[</span><span class="s1">&#39;year&#39;</span><span class="p">,</span> <span class="s1">&#39;code&#39;</span><span class="p">,</span> <span class="s1">&#39;FullName&#39;</span><span class="p">]]</span>
<span class="n">ind_df</span>
</code></pre></div><p><img loading="lazy" src="img/05-ind_df.png" alt=""  />
</p>
<br>
<p>以 <em><strong>交集(inner)</strong></em> 方式合并 <em><strong>mda_df</strong></em>  和  <em><strong>ind_df</strong></em>，  相当于剔除了mda数据中金融、信息、科学研究、技术服务、ST、<code>*ST</code> 公司</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">mda_df2 = pd.merge(mda_df, ind_df, on=[&#39;code&#39;, &#39;year&#39;], how=&#39;inner&#39;)
mda_df2 = mda_df2[[&#39;FullName&#39;, &#39;year&#39;, &#39;code&#39;, &#39;text&#39;]]
mda_df2
</code></pre></div><p><img loading="lazy" src="img/06-mda-df2.png" alt=""  />
</p>
<br>
<h2 id="四测量ai指标">四、测量AI指标</h2>
<p>测量人工智能指标代码比较简单，</p>
<ol>
<li>选中 <em><strong>text</strong></em>字段, 利用字符串属性 <em><strong>.str.count()</strong></em> 测量 <em><strong>AI-Words</strong></em> 出现次数，</li>
<li><em><strong>np.log</strong></em> 自然对数处理</li>
<li>选择必要的字段<em><strong>year</strong></em>、<em><strong>code</strong></em>、<em><strong>AI</strong></em> 进行保存和展示</li>
</ol>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="c1">#测量企业人工智能指数</span>
<span class="c1">#计算结果保存为字段AI</span>
<span class="n">mda_df2</span><span class="p">[</span><span class="s1">&#39;AI&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">mda_df2</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="n">AI_Words</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">mda_df3</span> <span class="o">=</span> <span class="n">mda_df2</span><span class="p">[[</span><span class="s1">&#39;year&#39;</span><span class="p">,</span> <span class="s1">&#39;code&#39;</span><span class="p">,</span> <span class="s1">&#39;AI&#39;</span><span class="p">]]</span>

<span class="c1">#保存为csv/xlsx</span>
<span class="n">mda_df3</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;A股人工智能指标2001-2022(mda).csv&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">mda_df3</span><span class="o">.</span><span class="n">to_excel</span><span class="p">(</span><span class="s1">&#39;A股人工智能指标2001-2022(mda).xlsx&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1">#展示结果</span>
<span class="n">mda_df3</span>
</code></pre></div><p><img loading="lazy" src="img/07-ai-index.png" alt=""  />
</p>
<br>
<br>
<h2 id="五获取资料">五、获取资料</h2>
<h3 id="51-免费说明">5.1 免费说明</h3>
<p>阅读是免费的， 推文内的相关模型、安装包、数据是付费获取。</p>
<p>今日推文最核心的python代码只有2行， 看到就赚到！今日推文要计算「<em><strong>企业人工智能指数</strong></em>」，</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#AI相关词</span>
<span class="n">AI_Words</span> <span class="o">=</span> <span class="s1">&#39;机器翻译|机器学习|计算机视觉|人机交互|深度学习|神经网络|生物识别|数据挖掘|特征识别|语音合成|语音识别|知识图谱|智慧银行|智能保险|人机协同|智能监管|智能教育|智能客服|智能零售|智能农业|智能投顾|增强现实|虚拟现实|智能医疗|智能语音|智能政务|自动驾驶|智能运输|卷积神经网络|声纹识别|特征提取|无人驾驶|人脸识别|商业智能|循环神经网络|大数据营销|大数据分析|大数据处理|支持向量机|长短期记忆|机器人流程|自然语言|分布式计算|可穿戴产品|大数据管理|智能传感器|模式识别|边缘计算|大数据平台|语音交互|智能环保|人机对话|深度神经网络|大数据运营&#39;</span>

<span class="c1">#企业人工智能指数，保存为字段AI</span>
<span class="n">mda_df2</span><span class="p">[</span><span class="s1">&#39;AI&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">mda_df2</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="n">AI_Words</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
</code></pre></div><br>
<h3 id="52-付费说明">5.2 付费说明</h3>
<p>内容整理不易， 想尽快复现本文的同学可以购买对应的数据、安装包、Word2Vec模型。加 <em><strong>WeChat: 372335839</strong></em> ， 备注 「<strong>姓名-学校-专业</strong>」。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">- 打包价300元, 资料含
   1. 专利摘要Word2Vec模型文件(1000w专利摘要文本.100.6.bin)
   2. 管理层讨论与分析Word2Vec模型文件(mda01-22.200.6.bin)
   3. cntext2安装文件(cntext-2.1.1-py3-none-any.whl)
   4. 管理层讨论与分析(mda01-22.csv.gz)、年报(A01-22.csv.gz)
   5. 上市公司基本信息2000-2022.csv
   6. A股人工智能指标2001-2022(mda).xlsx


- 零卖价格明细
- 100元  cntext2安装文件(cntext-2.1.1-py3-none-any.whl)
- 100元  管理层讨论与分析(mda01-22.csv.gz)、年报(A01-22.csv.gz)
- 100元  管理层讨论与分析Word2Vec模型文件(mda01-22.200.6.bin)
- 100元  专利摘要Word2Vec模型文件(1000w专利摘要文本.100.6.bin)
- 50元   上市公司基本信息2000-2022.csv
- 50元   A股人工智能指标2001-2022(mda).xlsx
</code></pre></div><br>
<h3 id="项目结构">项目结构</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">- 管理世界2024企业人工智能文件夹
    - 代码.ipynb                                    #代码文件
    
    - data                                         #数据文件夹
       - A01-22.csv.gz                             #年报
       - mda01-22.csv.gz                           #md&amp;a
       - 上市公司基本信息2000-2022.csv                #基本信息
       
    - A股人工智能指标2001-2022(mda).xlsx              #计算结果
    
    - Word2Vec                                     #模型文件夹
       - mda01-22.200.6.bin
       - mda01-22.200.6.bin.syn1neg.npy
       - mda01-22.200.6.bin.wv.vectors.npy
       - 1000w专利摘要文本.100.6.bin
       - 1000w专利摘要文本.100.6.bin.syn1neg.npy
       - 1000w专利摘要文本.100.6.bin.wv.vectors.npy
</code></pre></div><br>
<p>相关内容请阅读</p>
<ul>
<li>
<p><a href="https://textdata.cn/blog/2024-04-27-cntext2x-tutorial/">文本分析库cntext2.x使用说明文档</a></p>
</li>
<li>
<p><a href="https://textdata.cn/blog/2023-03-23-china-a-share-market-dataset-mda-from-01-to-21/">数据集 | 2001-2022年A股上市公司年报&amp;管理层讨论与分析</a></p>
</li>
<li>
<p><a href="https://textdata.cn/blog/2024-04-16-china-listed-company-information-dataset/">数据集 | 2000-2022年A股上市公司基本信息</a></p>
</li>
<li>
<p><a href="https://textdata.cn/blog/2023-03-24-load-w2v-and-expand-your-concpet-dicitonary/">词向量 | 使用MD&amp;A2001-2022语料训练Word2Vec模型</a></p>
</li>
<li>
<p><a href="https://textdata.cn/blog/2023-11-10-training-word2vec-model-using-china-3751w-patent-application-dataset/">词向量 | 使用1985年-2022年专利申请摘要训练word2vec模型</a></p>
</li>
</ul>
<br>
<br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>中国工业经济 | 使用Python测量MD&amp;A信息含量指标</title>
      <link>https://textdata.cn/blog/2023-01-06-mda_informative_content/</link>
      <pubDate>Sun, 21 Apr 2024 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-01-06-mda_informative_content/</guid>
      <description>每个上市公司 MD&amp;amp;A 信息不可避免地在某种程度上与同行业其他上市公司以及市场其他行业上市公司存在一定的相似性， 甚至某些公司可能直接参考其他公司 MD&amp;amp;A 的表述。 可以将与行业其他公司或其他行业的公司重复或相似的信息定义为不具有信息含量的内容，同时将不同的信息定义为真正具有信息含量的内容，简称为信息含量。In this paper ， we discuss the impact of informative content of Management Discussion and Analysis （ MD&amp;amp;A ） on stock price crash risk using the method of text vectorization. Using the MD&amp;amp;A in annual reports of China A -share listed firms from 2007 to 2015 ， we find that the informative content of MD&amp;amp;A can reduce future stock price crash risk ， and the informative content of preview section has significant effects on stock price crash risk ， while that of review section does not. After controlling endogeneity ， the conclusions still stand. Further ， we study the influence of informative content of preview section on crash risk from the aspects of readability and information opaqueness. The results show that the higher readability and higher information opaqueness ， the greater impact of informative content has on stock price crash risk. Finally ， after changing the calculation of crash risk ， and controlling the impact of stock price synchronicity ， the informative content of preview section still reduces stock price crash risk. This paper enriches the influencing factors of stock price crash risk and improves the study of the usefulness of MD&amp;amp;A from the perspective of incremental information ， which has important theoretical and practical significance.</description>
      <content:encoded><![CDATA[<p>由于任何一个行为主体都会受到 <strong>周围环境</strong> 和 <strong>自身经历</strong>(认知) 影响，所发表的信息必然包含通 <strong>环境信息</strong> 和 <strong>特异性信息</strong> 。如何通过文本，表征文本的通用信息和特意性信息，如何测量行为主体发表内容的信息含量，带着这些疑问， 一起读这篇17年的论文的方法论部分，并用Python将其实现。</p>
<p><br><br></p>
<h2 id="一信息含量">一、信息含量</h2>
<p>由于每个公司的 MD&amp;A 中不仅包括公司经营状况等历史信息， 也包括与其他公司相似的信息， 如外部环境、市场格局、风险因素等内容。 因此， 本文参考 Hanley and Hoberg （ 2010 ）， 从行业和市场两个维度来考察和定义公司 MD&amp;A 中的信息含量。</p>
<ul>
<li><strong>市场因素</strong>， 所有上市公司都处于相同的宏观经济环境、风险因素和政治、政策背景之下；</li>
<li><strong>行业因素</strong>， 同一行业中的各上市公司又面临着相似的产业政策、竞争环境和市场特征。</li>
</ul>
<p>由此可见， 每个上市公司 MD&amp;A 信息不可避免地在某种程度上与同行业其他上市公司以及市场其他行业上市公司存在一定的相似性， 甚至某些公司可能直接参考其他公司 MD&amp;A 的表述。 <strong>可以将与行业其他公司或其他行业的公司重复或相似的信息定义为不具有信息含量的内容，同时将不同的信息定义为真正具有信息含量的内容，简称为信息含量</strong>。</p>
<br>
<blockquote>
<p>孟庆斌, 杨俊华, and 鲁冰. &ldquo;管理层讨论与分析披露的信息含量与股价崩盘风险——基于文本向量化方法的研究.&rdquo; 中国工业经济 12 (2017): 132-150.</p>
</blockquote>
<br>
<h3 id="11-摘要">1.1 摘要</h3>
<p>本文采用文本向量化的方法， 对 2007—2015 年中国 A 股上市公司年报的管理层讨论与分析（MD&amp;A）所披露的信息含量加以度量， 研究其对股价崩盘风险的影响。 研究发现， MD&amp;A 的信息含量越高，未来股价崩盘风险越低。 将 MD&amp;A 进一步划分为回顾部分和展望部分后发现，仅有展望部分中的信息含量能够显著降低未来股价崩盘风险。 在控制内生性问题之后，本文的结论依然成立。 本文还分别从文本可读性和信息不对称的角度出发，研究它们对二者关系的影响。 结果表明，信息的可读性越高，信息不对称程度越高，展望部分的信息含量对股价崩盘风险的降低作用越大。 在重新定义股价崩盘风险的计算区间以及控制股价同步性之后， MD&amp;A 展望部分的信息含量依然能够显著降低股价崩盘风险， 表明本文的结论是稳健的。 本文从文本信息的角度丰富了股价崩盘风险影响因素的研究， 同时也从增量信息的角度完善了 MD&amp;A 信息有用性的研究，具有重要的理论和现实意义。</p>
<br>
<h3 id="12-样本选择和处理">1.2 样本选择和处理</h3>
<p>本文选取 2007 — 2015 年中国上市公司年报中的 MD&amp;A 信息作为研究样本。 之所以选取 2007 年作为样本的起点， 是因为从 2007 年开始， MD&amp;A 在企业定期报告中的披露要求已经较为完善， 而且 2007 年是中国会计准则国际趋同的重要时点， 新制定的《企业会计准则》已经开始实施， 为避免前后会计准则差异而产生的影响， 因此选取 2007 年作为样本区间的起点。</p>
<p>本文所使用的上市公司年度报告均来自于巨潮资讯网。 数据处理过程如下：</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">（ 1 ）剔除金融行业、 ST 和 *ST 类企业， 以及上市时间不足一年的企业。

（ 2 ）从 MD&amp;A 的内容中分别提取回顾和展望部分， 保存为回顾信息文件和展望信息文件， 部分无法抓取出的年报通过手工收集处理。

（ 3 ）文本处理-文本向量化。 借鉴 Hanley and Hoberg （ 2010 ）的研究思路， 将每个 MD&amp;A 文本通过向量的 形式表示出来， 其每个元素为文本中的每个词语出现的频率。 例如， 假设某 MD&amp;A 文本中包含 10000 个词， 则该文本对应一个 10000×1 维的向量。 举一个简单的例子来描述文本向量化的过程： 在两个简化的 MD&amp;A 文本中， 一个包含“我们生产土豆和生产玉米”， 另一个包含“我们生产家具”， 剔除连词“和”、代词“我们”之后， 只剩下“生产”、“土豆”、“玉米”、“家具”这 4 个词。 那么， 在第一个 MD&amp;A 文本中， “生产”、“土豆”和“玉米”分别出现了 2 次、 1 次和 1 次， 而“家具”出现 0 次， 所以该 文本的向量为 {2 ， 1 ， 1 ， 0} ， 同样得到第二个文本的向量为 {1 ， 0 ， 0 ， 1} 。

（ 4 ）向量标准化。 对于向量化的文本， 仍需解决文本长度不同导致的结果不可比问题。 一般来说， 某一个词在长文本中重复出现的次数较多， 在短文本中重复出现的次数较少， 但并不能因此说 长文本比短文本的信息量大。 为此， 本文进一步将这些向量进行标准化处理， 即将该向量除以文本 中单词的总数， 得到标准化后的向量。 在上面的例子中， 两个公司的标准化之后的向量就成为了 {0.50 ， 0.25 ， 0.25 ， 0} 和 {0.50 ， 0 ， 0 ， 0.50} 。
</code></pre></div><br>
<h3 id="13-文件目录">1.3 文件目录</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">管理层讨论信息含量/
├── 代码.ipynb
├── data/
│   ├── 行业代码00-22.xlsx
│   └── mda01-22.csv.gz
├── mda_infor2001-2022.csv
├── mda_infor_output/
│   └── 2022/
│       ├── A000002.csv
│       ├── A000004.csv
│       ├── A000005.csv
│       ├── A000006.csv
│       ├── ...
│   └── 2021/
│       ├── A000002.csv
│       ├── A000004.csv
│       ├── A000005.csv
│       ├── A000006.csv
│       ├── ...
│   └── 2019/
│       ├── A000002.csv
│       ├── A000004.csv
│       ├── A000005.csv
│       ├── A000006.csv
│       ├── ...
│   └── ...
</code></pre></div><p><br><br></p>
<h2 id="二导入数据">二、导入数据</h2>
<p>这里准备了2001-2022年A股经营讨论与分析内容和行业代码数据。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;data/mda01-22.csv.gz&#39;</span><span class="p">,</span> <span class="n">compression</span><span class="o">=</span><span class="s1">&#39;gzip&#39;</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;会计年度&#39;</span><span class="p">,</span> <span class="s1">&#39;股票代码&#39;</span><span class="p">,</span> <span class="s1">&#39;经营讨论与分析内容&#39;</span><span class="p">]</span>

<span class="c1">#上市公司行业信息</span>
<span class="n">ind_info_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_excel</span><span class="p">(</span><span class="s1">&#39;data/行业代码00-22.xlsx&#39;</span><span class="p">)</span>


<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">ind_info_df</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;股票代码&#39;</span><span class="p">,</span> <span class="s1">&#39;会计年度&#39;</span><span class="p">],</span> <span class="n">how</span><span class="o">=</span><span class="s1">&#39;inner&#39;</span><span class="p">)</span>


<span class="c1"># 剔除金融行业处理</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="o">~</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;行业代码&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="s2">&#34;J&#34;</span><span class="p">)]</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="o">~</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;股票简称&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="s2">&#34;ST&#34;</span><span class="p">)]</span>

<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/df2.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="三以2020年为例">三、以2020年为例</h2>
<p>写代码先局部后整体，以2020年为例，如果2020年可以成功计算出信息含量，则可以for循环推广到所有股票所有年份。本章节需要做</p>
<ol>
<li>选定某年份，以2020年为例</li>
<li>定义transform函数，用于处理「经营讨论与分析内容」字段内的内容。</li>
<li>文本向量化，向量标准化。</li>
</ol>
<br>
<h3 id="31-选定2020年">3.1 选定2020年</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df_per_year</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;会计年度&#39;</span><span class="p">]</span><span class="o">==</span><span class="mi">2020</span><span class="p">]</span>
<span class="n">df_per_year</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">df_per_year</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/df3.png" alt=""  />
</p>
<br>
<h3 id="32-定义transform函数">3.2 定义transform函数</h3>
<p>定义 <em><strong>transform</strong></em> 函数，该函数可以处理「<em><strong>经营讨论与分析内容</strong></em>」字段内容，使其:</p>
<ol>
<li>只保留中文内容</li>
<li>剔除停用词</li>
<li>整理为用空格间隔的字符串(类西方语言文本格式)</li>
</ol>
<p>之后应用 <em><strong>transform</strong></em>函数， 使用 <strong>apply</strong> 方法， 处理  <em><strong>df_per_year[&lsquo;经营讨论与分析内容&rsquo;]</strong></em> 。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">re</span>
<span class="kn">import</span> <span class="nn">jieba</span>
<span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>
    
<span class="c1">#cntext1.x</span>
<span class="c1">#stopwords = ct.load_pkl_dict(&#39;STOPWORDS.pkl&#39;)[&#39;STOPWORDS&#39;][&#39;chinese&#39;]</span>

<span class="c1">#cntext2.x</span>
<span class="n">stopwords</span><span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">read_yaml_dict</span><span class="p">(</span><span class="s1">&#39;enzh_common_StopWords.yaml&#39;</span><span class="p">)[</span><span class="s1">&#39;Dictionary&#39;</span><span class="p">][</span><span class="s1">&#39;chinese&#39;</span><span class="p">]</span>

    


<span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="c1">#只保留md&amp;a中的中文内容</span>
    <span class="n">text</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">re</span><span class="o">.</span><span class="n">findall</span><span class="p">(</span><span class="s1">&#39;[</span><span class="se">\u4e00</span><span class="s1">-</span><span class="se">\u9fa5</span><span class="s1">]+&#39;</span><span class="p">,</span> <span class="n">text</span><span class="p">))</span>
    <span class="c1">#剔除停用词</span>
    <span class="n">words</span> <span class="o">=</span> <span class="p">[</span><span class="n">w</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">jieba</span><span class="o">.</span><span class="n">cut</span><span class="p">(</span><span class="n">text</span><span class="p">)</span> <span class="k">if</span> <span class="n">w</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">stopwords</span><span class="p">]</span>
    <span class="c1">#整理为用空格间隔的字符串(类西方语言文本格式)</span>
    <span class="k">return</span> <span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">words</span><span class="p">)</span>


<span class="n">df_per_year</span><span class="p">[</span><span class="s1">&#39;clean_text&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_per_year</span><span class="p">[</span><span class="s1">&#39;经营讨论与分析内容&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">transform</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">    Building prefix dict from the default dictionary ...
    Loading model from cache /var/folders/sc/3mnt5tgs419_hk7s16gq61p80000gn/T/jieba.cache
    Loading model cost 0.556 seconds.
    Prefix dict has been built successfully.
</code></pre></div><br>
<h3 id="33-文本向量化">3.3 文本向量化</h3>
<p>本小节要做:</p>
<ol>
<li>文本向量化</li>
<li>向量标准化</li>
<li>合并多个字段为新的df</li>
</ol>
<p>先将df_per_year[&lsquo;clean_text&rsquo;] 向量化，代码如下</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="o">%%</span><span class="n">time</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">CountVectorizer</span>

<span class="n">cv</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">(</span><span class="n">min_df</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span> <span class="n">max_df</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span> 
<span class="c1"># 生成稀疏bow矩阵</span>
<span class="n">dtm_per_year</span> <span class="o">=</span> <span class="n">cv</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df_per_year</span><span class="p">[</span><span class="s1">&#39;clean_text&#39;</span><span class="p">])</span> 
<span class="n">dtm_per_year</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">dtm_per_year</span><span class="o">.</span><span class="n">toarray</span><span class="p">(),</span> <span class="n">index</span><span class="o">=</span><span class="n">df_per_year</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
<span class="n">dtm_per_year</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">CPU times: user 4.09 s, sys: 109 ms, total: 4.2 s
Wall time: 4.2 s
</code></pre></div><p><img loading="lazy" src="img/df4.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="c1">#向量标准化</span>
<span class="n">dtm_per_year</span> <span class="o">=</span> <span class="n">dtm_per_year</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">row</span><span class="p">:</span> <span class="n">row</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">row</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">dtm_per_year</span>
</code></pre></div><p><img loading="lazy" src="img/df5.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#合并多个字段为新的df</span>
<span class="n">dtm_per_year</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">df_per_year</span><span class="p">[[</span><span class="s1">&#39;股票代码&#39;</span><span class="p">,</span> <span class="s1">&#39;会计年度&#39;</span><span class="p">,</span> <span class="s1">&#39;行业代码&#39;</span><span class="p">]],</span> <span class="n">dtm_per_year</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">dtm_per_year</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/df6.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="四计算2020年行业向量市场向量">四、计算2020年行业向量、市场向量</h2>
<p>计算2020年所有公司的市场向量、行业向量。这里</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>

<span class="c1">#将中间计算结果存储在 mda_infor_output 文件夹。</span>
<span class="c1">#没有该文件夹，就新建</span>
<span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="s1">&#39;mda_infor_output&#39;</span><span class="p">):</span>
    <span class="n">os</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="s1">&#39;mda_infor_output&#39;</span><span class="p">)</span>
    
    
<span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dtm_per_year</span><span class="p">)),</span> <span class="n">desc</span><span class="o">=</span><span class="s2">&#34;会计年度2020进度&#34;</span><span class="p">):</span>
    <span class="n">code</span> <span class="o">=</span> <span class="n">dtm_per_year</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="s1">&#39;股票代码&#39;</span><span class="p">]</span>
    <span class="n">ind</span> <span class="o">=</span> <span class="n">dtm_per_year</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="s1">&#39;行业代码&#39;</span><span class="p">]</span>
    <span class="n">year</span> <span class="o">=</span> <span class="n">dtm_per_year</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="s1">&#39;会计年度&#39;</span><span class="p">]</span>
    
    <span class="n">ind_freq</span> <span class="o">=</span> <span class="n">dtm_per_year</span><span class="p">[</span><span class="n">dtm_per_year</span><span class="p">[</span><span class="s1">&#39;行业代码&#39;</span><span class="p">]</span><span class="o">==</span><span class="n">ind</span><span class="p">][</span><span class="n">dtm_per_year</span><span class="p">[</span><span class="s1">&#39;股票代码&#39;</span><span class="p">]</span><span class="o">==</span><span class="n">code</span><span class="p">]</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">3</span><span class="p">:]</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">market_freq</span> <span class="o">=</span> <span class="n">dtm_per_year</span><span class="p">[</span><span class="n">dtm_per_year</span><span class="p">[</span><span class="s1">&#39;行业代码&#39;</span><span class="p">]</span><span class="o">!=</span><span class="n">ind</span><span class="p">]</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">3</span><span class="p">:]</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    
    <span class="n">dtm_per_year_melted</span> <span class="o">=</span> <span class="n">dtm_per_year</span><span class="o">.</span><span class="n">melt</span><span class="p">(</span><span class="n">id_vars</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;股票代码&#39;</span><span class="p">,</span> <span class="s1">&#39;会计年度&#39;</span><span class="p">,</span> <span class="s1">&#39;行业代码&#39;</span><span class="p">],</span>
                                            <span class="n">var_name</span><span class="o">=</span><span class="s1">&#39;word_id&#39;</span><span class="p">,</span> 
                                            <span class="n">value_name</span><span class="o">=</span><span class="s1">&#39;word_freq&#39;</span><span class="p">)</span>
    <span class="n">corporate_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;word_id&#39;</span><span class="p">:</span> <span class="n">dtm_per_year_melted</span><span class="p">[</span><span class="n">dtm_per_year_melted</span><span class="p">[</span><span class="s1">&#39;股票代码&#39;</span><span class="p">]</span><span class="o">==</span><span class="n">code</span><span class="p">][</span><span class="s1">&#39;word_id&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span>
                                 <span class="s1">&#39;word_freq&#39;</span><span class="p">:</span> <span class="n">dtm_per_year_melted</span><span class="p">[</span><span class="n">dtm_per_year_melted</span><span class="p">[</span><span class="s1">&#39;股票代码&#39;</span><span class="p">]</span><span class="o">==</span><span class="n">code</span><span class="p">][</span><span class="s1">&#39;word_freq&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span>
                                 <span class="s1">&#39;ind_freq&#39;</span><span class="p">:</span> <span class="n">ind_freq</span><span class="p">,</span>
                                 <span class="s1">&#39;market_freq&#39;</span><span class="p">:</span><span class="n">market_freq</span><span class="p">})</span>
    <span class="n">corporate_df</span><span class="p">[</span><span class="s1">&#39;股票代码&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">code</span>
    <span class="n">corporate_df</span><span class="p">[</span><span class="s1">&#39;行业代码&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">ind</span>
    <span class="n">corporate_df</span><span class="p">[</span><span class="s1">&#39;会计年度&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">year</span>
    <span class="n">corporate_df</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">corporate_df</span> <span class="o">=</span> <span class="n">corporate_df</span><span class="p">[[</span><span class="s1">&#39;股票代码&#39;</span><span class="p">,</span> <span class="s1">&#39;行业代码&#39;</span><span class="p">,</span> <span class="s1">&#39;会计年度&#39;</span><span class="p">,</span> <span class="s1">&#39;word_id&#39;</span><span class="p">,</span> <span class="s1">&#39;word_freq&#39;</span><span class="p">,</span> <span class="s1">&#39;ind_freq&#39;</span><span class="p">,</span> <span class="s1">&#39;market_freq&#39;</span><span class="p">]]</span>

    
    <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="s1">&#39;mda_infor_output/</span><span class="si">{year}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">year</span><span class="o">=</span><span class="n">year</span><span class="p">)):</span>
        <span class="n">os</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="s1">&#39;mda_infor_output/</span><span class="si">{year}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">year</span><span class="o">=</span><span class="n">year</span><span class="p">))</span>
    <span class="n">corporate_df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;mda_infor_output/</span><span class="si">{year}</span><span class="s1">/</span><span class="si">{code}</span><span class="s1">.csv&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">year</span><span class="o">=</span><span class="n">year</span><span class="p">,</span> <span class="n">code</span><span class="o">=</span><span class="n">code</span><span class="p">),</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">会计年度2020进度: 100%|███████████████| 3923/3923 [1:35:32&lt;00:00,  1.46s/it]
</code></pre></div><p>从运行的进度条可知2020 年符合规则的记录有3923 条， 运行时间 1 小时 35 分钟。</p>
<p><br><br></p>
<h2 id="五计算2001-2022年所有公司行业向量市场向量">五、计算2001-2022年所有公司行业向量、市场向量</h2>
<p>信息含量的定义。 由于每个公司的 MD&amp;A 中不仅包括公司经营状况等历史信息， 也包括与其他公司相似的信息， 如外部环境、市场格局、风险因素等内容。 因此， 本文参考 Hanley and Hoberg （ 2010 ）， 从行业和市场两个维度来考察和定义公司 MD&amp;A 中的信息含量。</p>
<ul>
<li><strong>市场因素</strong>， 所有上市公司都处于相同的宏观经济环境、风险因素和政治、政策背景之下；</li>
<li><strong>行业因素</strong>， 同一行业中的各上市公司又面临着相似的产业政策、竞争环境和市场特征。</li>
</ul>
<p>由此可见， 每个上市公司 MD&amp;A 信息不可避免地在某种程度上与同行业其他上市公司以及市场其他行业上市公司存在一定的相似性， 甚至某些公司可能直接参考其他公司 MD&amp;A 的表述。</p>
<p><img loading="lazy" src="img/norm_ind_market.png" alt=""  />
</p>
<p>参考文中截图行业向量、市场向量计算方法，有如下代码。<strong>该部分代码运行较慢，全部运行下来大约10小时。</strong></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">CountVectorizer</span>
<span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">import</span> <span class="nn">jieba</span>
<span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>


<span class="c1">#检查是否有文件夹mda_infor_output，如果没有就新建一个</span>
<span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="s1">&#39;mda_infor_output&#39;</span><span class="p">):</span>
    <span class="n">os</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="s1">&#39;mda_infor_output&#39;</span><span class="p">)</span>
    
    
<span class="c1">#cntext1.x</span>
<span class="c1">#stopwords = ct.load_pkl_dict(&#39;STOPWORDS.pkl&#39;)[&#39;STOPWORDS&#39;][&#39;chinese&#39;]</span>

<span class="c1">#cntext2.x</span>
<span class="n">stopwords</span><span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">read_yaml_dict</span><span class="p">(</span><span class="s1">&#39;enzh_common_StopWords.yaml&#39;</span><span class="p">)[</span><span class="s1">&#39;Dictionary&#39;</span><span class="p">][</span><span class="s1">&#39;chinese&#39;</span><span class="p">]</span>


<span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="c1">#只保留md&amp;a中的中文内容</span>
    <span class="n">text</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">re</span><span class="o">.</span><span class="n">findall</span><span class="p">(</span><span class="s1">&#39;[</span><span class="se">\u4e00</span><span class="s1">-</span><span class="se">\u9fa5</span><span class="s1">]+&#39;</span><span class="p">,</span> <span class="n">text</span><span class="p">))</span>
    <span class="c1">#剔除停用词</span>
    <span class="n">words</span> <span class="o">=</span> <span class="p">[</span><span class="n">w</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">jieba</span><span class="o">.</span><span class="n">cut</span><span class="p">(</span><span class="n">text</span><span class="p">)</span> <span class="k">if</span> <span class="n">w</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">stopwords</span><span class="p">]</span>
    <span class="c1">#整理为用空格间隔的字符串(类西方语言文本格式)</span>
    <span class="k">return</span> <span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">words</span><span class="p">)</span>




<span class="c1">#读取数据</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;data/mda01-22.csv.gz&#39;</span><span class="p">,</span> <span class="n">compression</span><span class="o">=</span><span class="s1">&#39;gzip&#39;</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;会计年度&#39;</span><span class="p">,</span> <span class="s1">&#39;股票代码&#39;</span><span class="p">,</span> <span class="s1">&#39;经营讨论与分析内容&#39;</span><span class="p">]</span>

<span class="c1">#上市公司行业信息</span>
<span class="n">ind_info_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_excel</span><span class="p">(</span><span class="s1">&#39;data/行业代码00-22.xlsx&#39;</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">ind_info_df</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;股票代码&#39;</span><span class="p">,</span> <span class="s1">&#39;会计年度&#39;</span><span class="p">],</span> <span class="n">how</span><span class="o">=</span><span class="s1">&#39;inner&#39;</span><span class="p">)</span>

<span class="c1"># 剔除金融行业处理</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="o">~</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;行业代码&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="s2">&#34;J&#34;</span><span class="p">)]</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="o">~</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;股票简称&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="s2">&#34;ST&#34;</span><span class="p">)]</span>

 
<span class="k">for</span> <span class="n">year</span> <span class="ow">in</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;会计年度&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">():</span>
    <span class="n">df_per_year</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;会计年度&#39;</span><span class="p">]</span><span class="o">==</span><span class="n">year</span><span class="p">]</span>
    <span class="n">df_per_year</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">df_per_year</span><span class="p">[</span><span class="s1">&#39;clean_text&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_per_year</span><span class="p">[</span><span class="s1">&#39;经营讨论与分析内容&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">transform</span><span class="p">)</span>
    

    <span class="n">cv</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">(</span><span class="n">min_df</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span> <span class="n">max_df</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span> 
    <span class="c1"># 生成稀疏bow矩阵</span>
    <span class="n">dtm_per_year</span> <span class="o">=</span> <span class="n">cv</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df_per_year</span><span class="p">[</span><span class="s1">&#39;clean_text&#39;</span><span class="p">])</span> 
    <span class="n">dtm_per_year</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">dtm_per_year</span><span class="o">.</span><span class="n">toarray</span><span class="p">(),</span> <span class="n">index</span><span class="o">=</span><span class="n">df_per_year</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
    <span class="n">dtm_per_year</span> <span class="o">=</span> <span class="n">dtm_per_year</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">row</span><span class="p">:</span> <span class="n">row</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">row</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    
    <span class="n">dtm_per_year</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">df_per_year</span><span class="p">[[</span><span class="s1">&#39;股票代码&#39;</span><span class="p">,</span> <span class="s1">&#39;会计年度&#39;</span><span class="p">,</span> <span class="s1">&#39;行业代码&#39;</span><span class="p">]],</span> <span class="n">dtm_per_year</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    
    <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dtm_per_year</span><span class="p">)),</span> <span class="n">desc</span><span class="o">=</span><span class="sa">f</span><span class="s2">&#34;会计年度</span><span class="si">{</span><span class="n">year</span><span class="si">}</span><span class="s2">进度&#34;</span><span class="p">):</span>
        <span class="n">code</span> <span class="o">=</span> <span class="n">dtm_per_year</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="s1">&#39;股票代码&#39;</span><span class="p">]</span>
        <span class="n">ind</span> <span class="o">=</span> <span class="n">dtm_per_year</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="s1">&#39;行业代码&#39;</span><span class="p">]</span>
        <span class="n">year</span> <span class="o">=</span> <span class="n">dtm_per_year</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="s1">&#39;会计年度&#39;</span><span class="p">]</span>



        <span class="n">ind_freq</span> <span class="o">=</span> <span class="n">dtm_per_year</span><span class="p">[</span><span class="n">dtm_per_year</span><span class="p">[</span><span class="s1">&#39;行业代码&#39;</span><span class="p">]</span><span class="o">==</span><span class="n">ind</span><span class="p">][</span><span class="n">dtm_per_year</span><span class="p">[</span><span class="s1">&#39;股票代码&#39;</span><span class="p">]</span><span class="o">!=</span><span class="n">code</span><span class="p">]</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">3</span><span class="p">:]</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">market_freq</span> <span class="o">=</span> <span class="n">dtm_per_year</span><span class="p">[</span><span class="n">dtm_per_year</span><span class="p">[</span><span class="s1">&#39;行业代码&#39;</span><span class="p">]</span><span class="o">!=</span><span class="n">ind</span><span class="p">]</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">3</span><span class="p">:]</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        
        <span class="n">dtm_per_year_melted</span> <span class="o">=</span> <span class="n">dtm_per_year</span><span class="o">.</span><span class="n">melt</span><span class="p">(</span><span class="n">id_vars</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;股票代码&#39;</span><span class="p">,</span> <span class="s1">&#39;会计年度&#39;</span><span class="p">,</span> <span class="s1">&#39;行业代码&#39;</span><span class="p">],</span>
                                                <span class="n">var_name</span><span class="o">=</span><span class="s1">&#39;word_id&#39;</span><span class="p">,</span> 
                                                <span class="n">value_name</span><span class="o">=</span><span class="s1">&#39;word_freq&#39;</span><span class="p">)</span>
        <span class="n">corporate_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span> <span class="s1">&#39;word_id&#39;</span><span class="p">:</span> <span class="n">dtm_per_year_melted</span><span class="p">[</span><span class="n">dtm_per_year_melted</span><span class="p">[</span><span class="s1">&#39;股票代码&#39;</span><span class="p">]</span><span class="o">==</span><span class="n">code</span><span class="p">][</span><span class="s1">&#39;word_id&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span>
                                       <span class="s1">&#39;word_freq&#39;</span><span class="p">:</span> <span class="n">dtm_per_year_melted</span><span class="p">[</span><span class="n">dtm_per_year_melted</span><span class="p">[</span><span class="s1">&#39;股票代码&#39;</span><span class="p">]</span><span class="o">==</span><span class="n">code</span><span class="p">][</span><span class="s1">&#39;word_freq&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span>
                                       <span class="s1">&#39;ind_freq&#39;</span><span class="p">:</span> <span class="n">ind_freq</span><span class="p">,</span>
                                       <span class="s1">&#39;market_freq&#39;</span><span class="p">:</span><span class="n">market_freq</span><span class="p">})</span>
        <span class="n">corporate_df</span><span class="p">[</span><span class="s1">&#39;股票代码&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">code</span>
        <span class="n">corporate_df</span><span class="p">[</span><span class="s1">&#39;行业代码&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">ind</span>
        <span class="n">corporate_df</span><span class="p">[</span><span class="s1">&#39;会计年度&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">year</span>
        <span class="n">corporate_df</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">corporate_df</span> <span class="o">=</span> <span class="n">corporate_df</span><span class="p">[[</span><span class="s1">&#39;股票代码&#39;</span><span class="p">,</span> <span class="s1">&#39;行业代码&#39;</span><span class="p">,</span> <span class="s1">&#39;会计年度&#39;</span><span class="p">,</span> <span class="s1">&#39;word_id&#39;</span><span class="p">,</span> <span class="s1">&#39;word_freq&#39;</span><span class="p">,</span> <span class="s1">&#39;ind_freq&#39;</span><span class="p">,</span> <span class="s1">&#39;market_freq&#39;</span><span class="p">]]</span>
        
        
        <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="s1">&#39;mda_infor_output/</span><span class="si">{year}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">year</span><span class="o">=</span><span class="n">year</span><span class="p">)):</span>
            <span class="n">os</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="s1">&#39;mda_infor_output/</span><span class="si">{year}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">year</span><span class="o">=</span><span class="n">year</span><span class="p">))</span>
        <span class="n">corporate_df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;mda_infor_output/</span><span class="si">{year}</span><span class="s1">/</span><span class="si">{code}</span><span class="s1">.csv&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">year</span><span class="o">=</span><span class="n">year</span><span class="p">,</span> <span class="n">code</span><span class="o">=</span><span class="n">code</span><span class="p">),</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">Building prefix dict from the default dictionary ...
Loading model from cache /var/folders/y0/4gqxky0s2t94x1c1qhlwr6100000gn/T/jieba.cache
Loading model cost 0.281 seconds.
Prefix dict has been built successfully.
会计年度2001进度: 100%|█████████████████████| 1038/1038 [04:35&lt;00:00,  3.77it/s]
会计年度2002进度: 100%|█████████████████████| 1073/1073 [04:53&lt;00:00,  3.65it/s]
会计年度2003进度: 100%|█████████████████████| 1102/1102 [05:41&lt;00:00,  3.22it/s]
......
会计年度2020进度: 100%|███████████████| 3923/3923 [1:35:32&lt;00:00,  1.46s/it]
会计年度2021进度: 100%|███████████████████| 4412/4412 [2:51:33&lt;00:00,  2.33s/it]
会计年度2022进度: 100%|███████████████████| 4880/4880 [3:23:30&lt;00:00,  2.50s/it]
</code></pre></div><p>大邓使用的电脑是 96G 内存， 运行时间大概 12 小时。 常见电脑的内存是 16 G， 速度可能会慢一点， 预估 12 ~ 20 小时左右。</p>
<p><br><br></p>
<h2 id="六标准信息信息含量">六、标准信息、信息含量</h2>
<p>以2020年000002为例，计算其标准信息、信息含量。计算成功后，再计算所有年份所有上市公司 md&amp;a的标准信息、信息含量。</p>
<p><strong>原文除了计算md&amp;a，还将md&amp;a区分为回顾过去、展望未来两部分，并分别计算了对应的标准信息、信息含量。这里只计算md&amp;a的标准信息、信息含量。</strong></p>
<p><img loading="lazy" src="img/infor_pre.png" alt=""  />
</p>
<p>这里使用Python的统计模型statsmodels库OLS来计算标准信息和信息含量。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">csv_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;mda_infor_output/2020/A000002.csv&#39;</span><span class="p">)</span>
<span class="n">csv_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/df7.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#更改字段名</span>
<span class="n">csv_df</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;股票代码&#39;</span><span class="p">,</span> <span class="s1">&#39;行业代码&#39;</span><span class="p">,</span> <span class="s1">&#39;会计年度&#39;</span><span class="p">,</span> <span class="s1">&#39;word_id&#39;</span><span class="p">,</span> <span class="s1">&#39;Norm&#39;</span><span class="p">,</span> <span class="s1">&#39;Norm_Ind&#39;</span><span class="p">,</span> <span class="s1">&#39;Norm_Market&#39;</span><span class="p">]</span>
<span class="n">csv_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/df8.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">statsmodels.formula.api</span> <span class="k">as</span> <span class="nn">smf</span>

<span class="c1">#因变量Norm</span>
<span class="c1">#解释变量Norm_Ind、 Norm_Market</span>
<span class="n">formula</span> <span class="o">=</span> <span class="s1">&#39;Norm ~ Norm_Ind + Norm_Market&#39;</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="n">formula</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">csv_df</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">OLS Regression Results                            
==============================================================================
Dep. Variable:                   Norm   R-squared:                       0.302
Model:                            OLS   Adj. R-squared:                  0.302
Method:                 Least Squares   F-statistic:                     733.0
Date:                Mon, 06 May 2024   Prob (F-statistic):          3.00e-265
Time:                        13:56:33   Log-Likelihood:                 17276.
No. Observations:                3391   AIC:                        -3.455e+04
Df Residuals:                    3388   BIC:                        -3.453e+04
Df Model:                           2                                         
Covariance Type:            nonrobust                                         
===============================================================================
                  coef    std err          t      P&gt;|t|      [0.025      0.975]
-------------------------------------------------------------------------------
Intercept    1.564e-05   3.42e-05      0.457      0.647   -5.14e-05    8.27e-05
Norm_Ind        0.9839      0.026     37.377      0.000       0.932       1.035
Norm_Market    -0.0369      0.079     -0.467      0.640      -0.192       0.118
==============================================================================
Omnibus:                     4561.934   Durbin-Watson:                   1.982
Prob(Omnibus):                  0.000   Jarque-Bera (JB):          7732466.674
Skew:                           6.755   Prob(JB):                         0.00
Kurtosis:                     236.548   Cond. No.                     3.11e+03
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 3.11e+03. This might indicate that there are
strong multicollinearity or other numerical problems.
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#标准信息</span>
<span class="n">standard_info</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">Norm_Ind</span> <span class="o">+</span> <span class="n">result</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">Norm_Market</span>


<span class="c1">#信息含量</span>
<span class="n">informative_content</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="nb">abs</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">resid</span><span class="p">))</span>


<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;A000002标准信息: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">standard_info</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;A000002信息含量: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">informative_content</span><span class="p">))</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">A000002标准信息: 0.9469675274217055
A000002信息含量: 1.2260754443533075
</code></pre></div><br>
<p>既然能成功计算某年某公司的标准信息、信息含量，现在推广到所有年份所有公司，计算结果存储为一个csv文件。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="o">%%</span><span class="n">time</span>

<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">csv</span>
<span class="kn">import</span> <span class="nn">statsmodels.formula.api</span> <span class="k">as</span> <span class="nn">smf</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">re</span>


<span class="c1">#结果存储到mda_infor.csv</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;mda_infor2001-2022.csv&#39;</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">,</span> <span class="n">newline</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">csvf</span><span class="p">:</span>
    <span class="n">fieldnames</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;股票代码&#39;</span><span class="p">,</span> <span class="s1">&#39;会计年度&#39;</span><span class="p">,</span> <span class="s1">&#39;标准信息&#39;</span><span class="p">,</span> <span class="s1">&#39;信息含量&#39;</span><span class="p">]</span>
    <span class="n">writer</span> <span class="o">=</span> <span class="n">csv</span><span class="o">.</span><span class="n">DictWriter</span><span class="p">(</span><span class="n">csvf</span><span class="p">,</span> <span class="n">fieldnames</span><span class="o">=</span><span class="n">fieldnames</span><span class="p">)</span>
    <span class="n">writer</span><span class="o">.</span><span class="n">writeheader</span><span class="p">()</span>
    
    <span class="n">year_dirs</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="s1">&#39;mda_infor_output&#39;</span><span class="p">)</span>
    <span class="n">year_dirs</span> <span class="o">=</span> <span class="p">[</span><span class="n">y</span> <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">year_dirs</span> <span class="k">if</span> <span class="s1">&#39;DS&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">y</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">year_dir</span> <span class="ow">in</span> <span class="n">year_dirs</span><span class="p">:</span>
        <span class="n">code_csvfs</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;mda_infor_output/</span><span class="si">{year}</span><span class="s1">/</span><span class="si">{csvf}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">year</span><span class="o">=</span><span class="n">year_dir</span><span class="p">,</span> <span class="n">csvf</span><span class="o">=</span><span class="n">f</span><span class="p">)</span> 
                      <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="s1">&#39;mda_infor_output/</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">year_dir</span><span class="p">))]</span>
        <span class="n">code_csvfs</span> <span class="o">=</span> <span class="p">[</span><span class="n">f</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">code_csvfs</span> <span class="k">if</span> <span class="s1">&#39;DS&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">f</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">csvf</span> <span class="ow">in</span> <span class="n">code_csvfs</span><span class="p">:</span> 
            <span class="k">try</span><span class="p">:</span>
                <span class="n">csv_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">csvf</span><span class="p">)</span>
                <span class="n">csv_df</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;股票代码&#39;</span><span class="p">,</span> <span class="s1">&#39;行业代码&#39;</span><span class="p">,</span> <span class="s1">&#39;会计年度&#39;</span><span class="p">,</span> <span class="s1">&#39;word_id&#39;</span><span class="p">,</span> <span class="s1">&#39;Norm&#39;</span><span class="p">,</span> <span class="s1">&#39;Norm_Ind&#39;</span><span class="p">,</span> <span class="s1">&#39;Norm_Market&#39;</span><span class="p">]</span>
                <span class="n">formula</span> <span class="o">=</span> <span class="s1">&#39;Norm ~ Norm_Ind + Norm_Market&#39;</span>
                <span class="n">model</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="n">formula</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">csv_df</span><span class="p">)</span>
                <span class="n">result</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>

                <span class="c1">#标准信息</span>
                <span class="n">standard_info</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">Norm_Ind</span> <span class="o">+</span> <span class="n">result</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">Norm_Market</span>
                <span class="c1">#信息含量</span>
                <span class="n">informative_content</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="nb">abs</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">resid</span><span class="p">))</span>

                <span class="n">data</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;股票代码&#39;</span><span class="p">:</span> <span class="n">re</span><span class="o">.</span><span class="n">findall</span><span class="p">(</span><span class="s1">&#39;\d</span><span class="si">{6}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">csvf</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span> 
                        <span class="s1">&#39;会计年度&#39;</span><span class="p">:</span> <span class="n">re</span><span class="o">.</span><span class="n">findall</span><span class="p">(</span><span class="s1">&#39;\d</span><span class="si">{4}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">csvf</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span> 
                        <span class="s1">&#39;标准信息&#39;</span><span class="p">:</span> <span class="n">standard_info</span><span class="p">,</span> 
                        <span class="s1">&#39;信息含量&#39;</span><span class="p">:</span> <span class="n">informative_content</span><span class="p">}</span>
                <span class="n">writer</span><span class="o">.</span><span class="n">writerow</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
            <span class="k">except</span><span class="p">:</span>
                <span class="k">pass</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">CPU times: user 7min 40s, sys: 33min 5s, total: 40min 45s
Wall time: 4min 36s
</code></pre></div><p><br><br></p>
<p>读取生成的<em><strong>mda_infor2001-2022.csv</strong></em>  文件，欣赏一下 <code>标准信息、信息含量</code></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;mda_infor2001-2022.csv&#39;</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/df9.png" alt=""  />
</p>
<br>
<p>需要注意，原文选取 2007 — 2015 年中国上市公司年报中的 MD&amp;A 信息作为研究样本。 之所以选取 2007 年作为样本的起点， 是因为从 2007 年开始， MD&amp;A 在企业定期报告中的披露要求已经较为完善， 而且 2007 年是中国会计准则国际趋同的重要时点， 新制定的《企业会计准则》已经开始实施， 为避免前后会计准则差异而产生的影响， 因此选取 2007 年作为样本区间的起点。</p>
<p><strong>mda_infor.csv含有2010-2022年的数据，如要复现原文，需要注意筛选数据。</strong></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;mda_infor.csv记录数:&#39;</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">))</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">mda_infor2001-2022.csv记录数: 50811
</code></pre></div><p><br><br></p>
<h2 id="七资料获取">七、资料获取</h2>
<p>内容创作不易， <strong>200</strong> 元，加微信 <strong>372335839</strong>， 备注「姓名-学校-专业」。</p>
<p>资料截图， 整个资料文件夹体积高达 12 G。</p>
<p><img loading="lazy" src="img/screen.png" alt=""  />
</p>
<p><img loading="lazy" src="img/size.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="相关内容">相关内容</h2>
<ul>
<li><a href="https://textdata.cn/blog/2023-01-13-information-content-of-critical-audit/">金融研究 | 使用Python构建「关键审计事项信息含量」</a></li>
<li><a href="https://textdata.cn/blog/2023-09-08-earnings-communication-conference-forward-looking-statements-information/">中国管理科学 | 使用业绩说明会文本数据测量上市公司前瞻性信息</a></li>
<li><a href="https://textdata.cn/blog/2024-04-16-china-listed-company-information-dataset/"><strong>数据集 | A股上市公司基本信息</strong></a></li>
<li><a href="https://textdata.cn/blog/2024-01-21-hk-stock-market-anual-report/"><strong>数据集 | 港股年报文本数据集(2007 ~ 2023.12)</strong></a></li>
<li><a href="https://textdata.cn/blog/2024-01-18-neeq-china-listed-on-nation-equities-exchange-and-quotation-system-anunal-year-report/"><strong>数据集(付费) | 三板上市公司年报2002-2023.12</strong></a></li>
<li><a href="https://textdata.cn/blog/2024-01-14-usa-sec-10k-report-dataset/"><strong>数据集 | 美股年报10-K、20-F数据(2000-2023.12)</strong></a></li>
<li><a href="https://textdata.cn/blog/2023-03-24-load-w2v-and-expand-your-concpet-dicitonary/"><strong>词向量(付费) | 使用MD&amp;A2001-2022语料训练Word2Vec模型</strong></a></li>
<li><a href="https://textdata.cn/blog/2023-03-23-china-a-share-market-dataset-mda-from-01-to-21/"><strong>数据集 | 2001-2022年A股上市公司年报&amp;管理层讨论与分析</strong></a></li>
</ul>
<p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>数据集 |  上市公司董监高人员的个人特征/教育背景/任职情况</title>
      <link>https://textdata.cn/blog/2024-04-18-china-a-listed-company-figure-characteristic-dataset/</link>
      <pubDate>Thu, 18 Apr 2024 00:00:00 +0000</pubDate>
      
      <guid>/blog/2024-04-18-china-a-listed-company-figure-characteristic-dataset/</guid>
      <description>&lt;h2 id=&#34;一上市公司董监高&#34;&gt;一、上市公司董监高&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;数据集: 中国上市公司人物特征研究数据库
   
董监高人数: 375105

记录数:
   - 董监高个人特征  1548448
   - 董监高教育背景明细表 639615
   - 董监高任职情况表 1448841 

截止日期: 1990-2024.4.8
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;二查看数据&#34;&gt;二、查看数据&lt;/h2&gt;
&lt;h3 id=&#34;21-董监高教育背景明细表&#34;&gt;2.1 董监高教育背景明细表&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;import pandas as pd

df1 = pd.read_csv(&amp;#39;董监高教育背景明细表.csv&amp;#39;)
df1.head()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/01-df.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;p&gt;查看字段&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;field_max_len&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;max&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;([&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;df1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;iloc&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;:]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;index&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;desc_max_len&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;max&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;([&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;df1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;iloc&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;:]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;values&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;

&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;field&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;desc&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;zip&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;iloc&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;:]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;index&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;df1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;iloc&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;:]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;values&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
    &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;sa&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;- &lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;field&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;field_max_len&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}}&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt; &lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;desc&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;desc_max_len&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}}&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;- Symbol         股票代码  
- EndDate        截止日期  
- PersonID       人员ID  
- FullName       人员姓名  
- Degree         学历    
- UniversityID   毕业院校ID
- University     毕业院校  
- Major          专业    
- AdmissionTime  入校时间  
- GraduationTime 毕业时间  
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h3 id=&#34;22-董监高个人特征&#34;&gt;2.2 董监高个人特征&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;df2&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read_csv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;董监高个人特征.csv&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;df2&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;head&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/02-df.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;p&gt;查看字段&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;field_max_len = max([len(x) for x in df2.iloc[0, :].index])
desc_max_len = max([len(x) for x in df2.iloc[0, :].values])

for field, desc in zip(df2.iloc[0, :].index, df2.iloc[0, :].values):
    print(f&amp;#39;- {field:&amp;lt;{field_max_len}} {desc:&amp;lt;{desc_max_len}}&amp;#39;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Stkcd&lt;/span&gt;             &lt;span class=&#34;n&#34;&gt;证券代码&lt;/span&gt;          
&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Reptdt&lt;/span&gt;            &lt;span class=&#34;n&#34;&gt;统计截止日期&lt;/span&gt;        
&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;PersonID&lt;/span&gt;          &lt;span class=&#34;n&#34;&gt;人员ID&lt;/span&gt;          
&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Name&lt;/span&gt;              &lt;span class=&#34;n&#34;&gt;姓名&lt;/span&gt;            
&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Nationality&lt;/span&gt;       &lt;span class=&#34;n&#34;&gt;国籍&lt;/span&gt;            
&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;NativePlace&lt;/span&gt;       &lt;span class=&#34;n&#34;&gt;籍贯&lt;/span&gt;            
&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;NatAreaCode&lt;/span&gt;       &lt;span class=&#34;n&#34;&gt;籍贯所在地区代码&lt;/span&gt;      
&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;BirthPlace&lt;/span&gt;        &lt;span class=&#34;n&#34;&gt;出生地&lt;/span&gt;           
&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;BirAreaCode&lt;/span&gt;       &lt;span class=&#34;n&#34;&gt;出生地所在地区代码&lt;/span&gt;     
&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Gender&lt;/span&gt;            &lt;span class=&#34;n&#34;&gt;性别&lt;/span&gt;            
&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Age&lt;/span&gt;               &lt;span class=&#34;n&#34;&gt;年龄&lt;/span&gt;            
&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;University&lt;/span&gt;        &lt;span class=&#34;n&#34;&gt;毕业院校&lt;/span&gt;          
&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Degree&lt;/span&gt;            &lt;span class=&#34;n&#34;&gt;学历&lt;/span&gt;            
&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Major&lt;/span&gt;             &lt;span class=&#34;n&#34;&gt;专业&lt;/span&gt;            
&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Profession&lt;/span&gt;        &lt;span class=&#34;n&#34;&gt;职称&lt;/span&gt;            
&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Resume&lt;/span&gt;            &lt;span class=&#34;n&#34;&gt;个人简历&lt;/span&gt;          
&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;PaidSign&lt;/span&gt;          &lt;span class=&#34;n&#34;&gt;是否领取薪酬&lt;/span&gt;        
&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;TotalSalary&lt;/span&gt;       &lt;span class=&#34;n&#34;&gt;报告期报酬总额&lt;/span&gt;       
&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Allowance&lt;/span&gt;         &lt;span class=&#34;n&#34;&gt;其中&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;：&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;津贴&lt;/span&gt;         
&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;SharEnd&lt;/span&gt;           &lt;span class=&#34;n&#34;&gt;年末持股数&lt;/span&gt;         
&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;IsMTMT&lt;/span&gt;            &lt;span class=&#34;n&#34;&gt;是否高管团队成员&lt;/span&gt;      
&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;TMTP&lt;/span&gt;              &lt;span class=&#34;n&#34;&gt;高管职务类别&lt;/span&gt;        
&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;IsMTB&lt;/span&gt;             &lt;span class=&#34;n&#34;&gt;是否董事会成员&lt;/span&gt;       
&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;CTB&lt;/span&gt;               &lt;span class=&#34;n&#34;&gt;董事会职务类别&lt;/span&gt;       
&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;IsIdirecotr&lt;/span&gt;       &lt;span class=&#34;n&#34;&gt;是否独立董事&lt;/span&gt;        
&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;IsDuality&lt;/span&gt;         &lt;span class=&#34;n&#34;&gt;是否兼任董事长和CEO&lt;/span&gt;   
&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;IsSupervisor&lt;/span&gt;      &lt;span class=&#34;n&#34;&gt;是否监事&lt;/span&gt;          
&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Position&lt;/span&gt;          &lt;span class=&#34;n&#34;&gt;具体职务&lt;/span&gt;          
&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;PositionID&lt;/span&gt;        &lt;span class=&#34;n&#34;&gt;具体职务ID&lt;/span&gt;        
&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ServicePosition&lt;/span&gt;   &lt;span class=&#34;n&#34;&gt;在职职务&lt;/span&gt;          
&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ServicePositionID&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;在职职务ID&lt;/span&gt;        
&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Funback&lt;/span&gt;           &lt;span class=&#34;n&#34;&gt;职业背景&lt;/span&gt;          
&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;OveseaBack&lt;/span&gt;        &lt;span class=&#34;n&#34;&gt;海外背景&lt;/span&gt;          
&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Academic&lt;/span&gt;          &lt;span class=&#34;n&#34;&gt;学术背景&lt;/span&gt;          
&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;FinBack&lt;/span&gt;           &lt;span class=&#34;n&#34;&gt;金融背景&lt;/span&gt;          
&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;IsCocurP&lt;/span&gt;          &lt;span class=&#34;n&#34;&gt;是否在股东单位兼任&lt;/span&gt;     
&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;OtherCo&lt;/span&gt;           &lt;span class=&#34;n&#34;&gt;兼任职务&lt;/span&gt;          
&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;OtherCoType&lt;/span&gt;       &lt;span class=&#34;n&#34;&gt;兼任职务类别&lt;/span&gt;        
&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Director_TotCO&lt;/span&gt;    &lt;span class=&#34;n&#34;&gt;兼任职务为董事的公司总数&lt;/span&gt;  
&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Director_ListCO&lt;/span&gt;   &lt;span class=&#34;n&#34;&gt;兼任职务为董事的上市公司总数&lt;/span&gt;
&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Stkcd_director&lt;/span&gt;    &lt;span class=&#34;n&#34;&gt;兼任职务为董事的上市公司代码&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;br&gt;
&lt;h3 id=&#34;23-董监高任职情况表&#34;&gt;2.3 董监高任职情况表&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;df3&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read_csv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;董监高任职情况表.csv&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;df3&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;head&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/03-df.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;field_max_len&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;max&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;([&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;df3&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;iloc&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;:]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;index&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;desc_max_len&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;max&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;([&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;df3&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;iloc&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;:]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;values&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;

&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;field&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;desc&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;zip&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df3&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;iloc&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;:]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;index&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;df3&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;iloc&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;:]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;values&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
    &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;sa&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;- &lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;field&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;field_max_len&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}}&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt; &lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;desc&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;desc_max_len&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}}&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;- Stkcd         证券代码    
- Reptdt        统计截止日期  
- PersonID      人员ID    
- Name          姓名      
- Position      具体职务    
- PositionID    具体职务ID  
- StartDate     任职开始日期  
- EndDate       任职结束日期  
- ServiceStatus 是否在职    
- Tenure        任期      
- ToLeavPost    距离离任剩余日期
- ResignReason  离职原因    
- GTAPosition   职务名称    
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;三相关数据&#34;&gt;三、相关数据&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://textdata.cn/blog/2022-11-25-senior-manager-resume-dataset/&#34;&gt;数据集(付费) | 90w条中国上市公司高管数据&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://textdata.cn/blog/2023-05-17-top-manager-violation/&#34;&gt;数据集 | 上市公司高管违规数据(2008-2022)&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://textdata.cn/blog/2023-03-23-china-a-share-market-dataset-mda-from-01-to-21/&#34;&gt;数据集 | 2001-2022年A股上市公司年报&amp;amp;管理层讨论与分析&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://textdata.cn/blog/2024-01-18-neeq-china-listed-on-nation-equities-exchange-and-quotation-system-anunal-year-report/&#34;&gt;数据集(付费) | 三板上市公司年报2002-2023.12&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://textdata.cn/blog/2024-01-03-listed-company-arbitration-dataset/&#34;&gt;数据集 | 36330条上市公司仲裁数据(2000-2021)&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://textdata.cn/blog/2023-12-07-patent-application-dataset-of-listed-company-in-china-a-market/&#34;&gt;数据集 | 上市公司 208 万条专利数据集 (1991-2022)&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://textdata.cn/blog/2023-09-08-china-a-share-market-listed-company-earnings-communication-conference/&#34;&gt;数据集 | 84w条业绩说明会问答数据(2005-2023)&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://textdata.cn/blog/2023-08-11-china-a-market-corporate-social-responsibility-dataste/&#34;&gt;数据集 | 2006年-2022年企业社会责任报告&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://textdata.cn/blog/2023-04-17-china-a-market-inquiry-letter-datasets/&#34;&gt;数据集(付费) | 2014年-2022年监管问询函&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://textdata.cn/blog/2023-04-26-entrusted-loan-dataset/&#34;&gt;数据集| 07-21年上市公司「委托贷款公告」&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://textdata.cn/blog/coporate_social_responsibility_datasets/&#34;&gt;数据集 | 企业社会责任报告数据集&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;四获取数据&#34;&gt;四、获取数据&lt;/h2&gt;
&lt;p&gt;数据集 50 元， 加微信 &lt;strong&gt;372335839&lt;/strong&gt;, 备注「姓名-学校-专业-董监高」获取本数据集。&lt;/p&gt;
&lt;br&gt;
&lt;br&gt;
&lt;h2 id=&#34;广而告之&#34;&gt;广而告之&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/call_for_paper/&#34;&gt;长期征稿&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/we_need_you/&#34;&gt;长期招募小伙伴&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/management_python_course/&#34;&gt;付费视频课 | Python实证指标构建与文本分析&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
      <content:encoded><![CDATA[<h2 id="一上市公司董监高">一、上市公司董监高</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">数据集: 中国上市公司人物特征研究数据库
   
董监高人数: 375105

记录数:
   - 董监高个人特征  1548448
   - 董监高教育背景明细表 639615
   - 董监高任职情况表 1448841 

截止日期: 1990-2024.4.8
</code></pre></div><p><br><br></p>
<h2 id="二查看数据">二、查看数据</h2>
<h3 id="21-董监高教育背景明细表">2.1 董监高教育背景明细表</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">import pandas as pd

df1 = pd.read_csv(&#39;董监高教育背景明细表.csv&#39;)
df1.head()
</code></pre></div><p><img loading="lazy" src="img/01-df.png" alt=""  />
</p>
<br>
<p>查看字段</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">field_max_len</span> <span class="o">=</span> <span class="nb">max</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">df1</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">index</span><span class="p">])</span>
<span class="n">desc_max_len</span> <span class="o">=</span> <span class="nb">max</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">df1</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">values</span><span class="p">])</span>

<span class="k">for</span> <span class="n">field</span><span class="p">,</span> <span class="n">desc</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">df1</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">index</span><span class="p">,</span> <span class="n">df1</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">values</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;- </span><span class="si">{</span><span class="n">field</span><span class="si">:</span><span class="s1">&lt;</span><span class="si">{</span><span class="n">field_max_len</span><span class="si">}}</span><span class="s1"> </span><span class="si">{</span><span class="n">desc</span><span class="si">:</span><span class="s1">&lt;</span><span class="si">{</span><span class="n">desc_max_len</span><span class="si">}}</span><span class="s1">&#39;</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">- Symbol         股票代码  
- EndDate        截止日期  
- PersonID       人员ID  
- FullName       人员姓名  
- Degree         学历    
- UniversityID   毕业院校ID
- University     毕业院校  
- Major          专业    
- AdmissionTime  入校时间  
- GraduationTime 毕业时间  
</code></pre></div><p><br><br></p>
<h3 id="22-董监高个人特征">2.2 董监高个人特征</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df2</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;董监高个人特征.csv&#39;</span><span class="p">)</span>
<span class="n">df2</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/02-df.png" alt=""  />
</p>
<br>
<p>查看字段</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">field_max_len = max([len(x) for x in df2.iloc[0, :].index])
desc_max_len = max([len(x) for x in df2.iloc[0, :].values])

for field, desc in zip(df2.iloc[0, :].index, df2.iloc[0, :].values):
    print(f&#39;- {field:&lt;{field_max_len}} {desc:&lt;{desc_max_len}}&#39;)
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="o">-</span> <span class="n">Stkcd</span>             <span class="n">证券代码</span>          
<span class="o">-</span> <span class="n">Reptdt</span>            <span class="n">统计截止日期</span>        
<span class="o">-</span> <span class="n">PersonID</span>          <span class="n">人员ID</span>          
<span class="o">-</span> <span class="n">Name</span>              <span class="n">姓名</span>            
<span class="o">-</span> <span class="n">Nationality</span>       <span class="n">国籍</span>            
<span class="o">-</span> <span class="n">NativePlace</span>       <span class="n">籍贯</span>            
<span class="o">-</span> <span class="n">NatAreaCode</span>       <span class="n">籍贯所在地区代码</span>      
<span class="o">-</span> <span class="n">BirthPlace</span>        <span class="n">出生地</span>           
<span class="o">-</span> <span class="n">BirAreaCode</span>       <span class="n">出生地所在地区代码</span>     
<span class="o">-</span> <span class="n">Gender</span>            <span class="n">性别</span>            
<span class="o">-</span> <span class="n">Age</span>               <span class="n">年龄</span>            
<span class="o">-</span> <span class="n">University</span>        <span class="n">毕业院校</span>          
<span class="o">-</span> <span class="n">Degree</span>            <span class="n">学历</span>            
<span class="o">-</span> <span class="n">Major</span>             <span class="n">专业</span>            
<span class="o">-</span> <span class="n">Profession</span>        <span class="n">职称</span>            
<span class="o">-</span> <span class="n">Resume</span>            <span class="n">个人简历</span>          
<span class="o">-</span> <span class="n">PaidSign</span>          <span class="n">是否领取薪酬</span>        
<span class="o">-</span> <span class="n">TotalSalary</span>       <span class="n">报告期报酬总额</span>       
<span class="o">-</span> <span class="n">Allowance</span>         <span class="n">其中</span><span class="err">：</span><span class="n">津贴</span>         
<span class="o">-</span> <span class="n">SharEnd</span>           <span class="n">年末持股数</span>         
<span class="o">-</span> <span class="n">IsMTMT</span>            <span class="n">是否高管团队成员</span>      
<span class="o">-</span> <span class="n">TMTP</span>              <span class="n">高管职务类别</span>        
<span class="o">-</span> <span class="n">IsMTB</span>             <span class="n">是否董事会成员</span>       
<span class="o">-</span> <span class="n">CTB</span>               <span class="n">董事会职务类别</span>       
<span class="o">-</span> <span class="n">IsIdirecotr</span>       <span class="n">是否独立董事</span>        
<span class="o">-</span> <span class="n">IsDuality</span>         <span class="n">是否兼任董事长和CEO</span>   
<span class="o">-</span> <span class="n">IsSupervisor</span>      <span class="n">是否监事</span>          
<span class="o">-</span> <span class="n">Position</span>          <span class="n">具体职务</span>          
<span class="o">-</span> <span class="n">PositionID</span>        <span class="n">具体职务ID</span>        
<span class="o">-</span> <span class="n">ServicePosition</span>   <span class="n">在职职务</span>          
<span class="o">-</span> <span class="n">ServicePositionID</span> <span class="n">在职职务ID</span>        
<span class="o">-</span> <span class="n">Funback</span>           <span class="n">职业背景</span>          
<span class="o">-</span> <span class="n">OveseaBack</span>        <span class="n">海外背景</span>          
<span class="o">-</span> <span class="n">Academic</span>          <span class="n">学术背景</span>          
<span class="o">-</span> <span class="n">FinBack</span>           <span class="n">金融背景</span>          
<span class="o">-</span> <span class="n">IsCocurP</span>          <span class="n">是否在股东单位兼任</span>     
<span class="o">-</span> <span class="n">OtherCo</span>           <span class="n">兼任职务</span>          
<span class="o">-</span> <span class="n">OtherCoType</span>       <span class="n">兼任职务类别</span>        
<span class="o">-</span> <span class="n">Director_TotCO</span>    <span class="n">兼任职务为董事的公司总数</span>  
<span class="o">-</span> <span class="n">Director_ListCO</span>   <span class="n">兼任职务为董事的上市公司总数</span>
<span class="o">-</span> <span class="n">Stkcd_director</span>    <span class="n">兼任职务为董事的上市公司代码</span>
</code></pre></div><br>
<br>
<h3 id="23-董监高任职情况表">2.3 董监高任职情况表</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df3</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;董监高任职情况表.csv&#39;</span><span class="p">)</span>
<span class="n">df3</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/03-df.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">field_max_len</span> <span class="o">=</span> <span class="nb">max</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">df3</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">index</span><span class="p">])</span>
<span class="n">desc_max_len</span> <span class="o">=</span> <span class="nb">max</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">df3</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">values</span><span class="p">])</span>

<span class="k">for</span> <span class="n">field</span><span class="p">,</span> <span class="n">desc</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">df3</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">index</span><span class="p">,</span> <span class="n">df3</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">values</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;- </span><span class="si">{</span><span class="n">field</span><span class="si">:</span><span class="s1">&lt;</span><span class="si">{</span><span class="n">field_max_len</span><span class="si">}}</span><span class="s1"> </span><span class="si">{</span><span class="n">desc</span><span class="si">:</span><span class="s1">&lt;</span><span class="si">{</span><span class="n">desc_max_len</span><span class="si">}}</span><span class="s1">&#39;</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">- Stkcd         证券代码    
- Reptdt        统计截止日期  
- PersonID      人员ID    
- Name          姓名      
- Position      具体职务    
- PositionID    具体职务ID  
- StartDate     任职开始日期  
- EndDate       任职结束日期  
- ServiceStatus 是否在职    
- Tenure        任期      
- ToLeavPost    距离离任剩余日期
- ResignReason  离职原因    
- GTAPosition   职务名称    
</code></pre></div><p><br><br></p>
<h2 id="三相关数据">三、相关数据</h2>
<ul>
<li>
<p><a href="https://textdata.cn/blog/2022-11-25-senior-manager-resume-dataset/">数据集(付费) | 90w条中国上市公司高管数据</a></p>
</li>
<li>
<p><a href="https://textdata.cn/blog/2023-05-17-top-manager-violation/">数据集 | 上市公司高管违规数据(2008-2022)</a></p>
</li>
<li>
<p><a href="https://textdata.cn/blog/2023-03-23-china-a-share-market-dataset-mda-from-01-to-21/">数据集 | 2001-2022年A股上市公司年报&amp;管理层讨论与分析</a></p>
</li>
<li>
<p><a href="https://textdata.cn/blog/2024-01-18-neeq-china-listed-on-nation-equities-exchange-and-quotation-system-anunal-year-report/">数据集(付费) | 三板上市公司年报2002-2023.12</a></p>
</li>
<li>
<p><a href="https://textdata.cn/blog/2024-01-03-listed-company-arbitration-dataset/">数据集 | 36330条上市公司仲裁数据(2000-2021)</a></p>
</li>
<li>
<p><a href="https://textdata.cn/blog/2023-12-07-patent-application-dataset-of-listed-company-in-china-a-market/">数据集 | 上市公司 208 万条专利数据集 (1991-2022)</a></p>
</li>
<li>
<p><a href="https://textdata.cn/blog/2023-09-08-china-a-share-market-listed-company-earnings-communication-conference/">数据集 | 84w条业绩说明会问答数据(2005-2023)</a></p>
</li>
<li>
<p><a href="https://textdata.cn/blog/2023-08-11-china-a-market-corporate-social-responsibility-dataste/">数据集 | 2006年-2022年企业社会责任报告</a></p>
</li>
<li>
<p><a href="https://textdata.cn/blog/2023-04-17-china-a-market-inquiry-letter-datasets/">数据集(付费) | 2014年-2022年监管问询函</a></p>
</li>
<li>
<p><a href="https://textdata.cn/blog/2023-04-26-entrusted-loan-dataset/">数据集| 07-21年上市公司「委托贷款公告」</a></p>
</li>
<li>
<p><a href="https://textdata.cn/blog/coporate_social_responsibility_datasets/">数据集 | 企业社会责任报告数据集</a></p>
</li>
</ul>
<p><br><br></p>
<h2 id="四获取数据">四、获取数据</h2>
<p>数据集 50 元， 加微信 <strong>372335839</strong>, 备注「姓名-学校-专业-董监高」获取本数据集。</p>
<br>
<br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>数据集 |  使用3394w条豆瓣书评数据集</title>
      <link>https://textdata.cn/blog/2024-04-17-douban-book-3394w-ratings-comments-dataset/</link>
      <pubDate>Wed, 17 Apr 2024 00:00:00 +0000</pubDate>
      
      <guid>/blog/2024-04-17-douban-book-3394w-ratings-comments-dataset/</guid>
      <description>&lt;h2 id=&#34;一豆瓣读书介绍&#34;&gt;一、豆瓣读书介绍&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;数据集: douba-book

数据源: 豆瓣读书
   
记录数:
   - 标签 120 个
   - 书 17967 部
   - 书评 33941454 条
   
书评日期起止: 2005-06-12 ~ 2018-10-13
   
体积: 2.11G(解压后5.52G) 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;该数据已经过初步清洗，可用于推荐系统、情感分析、知识图谱、社会学文化变迁等多个领域(或主题)。&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;二查看数据&#34;&gt;二、查看数据&lt;/h2&gt;
&lt;h3 id=&#34;21-读取数据&#34;&gt;2.1 读取数据&lt;/h3&gt;
&lt;p&gt;下载 &lt;em&gt;&lt;strong&gt;douban_book.csv.gz&lt;/strong&gt;&lt;/em&gt; 解压后，可以看到数据集中有一个 &lt;em&gt;&lt;strong&gt;douban_book.csv&lt;/strong&gt;&lt;/em&gt; 文件。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pandas&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pd&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read_csv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;douban_book.csv.gz&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;compression&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;gzip&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;33941454
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/01-df.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;22-所含字段&#34;&gt;2.2 所含字段&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;col&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;columns&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
    &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;sa&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39; - &lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;col&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt; - tag          标签
 - book_name    书名
 - user_name    书评人
 - date         书评发布日期
 - comment      书评内容
 - star         评分(1-5)
 - vote_count   书评获赞数
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h3 id=&#34;23--覆盖日期&#34;&gt;2.3  覆盖日期&lt;/h3&gt;
&lt;p&gt;书评发布日期覆盖(最早~ 最晚)&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;date&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;to_datetime&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;date&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;

&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;date&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;min&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;())&lt;/span&gt;
&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;date&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;max&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;())&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;2005-06-12 00:00:00
2018-10-13 00:00:00
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h3 id=&#34;24-标签&#34;&gt;2.4 标签&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;tag&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;nunique&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;())&lt;/span&gt;
&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;tag&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;unique&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;())&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;120

[&amp;#39;思想&amp;#39; &amp;#39;科技&amp;#39; &amp;#39;金融&amp;#39; &amp;#39;政治学&amp;#39; &amp;#39;随笔&amp;#39; &amp;#39;爱情&amp;#39; &amp;#39;名著&amp;#39; &amp;#39;幾米&amp;#39; &amp;#39;人文&amp;#39; &amp;#39;交互&amp;#39; &amp;#39;悬疑&amp;#39; &amp;#39;算法&amp;#39; &amp;#39;哲学&amp;#39; &amp;#39;艺术史&amp;#39;
 &amp;#39;历史&amp;#39; &amp;#39;用户体验&amp;#39; &amp;#39;绘画&amp;#39; &amp;#39;诗词&amp;#39; &amp;#39;考古&amp;#39; &amp;#39;心理学&amp;#39; &amp;#39;互联网&amp;#39; &amp;#39;戏剧&amp;#39; &amp;#39;安妮宝贝&amp;#39; &amp;#39;艺术&amp;#39; &amp;#39;东野圭吾&amp;#39; &amp;#39;散文&amp;#39; &amp;#39;魔幻&amp;#39;
 &amp;#39;童话&amp;#39; &amp;#39;商业&amp;#39; &amp;#39;UCD&amp;#39; &amp;#39;日本文学&amp;#39; &amp;#39;武侠&amp;#39; &amp;#39;音乐&amp;#39; &amp;#39;通信&amp;#39; &amp;#39;科幻小说&amp;#39; &amp;#39;科普&amp;#39; &amp;#39;程序&amp;#39; &amp;#39;生活&amp;#39; &amp;#39;张悦然&amp;#39; &amp;#39;经济&amp;#39;
 &amp;#39;小说&amp;#39; &amp;#39;科幻&amp;#39; &amp;#39;军事&amp;#39; &amp;#39;心理&amp;#39; &amp;#39;文学&amp;#39; &amp;#39;电影&amp;#39; &amp;#39;社会学&amp;#39; &amp;#39;广告&amp;#39; &amp;#39;管理&amp;#39; &amp;#39;励志&amp;#39; &amp;#39;耽美&amp;#39; &amp;#39;郭敬明&amp;#39; &amp;#39;穿越&amp;#39;
 &amp;#39;阿加莎·克里斯蒂&amp;#39; &amp;#39;杂文&amp;#39; &amp;#39;传记&amp;#39; &amp;#39;韩寒&amp;#39; &amp;#39;设计&amp;#39; &amp;#39;落落&amp;#39; &amp;#39;言情&amp;#39; &amp;#39;职场&amp;#39; &amp;#39;成长&amp;#39; &amp;#39;佛教&amp;#39; &amp;#39;女性&amp;#39; &amp;#39;政治&amp;#39; &amp;#39;近代史&amp;#39;
 &amp;#39;营销&amp;#39; &amp;#39;推理小说&amp;#39; &amp;#39;建筑&amp;#39; &amp;#39;经典&amp;#39; &amp;#39;外国名著&amp;#39; &amp;#39;二战&amp;#39; &amp;#39;鲁迅&amp;#39; &amp;#39;J.K.罗琳&amp;#39; &amp;#39;奇幻&amp;#39; &amp;#39;外国文学&amp;#39; &amp;#39;校园&amp;#39; &amp;#39;人物传记&amp;#39;
 &amp;#39;西方哲学&amp;#39; &amp;#39;自由主义&amp;#39; &amp;#39;文化&amp;#39; &amp;#39;旅行&amp;#39; &amp;#39;张小娴&amp;#39; &amp;#39;企业史&amp;#39; &amp;#39;国学&amp;#39; &amp;#39;摄影&amp;#39; &amp;#39;亦舒&amp;#39; &amp;#39;青春&amp;#39; &amp;#39;科学&amp;#39; &amp;#39;策划&amp;#39; &amp;#39;web&amp;#39;
 &amp;#39;创业&amp;#39; &amp;#39;美术&amp;#39; &amp;#39;宗教&amp;#39; &amp;#39;古龙&amp;#39; &amp;#39;沧月&amp;#39; &amp;#39;村上春树&amp;#39; &amp;#39;社会&amp;#39; &amp;#39;股票&amp;#39; &amp;#39;理财&amp;#39; &amp;#39;日本漫画&amp;#39; &amp;#39;轻小说&amp;#39; &amp;#39;数学&amp;#39; &amp;#39;神经网络&amp;#39;
 &amp;#39;网络小说&amp;#39; &amp;#39;当代文学&amp;#39; &amp;#39;中国历史&amp;#39; &amp;#39;三毛&amp;#39; &amp;#39;回忆录&amp;#39; &amp;#39;古典文学&amp;#39; &amp;#39;交互设计&amp;#39; &amp;#39;推理&amp;#39; &amp;#39;高木直子&amp;#39; &amp;#39;中国文学&amp;#39; &amp;#39;青春文学&amp;#39;
 &amp;#39;金庸&amp;#39; &amp;#39;UE&amp;#39; &amp;#39;投资&amp;#39; &amp;#39;编程&amp;#39; &amp;#39;几米&amp;#39;]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h3 id=&#34;25--可视化&#34;&gt;2.5  可视化&lt;/h3&gt;
&lt;p&gt;书评发布数量随年份变化&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;plt&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;matplotlib&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;matplotlib_inline&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;matplotlib_inline&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;backend_inline&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;set_matplotlib_formats&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;png&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;svg&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;scienceplots&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;platform&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;#初始化matplotlib汉化美化配置&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;plt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;style&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;use&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;([&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;science&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;no-latex&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;cjk-sc-font&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;system&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;platform&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;system&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;# 获取操作系统类型&lt;/span&gt;
&lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;system&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;Windows&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;font&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;family&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;SimHei&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;span class=&#34;k&#34;&gt;elif&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;system&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;Darwin&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;font&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;family&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;Arial Unicode MS&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;span class=&#34;k&#34;&gt;else&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;font&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;family&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;sans-serif&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;matplotlib&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;rc&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;font&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;font&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;# 设置全局字体&lt;/span&gt;


&lt;span class=&#34;c1&#34;&gt;#构造数据&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;date_series&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;volume_series&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt;
&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;date&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;year_df&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;groupby&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Grouper&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;key&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;date&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;freq&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;M&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)):&lt;/span&gt;
    &lt;span class=&#34;c1&#34;&gt;#这里的date， month_df都是特殊数据类型&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;date_series&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;append&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;date&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;date&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;())&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;volume_series&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;append&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;year_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;volume_by_time_df&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;DataFrame&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;({&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;date&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;date_series&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;volume&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;volume_series&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;})&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;volume_by_time_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;date&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;to_datetime&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;volume_by_time_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;date&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;



&lt;span class=&#34;c1&#34;&gt;#开始绘图&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;plt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;figure&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;figsize&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;plt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;plot&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;volume_by_time_df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;date&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
         &lt;span class=&#34;n&#34;&gt;volume_by_time_df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;volume&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
         &lt;span class=&#34;n&#34;&gt;linestyle&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;--&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;plt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;scatter&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;volume_by_time_df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;date&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
            &lt;span class=&#34;n&#34;&gt;volume_by_time_df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;volume&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
            &lt;span class=&#34;n&#34;&gt;s&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;8&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;plt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;title&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;豆瓣读书随年份书评数量变化(2005.6.12 ~ 2018.10.13)&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
          &lt;span class=&#34;n&#34;&gt;fontsize&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;plt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;xlabel&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;日期&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;plt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ylabel&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;书评数量&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;plt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;savefig&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;plot.png&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;dpi&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;200&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;plt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;show&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/plot.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;三相关内容&#34;&gt;三、相关内容&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/2024-04-16-douban-movie-1000w-ratings-comments-dataset/&#34;&gt;数据集 | 使用1000w条豆瓣影评训练Word2Vec&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;四获取数据&#34;&gt;四、获取数据&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;douban-book&lt;/strong&gt;&lt;/em&gt; 链接: &lt;a href=&#34;https://pan.baidu.com/s/1qySKU_0dsoi1NAF9lQ971w?pwd=n5qe&#34;&gt;https://pan.baidu.com/s/1qySKU_0dsoi1NAF9lQ971w?pwd=n5qe&lt;/a&gt; 提取码: n5qe&lt;/p&gt;
&lt;br&gt;
&lt;br&gt;
&lt;h2 id=&#34;广而告之&#34;&gt;广而告之&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/call_for_paper/&#34;&gt;长期征稿&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/we_need_you/&#34;&gt;长期招募小伙伴&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/management_python_course/&#34;&gt;付费视频课 | Python实证指标构建与文本分析&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
      <content:encoded><![CDATA[<h2 id="一豆瓣读书介绍">一、豆瓣读书介绍</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">数据集: douba-book

数据源: 豆瓣读书
   
记录数:
   - 标签 120 个
   - 书 17967 部
   - 书评 33941454 条
   
书评日期起止: 2005-06-12 ~ 2018-10-13
   
体积: 2.11G(解压后5.52G) 
</code></pre></div><p>该数据已经过初步清洗，可用于推荐系统、情感分析、知识图谱、社会学文化变迁等多个领域(或主题)。</p>
<p><br><br></p>
<h2 id="二查看数据">二、查看数据</h2>
<h3 id="21-读取数据">2.1 读取数据</h3>
<p>下载 <em><strong>douban_book.csv.gz</strong></em> 解压后，可以看到数据集中有一个 <em><strong>douban_book.csv</strong></em> 文件。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;douban_book.csv.gz&#39;</span><span class="p">,</span> <span class="n">compression</span><span class="o">=</span><span class="s1">&#39;gzip&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">))</span>
<span class="n">df</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">33941454
</code></pre></div><p><img loading="lazy" src="img/01-df.png" alt=""  />
</p>
<br>
<h3 id="22-所含字段">2.2 所含字段</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39; - </span><span class="si">{</span><span class="n">col</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"> - tag          标签
 - book_name    书名
 - user_name    书评人
 - date         书评发布日期
 - comment      书评内容
 - star         评分(1-5)
 - vote_count   书评获赞数
</code></pre></div><br>
<h3 id="23--覆盖日期">2.3  覆盖日期</h3>
<p>书评发布日期覆盖(最早~ 最晚)</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df</span><span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">])</span>

<span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">2005-06-12 00:00:00
2018-10-13 00:00:00
</code></pre></div><br>
<h3 id="24-标签">2.4 标签</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">tag</span><span class="o">.</span><span class="n">nunique</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">tag</span><span class="o">.</span><span class="n">unique</span><span class="p">())</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">120

[&#39;思想&#39; &#39;科技&#39; &#39;金融&#39; &#39;政治学&#39; &#39;随笔&#39; &#39;爱情&#39; &#39;名著&#39; &#39;幾米&#39; &#39;人文&#39; &#39;交互&#39; &#39;悬疑&#39; &#39;算法&#39; &#39;哲学&#39; &#39;艺术史&#39;
 &#39;历史&#39; &#39;用户体验&#39; &#39;绘画&#39; &#39;诗词&#39; &#39;考古&#39; &#39;心理学&#39; &#39;互联网&#39; &#39;戏剧&#39; &#39;安妮宝贝&#39; &#39;艺术&#39; &#39;东野圭吾&#39; &#39;散文&#39; &#39;魔幻&#39;
 &#39;童话&#39; &#39;商业&#39; &#39;UCD&#39; &#39;日本文学&#39; &#39;武侠&#39; &#39;音乐&#39; &#39;通信&#39; &#39;科幻小说&#39; &#39;科普&#39; &#39;程序&#39; &#39;生活&#39; &#39;张悦然&#39; &#39;经济&#39;
 &#39;小说&#39; &#39;科幻&#39; &#39;军事&#39; &#39;心理&#39; &#39;文学&#39; &#39;电影&#39; &#39;社会学&#39; &#39;广告&#39; &#39;管理&#39; &#39;励志&#39; &#39;耽美&#39; &#39;郭敬明&#39; &#39;穿越&#39;
 &#39;阿加莎·克里斯蒂&#39; &#39;杂文&#39; &#39;传记&#39; &#39;韩寒&#39; &#39;设计&#39; &#39;落落&#39; &#39;言情&#39; &#39;职场&#39; &#39;成长&#39; &#39;佛教&#39; &#39;女性&#39; &#39;政治&#39; &#39;近代史&#39;
 &#39;营销&#39; &#39;推理小说&#39; &#39;建筑&#39; &#39;经典&#39; &#39;外国名著&#39; &#39;二战&#39; &#39;鲁迅&#39; &#39;J.K.罗琳&#39; &#39;奇幻&#39; &#39;外国文学&#39; &#39;校园&#39; &#39;人物传记&#39;
 &#39;西方哲学&#39; &#39;自由主义&#39; &#39;文化&#39; &#39;旅行&#39; &#39;张小娴&#39; &#39;企业史&#39; &#39;国学&#39; &#39;摄影&#39; &#39;亦舒&#39; &#39;青春&#39; &#39;科学&#39; &#39;策划&#39; &#39;web&#39;
 &#39;创业&#39; &#39;美术&#39; &#39;宗教&#39; &#39;古龙&#39; &#39;沧月&#39; &#39;村上春树&#39; &#39;社会&#39; &#39;股票&#39; &#39;理财&#39; &#39;日本漫画&#39; &#39;轻小说&#39; &#39;数学&#39; &#39;神经网络&#39;
 &#39;网络小说&#39; &#39;当代文学&#39; &#39;中国历史&#39; &#39;三毛&#39; &#39;回忆录&#39; &#39;古典文学&#39; &#39;交互设计&#39; &#39;推理&#39; &#39;高木直子&#39; &#39;中国文学&#39; &#39;青春文学&#39;
 &#39;金庸&#39; &#39;UE&#39; &#39;投资&#39; &#39;编程&#39; &#39;几米&#39;]
</code></pre></div><br>
<h3 id="25--可视化">2.5  可视化</h3>
<p>书评发布数量随年份变化</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">matplotlib</span>
<span class="kn">import</span> <span class="nn">matplotlib_inline</span>
<span class="n">matplotlib_inline</span><span class="o">.</span><span class="n">backend_inline</span><span class="o">.</span><span class="n">set_matplotlib_formats</span><span class="p">(</span><span class="s1">&#39;png&#39;</span><span class="p">,</span> <span class="s1">&#39;svg&#39;</span><span class="p">)</span>
<span class="kn">import</span> <span class="nn">scienceplots</span>
<span class="kn">import</span> <span class="nn">platform</span>

<span class="c1">#初始化matplotlib汉化美化配置</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">([</span><span class="s1">&#39;science&#39;</span><span class="p">,</span> <span class="s1">&#39;no-latex&#39;</span><span class="p">,</span> <span class="s1">&#39;cjk-sc-font&#39;</span><span class="p">])</span>
<span class="n">system</span> <span class="o">=</span> <span class="n">platform</span><span class="o">.</span><span class="n">system</span><span class="p">()</span>  <span class="c1"># 获取操作系统类型</span>
<span class="k">if</span> <span class="n">system</span> <span class="o">==</span> <span class="s1">&#39;Windows&#39;</span><span class="p">:</span>
    <span class="n">font</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;family&#39;</span><span class="p">:</span> <span class="s1">&#39;SimHei&#39;</span><span class="p">}</span>
<span class="k">elif</span> <span class="n">system</span> <span class="o">==</span> <span class="s1">&#39;Darwin&#39;</span><span class="p">:</span>
    <span class="n">font</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;family&#39;</span><span class="p">:</span> <span class="s1">&#39;Arial Unicode MS&#39;</span><span class="p">}</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">font</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;family&#39;</span><span class="p">:</span> <span class="s1">&#39;sans-serif&#39;</span><span class="p">}</span>
<span class="n">matplotlib</span><span class="o">.</span><span class="n">rc</span><span class="p">(</span><span class="s1">&#39;font&#39;</span><span class="p">,</span> <span class="o">**</span><span class="n">font</span><span class="p">)</span>  <span class="c1"># 设置全局字体</span>


<span class="c1">#构造数据</span>
<span class="n">date_series</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">volume_series</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">date</span><span class="p">,</span> <span class="n">year_df</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">Grouper</span><span class="p">(</span><span class="n">key</span><span class="o">=</span><span class="s1">&#39;date&#39;</span><span class="p">,</span> <span class="n">freq</span><span class="o">=</span><span class="s1">&#39;M&#39;</span><span class="p">)):</span>
    <span class="c1">#这里的date， month_df都是特殊数据类型</span>
    <span class="n">date_series</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">date</span><span class="o">.</span><span class="n">date</span><span class="p">())</span>
    <span class="n">volume_series</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">year_df</span><span class="p">))</span>
<span class="n">volume_by_time_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;date&#39;</span><span class="p">:</span> <span class="n">date_series</span><span class="p">,</span> <span class="s1">&#39;volume&#39;</span><span class="p">:</span> <span class="n">volume_series</span><span class="p">})</span>
<span class="n">volume_by_time_df</span><span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">volume_by_time_df</span><span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">])</span>



<span class="c1">#开始绘图</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">volume_by_time_df</span><span class="o">.</span><span class="n">date</span><span class="p">,</span> 
         <span class="n">volume_by_time_df</span><span class="o">.</span><span class="n">volume</span><span class="p">,</span>
         <span class="n">linestyle</span> <span class="o">=</span> <span class="s1">&#39;--&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">volume_by_time_df</span><span class="o">.</span><span class="n">date</span><span class="p">,</span> 
            <span class="n">volume_by_time_df</span><span class="o">.</span><span class="n">volume</span><span class="p">,</span> 
            <span class="n">s</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;豆瓣读书随年份书评数量变化(2005.6.12 ~ 2018.10.13)&#39;</span><span class="p">,</span> 
          <span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;日期&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;书评数量&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;plot.png&#39;</span><span class="p">,</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">200</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/plot.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="三相关内容">三、相关内容</h2>
<ul>
<li><a href="https://textdata.cn/blog/2024-04-16-douban-movie-1000w-ratings-comments-dataset/">数据集 | 使用1000w条豆瓣影评训练Word2Vec</a></li>
</ul>
<p><br><br></p>
<h2 id="四获取数据">四、获取数据</h2>
<p><em><strong>douban-book</strong></em> 链接: <a href="https://pan.baidu.com/s/1qySKU_0dsoi1NAF9lQ971w?pwd=n5qe">https://pan.baidu.com/s/1qySKU_0dsoi1NAF9lQ971w?pwd=n5qe</a> 提取码: n5qe</p>
<br>
<br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>数据集 |  使用1000w条豆瓣影评训练Word2Vec</title>
      <link>https://textdata.cn/blog/2024-04-16-douban-movie-1000w-ratings-comments-dataset/</link>
      <pubDate>Tue, 16 Apr 2024 00:00:00 +0000</pubDate>
      
      <guid>/blog/2024-04-16-douban-movie-1000w-ratings-comments-dataset/</guid>
      <description>&lt;p&gt;本文内容&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;介绍豆瓣影评数据集&lt;/li&gt;
&lt;li&gt;构造语料训练Word2Vec模型&lt;/li&gt;
&lt;li&gt;获取数据&amp;amp;cntext&amp;amp;Word2Vec模型文件&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;一豆瓣影评数据集&#34;&gt;一、豆瓣影评数据集&lt;/h2&gt;
&lt;h3 id=&#34;11-数据集介绍&#34;&gt;1.1 数据集介绍&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;数据集: douba-movie-1000w

数据源: 豆瓣电影
   
记录数:
   - 电影 10269 部
   - 影评 10310989 条
   
体积: 1.35G 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;该数据集正好弥补下国内公开电影数据集的空缺， 数据已经过初步清洗，可用于推荐系统、情感分析、知识图谱、新闻传播学、社会学文化变迁等多个领域(或主题)。&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;12-读取数据&#34;&gt;1.2 读取数据&lt;/h3&gt;
&lt;p&gt;下载 &lt;em&gt;&lt;strong&gt;douba-movie-1000w.zip&lt;/strong&gt;&lt;/em&gt; 解压后，可以看到数据集中有一个 &lt;em&gt;&lt;strong&gt;all_movies_with_id.csv&lt;/strong&gt;&lt;/em&gt; 文件。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pandas&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pd&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read_csv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;all_movies_with_id.csv&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/01-df.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;13-所含字段&#34;&gt;1.3 所含字段&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;col&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;columns&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
    &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;sa&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39; - &lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;col&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt; - ID
 - Movie_Name  电影名
 - Score  豆瓣电影评分(1-10)
 - Review_People  评论者人数
 - Star_Distribution  评论评分分布(1-5, 含多个数值，数值以%间隔)
 - Craw_Date 爬虫运行日期
 - Username 豆瓣评论者用户名
 - Date 影评日期
 - Star  影评评分(1-5)
 - Comment 影评内容
 - Comment_Distribution 影评评分分布
 - Like 影评获得的喜欢数
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;二-构造语料训练word2vec&#34;&gt;二、 构造语料&amp;amp;训练Word2Vec&lt;/h2&gt;
&lt;h3 id=&#34;21-构造语料&#34;&gt;2.1 构造语料&lt;/h3&gt;
&lt;p&gt;将字段 &lt;em&gt;&lt;strong&gt;Comment&lt;/strong&gt;&lt;/em&gt; 中所有文本汇总到 &lt;em&gt;&lt;strong&gt;douban-movie-1000w.txt&lt;/strong&gt;&lt;/em&gt;,&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;k&#34;&gt;with&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;open&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;douban-movie-1000w.txt&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;w&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;encoding&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;utf-8&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;text&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;join&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;Comment&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;values&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;write&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h3 id=&#34;22-配置cntext211&#34;&gt;2.2 配置cntext2.1.1&lt;/h3&gt;
&lt;p&gt;将 &lt;em&gt;&lt;strong&gt;cntext-2.1.1-py3-none-any.whl&lt;/strong&gt;&lt;/em&gt; 放置于桌面，打开 &lt;em&gt;&lt;strong&gt;cmd&lt;/strong&gt;&lt;/em&gt;  (苹果电脑打开terminal)， 输入cd desktop&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;cd desktop
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;之后在 &lt;em&gt;&lt;strong&gt;cmd&lt;/strong&gt;&lt;/em&gt;  (苹果电脑打开terminal) 中使用 &lt;em&gt;&lt;strong&gt;pip3&lt;/strong&gt;&lt;/em&gt; 安装&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;pip3 install distinctiveness
pip3 install cntext-2.1.1-py3-none-any.whl
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;文末有 &lt;em&gt;&lt;strong&gt;cntext-2.1.1-py3-none-any.whl&lt;/strong&gt;&lt;/em&gt; 获取方式&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;23-训练word2vec&#34;&gt;2.3 训练Word2Vec&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;c1&#34;&gt;#cntext为2.1.1&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;cntext&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;ct&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;w2v_model&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ct&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;W2VModel&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;corpus_file&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;douban-movie-1000w.txt&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                        &lt;span class=&#34;n&#34;&gt;lang&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;chinese&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;w2v_model&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;train&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;vector_size&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;200&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;window_size&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;6&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;Starting Preprocessing Corpus ...
Starting Training! This may take a while.Please be patient...
Traning word2vec model took 3965 seconds
Note: The Word2Vec model hase saved to output/Word2Vec
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/word2vec.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;经过大概一个小时的训练， 得到模型文件 &lt;em&gt;&lt;strong&gt;douban-movie-1000w.200.6.bin&lt;/strong&gt;&lt;/em&gt; 及相关文件， 注意不要删掉哦。 已训练好的模型，可以自己用， 也可分享给其他人使用。&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;四使用word2vec&#34;&gt;四、使用Word2Vec&lt;/h2&gt;
&lt;h3 id=&#34;41-导入word2vec模型文件&#34;&gt;4.1 导入Word2Vec模型文件&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;cntext&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;ct&lt;/span&gt;
 
&lt;span class=&#34;c1&#34;&gt;#导入模型，请注意路径。&lt;/span&gt;
&lt;span class=&#34;c1&#34;&gt;# 【当前代码】 与 【Word2Vec文件夹】 同处于一个文件夹内&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;dm_w2v&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ct&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;load_w2v&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;Word2Vec/douban-movie-1000w.200.6.bin&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;dm_w2v&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;Loading word2vec model...
&amp;lt;gensim.models.word2vec.Word2Vec at 0x10cb02090&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h3 id=&#34;42-常用函数&#34;&gt;4.2 常用函数&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;dm_w2v.wv.get_vector(key)&lt;/strong&gt;&lt;/em&gt; 获取key的词向量&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;dm_w2v.most_similar_to_given(key1, keys_list)&lt;/strong&gt;&lt;/em&gt; 从 keys_list 中获取与 key1 最相似的词&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;dm_w2v.n_similarity(ws1, ws2)&lt;/strong&gt;&lt;/em&gt;  两组词ws1, ws2 的相似度&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;dm_w2v.closer_than(key1, key2)&lt;/strong&gt;&lt;/em&gt;  更接近于key1的词向量(相比于key2)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;dm_w2v.most_similar(positive, negative)&lt;/strong&gt;&lt;/em&gt;  找出与positive同方向，与negative反向相反的词。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
&lt;h4 id=&#34;421-get_vectorkey&#34;&gt;4.2.1 get_vector(key)&lt;/h4&gt;
&lt;p&gt;使用词向量查看某&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;dm_w2v&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;get_vector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;给力&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;array&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;([&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;3.55084002e-01&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;1.22685611e+00&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;8.48365605e-01&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;  &lt;span class=&#34;mf&#34;&gt;1.23056602e+00&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
        &lt;span class=&#34;mf&#34;&gt;1.35057056e+00&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;  &lt;span class=&#34;mf&#34;&gt;1.65976137e-02&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;1.26512849e+00&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;  &lt;span class=&#34;mf&#34;&gt;1.47152972e+00&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
        &lt;span class=&#34;mf&#34;&gt;9.99028236e-03&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;1.00873756e+00&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;  &lt;span class=&#34;mf&#34;&gt;1.05153358e+00&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;1.39181948e+00&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
        &lt;span class=&#34;mf&#34;&gt;6.02373898e-01&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;1.00308895e+00&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;  &lt;span class=&#34;mf&#34;&gt;2.33978868e-01&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;1.83010173e+00&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
       &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;9.67333555e-01&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;  &lt;span class=&#34;mf&#34;&gt;3.04877937e-01&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;6.59058094e-01&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;  &lt;span class=&#34;mf&#34;&gt;3.19660306e+00&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
       &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;1.21165246e-01&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;3.68000716e-01&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;2.36653373e-01&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;6.83727741e-01&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
      &lt;span class=&#34;o&#34;&gt;......&lt;/span&gt;
      &lt;span class=&#34;o&#34;&gt;......&lt;/span&gt;
       &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;1.23901594e+00&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;  &lt;span class=&#34;mf&#34;&gt;5.07202707e-02&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;  &lt;span class=&#34;mf&#34;&gt;8.75848413e-01&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;4.31963325e-01&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
        &lt;span class=&#34;mf&#34;&gt;1.31377324e-01&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;1.19606090e+00&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;  &lt;span class=&#34;mf&#34;&gt;1.68391216e+00&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;6.27069890e-01&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
       &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;7.37121344e-01&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;  &lt;span class=&#34;mf&#34;&gt;2.49946609e-01&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;  &lt;span class=&#34;mf&#34;&gt;1.47220814e+00&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;1.33507824e+00&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
        &lt;span class=&#34;mf&#34;&gt;2.97913142e-02&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;4.91593599e-01&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;  &lt;span class=&#34;mf&#34;&gt;5.83192170e-01&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;8.48378658e-01&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
       &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;3.30877733e+00&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;  &lt;span class=&#34;mf&#34;&gt;2.17747837e-01&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;  &lt;span class=&#34;mf&#34;&gt;2.22701088e-01&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;1.00758147e+00&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
        &lt;span class=&#34;mf&#34;&gt;3.41430195e-02&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;7.27023900e-01&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;7.94953525e-01&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;1.03226733e+00&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
       &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;4.55965906e-01&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;  &lt;span class=&#34;mf&#34;&gt;1.66779244e+00&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;  &lt;span class=&#34;mf&#34;&gt;1.16857982e+00&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;1.02211344e+00&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
        &lt;span class=&#34;mf&#34;&gt;4.11061406e-01&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;  &lt;span class=&#34;mf&#34;&gt;8.95921767e-01&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;9.48565483e-01&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;1.48802996e-01&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
        &lt;span class=&#34;mf&#34;&gt;9.36261594e-01&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;  &lt;span class=&#34;mf&#34;&gt;3.98367733e-01&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;  &lt;span class=&#34;mf&#34;&gt;3.12385857e-01&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;8.67059827e-01&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;
      &lt;span class=&#34;n&#34;&gt;dtype&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;float32&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h4 id=&#34;422-most_similar_to_givenkey1-keys_list&#34;&gt;4.2.2 most_similar_to_given(key1, keys_list)&lt;/h4&gt;
&lt;p&gt;从 keys_list 中获取与 key1 最相似的词。例如在 1000w 影评中，从&lt;code&gt;&#39;爱情&#39;, &#39;悬疑&#39;, &#39;飞船&#39;, &#39;历史&#39;, &#39;战争&#39;&lt;/code&gt;找出最接近&lt;code&gt;&#39;太空&#39;&lt;/code&gt;，最后返回&lt;code&gt;&#39;飞船&#39;&lt;/code&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;c1&#34;&gt;#从 `keys_list` 中获取与 `key1` 最相似的 `key`。&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;dm_w2v&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;most_similar_to_given&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;key1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;太空&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
                                &lt;span class=&#34;n&#34;&gt;keys_list&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;爱情&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;悬疑&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;飞船&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;历史&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;战争&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&amp;#39;飞船&amp;#39;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h4 id=&#34;423-w2v_modeln_similarityws1-ws2&#34;&gt;4.2.3 w2v_model.n_similarity(ws1, ws2)&lt;/h4&gt;
&lt;p&gt;两组词ws1, ws2 的相似度。注意相似值更多的是体现了语义的相关性， 并不能准确反映语义的远近。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;sklearn.metrics.pairwise&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;cosine_similarity&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;cosine_similarity&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;([&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dm_w2v&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;get_vector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;理想&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)],&lt;/span&gt;  
                  &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dm_w2v&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;get_vector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;现实&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)])[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;][&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;0.4698379
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;c1&#34;&gt;#cosine算法&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;dm_w2v&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;n_similarity&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;([&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;理想&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt; 
                       &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;现实&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;0.4698379
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;c1&#34;&gt;#计算两组键之间的余弦相似度。&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;dm_w2v&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;n_similarity&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;([&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;给力&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;精彩&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;赞&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;推荐&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt; 
                       &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;无聊&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;尴尬&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;垃圾&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;0.109311774
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;dm_w2v&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;n_similarity&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;([&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;理想&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;梦想&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt; 
                       &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;现实&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;生活&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;0.48020104
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h4 id=&#34;424-closer_thankey1-key2&#34;&gt;4.2.4 closer_than(key1, key2)&lt;/h4&gt;
&lt;p&gt;更接近于key1的词向量(相比于key2)&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;c1&#34;&gt;#获取所有更接近 `key1` 的键，而不是 `key2` 。&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;dm_w2v&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;closer_than&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;key1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;理想&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
                      &lt;span class=&#34;n&#34;&gt;key2&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;现实&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;[&amp;#39;梦想&amp;#39;,
 &amp;#39;追求&amp;#39;,
 &amp;#39;实现&amp;#39;,
 &amp;#39;向往&amp;#39;,
 &amp;#39;信念&amp;#39;,
 &amp;#39;妥协&amp;#39;,
 &amp;#39;奋斗&amp;#39;,
 &amp;#39;乌托邦&amp;#39;,
 &amp;#39;愿望&amp;#39;,
 &amp;#39;理想主义&amp;#39;,
 &amp;#39;理想化&amp;#39;,
 &amp;#39;虚幻&amp;#39;,
 &amp;#39;憧憬&amp;#39;,
 &amp;#39;现实残酷&amp;#39;,
 &amp;#39;不切实际&amp;#39;,
 &amp;#39;实现梦想&amp;#39;,
 &amp;#39;崇高&amp;#39;,
 &amp;#39;理想主义者&amp;#39;,
 &amp;#39;追求自由&amp;#39;,
 &amp;#39;破灭&amp;#39;,
 &amp;#39;名利&amp;#39;,
 &amp;#39;追梦&amp;#39;,
 &amp;#39;奢望&amp;#39;,
 &amp;#39;追求梦想&amp;#39;,
 &amp;#39;现实现实&amp;#39;,
 &amp;#39;执著&amp;#39;,
 &amp;#39;理想现实&amp;#39;,
 &amp;#39;拼搏&amp;#39;,
 &amp;#39;面对现实&amp;#39;,
 &amp;#39;美好事物&amp;#39;,
 &amp;#39;追逐梦想&amp;#39;,
 &amp;#39;勇往直前&amp;#39;,
 &amp;#39;遥不可及&amp;#39;,
 &amp;#39;怀揣&amp;#39;,
 &amp;#39;梦想现实&amp;#39;,
 &amp;#39;美好生活&amp;#39;,
 &amp;#39;脚踏实地&amp;#39;,
 &amp;#39;本心&amp;#39;,
 &amp;#39;坚持梦想&amp;#39;,
 &amp;#39;梦想实现&amp;#39;,
 &amp;#39;青春梦想&amp;#39;,
 &amp;#39;热忱&amp;#39;,
 &amp;#39;空想&amp;#39;,
 &amp;#39;抱负&amp;#39;,
 &amp;#39;努力奋斗&amp;#39;,
 &amp;#39;美好幻想&amp;#39;,
 &amp;#39;务实&amp;#39;,
 &amp;#39;坚定信念&amp;#39;,
 &amp;#39;梦想努力&amp;#39;,
 &amp;#39;理想国&amp;#39;,
 &amp;#39;无法实现&amp;#39;,
 &amp;#39;美好愿望&amp;#39;,
 &amp;#39;理想生活&amp;#39;,
 &amp;#39;坚持自我&amp;#39;,
 &amp;#39;事业爱情&amp;#39;,
 &amp;#39;放弃梦想&amp;#39;,
 &amp;#39;愿景&amp;#39;,
 &amp;#39;自我价值&amp;#39;,
 &amp;#39;自我实现&amp;#39;,
 &amp;#39;现实面前&amp;#39;,
 &amp;#39;梦想坚持&amp;#39;,
 &amp;#39;梦想梦想&amp;#39;,
 &amp;#39;志向&amp;#39;,
 &amp;#39;乌托邦式&amp;#39;,
 &amp;#39;可能实现&amp;#39;,
 &amp;#39;追寻梦想&amp;#39;,
 &amp;#39;追求自我&amp;#39;,
 &amp;#39;追求理想&amp;#39;,
 &amp;#39;人生理想&amp;#39;,
 &amp;#39;追求完美&amp;#39;,
 &amp;#39;诗远方&amp;#39;,
 &amp;#39;梦想追求&amp;#39;,
 &amp;#39;追求艺术&amp;#39;,
 &amp;#39;执着追求&amp;#39;,
 &amp;#39;不断努力&amp;#39;,
 &amp;#39;怀揣梦想&amp;#39;,
 &amp;#39;儿时梦想&amp;#39;,
 &amp;#39;最初梦想&amp;#39;,
 &amp;#39;梦想奋斗&amp;#39;,
 &amp;#39;曾经梦想&amp;#39;,
 &amp;#39;美好向往&amp;#39;,
 &amp;#39;理想状态&amp;#39;,
 &amp;#39;现实妥协&amp;#39;,
 &amp;#39;实现理想&amp;#39;,
 &amp;#39;梦想执着&amp;#39;,
 &amp;#39;坚持理想&amp;#39;,
 &amp;#39;一个理想主义者&amp;#39;,
 &amp;#39;不切实际幻想&amp;#39;,
 &amp;#39;实现不了&amp;#39;,
 &amp;#39;努力追求&amp;#39;,
 &amp;#39;精神追求&amp;#39;,
 &amp;#39;现实打败&amp;#39;,
 &amp;#39;过于理想&amp;#39;,
 &amp;#39;美好憧憬&amp;#39;,
 &amp;#39;追寻自由&amp;#39;,
 &amp;#39;美好愿景&amp;#39;,
 &amp;#39;远大&amp;#39;,
 &amp;#39;梦想破灭&amp;#39;,
 &amp;#39;美好未来&amp;#39;,
 &amp;#39;最终实现&amp;#39;,
 &amp;#39;现实主义者&amp;#39;,
 &amp;#39;心中理想&amp;#39;,
 &amp;#39;努力实现&amp;#39;,
 &amp;#39;理想追求&amp;#39;,
 &amp;#39;理想丰满&amp;#39;,
 &amp;#39;难以实现&amp;#39;,
 &amp;#39;自由梦想&amp;#39;,
 &amp;#39;未竟&amp;#39;,
 &amp;#39;理想信念&amp;#39;,
 &amp;#39;追名逐利&amp;#39;,
 &amp;#39;崇尚自由&amp;#39;,
 &amp;#39;理想奋斗&amp;#39;,
 &amp;#39;摇滚梦&amp;#39;,
 &amp;#39;心中梦想&amp;#39;,
 &amp;#39;梦想追逐&amp;#39;,
 &amp;#39;崇高理想&amp;#39;,
 &amp;#39;爱与梦想&amp;#39;,
 &amp;#39;梦想放弃&amp;#39;,
 &amp;#39;自由理想&amp;#39;,
 &amp;#39;远大理想&amp;#39;,
 &amp;#39;革命理想&amp;#39;,
 &amp;#39;勇于追求&amp;#39;,
 &amp;#39;世俗成功&amp;#39;]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h4 id=&#34;425-most_similarpositive-negative&#34;&gt;4.2.5 most_similar(positive, negative)&lt;/h4&gt;
&lt;p&gt;找出与positive同方向，与negative反向相反的词。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;dm_w2v&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;most_similar&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;positive&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;给力&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;精彩&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;过瘾&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;
                       &lt;span class=&#34;n&#34;&gt;negative&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;垃圾&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;
                       &lt;span class=&#34;n&#34;&gt;topn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;[(&amp;#39;看得过瘾&amp;#39;, 0.7470669746398926),
 (&amp;#39;相当精彩&amp;#39;, 0.7082503437995911),
 (&amp;#39;带劲&amp;#39;, 0.6865044236183167),
 (&amp;#39;非常过瘾&amp;#39;, 0.6556571125984192),
 (&amp;#39;非常精彩&amp;#39;, 0.6555824875831604),
 (&amp;#39;够劲&amp;#39;, 0.6424692869186401),
 (&amp;#39;太精彩&amp;#39;, 0.6424689292907715),
 (&amp;#39;十分精彩&amp;#39;, 0.6388185024261475),
 (&amp;#39;足够精彩&amp;#39;, 0.6384131908416748),
 (&amp;#39;十分过瘾&amp;#39;, 0.6383010745048523)]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h3 id=&#34;43-类比king-manwomanqueen&#34;&gt;4.3 类比king-man+woman~queen&lt;/h3&gt;
&lt;p&gt;每个词是高维向量空间中的一个点， 两个点可以组成有方向的向量，而向量可以比较方向。&lt;/p&gt;
&lt;p&gt;这里是推理过程，受限于数据，公式不一定完全成立， 但是思维可以类比。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/king-queen-formular.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;这两个词相减，按感觉应该得到的是性别方向，雄性-&amp;gt;雌性。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;gender_direction_1 = vector(man)-vector(woman)&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;gender_direction_2 = vector(king)-vector(queen)&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;那两个性别方向应该近似，假设这里将其 &lt;em&gt;&lt;strong&gt;gender_direction_1=gender_direction_2&lt;/strong&gt;&lt;/em&gt; ，则对于公式中任意一个词，都可以由等式中的其他三个词经过运算得到。例如&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;vector(queen) = vector(king)-vector(man)+vector(woman)&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;这里构造了一个 &lt;code&gt;北京a - 中国b~=  巴黎c - 某国d&lt;/code&gt; 的公式，计算如下&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 北京a - 中国b~=  巴黎c - 某国d&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;a&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;dm_w2v&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;get_vector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;北京&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;b&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;dm_w2v&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;get_vector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;中国&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;c&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;dm_w2v&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;get_vector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;巴黎&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;#d = b-a+c&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;dm_w2v&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;similar_by_vector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;b&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;c&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;[(&amp;#39;中国&amp;#39;, 0.6384854912757874),
 (&amp;#39;法国&amp;#39;, 0.599371612071991),
 (&amp;#39;欧洲&amp;#39;, 0.5970593094825745),
 (&amp;#39;法国人&amp;#39;, 0.5338885188102722),
 (&amp;#39;欧洲人&amp;#39;, 0.5236572027206421),
 (&amp;#39;意大利&amp;#39;, 0.5203548669815063),
 (&amp;#39;西方&amp;#39;, 0.4940629303455353),
 (&amp;#39;亚洲&amp;#39;, 0.4907427728176117),
 (&amp;#39;美国&amp;#39;, 0.490087628364563),
 (&amp;#39;欧美&amp;#39;, 0.48989546298980713)]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;大概是跑出了我们预期的 &lt;strong&gt;法国&lt;/strong&gt;， 但不够Perfect， 有些遗憾。 毕竟语料是影评，且讨论环境不够正式， 豆瓣用户没那么多心思研究地理和政治，所以网络记忆不全不准。&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;五获取数据&#34;&gt;五、获取数据&lt;/h2&gt;
&lt;h3 id=&#34;51-获取影评数据&#34;&gt;5.1 获取影评数据&lt;/h3&gt;
&lt;p&gt;除了本文介绍的这个 1000w 条影评数据集， 大邓还有2个类似的豆瓣影评数据集，影评记录量 212w和442 w 条。 两个数据集下载链接我都公开，感兴趣的可以都下载下来。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;douba-movie-1000w&lt;/strong&gt;&lt;/em&gt; 链接: &lt;a href=&#34;https://pan.baidu.com/s/1NHttdosb0VZUQV7Tg7MHXw?pwd=rndk&#34;&gt;https://pan.baidu.com/s/1NHttdosb0VZUQV7Tg7MHXw?pwd=rndk&lt;/a&gt; 提取码: rndk&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;douban-movie-442w&lt;/strong&gt;&lt;/em&gt; 链接: &lt;a href=&#34;https://pan.baidu.com/s/10KK5FrGL0ZHx4wiuhlvuXw?pwd=db7m&#34;&gt;https://pan.baidu.com/s/10KK5FrGL0ZHx4wiuhlvuXw?pwd=db7m&lt;/a&gt; 提取码: db7m&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;【douban-movie-442w介绍】

采集时间: 
   - 电影&amp;amp;明星 2019年8月上旬
   - 影评(用户、评分、评论) 2019年9月初

记录数:
   - 电影 140502 部
   - 演员 72959 人
   - 影评 4428475 条
   - 评分 4169420 条
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;douban-movie-212w&lt;/strong&gt;&lt;/em&gt; 链接: &lt;a href=&#34;https://pan.baidu.com/s/1iCKGu_6zTe6ZhlB_9Bf1HA?pwd=cv2p&#34;&gt;https://pan.baidu.com/s/1iCKGu_6zTe6ZhlB_9Bf1HA?pwd=cv2p&lt;/a&gt; 提取码: cv2p&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h3 id=&#34;52-cntext211&#34;&gt;5.2 cntext2.1.1&lt;/h3&gt;
&lt;p&gt;cntext2.1.1 是非公开内容， &lt;strong&gt;100元&lt;/strong&gt;  可得 &lt;em&gt;&lt;strong&gt;cntext-2.1.1-py3-none-any.whl&lt;/strong&gt;&lt;/em&gt;  ， 加微信 &lt;em&gt;&lt;strong&gt;372335839&lt;/strong&gt;&lt;/em&gt;， 备注「姓名-学校-专业」&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;53-word2vec模型文件&#34;&gt;5.3 Word2Vec模型文件&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;douba-movie-1000w.200.6.bin&lt;/strong&gt;&lt;/em&gt; 链接: &lt;a href=&#34;https://pan.baidu.com/s/1ahbYq2IOqUA_AE0T3XIb9g?pwd=su1y&#34;&gt;https://pan.baidu.com/s/1ahbYq2IOqUA_AE0T3XIb9g?pwd=su1y&lt;/a&gt; 提取码: su1y&lt;/li&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;douban-movie-442w.200.6.bin&lt;/strong&gt;&lt;/em&gt;  链接: &lt;a href=&#34;https://pan.baidu.com/s/181eVuM0qldUJ53i7u1a5vA?pwd=uarj&#34;&gt;https://pan.baidu.com/s/181eVuM0qldUJ53i7u1a5vA?pwd=uarj&lt;/a&gt; 提取码: uarj&lt;/li&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;douban-movie-212w200.6.bin&lt;/strong&gt;&lt;/em&gt; 链接: &lt;a href=&#34;https://pan.baidu.com/s/1bvIZAM4zqX_35WHrBJSFUg?pwd=mf9u&#34;&gt;https://pan.baidu.com/s/1bvIZAM4zqX_35WHrBJSFUg?pwd=mf9u&lt;/a&gt; 提取码: mf9u&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
&lt;br&gt;
&lt;h2 id=&#34;相关内容&#34;&gt;相关内容&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/2024-04-17-douban-book-3394w-ratings-comments-dataset/&#34;&gt;数据集 | 3394w条豆瓣书评数据集&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;广而告之&#34;&gt;广而告之&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/call_for_paper/&#34;&gt;长期征稿&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/we_need_you/&#34;&gt;长期招募小伙伴&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/management_python_course/&#34;&gt;付费视频课 | Python实证指标构建与文本分析&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
      <content:encoded><![CDATA[<p>本文内容</p>
<ol>
<li>介绍豆瓣影评数据集</li>
<li>构造语料训练Word2Vec模型</li>
<li>获取数据&amp;cntext&amp;Word2Vec模型文件</li>
</ol>
<p><br><br></p>
<h2 id="一豆瓣影评数据集">一、豆瓣影评数据集</h2>
<h3 id="11-数据集介绍">1.1 数据集介绍</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">数据集: douba-movie-1000w

数据源: 豆瓣电影
   
记录数:
   - 电影 10269 部
   - 影评 10310989 条
   
体积: 1.35G 
</code></pre></div><p>该数据集正好弥补下国内公开电影数据集的空缺， 数据已经过初步清洗，可用于推荐系统、情感分析、知识图谱、新闻传播学、社会学文化变迁等多个领域(或主题)。</p>
<br>
<h3 id="12-读取数据">1.2 读取数据</h3>
<p>下载 <em><strong>douba-movie-1000w.zip</strong></em> 解压后，可以看到数据集中有一个 <em><strong>all_movies_with_id.csv</strong></em> 文件。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;all_movies_with_id.csv&#39;</span><span class="p">)</span>
<span class="n">df</span>
</code></pre></div><p><img loading="lazy" src="img/01-df.png" alt=""  />
</p>
<br>
<h3 id="13-所含字段">1.3 所含字段</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39; - </span><span class="si">{</span><span class="n">col</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"> - ID
 - Movie_Name  电影名
 - Score  豆瓣电影评分(1-10)
 - Review_People  评论者人数
 - Star_Distribution  评论评分分布(1-5, 含多个数值，数值以%间隔)
 - Craw_Date 爬虫运行日期
 - Username 豆瓣评论者用户名
 - Date 影评日期
 - Star  影评评分(1-5)
 - Comment 影评内容
 - Comment_Distribution 影评评分分布
 - Like 影评获得的喜欢数
</code></pre></div><p><br><br></p>
<h2 id="二-构造语料训练word2vec">二、 构造语料&amp;训练Word2Vec</h2>
<h3 id="21-构造语料">2.1 构造语料</h3>
<p>将字段 <em><strong>Comment</strong></em> 中所有文本汇总到 <em><strong>douban-movie-1000w.txt</strong></em>,</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;douban-movie-1000w.txt&#39;</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">text</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;Comment&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
    <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
</code></pre></div><br>
<h3 id="22-配置cntext211">2.2 配置cntext2.1.1</h3>
<p>将 <em><strong>cntext-2.1.1-py3-none-any.whl</strong></em> 放置于桌面，打开 <em><strong>cmd</strong></em>  (苹果电脑打开terminal)， 输入cd desktop</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">cd desktop
</code></pre></div><p>之后在 <em><strong>cmd</strong></em>  (苹果电脑打开terminal) 中使用 <em><strong>pip3</strong></em> 安装</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">pip3 install distinctiveness
pip3 install cntext-2.1.1-py3-none-any.whl
</code></pre></div><p>文末有 <em><strong>cntext-2.1.1-py3-none-any.whl</strong></em> 获取方式</p>
<br>
<h3 id="23-训练word2vec">2.3 训练Word2Vec</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#cntext为2.1.1</span>
<span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>

<span class="n">w2v_model</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">W2VModel</span><span class="p">(</span><span class="n">corpus_file</span><span class="o">=</span><span class="s1">&#39;douban-movie-1000w.txt&#39;</span><span class="p">,</span>
                        <span class="n">lang</span><span class="o">=</span><span class="s1">&#39;chinese&#39;</span><span class="p">)</span>

<span class="n">w2v_model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">vector_size</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">window_size</span><span class="o">=</span><span class="mi">6</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">Starting Preprocessing Corpus ...
Starting Training! This may take a while.Please be patient...
Traning word2vec model took 3965 seconds
Note: The Word2Vec model hase saved to output/Word2Vec
</code></pre></div><p><img loading="lazy" src="img/word2vec.png" alt=""  />
</p>
<p>经过大概一个小时的训练， 得到模型文件 <em><strong>douban-movie-1000w.200.6.bin</strong></em> 及相关文件， 注意不要删掉哦。 已训练好的模型，可以自己用， 也可分享给其他人使用。</p>
<p><br><br></p>
<h2 id="四使用word2vec">四、使用Word2Vec</h2>
<h3 id="41-导入word2vec模型文件">4.1 导入Word2Vec模型文件</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>
 
<span class="c1">#导入模型，请注意路径。</span>
<span class="c1"># 【当前代码】 与 【Word2Vec文件夹】 同处于一个文件夹内</span>
<span class="n">dm_w2v</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">load_w2v</span><span class="p">(</span><span class="s1">&#39;Word2Vec/douban-movie-1000w.200.6.bin&#39;</span><span class="p">)</span>
<span class="n">dm_w2v</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">Loading word2vec model...
&lt;gensim.models.word2vec.Word2Vec at 0x10cb02090&gt;
</code></pre></div><br>
<h3 id="42-常用函数">4.2 常用函数</h3>
<ul>
<li>
<p><em><strong>dm_w2v.wv.get_vector(key)</strong></em> 获取key的词向量</p>
</li>
<li>
<p><em><strong>dm_w2v.most_similar_to_given(key1, keys_list)</strong></em> 从 keys_list 中获取与 key1 最相似的词</p>
</li>
<li>
<p><em><strong>dm_w2v.n_similarity(ws1, ws2)</strong></em>  两组词ws1, ws2 的相似度</p>
</li>
<li>
<p><em><strong>dm_w2v.closer_than(key1, key2)</strong></em>  更接近于key1的词向量(相比于key2)</p>
</li>
<li>
<p><em><strong>dm_w2v.most_similar(positive, negative)</strong></em>  找出与positive同方向，与negative反向相反的词。</p>
</li>
</ul>
<br>
<h4 id="421-get_vectorkey">4.2.1 get_vector(key)</h4>
<p>使用词向量查看某</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">dm_w2v</span><span class="o">.</span><span class="n">wv</span><span class="o">.</span><span class="n">get_vector</span><span class="p">(</span><span class="s1">&#39;给力&#39;</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mf">3.55084002e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.22685611e+00</span><span class="p">,</span> <span class="o">-</span><span class="mf">8.48365605e-01</span><span class="p">,</span>  <span class="mf">1.23056602e+00</span><span class="p">,</span>
        <span class="mf">1.35057056e+00</span><span class="p">,</span>  <span class="mf">1.65976137e-02</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.26512849e+00</span><span class="p">,</span>  <span class="mf">1.47152972e+00</span><span class="p">,</span>
        <span class="mf">9.99028236e-03</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.00873756e+00</span><span class="p">,</span>  <span class="mf">1.05153358e+00</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.39181948e+00</span><span class="p">,</span>
        <span class="mf">6.02373898e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.00308895e+00</span><span class="p">,</span>  <span class="mf">2.33978868e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.83010173e+00</span><span class="p">,</span>
       <span class="o">-</span><span class="mf">9.67333555e-01</span><span class="p">,</span>  <span class="mf">3.04877937e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">6.59058094e-01</span><span class="p">,</span>  <span class="mf">3.19660306e+00</span><span class="p">,</span>
       <span class="o">-</span><span class="mf">1.21165246e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">3.68000716e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.36653373e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">6.83727741e-01</span><span class="p">,</span>
      <span class="o">......</span>
      <span class="o">......</span>
       <span class="o">-</span><span class="mf">1.23901594e+00</span><span class="p">,</span>  <span class="mf">5.07202707e-02</span><span class="p">,</span>  <span class="mf">8.75848413e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">4.31963325e-01</span><span class="p">,</span>
        <span class="mf">1.31377324e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.19606090e+00</span><span class="p">,</span>  <span class="mf">1.68391216e+00</span><span class="p">,</span> <span class="o">-</span><span class="mf">6.27069890e-01</span><span class="p">,</span>
       <span class="o">-</span><span class="mf">7.37121344e-01</span><span class="p">,</span>  <span class="mf">2.49946609e-01</span><span class="p">,</span>  <span class="mf">1.47220814e+00</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.33507824e+00</span><span class="p">,</span>
        <span class="mf">2.97913142e-02</span><span class="p">,</span> <span class="o">-</span><span class="mf">4.91593599e-01</span><span class="p">,</span>  <span class="mf">5.83192170e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">8.48378658e-01</span><span class="p">,</span>
       <span class="o">-</span><span class="mf">3.30877733e+00</span><span class="p">,</span>  <span class="mf">2.17747837e-01</span><span class="p">,</span>  <span class="mf">2.22701088e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.00758147e+00</span><span class="p">,</span>
        <span class="mf">3.41430195e-02</span><span class="p">,</span> <span class="o">-</span><span class="mf">7.27023900e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">7.94953525e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.03226733e+00</span><span class="p">,</span>
       <span class="o">-</span><span class="mf">4.55965906e-01</span><span class="p">,</span>  <span class="mf">1.66779244e+00</span><span class="p">,</span>  <span class="mf">1.16857982e+00</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.02211344e+00</span><span class="p">,</span>
        <span class="mf">4.11061406e-01</span><span class="p">,</span>  <span class="mf">8.95921767e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">9.48565483e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.48802996e-01</span><span class="p">,</span>
        <span class="mf">9.36261594e-01</span><span class="p">,</span>  <span class="mf">3.98367733e-01</span><span class="p">,</span>  <span class="mf">3.12385857e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">8.67059827e-01</span><span class="p">],</span>
      <span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">)</span>
</code></pre></div><br>
<h4 id="422-most_similar_to_givenkey1-keys_list">4.2.2 most_similar_to_given(key1, keys_list)</h4>
<p>从 keys_list 中获取与 key1 最相似的词。例如在 1000w 影评中，从<code>'爱情', '悬疑', '飞船', '历史', '战争'</code>找出最接近<code>'太空'</code>，最后返回<code>'飞船'</code></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#从 `keys_list` 中获取与 `key1` 最相似的 `key`。</span>
<span class="n">dm_w2v</span><span class="o">.</span><span class="n">wv</span><span class="o">.</span><span class="n">most_similar_to_given</span><span class="p">(</span><span class="n">key1</span><span class="o">=</span><span class="s1">&#39;太空&#39;</span><span class="p">,</span> 
                                <span class="n">keys_list</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;爱情&#39;</span><span class="p">,</span> <span class="s1">&#39;悬疑&#39;</span><span class="p">,</span> <span class="s1">&#39;飞船&#39;</span><span class="p">,</span> <span class="s1">&#39;历史&#39;</span><span class="p">,</span> <span class="s1">&#39;战争&#39;</span><span class="p">])</span>

</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">&#39;飞船&#39;
</code></pre></div><br>
<h4 id="423-w2v_modeln_similarityws1-ws2">4.2.3 w2v_model.n_similarity(ws1, ws2)</h4>
<p>两组词ws1, ws2 的相似度。注意相似值更多的是体现了语义的相关性， 并不能准确反映语义的远近。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">sklearn.metrics.pairwise</span> <span class="kn">import</span> <span class="n">cosine_similarity</span>

<span class="n">cosine_similarity</span><span class="p">([</span><span class="n">dm_w2v</span><span class="o">.</span><span class="n">wv</span><span class="o">.</span><span class="n">get_vector</span><span class="p">(</span><span class="s1">&#39;理想&#39;</span><span class="p">)],</span>  
                  <span class="p">[</span><span class="n">dm_w2v</span><span class="o">.</span><span class="n">wv</span><span class="o">.</span><span class="n">get_vector</span><span class="p">(</span><span class="s1">&#39;现实&#39;</span><span class="p">)])[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">0.4698379
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#cosine算法</span>
<span class="n">dm_w2v</span><span class="o">.</span><span class="n">wv</span><span class="o">.</span><span class="n">n_similarity</span><span class="p">([</span><span class="s1">&#39;理想&#39;</span><span class="p">],</span> 
                       <span class="p">[</span><span class="s1">&#39;现实&#39;</span><span class="p">])</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">0.4698379
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#计算两组键之间的余弦相似度。</span>
<span class="n">dm_w2v</span><span class="o">.</span><span class="n">wv</span><span class="o">.</span><span class="n">n_similarity</span><span class="p">([</span><span class="s1">&#39;给力&#39;</span><span class="p">,</span> <span class="s1">&#39;精彩&#39;</span><span class="p">,</span> <span class="s1">&#39;赞&#39;</span><span class="p">,</span> <span class="s1">&#39;推荐&#39;</span><span class="p">],</span> 
                       <span class="p">[</span><span class="s1">&#39;无聊&#39;</span><span class="p">,</span> <span class="s1">&#39;尴尬&#39;</span><span class="p">,</span> <span class="s1">&#39;垃圾&#39;</span><span class="p">])</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">0.109311774
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">dm_w2v</span><span class="o">.</span><span class="n">wv</span><span class="o">.</span><span class="n">n_similarity</span><span class="p">([</span><span class="s1">&#39;理想&#39;</span><span class="p">,</span> <span class="s1">&#39;梦想&#39;</span><span class="p">],</span> 
                       <span class="p">[</span><span class="s1">&#39;现实&#39;</span><span class="p">,</span> <span class="s1">&#39;生活&#39;</span><span class="p">])</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">0.48020104
</code></pre></div><br>
<h4 id="424-closer_thankey1-key2">4.2.4 closer_than(key1, key2)</h4>
<p>更接近于key1的词向量(相比于key2)</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#获取所有更接近 `key1` 的键，而不是 `key2` 。</span>
<span class="n">dm_w2v</span><span class="o">.</span><span class="n">wv</span><span class="o">.</span><span class="n">closer_than</span><span class="p">(</span><span class="n">key1</span><span class="o">=</span><span class="s1">&#39;理想&#39;</span><span class="p">,</span> 
                      <span class="n">key2</span><span class="o">=</span><span class="s1">&#39;现实&#39;</span><span class="p">)</span>

</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">[&#39;梦想&#39;,
 &#39;追求&#39;,
 &#39;实现&#39;,
 &#39;向往&#39;,
 &#39;信念&#39;,
 &#39;妥协&#39;,
 &#39;奋斗&#39;,
 &#39;乌托邦&#39;,
 &#39;愿望&#39;,
 &#39;理想主义&#39;,
 &#39;理想化&#39;,
 &#39;虚幻&#39;,
 &#39;憧憬&#39;,
 &#39;现实残酷&#39;,
 &#39;不切实际&#39;,
 &#39;实现梦想&#39;,
 &#39;崇高&#39;,
 &#39;理想主义者&#39;,
 &#39;追求自由&#39;,
 &#39;破灭&#39;,
 &#39;名利&#39;,
 &#39;追梦&#39;,
 &#39;奢望&#39;,
 &#39;追求梦想&#39;,
 &#39;现实现实&#39;,
 &#39;执著&#39;,
 &#39;理想现实&#39;,
 &#39;拼搏&#39;,
 &#39;面对现实&#39;,
 &#39;美好事物&#39;,
 &#39;追逐梦想&#39;,
 &#39;勇往直前&#39;,
 &#39;遥不可及&#39;,
 &#39;怀揣&#39;,
 &#39;梦想现实&#39;,
 &#39;美好生活&#39;,
 &#39;脚踏实地&#39;,
 &#39;本心&#39;,
 &#39;坚持梦想&#39;,
 &#39;梦想实现&#39;,
 &#39;青春梦想&#39;,
 &#39;热忱&#39;,
 &#39;空想&#39;,
 &#39;抱负&#39;,
 &#39;努力奋斗&#39;,
 &#39;美好幻想&#39;,
 &#39;务实&#39;,
 &#39;坚定信念&#39;,
 &#39;梦想努力&#39;,
 &#39;理想国&#39;,
 &#39;无法实现&#39;,
 &#39;美好愿望&#39;,
 &#39;理想生活&#39;,
 &#39;坚持自我&#39;,
 &#39;事业爱情&#39;,
 &#39;放弃梦想&#39;,
 &#39;愿景&#39;,
 &#39;自我价值&#39;,
 &#39;自我实现&#39;,
 &#39;现实面前&#39;,
 &#39;梦想坚持&#39;,
 &#39;梦想梦想&#39;,
 &#39;志向&#39;,
 &#39;乌托邦式&#39;,
 &#39;可能实现&#39;,
 &#39;追寻梦想&#39;,
 &#39;追求自我&#39;,
 &#39;追求理想&#39;,
 &#39;人生理想&#39;,
 &#39;追求完美&#39;,
 &#39;诗远方&#39;,
 &#39;梦想追求&#39;,
 &#39;追求艺术&#39;,
 &#39;执着追求&#39;,
 &#39;不断努力&#39;,
 &#39;怀揣梦想&#39;,
 &#39;儿时梦想&#39;,
 &#39;最初梦想&#39;,
 &#39;梦想奋斗&#39;,
 &#39;曾经梦想&#39;,
 &#39;美好向往&#39;,
 &#39;理想状态&#39;,
 &#39;现实妥协&#39;,
 &#39;实现理想&#39;,
 &#39;梦想执着&#39;,
 &#39;坚持理想&#39;,
 &#39;一个理想主义者&#39;,
 &#39;不切实际幻想&#39;,
 &#39;实现不了&#39;,
 &#39;努力追求&#39;,
 &#39;精神追求&#39;,
 &#39;现实打败&#39;,
 &#39;过于理想&#39;,
 &#39;美好憧憬&#39;,
 &#39;追寻自由&#39;,
 &#39;美好愿景&#39;,
 &#39;远大&#39;,
 &#39;梦想破灭&#39;,
 &#39;美好未来&#39;,
 &#39;最终实现&#39;,
 &#39;现实主义者&#39;,
 &#39;心中理想&#39;,
 &#39;努力实现&#39;,
 &#39;理想追求&#39;,
 &#39;理想丰满&#39;,
 &#39;难以实现&#39;,
 &#39;自由梦想&#39;,
 &#39;未竟&#39;,
 &#39;理想信念&#39;,
 &#39;追名逐利&#39;,
 &#39;崇尚自由&#39;,
 &#39;理想奋斗&#39;,
 &#39;摇滚梦&#39;,
 &#39;心中梦想&#39;,
 &#39;梦想追逐&#39;,
 &#39;崇高理想&#39;,
 &#39;爱与梦想&#39;,
 &#39;梦想放弃&#39;,
 &#39;自由理想&#39;,
 &#39;远大理想&#39;,
 &#39;革命理想&#39;,
 &#39;勇于追求&#39;,
 &#39;世俗成功&#39;]
</code></pre></div><br>
<h4 id="425-most_similarpositive-negative">4.2.5 most_similar(positive, negative)</h4>
<p>找出与positive同方向，与negative反向相反的词。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">dm_w2v</span><span class="o">.</span><span class="n">wv</span><span class="o">.</span><span class="n">most_similar</span><span class="p">(</span><span class="n">positive</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;给力&#39;</span><span class="p">,</span> <span class="s1">&#39;精彩&#39;</span><span class="p">,</span> <span class="s1">&#39;过瘾&#39;</span><span class="p">],</span>
                       <span class="n">negative</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;垃圾&#39;</span><span class="p">],</span>
                       <span class="n">topn</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">[(&#39;看得过瘾&#39;, 0.7470669746398926),
 (&#39;相当精彩&#39;, 0.7082503437995911),
 (&#39;带劲&#39;, 0.6865044236183167),
 (&#39;非常过瘾&#39;, 0.6556571125984192),
 (&#39;非常精彩&#39;, 0.6555824875831604),
 (&#39;够劲&#39;, 0.6424692869186401),
 (&#39;太精彩&#39;, 0.6424689292907715),
 (&#39;十分精彩&#39;, 0.6388185024261475),
 (&#39;足够精彩&#39;, 0.6384131908416748),
 (&#39;十分过瘾&#39;, 0.6383010745048523)]
</code></pre></div><br>
<h3 id="43-类比king-manwomanqueen">4.3 类比king-man+woman~queen</h3>
<p>每个词是高维向量空间中的一个点， 两个点可以组成有方向的向量，而向量可以比较方向。</p>
<p>这里是推理过程，受限于数据，公式不一定完全成立， 但是思维可以类比。</p>
<p><img loading="lazy" src="img/king-queen-formular.png" alt=""  />
</p>
<p>这两个词相减，按感觉应该得到的是性别方向，雄性-&gt;雌性。</p>
<p><em><strong>gender_direction_1 = vector(man)-vector(woman)</strong></em></p>
<p><em><strong>gender_direction_2 = vector(king)-vector(queen)</strong></em></p>
<p>那两个性别方向应该近似，假设这里将其 <em><strong>gender_direction_1=gender_direction_2</strong></em> ，则对于公式中任意一个词，都可以由等式中的其他三个词经过运算得到。例如</p>
<p><em><strong>vector(queen) = vector(king)-vector(man)+vector(woman)</strong></em></p>
<p>这里构造了一个 <code>北京a - 中国b~=  巴黎c - 某国d</code> 的公式，计算如下</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1"># 北京a - 中国b~=  巴黎c - 某国d</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">dm_w2v</span><span class="o">.</span><span class="n">wv</span><span class="o">.</span><span class="n">get_vector</span><span class="p">(</span><span class="s1">&#39;北京&#39;</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">dm_w2v</span><span class="o">.</span><span class="n">wv</span><span class="o">.</span><span class="n">get_vector</span><span class="p">(</span><span class="s1">&#39;中国&#39;</span><span class="p">)</span>
<span class="n">c</span> <span class="o">=</span> <span class="n">dm_w2v</span><span class="o">.</span><span class="n">wv</span><span class="o">.</span><span class="n">get_vector</span><span class="p">(</span><span class="s1">&#39;巴黎&#39;</span><span class="p">)</span>

<span class="c1">#d = b-a+c</span>
<span class="n">dm_w2v</span><span class="o">.</span><span class="n">wv</span><span class="o">.</span><span class="n">similar_by_vector</span><span class="p">(</span><span class="n">b</span><span class="o">-</span><span class="n">a</span><span class="o">+</span><span class="n">c</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">[(&#39;中国&#39;, 0.6384854912757874),
 (&#39;法国&#39;, 0.599371612071991),
 (&#39;欧洲&#39;, 0.5970593094825745),
 (&#39;法国人&#39;, 0.5338885188102722),
 (&#39;欧洲人&#39;, 0.5236572027206421),
 (&#39;意大利&#39;, 0.5203548669815063),
 (&#39;西方&#39;, 0.4940629303455353),
 (&#39;亚洲&#39;, 0.4907427728176117),
 (&#39;美国&#39;, 0.490087628364563),
 (&#39;欧美&#39;, 0.48989546298980713)]
</code></pre></div><p>大概是跑出了我们预期的 <strong>法国</strong>， 但不够Perfect， 有些遗憾。 毕竟语料是影评，且讨论环境不够正式， 豆瓣用户没那么多心思研究地理和政治，所以网络记忆不全不准。</p>
<p><br><br></p>
<h2 id="五获取数据">五、获取数据</h2>
<h3 id="51-获取影评数据">5.1 获取影评数据</h3>
<p>除了本文介绍的这个 1000w 条影评数据集， 大邓还有2个类似的豆瓣影评数据集，影评记录量 212w和442 w 条。 两个数据集下载链接我都公开，感兴趣的可以都下载下来。</p>
<ul>
<li>
<p><em><strong>douba-movie-1000w</strong></em> 链接: <a href="https://pan.baidu.com/s/1NHttdosb0VZUQV7Tg7MHXw?pwd=rndk">https://pan.baidu.com/s/1NHttdosb0VZUQV7Tg7MHXw?pwd=rndk</a> 提取码: rndk</p>
</li>
<li>
<p><em><strong>douban-movie-442w</strong></em> 链接: <a href="https://pan.baidu.com/s/10KK5FrGL0ZHx4wiuhlvuXw?pwd=db7m">https://pan.baidu.com/s/10KK5FrGL0ZHx4wiuhlvuXw?pwd=db7m</a> 提取码: db7m</p>
</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">【douban-movie-442w介绍】

采集时间: 
   - 电影&amp;明星 2019年8月上旬
   - 影评(用户、评分、评论) 2019年9月初

记录数:
   - 电影 140502 部
   - 演员 72959 人
   - 影评 4428475 条
   - 评分 4169420 条
</code></pre></div><ul>
<li><em><strong>douban-movie-212w</strong></em> 链接: <a href="https://pan.baidu.com/s/1iCKGu_6zTe6ZhlB_9Bf1HA?pwd=cv2p">https://pan.baidu.com/s/1iCKGu_6zTe6ZhlB_9Bf1HA?pwd=cv2p</a> 提取码: cv2p</li>
</ul>
<p><br><br></p>
<h3 id="52-cntext211">5.2 cntext2.1.1</h3>
<p>cntext2.1.1 是非公开内容， <strong>100元</strong>  可得 <em><strong>cntext-2.1.1-py3-none-any.whl</strong></em>  ， 加微信 <em><strong>372335839</strong></em>， 备注「姓名-学校-专业」</p>
<br>
<h3 id="53-word2vec模型文件">5.3 Word2Vec模型文件</h3>
<ul>
<li><em><strong>douba-movie-1000w.200.6.bin</strong></em> 链接: <a href="https://pan.baidu.com/s/1ahbYq2IOqUA_AE0T3XIb9g?pwd=su1y">https://pan.baidu.com/s/1ahbYq2IOqUA_AE0T3XIb9g?pwd=su1y</a> 提取码: su1y</li>
<li><em><strong>douban-movie-442w.200.6.bin</strong></em>  链接: <a href="https://pan.baidu.com/s/181eVuM0qldUJ53i7u1a5vA?pwd=uarj">https://pan.baidu.com/s/181eVuM0qldUJ53i7u1a5vA?pwd=uarj</a> 提取码: uarj</li>
<li><em><strong>douban-movie-212w200.6.bin</strong></em> 链接: <a href="https://pan.baidu.com/s/1bvIZAM4zqX_35WHrBJSFUg?pwd=mf9u">https://pan.baidu.com/s/1bvIZAM4zqX_35WHrBJSFUg?pwd=mf9u</a> 提取码: mf9u</li>
</ul>
<br>
<br>
<h2 id="相关内容">相关内容</h2>
<ul>
<li><a href="https://textdata.cn/blog/2024-04-17-douban-book-3394w-ratings-comments-dataset/">数据集 | 3394w条豆瓣书评数据集</a></li>
</ul>
<p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>数据集| A股上市公司基本信息2000-2023</title>
      <link>https://textdata.cn/blog/2024-04-16-china-listed-company-information-dataset/</link>
      <pubDate>Tue, 16 Apr 2024 00:00:00 +0000</pubDate>
      
      <guid>/blog/2024-04-16-china-listed-company-information-dataset/</guid>
      <description>A股上市公司基本信息</description>
      <content:encoded><![CDATA[<h2 id="一数据概况">一、数据概况</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">数据集: A股上市公司基本信息
年份: 2000-2023
公司数: 5504
记录数: 60901
用途: 可与年报、md&amp;a数据集进行并表
</code></pre></div><p><br><br></p>
<h2 id="二查看数据">二、查看数据</h2>
<h3 id="21-导入数据">2.1 导入数据</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;上市公司基本信息2000-2023.csv&#39;</span><span class="p">)</span>
<span class="n">df</span>
</code></pre></div><p><img loading="lazy" src="img/df1.png" alt=""  />
</p>
<p><br><br></p>
<p>如果股票代码中带的字母A别扭，可以剔除掉</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df</span><span class="o">.</span><span class="n">Symbol</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">Symbol</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;A&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">)</span>
<span class="n">df</span>
</code></pre></div><p><img loading="lazy" src="img/df2.png" alt=""  />
</p>
<p><br><br></p>
<h3 id="22-查看字段">2.2 查看字段</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1"># 查看字段/含义</span>
<span class="n">max_col_len</span> <span class="o">=</span> <span class="nb">max</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">col</span><span class="p">)</span> <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">])</span>
<span class="n">max_desc_len</span> <span class="o">=</span> <span class="nb">max</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">desc</span><span class="p">))</span> <span class="k">for</span> <span class="n">desc</span> <span class="ow">in</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="o">.</span><span class="n">index</span><span class="o">==</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="mi">0</span><span class="p">]])</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;- 字段                   含义         缺失率&#39;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">col</span><span class="p">,</span> <span class="n">desc</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="o">.</span><span class="n">index</span><span class="o">==</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
    <span class="n">ratio</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">isna</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;- </span><span class="si">{</span><span class="n">col</span><span class="si">:</span><span class="s1">&lt;</span><span class="si">{</span><span class="n">max_col_len</span><span class="si">}}</span><span class="s1">   </span><span class="si">{</span><span class="n">desc</span><span class="si">:</span><span class="s1">&lt;</span><span class="si">{</span><span class="n">max_desc_len</span><span class="si">}}</span><span class="s1">     </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">ratio</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span><span class="o">*</span><span class="mi">100</span><span class="si">}</span><span class="s1">%&#39;</span><span class="p">)</span>

</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">- 字段                   含义         缺失率
- Symbol                股票代码         0.0%
- ShortName             股票简称         0.0%
- EndDate               统计截止日期       0.0%
- ListedCoID            上市公司ID       0.0%
- SecurityID            证券ID         0.0%
- IndustryName          行业名称         0.0%
- IndustryCode          行业代码         0.0%
- IndustryNameC         行业名称C        0.0%
- IndustryCodeC         行业代码C        0.0%
- RegisterAddress       注册具体地址       0.0%
- OfficeAddress         公司办公地址       0.0%
- Zipcode               办公地址邮政编码     0.0%
- Secretary             董事会秘书        0.1%
- SecretaryTel          董秘联系电话       0.1%
- SecretaryFax          董秘传真         0.7000000000000001%
- SecretaryEmail        董秘电子邮箱       0.7000000000000001%
- SecurityConsultant    证券事务代表       17.7%
- SocialCreditCode      统一社会信用代码     23.400000000000002%
- Sigchange             重大变更         5.3%
- Lng                   办公地经度        4.6%
- Lat                   办公地纬度        4.6%
- ISIN                  ISIN编码       0.6%
- FullName              中文全称         0.0%
- LegalRepresentative   法人代表         0.0%
- EstablishDate         公司成立日期       0.0%
- Crcd                  ABH股交叉码      93.8%
- RegisterCapital       注册资本         0.0%
- Website               公司网址         4.5%
- BusinessScope         经营范围         0.0%
- RegisterLongitude     注册地经度        4.7%
- RegisterLatitude      注册地纬度        4.7%
- EMAIL                 电子邮箱         0.7000000000000001%
- LISTINGDATE           首次上市日期       0.0%
- PROVINCECODE          所属省份代码       0.0%
- PROVINCE              所属省份         0.0%
- CITYCODE              所属城市代码       0.2%
- CITY                  所属城市         0.0%
- MAINBUSSINESS         主营业务         0.0%
- LISTINGSTATE          上市状态         0.0%
</code></pre></div><br>
<h3 id="23-公司数">2.3 公司数</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df</span><span class="o">.</span><span class="n">Symbol</span><span class="o">.</span><span class="n">nunique</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">5504
</code></pre></div><br>
<br>
<h2 id="三增加其他数据集字段数量">三、增加其他数据集字段数量</h2>
<p><a href="https://textdata.cn/blog/2023-03-23-china-a-share-market-dataset-mda-from-01-to-21/"><strong>数据集 | 2001-2023A股上市公司年报&amp;管理层讨论与分析</strong></a> 只有 <em><strong>year</strong></em>、<em><strong>code</strong></em>、<em><strong>text</strong></em> 三个字段， 通过与本数据集合并操作(pd.merge) ，现在希望增加 <em><strong>EndDate</strong></em>、<em><strong>ShortName</strong></em>、<em><strong>IndustryCode</strong></em>、 <em><strong>RegisterAddress</strong></em> 四个字段。<br></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">mda_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;mda01-23.csv.gz&#39;</span><span class="p">,</span> <span class="n">compression</span><span class="o">=</span><span class="s1">&#39;gzip&#39;</span><span class="p">)</span>
<span class="n">mda_df</span><span class="p">[</span><span class="s1">&#39;year&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">mda_df</span><span class="p">[</span><span class="s1">&#39;year&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">str</span><span class="p">)</span>
<span class="n">mda_df</span>
</code></pre></div><p><img loading="lazy" src="img/mda.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#选择需要的字段进行读取</span>
<span class="n">info_df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="s1">&#39;Symbol&#39;</span><span class="p">,</span> <span class="s1">&#39;ShortName&#39;</span><span class="p">,</span> <span class="s1">&#39;EndDate&#39;</span><span class="p">,</span> <span class="s1">&#39;IndustryCode&#39;</span><span class="p">,</span> <span class="s1">&#39;RegisterAddress&#39;</span><span class="p">]]</span>

<span class="c1">#更改字段名Symbol为code</span>
<span class="n">info_df</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s2">&#34;Symbol&#34;</span><span class="p">:</span> <span class="s2">&#34;code&#34;</span><span class="p">},</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1">#根据EndDate计算会计年度year</span>
<span class="n">info_df</span><span class="p">[</span><span class="s1">&#39;year&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">info_df</span><span class="p">[</span><span class="s1">&#39;EndDate&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">y</span><span class="p">:</span> <span class="n">y</span><span class="p">[:</span><span class="mi">4</span><span class="p">])</span>
<span class="n">info_df</span>
</code></pre></div><p><img loading="lazy" src="img/info_df.png" alt=""  />
</p>
<p><br><br>根据字段 <em><strong>year</strong></em>、<em><strong>code</strong></em> 进行合并，合并方式为内连接 <em><strong>inner</strong></em> ， 即两数据集的交集。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df_merge</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">mda_df</span><span class="p">,</span> <span class="n">info_df</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;year&#39;</span><span class="p">,</span> <span class="s1">&#39;code&#39;</span><span class="p">],</span> <span class="n">how</span><span class="o">=</span><span class="s1">&#39;inner&#39;</span><span class="p">)</span>

<span class="c1">#保存</span>
<span class="c1">#df_merge.to_csv(&#39;合并后的数据.csv&#39;, index=False)</span>
<span class="c1">#df_merge.to_excel(&#39;合并后的数据.xlsx&#39;, index=False)</span>
<span class="n">df_merge</span>
</code></pre></div><p><img loading="lazy" src="img/merge.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="三相关内容">三、相关内容</h2>
<ul>
<li><a href="https://textdata.cn/blog/2023-03-23-china-a-share-market-dataset-mda-from-01-to-21/">数据集 | 2001-2023年A股上市公司年报&amp;管理层讨论与分析</a></li>
<li><a href="https://textdata.cn/blog/2023-01-06-mda_informative_content/">中国工业经济 | MD&amp;A信息含量指标构建代码实现</a></li>
<li><a href="https://textdata.cn/blog/2023-01-13-information-content-of-critical-audit/">金融研究 | 使用Python构建「关键审计事项信息含量」</a></li>
</ul>
<br>
<br>
<h2 id="四获取数据">四、获取数据</h2>
<p>整理不易， 50元 ， 加微信 372335839 ， 备注 「姓名-学校-专业」。</p>
<p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>文献&amp;代码 | 使用Python计算语义品牌评分(Semantic Brand Score)</title>
      <link>https://textdata.cn/blog/2024-04-12-semantic-brand-score/</link>
      <pubDate>Fri, 12 Apr 2024 00:00:00 +0000</pubDate>
      
      <guid>/blog/2024-04-12-semantic-brand-score/</guid>
      <description>Semantic Brand Score</description>
      <content:encoded><![CDATA[<h2 id="一语义品牌评分">一、语义品牌评分</h2>
<p><strong>语义品牌评分(SBS)</strong>  是一种新颖的指标，可以通过文本语料，衡量(评估)不同环境下一个或多个品牌的 <strong>品牌重要性</strong>。 <br></p>
<blockquote>
<p>Colladon, Andrea Fronzetti. &ldquo;<em><strong>The semantic brand score</strong></em>.&rdquo; <em>Journal of Business Research</em> 88 (2018): 150-160.</p>
</blockquote>
<br>
<p>相对于一些传统措施的优点是，SBS 不依赖于对小样本消费者进行的调查，可以捕捉到真实可信的信号 。该度量可以<strong>对任意来源的文本进行计算</strong>， 例如报纸文章、电子邮件、推文、在线论坛、博客和社交媒体上的帖子。  如果研究景点品牌的重要性，可以从消费者或其他品牌利益相关者通常出现的地方（例如旅游论坛）收集他们的发表的信息。这样做的优点是可以减少因使用问卷而引起的偏见，因为受访者知道他们正在被观察。 SBS 还可以适应不同的语言，并研究特定单词或单词集（不一定是“品牌”）的重要性。</p>
<p>通过 “品牌”，人们可以指政治家的名字，或者代表一个概念的一组单词（例如，“创新”的概念或企业核心价值）。该措施用于评估新品牌取代旧品牌时发生的过渡动态。语义品牌评分还可用于将品牌的重要性与其竞争对手的重要性联系起来，或分析单个品牌的重要性时间趋势。在某些应用中，事实证明该分数对于预测目的很有用。例如，人们发现在线媒体中政治候选人的品牌重要性与选举结果之间存在联系，或者景点品牌的重要性与游客数量趋势之间存在联系。</p>
<p><img loading="lazy" src="img/sbs-trend-plot.jpg" alt=""  />
</p>
<p><br><br></p>
<h2 id="二品牌重要性的三个维度">二、品牌重要性的三个维度</h2>
<p>SBS 衡量 <strong>品牌重要性</strong> ，这是品牌资产的基础(Fronzetti Colladon， 2018)。事实上，该指标的部分灵感来自于众所周知的品牌资产概念以及品牌形象和品牌意识的构建（Keller, 1993）。 品牌重要性通过三个维度来衡量：<strong>流行度</strong>、<strong>多样性</strong> 和 <strong>连通性</strong>。</p>
<ul>
<li><strong>流行度(Prevalence)</strong>   衡量品牌名称的使用频率，即直接提及品牌的次数。</li>
<li><strong>多样性(Diversity)</strong>  衡量与品牌相关的词语的多样性。</li>
<li><strong>连接性(Connectivity)</strong>  代表品牌在其他单词或单词组（有时被视为话语主题）之间建立联系的能力。</li>
</ul>
<p><br><br></p>
<h2 id="三文本分析步骤">三、文本分析步骤</h2>
<p><strong>语义品牌得分(SBS)</strong>  的计算需要结合文本挖掘和社交网络分析的方法和工具。下图说明了主要的初步步骤，包括数据收集、文本预处理和单词共现网络的构建。</p>
<p><img loading="lazy" src="img/text-preprocess.jpg" alt=""  />
</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">1. 准备文本数据
2. 文本预处理(剔除标点符号、剔除特殊字符、剔除html标签、剔除#@等符号、剔除停用词)
3. 英文小写、分词、合并同类项(类似于is、was、are都合并到be)
4. 从文本信息中构建共现语义网络(确定词语上下文范围，涉及到co-range， 默认co-range=7)
5. 剔除贡献语义网络中不重要的边(联系， 涉及到参数link_filter， 默认link_filter=2))
</code></pre></div><br>
<br>
<h2 id="四实验">四、实验</h2>
<p>以三体为例，分析小说中5个角色的语义品牌评分（类比于文本中分析品牌的重要性） 。我们将小说等分为20分，希望得到角色语义品牌评分随着小说进度的变化趋势。</p>
<p><img loading="lazy" src="img/plot.png" alt=""  />
</p>
<br>
<h3 id="41-读取数据">4.1 读取数据</h3>
<p>三体小说2.5M</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>


<span class="k">def</span> <span class="nf">read_txt</span><span class="p">(</span><span class="n">file</span><span class="p">,</span> <span class="n">num_segments</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">):</span>
    <span class="c1"># 读取txt文件</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">file</span><span class="p">,</span> <span class="s2">&#34;r&#34;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="n">encoding</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">text</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
    
    <span class="c1"># 获取文本的总长度和每一段的长度</span>
    <span class="n">total_length</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
    <span class="n">segment_length</span> <span class="o">=</span> <span class="n">total_length</span> <span class="o">//</span> <span class="n">num_segments</span>
    
    <span class="c1"># 将文本分割成指定数量的段落</span>
    <span class="n">segments</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_segments</span><span class="p">):</span>
        <span class="n">start</span> <span class="o">=</span> <span class="n">i</span> <span class="o">*</span> <span class="n">segment_length</span>
        <span class="n">end</span> <span class="o">=</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">segment_length</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="n">num_segments</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">end</span> <span class="o">=</span> <span class="n">total_length</span>
        <span class="n">segment</span> <span class="o">=</span> <span class="n">text</span><span class="p">[</span><span class="n">start</span><span class="p">:</span><span class="n">end</span><span class="p">]</span>
        <span class="n">segments</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">segment</span><span class="p">)</span>

    <span class="c1"># 将内容存储在数据框中</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">segments</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&#34;docs&#34;</span><span class="p">])</span>
    
    <span class="k">return</span> <span class="n">df</span>


<span class="c1">#分成20份</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">read_txt</span><span class="p">(</span><span class="n">file</span><span class="o">=</span><span class="s1">&#39;三体全集.txt&#39;</span><span class="p">,</span> <span class="n">num_segments</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">df</span>
</code></pre></div><p><img loading="lazy" src="img/01-df.png" alt=""  />
</p>
<br>
<h3 id="42-计算sbs">4.2 计算SBS</h3>
<p>语义品牌评分SBS已经封装到  <em><strong>cntext2.1.1</strong></em> 中， 文末有 <em><strong>cntext-2.1.1-py3-none-any.whl</strong></em> 获取方式 。</p>
<br>
<h4 id="421-安装cntext211">4.2.1 安装cntext2.1.1</h4>
<p>将 cntext-2.1.1-py3-none-any.whl 放置于桌面，打开 cmd (苹果电脑打开terminal)， 输入 cd desktop</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">cd desktop
</code></pre></div><br>
<p>之后在 <em><strong>cmd</strong></em>  (苹果电脑打开terminal) 中使用 <em><strong>pip3</strong></em> 安装</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">pip3 install distinctiveness
pip3 install cntext-2.1.1-py3-none-any.whl
</code></pre></div><p><br><br></p>
<h4 id="422--开始计算">4.2.2  开始计算</h4>
<p><em><strong>2.7M</strong></em> 的三体小说文本，全部运行下来大概 10-20min ，可见SBS计算非常慢， 所以为了省时间，我们先以三体小说第一份（等分20份中的第一份）做个小实验。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>

<span class="n">brands</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;汪淼&#39;</span><span class="p">,</span> <span class="s1">&#39;史强&#39;</span><span class="p">,</span> <span class="s1">&#39;罗辑&#39;</span><span class="p">,</span> <span class="s1">&#39;叶文洁&#39;</span><span class="p">,</span> <span class="s1">&#39;伊文斯&#39;</span><span class="p">]</span>

<span class="c1">#小说第一份文本（等分20份中的第一份）</span>
<span class="n">text</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;docs&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="c1">#如果不用三体， 只想分析某个txt，以data.txt为例</span>
<span class="c1">#text = open(&#39;data.txt&#39;).read()</span>

<span class="n">sbs_df0</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">semantic_brand_score</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="n">text</span><span class="p">,</span> 
                               <span class="n">brands</span><span class="o">=</span><span class="n">brands</span><span class="p">,</span> 
                               <span class="n">lang</span><span class="o">=</span><span class="s1">&#39;chinese&#39;</span><span class="p">)</span>
<span class="n">sbs_df0</span><span class="p">[</span><span class="s1">&#39;doc_idx&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">sbs_df0</span>
</code></pre></div><p><img loading="lazy" src="img/02-df.png" alt=""  />
</p>
<p><br> 运行没出现问题， 现在我们对整个小说进行实验，计算五个角色的 SBS 随时间变化。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="o">%%</span><span class="n">time</span>  <span class="c1">#记录时间</span>

<span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>

<span class="n">brands</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;汪淼&#39;</span><span class="p">,</span> <span class="s1">&#39;史强&#39;</span><span class="p">,</span> <span class="s1">&#39;罗辑&#39;</span><span class="p">,</span> <span class="s1">&#39;叶文洁&#39;</span><span class="p">,</span> <span class="s1">&#39;伊文斯&#39;</span><span class="p">]</span>
<span class="n">sbs_dfs</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">text</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;docs&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span>
    <span class="n">sbs_df</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">semantic_brand_score</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="n">text</span><span class="p">,</span> 
                              <span class="n">brands</span><span class="o">=</span><span class="n">brands</span><span class="p">,</span> 
                              <span class="n">lang</span><span class="o">=</span><span class="s1">&#39;chinese&#39;</span><span class="p">)</span>
    <span class="n">sbs_df</span><span class="p">[</span><span class="s1">&#39;doc_idx&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">idx</span>
    <span class="n">sbs_dfs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">sbs_df</span><span class="p">)</span>
    
<span class="n">SBS_DFs</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">sbs_dfs</span><span class="p">)</span>
<span class="n">SBS_DFs</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">0
WARNING: Loops will be ignored.
1
WARNING: Loops will be ignored.
2
WARNING: Loops will be ignored.
3
WARNING: Loops will be ignored.
4
WARNING: Loops will be ignored.
5
WARNING: Loops will be ignored.
6
WARNING: Loops will be ignored.
7
WARNING: Loops will be ignored.
8
WARNING: Loops will be ignored.
9
WARNING: Loops will be ignored.
10
WARNING: Loops will be ignored.
11
WARNING: Loops will be ignored.
12
WARNING: Loops will be ignored.
13
WARNING: Loops will be ignored.
14
WARNING: Loops will be ignored.
15
WARNING: Loops will be ignored.
16
WARNING: Loops will be ignored.
17
WARNING: Loops will be ignored.
18
WARNING: Loops will be ignored.
19
WARNING: Loops will be ignored.

CPU times: user 10min 9s, sys: 8.53 s, total: 10min 17s
Wall time: 10min 19s
</code></pre></div><p><img loading="lazy" src="img/03-df.png" alt=""  />
</p>
<br>
<h3 id="43-可视化sbs">4.3 可视化SBS</h3>
<p>可视化三体小说五个角色重要性（语义品牌评分， SBS）随时间 (文本字符位置) 变化趋势</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">SBS_DFs</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">SBS_DFs</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;index&#39;</span><span class="p">:</span> <span class="s1">&#39;Brand&#39;</span><span class="p">},</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">SBS_DFs</span>
</code></pre></div><p><img loading="lazy" src="img/04-df.png" alt=""  />

<br></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">matplotlib</span>
<span class="kn">import</span> <span class="nn">matplotlib_inline</span>
<span class="n">matplotlib_inline</span><span class="o">.</span><span class="n">backend_inline</span><span class="o">.</span><span class="n">set_matplotlib_formats</span><span class="p">(</span><span class="s1">&#39;png&#39;</span><span class="p">,</span> <span class="s1">&#39;svg&#39;</span><span class="p">)</span>
<span class="kn">import</span> <span class="nn">scienceplots</span>
<span class="kn">import</span> <span class="nn">platform</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">([</span><span class="s1">&#39;science&#39;</span><span class="p">,</span> <span class="s1">&#39;no-latex&#39;</span><span class="p">,</span> <span class="s1">&#39;cjk-sc-font&#39;</span><span class="p">])</span>
<span class="n">system</span> <span class="o">=</span> <span class="n">platform</span><span class="o">.</span><span class="n">system</span><span class="p">()</span>  <span class="c1"># 获取操作系统类型</span>

<span class="k">if</span> <span class="n">system</span> <span class="o">==</span> <span class="s1">&#39;Windows&#39;</span><span class="p">:</span>
    <span class="n">font</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;family&#39;</span><span class="p">:</span> <span class="s1">&#39;SimHei&#39;</span><span class="p">}</span>
<span class="k">elif</span> <span class="n">system</span> <span class="o">==</span> <span class="s1">&#39;Darwin&#39;</span><span class="p">:</span>
    <span class="n">font</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;family&#39;</span><span class="p">:</span> <span class="s1">&#39;Arial Unicode MS&#39;</span><span class="p">}</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">font</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;family&#39;</span><span class="p">:</span> <span class="s1">&#39;sans-serif&#39;</span><span class="p">}</span>
<span class="n">matplotlib</span><span class="o">.</span><span class="n">rc</span><span class="p">(</span><span class="s1">&#39;font&#39;</span><span class="p">,</span> <span class="o">**</span><span class="n">font</span><span class="p">)</span>  <span class="c1"># 设置全局字体</span>
    
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>


<span class="k">for</span> <span class="n">brand</span><span class="p">,</span> <span class="n">brand_df</span> <span class="ow">in</span> <span class="n">SBS_DFs</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;Brand&#39;</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">brand_df</span><span class="o">.</span><span class="n">doc_idx</span><span class="p">,</span> <span class="n">brand_df</span><span class="o">.</span><span class="n">SBS</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">brand</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">brand_df</span><span class="o">.</span><span class="n">doc_idx</span><span class="p">,</span> <span class="n">brand_df</span><span class="o">.</span><span class="n">SBS</span><span class="p">)</span>
    
    
    
    
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;三体人物角色的语义品牌评分(semantic brand score)趋势&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;小说字符位置(小说等分为20份)&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">13</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Semantic Brand Score&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper right&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>    
</code></pre></div><p><img loading="lazy" src="img/plot.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="五-获取资源">五、 获取资源</h2>
<p>内容整理不易， 如果对本文感兴趣</p>
<ul>
<li><em><strong>免费</strong></em>   获取本文代码&amp;实验数据  链接: <a href="https://pan.baidu.com/s/1ut8bKDxd5PGL_dm_yXTzcA?pwd=tr3t">https://pan.baidu.com/s/1ut8bKDxd5PGL_dm_yXTzcA?pwd=tr3t</a> 提取码: tr3t</li>
<li><em><strong>100元</strong></em>   <em><strong>cntext-2.1.1-py3-none-any.whl</strong></em>  ，可加微信 <em><strong>372335839</strong></em>， 备注「姓名-学校-专业」</li>
</ul>
<p><br><br></p>
<h2 id="相关资料">相关资料</h2>
<p>Colladon, Andrea Fronzetti. &ldquo;<em><strong>The semantic brand score</strong></em>.&rdquo; <em>Journal of Business Research</em> 88 (2018): 150-160.</p>
<p>SBS相关文章列表  <a href="https://semanticbrandscore.com/sbsarticles.html">https://semanticbrandscore.com/sbsarticles.html</a></p>
<p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>数据集 | 众筹金融投资平台kiva借贷数据</title>
      <link>https://textdata.cn/blog/2024-04-10-kiva-crowdfunding/</link>
      <pubDate>Wed, 10 Apr 2024 00:00:00 +0000</pubDate>
      
      <guid>/blog/2024-04-10-kiva-crowdfunding/</guid>
      <description>众筹</description>
      <content:encoded><![CDATA[<h2 id="一kiva简介">一、Kiva简介</h2>
<p>Kiva.org 是一个成立于 2005 年的国际非营利亲社会金融投资平台，其主要工作是通过众筹贷款，并以极低的利息来发放给那些需要的人们， 以助其购买生活必需品，或是找到一份能维持生计的工作。具体来说，这一类 <strong>亲社会</strong> 金融投资平台在世界各地寻找合作伙伴，例如当地的享有盛誉的非营利组织，来筛选当地对于低息贷款有需要或生活上遭受苦难的人，并收集其资料， 然后向平台发出这些资料以请求帮助。而平台则通过众筹的方式为这些项目筹集贷款资金，投资者则可以以个人或团队的形式进行投资。</p>
<p><br><br></p>
<h2 id="二研究主题">二、研究主题</h2>
<ul>
<li>亲社会行为心理（Pro-Social Behaviorial Psychology)</li>
<li>社会公益 ML 应用（Social Good ML Applications ）</li>
<li>公平性研究（Fairness Research）</li>
<li>社会影响评估（Social Impact Assessments）</li>
</ul>
<p>部分参考文献</p>
<blockquote>
<p>Defazio, Daniela, Chiara Franzoni, and Cristina Rossi-Lamastra. &ldquo;How pro-social framing affects the success of crowdfunding projects: The role of emphasis and information crowdedness.&rdquo; <em>Journal of Business Ethics</em> 171 (2021): 357-378.</p>
</blockquote>
<p><br><br></p>
<h2 id="三获取数据">三、获取数据</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">网站: Kiva Tools

网址: http://kivatools.com/downloads

项目数(截止2024.4.10): 2187819

介绍: Kiva Tools 是一个帮助Kiva贷方更好地了解小额信贷和 Kiva 运营的网站。 Kiva 目前在多个国家开展业务，并生成大量数据。查看这些数据以更好地了解地理和经济是非常有教育意义的。注意：Kiva Tools不隶属于 Kiva，也不受 Kiva 认可。
</code></pre></div><p><img loading="lazy" src="img/kivatools.png" alt=""  />
</p>
<p><br>2024.4.10 打开 <a href="http://kivatools.com/downloads">http://kivatools.com/downloads</a> ，点击 <em><strong>All loans</strong></em> 对应的数据，进行下载，最终得到 875M 的 csv 文件。</p>
<p><br><br></p>
<h2 id="四查看数据">四、查看数据</h2>
<h3 id="41-导入数据">4.1 导入数据</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;all_loans.csv&#39;</span><span class="p">)</span>
<span class="n">df</span>
</code></pre></div><p><img loading="lazy" src="img/df.png" alt=""  />
</p>
 <br>
<h3 id="42-所含字段">4.2 所含字段</h3>
<p>所含字段包含</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">col</span><span class="p">)</span>
</code></pre></div><p>字段详情</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"> - LOAN_ID:    贷款ID
 - LOAN_NAME:   Kiva贷方(出借人)姓名
 - FUNDED_AMOUNT:  Kiva贷方(出借人)已购买的贷款金额
 - LOAN_AMOUNT: 贷款额度
 - STATUS:   贷款状态包括违约、还款和已付级别，请参阅 http://build.kiva.org/docs/data/loans 了解每个级别的含义
 - IMAGE_ID: 图片ID
 - VIDEO_ID: 视频ID
 - ACTIVITY_NAME: 活动
 - SECTOR_NAME: 部门
 - LOAN_USE: 借款用途
 - COUNTRY_CODE: 国家代码
 - COUNTRY_NAME: 国家名称
 - TOWN_NAME: 城镇名称
 - CURRENCY_POLICY: 货币政策
 - CURRENCY_EXCHANGE_COVERAGE_RATE: 货币兑换
 - CURRENCY: 货币类型
 - PARTNER_ID: 当地贷款机构的现场合作伙伴 ID，请参阅http://api.kivaws.org/v1/partners.json
 - POSTED_TIME: 项目发布时间
 - PLANNED_EXPIRATION_TIME: 项目截止时间
 - DISBURSE_TIME: 发放给借款人的时间;  请注意，在 Kiva 上发布贷款之前，这笔钱可能会支付给借款人。
 - RAISED_TIME:   
 - LENDER_TERM:   借款人条款
 - NUM_LENDERS_TOTAL: 借款人数量
 - NUM_JOURNAL_ENTRIES: 借款人的日记账分录数量（Kiva 网站上的更新）。Number of journal entries (updates on the Kiva website) by borrower.
 - NUM_BULK_ENTRIES:
 - TAGS: 标签
 - BORROWER_NAMES:  借款人姓名
 - BORROWER_GENDERS: 借款人性别（有可能会存在多个借款人，所以数据类型为字符串或列表）
 - BORROWER_PICTURED:  借款人是否提供了图片
 - REPAYMENT_INTERVAL:  还款间隔
 - DISTRIBUTION_MODEL: 分销模式
</code></pre></div> <br>
<h3 id="43-行业">4.3 行业</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">matplotlib</span>
<span class="kn">import</span> <span class="nn">matplotlib_inline</span>
<span class="n">matplotlib_inline</span><span class="o">.</span><span class="n">backend_inline</span><span class="o">.</span><span class="n">set_matplotlib_formats</span><span class="p">(</span><span class="s1">&#39;png&#39;</span><span class="p">,</span> <span class="s1">&#39;svg&#39;</span><span class="p">)</span>
<span class="kn">import</span> <span class="nn">scienceplots</span>
<span class="kn">import</span> <span class="nn">platform</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">([</span><span class="s1">&#39;science&#39;</span><span class="p">,</span> <span class="s1">&#39;no-latex&#39;</span><span class="p">,</span> <span class="s1">&#39;cjk-sc-font&#39;</span><span class="p">])</span>
<span class="n">system</span> <span class="o">=</span> <span class="n">platform</span><span class="o">.</span><span class="n">system</span><span class="p">()</span>  <span class="c1"># 获取操作系统类型</span>

<span class="k">if</span> <span class="n">system</span> <span class="o">==</span> <span class="s1">&#39;Windows&#39;</span><span class="p">:</span>
    <span class="n">font</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;family&#39;</span><span class="p">:</span> <span class="s1">&#39;SimHei&#39;</span><span class="p">}</span>
<span class="k">elif</span> <span class="n">system</span> <span class="o">==</span> <span class="s1">&#39;Darwin&#39;</span><span class="p">:</span>
    <span class="n">font</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;family&#39;</span><span class="p">:</span> <span class="s1">&#39;Arial Unicode MS&#39;</span><span class="p">}</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">font</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;family&#39;</span><span class="p">:</span> <span class="s1">&#39;sans-serif&#39;</span><span class="p">}</span>
<span class="n">matplotlib</span><span class="o">.</span><span class="n">rc</span><span class="p">(</span><span class="s1">&#39;font&#39;</span><span class="p">,</span> <span class="o">**</span><span class="n">font</span><span class="p">)</span>  <span class="c1"># 设置全局字体</span>


<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;SECTOR_NAME&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s1">&#39;pie&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Kiva项目所属行业部门分布&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/pie.png" alt=""  />
</p>
<br>
<h3 id="44-国家项目数量">4.4 国家项目数量</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>

<span class="n">props</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;COUNTRY_NAME&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">props_</span> <span class="o">=</span> <span class="n">props</span><span class="p">[</span><span class="n">props</span><span class="o">&gt;=</span><span class="mf">0.01</span><span class="p">]</span>
<span class="n">props_</span><span class="p">[</span><span class="s1">&#39;Others&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">props</span><span class="p">[</span><span class="n">props</span><span class="o">&lt;</span><span class="mf">0.01</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

<span class="n">props_</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s1">&#39;pie&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;国家Kiva项目数量分布&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/pie2.png" alt=""  />
</p>
<p>Kiva 向菲律宾提供的贷款数量较多，按数量(递减)依次是是肯尼亚、柬埔寨、秘鲁、萨瓦尔多、乌干达等。</p>
<p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>数据集(付费) | 372w政府采购合同公告明细数据（2024.03）</title>
      <link>https://textdata.cn/blog/2023-09-03-government-procurement-contract-data/</link>
      <pubDate>Wed, 10 Apr 2024 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-09-03-government-procurement-contract-data/</guid>
      <description>&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/01-cover.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;h2 id=&#34;一数据集简介&#34;&gt;一、数据集简介&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;- 数据来源: 中国政府采购网（www.ccgp.gov.cn）
- 记录数量: 3724395
- 发布时间: 1996-06-05 ~ 2024-03-07, 但主要是2015之后


数据集 100 元，购买请加微信 372335839， 备注 【姓名-学校-专业】
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;span style=&#34;font-size: 18px;color: green;&#34;&gt;1. 付费数据集，100元；加微信 372335839， 备注「姓名-学校-专业」。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span style=&#34;font-size: 18px;color: green;&#34;&gt;2. 数据是虚拟产品，一经售出，不再退还！&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span style=&#34;font-size: 18px;color: green;&#34;&gt;3. 请仔细阅读推文内容， 确认无误再加微信详谈购买事宜 &lt;/span&gt;&lt;/p&gt;
&lt;br&gt;
&lt;h2 id=&#34;二应用&#34;&gt;二、应用&lt;/h2&gt;
&lt;p&gt;随着政府采购规模的逐步增加，中国政府采购网披露的信息越来越丰富。近年来一些学者也关 注到中国政府采购数据，但由于文本数据半结构化、高维、数据量大的特性，该数据在文本的整理、 关键变量识别与关键变量提取方面存在着不小的难度，目前而言使用该数据的研究并没有很多。&lt;/p&gt;
&lt;h3 id=&#34;21-创新&#34;&gt;2.1 创新&lt;/h3&gt;
&lt;p&gt;姜爱华和费堃桀（2021） 手工整理了 2015-2019 年的政府采购数据，利用公告中供应商的名称与上市公司全称进行匹配，最终得到了 13 004 个企业年度观测值，发现企业获 得政府采购订单能够显著促进企业创新。&lt;/p&gt;
&lt;p&gt;Beraja 等（2020）基 于 2013-2019 年政府采购合同，与中国人工智能企业进行名单匹配，得到 28 023 份政 府人脸识别采购合同样本，发现政府采购对人脸识别相关的人工智能专利的增长起到了推动作用。&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;22-政企关系&#34;&gt;2.2 政企关系&lt;/h3&gt;
&lt;p&gt;Fang 等（2022）利用中国政府采购网 2013-2020 年的采购公告与工商注册企业数据进行匹配，发现当本地官员处于激烈的政治竞争中时，本地政府将更少地向 竞争地区的企业进行采购，这造成了市场分割，影响了资源分配。&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;23-其他&#34;&gt;2.3 其他&lt;/h3&gt;
&lt;p&gt;政府采购影响企业履行企业社会责任（韩旭和武威，2021）、中国特色精准扶贫（武威等，2022）、经济 发展（武威和刘国平，2021）等。此外，还有研究单独使用政府采购数据测量经济生产生活。江鸿 泽和梁平汉（2022）基于政府采购公告整理了各地的公共视频监控系统使用情况，Liu 等（2022） 则抓取了 2013-2021 年政府采购公告，用以识别企业的政治联系。&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;二查看数据&#34;&gt;二、查看数据&lt;/h2&gt;
&lt;h3 id=&#34;21-读取数据&#34;&gt;2.1 读取数据&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pandas&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pd&lt;/span&gt;


&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read_csv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;政府采购公告1996-2024.3.csv.gz&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;compression&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;gzip&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;#gz文件可用bandizp或winrar解压得到csv&lt;/span&gt;
&lt;span class=&#34;c1&#34;&gt;#df = pd.read_csv(&amp;#39;政府采购公告1996-2024.3.csv&amp;#39;)&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;合同公告日期&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;to_datetime&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;合同公告日期&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;head&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/02-df.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;22-记录数&#34;&gt;2.2 记录数&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;数据集记录数: &amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;数据集记录数:  2883958
&lt;/code&gt;&lt;/pre&gt;
&lt;br&gt;
&lt;h3 id=&#34;23-字段&#34;&gt;2.3 字段&lt;/h3&gt;
&lt;p&gt;数据所含字段&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;col&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;columns&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
    &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;col&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;合同编号
合同名称
项目编号
项目名称
采购人(甲方)
采购人地址
采购人联系方式
供应商(乙方)
供应商地址
供应商联系方式
主要标的名称
规格型号或服务要求
主要标的数量
主要标的单价
合同金额(万元)
履约期限、地点等简要信息
采购方式
合同签订日期
合同公告日期
其他补充事宜
所属地域
所属行业
代理机构
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h3 id=&#34;24-公告日期&#34;&gt;2.4 公告日期&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;c1&#34;&gt;#数据集公告日期起止&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;合同公告日期&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;to_datetime&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;合同公告日期&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;

&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;发布时间&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;合同公告日期&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;min&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;())&lt;/span&gt;
&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;发布时间&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;合同公告日期&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;max&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;())&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;发布时间 1996-06-05 00:00:00
发布时间 2024-03-07 00:00:00
&lt;/code&gt;&lt;/pre&gt;
&lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;c1&#34;&gt;#政府采购合同公告数据，主要出现在2015年之后&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;合同公告日期&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;year&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;value_counts&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sort_index&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;合同公告日期
1996          1
2000          1
2002          2
2004          7
2008          5
2009          3
2010          2
2011         13
2012          3
2013          4
2014         24
2015      15543
2016      42195
2017      94193
2018     154922
2019     151181
2020     187874
2021     549078
2022    1060710
2023    1355749
2024     112885
Name: count, dtype: int64
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;梁平汉和郭宇辰(2023) 认为 &lt;strong&gt;2015年财政部相关采购信息发布文件出台之后采购公告上传率大幅上升至80%以上，因此采用2015年以后的中国政府采购网数据进行研究更为合适&lt;/strong&gt;。&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;24-甲乙方人数&#34;&gt;2.4 甲(乙)方人数&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;c1&#34;&gt;#甲方乙方数量&lt;/span&gt;
&lt;span class=&#34;c1&#34;&gt;#甲方乙方数量&lt;/span&gt;
&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;采购人(甲方)数: &amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;采购人&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;nunique&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;())&lt;/span&gt;
&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;供应商(乙方)数: &amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;供应商&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;nunique&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;())&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;采购人(甲方)数:  234082
供应商(乙方)数:  499943
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;三实验代码&#34;&gt;三、实验代码&lt;/h2&gt;
&lt;h3 id=&#34;31-是否含某类词&#34;&gt;3.1 是否含某(类)词&lt;/h3&gt;
&lt;p&gt;根据公告中是否出现某(类)词，可以提起一些指标。例如 Beraja 等（2020）基于 2013-2019 年政府采购合同，与中国人工智能企业进行名单匹配，得到 28 023 份政府人脸识别采购合同样本。 本文仅简单示范， 以 &lt;em&gt;&lt;strong&gt;人工智能&lt;/strong&gt;&lt;/em&gt; 相关词为例&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;合同名称&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fillna&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;str&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;contains&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;人工智能|自然语言处理|自动驾驶|AI|ai&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;0          False
1          False
2          False
3          False
4          False
           ...  
3724390    False
3724391    False
3724392    False
3724393    False
3724394    False
Name: 合同名称, Length: 3724395, dtype: bool
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;c1&#34;&gt;#AI相关公告的数量&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;合同名称&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fillna&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;str&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;contains&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;人工智能|自然语言处理|自动驾驶|AI|ai&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sum&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;1323
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;c1&#34;&gt;#显示匹配到的与 AI 有关的【合同名称】&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;合同名称&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fillna&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;str&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;contains&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;人工智能|自然语言处理|自动驾驶|AI|ai&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)][&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;合同名称&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;1129                                     贵州大学人工智能研究院建设项目采购合同
4935            龙岩初级中学人工智能创客实验室设备货物类采购项目合同\n （macrodatas.cn）
12231                       中国医学科学院系统医学研究院人工智能高性能计算设备采购合同协议书
13171      双高基于AIoT轨道交通智慧运维环境信号检测分析设备购置(二次)\n\n微信公众号“马克 数据网”
16921                           广州国际生物岛自动驾驶新能源环卫作业创新试点服务采购项目
                                 ...                        
3708596               榆林市教育技术中心人工智能助推教师队伍建设-教师发展智慧管理平台建设项目合同
3708922        邢台市信都区“人工智能公共技术服务平台”项目一标段数字教育、数字文旅采购合同\n\n （）
3709875         吴忠市第三中学南湖校区AI课堂教学行为分析评测系统及智慧教室设备采购项目系统集成服务合同
3712051                               人工智能与机器人领域创新成果产业化成熟度评价
3724277        民乐县现代农业投资有限责任公司民乐县人工智能一二三产业融合功能区食用菌菌棒生产项目  （）
Name: 合同名称, Length: 1323, dtype: object
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h3 id=&#34;32-构建省份字段&#34;&gt;3.2 构建省份字段&lt;/h3&gt;
&lt;p&gt;数据集中有  &lt;em&gt;&lt;strong&gt;采购人地址&lt;/strong&gt;&lt;/em&gt;、&lt;em&gt;&lt;strong&gt;采购人(甲方)&lt;/strong&gt;&lt;/em&gt; 两个地址字段，我们以 &lt;em&gt;&lt;strong&gt;采购人(甲方)&lt;/strong&gt;&lt;/em&gt; 为例，构建 &lt;em&gt;&lt;strong&gt;采购人省份&lt;/strong&gt;&lt;/em&gt; 字段。 注意: 经过测试，使用cpca库提取省份信息， 两种方式提取省份信息缺失率依次是 24.8%、 7%， 因此我们决定采用 &lt;em&gt;&lt;strong&gt;采购人(甲方)&lt;/strong&gt;&lt;/em&gt;  来提取省份。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;cpca&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;provs_df&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;cpca&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;transform&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;采购人(甲方)&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;采购人省份&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;cpca&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;transform&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;采购人(甲方)&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;省&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;采购人省份&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;采购人省份&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fillna&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;apply&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;lambda&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;k&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;re&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sub&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;自治区|特别行政区&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;k&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;head&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/03-df.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;33-按省分组查看记录量&#34;&gt;3.3 按省分组查看记录量&lt;/h3&gt;
&lt;p&gt;假设 &lt;em&gt;&lt;strong&gt;采购人省份&lt;/strong&gt;&lt;/em&gt; 构建的准确的话， 就可以分组查看每个省的记录量。   df.groupby(&amp;lsquo;采购人省份&amp;rsquo;)&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;prov&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;prov_df&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;groupby&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;采购人省份&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
    &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;prov&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;prov_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt; 267312  (未知省份，cpca缺失字段，占比大概7%)
上海市 29493
云南省 49789
内蒙古 480459
北京市 71869
台湾省 93
吉林省 14219
四川省 155028
天津市 10734
宁夏回族 76783
安徽省 44133
山东省 14634
山西省 5784
广东省 1349039
广西壮族 12534
新疆维吾尔 8000
江苏省 28655
江西省 8949
河北省 203761
河南省 8159
浙江省 12158
海南省 38603
湖北省 6156
湖南省 11300
甘肃省 289772
福建省 97527
西藏 2558
贵州省 2599
辽宁省 34547
重庆市 58673
陕西省 55478
青海省 22441
香港 80
黑龙江省 253076
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;plt&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;matplotlib&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;scienceplots&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;platform&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pandas&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pd&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;matplotlib_inline&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;matplotlib_inline&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;backend_inline&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;set_matplotlib_formats&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;png&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;svg&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;jieba&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;warnings&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;warnings&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;filterwarnings&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;ignore&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;plt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;style&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;use&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;([&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;science&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;no-latex&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;cjk-sc-font&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;system&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;platform&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;system&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;# 获取操作系统类型&lt;/span&gt;
&lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;system&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;Windows&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;font&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;family&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;SimHei&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;span class=&#34;k&#34;&gt;elif&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;system&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;Darwin&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;font&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;family&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;Arial Unicode MS&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;span class=&#34;k&#34;&gt;else&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;font&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;family&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;sans-serif&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;matplotlib&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;rc&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;font&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;font&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;# 设置全局字体&lt;/span&gt;



&lt;span class=&#34;n&#34;&gt;prov_volumes&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt;
&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;prov&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;prov_df&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;groupby&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;采购人省份&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;prov_volumes&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;append&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;({&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;prov&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;prov&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;volume&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;prov_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)})&lt;/span&gt;
    
&lt;span class=&#34;n&#34;&gt;prov_volumes_df&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;DataFrame&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;prov_volumes&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;prov_volumes_df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;set_index&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;prov&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sort_values&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;volume&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ascending&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;False&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;plot&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;bar&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;figsize&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;plt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;title&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;政府采购数量(采购人按省)&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;size&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;15&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;plt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;xticks&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;size&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;rotation&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;45&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;plt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;xlabel&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;省份&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;size&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;13&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;plt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ylabel&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;采购公告数量&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;size&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;13&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;plt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;show&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/plot.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;采购按省， 最多的几个省份依次是广东、内蒙、甘肃、黑龙江等。  甘肃和黑龙江之间有个空白， 这是因为根据采购人(甲方)使用cpca提取省份信息时，有7%记录是缺失的。&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;三相关研究&#34;&gt;三、相关研究&lt;/h2&gt;
&lt;p&gt;相关研究近期文献&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;[1]周亚虹,蒲余路,陈诗一等.政府扶持与新型产业发展——以新能源为例[J].经济研究,2015,50(06):147-161.
[2]武威,刘国平.政府采购与经济发展：转型效应与协同效应——基于产业结构升级视角[J].财政研究,2021(08):77-90.
[3]孙薇,叶初升.政府采购何以牵动企业创新——兼论需求侧政策“拉力”与供给侧政策“推力”的协同[J].中国工业经济,2023(01):95-113.
[4]姜爱华,费堃桀,张鑫娜.政府采购、营商环境与企业创新——基于A股上市公司的经验证据[J].中央财经大学学报,2022(09):3-15.
[5]梁平汉, 郭宇辰. 中国政府采购公告数据的使用和潜在问题[J]. 产业经济评论, 2023, (01): 68-80.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;四获取数据&#34;&gt;四、获取数据&lt;/h2&gt;
&lt;p&gt;&lt;span style=&#34;font-size: 18px;color: green;&#34;&gt;1. 付费数据集，100元；加微信 372335839， 备注「姓名-学校-专业」。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span style=&#34;font-size: 18px;color: green;&#34;&gt;2. 数据是虚拟产品，一经售出，不再退还！&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span style=&#34;font-size: 18px;color: green;&#34;&gt;3. 请仔细阅读推文内容， 确认无误再加微信详谈购买事宜 &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;广而告之&#34;&gt;广而告之&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/call_for_paper/&#34;&gt;长期征稿&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/we_need_you/&#34;&gt;长期招募小伙伴&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/management_python_course/&#34;&gt;付费视频课 | Python实证指标构建与文本分析&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
      <content:encoded><![CDATA[<p><img loading="lazy" src="img/01-cover.png" alt=""  />
</p>
<h2 id="一数据集简介">一、数据集简介</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">- 数据来源: 中国政府采购网（www.ccgp.gov.cn）
- 记录数量: 3724395
- 发布时间: 1996-06-05 ~ 2024-03-07, 但主要是2015之后


数据集 100 元，购买请加微信 372335839， 备注 【姓名-学校-专业】
</code></pre></div><p><span style="font-size: 18px;color: green;">1. 付费数据集，100元；加微信 372335839， 备注「姓名-学校-专业」。</span></p>
<p><span style="font-size: 18px;color: green;">2. 数据是虚拟产品，一经售出，不再退还！</span></p>
<p><span style="font-size: 18px;color: green;">3. 请仔细阅读推文内容， 确认无误再加微信详谈购买事宜 </span></p>
<br>
<h2 id="二应用">二、应用</h2>
<p>随着政府采购规模的逐步增加，中国政府采购网披露的信息越来越丰富。近年来一些学者也关 注到中国政府采购数据，但由于文本数据半结构化、高维、数据量大的特性，该数据在文本的整理、 关键变量识别与关键变量提取方面存在着不小的难度，目前而言使用该数据的研究并没有很多。</p>
<h3 id="21-创新">2.1 创新</h3>
<p>姜爱华和费堃桀（2021） 手工整理了 2015-2019 年的政府采购数据，利用公告中供应商的名称与上市公司全称进行匹配，最终得到了 13 004 个企业年度观测值，发现企业获 得政府采购订单能够显著促进企业创新。</p>
<p>Beraja 等（2020）基 于 2013-2019 年政府采购合同，与中国人工智能企业进行名单匹配，得到 28 023 份政 府人脸识别采购合同样本，发现政府采购对人脸识别相关的人工智能专利的增长起到了推动作用。</p>
<br>
<h3 id="22-政企关系">2.2 政企关系</h3>
<p>Fang 等（2022）利用中国政府采购网 2013-2020 年的采购公告与工商注册企业数据进行匹配，发现当本地官员处于激烈的政治竞争中时，本地政府将更少地向 竞争地区的企业进行采购，这造成了市场分割，影响了资源分配。</p>
<br>
<h3 id="23-其他">2.3 其他</h3>
<p>政府采购影响企业履行企业社会责任（韩旭和武威，2021）、中国特色精准扶贫（武威等，2022）、经济 发展（武威和刘国平，2021）等。此外，还有研究单独使用政府采购数据测量经济生产生活。江鸿 泽和梁平汉（2022）基于政府采购公告整理了各地的公共视频监控系统使用情况，Liu 等（2022） 则抓取了 2013-2021 年政府采购公告，用以识别企业的政治联系。</p>
<p><br><br></p>
<h2 id="二查看数据">二、查看数据</h2>
<h3 id="21-读取数据">2.1 读取数据</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>


<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;政府采购公告1996-2024.3.csv.gz&#39;</span><span class="p">,</span> <span class="n">compression</span><span class="o">=</span><span class="s1">&#39;gzip&#39;</span><span class="p">)</span>

<span class="c1">#gz文件可用bandizp或winrar解压得到csv</span>
<span class="c1">#df = pd.read_csv(&#39;政府采购公告1996-2024.3.csv&#39;)</span>

<span class="n">df</span><span class="p">[</span><span class="s1">&#39;合同公告日期&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;合同公告日期&#39;</span><span class="p">])</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div><p><img loading="lazy" src="img/02-df.png" alt=""  />
</p>
<br>
<h3 id="22-记录数">2.2 记录数</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;数据集记录数: &#39;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">))</span>
</code></pre></div><pre><code>数据集记录数:  2883958
</code></pre>
<br>
<h3 id="23-字段">2.3 字段</h3>
<p>数据所含字段</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">col</span><span class="p">)</span>
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">合同编号
合同名称
项目编号
项目名称
采购人(甲方)
采购人地址
采购人联系方式
供应商(乙方)
供应商地址
供应商联系方式
主要标的名称
规格型号或服务要求
主要标的数量
主要标的单价
合同金额(万元)
履约期限、地点等简要信息
采购方式
合同签订日期
合同公告日期
其他补充事宜
所属地域
所属行业
代理机构
</code></pre></div><br>
<h3 id="24-公告日期">2.4 公告日期</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#数据集公告日期起止</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;合同公告日期&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;合同公告日期&#39;</span><span class="p">])</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;发布时间&#39;</span><span class="p">,</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;合同公告日期&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;发布时间&#39;</span><span class="p">,</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;合同公告日期&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>
</code></pre></div><pre><code>发布时间 1996-06-05 00:00:00
发布时间 2024-03-07 00:00:00
</code></pre>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#政府采购合同公告数据，主要出现在2015年之后</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;合同公告日期&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">dt</span><span class="o">.</span><span class="n">year</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span><span class="o">.</span><span class="n">sort_index</span><span class="p">()</span>
</code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">合同公告日期
1996          1
2000          1
2002          2
2004          7
2008          5
2009          3
2010          2
2011         13
2012          3
2013          4
2014         24
2015      15543
2016      42195
2017      94193
2018     154922
2019     151181
2020     187874
2021     549078
2022    1060710
2023    1355749
2024     112885
Name: count, dtype: int64
</code></pre></div><p>梁平汉和郭宇辰(2023) 认为 <strong>2015年财政部相关采购信息发布文件出台之后采购公告上传率大幅上升至80%以上，因此采用2015年以后的中国政府采购网数据进行研究更为合适</strong>。</p>
<br>
<h3 id="24-甲乙方人数">2.4 甲(乙)方人数</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#甲方乙方数量</span>
<span class="c1">#甲方乙方数量</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;采购人(甲方)数: &#39;</span><span class="p">,</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;采购人&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">nunique</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;供应商(乙方)数: &#39;</span><span class="p">,</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;供应商&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">nunique</span><span class="p">())</span>
</code></pre></div><pre><code>采购人(甲方)数:  234082
供应商(乙方)数:  499943
</code></pre>
<p><br><br></p>
<h2 id="三实验代码">三、实验代码</h2>
<h3 id="31-是否含某类词">3.1 是否含某(类)词</h3>
<p>根据公告中是否出现某(类)词，可以提起一些指标。例如 Beraja 等（2020）基于 2013-2019 年政府采购合同，与中国人工智能企业进行名单匹配，得到 28 023 份政府人脸识别采购合同样本。 本文仅简单示范， 以 <em><strong>人工智能</strong></em> 相关词为例</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df</span><span class="p">[</span><span class="s1">&#39;合同名称&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="s1">&#39;人工智能|自然语言处理|自动驾驶|AI|ai&#39;</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">0          False
1          False
2          False
3          False
4          False
           ...  
3724390    False
3724391    False
3724392    False
3724393    False
3724394    False
Name: 合同名称, Length: 3724395, dtype: bool
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#AI相关公告的数量</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;合同名称&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="s1">&#39;人工智能|自然语言处理|自动驾驶|AI|ai&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">1323
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#显示匹配到的与 AI 有关的【合同名称】</span>
<span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;合同名称&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="s1">&#39;人工智能|自然语言处理|自动驾驶|AI|ai&#39;</span><span class="p">)][</span><span class="s1">&#39;合同名称&#39;</span><span class="p">]</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">1129                                     贵州大学人工智能研究院建设项目采购合同
4935            龙岩初级中学人工智能创客实验室设备货物类采购项目合同\n （macrodatas.cn）
12231                       中国医学科学院系统医学研究院人工智能高性能计算设备采购合同协议书
13171      双高基于AIoT轨道交通智慧运维环境信号检测分析设备购置(二次)\n\n微信公众号“马克 数据网”
16921                           广州国际生物岛自动驾驶新能源环卫作业创新试点服务采购项目
                                 ...                        
3708596               榆林市教育技术中心人工智能助推教师队伍建设-教师发展智慧管理平台建设项目合同
3708922        邢台市信都区“人工智能公共技术服务平台”项目一标段数字教育、数字文旅采购合同\n\n （）
3709875         吴忠市第三中学南湖校区AI课堂教学行为分析评测系统及智慧教室设备采购项目系统集成服务合同
3712051                               人工智能与机器人领域创新成果产业化成熟度评价
3724277        民乐县现代农业投资有限责任公司民乐县人工智能一二三产业融合功能区食用菌菌棒生产项目  （）
Name: 合同名称, Length: 1323, dtype: object
</code></pre></div><br>
<h3 id="32-构建省份字段">3.2 构建省份字段</h3>
<p>数据集中有  <em><strong>采购人地址</strong></em>、<em><strong>采购人(甲方)</strong></em> 两个地址字段，我们以 <em><strong>采购人(甲方)</strong></em> 为例，构建 <em><strong>采购人省份</strong></em> 字段。 注意: 经过测试，使用cpca库提取省份信息， 两种方式提取省份信息缺失率依次是 24.8%、 7%， 因此我们决定采用 <em><strong>采购人(甲方)</strong></em>  来提取省份。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cpca</span>

<span class="n">provs_df</span> <span class="o">=</span> <span class="n">cpca</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;采购人(甲方)&#39;</span><span class="p">])</span>

<span class="n">df</span><span class="p">[</span><span class="s1">&#39;采购人省份&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">cpca</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;采购人(甲方)&#39;</span><span class="p">])[</span><span class="s1">&#39;省&#39;</span><span class="p">]</span>

<span class="n">df</span><span class="p">[</span><span class="s1">&#39;采购人省份&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;采购人省份&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">k</span><span class="p">:</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s1">&#39;自治区|特别行政区&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">k</span><span class="p">))</span>

<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</code></pre></div><p><img loading="lazy" src="img/03-df.png" alt=""  />
</p>
<br>
<h3 id="33-按省分组查看记录量">3.3 按省分组查看记录量</h3>
<p>假设 <em><strong>采购人省份</strong></em> 构建的准确的话， 就可以分组查看每个省的记录量。   df.groupby(&lsquo;采购人省份&rsquo;)</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="k">for</span> <span class="n">prov</span><span class="p">,</span> <span class="n">prov_df</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;采购人省份&#39;</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">prov</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">prov_df</span><span class="p">))</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"> 267312  (未知省份，cpca缺失字段，占比大概7%)
上海市 29493
云南省 49789
内蒙古 480459
北京市 71869
台湾省 93
吉林省 14219
四川省 155028
天津市 10734
宁夏回族 76783
安徽省 44133
山东省 14634
山西省 5784
广东省 1349039
广西壮族 12534
新疆维吾尔 8000
江苏省 28655
江西省 8949
河北省 203761
河南省 8159
浙江省 12158
海南省 38603
湖北省 6156
湖南省 11300
甘肃省 289772
福建省 97527
西藏 2558
贵州省 2599
辽宁省 34547
重庆市 58673
陕西省 55478
青海省 22441
香港 80
黑龙江省 253076
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">matplotlib</span>
<span class="kn">import</span> <span class="nn">scienceplots</span>
<span class="kn">import</span> <span class="nn">platform</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib_inline</span>
<span class="n">matplotlib_inline</span><span class="o">.</span><span class="n">backend_inline</span><span class="o">.</span><span class="n">set_matplotlib_formats</span><span class="p">(</span><span class="s1">&#39;png&#39;</span><span class="p">,</span> <span class="s1">&#39;svg&#39;</span><span class="p">)</span>
<span class="kn">import</span> <span class="nn">jieba</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">([</span><span class="s1">&#39;science&#39;</span><span class="p">,</span> <span class="s1">&#39;no-latex&#39;</span><span class="p">,</span> <span class="s1">&#39;cjk-sc-font&#39;</span><span class="p">])</span>
<span class="n">system</span> <span class="o">=</span> <span class="n">platform</span><span class="o">.</span><span class="n">system</span><span class="p">()</span>  <span class="c1"># 获取操作系统类型</span>
<span class="k">if</span> <span class="n">system</span> <span class="o">==</span> <span class="s1">&#39;Windows&#39;</span><span class="p">:</span>
    <span class="n">font</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;family&#39;</span><span class="p">:</span> <span class="s1">&#39;SimHei&#39;</span><span class="p">}</span>
<span class="k">elif</span> <span class="n">system</span> <span class="o">==</span> <span class="s1">&#39;Darwin&#39;</span><span class="p">:</span>
    <span class="n">font</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;family&#39;</span><span class="p">:</span> <span class="s1">&#39;Arial Unicode MS&#39;</span><span class="p">}</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">font</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;family&#39;</span><span class="p">:</span> <span class="s1">&#39;sans-serif&#39;</span><span class="p">}</span>
<span class="n">matplotlib</span><span class="o">.</span><span class="n">rc</span><span class="p">(</span><span class="s1">&#39;font&#39;</span><span class="p">,</span> <span class="o">**</span><span class="n">font</span><span class="p">)</span>  <span class="c1"># 设置全局字体</span>



<span class="n">prov_volumes</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">prov</span><span class="p">,</span> <span class="n">prov_df</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;采购人省份&#39;</span><span class="p">):</span>
    <span class="n">prov_volumes</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="s1">&#39;prov&#39;</span><span class="p">:</span> <span class="n">prov</span><span class="p">,</span> <span class="s1">&#39;volume&#39;</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">prov_df</span><span class="p">)})</span>
    
<span class="n">prov_volumes_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">prov_volumes</span><span class="p">)</span>
<span class="n">prov_volumes_df</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="s1">&#39;prov&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s1">&#39;volume&#39;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s1">&#39;bar&#39;</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;政府采购数量(采购人按省)&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">45</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;省份&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">13</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;采购公告数量&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">13</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/plot.png" alt=""  />
</p>
<p>采购按省， 最多的几个省份依次是广东、内蒙、甘肃、黑龙江等。  甘肃和黑龙江之间有个空白， 这是因为根据采购人(甲方)使用cpca提取省份信息时，有7%记录是缺失的。<br><br></p>
<h2 id="三相关研究">三、相关研究</h2>
<p>相关研究近期文献</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">[1]周亚虹,蒲余路,陈诗一等.政府扶持与新型产业发展——以新能源为例[J].经济研究,2015,50(06):147-161.
[2]武威,刘国平.政府采购与经济发展：转型效应与协同效应——基于产业结构升级视角[J].财政研究,2021(08):77-90.
[3]孙薇,叶初升.政府采购何以牵动企业创新——兼论需求侧政策“拉力”与供给侧政策“推力”的协同[J].中国工业经济,2023(01):95-113.
[4]姜爱华,费堃桀,张鑫娜.政府采购、营商环境与企业创新——基于A股上市公司的经验证据[J].中央财经大学学报,2022(09):3-15.
[5]梁平汉, 郭宇辰. 中国政府采购公告数据的使用和潜在问题[J]. 产业经济评论, 2023, (01): 68-80.
</code></pre></div><p><br><br></p>
<h2 id="四获取数据">四、获取数据</h2>
<p><span style="font-size: 18px;color: green;">1. 付费数据集，100元；加微信 372335839， 备注「姓名-学校-专业」。</span></p>
<p><span style="font-size: 18px;color: green;">2. 数据是虚拟产品，一经售出，不再退还！</span></p>
<p><span style="font-size: 18px;color: green;">3. 请仔细阅读推文内容， 确认无误再加微信详谈购买事宜 </span></p>
<p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>数据集 | 2010-2023年国家社会科学基金立项名单.xlsx</title>
      <link>https://textdata.cn/blog/2024-01-23-china-national-social-science-fund-projects-from-2010-to-2023/</link>
      <pubDate>Mon, 22 Jan 2024 00:00:00 +0000</pubDate>
      
      <guid>/blog/2024-01-23-china-national-social-science-fund-projects-from-2010-to-2023/</guid>
      <description>&lt;h2 id=&#34;一数据概况&#34;&gt;一、数据概况&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;数据集名称: 国家社会科学基金立项名单
格式: xlsx
年份:2010~2023
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;点击下载 &lt;a href=&#34;2010-2023%E5%B9%B4%E5%9B%BD%E5%AE%B6%E7%A4%BE%E4%BC%9A%E7%A7%91%E5%AD%A6%E5%9F%BA%E9%87%91%E7%AB%8B%E9%A1%B9%E5%90%8D%E5%8D%95.xlsx&#34;&gt;2010-2023年国家社会科学基金立项名单.xlsx&lt;/a&gt;&lt;/p&gt;
&lt;br&gt;
&lt;br&gt;
&lt;h2 id=&#34;二读取数据&#34;&gt;二、读取数据&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pandas&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pd&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read_excel&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;2010-2023年国家社会科学基金立项名单.xlsx&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;所在学科&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;所在学科&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fillna&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;head&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/01-df.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;所在学科&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;unique&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;array([&amp;#39;马列·科社&amp;#39;, &amp;#39;管理学&amp;#39;, &amp;#39;政治学&amp;#39;, &amp;#39;外国文学&amp;#39;, &amp;#39;人口学&amp;#39;, &amp;#39;图书馆、情报与文献学&amp;#39;, &amp;#39;新闻学与传播学&amp;#39;,
       &amp;#39;中国文学&amp;#39;, &amp;#39;世界历史&amp;#39;, &amp;#39;语言学&amp;#39;, &amp;#39;民族问题研究&amp;#39;, &amp;#39;哲学&amp;#39;, &amp;#39;理论经济&amp;#39;, &amp;#39;体育学&amp;#39;, &amp;#39;国际问题研究&amp;#39;,
       &amp;#39;中国历史&amp;#39;, &amp;#39;党史·党建&amp;#39;, &amp;#39;法学&amp;#39;, &amp;#39;应用经济&amp;#39;, &amp;#39;社会学&amp;#39;, &amp;#39;统计学&amp;#39;, &amp;#39;宗教学&amp;#39;, &amp;#39;&amp;#39;, &amp;#39;教育学&amp;#39;,
       &amp;#39;考古学&amp;#39;, &amp;#39;图书馆、情报与档案学&amp;#39;, &amp;#39;其他&amp;#39;, &amp;#39;图书情报&amp;#39;, &amp;#39;军事学&amp;#39;, &amp;#39;艺术学&amp;#39;, &amp;#39;党史•党建&amp;#39;, &amp;#39;马列•科社&amp;#39;,
       &amp;#39;新闻传播学&amp;#39;, &amp;#39;中国历史、&amp;#39;, &amp;#39;民族学&amp;#39;, &amp;#39;国际问题&amp;#39;, &amp;#39;法学、医学、公共卫生学&amp;#39;, &amp;#39;灾害学、社会学、管理学、系统科学&amp;#39;,
       &amp;#39;法学、医学、社会学&amp;#39;, &amp;#39;应用经济学 法学&amp;#39;, &amp;#39;宏观经济、计量经济、管理学等&amp;#39;, &amp;#39;智能技术、电子商务、人工智能、信&amp;#39;,
       &amp;#39;管理学、经济学、地理学&amp;#39;, &amp;#39;艺术学、人类学、计算机科学&amp;#39;, &amp;#39;文化人类学、非遗保护、考古学、影&amp;#39;,
       &amp;#39;文学艺术、文化人类学、计算机科学&amp;#39;, &amp;#39;计算机科学与技术、社会学、公共管&amp;#39;, &amp;#39;电气工程；产业经济学；管理学；热&amp;#39;,
       &amp;#39;城市规划学、计算机学、信息网络学&amp;#39;, &amp;#39;心理学、认知和行为科学、脑科学、&amp;#39;, &amp;#39;产业经济学、管理学、信息技术及应&amp;#39;,
       &amp;#39;法学、社会学、信息科学、计算机科&amp;#39;, &amp;#39;管理科学与工程、控制科学与工程、&amp;#39;, &amp;#39;智能技术、产业经济、经济学、管理&amp;#39;,
       &amp;#39;语言学、计算机科学、生态学、社会&amp;#39;, &amp;#39;理论经济学、应用经济学、法学、公&amp;#39;, &amp;#39;语言学、人类学、信息科学&amp;#39;,
       &amp;#39;宏观经济、计量经济、管理学、统计&amp;#39;, &amp;#39;管理学、 经济学 、环境科学、&amp;#39;, &amp;#39;语言学、计算机科学、统计学等&amp;#39;,
       &amp;#39;城乡规划学、管理学、地理学、经济&amp;#39;, &amp;#39;语言文学、心理学、教育学&amp;#39;, &amp;#39;人类学、社会心理学、认知神经科学&amp;#39;,
       &amp;#39;应用经济、管理学、资源环境科学、&amp;#39;, &amp;#39;电气工程、管理学、产业经济、能源&amp;#39;, &amp;#39;产业经济、生态学、系统科学、管理&amp;#39;, &amp;#39;马列科社&amp;#39;,
       &amp;#39;党史党建&amp;#39;, &amp;#39;综合研究&amp;#39;, &amp;#39;民族问题&amp;#39;, &amp;#39;图书·情报与文献&amp;#39;, &amp;#39;新闻学&amp;#39;, &amp;#39;跨学科&amp;#39;, &amp;#39;民族问题 研究&amp;#39;,
       &amp;#39;新闻与传播学&amp;#39;, &amp;#39;新闻学与 传播学&amp;#39;, &amp;#39;马列.科社&amp;#39;, &amp;#39;系列丛书&amp;#39;, &amp;#39;图书馆·情报与文献学&amp;#39;, &amp;#39;重点项目&amp;#39;,
       &amp;#39;一般项目&amp;#39;, &amp;#39;学术期刊&amp;#39;, &amp;#39;理论经济学&amp;#39;, &amp;#39;应用经济学&amp;#39;, &amp;#39;国际问题研\n究&amp;#39;, &amp;#39;新闻学与传\n播学&amp;#39;,
       &amp;#39;图书馆、情\n报与文献学&amp;#39;], dtype=object)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h2 id=&#34;三简单分析&#34;&gt;三、简单分析&lt;/h2&gt;
&lt;h3 id=&#34;31-可视化准备&#34;&gt;3.1 可视化准备&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;plt&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;matplotlib&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;matplotlib_inline&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;matplotlib_inline&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;backend_inline&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;set_matplotlib_formats&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;png&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;svg&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;scienceplots&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;platform&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;plt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;style&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;use&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;([&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;science&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;no-latex&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;cjk-sc-font&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;system&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;platform&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;system&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;# 获取操作系统类型&lt;/span&gt;

&lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;system&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;Windows&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;font&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;family&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;SimHei&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;span class=&#34;k&#34;&gt;elif&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;system&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;Darwin&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;font&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;family&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;Arial Unicode MS&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;span class=&#34;k&#34;&gt;else&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;font&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;family&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;sans-serif&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;matplotlib&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;rc&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;font&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;font&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;# 设置全局字体&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h3 id=&#34;32-立项数量&#34;&gt;3.2 立项数量&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;df[&amp;#39;批准年份&amp;#39;].value_counts(ascending=True).plot(kind=&amp;#39;bar&amp;#39;, figsize=(8, 4))
plt.xticks(rotation=0)
plt.ylabel(&amp;#39;立项数量&amp;#39;, rotation=0)
plt.title(&amp;#39;国社科立项数量(2010-2023)&amp;#39;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/02-plot.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;33-经管学科&#34;&gt;3.3 经管学科&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;management_economic_displines&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;d&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;d&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;所在学科&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;unique&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;经济&amp;#39;&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;d&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;or&lt;/span&gt;  &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;管理&amp;#39;&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;d&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)]&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;management_economic_displines&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;[&amp;#39;管理学&amp;#39;,
 &amp;#39;理论经济&amp;#39;,
 &amp;#39;应用经济&amp;#39;,
 &amp;#39;灾害学、社会学、管理学、系统科学&amp;#39;,
 &amp;#39;应用经济学 法学&amp;#39;,
 &amp;#39;宏观经济、计量经济、管理学等&amp;#39;,
 &amp;#39;管理学、经济学、地理学&amp;#39;,
 &amp;#39;电气工程；产业经济学；管理学；热&amp;#39;,
 &amp;#39;产业经济学、管理学、信息技术及应&amp;#39;,
 &amp;#39;管理科学与工程、控制科学与工程、&amp;#39;,
 &amp;#39;智能技术、产业经济、经济学、管理&amp;#39;,
 &amp;#39;理论经济学、应用经济学、法学、公&amp;#39;,
 &amp;#39;宏观经济、计量经济、管理学、统计&amp;#39;,
 &amp;#39;管理学、 经济学 、环境科学、&amp;#39;,
 &amp;#39;城乡规划学、管理学、地理学、经济&amp;#39;,
 &amp;#39;应用经济、管理学、资源环境科学、&amp;#39;,
 &amp;#39;电气工程、管理学、产业经济、能源&amp;#39;,
 &amp;#39;产业经济、生态学、系统科学、管理&amp;#39;,
 &amp;#39;理论经济学&amp;#39;,
 &amp;#39;应用经济学&amp;#39;]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h3 id=&#34;34-经管立项&#34;&gt;3.4 经管立项&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;eco_man_df&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;所在学科&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;isin&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;management_economic_displines&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)]&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;eco_man_df&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/03-df.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;p&gt;经管类国社科立项数量占比&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;所在学科&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;isin&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;management_economic_displines&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sum&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;/&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;0.18713464870187335
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h3 id=&#34;35-经管立项数量&#34;&gt;3.5 经管立项数量&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;eco_man_with_ds_df&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;eco_man_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;eco_man_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;课题名称&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fillna&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;str&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;contains&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;大数据|数据挖掘|机器学习|人工智能|AIGC&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)]&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;eco_man_with_ds_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;批准年份&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;value_counts&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ascending&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;plot&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;bar&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;figsize&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;8&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;plt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;xticks&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;rotation&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;plt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ylabel&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;立项数量&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;rotation&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;plt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;title&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;国社科基金中结合数据科学的经济、管理类立项数量(2010-2023)&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/05-plot.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;36-经管立项占比&#34;&gt;3.6 经管立项占比&lt;/h3&gt;
&lt;p&gt;按年度查看， 国社科中经管类立项占比&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;year_ratios&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt;
&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;year&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;year_df&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;groupby&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;批准年份&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;ratio&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;year_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;所在学科&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;isin&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;management_economic_displines&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sum&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;/&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;year_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;year_ratios&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;append&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;((&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;year&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ratio&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
    
&lt;span class=&#34;n&#34;&gt;year_ratio_df&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;DataFrame&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;year_ratios&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;year_ratio_df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;columns&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;year&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;ratio&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;year_ratio_df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;set_index&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;year&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;inplace&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;year_ratio_df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;plot&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;bar&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;figsize&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;8&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;plt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ylabel&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;立项占比&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;rotation&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;plt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;title&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;国社科基金中经济、管理类立项占比(2010-2023)&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/04-plot.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;广而告之&#34;&gt;广而告之&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/call_for_paper/&#34;&gt;长期征稿&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/we_need_you/&#34;&gt;长期招募小伙伴&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/management_python_course/&#34;&gt;付费视频课 | Python实证指标构建与文本分析&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
      <content:encoded><![CDATA[<h2 id="一数据概况">一、数据概况</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">数据集名称: 国家社会科学基金立项名单
格式: xlsx
年份:2010~2023
</code></pre></div><p>点击下载 <a href="2010-2023%E5%B9%B4%E5%9B%BD%E5%AE%B6%E7%A4%BE%E4%BC%9A%E7%A7%91%E5%AD%A6%E5%9F%BA%E9%87%91%E7%AB%8B%E9%A1%B9%E5%90%8D%E5%8D%95.xlsx">2010-2023年国家社会科学基金立项名单.xlsx</a></p>
<br>
<br>
<h2 id="二读取数据">二、读取数据</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_excel</span><span class="p">(</span><span class="s1">&#39;2010-2023年国家社会科学基金立项名单.xlsx&#39;</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;所在学科&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;所在学科&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/01-df.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df</span><span class="p">[</span><span class="s1">&#39;所在学科&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">array([&#39;马列·科社&#39;, &#39;管理学&#39;, &#39;政治学&#39;, &#39;外国文学&#39;, &#39;人口学&#39;, &#39;图书馆、情报与文献学&#39;, &#39;新闻学与传播学&#39;,
       &#39;中国文学&#39;, &#39;世界历史&#39;, &#39;语言学&#39;, &#39;民族问题研究&#39;, &#39;哲学&#39;, &#39;理论经济&#39;, &#39;体育学&#39;, &#39;国际问题研究&#39;,
       &#39;中国历史&#39;, &#39;党史·党建&#39;, &#39;法学&#39;, &#39;应用经济&#39;, &#39;社会学&#39;, &#39;统计学&#39;, &#39;宗教学&#39;, &#39;&#39;, &#39;教育学&#39;,
       &#39;考古学&#39;, &#39;图书馆、情报与档案学&#39;, &#39;其他&#39;, &#39;图书情报&#39;, &#39;军事学&#39;, &#39;艺术学&#39;, &#39;党史•党建&#39;, &#39;马列•科社&#39;,
       &#39;新闻传播学&#39;, &#39;中国历史、&#39;, &#39;民族学&#39;, &#39;国际问题&#39;, &#39;法学、医学、公共卫生学&#39;, &#39;灾害学、社会学、管理学、系统科学&#39;,
       &#39;法学、医学、社会学&#39;, &#39;应用经济学 法学&#39;, &#39;宏观经济、计量经济、管理学等&#39;, &#39;智能技术、电子商务、人工智能、信&#39;,
       &#39;管理学、经济学、地理学&#39;, &#39;艺术学、人类学、计算机科学&#39;, &#39;文化人类学、非遗保护、考古学、影&#39;,
       &#39;文学艺术、文化人类学、计算机科学&#39;, &#39;计算机科学与技术、社会学、公共管&#39;, &#39;电气工程；产业经济学；管理学；热&#39;,
       &#39;城市规划学、计算机学、信息网络学&#39;, &#39;心理学、认知和行为科学、脑科学、&#39;, &#39;产业经济学、管理学、信息技术及应&#39;,
       &#39;法学、社会学、信息科学、计算机科&#39;, &#39;管理科学与工程、控制科学与工程、&#39;, &#39;智能技术、产业经济、经济学、管理&#39;,
       &#39;语言学、计算机科学、生态学、社会&#39;, &#39;理论经济学、应用经济学、法学、公&#39;, &#39;语言学、人类学、信息科学&#39;,
       &#39;宏观经济、计量经济、管理学、统计&#39;, &#39;管理学、 经济学 、环境科学、&#39;, &#39;语言学、计算机科学、统计学等&#39;,
       &#39;城乡规划学、管理学、地理学、经济&#39;, &#39;语言文学、心理学、教育学&#39;, &#39;人类学、社会心理学、认知神经科学&#39;,
       &#39;应用经济、管理学、资源环境科学、&#39;, &#39;电气工程、管理学、产业经济、能源&#39;, &#39;产业经济、生态学、系统科学、管理&#39;, &#39;马列科社&#39;,
       &#39;党史党建&#39;, &#39;综合研究&#39;, &#39;民族问题&#39;, &#39;图书·情报与文献&#39;, &#39;新闻学&#39;, &#39;跨学科&#39;, &#39;民族问题 研究&#39;,
       &#39;新闻与传播学&#39;, &#39;新闻学与 传播学&#39;, &#39;马列.科社&#39;, &#39;系列丛书&#39;, &#39;图书馆·情报与文献学&#39;, &#39;重点项目&#39;,
       &#39;一般项目&#39;, &#39;学术期刊&#39;, &#39;理论经济学&#39;, &#39;应用经济学&#39;, &#39;国际问题研\n究&#39;, &#39;新闻学与传\n播学&#39;,
       &#39;图书馆、情\n报与文献学&#39;], dtype=object)
</code></pre></div><br>
<h2 id="三简单分析">三、简单分析</h2>
<h3 id="31-可视化准备">3.1 可视化准备</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">matplotlib</span>
<span class="kn">import</span> <span class="nn">matplotlib_inline</span>
<span class="n">matplotlib_inline</span><span class="o">.</span><span class="n">backend_inline</span><span class="o">.</span><span class="n">set_matplotlib_formats</span><span class="p">(</span><span class="s1">&#39;png&#39;</span><span class="p">,</span> <span class="s1">&#39;svg&#39;</span><span class="p">)</span>
<span class="kn">import</span> <span class="nn">scienceplots</span>
<span class="kn">import</span> <span class="nn">platform</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">([</span><span class="s1">&#39;science&#39;</span><span class="p">,</span> <span class="s1">&#39;no-latex&#39;</span><span class="p">,</span> <span class="s1">&#39;cjk-sc-font&#39;</span><span class="p">])</span>
<span class="n">system</span> <span class="o">=</span> <span class="n">platform</span><span class="o">.</span><span class="n">system</span><span class="p">()</span>  <span class="c1"># 获取操作系统类型</span>

<span class="k">if</span> <span class="n">system</span> <span class="o">==</span> <span class="s1">&#39;Windows&#39;</span><span class="p">:</span>
    <span class="n">font</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;family&#39;</span><span class="p">:</span> <span class="s1">&#39;SimHei&#39;</span><span class="p">}</span>
<span class="k">elif</span> <span class="n">system</span> <span class="o">==</span> <span class="s1">&#39;Darwin&#39;</span><span class="p">:</span>
    <span class="n">font</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;family&#39;</span><span class="p">:</span> <span class="s1">&#39;Arial Unicode MS&#39;</span><span class="p">}</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">font</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;family&#39;</span><span class="p">:</span> <span class="s1">&#39;sans-serif&#39;</span><span class="p">}</span>
<span class="n">matplotlib</span><span class="o">.</span><span class="n">rc</span><span class="p">(</span><span class="s1">&#39;font&#39;</span><span class="p">,</span> <span class="o">**</span><span class="n">font</span><span class="p">)</span>  <span class="c1"># 设置全局字体</span>
</code></pre></div><br>
<h3 id="32-立项数量">3.2 立项数量</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">df[&#39;批准年份&#39;].value_counts(ascending=True).plot(kind=&#39;bar&#39;, figsize=(8, 4))
plt.xticks(rotation=0)
plt.ylabel(&#39;立项数量&#39;, rotation=0)
plt.title(&#39;国社科立项数量(2010-2023)&#39;)
</code></pre></div><p><img loading="lazy" src="img/02-plot.png" alt=""  />
</p>
<br>
<h3 id="33-经管学科">3.3 经管学科</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">management_economic_displines</span> <span class="o">=</span> <span class="p">[</span><span class="n">d</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;所在学科&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span> <span class="k">if</span> <span class="p">(</span><span class="s1">&#39;经济&#39;</span> <span class="ow">in</span> <span class="n">d</span><span class="p">)</span> <span class="ow">or</span>  <span class="p">(</span><span class="s1">&#39;管理&#39;</span> <span class="ow">in</span> <span class="n">d</span><span class="p">)]</span>
<span class="n">management_economic_displines</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">[&#39;管理学&#39;,
 &#39;理论经济&#39;,
 &#39;应用经济&#39;,
 &#39;灾害学、社会学、管理学、系统科学&#39;,
 &#39;应用经济学 法学&#39;,
 &#39;宏观经济、计量经济、管理学等&#39;,
 &#39;管理学、经济学、地理学&#39;,
 &#39;电气工程；产业经济学；管理学；热&#39;,
 &#39;产业经济学、管理学、信息技术及应&#39;,
 &#39;管理科学与工程、控制科学与工程、&#39;,
 &#39;智能技术、产业经济、经济学、管理&#39;,
 &#39;理论经济学、应用经济学、法学、公&#39;,
 &#39;宏观经济、计量经济、管理学、统计&#39;,
 &#39;管理学、 经济学 、环境科学、&#39;,
 &#39;城乡规划学、管理学、地理学、经济&#39;,
 &#39;应用经济、管理学、资源环境科学、&#39;,
 &#39;电气工程、管理学、产业经济、能源&#39;,
 &#39;产业经济、生态学、系统科学、管理&#39;,
 &#39;理论经济学&#39;,
 &#39;应用经济学&#39;]
</code></pre></div><br>
<h3 id="34-经管立项">3.4 经管立项</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">eco_man_df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;所在学科&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="n">management_economic_displines</span><span class="p">)]</span>
<span class="n">eco_man_df</span>
</code></pre></div><p><img loading="lazy" src="img/03-df.png" alt=""  />
</p>
<br>
<p>经管类国社科立项数量占比</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df</span><span class="p">[</span><span class="s1">&#39;所在学科&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="n">management_economic_displines</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">0.18713464870187335
</code></pre></div><br>
<h3 id="35-经管立项数量">3.5 经管立项数量</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">eco_man_with_ds_df</span> <span class="o">=</span> <span class="n">eco_man_df</span><span class="p">[</span><span class="n">eco_man_df</span><span class="p">[</span><span class="s1">&#39;课题名称&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="s1">&#39;大数据|数据挖掘|机器学习|人工智能|AIGC&#39;</span><span class="p">)]</span>
<span class="n">eco_man_with_ds_df</span><span class="p">[</span><span class="s1">&#39;批准年份&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s1">&#39;bar&#39;</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">rotation</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;立项数量&#39;</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;国社科基金中结合数据科学的经济、管理类立项数量(2010-2023)&#39;</span><span class="p">)</span>
</code></pre></div><p><img loading="lazy" src="img/05-plot.png" alt=""  />
</p>
<br>
<h3 id="36-经管立项占比">3.6 经管立项占比</h3>
<p>按年度查看， 国社科中经管类立项占比</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">year_ratios</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">year</span><span class="p">,</span> <span class="n">year_df</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;批准年份&#39;</span><span class="p">):</span>
    <span class="n">ratio</span> <span class="o">=</span> <span class="n">year_df</span><span class="p">[</span><span class="s1">&#39;所在学科&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="n">management_economic_displines</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">year_df</span><span class="p">)</span>
    <span class="n">year_ratios</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">year</span><span class="p">,</span> <span class="n">ratio</span><span class="p">))</span>
    
<span class="n">year_ratio_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">year_ratios</span><span class="p">)</span>
<span class="n">year_ratio_df</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;year&#39;</span><span class="p">,</span> <span class="s1">&#39;ratio&#39;</span><span class="p">]</span>
<span class="n">year_ratio_df</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="s1">&#39;year&#39;</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">year_ratio_df</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s1">&#39;bar&#39;</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;立项占比&#39;</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;国社科基金中经济、管理类立项占比(2010-2023)&#39;</span><span class="p">)</span>
</code></pre></div><p><img loading="lazy" src="img/04-plot.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>opencc | 中文简体、繁体转换库</title>
      <link>https://textdata.cn/blog/2024-01-21-chinese-traditional-to-simplified-text/</link>
      <pubDate>Sun, 21 Jan 2024 00:00:00 +0000</pubDate>
      
      <guid>/blog/2024-01-21-chinese-traditional-to-simplified-text/</guid>
      <description>&lt;h2 id=&#34;一介绍&#34;&gt;一、介绍&lt;/h2&gt;
&lt;p&gt;opencc-python是中文简体、繁体转换库， 可以进行简转繁、繁转简、杂转简、杂转繁等操作。&lt;/p&gt;
&lt;br&gt;
&lt;ul&gt;
&lt;li&gt;t2s：繁体中文转简体中文&lt;/li&gt;
&lt;li&gt;s2t：简体中文转繁体中文&lt;/li&gt;
&lt;li&gt;hk2s：繁体中文（香港标准）至简体中文&lt;/li&gt;
&lt;li&gt;s2hk：简体中文转繁体中文（香港标准）&lt;/li&gt;
&lt;li&gt;s2tw：简体中文转繁体中文（台湾标准）&lt;/li&gt;
&lt;li&gt;s2twp：简体中文转繁体中文（台湾标准，带短语）&lt;/li&gt;
&lt;li&gt;t2hk：繁体中文转繁体中文（香港标准）&lt;/li&gt;
&lt;li&gt;t2tw：繁体中文转繁体中文（台湾标准）&lt;/li&gt;
&lt;li&gt;tw2s：繁体中文（台湾标准）到简体中文&lt;/li&gt;
&lt;li&gt;tw2sp：繁体中文（台湾标准）到简体中文（带短语）&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
&lt;br&gt;
&lt;h2 id=&#34;二安装&#34;&gt;二、安装&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;pip3 install opencc-python-reimplemented
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;三快速上手&#34;&gt;三、快速上手&lt;/h2&gt;
&lt;h3 id=&#34;31-繁to简&#34;&gt;3.1 繁to简&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;opencc&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;OpenCC&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;cc&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;OpenCC&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;t2s&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;#繁体2简体&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;text&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;簡體漢字&amp;#39;&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;cc&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;convert&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&amp;#39;简体汉字&amp;#39;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h3 id=&#34;32-简to繁&#34;&gt;3.2 简to繁&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;opencc&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;OpenCC&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;cc&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;OpenCC&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;s2t&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;# 简体2繁体&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;text&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;简体汉字&amp;#39;&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;cc&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;convert&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&amp;#39;簡體漢字&amp;#39;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;br&gt;
&lt;h2 id=&#34;广而告之&#34;&gt;广而告之&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/call_for_paper/&#34;&gt;长期征稿&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/we_need_you/&#34;&gt;长期招募小伙伴&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/management_python_course&#34;&gt;&lt;strong&gt;付费视频课 | Python实证指标构建与文本分析&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
      <content:encoded><![CDATA[<h2 id="一介绍">一、介绍</h2>
<p>opencc-python是中文简体、繁体转换库， 可以进行简转繁、繁转简、杂转简、杂转繁等操作。</p>
<br>
<ul>
<li>t2s：繁体中文转简体中文</li>
<li>s2t：简体中文转繁体中文</li>
<li>hk2s：繁体中文（香港标准）至简体中文</li>
<li>s2hk：简体中文转繁体中文（香港标准）</li>
<li>s2tw：简体中文转繁体中文（台湾标准）</li>
<li>s2twp：简体中文转繁体中文（台湾标准，带短语）</li>
<li>t2hk：繁体中文转繁体中文（香港标准）</li>
<li>t2tw：繁体中文转繁体中文（台湾标准）</li>
<li>tw2s：繁体中文（台湾标准）到简体中文</li>
<li>tw2sp：繁体中文（台湾标准）到简体中文（带短语）</li>
</ul>
<br>
<br>
<h2 id="二安装">二、安装</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">pip3 install opencc-python-reimplemented
</code></pre></div><p><br><br></p>
<h2 id="三快速上手">三、快速上手</h2>
<h3 id="31-繁to简">3.1 繁to简</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">opencc</span> <span class="kn">import</span> <span class="n">OpenCC</span>
<span class="n">cc</span> <span class="o">=</span> <span class="n">OpenCC</span><span class="p">(</span><span class="s1">&#39;t2s&#39;</span><span class="p">)</span>  <span class="c1">#繁体2简体</span>

<span class="n">text</span> <span class="o">=</span> <span class="s1">&#39;簡體漢字&#39;</span>
<span class="n">cc</span><span class="o">.</span><span class="n">convert</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">&#39;简体汉字&#39;
</code></pre></div><br>
<h3 id="32-简to繁">3.2 简to繁</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">opencc</span> <span class="kn">import</span> <span class="n">OpenCC</span>
<span class="n">cc</span> <span class="o">=</span> <span class="n">OpenCC</span><span class="p">(</span><span class="s1">&#39;s2t&#39;</span><span class="p">)</span>  <span class="c1"># 简体2繁体</span>
<span class="n">text</span> <span class="o">=</span> <span class="s1">&#39;简体汉字&#39;</span>
<span class="n">cc</span><span class="o">.</span><span class="n">convert</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">&#39;簡體漢字&#39;
</code></pre></div><br>
<br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course"><strong>付费视频课 | Python实证指标构建与文本分析</strong></a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>数据集 |  港股年报文本数据集(2007 ~ 2023.12)</title>
      <link>https://textdata.cn/blog/2024-01-21-hk-stock-market-anual-report/</link>
      <pubDate>Sun, 21 Jan 2024 00:00:00 +0000</pubDate>
      
      <guid>/blog/2024-01-21-hk-stock-market-anual-report/</guid>
      <description>&lt;h2 id=&#34;一数据集概况&#34;&gt;一、数据集概况&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;数据名称: 港股年报
数据来源: 披露易（https://www1.hkexnews.hk/）
报告类型: 中(英)文年报
公司数量: 2671
报告数量: 27172
会计年度: 2007 ~ 2023
报告发布日期: 2007-01-08 ~ 2023-12-22
数据类型: pdf、txt、csv(csv是对所有txt的汇总文件)
数据体积: 257G

港股年报数据集，500元；加微信 372335839， 备注「姓名-学校-专业」
数据是虚拟产品，一经售出，不再退还！ 请仔细阅读推文内容， 确认无误再加微信详谈购买事宜 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;11-数据集截图&#34;&gt;1.1 数据集截图&lt;/h3&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/01-size.jpg&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/02-datascreen.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/03-pdf.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/04-txt.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;12-数据来源&#34;&gt;1.2 数据来源&lt;/h3&gt;
&lt;p&gt;数据整理自 &lt;em&gt;&lt;strong&gt;披露易 &lt;a href=&#34;https://www1.hkexnews.hk&#34;&gt;https://www1.hkexnews.hk&lt;/a&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;https://www1.hkexnews.hk/search/titlesearch.xhtml?lang=zh
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/05-site.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;二pdftxt&#34;&gt;二、PDF、TXT&lt;/h2&gt;
&lt;h3 id=&#34;21-读取txt&#34;&gt;2.1 读取TXT&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;text&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;open&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;港股年报中文TXT/09985_2022_衛龍_2022年年報_27-04-2023.txt&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[:&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;500&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&amp;#39;(Incorporated in the Cayman Islands with Limited Liability)\n（於開曼群島註冊成立的有限公司）\nStock code 股份代號 : 09985.HK\nANNUAL\nREPORT\n2022\n年報 2022\nANNUAL REPORT\n年報Contents 2 Company Profile\n公司簡介\n目錄\n3 Definitions\n釋義\n6 Corporate Information\n公司資料\n8 Financial Overview\n財務概覽\n10 Chairman’s Statement\n主席報告\n14 Management Discussion and Analysis\n管理層討論與分析\n33 Corporate Governance Report\n企業管治報告\n57 Biographies of Directors and Senior Management\n董事及高級管理人員履歷\n66 Report of the Directors\n董事會報告\n90 Independent Auditor’s Report\n獨立核數師&amp;#39;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h3 id=&#34;22--pdf&#34;&gt;2.2  PDF&lt;/h3&gt;
&lt;h3 id=&#34;221-安装pdfdocx&#34;&gt;2.2.1 安装pdfdocx&lt;/h3&gt;
&lt;p&gt;打开命令行(cmd）， 执行安装命令&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;pip install pdfdocx
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;222-读取pdf&#34;&gt;2.2.2 读取pdf&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pdfdocx&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;read_pdf&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;text&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;read_pdf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;港股年报中文PDF/09990_2022_祖龍娛樂_2022年度報告_24-04-2023.PDF&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[:&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;500&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&amp;#39;2022\n2022\n年\n報\nANNUAL REPORT \n(Incorporated in the Cayman Islands with limited liability)\n( 於開曼群島註冊成立的有限公司 )\nStock Code 股份代號 : 9990\n祖龍娛樂有限公司\nArchosaur Games Inc.\n \n頁次\n釋義 \n2\n公司資料 \n9\n財務概要 \n11\n主席致辭 \n13\n財務表現摘要 \n18\n管理層討論與分析 \n19\n董事會報告 \n32\n董事及高級管理層履歷詳情 \n61\n企業管治報告 \n66\n獨立核數師報告 \n79\n綜合損益表 \n85\n綜合全面收益表 \n86\n綜合資產負債表 \n87\n綜合權益變動表 \n89\n綜合現金流量表 \n91\n綜合財務報表附註 \n93\n目錄\n祖龙娛樂有限公司  年度報告 2022\n02\n釋義\n於本年報內，除文義另有所指外，下列詞彙具有以下涵義：\n「採納日期」\n指\n2021年2月5日，即股東於本公司在2021年2月5日（星期五）舉行的股東\n特別大會上採納購股權計劃的日期\n「修訂日期」\n指\n2022年12月22日，即購股權計劃的修訂獲股東在本公司於&amp;#39;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;三-繁体2简体&#34;&gt;三、 繁体2简体&lt;/h2&gt;
&lt;p&gt;港股年报 PDF 和  TXT 内容均为繁体字未做处理， 后续如果用 Python 做文本分析， 可以使用 opencc-python 处理中英文&lt;/p&gt;
&lt;h3 id=&#34;31-安装&#34;&gt;3.1 安装&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;pip3 install opencc-python-reimplemented
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h3 id=&#34;32-转换语法&#34;&gt;3.2 转换语法&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;opencc&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;OpenCC&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;cc&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;OpenCC&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;t2s&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;# 繁体2简体&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;text&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;開放中文轉換&amp;#39;&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;cc&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;convert&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;开放中文转换
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;四csv&#34;&gt;四、CSV&lt;/h2&gt;
&lt;p&gt;csv是对港股中(英)文TXT的汇总，且已对中文进行了繁体转简体处理。&lt;/p&gt;
&lt;h3 id=&#34;41-读取&#34;&gt;4.1 读取&lt;/h3&gt;
&lt;p&gt;csv是对所有 txt 的汇总文件， 如果电脑内存16G +， 可直接读取。 &lt;code&gt;港股中文年报.csv.gz(2.69G，解压后大概8.8G)&lt;/code&gt;。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pandas&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pd&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;cdf&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read_csv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;港股中文年报.csv.gz&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;cdf&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/06-df.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;br&gt;
&lt;p&gt;如果电脑内存小于16G， 可参考 &lt;a href=&#34;https://textdata.cn/blog/2023-11-17-how-handle-mega-csv-that-far-exceed-memory/&#34;&gt;&lt;strong&gt;代码 | 如何处理远超电脑内存的csv文件&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pandas&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pd&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;#只读取5行&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;cdf2&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read_csv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;港股中文年报.csv.gz&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
                  &lt;span class=&#34;n&#34;&gt;compression&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;gzip&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
                  &lt;span class=&#34;n&#34;&gt;nrows&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h3 id=&#34;42-记录数&#34;&gt;4.2 记录数&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;cdf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;27170
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;43-公司数量&#34;&gt;4.3 公司数量&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;cdf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;code&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;nunique&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;2670
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h3 id=&#34;44-会计年度&#34;&gt;4.4 会计年度&lt;/h3&gt;
&lt;p&gt;数据集覆盖的会计年度主要集中在 2007 ~ 2023，但2001 ~ 2006也会有少量记录。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;nb&#34;&gt;sorted&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;cdf&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;year&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;unique&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;())&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;[2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;cdf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;cdf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;year&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;==&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2001&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/07-df.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;cdf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;cdf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;year&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;==&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2003&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/08-df.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;cdf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;cdf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;year&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;==&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2006&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/09-df.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;cdf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;cdf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;year&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;==&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2007&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/10-df.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;45-发布日期&#34;&gt;4.5 发布日期&lt;/h3&gt;
&lt;p&gt;港股年报报告发布日期&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;cdf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;pubdate&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;to_datetime&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;cdf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;pubdate&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;

&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;cdf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;pubdate&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;min&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;())&lt;/span&gt;
&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;cdf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;pubdate&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;max&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;())&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;2007-01-08 00:00:00
2023-12-22 00:00:00
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;br&gt;
&lt;h2 id=&#34;五相关内容&#34;&gt;五、相关内容&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/2023-03-23-china-a-share-market-dataset-mda-from-01-to-21/&#34;&gt;数据集 | 2001-2022年A股上市公司年报&amp;amp;管理层讨论与分析&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/2024-01-18-neeq-china-listed-on-nation-equities-exchange-and-quotation-system-anunal-year-report/&#34;&gt;数据集(付费) | 三板上市公司年报2002-2023.12&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/2024-01-14-usa-sec-10k-report-dataset/&#34;&gt;数据集 | 美股年报10-K、20-F数据(2000-2023.12)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;六获取数据&#34;&gt;六、获取数据&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;港股年报数据集，&lt;strong&gt;500&lt;/strong&gt;元；加微信 372335839， 备注「&lt;strong&gt;姓名-学校-专业&lt;/strong&gt;」。&lt;/li&gt;
&lt;li&gt;数据是虚拟产品，一经售出，不再退还！&lt;/li&gt;
&lt;li&gt;请仔细阅读推文内容， 确认无误再加微信详谈购买事宜&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;广而告之&#34;&gt;广而告之&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/call_for_paper/&#34;&gt;长期征稿&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/we_need_you/&#34;&gt;长期招募小伙伴&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/management_python_course&#34;&gt;&lt;strong&gt;付费视频课 | Python实证指标构建与文本分析&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
      <content:encoded><![CDATA[<h2 id="一数据集概况">一、数据集概况</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">数据名称: 港股年报
数据来源: 披露易（https://www1.hkexnews.hk/）
报告类型: 中(英)文年报
公司数量: 2671
报告数量: 27172
会计年度: 2007 ~ 2023
报告发布日期: 2007-01-08 ~ 2023-12-22
数据类型: pdf、txt、csv(csv是对所有txt的汇总文件)
数据体积: 257G

港股年报数据集，500元；加微信 372335839， 备注「姓名-学校-专业」
数据是虚拟产品，一经售出，不再退还！ 请仔细阅读推文内容， 确认无误再加微信详谈购买事宜 
</code></pre></div><h3 id="11-数据集截图">1.1 数据集截图</h3>
<p><img loading="lazy" src="img/01-size.jpg" alt=""  />
</p>
<p><img loading="lazy" src="img/02-datascreen.png" alt=""  />
</p>
<p><img loading="lazy" src="img/03-pdf.png" alt=""  />
</p>
<p><img loading="lazy" src="img/04-txt.png" alt=""  />
</p>
<br>
<h3 id="12-数据来源">1.2 数据来源</h3>
<p>数据整理自 <em><strong>披露易 <a href="https://www1.hkexnews.hk">https://www1.hkexnews.hk</a></strong></em></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">https://www1.hkexnews.hk/search/titlesearch.xhtml?lang=zh
</code></pre></div><p><img loading="lazy" src="img/05-site.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="二pdftxt">二、PDF、TXT</h2>
<h3 id="21-读取txt">2.1 读取TXT</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">text</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;港股年报中文TXT/09985_2022_衛龍_2022年年報_27-04-2023.txt&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
<span class="n">text</span><span class="p">[:</span><span class="mi">500</span><span class="p">]</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">&#39;(Incorporated in the Cayman Islands with Limited Liability)\n（於開曼群島註冊成立的有限公司）\nStock code 股份代號 : 09985.HK\nANNUAL\nREPORT\n2022\n年報 2022\nANNUAL REPORT\n年報Contents 2 Company Profile\n公司簡介\n目錄\n3 Definitions\n釋義\n6 Corporate Information\n公司資料\n8 Financial Overview\n財務概覽\n10 Chairman’s Statement\n主席報告\n14 Management Discussion and Analysis\n管理層討論與分析\n33 Corporate Governance Report\n企業管治報告\n57 Biographies of Directors and Senior Management\n董事及高級管理人員履歷\n66 Report of the Directors\n董事會報告\n90 Independent Auditor’s Report\n獨立核數師&#39;
</code></pre></div><br>
<h3 id="22--pdf">2.2  PDF</h3>
<h3 id="221-安装pdfdocx">2.2.1 安装pdfdocx</h3>
<p>打开命令行(cmd）， 执行安装命令</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">pip install pdfdocx
</code></pre></div><h3 id="222-读取pdf">2.2.2 读取pdf</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">pdfdocx</span> <span class="kn">import</span> <span class="n">read_pdf</span>

<span class="n">text</span> <span class="o">=</span> <span class="n">read_pdf</span><span class="p">(</span><span class="s1">&#39;港股年报中文PDF/09990_2022_祖龍娛樂_2022年度報告_24-04-2023.PDF&#39;</span><span class="p">)</span>
<span class="n">text</span><span class="p">[:</span><span class="mi">500</span><span class="p">]</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">&#39;2022\n2022\n年\n報\nANNUAL REPORT \n(Incorporated in the Cayman Islands with limited liability)\n( 於開曼群島註冊成立的有限公司 )\nStock Code 股份代號 : 9990\n祖龍娛樂有限公司\nArchosaur Games Inc.\n \n頁次\n釋義 \n2\n公司資料 \n9\n財務概要 \n11\n主席致辭 \n13\n財務表現摘要 \n18\n管理層討論與分析 \n19\n董事會報告 \n32\n董事及高級管理層履歷詳情 \n61\n企業管治報告 \n66\n獨立核數師報告 \n79\n綜合損益表 \n85\n綜合全面收益表 \n86\n綜合資產負債表 \n87\n綜合權益變動表 \n89\n綜合現金流量表 \n91\n綜合財務報表附註 \n93\n目錄\n祖龙娛樂有限公司  年度報告 2022\n02\n釋義\n於本年報內，除文義另有所指外，下列詞彙具有以下涵義：\n「採納日期」\n指\n2021年2月5日，即股東於本公司在2021年2月5日（星期五）舉行的股東\n特別大會上採納購股權計劃的日期\n「修訂日期」\n指\n2022年12月22日，即購股權計劃的修訂獲股東在本公司於&#39;
</code></pre></div><p><br><br></p>
<h2 id="三-繁体2简体">三、 繁体2简体</h2>
<p>港股年报 PDF 和  TXT 内容均为繁体字未做处理， 后续如果用 Python 做文本分析， 可以使用 opencc-python 处理中英文</p>
<h3 id="31-安装">3.1 安装</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">pip3 install opencc-python-reimplemented
</code></pre></div><br>
<h3 id="32-转换语法">3.2 转换语法</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">opencc</span> <span class="kn">import</span> <span class="n">OpenCC</span>
<span class="n">cc</span> <span class="o">=</span> <span class="n">OpenCC</span><span class="p">(</span><span class="s1">&#39;t2s&#39;</span><span class="p">)</span>  <span class="c1"># 繁体2简体</span>

<span class="n">text</span> <span class="o">=</span> <span class="s1">&#39;開放中文轉換&#39;</span>
<span class="n">cc</span><span class="o">.</span><span class="n">convert</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">开放中文转换
</code></pre></div><p><br><br></p>
<h2 id="四csv">四、CSV</h2>
<p>csv是对港股中(英)文TXT的汇总，且已对中文进行了繁体转简体处理。</p>
<h3 id="41-读取">4.1 读取</h3>
<p>csv是对所有 txt 的汇总文件， 如果电脑内存16G +， 可直接读取。 <code>港股中文年报.csv.gz(2.69G，解压后大概8.8G)</code>。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">cdf</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;港股中文年报.csv.gz&#39;</span><span class="p">)</span>
<span class="n">cdf</span>
</code></pre></div><p><img loading="lazy" src="img/06-df.png" alt=""  />
</p>
<br>
<br>
<p>如果电脑内存小于16G， 可参考 <a href="https://textdata.cn/blog/2023-11-17-how-handle-mega-csv-that-far-exceed-memory/"><strong>代码 | 如何处理远超电脑内存的csv文件</strong></a></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="c1">#只读取5行</span>
<span class="n">cdf2</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;港股中文年报.csv.gz&#39;</span><span class="p">,</span> 
                  <span class="n">compression</span><span class="o">=</span><span class="s1">&#39;gzip&#39;</span><span class="p">,</span> 
                  <span class="n">nrows</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</code></pre></div><br>
<h3 id="42-记录数">4.2 记录数</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="nb">len</span><span class="p">(</span><span class="n">cdf</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">27170
</code></pre></div><h3 id="43-公司数量">4.3 公司数量</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">cdf</span><span class="p">[</span><span class="s1">&#39;code&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">nunique</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">2670
</code></pre></div><br>
<h3 id="44-会计年度">4.4 会计年度</h3>
<p>数据集覆盖的会计年度主要集中在 2007 ~ 2023，但2001 ~ 2006也会有少量记录。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="nb">sorted</span><span class="p">(</span><span class="n">cdf</span><span class="o">.</span><span class="n">year</span><span class="o">.</span><span class="n">unique</span><span class="p">())</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">[2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023]
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">cdf</span><span class="p">[</span><span class="n">cdf</span><span class="p">[</span><span class="s1">&#39;year&#39;</span><span class="p">]</span><span class="o">==</span><span class="mi">2001</span><span class="p">]</span>
</code></pre></div><p><img loading="lazy" src="img/07-df.png" alt=""  />
</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">cdf</span><span class="p">[</span><span class="n">cdf</span><span class="p">[</span><span class="s1">&#39;year&#39;</span><span class="p">]</span><span class="o">==</span><span class="mi">2003</span><span class="p">]</span>
</code></pre></div><p><img loading="lazy" src="img/08-df.png" alt=""  />
</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">cdf</span><span class="p">[</span><span class="n">cdf</span><span class="p">[</span><span class="s1">&#39;year&#39;</span><span class="p">]</span><span class="o">==</span><span class="mi">2006</span><span class="p">]</span>
</code></pre></div><p><img loading="lazy" src="img/09-df.png" alt=""  />
</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">cdf</span><span class="p">[</span><span class="n">cdf</span><span class="p">[</span><span class="s1">&#39;year&#39;</span><span class="p">]</span><span class="o">==</span><span class="mi">2007</span><span class="p">]</span>
</code></pre></div><p><img loading="lazy" src="img/10-df.png" alt=""  />
</p>
<br>
<h3 id="45-发布日期">4.5 发布日期</h3>
<p>港股年报报告发布日期</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">cdf</span><span class="p">[</span><span class="s1">&#39;pubdate&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">cdf</span><span class="p">[</span><span class="s1">&#39;pubdate&#39;</span><span class="p">])</span>

<span class="nb">print</span><span class="p">(</span><span class="n">cdf</span><span class="p">[</span><span class="s1">&#39;pubdate&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">cdf</span><span class="p">[</span><span class="s1">&#39;pubdate&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">2007-01-08 00:00:00
2023-12-22 00:00:00
</code></pre></div><br>
<br>
<h2 id="五相关内容">五、相关内容</h2>
<ul>
<li><a href="https://textdata.cn/blog/2023-03-23-china-a-share-market-dataset-mda-from-01-to-21/">数据集 | 2001-2022年A股上市公司年报&amp;管理层讨论与分析</a></li>
<li><a href="https://textdata.cn/blog/2024-01-18-neeq-china-listed-on-nation-equities-exchange-and-quotation-system-anunal-year-report/">数据集(付费) | 三板上市公司年报2002-2023.12</a></li>
<li><a href="https://textdata.cn/blog/2024-01-14-usa-sec-10k-report-dataset/">数据集 | 美股年报10-K、20-F数据(2000-2023.12)</a></li>
</ul>
<p><br><br></p>
<h2 id="六获取数据">六、获取数据</h2>
<ol>
<li>港股年报数据集，<strong>500</strong>元；加微信 372335839， 备注「<strong>姓名-学校-专业</strong>」。</li>
<li>数据是虚拟产品，一经售出，不再退还！</li>
<li>请仔细阅读推文内容， 确认无误再加微信详谈购买事宜</li>
</ol>
<p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course"><strong>付费视频课 | Python实证指标构建与文本分析</strong></a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>数据集 | 用来练习pandas的招聘数据</title>
      <link>https://textdata.cn/blog/2024-01-19-recruitment-dataset/</link>
      <pubDate>Fri, 19 Jan 2024 00:00:00 +0000</pubDate>
      
      <guid>/blog/2024-01-19-recruitment-dataset/</guid>
      <description>&lt;h2 id=&#34;相关推文&#34;&gt;相关推文&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://textdata.cn/blog/2023-11-17-how-handle-mega-csv-that-far-exceed-memory/&#34;&gt;推荐 | 如何处理远超电脑内存的csv文件&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;一数据集概况&#34;&gt;一、数据集概况&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;- 数据集名：招聘数据集
- 采集时间：2018.7
- 数据来源：58同城、智联招聘
- 记录数: 1701992

百度网盘链接: https://pan.baidu.com/s/1arYXcrexLW__SFF5AbjAaA?pwd=sfg5 提取码: sfg5 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;注意:   免费公开，大家可以用来练习Pandas。&lt;/p&gt;
&lt;p&gt;该数据集是有偏的， 不太适合做研究。 如果你想用这个数据集做研究， 拿去不谢，但不要加我微信提问呀！！我知道的都在推文里！！&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;二pandas练习&#34;&gt;二、Pandas练习&lt;/h2&gt;
&lt;h3 id=&#34;21-读取&#34;&gt;2.1 读取&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pandas&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pd&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read_csv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;2018.7招聘数据.csv.gz&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;compression&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;gzip&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;#使用bandizip或winrar解压gz，得到csv&lt;/span&gt;
&lt;span class=&#34;c1&#34;&gt;#df = pd.read_csv(&amp;#39;2018.7招聘数据.csv&amp;#39;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;head&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/01-df.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;p&gt;记录数&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;1701992
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h3 id=&#34;22-省份&#34;&gt;2.2 省份&lt;/h3&gt;
&lt;p&gt;不同省份的记录数&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;省份&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;value_counts&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;省份
北京市         410142
上海市         364047
河南省         156374
福建省         120816
广东省         101390
湖北省          63507
河北省          57152
江苏省          52360
四川省          51849
山东省          46956
重庆市          43153
湖南省          41438
陕西省          32108
浙江省          31838
黑龙江省         20466
贵州省          17837
辽宁省          15015
海南省          14412
云南省          13542
广西壮族自治区      12842
吉林省          11502
江西省           9638
新疆维吾尔自治区      5071
天津市           3681
安徽省           3547
山西省           1308
Name: count, dtype: int64
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h3 id=&#34;23-学历&#34;&gt;2.3 学历&lt;/h3&gt;
&lt;p&gt;不同学历的记录数&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;学历&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;value_counts&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;学历
学历不限    999542
大专      286629
高中      123481
中专      100423
不限       84206
本科       83400
中技       10810
技校        6736
硕士        6151
博士         613
Name: count, dtype: int64
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;p&gt;筛选出需要博士学历的记录&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;学历&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;==&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;博士&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/02-df.png&#34; alt=&#34;&#34;  /&gt;
&lt;img loading=&#34;lazy&#34; src=&#34;img/03-df.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;24-岗位描述&#34;&gt;2.4 岗位描述&lt;/h3&gt;
&lt;h4 id=&#34;241-文本长度&#34;&gt;2.4.1 文本长度&lt;/h4&gt;
&lt;p&gt;岗位描述文本长度&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;岗位描述&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fillna&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;str&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;0           974
1           457
2           731
3           430
4           348
           ... 
1701987     294
1701988    1029
1701989     322
1701990      25
1701991     377
Name: 岗位描述, Length: 1701992, dtype: int64
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h4 id=&#34;242-是否含某个类词&#34;&gt;2.4.2 是否含某个(类)词&lt;/h4&gt;
&lt;p&gt;岗位描述是否含 &lt;code&gt;抗压能力强&lt;/code&gt; 或 &lt;code&gt;压力大&lt;/code&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;c1&#34;&gt;#一个词&lt;/span&gt;
&lt;span class=&#34;c1&#34;&gt;#df[df[&amp;#39;岗位描述&amp;#39;].fillna(&amp;#39;&amp;#39;).str.contains(&amp;#39;抗压能力强&amp;#39;)].head()&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;#多个词用|间隔&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;岗位描述&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fillna&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;str&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;contains&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;抗压能力强|压力大&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;head&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/04-df.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;p&gt;岗位描述含 &lt;code&gt;抗压能力强|压力大&lt;/code&gt; 的工作占比&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;压力占比&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;岗位描述&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fillna&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;str&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;contains&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;抗压能力强|压力大&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sum&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;

&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;轻松占比&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;岗位描述&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fillna&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;str&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;contains&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;工作轻松|压力小&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sum&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;压力占比 0.012797357449388716
轻松占比 0.018608195573187183
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&amp;hellip;&lt;/p&gt;
&lt;h2 id=&#34;三获取数据&#34;&gt;三、获取数据&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;百度网盘链接: https://pan.baidu.com/s/1arYXcrexLW__SFF5AbjAaA?pwd=sfg5 提取码: sfg5 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;注意:   免费公开，大家可以用来练习Pandas。&lt;/p&gt;
&lt;p&gt;该数据集是有偏的， 不太适合做研究。 如果你想用这个数据集做研究， 拿去不谢，但不要加我微信提问呀！！我知道的都在推文里！！&lt;/p&gt;
&lt;br&gt;
&lt;br&gt;
&lt;h2 id=&#34;广而告之&#34;&gt;广而告之&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/call_for_paper/&#34;&gt;长期征稿&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/we_need_you/&#34;&gt;长期招募小伙伴&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/management_python_course/&#34;&gt;付费视频课 | Python实证指标构建与文本分析&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
      <content:encoded><![CDATA[<h2 id="相关推文">相关推文</h2>
<p><a href="https://textdata.cn/blog/2023-11-17-how-handle-mega-csv-that-far-exceed-memory/">推荐 | 如何处理远超电脑内存的csv文件</a></p>
<p><br><br></p>
<h2 id="一数据集概况">一、数据集概况</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">- 数据集名：招聘数据集
- 采集时间：2018.7
- 数据来源：58同城、智联招聘
- 记录数: 1701992

百度网盘链接: https://pan.baidu.com/s/1arYXcrexLW__SFF5AbjAaA?pwd=sfg5 提取码: sfg5 
</code></pre></div><p>注意:   免费公开，大家可以用来练习Pandas。</p>
<p>该数据集是有偏的， 不太适合做研究。 如果你想用这个数据集做研究， 拿去不谢，但不要加我微信提问呀！！我知道的都在推文里！！</p>
<p><br><br></p>
<h2 id="二pandas练习">二、Pandas练习</h2>
<h3 id="21-读取">2.1 读取</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;2018.7招聘数据.csv.gz&#39;</span><span class="p">,</span> <span class="n">compression</span><span class="o">=</span><span class="s1">&#39;gzip&#39;</span><span class="p">)</span>

<span class="c1">#使用bandizip或winrar解压gz，得到csv</span>
<span class="c1">#df = pd.read_csv(&#39;2018.7招聘数据.csv&#39;)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/01-df.png" alt=""  />
</p>
<br>
<p>记录数</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">1701992
</code></pre></div><br>
<h3 id="22-省份">2.2 省份</h3>
<p>不同省份的记录数</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df</span><span class="p">[</span><span class="s1">&#39;省份&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">省份
北京市         410142
上海市         364047
河南省         156374
福建省         120816
广东省         101390
湖北省          63507
河北省          57152
江苏省          52360
四川省          51849
山东省          46956
重庆市          43153
湖南省          41438
陕西省          32108
浙江省          31838
黑龙江省         20466
贵州省          17837
辽宁省          15015
海南省          14412
云南省          13542
广西壮族自治区      12842
吉林省          11502
江西省           9638
新疆维吾尔自治区      5071
天津市           3681
安徽省           3547
山西省           1308
Name: count, dtype: int64
</code></pre></div><br>
<h3 id="23-学历">2.3 学历</h3>
<p>不同学历的记录数</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df</span><span class="p">[</span><span class="s1">&#39;学历&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">学历
学历不限    999542
大专      286629
高中      123481
中专      100423
不限       84206
本科       83400
中技       10810
技校        6736
硕士        6151
博士         613
Name: count, dtype: int64
</code></pre></div><br>
<p>筛选出需要博士学历的记录</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;学历&#39;</span><span class="p">]</span><span class="o">==</span><span class="s1">&#39;博士&#39;</span><span class="p">]</span>
</code></pre></div><p><img loading="lazy" src="img/02-df.png" alt=""  />
<img loading="lazy" src="img/03-df.png" alt=""  />
</p>
<br>
<h3 id="24-岗位描述">2.4 岗位描述</h3>
<h4 id="241-文本长度">2.4.1 文本长度</h4>
<p>岗位描述文本长度</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df</span><span class="p">[</span><span class="s1">&#39;岗位描述&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">len</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">0           974
1           457
2           731
3           430
4           348
           ... 
1701987     294
1701988    1029
1701989     322
1701990      25
1701991     377
Name: 岗位描述, Length: 1701992, dtype: int64
</code></pre></div><br>
<h4 id="242-是否含某个类词">2.4.2 是否含某个(类)词</h4>
<p>岗位描述是否含 <code>抗压能力强</code> 或 <code>压力大</code></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#一个词</span>
<span class="c1">#df[df[&#39;岗位描述&#39;].fillna(&#39;&#39;).str.contains(&#39;抗压能力强&#39;)].head()</span>

<span class="c1">#多个词用|间隔</span>
<span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;岗位描述&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="s1">&#39;抗压能力强|压力大&#39;</span><span class="p">)]</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<p><img loading="lazy" src="img/04-df.png" alt=""  />
</p>
<br>
<p>岗位描述含 <code>抗压能力强|压力大</code> 的工作占比</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;压力占比&#39;</span><span class="p">,</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;岗位描述&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="s1">&#39;抗压能力强|压力大&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;轻松占比&#39;</span><span class="p">,</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;岗位描述&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="s1">&#39;工作轻松|压力小&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">))</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">压力占比 0.012797357449388716
轻松占比 0.018608195573187183
</code></pre></div><p>&hellip;</p>
<h2 id="三获取数据">三、获取数据</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">百度网盘链接: https://pan.baidu.com/s/1arYXcrexLW__SFF5AbjAaA?pwd=sfg5 提取码: sfg5 
</code></pre></div><p>注意:   免费公开，大家可以用来练习Pandas。</p>
<p>该数据集是有偏的， 不太适合做研究。 如果你想用这个数据集做研究， 拿去不谢，但不要加我微信提问呀！！我知道的都在推文里！！</p>
<br>
<br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>数据集(付费) | 三板上市公司年报2002-2023.12</title>
      <link>https://textdata.cn/blog/2024-01-18-neeq-china-listed-on-nation-equities-exchange-and-quotation-system-anunal-year-report/</link>
      <pubDate>Thu, 18 Jan 2024 00:00:00 +0000</pubDate>
      
      <guid>/blog/2024-01-18-neeq-china-listed-on-nation-equities-exchange-and-quotation-system-anunal-year-report/</guid>
      <description>&lt;h2 id=&#34;一数据集&#34;&gt;一、数据集&lt;/h2&gt;
&lt;h3 id=&#34;11-概况&#34;&gt;1.1 概况&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;数据来源: 全国中小企业股份转让系统(https://www.neeq.com.cn/）

覆盖时间: 2002-04-02 ~ 2023-12-06

年报数量: 70838

累积挂牌数量: 13884

数据集体积: 131G

文件格式: pdf、txt、csv(csv是一个汇总文件，方便数据分析)
   
    
csv所含字段:
 - code
 - year
 - text
 
 
 500元，支持开票；加微信 372335839， 备注「姓名-学校-专业」
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/01-dataset.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/02-pdf.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/03-txt.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;br&gt;
&lt;h3 id=&#34;13--注意&#34;&gt;1.3  注意&lt;/h3&gt;
&lt;p&gt;&lt;span style=&#34;font-size: 18px;color: green;&#34;&gt;1. 付费数据集，500元，支持开票；加微信 372335839， 备注「姓名-学校-专业」。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span style=&#34;font-size: 18px;color: green;&#34;&gt;2. 数据是虚拟产品，一经售出，不再退还！&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span style=&#34;font-size: 18px;color: green;&#34;&gt;3. 请仔细阅读推文内容， 再加微信详谈购买事宜 &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;二查看数据&#34;&gt;二、查看数据&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;三板年报.csv.gz&lt;/strong&gt;&lt;/em&gt; 是一个汇总的 csv 文件，特别适合进行数据分析。 解压后大概 15G， 如果你的电脑内存小于32G， &lt;a href=&#34;https://textdata.cn/blog/2023-11-17-how-handle-mega-csv-that-far-exceed-memory/&#34;&gt;推荐阅读 | 如何处理远超电脑内存的csv文件&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;21-读取数据&#34;&gt;2.1 读取数据&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pandas&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pd&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read_csv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;三板年报.csv.gz&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;compression&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;gzip&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;head&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/04-df.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;22-记录数&#34;&gt;2.2 记录数&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;
&lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;70838
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h3 id=&#34;23--累计挂牌企业数量&#34;&gt;2.3  累计挂牌企业数量&lt;/h3&gt;
&lt;p&gt;累计挂牌企业数量&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;code&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;nunique&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;13884
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h3 id=&#34;24-日期范围&#34;&gt;2.4 日期范围&lt;/h3&gt;
&lt;p&gt;数据集覆盖的日期范围&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;date&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;to_datetime&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;date&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;#年报发布日期&lt;/span&gt;
&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;date&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;min&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;())&lt;/span&gt;
&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;date&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;max&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;())&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;2002-04-02
2023-12-06
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h3 id=&#34;25-年度记录数&#34;&gt;2.5 年度记录数&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;year&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;year_df&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;groupby&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;date&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;year&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
    &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;year&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;year_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;2002 5
2003 6
2004 19
2005 29
2006 33
2007 48
2008 59
2009 80
2010 90
2011 107
2012 139
2013 225
2014 732
2015 2336
2016 6874
2017 10811
2018 10948
2019 9258
2020 8400
2021 6859
2022 7019
2023 6761
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;plt&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;matplotlib&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;scienceplots&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;platform&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pandas&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pd&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;matplotlib_inline&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;matplotlib_inline&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;backend_inline&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;set_matplotlib_formats&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;png&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;svg&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;jieba&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;warnings&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;warnings&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;filterwarnings&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;ignore&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;plt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;style&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;use&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;([&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;science&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;no-latex&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;cjk-sc-font&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;system&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;platform&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;system&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;# 获取操作系统类型&lt;/span&gt;
&lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;system&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;Windows&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;font&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;family&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;SimHei&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;span class=&#34;k&#34;&gt;elif&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;system&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;Darwin&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;font&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;family&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;Arial Unicode MS&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;span class=&#34;k&#34;&gt;else&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;font&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;family&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;sans-serif&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;matplotlib&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;rc&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;font&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;font&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;# 设置全局字体&lt;/span&gt;


&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;groupby&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;date&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;year&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;count&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;year&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;plot&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;bar&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;figsize&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;8&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;title&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;三板历年企业年报数&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/05-plot.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;三相关内容&#34;&gt;三、相关内容&lt;/h2&gt;
&lt;p&gt;想用 python 对 csv、xlsx 进行分析， 要学会尽量用 pandas 写代码。 以下是近期 pandas 的一些处理推文免费教程， 感兴趣的可以进去浏览浏览。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/2023-11-17-how-handle-mega-csv-that-far-exceed-memory/&#34;&gt;推荐阅读 | 如何处理远超电脑内存的csv文件&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/2023-03-23-china-a-share-market-dataset-mda-from-01-to-21/&#34;&gt;数据集 | 2001-2022年A股上市公司年报&amp;amp;管理层讨论与分析&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/2023-03-24-load-w2v-and-expand-your-concpet-dicitonary/&#34;&gt;词向量(付费) | 使用MD&amp;amp;A2001-2022语料训练Word2Vec模型&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/2024-01-21-hk-stock-market-anual-report/&#34;&gt;&lt;strong&gt;数据集 | 港股年报文本数据集(2007 ~ 2023.12)&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/2024-01-14-usa-sec-10k-report-dataset/&#34;&gt;&lt;strong&gt;数据集(付费) |  美股年报10-K、20-F数据(2000-2023.12)&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/2024-01-21-hk-stock-market-anual-report/&#34;&gt;数据集 |  港股年报文本数据集(2007 ~ 2023.12)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;四获取数据&#34;&gt;四、获取数据&lt;/h2&gt;
&lt;p&gt;&lt;span style=&#34;font-size: 18px;color: green;&#34;&gt;1. 付费数据集，500元；加微信 372335839， 备注「姓名-学校-专业」。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span style=&#34;font-size: 18px;color: green;&#34;&gt;2. 数据是虚拟产品，一经售出，不再退还！&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span style=&#34;font-size: 18px;color: green;&#34;&gt;3. 请仔细阅读推文内容， 再加微信详谈购买事宜 &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;广而告之&#34;&gt;广而告之&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/call_for_paper/&#34;&gt;长期征稿&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/we_need_you/&#34;&gt;长期招募小伙伴&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/management_python_course/&#34;&gt;付费视频课 | Python实证指标构建与文本分析&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
      <content:encoded><![CDATA[<h2 id="一数据集">一、数据集</h2>
<h3 id="11-概况">1.1 概况</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">数据来源: 全国中小企业股份转让系统(https://www.neeq.com.cn/）

覆盖时间: 2002-04-02 ~ 2023-12-06

年报数量: 70838

累积挂牌数量: 13884

数据集体积: 131G

文件格式: pdf、txt、csv(csv是一个汇总文件，方便数据分析)
   
    
csv所含字段:
 - code
 - year
 - text
 
 
 500元，支持开票；加微信 372335839， 备注「姓名-学校-专业」
</code></pre></div><p><img loading="lazy" src="img/01-dataset.png" alt=""  />
</p>
<p><img loading="lazy" src="img/02-pdf.png" alt=""  />
</p>
<p><img loading="lazy" src="img/03-txt.png" alt=""  />
</p>
<br>
<br>
<h3 id="13--注意">1.3  注意</h3>
<p><span style="font-size: 18px;color: green;">1. 付费数据集，500元，支持开票；加微信 372335839， 备注「姓名-学校-专业」。</span></p>
<p><span style="font-size: 18px;color: green;">2. 数据是虚拟产品，一经售出，不再退还！</span></p>
<p><span style="font-size: 18px;color: green;">3. 请仔细阅读推文内容， 再加微信详谈购买事宜 </span></p>
<p><br><br></p>
<h2 id="二查看数据">二、查看数据</h2>
<p><em><strong>三板年报.csv.gz</strong></em> 是一个汇总的 csv 文件，特别适合进行数据分析。 解压后大概 15G， 如果你的电脑内存小于32G， <a href="https://textdata.cn/blog/2023-11-17-how-handle-mega-csv-that-far-exceed-memory/">推荐阅读 | 如何处理远超电脑内存的csv文件</a></p>
<h3 id="21-读取数据">2.1 读取数据</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;三板年报.csv.gz&#39;</span><span class="p">,</span> <span class="n">compression</span><span class="o">=</span><span class="s1">&#39;gzip&#39;</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/04-df.png" alt=""  />
</p>
<br>
<h3 id="22-记录数">2.2 记录数</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python">
<span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">70838
</code></pre></div><br>
<h3 id="23--累计挂牌企业数量">2.3  累计挂牌企业数量</h3>
<p>累计挂牌企业数量</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df</span><span class="p">[</span><span class="s1">&#39;code&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">nunique</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">13884
</code></pre></div><br>
<h3 id="24-日期范围">2.4 日期范围</h3>
<p>数据集覆盖的日期范围</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df</span><span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">])</span>

<span class="c1">#年报发布日期</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">2002-04-02
2023-12-06
</code></pre></div><br>
<h3 id="25-年度记录数">2.5 年度记录数</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="k">for</span> <span class="n">year</span><span class="p">,</span> <span class="n">year_df</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">dt</span><span class="o">.</span><span class="n">year</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">year</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">year_df</span><span class="p">))</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">2002 5
2003 6
2004 19
2005 29
2006 33
2007 48
2008 59
2009 80
2010 90
2011 107
2012 139
2013 225
2014 732
2015 2336
2016 6874
2017 10811
2018 10948
2019 9258
2020 8400
2021 6859
2022 7019
2023 6761
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">matplotlib</span>
<span class="kn">import</span> <span class="nn">scienceplots</span>
<span class="kn">import</span> <span class="nn">platform</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib_inline</span>
<span class="n">matplotlib_inline</span><span class="o">.</span><span class="n">backend_inline</span><span class="o">.</span><span class="n">set_matplotlib_formats</span><span class="p">(</span><span class="s1">&#39;png&#39;</span><span class="p">,</span> <span class="s1">&#39;svg&#39;</span><span class="p">)</span>
<span class="kn">import</span> <span class="nn">jieba</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">([</span><span class="s1">&#39;science&#39;</span><span class="p">,</span> <span class="s1">&#39;no-latex&#39;</span><span class="p">,</span> <span class="s1">&#39;cjk-sc-font&#39;</span><span class="p">])</span>
<span class="n">system</span> <span class="o">=</span> <span class="n">platform</span><span class="o">.</span><span class="n">system</span><span class="p">()</span>  <span class="c1"># 获取操作系统类型</span>
<span class="k">if</span> <span class="n">system</span> <span class="o">==</span> <span class="s1">&#39;Windows&#39;</span><span class="p">:</span>
    <span class="n">font</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;family&#39;</span><span class="p">:</span> <span class="s1">&#39;SimHei&#39;</span><span class="p">}</span>
<span class="k">elif</span> <span class="n">system</span> <span class="o">==</span> <span class="s1">&#39;Darwin&#39;</span><span class="p">:</span>
    <span class="n">font</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;family&#39;</span><span class="p">:</span> <span class="s1">&#39;Arial Unicode MS&#39;</span><span class="p">}</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">font</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;family&#39;</span><span class="p">:</span> <span class="s1">&#39;sans-serif&#39;</span><span class="p">}</span>
<span class="n">matplotlib</span><span class="o">.</span><span class="n">rc</span><span class="p">(</span><span class="s1">&#39;font&#39;</span><span class="p">,</span> <span class="o">**</span><span class="n">font</span><span class="p">)</span>  <span class="c1"># 设置全局字体</span>


<span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">dt</span><span class="o">.</span><span class="n">year</span><span class="p">)</span><span class="o">.</span><span class="n">count</span><span class="p">()[</span><span class="s1">&#39;year&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s1">&#39;bar&#39;</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">title</span><span class="o">=</span><span class="s1">&#39;三板历年企业年报数&#39;</span><span class="p">)</span>
</code></pre></div><p><img loading="lazy" src="img/05-plot.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="三相关内容">三、相关内容</h2>
<p>想用 python 对 csv、xlsx 进行分析， 要学会尽量用 pandas 写代码。 以下是近期 pandas 的一些处理推文免费教程， 感兴趣的可以进去浏览浏览。</p>
<ul>
<li><a href="https://textdata.cn/blog/2023-11-17-how-handle-mega-csv-that-far-exceed-memory/">推荐阅读 | 如何处理远超电脑内存的csv文件</a></li>
<li><a href="https://textdata.cn/blog/2023-03-23-china-a-share-market-dataset-mda-from-01-to-21/">数据集 | 2001-2022年A股上市公司年报&amp;管理层讨论与分析</a></li>
<li><a href="https://textdata.cn/blog/2023-03-24-load-w2v-and-expand-your-concpet-dicitonary/">词向量(付费) | 使用MD&amp;A2001-2022语料训练Word2Vec模型</a></li>
<li><a href="https://textdata.cn/blog/2024-01-21-hk-stock-market-anual-report/"><strong>数据集 | 港股年报文本数据集(2007 ~ 2023.12)</strong></a></li>
<li><a href="https://textdata.cn/blog/2024-01-14-usa-sec-10k-report-dataset/"><strong>数据集(付费) |  美股年报10-K、20-F数据(2000-2023.12)</strong></a></li>
<li><a href="https://textdata.cn/blog/2024-01-21-hk-stock-market-anual-report/">数据集 |  港股年报文本数据集(2007 ~ 2023.12)</a></li>
</ul>
<p><br><br></p>
<h2 id="四获取数据">四、获取数据</h2>
<p><span style="font-size: 18px;color: green;">1. 付费数据集，500元；加微信 372335839， 备注「姓名-学校-专业」。</span></p>
<p><span style="font-size: 18px;color: green;">2. 数据是虚拟产品，一经售出，不再退还！</span></p>
<p><span style="font-size: 18px;color: green;">3. 请仔细阅读推文内容， 再加微信详谈购买事宜 </span></p>
<p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>cpca库 | 中国省、市区划匹配库</title>
      <link>https://textdata.cn/blog/2024-01-16-cpca-china-province-city-area/</link>
      <pubDate>Tue, 16 Jan 2024 00:00:00 +0000</pubDate>
      
      <guid>/blog/2024-01-16-cpca-china-province-city-area/</guid>
      <description>&lt;p&gt;cpca库， 可提取简体中文字符串中 **省、市和区(县)**区划信息，且能够进行映射，检验和简单绘图。&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;一安装&#34;&gt;一、安装&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;pip3 install jinja2==3.0.1
pip3 install pyecharts==0.5.11
pip3 install echarts-countries-pypkg
pip3 install pyecharts-snapshot
pip3 install cpca
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;二快速上手&#34;&gt;二、快速上手&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;cpca&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;location_str&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;徐汇区虹漕路461号58号楼5楼&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
                &lt;span class=&#34;s2&#34;&gt;&amp;#34;泉州市洛江区万安塘西工业区&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
                &lt;span class=&#34;s2&#34;&gt;&amp;#34;北京朝阳区北苑华贸城&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;cpca&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;transform&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;location_str&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;|    | 省     | 市     | 区     | 地址                 |   adcode |
|---:|:-------|:------|:-------|:--------------------|---------:|
|  0 | 上海市  | 市辖区 |  徐汇区 | 虹漕路461号58号楼5楼   |   310104 |
|  1 | 福建省  | 泉州市 |  洛江区 | 万安塘西工业区         |   350504 |
|  2 | 北京市  | 市辖区 |  朝阳区 | 北苑华贸城            |   110105 |
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;cpca&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;cpca&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;transform&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;([&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;朝阳区汉庭酒店大山子店&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;    &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;省&lt;/span&gt;     &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;市&lt;/span&gt;      &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;区&lt;/span&gt;     &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;    &lt;span class=&#34;n&#34;&gt;地址&lt;/span&gt;          &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;   &lt;span class=&#34;n&#34;&gt;adcode&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;
&lt;span class=&#34;o&#34;&gt;|---&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-------|&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-------|&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-------|&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-----------------|---------&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;
&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;  &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;吉林省&lt;/span&gt;  &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;长春市&lt;/span&gt;  &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;朝阳区&lt;/span&gt;  &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;汉庭酒店大山子店&lt;/span&gt;   &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;   &lt;span class=&#34;mi&#34;&gt;220104&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;p&gt;中国的区级行政单位非常的多，经常有重名的情况，比如 “&lt;em&gt;&lt;strong&gt;北京市朝阳区&lt;/strong&gt;&lt;/em&gt;”和“&lt;em&gt;&lt;strong&gt;吉林省长春市朝阳区&lt;/strong&gt;&lt;/em&gt;”，当有上级地址信息的时候，cpca 能够根据上级地址推断出这是哪个区。但是如果没有上级地址信息，只有一个区名的时候， cpca 就没法推断了，只能随便选一个， 通过 umap 参数你可以指定这种情况下该选择哪一个：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;cpca&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;transform&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;([&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;朝阳区汉庭酒店大山子店&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;umap&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;朝阳区&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;110105&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;})&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;|    | 省     | 市      | 区     |    地址          |   adcode |
|---:|:-------|:-------|:-------|:-----------------|---------:|
|  0 | 北京市  | 市辖区  | 朝阳区  | 汉庭酒店大山子店   |   110105 |
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;br&gt;
&lt;h2 id=&#34;三案例&#34;&gt;三、案例&lt;/h2&gt;
&lt;p&gt;cpca运行速度很快，这里提供了案例数据 &lt;em&gt;&lt;strong&gt;addr.csv&lt;/strong&gt;&lt;/em&gt; , 有 18367  条地址记录。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/DQinYuan/chinese_province_city_area_mapper/blob/master/cpca/resources/adcodes.csv&#34;&gt;https://github.com/DQinYuan/chinese_province_city_area_mapper/blob/master/cpca/resources/adcodes.csv&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;31-读取数据&#34;&gt;3.1 读取数据&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pandas&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pd&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;raw_addr_df&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read_csv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;addr.csv&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;raw_addr_df&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/01-df.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;33--地址操作&#34;&gt;3.3  地址操作&lt;/h3&gt;
&lt;p&gt;生成标准地址信息&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;cpca&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;addr_df&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;cpca&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;transform&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;raw_addr_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;原始地址&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;addr_df&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/03-df.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;33-绘制热力图&#34;&gt;3.3 绘制热力图&lt;/h3&gt;
&lt;p&gt;使用 folium库绘热力图（需要注意，打开 html时，需要有梯子的网络环境）&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;cpca&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;drawer&lt;/span&gt;
&lt;span class=&#34;c1&#34;&gt;#df为上一段代码输出的df&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;drawer&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;draw_locations&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;addr_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;adcode&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;df.html&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;这一段代码运行结束后会在运行代码的当前目录下生成一个df.html文件，用浏览器打开即可看到 绘制好的地图（如果某条数据&amp;rsquo;省&#39;，&amp;lsquo;市&amp;rsquo;或&amp;rsquo;区&amp;rsquo;字段有缺，则会忽略该条数据不进行绘制），速度会比较慢，需要耐心等待，绘制的图像如下：&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/02-folium.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;br&gt;
&lt;h2 id=&#34;广而告之&#34;&gt;广而告之&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/call_for_paper/&#34;&gt;长期征稿&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/we_need_you/&#34;&gt;长期招募小伙伴&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/management_python_course&#34;&gt;&lt;strong&gt;付费视频课 | Python实证指标构建与文本分析&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
      <content:encoded><![CDATA[<p>cpca库， 可提取简体中文字符串中 **省、市和区(县)**区划信息，且能够进行映射，检验和简单绘图。</p>
<p><br><br></p>
<h2 id="一安装">一、安装</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">pip3 install jinja2==3.0.1
pip3 install pyecharts==0.5.11
pip3 install echarts-countries-pypkg
pip3 install pyecharts-snapshot
pip3 install cpca
</code></pre></div><p><br><br></p>
<h2 id="二快速上手">二、快速上手</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cpca</span>

<span class="n">location_str</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&#34;徐汇区虹漕路461号58号楼5楼&#34;</span><span class="p">,</span> 
                <span class="s2">&#34;泉州市洛江区万安塘西工业区&#34;</span><span class="p">,</span> 
                <span class="s2">&#34;北京朝阳区北苑华贸城&#34;</span><span class="p">]</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">cpca</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">location_str</span><span class="p">)</span>
<span class="n">df</span>
</code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">|    | 省     | 市     | 区     | 地址                 |   adcode |
|---:|:-------|:------|:-------|:--------------------|---------:|
|  0 | 上海市  | 市辖区 |  徐汇区 | 虹漕路461号58号楼5楼   |   310104 |
|  1 | 福建省  | 泉州市 |  洛江区 | 万安塘西工业区         |   350504 |
|  2 | 北京市  | 市辖区 |  朝阳区 | 北苑华贸城            |   110105 |
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cpca</span>

<span class="n">cpca</span><span class="o">.</span><span class="n">transform</span><span class="p">([</span><span class="s2">&#34;朝阳区汉庭酒店大山子店&#34;</span><span class="p">])</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="o">|</span>    <span class="o">|</span> <span class="n">省</span>     <span class="o">|</span> <span class="n">市</span>      <span class="o">|</span> <span class="n">区</span>     <span class="o">|</span>    <span class="n">地址</span>          <span class="o">|</span>   <span class="n">adcode</span> <span class="o">|</span>
<span class="o">|---</span><span class="p">:</span><span class="o">|</span><span class="p">:</span><span class="o">-------|</span><span class="p">:</span><span class="o">-------|</span><span class="p">:</span><span class="o">-------|</span><span class="p">:</span><span class="o">-----------------|---------</span><span class="p">:</span><span class="o">|</span>
<span class="o">|</span>  <span class="mi">0</span> <span class="o">|</span> <span class="n">吉林省</span>  <span class="o">|</span> <span class="n">长春市</span>  <span class="o">|</span> <span class="n">朝阳区</span>  <span class="o">|</span> <span class="n">汉庭酒店大山子店</span>   <span class="o">|</span>   <span class="mi">220104</span> <span class="o">|</span>
</code></pre></div><br>
<p>中国的区级行政单位非常的多，经常有重名的情况，比如 “<em><strong>北京市朝阳区</strong></em>”和“<em><strong>吉林省长春市朝阳区</strong></em>”，当有上级地址信息的时候，cpca 能够根据上级地址推断出这是哪个区。但是如果没有上级地址信息，只有一个区名的时候， cpca 就没法推断了，只能随便选一个， 通过 umap 参数你可以指定这种情况下该选择哪一个：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">cpca</span><span class="o">.</span><span class="n">transform</span><span class="p">([</span><span class="s2">&#34;朝阳区汉庭酒店大山子店&#34;</span><span class="p">],</span> <span class="n">umap</span><span class="o">=</span><span class="p">{</span><span class="s2">&#34;朝阳区&#34;</span><span class="p">:</span><span class="s2">&#34;110105&#34;</span><span class="p">})</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">|    | 省     | 市      | 区     |    地址          |   adcode |
|---:|:-------|:-------|:-------|:-----------------|---------:|
|  0 | 北京市  | 市辖区  | 朝阳区  | 汉庭酒店大山子店   |   110105 |
</code></pre></div><br>
<br>
<h2 id="三案例">三、案例</h2>
<p>cpca运行速度很快，这里提供了案例数据 <em><strong>addr.csv</strong></em> , 有 18367  条地址记录。</p>
<blockquote>
<p><a href="https://github.com/DQinYuan/chinese_province_city_area_mapper/blob/master/cpca/resources/adcodes.csv">https://github.com/DQinYuan/chinese_province_city_area_mapper/blob/master/cpca/resources/adcodes.csv</a></p>
</blockquote>
<h3 id="31-读取数据">3.1 读取数据</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">raw_addr_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;addr.csv&#39;</span><span class="p">)</span>
<span class="n">raw_addr_df</span>
</code></pre></div><p><img loading="lazy" src="img/01-df.png" alt=""  />
</p>
<br>
<h3 id="33--地址操作">3.3  地址操作</h3>
<p>生成标准地址信息</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cpca</span>

<span class="n">addr_df</span> <span class="o">=</span> <span class="n">cpca</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">raw_addr_df</span><span class="p">[</span><span class="s1">&#39;原始地址&#39;</span><span class="p">])</span>
<span class="n">addr_df</span>
</code></pre></div><p><img loading="lazy" src="img/03-df.png" alt=""  />
</p>
<br>
<h3 id="33-绘制热力图">3.3 绘制热力图</h3>
<p>使用 folium库绘热力图（需要注意，打开 html时，需要有梯子的网络环境）</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">cpca</span> <span class="kn">import</span> <span class="n">drawer</span>
<span class="c1">#df为上一段代码输出的df</span>
<span class="n">drawer</span><span class="o">.</span><span class="n">draw_locations</span><span class="p">(</span><span class="n">addr_df</span><span class="p">[</span><span class="s1">&#39;adcode&#39;</span><span class="p">],</span> <span class="s2">&#34;df.html&#34;</span><span class="p">)</span>
</code></pre></div><p>这一段代码运行结束后会在运行代码的当前目录下生成一个df.html文件，用浏览器打开即可看到 绘制好的地图（如果某条数据&rsquo;省'，&lsquo;市&rsquo;或&rsquo;区&rsquo;字段有缺，则会忽略该条数据不进行绘制），速度会比较慢，需要耐心等待，绘制的图像如下：</p>
<p><img loading="lazy" src="img/02-folium.png" alt=""  />
</p>
<br>
<br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course"><strong>付费视频课 | Python实证指标构建与文本分析</strong></a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>数据集 |  美股年报10-K、20-F数据(2000-2023.12)</title>
      <link>https://textdata.cn/blog/2024-01-14-usa-sec-10k-report-dataset/</link>
      <pubDate>Sat, 13 Jan 2024 00:00:00 +0000</pubDate>
      
      <guid>/blog/2024-01-14-usa-sec-10k-report-dataset/</guid>
      <description>&lt;h2 id=&#34;一数据集概况&#34;&gt;一、数据集概况&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;数据名称: 美股年报10-K、20-F报告
数据来源: SEC
报告类型: 10-K、20-F
公司数量: 33619
报告数量: 189739
覆盖日期: 2000-07-05 ~ 2024.01.05
数据类型: html、csv(csv是对所有html的汇总文件)
数据体积: 378G

美股年报数据集，500元；加微信 372335839， 备注「姓名-学校-专业」
数据是虚拟产品，一经售出，不再退还！ 请仔细阅读推文内容， 确认无误再加微信详谈购买事宜 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/01-size.jpg&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/02-file.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;p&gt;美股报告是html格式(中国沪深交易所的报告是pdf格式),   可以通过爬虫批量下载所有的报告，并保存为html。&lt;/p&gt;
&lt;p&gt;以苹果公司为例，&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;https://www.sec.gov/Archives/edgar/data/320193/000032019323000106/aapl-20230930.htm
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/03-apple.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;二-html文件&#34;&gt;二、 html文件&lt;/h2&gt;
&lt;p&gt;美股报告数据以html格式存储， 总体积了解其命名规则和处理方式，才能更好的使用该数据集。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/04-2023.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;21-html命名规则&#34;&gt;2.1 html命名规则&lt;/h3&gt;
&lt;p&gt;以 &lt;code&gt;1973368_2023-03-31_SVMH_SRIVARU Holding Ltd_20-F_2023-12-28.html&lt;/code&gt; 为例, html命名遵循CIK码(股票代码)、会计期末、上市公司简称、上市公司全名、Form类型、报告发布日期&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;file&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;1973368_2023-03-31_SVMH_SRIVARU Holding Ltd_20-F_2023-12-28.html&amp;#39;&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;file&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;split&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;_&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;[&amp;#39;1973368&amp;#39;,
 &amp;#39;2023-03-31&amp;#39;,
 &amp;#39;SVMH&amp;#39;,
 &amp;#39;SRIVARU Holding Ltd&amp;#39;,
 &amp;#39;20-F&amp;#39;,
 &amp;#39;2023-12-28.html&amp;#39;]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h3 id=&#34;22-提取文本&#34;&gt;2.2 提取文本&lt;/h3&gt;
&lt;p&gt;如果觉得html不方便分析，可以使用 pyquery、BeautifulSoup等html解析库，提取html中的文本内容。本文以pyquery为例&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pyquery&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;PyQuery&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;file&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;1973368_2023-03-31_SVMH_SRIVARU Holding Ltd_20-F_2023-12-28.html&amp;#39;&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;doc&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;PyQuery&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;open&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;file&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;rb&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;())&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;doc&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;bazadebezolkohpepadr=&amp;#34;608506832&amp;#34;\nfalse\nFY\n0001973368\n0001973368\n2022-04-01\n2023-03-31\n0001973368\ndei:BusinessContactMember\n2022-04-01\n2023-03-31\n0001973368\nSVMHW:OrdinarySharesMember\n2022-04-01\n2023-03-31\n0001973368\nSVMHW:WarrantsMember\n2022-04-01\n2023-03-31\n0001973368\n2023-03-31\n0001973368\n2022-03-31\n0001973368\n2021-06-16\n2022-03-31\n0001973368\nSVMHW:PredecessorMember\n2021-04-01\n2021-06-15\n0001973368\n2021-04-01\n2021-06-15\n0001973368\nSVMHW:PredecessorMember\nus-gaap:CommonStockMember\n2021-03-31\n0001973368\nSVMHW:PredecessorMember\nSVMHW:SharePremiumMember\n2021-03-31\n0001973368\nSVMHW:PredecessorMember\nus-gaap:RetainedEarningsMember\n2021-03-
......
SVMHW:Integer\nxbrli:pure\nUNITED STATES\nSECURITIES AND EXCHANGE COMMISSION\nWASHINGTON, D.C. 20549\nFORM\n20-F\n(Mark One)\n☐\nREGISTRATION STATEMENT PURSUANT TO SECTION 12(b) OR 12(g) OF THE SECURITIES EXCHANGE ACT OF 1934\nOR\n☐\nANNUAL REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE ACT OF 1934\nFor the fiscal year ended\nMarch 31\n,\n2023\nOR\n☐\nTRANSITION REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE ACT OF 1934\nOR\n☒\nSHELL COMPANY REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE ACT OF 1934\nDate of event requiring this shell company report:\nDecember 8, 2023\nCommission File Number:\n333-272717\nSRIVARU Holding Limited\n(Exact name of Registrant as specified in its charter)\nNot applicable\nCayman Islands\n(Translation of Registrant’s name into English)\n(Jurisdiction of incorporation or organization)\n2nd Floor, Regatta Office Park\n,\nWest Bay Road\nP.O. Box 10655\nGrand Cayman\n,\nKY1-1006\nCayman Islands\n(Address of Principal Executive Offices)\nSRIVARU Holding Limited\n2nd Floor, Regatta Office Park,\nWest Bay Road\nP.O. Box 10655\nGrand Cayman\n,\nKY1-1006\nCayman Islands\nTelephone:\n+1 (888)\n227-8066\nEmail: ir@srivarumotors.com\n(Name, Telephone, Email and/or Facsimile number and Address of Company Contact Person)\nSecurities registered or to be registered pursuant to Section 12(b) of the Act:\nTitle of each class\nTrading Symbol(s)\nName of each exchange\non which registered\nOrdinary shares\nSVMH\nThe\nNasdaq\nGlobal Market\nWarrants\nSVMHW\nThe\nNasdaq\nGlobal Market\nSecurities registered or to be registered pursuant to Section 12(g) of the Act:\nNone\n(Title of Class)\nSecurities for which there is a reporting obligation pursuant to Section 15(d) of the Act:\nNone\n(Title of Class)\nIndicate the number of outstanding shares of each of the issuer’s classes of capital or common stock as of the close of the period covered by the shell company report:\n14,946,286\nordinary shares and 10,005,000 warrants.\nIndicate by check mark if the registrant is a well-known seasoned issuer, as defined in Rule 405 of the Securities Act. Yes ☐\nNo\n☒\nIf this report is an annual or transition report, indicate by check mark if the registrant is not required to file reports pursuant to Section 13 or 15(d) of the Securities Exchange Act of 1934. Yes ☐\nNo\n☒\nIndicate by check mark whether the registrant (1) has filed all reports required to be filed by Section 13 or 15(d) of the Securities Exchange Act of 1934 during the preceding 12 months (or for such shorter period that the registrant was required to file such reports), and (2) has been subject to such filing requirements for the past 90 days. Yes ☐\nNo\n☒\nIndicate by check mark whether the registrant has submitted electronically every Interactive Data File required to be submitted pursuant to Rule 405 of Regulation S-T (§232.405 of this chapter) during the preceding 12 months (or for such shorter period that the registrant was required to submit and post such files).\nYes\n☒ No ☐\nIf securities are registered pursuant to Section 12(b) of the Act, indicate by check mark whether the financial statements of the registrant included in the filing reflect the correction of an error to previously issued financial statements.\n☐\nIndicate by check mark whether any of those error corrections are restatements that required a recovery analysis of incentive-based compensation received by any of the registrant’s executive officers during the relevant recovery period pursuant to §240.10D-1(b).\u202f☐\nIndicate by check mark whether the registrant is a large accelerated filer, an accelerated filer, a non-accelerated filer, or an emerging growth company. See definition of “large accelerated filer,” “accelerated filer,” and “emerging growth company” in Rule 12b-2 of the Exchange Act.\nLarge accelerated filer\n☐\nAccelerated filer\n☐\nNon-accelerated filer\n☒\nEmerging growth company\n☒\nIf an emerging growth company that prepares its financial statements in accordance with U.S. GAAP, indicate by check mark if the registrant has elected to use the extended transition period for complying with any new or revised financial accounting standards† provided pursuant to Section 13(a) of the Exchange Act.
......
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;三csv文件&#34;&gt;三、csv文件&lt;/h2&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/02-file.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;h3 id=&#34;31-读取&#34;&gt;3.1 读取&lt;/h3&gt;
&lt;p&gt;csv是对所有html的汇总文件， 如果电脑内存OK， 直接读取 &lt;code&gt;美股年报_10-K和20-F.csv.gz(14.27G，解压后大概50+G)&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;我使用的电内存256G， 读取时间大概17min。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pandas&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pd&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read_csv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;美股年报_10-K和20-F.csv&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;converters&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;cik&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;str&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;})&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/05-df.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;p&gt;常见电脑内存一般8~16G， 可以借鉴这篇推文 &lt;a href=&#34;https://textdata.cn/blog/2023-11-17-how-handle-mega-csv-that-far-exceed-memory/&#34;&gt;&lt;strong&gt;代码 | 如何处理远超电脑内存的csv文件&lt;/strong&gt;&lt;/a&gt;。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pandas&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pd&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;#只读取5行&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;df2&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read_csv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;美股年报_10-K和20-F.csv.gzip&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
                  &lt;span class=&#34;n&#34;&gt;converters&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;cik&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;str&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;},&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;#防止股票代码被识别为数字&lt;/span&gt;
                  &lt;span class=&#34;n&#34;&gt;compression&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;gzip&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
                  &lt;span class=&#34;n&#34;&gt;nrows&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;df2&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/06-nrows5.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;32-公司数量&#34;&gt;3.2 公司数量&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;cik&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;nunique&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;33619
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h3 id=&#34;33-查看content&#34;&gt;3.3 查看content&lt;/h3&gt;
&lt;p&gt;使用df.loc方式查看content字段的内容&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;c1&#34;&gt;#第一行，content字段&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;loc&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;content&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&amp;#39;10-K\n1\nw46943e10-k.txt\nANNUAL REPORT FOR FISCAL YEAR ENDED 12/30/2000\n1 SECURITIES AND EXCHANGE COMMISSION WASHINGTON, D.C. 20549 FORM 10-K (Mark One) [X] Annual report pursuant to section 13 or 15(d) of the Securities Exchange Act of 1934 [NO FEE REQUIRED] for the fiscal year ended December 30, 2000 or [ ] Transition report pursuant to section 13 or 15(d) of the Securities Exchange Act of 1934 [NO FEE REQUIRED] for the transition period from ________ to ________ COMMISSION FILE NUMBER 0-9576 ------ K-TRON INTERNATIONAL, INC. (EXACT NAME OF REGISTRANT AS SPECIFIED IN ITS CHARTER)\nNew Jersey 22-1759452 ------------ ------------\n(State or other jurisdiction of (I.R.S. Employer Identification No.) incorporation or organization)\nRoutes 55 and 553 P.O. Box 888 Pitman, New Jersey 08071-0888 -------------------- ---------- (Address of principal executive offices) (Zip Code) Registrant\&amp;#39;s telephone number, including area code: (856) 589-0500 -------------- Securities registered pursuant to Section 12(b) of the Act:\nTitle of each class Name of each exchange on which registered\nNone None ------------------- -----------------------------------------\nSecurities registered pursuant to Section 12(g) of the Act: Common Stock, par value $.01 per share -------------------------------------- (Title of class) Indicate by check mark whether the Registrant (1) has filed all reports required to be filed by Section 13 or 15(d) of the Securities Exchange Act of 1934 during the preceding 12 months (or for such shorter period that the Registrant was required to file such reports), and (2) has been subject to such filing requirements for the past 90 days. Yes X No --- ---\n2 Indicate by check mark if disclosure of delinquent filers pursuant to Item 405 of Regulation S-K is not contained herein, and will not be contained, to the best of Registrant\&amp;#39;s knowledge, in the definitive proxy statement incorporated by reference in Part III of this annual report on Form 10-K or any amendment to this annual report on Form 10-K. |X| As of February 28, 2001, the aggregate market value of the Common Stock held by non-affiliates of the Registrant was $35,606,718. Such aggregate market value was computed by reference to the closing sale price of the Common Stock as quoted on the Nasdaq National Market on such date. For purposes of making this calculation only, the Registrant has defined affiliates as including all directors and executive ......此处略去无数字
......此处略去无数字
......此处略去无数字

Amendment No. 1 to Employment Agreement dated October 5, 1998 by and between K-Tron International, Inc. and Edward B. Cloues, II (Filed as Exhibit 10.1 to our report on Form 10-Q for the quarterly period ended October 3, 1998 and incorporated herein by reference)** 10.10 Form of Employment Agreement with certain of our employees, which are identical in all material respects except for the employee, amount of salary to be paid and date of execution (Filed as Exhibit 10.12 to our annual report on Form 10-K for the year ended January 3, 1998 and incorporated herein by reference)** 10.11 Form of Indemnification Agreement with certain of our directors and officers listed on Schedule 10.11, which are identical in all material respects except for the director or officer who is a party thereto and the date of execution (Filed as Exhibit 10.11 to the 1999 Form 10-K and incorporated herein by reference)** 10.12 Leasing Agreement dated October 30, 1990 between CS Immobilien Leasing AG, Zurich and Hasler Freres SA, with limited guaranty of K-Tron Soder AG (Filed as Exhibit 10.1(b) to our report on Form 8-K dated October 30, 1990 and incorporated herein by reference) 10.13 Amendment, dated January 25, 1991, to Leasing Agreement, dated October 30, 1990, between CS Immobilien Leasing AG, Zurich and Hasler Freres SA and to the related limited guaranty of K-Tron Soder AG (Filed as Exhibit 10.3.3 to our annual report on Form 10-K for the year ended December 29, 1990 and incorporated herein by reference) 10.14 Note dated February 4, 2000 from K-Tron America, Inc. in favor of The Bank of Gloucester County (Filed as Exhibit (b)(1) on Amendment No.1 to our Tender Offer Statement on Schedule TO dated February 16, 2000 and incorporated herein by reference)\n55 10.15 Mortgage Note dated June 11, 1996 from K-Tron America, Inc. in favor of The Bank of Gloucester County (Filed as Exhibit 10.15 to the 1999 Form 10-K and incorporated herein by reference) 10.16 Loan Modification Agreement dated June 24, 1998 between K-Tron America, Inc. and The Bank of Gloucester County (Filed as Exhibit 10.16 to the 1999 Form 10-K and incorporated herein by reference) 10.17 Note dated June 24, 1998 from K-Tron America, Inc. in favor of The Bank of Gloucester County (Filed as Exhibit 10.17 to the 1999 Form 10-K and incorporated herein by reference) 10.18 Loan Modification Agreement dated as of July 22, 1999 between K-Tron America, Inc. and The Bank of Gloucester County (Filed as Exhibit 10.18 to the 1999 Form 10-K and incorporated herein by reference) 10.19 Loan Modification Agreement dated June 21, 2000 between K-Tron America, Inc. and The Bank of Gloucester County* 21.1 Subsidiaries* 23.1 Consent of Arthur Andersen LLP* 24.1 Power of Attorney (Included on Signature Page)* -------------------- * Filed herewith ** Management contract or compensatory plan or arrangement required to be filed or incorporated as an exhibit&amp;#39;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h3 id=&#34;34-日期&#34;&gt;3.4 日期&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;account_date&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;to_datetime&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;account_date&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;pub_date&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;to_datetime&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;pub_date&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;#会计期末account_date&lt;/span&gt;
&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;account_date&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;min&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;())&lt;/span&gt;
&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;account_date&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;max&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;())&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;2000-01-31 00:00:00
2023-10-31 00:00:00
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;c1&#34;&gt;#报告发布日期&lt;/span&gt;
&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;pub_date&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;min&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;())&lt;/span&gt;
&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;pub_date&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;max&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;())&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;2000-07-05 00:00:00
2024-01-05 00:00:00
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;br&gt;
&lt;h2 id=&#34;四相关内容&#34;&gt;四、相关内容&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/2024-01-21-hk-stock-market-anual-report/&#34;&gt;&lt;strong&gt;数据集 | 港股年报文本数据集(2007 ~ 2023.12)&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/2024-01-18-neeq-china-listed-on-nation-equities-exchange-and-quotation-system-anunal-year-report/&#34;&gt;&lt;strong&gt;数据集(付费) | 三板上市公司年报2002-2023.12&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/2023-03-23-china-a-share-market-dataset-mda-from-01-to-21/&#34;&gt;&lt;strong&gt;数据集 | 2001-2022年A股上市公司年报&amp;amp;管理层讨论与分析&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
&lt;br&gt;
&lt;h2 id=&#34;五获取数据&#34;&gt;五、获取数据&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;美股年报数据集，&lt;strong&gt;500&lt;/strong&gt;元；加微信 372335839， 备注「&lt;strong&gt;姓名-学校-专业&lt;/strong&gt;」。&lt;/li&gt;
&lt;li&gt;数据是虚拟产品，一经售出，不再退还！&lt;/li&gt;
&lt;li&gt;请仔细阅读推文内容， 确认无误再加微信详谈购买事宜&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;广而告之&#34;&gt;广而告之&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/call_for_paper/&#34;&gt;长期征稿&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/we_need_you/&#34;&gt;长期招募小伙伴&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/management_python_course&#34;&gt;&lt;strong&gt;付费视频课 | Python实证指标构建与文本分析&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
      <content:encoded><![CDATA[<h2 id="一数据集概况">一、数据集概况</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">数据名称: 美股年报10-K、20-F报告
数据来源: SEC
报告类型: 10-K、20-F
公司数量: 33619
报告数量: 189739
覆盖日期: 2000-07-05 ~ 2024.01.05
数据类型: html、csv(csv是对所有html的汇总文件)
数据体积: 378G

美股年报数据集，500元；加微信 372335839， 备注「姓名-学校-专业」
数据是虚拟产品，一经售出，不再退还！ 请仔细阅读推文内容， 确认无误再加微信详谈购买事宜 
</code></pre></div><p><img loading="lazy" src="img/01-size.jpg" alt=""  />
</p>
<p><img loading="lazy" src="img/02-file.png" alt=""  />
</p>
<br>
<p>美股报告是html格式(中国沪深交易所的报告是pdf格式),   可以通过爬虫批量下载所有的报告，并保存为html。</p>
<p>以苹果公司为例，</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">https://www.sec.gov/Archives/edgar/data/320193/000032019323000106/aapl-20230930.htm
</code></pre></div><p><img loading="lazy" src="img/03-apple.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="二-html文件">二、 html文件</h2>
<p>美股报告数据以html格式存储， 总体积了解其命名规则和处理方式，才能更好的使用该数据集。</p>
<p><img loading="lazy" src="img/04-2023.png" alt=""  />
</p>
<br>
<h3 id="21-html命名规则">2.1 html命名规则</h3>
<p>以 <code>1973368_2023-03-31_SVMH_SRIVARU Holding Ltd_20-F_2023-12-28.html</code> 为例, html命名遵循CIK码(股票代码)、会计期末、上市公司简称、上市公司全名、Form类型、报告发布日期</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">file</span> <span class="o">=</span> <span class="s1">&#39;1973368_2023-03-31_SVMH_SRIVARU Holding Ltd_20-F_2023-12-28.html&#39;</span>
<span class="n">file</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;_&#39;</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">[&#39;1973368&#39;,
 &#39;2023-03-31&#39;,
 &#39;SVMH&#39;,
 &#39;SRIVARU Holding Ltd&#39;,
 &#39;20-F&#39;,
 &#39;2023-12-28.html&#39;]
</code></pre></div><br>
<h3 id="22-提取文本">2.2 提取文本</h3>
<p>如果觉得html不方便分析，可以使用 pyquery、BeautifulSoup等html解析库，提取html中的文本内容。本文以pyquery为例</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">pyquery</span> <span class="kn">import</span> <span class="n">PyQuery</span>

<span class="n">file</span> <span class="o">=</span> <span class="s1">&#39;1973368_2023-03-31_SVMH_SRIVARU Holding Ltd_20-F_2023-12-28.html&#39;</span>
<span class="n">doc</span> <span class="o">=</span> <span class="n">PyQuery</span><span class="p">(</span><span class="nb">open</span><span class="p">(</span><span class="n">file</span><span class="p">,</span> <span class="s1">&#39;rb&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">read</span><span class="p">())</span>
<span class="n">doc</span><span class="o">.</span><span class="n">text</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">bazadebezolkohpepadr=&#34;608506832&#34;\nfalse\nFY\n0001973368\n0001973368\n2022-04-01\n2023-03-31\n0001973368\ndei:BusinessContactMember\n2022-04-01\n2023-03-31\n0001973368\nSVMHW:OrdinarySharesMember\n2022-04-01\n2023-03-31\n0001973368\nSVMHW:WarrantsMember\n2022-04-01\n2023-03-31\n0001973368\n2023-03-31\n0001973368\n2022-03-31\n0001973368\n2021-06-16\n2022-03-31\n0001973368\nSVMHW:PredecessorMember\n2021-04-01\n2021-06-15\n0001973368\n2021-04-01\n2021-06-15\n0001973368\nSVMHW:PredecessorMember\nus-gaap:CommonStockMember\n2021-03-31\n0001973368\nSVMHW:PredecessorMember\nSVMHW:SharePremiumMember\n2021-03-31\n0001973368\nSVMHW:PredecessorMember\nus-gaap:RetainedEarningsMember\n2021-03-
......
SVMHW:Integer\nxbrli:pure\nUNITED STATES\nSECURITIES AND EXCHANGE COMMISSION\nWASHINGTON, D.C. 20549\nFORM\n20-F\n(Mark One)\n☐\nREGISTRATION STATEMENT PURSUANT TO SECTION 12(b) OR 12(g) OF THE SECURITIES EXCHANGE ACT OF 1934\nOR\n☐\nANNUAL REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE ACT OF 1934\nFor the fiscal year ended\nMarch 31\n,\n2023\nOR\n☐\nTRANSITION REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE ACT OF 1934\nOR\n☒\nSHELL COMPANY REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE ACT OF 1934\nDate of event requiring this shell company report:\nDecember 8, 2023\nCommission File Number:\n333-272717\nSRIVARU Holding Limited\n(Exact name of Registrant as specified in its charter)\nNot applicable\nCayman Islands\n(Translation of Registrant’s name into English)\n(Jurisdiction of incorporation or organization)\n2nd Floor, Regatta Office Park\n,\nWest Bay Road\nP.O. Box 10655\nGrand Cayman\n,\nKY1-1006\nCayman Islands\n(Address of Principal Executive Offices)\nSRIVARU Holding Limited\n2nd Floor, Regatta Office Park,\nWest Bay Road\nP.O. Box 10655\nGrand Cayman\n,\nKY1-1006\nCayman Islands\nTelephone:\n+1 (888)\n227-8066\nEmail: ir@srivarumotors.com\n(Name, Telephone, Email and/or Facsimile number and Address of Company Contact Person)\nSecurities registered or to be registered pursuant to Section 12(b) of the Act:\nTitle of each class\nTrading Symbol(s)\nName of each exchange\non which registered\nOrdinary shares\nSVMH\nThe\nNasdaq\nGlobal Market\nWarrants\nSVMHW\nThe\nNasdaq\nGlobal Market\nSecurities registered or to be registered pursuant to Section 12(g) of the Act:\nNone\n(Title of Class)\nSecurities for which there is a reporting obligation pursuant to Section 15(d) of the Act:\nNone\n(Title of Class)\nIndicate the number of outstanding shares of each of the issuer’s classes of capital or common stock as of the close of the period covered by the shell company report:\n14,946,286\nordinary shares and 10,005,000 warrants.\nIndicate by check mark if the registrant is a well-known seasoned issuer, as defined in Rule 405 of the Securities Act. Yes ☐\nNo\n☒\nIf this report is an annual or transition report, indicate by check mark if the registrant is not required to file reports pursuant to Section 13 or 15(d) of the Securities Exchange Act of 1934. Yes ☐\nNo\n☒\nIndicate by check mark whether the registrant (1) has filed all reports required to be filed by Section 13 or 15(d) of the Securities Exchange Act of 1934 during the preceding 12 months (or for such shorter period that the registrant was required to file such reports), and (2) has been subject to such filing requirements for the past 90 days. Yes ☐\nNo\n☒\nIndicate by check mark whether the registrant has submitted electronically every Interactive Data File required to be submitted pursuant to Rule 405 of Regulation S-T (§232.405 of this chapter) during the preceding 12 months (or for such shorter period that the registrant was required to submit and post such files).\nYes\n☒ No ☐\nIf securities are registered pursuant to Section 12(b) of the Act, indicate by check mark whether the financial statements of the registrant included in the filing reflect the correction of an error to previously issued financial statements.\n☐\nIndicate by check mark whether any of those error corrections are restatements that required a recovery analysis of incentive-based compensation received by any of the registrant’s executive officers during the relevant recovery period pursuant to §240.10D-1(b).\u202f☐\nIndicate by check mark whether the registrant is a large accelerated filer, an accelerated filer, a non-accelerated filer, or an emerging growth company. See definition of “large accelerated filer,” “accelerated filer,” and “emerging growth company” in Rule 12b-2 of the Exchange Act.\nLarge accelerated filer\n☐\nAccelerated filer\n☐\nNon-accelerated filer\n☒\nEmerging growth company\n☒\nIf an emerging growth company that prepares its financial statements in accordance with U.S. GAAP, indicate by check mark if the registrant has elected to use the extended transition period for complying with any new or revised financial accounting standards† provided pursuant to Section 13(a) of the Exchange Act.
......
</code></pre></div><p><br><br></p>
<h2 id="三csv文件">三、csv文件</h2>
<p><img loading="lazy" src="img/02-file.png" alt=""  />
</p>
<h3 id="31-读取">3.1 读取</h3>
<p>csv是对所有html的汇总文件， 如果电脑内存OK， 直接读取 <code>美股年报_10-K和20-F.csv.gz(14.27G，解压后大概50+G)</code>。</p>
<p>我使用的电内存256G， 读取时间大概17min。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;美股年报_10-K和20-F.csv&#39;</span><span class="p">,</span> <span class="n">converters</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;cik&#39;</span><span class="p">:</span> <span class="nb">str</span><span class="p">})</span>
<span class="n">df</span>
</code></pre></div><p><img loading="lazy" src="img/05-df.png" alt=""  />
</p>
<br>
<p>常见电脑内存一般8~16G， 可以借鉴这篇推文 <a href="https://textdata.cn/blog/2023-11-17-how-handle-mega-csv-that-far-exceed-memory/"><strong>代码 | 如何处理远超电脑内存的csv文件</strong></a>。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="c1">#只读取5行</span>
<span class="n">df2</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;美股年报_10-K和20-F.csv.gzip&#39;</span><span class="p">,</span> 
                  <span class="n">converters</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;cik&#39;</span><span class="p">:</span> <span class="nb">str</span><span class="p">},</span> <span class="c1">#防止股票代码被识别为数字</span>
                  <span class="n">compression</span><span class="o">=</span><span class="s1">&#39;gzip&#39;</span><span class="p">,</span> 
                  <span class="n">nrows</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">df2</span>
</code></pre></div><p><img loading="lazy" src="img/06-nrows5.png" alt=""  />
</p>
<br>
<h3 id="32-公司数量">3.2 公司数量</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df</span><span class="p">[</span><span class="s1">&#39;cik&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">nunique</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">33619
</code></pre></div><br>
<h3 id="33-查看content">3.3 查看content</h3>
<p>使用df.loc方式查看content字段的内容</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#第一行，content字段</span>
<span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;content&#39;</span><span class="p">]</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">&#39;10-K\n1\nw46943e10-k.txt\nANNUAL REPORT FOR FISCAL YEAR ENDED 12/30/2000\n1 SECURITIES AND EXCHANGE COMMISSION WASHINGTON, D.C. 20549 FORM 10-K (Mark One) [X] Annual report pursuant to section 13 or 15(d) of the Securities Exchange Act of 1934 [NO FEE REQUIRED] for the fiscal year ended December 30, 2000 or [ ] Transition report pursuant to section 13 or 15(d) of the Securities Exchange Act of 1934 [NO FEE REQUIRED] for the transition period from ________ to ________ COMMISSION FILE NUMBER 0-9576 ------ K-TRON INTERNATIONAL, INC. (EXACT NAME OF REGISTRANT AS SPECIFIED IN ITS CHARTER)\nNew Jersey 22-1759452 ------------ ------------\n(State or other jurisdiction of (I.R.S. Employer Identification No.) incorporation or organization)\nRoutes 55 and 553 P.O. Box 888 Pitman, New Jersey 08071-0888 -------------------- ---------- (Address of principal executive offices) (Zip Code) Registrant\&#39;s telephone number, including area code: (856) 589-0500 -------------- Securities registered pursuant to Section 12(b) of the Act:\nTitle of each class Name of each exchange on which registered\nNone None ------------------- -----------------------------------------\nSecurities registered pursuant to Section 12(g) of the Act: Common Stock, par value $.01 per share -------------------------------------- (Title of class) Indicate by check mark whether the Registrant (1) has filed all reports required to be filed by Section 13 or 15(d) of the Securities Exchange Act of 1934 during the preceding 12 months (or for such shorter period that the Registrant was required to file such reports), and (2) has been subject to such filing requirements for the past 90 days. Yes X No --- ---\n2 Indicate by check mark if disclosure of delinquent filers pursuant to Item 405 of Regulation S-K is not contained herein, and will not be contained, to the best of Registrant\&#39;s knowledge, in the definitive proxy statement incorporated by reference in Part III of this annual report on Form 10-K or any amendment to this annual report on Form 10-K. |X| As of February 28, 2001, the aggregate market value of the Common Stock held by non-affiliates of the Registrant was $35,606,718. Such aggregate market value was computed by reference to the closing sale price of the Common Stock as quoted on the Nasdaq National Market on such date. For purposes of making this calculation only, the Registrant has defined affiliates as including all directors and executive ......此处略去无数字
......此处略去无数字
......此处略去无数字

Amendment No. 1 to Employment Agreement dated October 5, 1998 by and between K-Tron International, Inc. and Edward B. Cloues, II (Filed as Exhibit 10.1 to our report on Form 10-Q for the quarterly period ended October 3, 1998 and incorporated herein by reference)** 10.10 Form of Employment Agreement with certain of our employees, which are identical in all material respects except for the employee, amount of salary to be paid and date of execution (Filed as Exhibit 10.12 to our annual report on Form 10-K for the year ended January 3, 1998 and incorporated herein by reference)** 10.11 Form of Indemnification Agreement with certain of our directors and officers listed on Schedule 10.11, which are identical in all material respects except for the director or officer who is a party thereto and the date of execution (Filed as Exhibit 10.11 to the 1999 Form 10-K and incorporated herein by reference)** 10.12 Leasing Agreement dated October 30, 1990 between CS Immobilien Leasing AG, Zurich and Hasler Freres SA, with limited guaranty of K-Tron Soder AG (Filed as Exhibit 10.1(b) to our report on Form 8-K dated October 30, 1990 and incorporated herein by reference) 10.13 Amendment, dated January 25, 1991, to Leasing Agreement, dated October 30, 1990, between CS Immobilien Leasing AG, Zurich and Hasler Freres SA and to the related limited guaranty of K-Tron Soder AG (Filed as Exhibit 10.3.3 to our annual report on Form 10-K for the year ended December 29, 1990 and incorporated herein by reference) 10.14 Note dated February 4, 2000 from K-Tron America, Inc. in favor of The Bank of Gloucester County (Filed as Exhibit (b)(1) on Amendment No.1 to our Tender Offer Statement on Schedule TO dated February 16, 2000 and incorporated herein by reference)\n55 10.15 Mortgage Note dated June 11, 1996 from K-Tron America, Inc. in favor of The Bank of Gloucester County (Filed as Exhibit 10.15 to the 1999 Form 10-K and incorporated herein by reference) 10.16 Loan Modification Agreement dated June 24, 1998 between K-Tron America, Inc. and The Bank of Gloucester County (Filed as Exhibit 10.16 to the 1999 Form 10-K and incorporated herein by reference) 10.17 Note dated June 24, 1998 from K-Tron America, Inc. in favor of The Bank of Gloucester County (Filed as Exhibit 10.17 to the 1999 Form 10-K and incorporated herein by reference) 10.18 Loan Modification Agreement dated as of July 22, 1999 between K-Tron America, Inc. and The Bank of Gloucester County (Filed as Exhibit 10.18 to the 1999 Form 10-K and incorporated herein by reference) 10.19 Loan Modification Agreement dated June 21, 2000 between K-Tron America, Inc. and The Bank of Gloucester County* 21.1 Subsidiaries* 23.1 Consent of Arthur Andersen LLP* 24.1 Power of Attorney (Included on Signature Page)* -------------------- * Filed herewith ** Management contract or compensatory plan or arrangement required to be filed or incorporated as an exhibit&#39;
</code></pre></div><br>
<h3 id="34-日期">3.4 日期</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df</span><span class="p">[</span><span class="s1">&#39;account_date&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;account_date&#39;</span><span class="p">])</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;pub_date&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;pub_date&#39;</span><span class="p">])</span>

<span class="c1">#会计期末account_date</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;account_date&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;account_date&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">2000-01-31 00:00:00
2023-10-31 00:00:00
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#报告发布日期</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;pub_date&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;pub_date&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">2000-07-05 00:00:00
2024-01-05 00:00:00
</code></pre></div><br>
<br>
<h2 id="四相关内容">四、相关内容</h2>
<ul>
<li><a href="https://textdata.cn/blog/2024-01-21-hk-stock-market-anual-report/"><strong>数据集 | 港股年报文本数据集(2007 ~ 2023.12)</strong></a></li>
<li><a href="https://textdata.cn/blog/2024-01-18-neeq-china-listed-on-nation-equities-exchange-and-quotation-system-anunal-year-report/"><strong>数据集(付费) | 三板上市公司年报2002-2023.12</strong></a></li>
<li><a href="https://textdata.cn/blog/2023-03-23-china-a-share-market-dataset-mda-from-01-to-21/"><strong>数据集 | 2001-2022年A股上市公司年报&amp;管理层讨论与分析</strong></a></li>
</ul>
<br>
<br>
<h2 id="五获取数据">五、获取数据</h2>
<ol>
<li>美股年报数据集，<strong>500</strong>元；加微信 372335839， 备注「<strong>姓名-学校-专业</strong>」。</li>
<li>数据是虚拟产品，一经售出，不再退还！</li>
<li>请仔细阅读推文内容， 确认无误再加微信详谈购买事宜</li>
</ol>
<p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course"><strong>付费视频课 | Python实证指标构建与文本分析</strong></a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>数据集 |  5.6亿条海关数据集(2000-2021.3 商品hs编码已统一)</title>
      <link>https://textdata.cn/blog/2024-01-06-china-export-import-dataset/</link>
      <pubDate>Sat, 06 Jan 2024 00:00:00 +0000</pubDate>
      
      <guid>/blog/2024-01-06-china-export-import-dataset/</guid>
      <description>5.6亿条海关数据集(2000-2021.3 商品hs编码已统一)</description>
      <content:encoded><![CDATA[<h2 id="一海关数据集">一、海关数据集</h2>
<h3 id="11-数据概况">1.1 数据概况</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">覆盖时间: 2000 ~ 2021.3
记录条数: 562453390 (5.6亿条)
数据格式: csv文件(utf-8编码)
HS编码:  所有年份均统一为1996年HS编码(6位数)

海关数据集，300元；加微信 372335839， 备注「姓名-学校-专业」
</code></pre></div><p>数据是虚拟产品，一经售出，不再退还！ 请仔细阅读推文内容， 确认无误再加微信详谈购买事宜</p>
<br>
<h3 id="12-有何不同">1.2 有何不同？</h3>
<p>目前市面上售卖的海关数据，格式未做编码统一、文件格式统一、字段统一(对齐)。 所以大概率会遇到以下问题， 如 PYTHON 读取 dta 文件乱码、 Mac 电脑打不开 mdb ， 体验下来的感觉是数据很脏，格式很乱， 老子宁可买贵买个一步到位。</p>
<br>
<p>注意, 大邓卖的这个数据集跟市面上数据集的信息量是一样的，区别在于大邓用了三个整天时间把数据集变的干净整洁了:</p>
<ol>
<li>将 dta、mdb 等文件格式统一为编码 utf-8 的 csv 文件</li>
<li>不同年份的字段命名统一，并进行了字段对齐</li>
<li>新设字段 <strong>hs96_6</strong>， 将 2000-2021.3 中所有的商品hs编码统一为1996版的HS编码</li>
</ol>
<br>
<h3 id="13-字段含义">1.3 字段含义</h3>
<p>字段含义如下</p>
<ul>
<li><strong>exp_or_imp</strong> 进口/出口</li>
<li><strong>date</strong> 日期，有的年份是year-month， 有的年份数据只有year</li>
<li><strong>hs</strong> 商品编码，不同年份采用的hs编码系统不同， 有hs1996/hs2002/2012/2017四种。</li>
<li><strong>hsdetail</strong>  商品详情</li>
<li><strong>value</strong>  货值， 默认是美元计价</li>
<li><strong>quantity</strong> 数量</li>
<li><strong>unit</strong> 计量单位</li>
<li><strong>country</strong> 起运国/目的国</li>
<li><strong>shipment</strong> 贸易方式</li>
<li><strong>port</strong> 海关</li>
<li><strong>transportation</strong> 运输方式</li>
<li><strong>routing</strong> 中转国</li>
<li><strong>company</strong> 公司</li>
<li><strong>companytype</strong> 公司性质</li>
<li><strong>address</strong> 地址</li>
<li><strong>fax</strong> 传真</li>
<li><strong>tel</strong> 电话</li>
<li><strong>zip</strong> 邮编</li>
<li><strong>email</strong> 邮箱</li>
<li><strong>contacts</strong> 联系人</li>
<li><strong>city</strong> 消费地进口/生产地出口</li>
<li><strong>hs96</strong> 商品1996年HS编码(2000-2021统一用HS96编码)</li>
</ul>
 <br>
<h3 id="14-各年份字段">1.4 各年份字段</h3>
<p>每个年份的所含字段不同</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">[&#39;2007&#39;]
exp_or_imp date hs hsdetail value quantity unit country shipment port transportation routing partyid company companytype address fax tel zip email contacts city hs96


[&#39;2000&#39;, &#39;2001&#39;, &#39;2002&#39;, &#39;2003&#39;, &#39;2004&#39;, &#39;2005&#39;, &#39;2006&#39;, &#39;2008&#39;, &#39;2009&#39;, &#39;2010&#39;, &#39;2011&#39;, &#39;2012&#39;, &#39;2013&#39;, &#39;2014&#39;]
exp_or_imp date hs hsdetail value quantity unit country shipment port transportation routing company companytype address fax tel zip email contacts city hs96


[&#39;2014&#39;]
exp_or_imp date hs hsdetail value quantity unit country shipment transportation company hs96


[&#39;2016&#39;]
exp_or_imp date hs hsdetail value country shipment company hs96


[&#39;2017&#39;, &#39;2018&#39;, &#39;2019&#39;, &#39;2020&#39;, &#39;2021&#39;]
exp_or_imp date hs hsdetail value quantity unit country shipment currency address quantity2 unit2 hs96
</code></pre></div><p><br><br></p>
<h2 id="二查看数据">二、查看数据</h2>
<p>数据集均为 csv 格式， 按年份进行整理的数据。csv按照体量有两种</p>
<ul>
<li>千万级记录的全年csv， 如 <strong>full2000.csv.gz</strong></li>
<li>100w条记录量的小csv， 如 <strong>2000_0.csv.gz</strong></li>
</ul>
<p><img loading="lazy" src="img/01-dataset.png" alt=""  />
</p>
<br>
<p><img loading="lazy" src="img/02-gzip2csv.png" alt=""  />
</p>
<p>注意 <em><strong>gz</strong></em> 解压后， 一般文件体积会放大 8 倍左右。</p>
<br>
<h3 id="21-查看大文件">2.1 查看大文件</h3>
<p>电脑内存16G以上，可以直接读取按年份存储的大csv文件(gz解压后得到csv文件)</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">glob</span>

<span class="nb">sorted</span><span class="p">(</span><span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="s1">&#39;*.csv.gz&#39;</span><span class="p">))</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">[&#39;full2000.csv.gz&#39;,
 &#39;full2001.csv.gz&#39;,
 &#39;full2002.csv.gz&#39;,
 &#39;full2003.csv.gz&#39;,
 &#39;full2004.csv.gz&#39;,
 &#39;full2005.csv.gz&#39;,
 &#39;full2006.csv.gz&#39;,
 &#39;full2007.csv.gz&#39;,
 &#39;full2008.csv.gz&#39;,
 &#39;full2009.csv.gz&#39;,
 &#39;full2010.csv.gz&#39;,
 &#39;full2011.csv.gz&#39;,
 &#39;full2012.csv.gz&#39;,
 &#39;full2013.csv.gz&#39;,
 &#39;full2014.csv.gz&#39;,
 &#39;full2015.csv.gz&#39;,
 &#39;full2016.csv.gz&#39;,
 &#39;full2017.csv.gz&#39;,
 &#39;full2018.csv.gz&#39;,
 &#39;full2019.csv.gz&#39;,
 &#39;full2020.csv.gz&#39;,
 &#39;part2021.csv.gz&#39;]
</code></pre></div><br>
<h3 id="22-小文件">2.2 小文件</h3>
<p>如果想了解数据，或者电脑内存较小，可以选择这种小文件(每个csv文件100w条记录)</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">glob</span>

<span class="c1">#572个小文件</span>
<span class="nb">sorted</span><span class="p">(</span><span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="s1">&#39;*/*.csv.gz&#39;</span><span class="p">))</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">[&#39;2000/2000_0.csv.gz&#39;,
 &#39;2000/2000_1.csv.gz&#39;,
 &#39;2000/2000_10.csv.gz&#39;,
 &#39;2000/2000_2.csv.gz&#39;,
 &#39;2000/2000_3.csv.gz&#39;,
 &#39;2000/2000_4.csv.gz&#39;,
 &#39;2000/2000_5.csv.gz&#39;,
 &#39;2000/2000_6.csv.gz&#39;,
 &#39;2000/2000_7.csv.gz&#39;,
 &#39;2000/2000_8.csv.gz&#39;,
 &#39;2000/2000_9.csv.gz&#39;,
 &#39;2001/2001_0.csv.gz&#39;,
 &#39;2001/2001_1.csv.gz&#39;,
 &#39;2001/2001_10.csv.gz&#39;,
 ...
 ...
&#39;2020/2020_68.csv.gz&#39;,
 &#39;2020/2020_7.csv.gz&#39;,
 &#39;2020/2020_8.csv.gz&#39;,
 &#39;2020/2020_9.csv.gz&#39;,
 &#39;2021/2021_0.csv.gz&#39;,
 &#39;2021/2021_1.csv.gz&#39;,
 &#39;2021/2021_10.csv.gz&#39;,
 &#39;2021/2021_11.csv.gz&#39;,
 &#39;2021/2021_12.csv.gz&#39;,
 &#39;2021/2021_13.csv.gz&#39;,
 &#39;2021/2021_14.csv.gz&#39;,
 &#39;2021/2021_15.csv.gz&#39;,
 &#39;2021/2021_16.csv.gz&#39;,
 &#39;2021/2021_17.csv.gz&#39;,
 &#39;2021/2021_18.csv.gz&#39;,
 &#39;2021/2021_2.csv.gz&#39;,
 &#39;2021/2021_3.csv.gz&#39;,
 &#39;2021/2021_4.csv.gz&#39;,
 &#39;2021/2021_5.csv.gz&#39;,
 &#39;2021/2021_6.csv.gz&#39;,
 &#39;2021/2021_7.csv.gz&#39;,
 &#39;2021/2021_8.csv.gz&#39;,
 &#39;2021/2021_9.csv.gz&#39;]
</code></pre></div> <br>
<h3 id="23-记录数">2.3 记录数</h3>
<p>不同年份， 记录数统计。为了提高统计速度， 每个大文件，只读取了 date 字段</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">glob</span>

<span class="c1"># 查看每年记录数</span>
<span class="n">csvfs</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="s1">&#39;*.csv.gz&#39;</span><span class="p">))</span>
<span class="k">for</span> <span class="n">csvf</span> <span class="ow">in</span> <span class="n">csvfs</span><span class="p">:</span><span class="c1">#, converters={&#39;hs&#39;:str}</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">csvf</span><span class="p">,</span> <span class="n">compression</span><span class="o">=</span><span class="s1">&#39;gzip&#39;</span><span class="p">,</span> <span class="n">usecols</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">])</span>
    <span class="n">year</span> <span class="o">=</span> <span class="n">csvf</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;.csv.gz&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;full&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">year</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">))</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">2000 10598247
2001 12682006
2002 13843463
2003 16616696
2004 19703008
2005 22819289
2006 25661754
2007 10635560
2008 11230600
2009 11341519
2010 13351580
2011 14288585
2012 15933823
2013 16662038
2014 17515154
2015 17515154
2016 17288381
2017 65783926
2018 69038499
2019 72391866
2020 68603295
2021 18668460
</code></pre></div><br>
<h3 id="24-字段详情">2.4 字段详情</h3>
<p>数据集有几种字段体系</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">glob</span>

<span class="c1"># 查看字段</span>
<span class="n">dfs</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">csvfs</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="s1">&#39;*.csv.gz&#39;</span><span class="p">))</span>
<span class="k">for</span> <span class="n">csvf</span> <span class="ow">in</span> <span class="n">csvfs</span><span class="p">:</span><span class="c1">#, converters={&#39;hs&#39;:str}</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">csvf</span><span class="p">,</span> <span class="n">compression</span><span class="o">=</span><span class="s1">&#39;gzip&#39;</span><span class="p">,</span> <span class="n">nrows</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">dfs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
    
<span class="n">fieldtext_set</span> <span class="o">=</span> <span class="nb">set</span><span class="p">([</span><span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span> <span class="k">for</span> <span class="n">df</span> <span class="ow">in</span> <span class="n">dfs</span><span class="p">])</span>
<span class="n">fieldtext_set</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">{&#39;exp_or_imp date hs hsdetail value country shipment company hs96&#39;,

 &#39;exp_or_imp date hs hsdetail value quantity unit country shipment currency address quantity2 unit2 hs96&#39;,
 
 &#39;exp_or_imp date hs hsdetail value quantity unit country shipment port transportation routing company companytype address fax tel zip email contacts city hs96&#39;,
 
 &#39;exp_or_imp date hs hsdetail value quantity unit country shipment port transportation routing partyid company companytype address fax tel zip email contacts city hs96&#39;,
 
 &#39;exp_or_imp date hs hsdetail value quantity unit country shipment transportation company hs96&#39;}
</code></pre></div><br>
<p>不同年份， 分别存储了哪些字段</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="k">for</span> <span class="n">field_text</span> <span class="ow">in</span> <span class="n">fieldtext_set</span><span class="p">:</span>
    <span class="n">years</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">df</span> <span class="ow">in</span> <span class="n">dfs</span><span class="p">:</span>
        <span class="k">if</span> <span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span><span class="o">==</span><span class="n">field_text</span><span class="p">:</span>
            <span class="n">year</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="mi">0</span><span class="p">])[:</span><span class="mi">4</span><span class="p">]</span>
            <span class="n">years</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">year</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">years</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">field_text</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">[&#39;2007&#39;]
exp_or_imp date hs hsdetail value quantity unit country shipment port transportation routing partyid company companytype address fax tel zip email contacts city hs96


[&#39;2014&#39;]
exp_or_imp date hs hsdetail value quantity unit country shipment transportation company hs96


[&#39;2016&#39;]
exp_or_imp date hs hsdetail value country shipment company hs96


[&#39;2017&#39;, &#39;2018&#39;, &#39;2019&#39;, &#39;2020&#39;, &#39;2021&#39;]
exp_or_imp date hs hsdetail value quantity unit country shipment currency address quantity2 unit2 hs96


[&#39;2000&#39;, &#39;2001&#39;, &#39;2002&#39;, &#39;2003&#39;, &#39;2004&#39;, &#39;2005&#39;, &#39;2006&#39;, &#39;2008&#39;, &#39;2009&#39;, &#39;2010&#39;, &#39;2011&#39;, &#39;2012&#39;, &#39;2013&#39;, &#39;2014&#39;]
exp_or_imp date hs hsdetail value quantity unit country shipment port transportation routing company companytype address fax tel zip email contacts city hs96
</code></pre></div><p><br><br></p>
<h2 id="三实验代码">三、实验代码</h2>
<p>数据集文件的体量比较大， 使用 PYTHON 处理时，可参照<a href="https://textdata.cn/blog/2023-11-17-how-handle-mega-csv-that-far-exceed-memory/"><strong>如何处理远超电脑内存的csv文件</strong></a> 进行数据分析。</p>
<br>
<h3 id="31-读取前-5-条记录">3.1 读取前 5 条记录</h3>
<p>先读取 2014年前 5 条记录，</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">df2014</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;full2014.csv.gz&#39;</span><span class="p">,</span> <span class="n">compression</span><span class="o">=</span><span class="s1">&#39;gzip&#39;</span><span class="p">,</span> <span class="n">nrows</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="c1">#df2014 = pd.read_csv(&#39;full2014.csv&#39;, nrows=5)</span>
<span class="n">df2014</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/03-df.png" alt=""  />
</p>
<br>
<h3 id="32-获取所有字段">3.2 获取所有字段</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df2014</span><span class="o">.</span><span class="n">columns</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">Index([&#39;exp_or_imp&#39;, &#39;date&#39;, &#39;hs&#39;, &#39;hsdetail&#39;, &#39;value&#39;, &#39;quantity&#39;, &#39;unit&#39;,
       &#39;country&#39;, &#39;shipment&#39;, &#39;port&#39;, &#39;transportation&#39;, &#39;routing&#39;, &#39;company&#39;,
       &#39;companytype&#39;, &#39;address&#39;, &#39;fax&#39;, &#39;tel&#39;, &#39;zip&#39;, &#39;email&#39;, &#39;contacts&#39;,
       &#39;city&#39;, &#39;hs96&#39;],
      dtype=&#39;object&#39;)
</code></pre></div><br>
<h3 id="33-读取指定字段数据">3.3 读取指定字段数据</h3>
<p>为了减轻内存压力，可以选择部分字段usecols进行读取, nrows记录数参数可以同时起作用。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df2014_</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;full2014.csv.gz&#39;</span><span class="p">,</span> 
                      <span class="n">usecols</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">,</span> <span class="s1">&#39;hs&#39;</span><span class="p">,</span> <span class="s1">&#39;hsdetail&#39;</span><span class="p">,</span> <span class="s1">&#39;value&#39;</span><span class="p">,</span> <span class="s1">&#39;address&#39;</span><span class="p">,</span> <span class="s1">&#39;hs96&#39;</span><span class="p">,</span> <span class="s1">&#39;exp_or_imp&#39;</span><span class="p">],</span>
                      <span class="n">compression</span><span class="o">=</span><span class="s1">&#39;gzip&#39;</span><span class="p">,</span> 
                      <span class="n">nrows</span><span class="o">=</span><span class="mi">1000000</span><span class="p">,</span> 
                      <span class="p">)</span>

<span class="c1">#df2014_ = pd.read_csv(&#39;full2014.csv&#39;,</span>
<span class="c1">#                      usecols = [&#39;date&#39;, &#39;hs&#39;, &#39;hsdetail&#39;, &#39;value&#39;, &#39;address&#39;, &#39;hs96&#39;, &#39;exp_or_imp&#39;],</span>
<span class="c1">#                      nrows=1000000)</span>

<span class="n">df2014_</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/04-df.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#记录数</span>
<span class="nb">len</span><span class="p">(</span><span class="n">df2014_</span><span class="p">)</span>
</code></pre></div><p>1000000</p>
<br>
<h3 id="34-含某类-关键词的记录">3.4 含某(类) 关键词的记录</h3>
<p>筛选出感兴趣的产品记录， 例如筛选出 2014 年 <code>键盘、鼠标、显示器</code> 等产品的进出口</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">mask1</span> <span class="o">=</span> <span class="n">df2014_</span><span class="p">[</span><span class="s1">&#39;hsdetail&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="s1">&#39;键盘|鼠标|显示器&#39;</span><span class="p">)</span>
<span class="n">df2014_</span><span class="p">[</span><span class="n">mask1</span><span class="p">]</span>
</code></pre></div><p><img loading="lazy" src="img/05-df.png" alt=""  />
</p>
<br>
<h3 id="35--多条件筛选">3.5  多条件筛选</h3>
<p>筛选出 2014 年 <code>键盘、鼠标、显示器</code> 金额大于10000美元的进口记录 。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">mask1</span> <span class="o">=</span> <span class="n">df2014_</span><span class="p">[</span><span class="s1">&#39;hsdetail&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="s1">&#39;键盘|鼠标|显示器&#39;</span><span class="p">)</span>
<span class="n">mask2</span> <span class="o">=</span> <span class="p">(</span><span class="n">df2014_</span><span class="p">[</span><span class="s1">&#39;exp_or_imp&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;进口&#39;</span><span class="p">)</span>
<span class="n">mask3</span> <span class="o">=</span> <span class="p">(</span><span class="n">df2014_</span><span class="p">[</span><span class="s1">&#39;value&#39;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">10000</span><span class="p">)</span>

<span class="n">df2014_</span><span class="p">[</span><span class="n">mask1</span> <span class="o">&amp;</span> <span class="n">mask2</span> <span class="o">&amp;</span> <span class="n">mask3</span><span class="p">]</span>
</code></pre></div><p><img loading="lazy" src="img/06-df.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="四数据获取">四、数据获取</h2>
<h3 id="41-收费说明">4.1 收费说明</h3>
<ol>
<li>海关数据集，<strong>300</strong>元；加微信 372335839， 备注「<strong>姓名-学校-专业</strong>」。</li>
<li>数据是虚拟产品，一经售出，不再退还！</li>
<li>请仔细阅读推文内容， 确认无误再加微信详谈购买事宜</li>
</ol>
<br>
<h3 id="42-样例数据">4.2 样例数据</h3>
<p>提供样例数据供大家下载检查   链接: <a href="https://pan.baidu.com/s/1nBcQ63z8n_hqdtkb84_VjA?pwd=p2gk">https://pan.baidu.com/s/1nBcQ63z8n_hqdtkb84_VjA?pwd=p2gk</a> 提取码: p2gk</p>
<p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course"><strong>付费视频课 | Python实证指标构建与文本分析</strong></a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>数据集 | 36330条上市公司仲裁数据(2000-2021)</title>
      <link>https://textdata.cn/blog/2024-01-03-listed-company-arbitration-dataset/</link>
      <pubDate>Wed, 03 Jan 2024 00:00:00 +0000</pubDate>
      
      <guid>/blog/2024-01-03-listed-company-arbitration-dataset/</guid>
      <description>&lt;h2 id=&#34;一数据介绍&#34;&gt;一、数据介绍&lt;/h2&gt;
&lt;h3 id=&#34;11-数据集概况&#34;&gt;1.1 数据集概况&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;- 数据集名: 上市公司仲裁数据
- 时间跨度: 2000-01-26 ~ 2021-09-28
- 案件数据: 36330
- 数据来源: 裁判文书网

  获取数据  20元；加微信 372335839， 备注「姓名-学校-专业」。
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;数据整理自&lt;a href=&#34;https://textdata.cn/blog/2023-05-07-china-law-judgment-documents-datasets/&#34;&gt;数据集(付费) | 中国裁判文书网(2010-2021)&lt;/a&gt;&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;12-用途&#34;&gt;1.2 用途&lt;/h3&gt;
&lt;p&gt;上市公司仲裁数据可用于衡量上市公司法律风险等，&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;[1]冯延超,梁莱歆.上市公司法律风险、审计收费及非标准审计意见——来自中国上市公司的经验证据[J].审计研究,2010(03):75-81.
[2]祝继高.会计稳健性与债权人利益保护——基于银行与上市公司关于贷款的法律诉讼的研究[J].会计研究,2011(05):50-57+96.
[3]辛宇,黄欣怡,纪蓓蓓.投资者保护公益组织与股东诉讼在中国的实践——基于中证投服证券支持诉讼的多案例研究[J].管理世界,2020,36(01):69-87+235.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;br&gt;
&lt;h3 id=&#34;13-字段&#34;&gt;1.3 字段&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt; -  公告日期
 -  股票代码
 -  股票简称
 -  涉案类型
 -  原告被告
 -  案件案由
 -  涉案金额
 -  判决情况
 -  执行情况
 -  货币种类
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;二查看数据&#34;&gt;二、查看数据&lt;/h2&gt;
&lt;h3 id=&#34;21-读取数据&#34;&gt;2.1 读取数据&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pandas&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pd&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read_excel&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;上市公司仲裁数据2000-2021.xlsx&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;公告日期&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;to_datetime&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;公告日期&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;head&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/01-df.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;22-记录数&#34;&gt;2.2 记录数&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;36330
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h3 id=&#34;23-公司数&#34;&gt;2.3 公司数&lt;/h3&gt;
&lt;p&gt;涉案的上市公司数量&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;股票代码&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;nunique&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;2251
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h3 id=&#34;2-4-覆盖日期&#34;&gt;2. 4 覆盖日期&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;公告日期&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;min&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;())&lt;/span&gt;
&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;公告日期&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;max&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;())&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;2000-01-26 00:00:00
2021-09-28 00:00:00
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h3 id=&#34;25-字段缺失率&#34;&gt;2.5 字段&amp;amp;缺失率&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;col&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;columns&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;ratio&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;col&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;isna&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sum&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
    &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;col&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ratio&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;公告日期 0.0
股票代码 0.0
股票简称 2.7525461051472613e-05
涉案类型 0.0002202036884117809
原告被告 0.001568951279933939
案件案由 0.00013762730525736306
涉案金额 0.00016515276630883568
判决情况 0.8911643270024773
执行情况 0.740765207817231
货币种类 0.0
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;br&gt;
&lt;h2 id=&#34;三获取数据&#34;&gt;三、获取数据&lt;/h2&gt;
&lt;p&gt;&lt;span style=&#34;font-size: 18px;color: green;&#34;&gt;1. 付费数据集，20元；加微信 372335839， 备注「姓名-学校-专业」。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span style=&#34;font-size: 18px;color: green;&#34;&gt;2. 数据是虚拟产品，一经售出，不再退还！&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span style=&#34;font-size: 18px;color: green;&#34;&gt;3. 请仔细阅读推文内容， 再加微信详谈购买事宜  &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;广而告之&#34;&gt;广而告之&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/call_for_paper/&#34;&gt;长期征稿&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/we_need_you/&#34;&gt;长期招募小伙伴&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/management_python_course/&#34;&gt;付费视频课 | Python实证指标构建与文本分析&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
      <content:encoded><![CDATA[<h2 id="一数据介绍">一、数据介绍</h2>
<h3 id="11-数据集概况">1.1 数据集概况</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">- 数据集名: 上市公司仲裁数据
- 时间跨度: 2000-01-26 ~ 2021-09-28
- 案件数据: 36330
- 数据来源: 裁判文书网

  获取数据  20元；加微信 372335839， 备注「姓名-学校-专业」。
</code></pre></div><p>数据整理自<a href="https://textdata.cn/blog/2023-05-07-china-law-judgment-documents-datasets/">数据集(付费) | 中国裁判文书网(2010-2021)</a></p>
<br>
<h3 id="12-用途">1.2 用途</h3>
<p>上市公司仲裁数据可用于衡量上市公司法律风险等，</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">[1]冯延超,梁莱歆.上市公司法律风险、审计收费及非标准审计意见——来自中国上市公司的经验证据[J].审计研究,2010(03):75-81.
[2]祝继高.会计稳健性与债权人利益保护——基于银行与上市公司关于贷款的法律诉讼的研究[J].会计研究,2011(05):50-57+96.
[3]辛宇,黄欣怡,纪蓓蓓.投资者保护公益组织与股东诉讼在中国的实践——基于中证投服证券支持诉讼的多案例研究[J].管理世界,2020,36(01):69-87+235.
</code></pre></div><br>
<br>
<h3 id="13-字段">1.3 字段</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"> -  公告日期
 -  股票代码
 -  股票简称
 -  涉案类型
 -  原告被告
 -  案件案由
 -  涉案金额
 -  判决情况
 -  执行情况
 -  货币种类
</code></pre></div><p><br><br></p>
<h2 id="二查看数据">二、查看数据</h2>
<h3 id="21-读取数据">2.1 读取数据</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_excel</span><span class="p">(</span><span class="s1">&#39;上市公司仲裁数据2000-2021.xlsx&#39;</span><span class="p">)</span>

<span class="n">df</span><span class="p">[</span><span class="s1">&#39;公告日期&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;公告日期&#39;</span><span class="p">])</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/01-df.png" alt=""  />
</p>
<br>
<h3 id="22-记录数">2.2 记录数</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">36330
</code></pre></div><br>
<h3 id="23-公司数">2.3 公司数</h3>
<p>涉案的上市公司数量</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df</span><span class="p">[</span><span class="s1">&#39;股票代码&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">nunique</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">2251
</code></pre></div><br>
<h3 id="2-4-覆盖日期">2. 4 覆盖日期</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;公告日期&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;公告日期&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">2000-01-26 00:00:00
2021-09-28 00:00:00
</code></pre></div><br>
<h3 id="25-字段缺失率">2.5 字段&amp;缺失率</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
    <span class="n">ratio</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">isna</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">col</span><span class="p">,</span> <span class="n">ratio</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">公告日期 0.0
股票代码 0.0
股票简称 2.7525461051472613e-05
涉案类型 0.0002202036884117809
原告被告 0.001568951279933939
案件案由 0.00013762730525736306
涉案金额 0.00016515276630883568
判决情况 0.8911643270024773
执行情况 0.740765207817231
货币种类 0.0
</code></pre></div><br>
<br>
<h2 id="三获取数据">三、获取数据</h2>
<p><span style="font-size: 18px;color: green;">1. 付费数据集，20元；加微信 372335839， 备注「姓名-学校-专业」。</span></p>
<p><span style="font-size: 18px;color: green;">2. 数据是虚拟产品，一经售出，不再退还！</span></p>
<p><span style="font-size: 18px;color: green;">3. 请仔细阅读推文内容， 再加微信详谈购买事宜  </span></p>
<p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>词向量  | 使用人民网领导留言板语料训练Word2Vec模型</title>
      <link>https://textdata.cn/blog/2023-12-28-train-word2vec-using-renmin-gov-leader-board-dataset/</link>
      <pubDate>Thu, 28 Dec 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-12-28-train-word2vec-using-renmin-gov-leader-board-dataset/</guid>
      <description>&lt;p&gt;本文使用 3.88G 语料训练得到词汇量近 150w 的 Word2Vec 模型，使用该模型，可以用于寻找近义词，扩展(构建)概念词典。 &lt;strong&gt;该Word2Vec模型文件可在文末免费下载&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;一构建语料&#34;&gt;一、构建语料&lt;/h2&gt;
&lt;p&gt;使用 &lt;a href=&#34;https://textdata.cn/blog/2023-12-22-renmin-gov-leader-comment-board/&#34;&gt;&lt;strong&gt;数据集(付费) | 人民网地方领导留言板原始文本(2011-2023.12)&lt;/strong&gt;&lt;/a&gt; 来构建本文的语料。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pandas&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pd&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;df1&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read_csv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;2011-2019.csv.gzip&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;compression&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;gzip&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;df2&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read_csv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;2020-2023.csv.gzip&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;compression&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;gzip&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;


&lt;span class=&#34;n&#34;&gt;text_series1&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;df1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;留言内容&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;df1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;回复内容&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;text_series1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fillna&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;inplace&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;text_series2&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;df2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;留言内容&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;df2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;回复内容&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;text_series2&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fillna&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;inplace&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;

&lt;span class=&#34;k&#34;&gt;with&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;open&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;renmin_board.txt&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;a+&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;encoding&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;utf-8&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;text&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;join&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;text_series1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;tolist&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;())&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;join&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;text_series2&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;tolist&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;())&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;write&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;最终得到 3.88 G 的 &lt;strong&gt;renmin_board.txt&lt;/strong&gt; 。&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;二训练模型&#34;&gt;二、训练模型&lt;/h2&gt;
&lt;h3 id=&#34;21-配置cntext&#34;&gt;2.1 配置cntext&lt;/h3&gt;
&lt;p&gt;使用 cntext 2.0.0 或者 cntext 2.1.0 ， 已购买 cntext2.0.0 的同学可以找我更新至 2.1.0 ，微信372335839， 备注「姓名-学校-专业」。&lt;/p&gt;
&lt;p&gt;将 &lt;strong&gt;cntext-2.1.0-py3-none-any.whl&lt;/strong&gt; 放置于桌面， 打开 **命令行cmd **(苹果电脑terminal)，依次执行以下命令&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;cd&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;desktop&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;pip3&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;install&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;cntext&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;2.1.0&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;py3&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;none&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;any&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;whl&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h3 id=&#34;22-训练word2vec&#34;&gt;2.2 训练Word2Vec&lt;/h3&gt;
&lt;p&gt;训练 word2vec 代码已封装 cntext2， 所以代码很简洁，只有三行代码。&lt;/p&gt;
&lt;p&gt;训练环境win11,  内存128G。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;cntext&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;ct&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;w2v_model&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ct&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;W2vModel&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;corpus_file&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;renmin_board.txt&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;lang&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;chinese&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;w2v_model&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;train&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;window_size&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;6&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;vector_size&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;200&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;renmin_board.txt

Start Preprocessing Corpus...
Start Training! This may take a while. Please be patient...

Training word2vec model took 12779 seconds

Note: The Word2Vec model has been saved to output/Word2Vec
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;使用 3.88G 的renmin_board.txt，训练了 12779 秒， 约 3.5 小时。在Python代码文件所在的文件夹内，出现了 output/Word2Vec 文件夹，打开可以看到训练好的模型， 可以看出模型文件的体量还是很大的。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/02-word2vec.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;三使用模型&#34;&gt;三、使用模型&lt;/h2&gt;
&lt;h3 id=&#34;31-读取模型&#34;&gt;3.1 读取模型&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;cntext&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ct&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;w2v&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ct&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;load_w2v&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;output/Word2Vec/renmin_board.200.6.bin&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;w2v&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;Loading word2vec model...
&amp;lt;gensim.models.word2vec.Word2Vec at 0x2a11dfad0&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h3 id=&#34;32-模型词汇量&#34;&gt;3.2 模型词汇量&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;c1&#34;&gt;#词汇量&lt;/span&gt;
&lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;w2v&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;1499961
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h3 id=&#34;33-查看词表&#34;&gt;3.3 查看词表&lt;/h3&gt;
&lt;p&gt;因为词表有 1499961 个词， 为了方便，这里只显示前20个词&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;##词表带顺序的
list(w2v.wv.key_to_index.keys())[:20]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;[&amp;#39; &amp;#39;,
 &amp;#39;\n&amp;#39;,
 &amp;#39;问题&amp;#39;,
 &amp;#39;进行&amp;#39;,
 &amp;#39;小区&amp;#39;,
 &amp;#39;工作&amp;#39;,
 &amp;#39;”&amp;#39;,
 &amp;#39;没有&amp;#39;,
 &amp;#39;情况&amp;#39;,
 &amp;#39;目前&amp;#39;,
 &amp;#39;反映&amp;#39;,
 &amp;#39;业主&amp;#39;,
 &amp;#39;项目&amp;#39;,
 &amp;#39;要求&amp;#39;,
 &amp;#39;“&amp;#39;,
 &amp;#39;公司&amp;#39;,
 &amp;#39;网友您好&amp;#39;,
 &amp;#39;现在&amp;#39;,
 &amp;#39;建设&amp;#39;,
 &amp;#39;反映问题&amp;#39;]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h3 id=&#34;34-获取某词的向量&#34;&gt;3.4 获取某词的向量&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;c1&#34;&gt;#w2v.wv[&amp;#39;利民&amp;#39;]&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;w2v&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;get_vector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;利民&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;array([-0.72336054,  0.5448769 ,  0.02187554,  0.18723099,  0.10518928,
       -0.4829346 ,  1.2029709 ,  1.325142  ,  1.7153364 , -0.9134816 ,
        0.21033671, -0.05412149,  0.1750608 ,  0.36092624,  0.24550831,
        0.02644009,  0.95183885, -1.0317421 , -0.10972459, -2.5780423 ,
       -0.89232576, -1.043176  ,  0.72673726, -0.17512426, -0.24233247,
        0.2569658 , -1.0063888 ,  0.5180029 ,  0.83510065,  0.8907923 ,
       -0.24386375, -0.53083295, -1.5156878 , -0.9040948 ,  0.25330988,
       -0.79177266,  0.06866979,  0.6199285 ,  0.9562961 ,  3.6091647 ,
       -1.3558179 ,  1.4279033 , -0.6923549 ,  0.17637855,  0.6416902 ,
        0.8726301 , -0.8316238 ,  0.8974303 , -1.342718  ,  0.3960099 ,
        0.7404184 ,  0.41476634,  0.5397854 , -0.9964916 ,  0.72252625,
       -0.24338841, -1.1583921 , -0.8719721 , -0.1476895 ,  0.4893649 ,
        1.0152714 , -3.2469108 ,  0.61867106, -1.1033677 ,  0.7277995 ,
        0.68194056,  1.9562886 , -2.0847485 ,  1.5790684 ,  0.9881281 ,
       -1.6833613 ,  0.52788144,  0.81453127, -0.72605026,  0.67317885,
        0.4130878 ,  0.5682669 , -0.14777663,  0.6144105 , -0.6402672 ,
       -0.8752994 ,  1.6374044 , -0.66893923,  0.5865543 ,  0.6375472 ,
       -0.99829054, -1.0806116 ,  2.6740906 , -0.7968034 , -0.39872456,
       -2.0882657 ,  0.4091569 ,  0.44333985,  0.80311924, -0.02302606,
       -0.2762922 ,  0.172768  ,  2.2813802 , -0.39281502,  0.57268375,
        1.4626628 , -0.14473361,  0.5739576 ,  0.61773837, -0.18331125,
        1.2602748 ,  0.9424055 ,  1.5969577 ,  0.6106542 , -2.7610633 ,
       -1.1409078 , -1.7803516 , -0.3264908 ,  1.2968934 ,  0.7250817 ,
        0.0589628 ,  0.42458364, -0.3242822 , -2.6474693 ,  0.3660026 ,
        0.5749114 ,  0.1812738 ,  0.34291452, -0.20228535,  0.40417868,
        0.06284425,  0.7266579 ,  1.5118539 ,  2.0363107 , -1.1808697 ,
       -0.19834429, -1.105297  ,  0.7594476 , -0.90230256,  0.13537973,
        1.5452795 ,  1.3571783 ,  0.15807565, -1.0794616 ,  2.3592122 ,
        0.62628454, -0.61704504,  0.65674806, -0.91116625, -2.1521432 ,
       -0.08805666, -0.6956923 , -1.4443843 , -0.84095645,  0.64748996,
       -0.7432282 ,  1.7160741 ,  1.1697325 ,  1.0834908 , -1.0323627 ,
       -1.3480235 ,  1.004517  , -0.40515316,  0.38016117,  1.6717825 ,
       -0.40651798,  1.0373042 ,  0.24744533, -2.353417  ,  0.06758213,
        0.34440002,  0.8656946 ,  0.76431715, -1.7378451 ,  1.2329959 ,
       -1.4538856 ,  1.0956937 ,  0.6151345 ,  2.4905207 , -0.24415112,
       -0.23886327,  0.09834331,  0.00791643, -0.53527415,  0.7039957 ,
        0.83675224, -1.5712336 , -0.14135051,  0.34811664,  0.41304144,
        0.78504366, -0.13325912, -0.9898512 , -0.497319  , -0.32992417,
       -0.58120775,  0.29686695, -0.9618549 ,  0.39253774,  0.14620592,
       -0.45337242,  0.69179136,  0.1934781 , -2.0494404 ,  1.8545331 ],
      dtype=float32)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;p&gt;需要注意，如果查询的词不存在于模型词表，则会出现报错。例如&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;word = &amp;#39;这是一个不存在的词&amp;#39;
w2v.wv.get_vector(word)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;---------------------------------------------------------------------------
KeyError                                  Traceback (most recent call last)
Cell In[130], line 2
      1 word = &amp;#39;这是一个不存在的词&amp;#39;
----&amp;gt; 2 w2v.wv.get_vector(word)

File /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/gensim/models/keyedvectors.py:446, in KeyedVectors.get_vector(self, key, norm)
    422 def get_vector(self, key, norm=False):
    423     &amp;#34;&amp;#34;&amp;#34;Get the key&amp;#39;s vector, as a 1D numpy array.
    424 
    425     Parameters
   (...)
    444 
    445     &amp;#34;&amp;#34;&amp;#34;
--&amp;gt; 446     index = self.get_index(key)
    447     if norm:
    448         self.fill_norms()

File /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/gensim/models/keyedvectors.py:420, in KeyedVectors.get_index(self, key, default)
    418     return default
    419 else:
--&amp;gt; 420     raise KeyError(f&amp;#34;Key &amp;#39;{key}&amp;#39; not present&amp;#34;)

KeyError: &amp;#34;Key &amp;#39;这是一个不存在的词&amp;#39; not present&amp;#34;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h3 id=&#34;35-查询近义词&#34;&gt;3.5 查询近义词&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;w2v.wv.most_similar(positive=None, topn=10)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;positive 待查的词语列表或者词向量&lt;/li&gt;
&lt;li&gt;topn 显示返回多少个近义词&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;351-使用词语列表查询&#34;&gt;3.5.1 使用词语列表查询&lt;/h4&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;w2v&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;most_similar&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;([&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;经济&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;建设&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;发展&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt; 
                    &lt;span class=&#34;n&#34;&gt;topn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;20&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;[(&amp;#39;经济发展&amp;#39;, 0.7514141201972961),
 (&amp;#39;产业发展&amp;#39;, 0.6954267024993896),
 (&amp;#39;发展壮大&amp;#39;, 0.6707271337509155),
 (&amp;#39;社会发展&amp;#39;, 0.6637671589851379),
 (&amp;#39;发展重要&amp;#39;, 0.6603672504425049),
 (&amp;#39;城镇化发展&amp;#39;, 0.6574274301528931),
 (&amp;#39;城市发展&amp;#39;, 0.6558148264884949),
 (&amp;#39;高质量发展&amp;#39;, 0.6517276167869568),
 (&amp;#39;大力发展&amp;#39;, 0.6500106453895569),
 (&amp;#39;产业&amp;#39;, 0.6494895219802856),
 (&amp;#39;发展产业&amp;#39;, 0.6458864212036133),
 (&amp;#39;壮大&amp;#39;, 0.6379123330116272),
 (&amp;#39;发展带动&amp;#39;, 0.6357436776161194),
 (&amp;#39;未来发展&amp;#39;, 0.6351119875907898),
 (&amp;#39;第三产业&amp;#39;, 0.6345765590667725),
 (&amp;#39;经济增长&amp;#39;, 0.6329594850540161),
 (&amp;#39;改革开放&amp;#39;, 0.6297498345375061),
 (&amp;#39;融合发展&amp;#39;, 0.6290864944458008),
 (&amp;#39;长远发展&amp;#39;, 0.6279110908508301),
 (&amp;#39;经济繁荣&amp;#39;, 0.627375602722168)]

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h3 id=&#34;352-使用词向量查询&#34;&gt;3.5.2 使用词向量查询&lt;/h3&gt;
&lt;p&gt;先构建一个函数concept_vector，该函数可以将多个词转化为一个向量。 遇到词语不在词表中的异常，也能正常运行。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;numpy&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;np&lt;/span&gt;


&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;concept_vector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;words&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;container&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;np&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;zeros&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;200&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
    &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;word&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;words&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
        &lt;span class=&#34;k&#34;&gt;try&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
            &lt;span class=&#34;n&#34;&gt;container&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;container&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;w2v&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;get_vector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;word&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
        &lt;span class=&#34;k&#34;&gt;except&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
            &lt;span class=&#34;k&#34;&gt;pass&lt;/span&gt;
    &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;container&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;words&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
  
  
&lt;span class=&#34;n&#34;&gt;word_vec&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;concept_vector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;words&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;她&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;她们&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;母亲&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;奶奶&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;女性&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;女人&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
&lt;span class=&#34;c1&#34;&gt;#查找与word_vec近义词10个词&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;w2v&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;most_similar&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;word_vec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
                    &lt;span class=&#34;n&#34;&gt;topn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;[(&amp;#39;奶奶&amp;#39;, 0.9064152836799622),
 (&amp;#39;母亲&amp;#39;, 0.9003509879112244),
 (&amp;#39;爷爷&amp;#39;, 0.8559296131134033),
 (&amp;#39;婆婆&amp;#39;, 0.846263587474823),
 (&amp;#39;我妈&amp;#39;, 0.8314375877380371),
 (&amp;#39;老伴&amp;#39;, 0.8306034803390503),
 (&amp;#39;老父亲&amp;#39;, 0.8257972598075867),
 (&amp;#39;姥爷&amp;#39;, 0.8255906701087952),
 (&amp;#39;父亲&amp;#39;, 0.821728527545929),
 (&amp;#39;女孩&amp;#39;, 0.8210363984107971)]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;四-相关&#34;&gt;四、 相关&lt;/h2&gt;
&lt;h3 id=&#34;41-文献资料&#34;&gt;4.1 文献资料&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;郑石明, 兰雨潇, 黎枫. 网络公共舆论与政府回应的互动逻辑——基于新冠肺炎疫情期间“领导留言板”的数据分析[J]. 公共管理学报, 2021, 18 (03): 24-37+169.
王磊,易扬.公共卫生危机中的数字政府回应如何纾解网络负面舆情——基于人民网“领导留言板”回复情况的调查[J].公共管理学报,2022,19(04):65-78+169.
Lu, Liangdong, Jia Xu, and Jiuchang Wei. &amp;#34;Understanding the effects of the textual complexity on government communication: Insights from China’s online public service platform.&amp;#34; Telematics and Informatics 83 (2023): 102028.
...
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h3 id=&#34;42-代码资料&#34;&gt;4.2 代码资料&lt;/h3&gt;
&lt;p&gt;想用 python 对 csv、xlsx 进行分析， 要学会尽量用 pandas 写代码。 以下是近期 pandas 的一些处理推文免费教程， 感兴趣的可以进去浏览浏览。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://textdata.cn/blog/2023-12-17-how-to-generate-panel-data-from-gov-report-dataset/&#34;&gt;&lt;strong&gt;代码 | 使用地方gov工作报告生成某类概念词频「面板数据」&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://textdata.cn/blog/2023-12-18-how-to-generate-panel-data-from-daily-news-dataset/&#34;&gt;&lt;strong&gt;代码 | 使用「新闻数据」构造概念词提及量「面板数据」&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://textdata.cn/blog/2023-02-26-cctv1-xwlb-news-text-dataset/&#34;&gt;&lt;strong&gt;数据代码| 使用cctv新闻联播文稿构造「面板数据」&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://textdata.cn/blog/2028-12-18-how-to-extract-data-from-patent-application-dataset/&#34;&gt;&lt;strong&gt;代码 | 使用3571w专利申请数据集构造「面板数据」&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://textdata.cn/blog/2023-12-20-measure-china-economic-policy-uncertainty/&#34;&gt;&lt;strong&gt;代码 | 使用「新闻数据」计算 「经济政策不确定性」指数&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://textdata.cn/blog/2023-03-15-39faq-about-word-embeddings-for-social-science/&#34;&gt;词嵌入技术在社会科学领域进行数据挖掘常见39个FAQ汇总&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://textdata.cn/blog/2023-11-03-organization-science-with-word-embeddings/&#34;&gt;OS2022 | 概念空间 | 词嵌入模型如何为组织科学中的测量和理论提供信息&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;数据集(付费) | 人民网地方领导留言板原始文本(2011-2023.12)  2023-12-22-renmin-gov-leader-comment-board&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;五获取资料&#34;&gt;五、获取资料&lt;/h2&gt;
&lt;h3 id=&#34;51-免费资料&#34;&gt;5.1 免费资料&lt;/h3&gt;
&lt;p&gt;本文训练所得的 &lt;strong&gt;renmin_board.200.6.bin模型文件&lt;/strong&gt; 免费开源，&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/02-word2vec.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;链接: &lt;a href=&#34;https://pan.baidu.com/s/1u-eUuATCTSIDjhOvSaG7sA?pwd=whf5&#34;&gt;https://pan.baidu.com/s/1u-eUuATCTSIDjhOvSaG7sA?pwd=whf5&lt;/a&gt; 提取码: whf5&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;52-付费资料&#34;&gt;5.2 付费资料&lt;/h3&gt;
&lt;p&gt;&lt;span style=&#34;font-size: 18px;color: green;&#34;&gt;1.  &lt;a href=&#34;https://textdata.cn/blog/2023-12-22-renmin-gov-leader-comment-board/&#34;&gt;数据集(付费) | 人民网地方领导留言板原始文本(2011-2023.12)&lt;/a&gt; ，2000元&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span style=&#34;font-size: 18px;color: green;&#34;&gt;2. cntext2.1.0 价格100元，已购买2.0.0可免费更新至2.1.0&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span style=&#34;font-size: 18px;color: green;&#34;&gt;3. 数据是虚拟产品，一经售出，不再退还！&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span style=&#34;font-size: 18px;color: green;&#34;&gt;4. 大家时间其实都很宝贵，请仔细阅读推文内容， 确认无误再加微信372335839， 备注「姓名-学校-专业」详谈购买事宜 &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;广而告之&#34;&gt;广而告之&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/call_for_paper/&#34;&gt;长期征稿&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/we_need_you/&#34;&gt;长期招募小伙伴&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/management_python_course/&#34;&gt;付费视频课 | Python实证指标构建与文本分析&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
      <content:encoded><![CDATA[<p>本文使用 3.88G 语料训练得到词汇量近 150w 的 Word2Vec 模型，使用该模型，可以用于寻找近义词，扩展(构建)概念词典。 <strong>该Word2Vec模型文件可在文末免费下载</strong></p>
<p><br><br></p>
<h2 id="一构建语料">一、构建语料</h2>
<p>使用 <a href="https://textdata.cn/blog/2023-12-22-renmin-gov-leader-comment-board/"><strong>数据集(付费) | 人民网地方领导留言板原始文本(2011-2023.12)</strong></a> 来构建本文的语料。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">df1</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;2011-2019.csv.gzip&#39;</span><span class="p">,</span> <span class="n">compression</span><span class="o">=</span><span class="s1">&#39;gzip&#39;</span><span class="p">)</span>
<span class="n">df2</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;2020-2023.csv.gzip&#39;</span><span class="p">,</span> <span class="n">compression</span><span class="o">=</span><span class="s1">&#39;gzip&#39;</span><span class="p">)</span>


<span class="n">text_series1</span> <span class="o">=</span> <span class="n">df1</span><span class="p">[</span><span class="s1">&#39;留言内容&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="n">df1</span><span class="p">[</span><span class="s1">&#39;回复内容&#39;</span><span class="p">]</span>
<span class="n">text_series1</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">text_series2</span> <span class="o">=</span> <span class="n">df2</span><span class="p">[</span><span class="s1">&#39;留言内容&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="n">df2</span><span class="p">[</span><span class="s1">&#39;回复内容&#39;</span><span class="p">]</span>
<span class="n">text_series2</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;renmin_board.txt&#39;</span><span class="p">,</span> <span class="s1">&#39;a+&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">text</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">text_series1</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span> <span class="o">+</span> <span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">text_series2</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span>
    <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
</code></pre></div><p>最终得到 3.88 G 的 <strong>renmin_board.txt</strong> 。</p>
<p><br><br></p>
<h2 id="二训练模型">二、训练模型</h2>
<h3 id="21-配置cntext">2.1 配置cntext</h3>
<p>使用 cntext 2.0.0 或者 cntext 2.1.0 ， 已购买 cntext2.0.0 的同学可以找我更新至 2.1.0 ，微信372335839， 备注「姓名-学校-专业」。</p>
<p>将 <strong>cntext-2.1.0-py3-none-any.whl</strong> 放置于桌面， 打开 **命令行cmd **(苹果电脑terminal)，依次执行以下命令</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">cd</span> <span class="n">desktop</span>
<span class="n">pip3</span> <span class="n">install</span> <span class="n">cntext</span><span class="o">-</span><span class="mf">2.1.0</span><span class="o">-</span><span class="n">py3</span><span class="o">-</span><span class="n">none</span><span class="o">-</span><span class="nb">any</span><span class="o">.</span><span class="n">whl</span>
</code></pre></div><br>
<h3 id="22-训练word2vec">2.2 训练Word2Vec</h3>
<p>训练 word2vec 代码已封装 cntext2， 所以代码很简洁，只有三行代码。</p>
<p>训练环境win11,  内存128G。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>

<span class="n">w2v_model</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">W2vModel</span><span class="p">(</span><span class="n">corpus_file</span><span class="o">=</span><span class="s1">&#39;renmin_board.txt&#39;</span><span class="p">,</span> <span class="n">lang</span><span class="o">=</span><span class="s1">&#39;chinese&#39;</span><span class="p">)</span>
<span class="n">w2v_model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">window_size</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">vector_size</span><span class="o">=</span><span class="mi">200</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">renmin_board.txt

Start Preprocessing Corpus...
Start Training! This may take a while. Please be patient...

Training word2vec model took 12779 seconds

Note: The Word2Vec model has been saved to output/Word2Vec
</code></pre></div><p>使用 3.88G 的renmin_board.txt，训练了 12779 秒， 约 3.5 小时。在Python代码文件所在的文件夹内，出现了 output/Word2Vec 文件夹，打开可以看到训练好的模型， 可以看出模型文件的体量还是很大的。</p>
<p><img loading="lazy" src="img/02-word2vec.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="三使用模型">三、使用模型</h2>
<h3 id="31-读取模型">3.1 读取模型</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cntext</span> <span class="n">ct</span>

<span class="n">w2v</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">load_w2v</span><span class="p">(</span><span class="s1">&#39;output/Word2Vec/renmin_board.200.6.bin&#39;</span><span class="p">)</span>
<span class="n">w2v</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">Loading word2vec model...
&lt;gensim.models.word2vec.Word2Vec at 0x2a11dfad0&gt;
</code></pre></div><br>
<h3 id="32-模型词汇量">3.2 模型词汇量</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#词汇量</span>
<span class="nb">len</span><span class="p">(</span><span class="n">w2v</span><span class="o">.</span><span class="n">wv</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">1499961
</code></pre></div><br>
<h3 id="33-查看词表">3.3 查看词表</h3>
<p>因为词表有 1499961 个词， 为了方便，这里只显示前20个词</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">##词表带顺序的
list(w2v.wv.key_to_index.keys())[:20]
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">[&#39; &#39;,
 &#39;\n&#39;,
 &#39;问题&#39;,
 &#39;进行&#39;,
 &#39;小区&#39;,
 &#39;工作&#39;,
 &#39;”&#39;,
 &#39;没有&#39;,
 &#39;情况&#39;,
 &#39;目前&#39;,
 &#39;反映&#39;,
 &#39;业主&#39;,
 &#39;项目&#39;,
 &#39;要求&#39;,
 &#39;“&#39;,
 &#39;公司&#39;,
 &#39;网友您好&#39;,
 &#39;现在&#39;,
 &#39;建设&#39;,
 &#39;反映问题&#39;]
</code></pre></div><br>
<h3 id="34-获取某词的向量">3.4 获取某词的向量</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#w2v.wv[&#39;利民&#39;]</span>
<span class="n">w2v</span><span class="o">.</span><span class="n">wv</span><span class="o">.</span><span class="n">get_vector</span><span class="p">(</span><span class="s1">&#39;利民&#39;</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">array([-0.72336054,  0.5448769 ,  0.02187554,  0.18723099,  0.10518928,
       -0.4829346 ,  1.2029709 ,  1.325142  ,  1.7153364 , -0.9134816 ,
        0.21033671, -0.05412149,  0.1750608 ,  0.36092624,  0.24550831,
        0.02644009,  0.95183885, -1.0317421 , -0.10972459, -2.5780423 ,
       -0.89232576, -1.043176  ,  0.72673726, -0.17512426, -0.24233247,
        0.2569658 , -1.0063888 ,  0.5180029 ,  0.83510065,  0.8907923 ,
       -0.24386375, -0.53083295, -1.5156878 , -0.9040948 ,  0.25330988,
       -0.79177266,  0.06866979,  0.6199285 ,  0.9562961 ,  3.6091647 ,
       -1.3558179 ,  1.4279033 , -0.6923549 ,  0.17637855,  0.6416902 ,
        0.8726301 , -0.8316238 ,  0.8974303 , -1.342718  ,  0.3960099 ,
        0.7404184 ,  0.41476634,  0.5397854 , -0.9964916 ,  0.72252625,
       -0.24338841, -1.1583921 , -0.8719721 , -0.1476895 ,  0.4893649 ,
        1.0152714 , -3.2469108 ,  0.61867106, -1.1033677 ,  0.7277995 ,
        0.68194056,  1.9562886 , -2.0847485 ,  1.5790684 ,  0.9881281 ,
       -1.6833613 ,  0.52788144,  0.81453127, -0.72605026,  0.67317885,
        0.4130878 ,  0.5682669 , -0.14777663,  0.6144105 , -0.6402672 ,
       -0.8752994 ,  1.6374044 , -0.66893923,  0.5865543 ,  0.6375472 ,
       -0.99829054, -1.0806116 ,  2.6740906 , -0.7968034 , -0.39872456,
       -2.0882657 ,  0.4091569 ,  0.44333985,  0.80311924, -0.02302606,
       -0.2762922 ,  0.172768  ,  2.2813802 , -0.39281502,  0.57268375,
        1.4626628 , -0.14473361,  0.5739576 ,  0.61773837, -0.18331125,
        1.2602748 ,  0.9424055 ,  1.5969577 ,  0.6106542 , -2.7610633 ,
       -1.1409078 , -1.7803516 , -0.3264908 ,  1.2968934 ,  0.7250817 ,
        0.0589628 ,  0.42458364, -0.3242822 , -2.6474693 ,  0.3660026 ,
        0.5749114 ,  0.1812738 ,  0.34291452, -0.20228535,  0.40417868,
        0.06284425,  0.7266579 ,  1.5118539 ,  2.0363107 , -1.1808697 ,
       -0.19834429, -1.105297  ,  0.7594476 , -0.90230256,  0.13537973,
        1.5452795 ,  1.3571783 ,  0.15807565, -1.0794616 ,  2.3592122 ,
        0.62628454, -0.61704504,  0.65674806, -0.91116625, -2.1521432 ,
       -0.08805666, -0.6956923 , -1.4443843 , -0.84095645,  0.64748996,
       -0.7432282 ,  1.7160741 ,  1.1697325 ,  1.0834908 , -1.0323627 ,
       -1.3480235 ,  1.004517  , -0.40515316,  0.38016117,  1.6717825 ,
       -0.40651798,  1.0373042 ,  0.24744533, -2.353417  ,  0.06758213,
        0.34440002,  0.8656946 ,  0.76431715, -1.7378451 ,  1.2329959 ,
       -1.4538856 ,  1.0956937 ,  0.6151345 ,  2.4905207 , -0.24415112,
       -0.23886327,  0.09834331,  0.00791643, -0.53527415,  0.7039957 ,
        0.83675224, -1.5712336 , -0.14135051,  0.34811664,  0.41304144,
        0.78504366, -0.13325912, -0.9898512 , -0.497319  , -0.32992417,
       -0.58120775,  0.29686695, -0.9618549 ,  0.39253774,  0.14620592,
       -0.45337242,  0.69179136,  0.1934781 , -2.0494404 ,  1.8545331 ],
      dtype=float32)
</code></pre></div><br>
<p>需要注意，如果查询的词不存在于模型词表，则会出现报错。例如</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">word = &#39;这是一个不存在的词&#39;
w2v.wv.get_vector(word)
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">---------------------------------------------------------------------------
KeyError                                  Traceback (most recent call last)
Cell In[130], line 2
      1 word = &#39;这是一个不存在的词&#39;
----&gt; 2 w2v.wv.get_vector(word)

File /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/gensim/models/keyedvectors.py:446, in KeyedVectors.get_vector(self, key, norm)
    422 def get_vector(self, key, norm=False):
    423     &#34;&#34;&#34;Get the key&#39;s vector, as a 1D numpy array.
    424 
    425     Parameters
   (...)
    444 
    445     &#34;&#34;&#34;
--&gt; 446     index = self.get_index(key)
    447     if norm:
    448         self.fill_norms()

File /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/gensim/models/keyedvectors.py:420, in KeyedVectors.get_index(self, key, default)
    418     return default
    419 else:
--&gt; 420     raise KeyError(f&#34;Key &#39;{key}&#39; not present&#34;)

KeyError: &#34;Key &#39;这是一个不存在的词&#39; not present&#34;

</code></pre></div><br>
<h3 id="35-查询近义词">3.5 查询近义词</h3>
<p><strong>w2v.wv.most_similar(positive=None, topn=10)</strong></p>
<ul>
<li>positive 待查的词语列表或者词向量</li>
<li>topn 显示返回多少个近义词</li>
</ul>
<h4 id="351-使用词语列表查询">3.5.1 使用词语列表查询</h4>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">w2v</span><span class="o">.</span><span class="n">wv</span><span class="o">.</span><span class="n">most_similar</span><span class="p">([</span><span class="s1">&#39;经济&#39;</span><span class="p">,</span> <span class="s1">&#39;建设&#39;</span><span class="p">,</span> <span class="s1">&#39;发展&#39;</span><span class="p">],</span> 
                    <span class="n">topn</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">[(&#39;经济发展&#39;, 0.7514141201972961),
 (&#39;产业发展&#39;, 0.6954267024993896),
 (&#39;发展壮大&#39;, 0.6707271337509155),
 (&#39;社会发展&#39;, 0.6637671589851379),
 (&#39;发展重要&#39;, 0.6603672504425049),
 (&#39;城镇化发展&#39;, 0.6574274301528931),
 (&#39;城市发展&#39;, 0.6558148264884949),
 (&#39;高质量发展&#39;, 0.6517276167869568),
 (&#39;大力发展&#39;, 0.6500106453895569),
 (&#39;产业&#39;, 0.6494895219802856),
 (&#39;发展产业&#39;, 0.6458864212036133),
 (&#39;壮大&#39;, 0.6379123330116272),
 (&#39;发展带动&#39;, 0.6357436776161194),
 (&#39;未来发展&#39;, 0.6351119875907898),
 (&#39;第三产业&#39;, 0.6345765590667725),
 (&#39;经济增长&#39;, 0.6329594850540161),
 (&#39;改革开放&#39;, 0.6297498345375061),
 (&#39;融合发展&#39;, 0.6290864944458008),
 (&#39;长远发展&#39;, 0.6279110908508301),
 (&#39;经济繁荣&#39;, 0.627375602722168)]

</code></pre></div><br>
<h3 id="352-使用词向量查询">3.5.2 使用词向量查询</h3>
<p>先构建一个函数concept_vector，该函数可以将多个词转化为一个向量。 遇到词语不在词表中的异常，也能正常运行。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>


<span class="k">def</span> <span class="nf">concept_vector</span><span class="p">(</span><span class="n">words</span><span class="p">):</span>
    <span class="n">container</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">200</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">words</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">container</span> <span class="o">=</span> <span class="n">container</span> <span class="o">+</span> <span class="n">w2v</span><span class="o">.</span><span class="n">wv</span><span class="o">.</span><span class="n">get_vector</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
        <span class="k">except</span><span class="p">:</span>
            <span class="k">pass</span>
    <span class="k">return</span> <span class="n">container</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">words</span><span class="p">)</span>
  
  
<span class="n">word_vec</span> <span class="o">=</span> <span class="n">concept_vector</span><span class="p">(</span><span class="n">words</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;她&#39;</span><span class="p">,</span> <span class="s1">&#39;她们&#39;</span><span class="p">,</span> <span class="s1">&#39;母亲&#39;</span><span class="p">,</span> <span class="s1">&#39;奶奶&#39;</span><span class="p">,</span> <span class="s1">&#39;女性&#39;</span><span class="p">,</span> <span class="s1">&#39;女人&#39;</span><span class="p">])</span>
<span class="c1">#查找与word_vec近义词10个词</span>
<span class="n">w2v</span><span class="o">.</span><span class="n">wv</span><span class="o">.</span><span class="n">most_similar</span><span class="p">(</span><span class="n">word_vec</span><span class="p">,</span> 
                    <span class="n">topn</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">[(&#39;奶奶&#39;, 0.9064152836799622),
 (&#39;母亲&#39;, 0.9003509879112244),
 (&#39;爷爷&#39;, 0.8559296131134033),
 (&#39;婆婆&#39;, 0.846263587474823),
 (&#39;我妈&#39;, 0.8314375877380371),
 (&#39;老伴&#39;, 0.8306034803390503),
 (&#39;老父亲&#39;, 0.8257972598075867),
 (&#39;姥爷&#39;, 0.8255906701087952),
 (&#39;父亲&#39;, 0.821728527545929),
 (&#39;女孩&#39;, 0.8210363984107971)]
</code></pre></div><p><br><br></p>
<h2 id="四-相关">四、 相关</h2>
<h3 id="41-文献资料">4.1 文献资料</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">郑石明, 兰雨潇, 黎枫. 网络公共舆论与政府回应的互动逻辑——基于新冠肺炎疫情期间“领导留言板”的数据分析[J]. 公共管理学报, 2021, 18 (03): 24-37+169.
王磊,易扬.公共卫生危机中的数字政府回应如何纾解网络负面舆情——基于人民网“领导留言板”回复情况的调查[J].公共管理学报,2022,19(04):65-78+169.
Lu, Liangdong, Jia Xu, and Jiuchang Wei. &#34;Understanding the effects of the textual complexity on government communication: Insights from China’s online public service platform.&#34; Telematics and Informatics 83 (2023): 102028.
...
</code></pre></div><br>
<h3 id="42-代码资料">4.2 代码资料</h3>
<p>想用 python 对 csv、xlsx 进行分析， 要学会尽量用 pandas 写代码。 以下是近期 pandas 的一些处理推文免费教程， 感兴趣的可以进去浏览浏览。</p>
<ul>
<li>
<p><a href="https://textdata.cn/blog/2023-12-17-how-to-generate-panel-data-from-gov-report-dataset/"><strong>代码 | 使用地方gov工作报告生成某类概念词频「面板数据」</strong></a></p>
</li>
<li>
<p><a href="https://textdata.cn/blog/2023-12-18-how-to-generate-panel-data-from-daily-news-dataset/"><strong>代码 | 使用「新闻数据」构造概念词提及量「面板数据」</strong></a></p>
</li>
<li>
<p><a href="https://textdata.cn/blog/2023-02-26-cctv1-xwlb-news-text-dataset/"><strong>数据代码| 使用cctv新闻联播文稿构造「面板数据」</strong></a></p>
</li>
<li>
<p><a href="https://textdata.cn/blog/2028-12-18-how-to-extract-data-from-patent-application-dataset/"><strong>代码 | 使用3571w专利申请数据集构造「面板数据」</strong></a></p>
</li>
<li>
<p><a href="https://textdata.cn/blog/2023-12-20-measure-china-economic-policy-uncertainty/"><strong>代码 | 使用「新闻数据」计算 「经济政策不确定性」指数</strong></a></p>
</li>
<li>
<p><a href="https://textdata.cn/blog/2023-03-15-39faq-about-word-embeddings-for-social-science/">词嵌入技术在社会科学领域进行数据挖掘常见39个FAQ汇总</a></p>
</li>
<li>
<p><a href="https://textdata.cn/blog/2023-11-03-organization-science-with-word-embeddings/">OS2022 | 概念空间 | 词嵌入模型如何为组织科学中的测量和理论提供信息</a></p>
</li>
</ul>
<p>数据集(付费) | 人民网地方领导留言板原始文本(2011-2023.12)  2023-12-22-renmin-gov-leader-comment-board</p>
<p><br><br></p>
<h2 id="五获取资料">五、获取资料</h2>
<h3 id="51-免费资料">5.1 免费资料</h3>
<p>本文训练所得的 <strong>renmin_board.200.6.bin模型文件</strong> 免费开源，</p>
<p><img loading="lazy" src="img/02-word2vec.png" alt=""  />
</p>
<p>链接: <a href="https://pan.baidu.com/s/1u-eUuATCTSIDjhOvSaG7sA?pwd=whf5">https://pan.baidu.com/s/1u-eUuATCTSIDjhOvSaG7sA?pwd=whf5</a> 提取码: whf5</p>
<br>
<h3 id="52-付费资料">5.2 付费资料</h3>
<p><span style="font-size: 18px;color: green;">1.  <a href="https://textdata.cn/blog/2023-12-22-renmin-gov-leader-comment-board/">数据集(付费) | 人民网地方领导留言板原始文本(2011-2023.12)</a> ，2000元</span></p>
<p><span style="font-size: 18px;color: green;">2. cntext2.1.0 价格100元，已购买2.0.0可免费更新至2.1.0</span></p>
<p><span style="font-size: 18px;color: green;">3. 数据是虚拟产品，一经售出，不再退还！</span></p>
<p><span style="font-size: 18px;color: green;">4. 大家时间其实都很宝贵，请仔细阅读推文内容， 确认无误再加微信372335839， 备注「姓名-学校-专业」详谈购买事宜 </span></p>
<p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>数据集(付费) | 人民网地方领导留言板原始文本(2011-2023.12)</title>
      <link>https://textdata.cn/blog/2023-12-22-renmin-gov-leader-comment-board/</link>
      <pubDate>Fri, 22 Dec 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-12-22-renmin-gov-leader-comment-board/</guid>
      <description>&lt;img src=&#34;img/04-dataset.png&#34; style=&#34;zoom:80%;&#34; /&gt;
&lt;br&gt;
&lt;h2 id=&#34;一数据集&#34;&gt;一、数据集&lt;/h2&gt;
&lt;h3 id=&#34;11-概况&#34;&gt;1.1 概况&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;数据来源: 人民网地方领导留言板

覆盖时间: 2011-01-01 ~ 2023.12.06

记录条数: 3914385

文件格式: xlsx、csv
    
所含字段:
 -  留言领导
 -  留言标题
 -  省份
 -  市
 -  状态
 -  主题类别
 -  投诉种类
 -  留言人
 -  留言时间
 -  留言内容
 -  回复内容
 -  回复时间
 -  回复机构
 -  办理速度评分(该字段出现在2019之后)
 -  办理态度评分(该字段出现在2019之后)
 -  解决程度评分(该字段出现在2019之后)
 -  用户评价(该字段出现在2019之后)
 -  评价标签(该字段出现在2019之后)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h3 id=&#34;12-相关研究&#34;&gt;1.2 相关研究&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;
[1]郑石明, 兰雨潇, 黎枫. 网络公共舆论与政府回应的互动逻辑——基于新冠肺炎疫情期间“领导留言板”的数据分析[J]. 公共管理学报, 2021, 18 (03): 24-37+169.
王磊,易扬.公共卫生危机中的数字政府回应如何纾解网络负面舆情——基于人民网“领导留言板”回复情况的调查[J].公共管理学报,2022,19(04):65-78+169.

[2]Lu, Liangdong, Jia Xu, and Jiuchang Wei. &amp;#34;Understanding the effects of the textual complexity on government communication: Insights from China’s online public service platform.&amp;#34; Telematics and Informatics 83 (2023): 102028.
...
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h3 id=&#34;13-获取数据&#34;&gt;1.3 获取数据&lt;/h3&gt;
&lt;p&gt;&lt;span style=&#34;font-size: 18px;color: green;&#34;&gt;1. 付费数据集，2000元，支持开票；加微信 372335839， 备注「姓名-学校-专业」。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span style=&#34;font-size: 18px;color: green;&#34;&gt;2. 数据是虚拟产品，一经售出，不再退还！&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span style=&#34;font-size: 18px;color: green;&#34;&gt;3. 大家时间其实都很宝贵，请仔细阅读推文内容， 确认无误再加微信详谈购买事宜 &lt;/span&gt;&lt;/p&gt;
&lt;br&gt;
&lt;p&gt;&lt;br&gt;&lt;img src=&#34;img/2023a.png&#34; style=&#34;zoom:80%;&#34; /&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;img/2023b.png&#34; style=&#34;zoom:80%;&#34; /&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;二查看数据&#34;&gt;二、查看数据&lt;/h2&gt;
&lt;h3 id=&#34;21-读取数据&#34;&gt;2.1 读取数据&lt;/h3&gt;
&lt;p&gt;依次读取&lt;em&gt;&lt;strong&gt;2011-2019.csv.gz&lt;/strong&gt;&lt;/em&gt; 和  &lt;em&gt;&lt;strong&gt;2020-2023.csv.gz&lt;/strong&gt;&lt;/em&gt;  两个csv文件，    &lt;em&gt;&lt;strong&gt;.csv.gz&lt;/strong&gt;&lt;/em&gt; 解压得到  &lt;em&gt;&lt;strong&gt;.csv&lt;/strong&gt;&lt;/em&gt; 后再读取。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pandas&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pd&lt;/span&gt;


&lt;span class=&#34;n&#34;&gt;df11_19&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read_csv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;2011-2019.csv&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;c1&#34;&gt;#df11_19 = pd.read_csv(&amp;#39;2011-2019.csv.gz&amp;#39;, compression=&amp;#39;gzip&amp;#39;)&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;df11_19&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;head&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/02-df.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;df20_23&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read_csv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;2020-2023.csv&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;c1&#34;&gt;#df20_23 = pd.read_csv(&amp;#39;2020-2023.csv.gz&amp;#39;, compression=&amp;#39;gzip&amp;#39;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;df20_23&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;head&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/03-df.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;22-字段&#34;&gt;2.2 字段&lt;/h3&gt;
&lt;p&gt;10多年的时间，网站会变动，写爬虫运行爬虫的人也会变动。为了让大家更丝滑的使用数据，大邓对所有的年份进行了字段矫正和统一， 最后字段只有两大类，&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;2011-2019&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df11_19&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;columns&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\n&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;

&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;2020-2023&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df20_23&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;columns&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;2011-2019
Index([&amp;#39;留言领导&amp;#39;, &amp;#39;留言标题&amp;#39;, &amp;#39;省份&amp;#39;, &amp;#39;市&amp;#39;, &amp;#39;状态&amp;#39;, &amp;#39;主题类别&amp;#39;, &amp;#39;投诉种类&amp;#39;, &amp;#39;留言人&amp;#39;, &amp;#39;留言时间&amp;#39;, &amp;#39;留言内容&amp;#39;, &amp;#39;回复机构&amp;#39;, 
       &amp;#39;回复内容&amp;#39;, &amp;#39;回复时间&amp;#39;, &amp;#39;留言评价&amp;#39;, &amp;#39;评价时间&amp;#39;],
      dtype=&amp;#39;object&amp;#39;)


2020-2023
Index([&amp;#39;留言领导&amp;#39;, &amp;#39;留言标题&amp;#39;, &amp;#39;省份&amp;#39;, &amp;#39;市&amp;#39;, &amp;#39;状态&amp;#39;, &amp;#39;主题类别&amp;#39;, &amp;#39;投诉种类&amp;#39;, &amp;#39;留言人&amp;#39;, &amp;#39;留言时间&amp;#39;, &amp;#39;留言内容&amp;#39;,
       &amp;#39;回复内容&amp;#39;, &amp;#39;回复时间&amp;#39;, &amp;#39;回复机构&amp;#39;, &amp;#39;办理速度评分&amp;#39;, &amp;#39;办理态度评分&amp;#39;, &amp;#39;解决程度评分&amp;#39;, &amp;#39;用户评价&amp;#39;, &amp;#39;评价标签&amp;#39;],
      dtype=&amp;#39;object&amp;#39;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h3 id=&#34;23-记录数&#34;&gt;2.3 记录数&lt;/h3&gt;
&lt;p&gt;数据集总记录数&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;总记录数: &amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df11_19&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df20_23&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;总记录数: 3914385
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h3 id=&#34;24-每年是否包含年末数据&#34;&gt;2.4 每年是否包含年末数据&lt;/h3&gt;
&lt;p&gt;由于人民网只 “&lt;strong&gt;可查询留言为上一年1月1日至今的所有留言&lt;/strong&gt;”, 有同学没看懂这句话含义，担心每年12月月末或1月月初是否会缺失数据。这里我们检查下数据集每年的年初是否为1.1， 年底是否为12.31&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;year&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;year_df&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;df11_19&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;groupby&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df11_19&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;留言时间&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;year&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
    &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;year&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;year_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;留言时间&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;min&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;date&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(),&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;year_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;留言时间&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;max&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;date&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;())&lt;/span&gt;
    
    
&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;year&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;year_df&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;df20_23&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;groupby&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df20_23&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;留言时间&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;year&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
    &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;year&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;year_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;留言时间&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;min&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;date&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(),&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;year_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;留言时间&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;max&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;date&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;())&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;mi&#34;&gt;2011&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2011&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;01&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;01&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2011&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;12&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;31&lt;/span&gt;
&lt;span class=&#34;mi&#34;&gt;2012&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2012&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;01&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;01&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2012&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;12&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;31&lt;/span&gt;
&lt;span class=&#34;mi&#34;&gt;2013&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2013&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;01&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;01&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2013&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;12&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;31&lt;/span&gt;
&lt;span class=&#34;mi&#34;&gt;2014&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2014&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;01&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;01&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2014&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;12&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;31&lt;/span&gt;
&lt;span class=&#34;mi&#34;&gt;2015&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2015&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;01&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;01&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2015&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;12&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;31&lt;/span&gt;
&lt;span class=&#34;mi&#34;&gt;2016&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2016&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;01&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;01&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2016&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;12&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;31&lt;/span&gt;
&lt;span class=&#34;mi&#34;&gt;2017&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2017&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;01&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;01&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2017&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;12&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;31&lt;/span&gt;
&lt;span class=&#34;mi&#34;&gt;2018&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2018&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;01&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;01&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2018&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;12&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;31&lt;/span&gt;
&lt;span class=&#34;mi&#34;&gt;2019&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2019&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;01&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;01&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2019&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;12&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;31&lt;/span&gt;
&lt;span class=&#34;mi&#34;&gt;2020&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2020&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;01&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;01&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2020&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;12&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;31&lt;/span&gt;
&lt;span class=&#34;mi&#34;&gt;2021&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2021&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;01&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;01&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2021&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;12&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;31&lt;/span&gt;
&lt;span class=&#34;mi&#34;&gt;2022&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2022&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;01&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;01&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2022&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;12&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;31&lt;/span&gt;
&lt;span class=&#34;mi&#34;&gt;2023&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2023&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;01&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;01&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2023&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;12&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;06&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;因为数据集是 2023.12.6 运行的， 日期截止到 2023.12.6 。不过不用担心， 下次更新数据时候会覆盖到  2023.12.31 。&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;25-年度记录数&#34;&gt;2.5 年度记录数&lt;/h3&gt;
&lt;p&gt;两个 dataframe 中都有 &lt;em&gt;&lt;strong&gt;留言日期&lt;/strong&gt;&lt;/em&gt; ， 我们根据该字段查看每个年份的记录数。首先，要先将该字段转化为 datetime 日期类型。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;data&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;df11_19&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;留言时间&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;to_datetime&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df11_19&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;留言时间&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;df20_23&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;留言时间&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;to_datetime&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df20_23&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;留言时间&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;

&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;year&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;year_df&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;df11_19&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;groupby&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df11_19&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;留言时间&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;year&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;append&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;({&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;year&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;year&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;volume&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;year_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)})&lt;/span&gt;
    &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;year&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39; &amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;year_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;

&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;year&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;year_df&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;df20_23&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;groupby&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df20_23&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;留言时间&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;year&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;append&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;({&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;year&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;year&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;volume&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;year_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)})&lt;/span&gt;
    &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;year&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39; &amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;year_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
    

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;2011 23307
2012 20178
2013 42950
2014 97640
2015 131930
2016 201525
2017 202793
2018 243648
2019 464622
2020 517167
2021 783139
2022 648055
2023 537422
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;plt&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;matplotlib&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;scienceplots&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;platform&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pandas&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pd&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;matplotlib_inline&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;matplotlib_inline&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;backend_inline&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;set_matplotlib_formats&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;png&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;svg&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;jieba&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;warnings&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;warnings&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;filterwarnings&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;ignore&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;plt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;style&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;use&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;([&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;science&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;no-latex&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;cjk-sc-font&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;system&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;platform&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;system&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;# 获取操作系统类型&lt;/span&gt;
&lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;system&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;Windows&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;font&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;family&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;SimHei&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;span class=&#34;k&#34;&gt;elif&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;system&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;Darwin&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;font&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;family&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;Arial Unicode MS&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;span class=&#34;k&#34;&gt;else&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;font&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;family&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;sans-serif&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;matplotlib&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;rc&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;font&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;font&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;# 设置全局字体&lt;/span&gt;
    
&lt;span class=&#34;n&#34;&gt;year_volume_df&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;DataFrame&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;c1&#34;&gt;#year_volume_df[&amp;#39;year&amp;#39;] = pd.to_datetime(year_volume_df[&amp;#39;year&amp;#39;])&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;year_volume_df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;set_index&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;year&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;inplace&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;year_volume_df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;plot&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;bar&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;figsize&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;7&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;plt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;title&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;人民网留言板留言数量(2011 ~ 2023)&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;size&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;15&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;plt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;xticks&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;size&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;rotation&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;plt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;xlabel&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;年份&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;size&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;13&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;plt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ylabel&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;留言数量&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;size&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;13&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/plot.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;需要声明， 采集的数据量与真实数据量肯定会有出入的， 例如爬虫运行的时间点、IP被封、请求失败、文件编码(格式)问题等会遗失一定量的记录量。&lt;/p&gt;
&lt;p&gt;但是大家做Python定量文本分析， 不用担心这个问题。  Python为代表的大规模数据挖掘，只要满足  &lt;strong&gt;Earnings(规模带来的信息增益) &amp;raquo; Loss(数据质量产生的损失)&lt;/strong&gt; ，做文本分析就是可行的，有意义的。 而咱们的数据， 数据规模近 400 万条， 数据质量也是有保证的。&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h3 id=&#34;26-value_counts&#34;&gt;2.6 value_counts&lt;/h3&gt;
&lt;p&gt;查看2011-2019年， 不同留 &lt;em&gt;&lt;strong&gt;主题类别&lt;/strong&gt;&lt;/em&gt;  的记录数&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;c1&#34;&gt;#2011-2019&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;df11_19&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;主题类别&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;value_counts&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;主题类别
城建    474413
交通    180195
其他    177262
三农    116151
环保     94344
教育     90603
政务     69910
治安     63752
就业     47854
医疗     37215
企业     36826
旅游     18675
文娱      9866
金融      6778
征集      4741
求助         3
咨询         2
建言         2
投诉         1
Name: count, dtype: int64
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h3 id=&#34;27-查看是否含某词&#34;&gt;2.7 查看是否含某词&lt;/h3&gt;
&lt;p&gt;查看字段 &lt;em&gt;&lt;strong&gt;留言内容&lt;/strong&gt;&lt;/em&gt;, 是否出现 &lt;em&gt;&lt;strong&gt;扰民|噪音&lt;/strong&gt;&lt;/em&gt; 等词语&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;df11_19&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;留言内容&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fillna&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;str&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;contains&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;扰民|噪音&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;0          False
1          False
2          False
3          False
4          False
           ...  
1428614    False
1428615    False
1428616    False
1428617    False
1428618    False
Name: 留言内容, Length: 1428619, dtype: bool
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;p&gt;噪音的留言记录数&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;df11_19&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;留言内容&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fillna&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;str&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;contains&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;扰民|噪音&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sum&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;57845
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;p&gt;噪音的留言记录占总留言数的比例&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;df11_19&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;留言内容&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fillna&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;str&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;contains&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;扰民|噪音&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sum&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df11_19&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;0.04049063350044309
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;有4%的留言是跟扰民、噪音相关的 。&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;三-相关研究&#34;&gt;三、 相关研究&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;郑石明, 兰雨潇, 黎枫. 网络公共舆论与政府回应的互动逻辑——基于新冠肺炎疫情期间“领导留言板”的数据分析[J]. 公共管理学报, 2021, 18 (03): 24-37+169.
王磊,易扬.公共卫生危机中的数字政府回应如何纾解网络负面舆情——基于人民网“领导留言板”回复情况的调查[J].公共管理学报,2022,19(04):65-78+169.
Lu, Liangdong, Jia Xu, and Jiuchang Wei. &amp;#34;Understanding the effects of the textual complexity on government communication: Insights from China’s online public service platform.&amp;#34; Telematics and Informatics 83 (2023): 102028.
...
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;四相关代码&#34;&gt;四、相关代码&lt;/h2&gt;
&lt;p&gt;想用 python 对 csv、xlsx 进行分析， 要学会尽量用 pandas 写代码。 以下是近期 pandas 的一些处理推文免费教程， 感兴趣的可以进去浏览浏览。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/2023-12-29-china-area-dataset/&#34;&gt;数据集 | 2024年中国全国5级行政区划（省、市、县、镇、村）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/2023-12-28-train-word2vec-using-renmin-gov-leader-board-dataset/&#34;&gt;词向量  | 使用&lt;strong&gt;人民网领导留言板&lt;/strong&gt;语料训练Word2Vec模型&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/2023-12-17-how-to-generate-panel-data-from-gov-report-dataset/&#34;&gt;&lt;strong&gt;代码 | 使用地方gov工作报告生成某类概念词频「面板数据」&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/2023-12-18-how-to-generate-panel-data-from-daily-news-dataset/&#34;&gt;&lt;strong&gt;代码 | 使用「新闻数据」构造概念词提及量「面板数据」&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/2023-02-26-cctv1-xwlb-news-text-dataset/&#34;&gt;&lt;strong&gt;数据代码| 使用cctv新闻联播文稿构造「面板数据」&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/2028-12-18-how-to-extract-data-from-patent-application-dataset/&#34;&gt;&lt;strong&gt;代码 | 使用3571w专利申请数据集构造「面板数据」&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/2023-12-20-measure-china-economic-policy-uncertainty/&#34;&gt;&lt;strong&gt;代码 | 使用「新闻数据」计算 「经济政策不确定性」指数&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;五获取数据&#34;&gt;五、获取数据&lt;/h2&gt;
&lt;p&gt;&lt;span style=&#34;font-size: 18px;color: green;&#34;&gt;1. 付费数据集，2000元；加微信 372335839， 备注「姓名-学校-专业」。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span style=&#34;font-size: 18px;color: green;&#34;&gt;2. 数据是虚拟产品，一经售出，不再退还！&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span style=&#34;font-size: 18px;color: green;&#34;&gt;3. 大家时间其实都很宝贵，请仔细阅读推文内容， 确认无误再加微信详谈购买事宜 &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;广而告之&#34;&gt;广而告之&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/call_for_paper/&#34;&gt;长期征稿&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/we_need_you/&#34;&gt;长期招募小伙伴&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/management_python_course/&#34;&gt;付费视频课 | Python实证指标构建与文本分析&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
      <content:encoded><![CDATA[<img src="img/04-dataset.png" style="zoom:80%;" />
<br>
<h2 id="一数据集">一、数据集</h2>
<h3 id="11-概况">1.1 概况</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">数据来源: 人民网地方领导留言板

覆盖时间: 2011-01-01 ~ 2023.12.06

记录条数: 3914385

文件格式: xlsx、csv
    
所含字段:
 -  留言领导
 -  留言标题
 -  省份
 -  市
 -  状态
 -  主题类别
 -  投诉种类
 -  留言人
 -  留言时间
 -  留言内容
 -  回复内容
 -  回复时间
 -  回复机构
 -  办理速度评分(该字段出现在2019之后)
 -  办理态度评分(该字段出现在2019之后)
 -  解决程度评分(该字段出现在2019之后)
 -  用户评价(该字段出现在2019之后)
 -  评价标签(该字段出现在2019之后)
</code></pre></div><br>
<h3 id="12-相关研究">1.2 相关研究</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">
[1]郑石明, 兰雨潇, 黎枫. 网络公共舆论与政府回应的互动逻辑——基于新冠肺炎疫情期间“领导留言板”的数据分析[J]. 公共管理学报, 2021, 18 (03): 24-37+169.
王磊,易扬.公共卫生危机中的数字政府回应如何纾解网络负面舆情——基于人民网“领导留言板”回复情况的调查[J].公共管理学报,2022,19(04):65-78+169.

[2]Lu, Liangdong, Jia Xu, and Jiuchang Wei. &#34;Understanding the effects of the textual complexity on government communication: Insights from China’s online public service platform.&#34; Telematics and Informatics 83 (2023): 102028.
...
</code></pre></div><br>
<h3 id="13-获取数据">1.3 获取数据</h3>
<p><span style="font-size: 18px;color: green;">1. 付费数据集，2000元，支持开票；加微信 372335839， 备注「姓名-学校-专业」。</span></p>
<p><span style="font-size: 18px;color: green;">2. 数据是虚拟产品，一经售出，不再退还！</span></p>
<p><span style="font-size: 18px;color: green;">3. 大家时间其实都很宝贵，请仔细阅读推文内容， 确认无误再加微信详谈购买事宜 </span></p>
<br>
<p><br><img src="img/2023a.png" style="zoom:80%;" /><br></p>
<p><img src="img/2023b.png" style="zoom:80%;" /><br><br></p>
<h2 id="二查看数据">二、查看数据</h2>
<h3 id="21-读取数据">2.1 读取数据</h3>
<p>依次读取<em><strong>2011-2019.csv.gz</strong></em> 和  <em><strong>2020-2023.csv.gz</strong></em>  两个csv文件，    <em><strong>.csv.gz</strong></em> 解压得到  <em><strong>.csv</strong></em> 后再读取。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>


<span class="n">df11_19</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;2011-2019.csv&#39;</span><span class="p">)</span>
<span class="c1">#df11_19 = pd.read_csv(&#39;2011-2019.csv.gz&#39;, compression=&#39;gzip&#39;)</span>

<span class="n">df11_19</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div><p><img loading="lazy" src="img/02-df.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df20_23</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;2020-2023.csv&#39;</span><span class="p">)</span>
<span class="c1">#df20_23 = pd.read_csv(&#39;2020-2023.csv.gz&#39;, compression=&#39;gzip&#39;)</span>
<span class="n">df20_23</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div><p><img loading="lazy" src="img/03-df.png" alt=""  />
</p>
<br>
<h3 id="22-字段">2.2 字段</h3>
<p>10多年的时间，网站会变动，写爬虫运行爬虫的人也会变动。为了让大家更丝滑的使用数据，大邓对所有的年份进行了字段矫正和统一， 最后字段只有两大类，</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;2011-2019&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df11_19</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;2020-2023&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df20_23</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">2011-2019
Index([&#39;留言领导&#39;, &#39;留言标题&#39;, &#39;省份&#39;, &#39;市&#39;, &#39;状态&#39;, &#39;主题类别&#39;, &#39;投诉种类&#39;, &#39;留言人&#39;, &#39;留言时间&#39;, &#39;留言内容&#39;, &#39;回复机构&#39;, 
       &#39;回复内容&#39;, &#39;回复时间&#39;, &#39;留言评价&#39;, &#39;评价时间&#39;],
      dtype=&#39;object&#39;)


2020-2023
Index([&#39;留言领导&#39;, &#39;留言标题&#39;, &#39;省份&#39;, &#39;市&#39;, &#39;状态&#39;, &#39;主题类别&#39;, &#39;投诉种类&#39;, &#39;留言人&#39;, &#39;留言时间&#39;, &#39;留言内容&#39;,
       &#39;回复内容&#39;, &#39;回复时间&#39;, &#39;回复机构&#39;, &#39;办理速度评分&#39;, &#39;办理态度评分&#39;, &#39;解决程度评分&#39;, &#39;用户评价&#39;, &#39;评价标签&#39;],
      dtype=&#39;object&#39;)
</code></pre></div><br>
<h3 id="23-记录数">2.3 记录数</h3>
<p>数据集总记录数</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;总记录数: &#39;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">df11_19</span><span class="p">)</span><span class="o">+</span><span class="nb">len</span><span class="p">(</span><span class="n">df20_23</span><span class="p">))</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">总记录数: 3914385
</code></pre></div><br>
<h3 id="24-每年是否包含年末数据">2.4 每年是否包含年末数据</h3>
<p>由于人民网只 “<strong>可查询留言为上一年1月1日至今的所有留言</strong>”, 有同学没看懂这句话含义，担心每年12月月末或1月月初是否会缺失数据。这里我们检查下数据集每年的年初是否为1.1， 年底是否为12.31</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="k">for</span> <span class="n">year</span><span class="p">,</span> <span class="n">year_df</span> <span class="ow">in</span> <span class="n">df11_19</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">df11_19</span><span class="p">[</span><span class="s1">&#39;留言时间&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">dt</span><span class="o">.</span><span class="n">year</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">year</span><span class="p">,</span> <span class="n">year_df</span><span class="p">[</span><span class="s1">&#39;留言时间&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">()</span><span class="o">.</span><span class="n">date</span><span class="p">(),</span> <span class="n">year_df</span><span class="p">[</span><span class="s1">&#39;留言时间&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">.</span><span class="n">date</span><span class="p">())</span>
    
    
<span class="k">for</span> <span class="n">year</span><span class="p">,</span> <span class="n">year_df</span> <span class="ow">in</span> <span class="n">df20_23</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">df20_23</span><span class="p">[</span><span class="s1">&#39;留言时间&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">dt</span><span class="o">.</span><span class="n">year</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">year</span><span class="p">,</span> <span class="n">year_df</span><span class="p">[</span><span class="s1">&#39;留言时间&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">()</span><span class="o">.</span><span class="n">date</span><span class="p">(),</span> <span class="n">year_df</span><span class="p">[</span><span class="s1">&#39;留言时间&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">.</span><span class="n">date</span><span class="p">())</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="mi">2011</span> <span class="mi">2011</span><span class="o">-</span><span class="mi">01</span><span class="o">-</span><span class="mi">01</span> <span class="mi">2011</span><span class="o">-</span><span class="mi">12</span><span class="o">-</span><span class="mi">31</span>
<span class="mi">2012</span> <span class="mi">2012</span><span class="o">-</span><span class="mi">01</span><span class="o">-</span><span class="mi">01</span> <span class="mi">2012</span><span class="o">-</span><span class="mi">12</span><span class="o">-</span><span class="mi">31</span>
<span class="mi">2013</span> <span class="mi">2013</span><span class="o">-</span><span class="mi">01</span><span class="o">-</span><span class="mi">01</span> <span class="mi">2013</span><span class="o">-</span><span class="mi">12</span><span class="o">-</span><span class="mi">31</span>
<span class="mi">2014</span> <span class="mi">2014</span><span class="o">-</span><span class="mi">01</span><span class="o">-</span><span class="mi">01</span> <span class="mi">2014</span><span class="o">-</span><span class="mi">12</span><span class="o">-</span><span class="mi">31</span>
<span class="mi">2015</span> <span class="mi">2015</span><span class="o">-</span><span class="mi">01</span><span class="o">-</span><span class="mi">01</span> <span class="mi">2015</span><span class="o">-</span><span class="mi">12</span><span class="o">-</span><span class="mi">31</span>
<span class="mi">2016</span> <span class="mi">2016</span><span class="o">-</span><span class="mi">01</span><span class="o">-</span><span class="mi">01</span> <span class="mi">2016</span><span class="o">-</span><span class="mi">12</span><span class="o">-</span><span class="mi">31</span>
<span class="mi">2017</span> <span class="mi">2017</span><span class="o">-</span><span class="mi">01</span><span class="o">-</span><span class="mi">01</span> <span class="mi">2017</span><span class="o">-</span><span class="mi">12</span><span class="o">-</span><span class="mi">31</span>
<span class="mi">2018</span> <span class="mi">2018</span><span class="o">-</span><span class="mi">01</span><span class="o">-</span><span class="mi">01</span> <span class="mi">2018</span><span class="o">-</span><span class="mi">12</span><span class="o">-</span><span class="mi">31</span>
<span class="mi">2019</span> <span class="mi">2019</span><span class="o">-</span><span class="mi">01</span><span class="o">-</span><span class="mi">01</span> <span class="mi">2019</span><span class="o">-</span><span class="mi">12</span><span class="o">-</span><span class="mi">31</span>
<span class="mi">2020</span> <span class="mi">2020</span><span class="o">-</span><span class="mi">01</span><span class="o">-</span><span class="mi">01</span> <span class="mi">2020</span><span class="o">-</span><span class="mi">12</span><span class="o">-</span><span class="mi">31</span>
<span class="mi">2021</span> <span class="mi">2021</span><span class="o">-</span><span class="mi">01</span><span class="o">-</span><span class="mi">01</span> <span class="mi">2021</span><span class="o">-</span><span class="mi">12</span><span class="o">-</span><span class="mi">31</span>
<span class="mi">2022</span> <span class="mi">2022</span><span class="o">-</span><span class="mi">01</span><span class="o">-</span><span class="mi">01</span> <span class="mi">2022</span><span class="o">-</span><span class="mi">12</span><span class="o">-</span><span class="mi">31</span>
<span class="mi">2023</span> <span class="mi">2023</span><span class="o">-</span><span class="mi">01</span><span class="o">-</span><span class="mi">01</span> <span class="mi">2023</span><span class="o">-</span><span class="mi">12</span><span class="o">-</span><span class="mi">06</span>
</code></pre></div><p>因为数据集是 2023.12.6 运行的， 日期截止到 2023.12.6 。不过不用担心， 下次更新数据时候会覆盖到  2023.12.31 。</p>
<br>
<h3 id="25-年度记录数">2.5 年度记录数</h3>
<p>两个 dataframe 中都有 <em><strong>留言日期</strong></em> ， 我们根据该字段查看每个年份的记录数。首先，要先将该字段转化为 datetime 日期类型。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">data</span> <span class="o">=</span> <span class="p">[]</span>

<span class="n">df11_19</span><span class="p">[</span><span class="s1">&#39;留言时间&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">df11_19</span><span class="p">[</span><span class="s1">&#39;留言时间&#39;</span><span class="p">])</span>
<span class="n">df20_23</span><span class="p">[</span><span class="s1">&#39;留言时间&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">df20_23</span><span class="p">[</span><span class="s1">&#39;留言时间&#39;</span><span class="p">])</span>

<span class="k">for</span> <span class="n">year</span><span class="p">,</span> <span class="n">year_df</span> <span class="ow">in</span> <span class="n">df11_19</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">df11_19</span><span class="p">[</span><span class="s1">&#39;留言时间&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">dt</span><span class="o">.</span><span class="n">year</span><span class="p">):</span>
    <span class="n">data</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="s1">&#39;year&#39;</span><span class="p">:</span> <span class="n">year</span><span class="p">,</span> <span class="s1">&#39;volume&#39;</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">year_df</span><span class="p">)})</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">year</span><span class="p">,</span> <span class="s1">&#39; &#39;</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">year_df</span><span class="p">))</span>

<span class="k">for</span> <span class="n">year</span><span class="p">,</span> <span class="n">year_df</span> <span class="ow">in</span> <span class="n">df20_23</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">df20_23</span><span class="p">[</span><span class="s1">&#39;留言时间&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">dt</span><span class="o">.</span><span class="n">year</span><span class="p">):</span>
    <span class="n">data</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="s1">&#39;year&#39;</span><span class="p">:</span> <span class="n">year</span><span class="p">,</span> <span class="s1">&#39;volume&#39;</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">year_df</span><span class="p">)})</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">year</span><span class="p">,</span> <span class="s1">&#39; &#39;</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">year_df</span><span class="p">))</span>
    

</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">2011 23307
2012 20178
2013 42950
2014 97640
2015 131930
2016 201525
2017 202793
2018 243648
2019 464622
2020 517167
2021 783139
2022 648055
2023 537422
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">matplotlib</span>
<span class="kn">import</span> <span class="nn">scienceplots</span>
<span class="kn">import</span> <span class="nn">platform</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib_inline</span>
<span class="n">matplotlib_inline</span><span class="o">.</span><span class="n">backend_inline</span><span class="o">.</span><span class="n">set_matplotlib_formats</span><span class="p">(</span><span class="s1">&#39;png&#39;</span><span class="p">,</span> <span class="s1">&#39;svg&#39;</span><span class="p">)</span>
<span class="kn">import</span> <span class="nn">jieba</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">([</span><span class="s1">&#39;science&#39;</span><span class="p">,</span> <span class="s1">&#39;no-latex&#39;</span><span class="p">,</span> <span class="s1">&#39;cjk-sc-font&#39;</span><span class="p">])</span>
<span class="n">system</span> <span class="o">=</span> <span class="n">platform</span><span class="o">.</span><span class="n">system</span><span class="p">()</span>  <span class="c1"># 获取操作系统类型</span>
<span class="k">if</span> <span class="n">system</span> <span class="o">==</span> <span class="s1">&#39;Windows&#39;</span><span class="p">:</span>
    <span class="n">font</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;family&#39;</span><span class="p">:</span> <span class="s1">&#39;SimHei&#39;</span><span class="p">}</span>
<span class="k">elif</span> <span class="n">system</span> <span class="o">==</span> <span class="s1">&#39;Darwin&#39;</span><span class="p">:</span>
    <span class="n">font</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;family&#39;</span><span class="p">:</span> <span class="s1">&#39;Arial Unicode MS&#39;</span><span class="p">}</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">font</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;family&#39;</span><span class="p">:</span> <span class="s1">&#39;sans-serif&#39;</span><span class="p">}</span>
<span class="n">matplotlib</span><span class="o">.</span><span class="n">rc</span><span class="p">(</span><span class="s1">&#39;font&#39;</span><span class="p">,</span> <span class="o">**</span><span class="n">font</span><span class="p">)</span>  <span class="c1"># 设置全局字体</span>
    
<span class="n">year_volume_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="c1">#year_volume_df[&#39;year&#39;] = pd.to_datetime(year_volume_df[&#39;year&#39;])</span>
<span class="n">year_volume_df</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="s1">&#39;year&#39;</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">year_volume_df</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s1">&#39;bar&#39;</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;人民网留言板留言数量(2011 ~ 2023)&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;年份&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">13</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;留言数量&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">13</span><span class="p">)</span>
</code></pre></div><p><img loading="lazy" src="img/plot.png" alt=""  />
</p>
<p>需要声明， 采集的数据量与真实数据量肯定会有出入的， 例如爬虫运行的时间点、IP被封、请求失败、文件编码(格式)问题等会遗失一定量的记录量。</p>
<p>但是大家做Python定量文本分析， 不用担心这个问题。  Python为代表的大规模数据挖掘，只要满足  <strong>Earnings(规模带来的信息增益) &raquo; Loss(数据质量产生的损失)</strong> ，做文本分析就是可行的，有意义的。 而咱们的数据， 数据规模近 400 万条， 数据质量也是有保证的。</p>
<p><br><br></p>
<h3 id="26-value_counts">2.6 value_counts</h3>
<p>查看2011-2019年， 不同留 <em><strong>主题类别</strong></em>  的记录数</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#2011-2019</span>
<span class="n">df11_19</span><span class="p">[</span><span class="s1">&#39;主题类别&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">主题类别
城建    474413
交通    180195
其他    177262
三农    116151
环保     94344
教育     90603
政务     69910
治安     63752
就业     47854
医疗     37215
企业     36826
旅游     18675
文娱      9866
金融      6778
征集      4741
求助         3
咨询         2
建言         2
投诉         1
Name: count, dtype: int64
</code></pre></div><br>
<h3 id="27-查看是否含某词">2.7 查看是否含某词</h3>
<p>查看字段 <em><strong>留言内容</strong></em>, 是否出现 <em><strong>扰民|噪音</strong></em> 等词语</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df11_19</span><span class="p">[</span><span class="s1">&#39;留言内容&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="s1">&#39;扰民|噪音&#39;</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">0          False
1          False
2          False
3          False
4          False
           ...  
1428614    False
1428615    False
1428616    False
1428617    False
1428618    False
Name: 留言内容, Length: 1428619, dtype: bool
</code></pre></div><br>
<p>噪音的留言记录数</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df11_19</span><span class="p">[</span><span class="s1">&#39;留言内容&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="s1">&#39;扰民|噪音&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">57845
</code></pre></div><br>
<p>噪音的留言记录占总留言数的比例</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df11_19</span><span class="p">[</span><span class="s1">&#39;留言内容&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="s1">&#39;扰民|噪音&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">df11_19</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">0.04049063350044309
</code></pre></div><p>有4%的留言是跟扰民、噪音相关的 。</p>
<p><br><br></p>
<h2 id="三-相关研究">三、 相关研究</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">郑石明, 兰雨潇, 黎枫. 网络公共舆论与政府回应的互动逻辑——基于新冠肺炎疫情期间“领导留言板”的数据分析[J]. 公共管理学报, 2021, 18 (03): 24-37+169.
王磊,易扬.公共卫生危机中的数字政府回应如何纾解网络负面舆情——基于人民网“领导留言板”回复情况的调查[J].公共管理学报,2022,19(04):65-78+169.
Lu, Liangdong, Jia Xu, and Jiuchang Wei. &#34;Understanding the effects of the textual complexity on government communication: Insights from China’s online public service platform.&#34; Telematics and Informatics 83 (2023): 102028.
...
</code></pre></div><h2 id="四相关代码">四、相关代码</h2>
<p>想用 python 对 csv、xlsx 进行分析， 要学会尽量用 pandas 写代码。 以下是近期 pandas 的一些处理推文免费教程， 感兴趣的可以进去浏览浏览。</p>
<ul>
<li><a href="https://textdata.cn/blog/2023-12-29-china-area-dataset/">数据集 | 2024年中国全国5级行政区划（省、市、县、镇、村）</a></li>
<li><a href="https://textdata.cn/blog/2023-12-28-train-word2vec-using-renmin-gov-leader-board-dataset/">词向量  | 使用<strong>人民网领导留言板</strong>语料训练Word2Vec模型</a></li>
<li><a href="https://textdata.cn/blog/2023-12-17-how-to-generate-panel-data-from-gov-report-dataset/"><strong>代码 | 使用地方gov工作报告生成某类概念词频「面板数据」</strong></a></li>
<li><a href="https://textdata.cn/blog/2023-12-18-how-to-generate-panel-data-from-daily-news-dataset/"><strong>代码 | 使用「新闻数据」构造概念词提及量「面板数据」</strong></a></li>
<li><a href="https://textdata.cn/blog/2023-02-26-cctv1-xwlb-news-text-dataset/"><strong>数据代码| 使用cctv新闻联播文稿构造「面板数据」</strong></a></li>
<li><a href="https://textdata.cn/blog/2028-12-18-how-to-extract-data-from-patent-application-dataset/"><strong>代码 | 使用3571w专利申请数据集构造「面板数据」</strong></a></li>
<li><a href="https://textdata.cn/blog/2023-12-20-measure-china-economic-policy-uncertainty/"><strong>代码 | 使用「新闻数据」计算 「经济政策不确定性」指数</strong></a></li>
</ul>
<p><br><br></p>
<h2 id="五获取数据">五、获取数据</h2>
<p><span style="font-size: 18px;color: green;">1. 付费数据集，2000元；加微信 372335839， 备注「姓名-学校-专业」。</span></p>
<p><span style="font-size: 18px;color: green;">2. 数据是虚拟产品，一经售出，不再退还！</span></p>
<p><span style="font-size: 18px;color: green;">3. 大家时间其实都很宝贵，请仔细阅读推文内容， 确认无误再加微信详谈购买事宜 </span></p>
<p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>数据集 | 2.49亿条中国工商注册企业信息(23.9更新)</title>
      <link>https://textdata.cn/blog/2023-12-03-china-mainland-corporate-registration-information/</link>
      <pubDate>Sun, 03 Dec 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-12-03-china-mainland-corporate-registration-information/</guid>
      <description>341个地市， 2亿条工商注册信息， 网盘压缩文件夹体积17.6G</description>
      <content:encoded><![CDATA[<h2 id="一工商数据集概况">一、工商数据集概况</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">数据来源: 国家企业信用信息公示系统
记录条数: 2.49亿条
文件体积: 160G(解压后)
涵盖日期: 1949.10.1~2023.9.19
</code></pre></div><p><img loading="lazy" src="img/dataset-screen.png" alt=""  />
</p>
<br>
<h3 id="11-字段">1.1 字段</h3>
<p>任意csv文件的字段包括</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">- 企业名称
- 英文名称
- 统一社会信用代码
- 企业类型
- 经营状态
- 成立日期
- 核准日期
- 法定代表人
- 注册咨本
- 实缴资本
- 参保人数
- 公司规模
- 经营范围
- 注册地址
- 营业期限
- 纳税人识别号
- 工商注册号
- 组织机构代码
- 联系电话(脱敏)
- 邮箱(脱敏)
- 纳税人资质
- 曾用名
- 所属省份
- 所属城市
- 所属区县
- 网站链接
- 所属行业
- 登记机关
- 经度
- 纬度
</code></pre></div><p>数据集已经脱敏处理， 避免分享过程出现违规(法)问题。 如果你想获取手机号，商业用途， 就不要联系我了！我没有，有也不卖。</p>
<br>
<h3 id="12-查看文件">1.2 查看文件</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">os</span>

<span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"> [
 &#39;北京.csv.gz&#39;,
 &#39;上海.csv.gz&#39;,
 &#39;南京.csv.gz&#39;,
 ...
 &#39;重庆.csv.gz&#39;,
  ]
</code></pre></div><br>
<h2 id="二实验代码">二、实验代码</h2>
<h3 id="21-读取数据">2.1 读取数据</h3>
<p>不考虑电脑内存容量限制， 读取 石家庄市、长沙市、杭州市。如果电脑内存很小，请先阅读  <a href="https://textdata.cn/blog/2023-11-17-how-handle-mega-csv-that-far-exceed-memory/">推荐 | 如何处理远超电脑内存的csv文件</a></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">sjz_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;石家庄.csv.gz&#39;</span><span class="p">,</span> <span class="n">compression</span><span class="o">=</span><span class="s1">&#39;gzip&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">,</span> <span class="n">low_memory</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">cs_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;长沙.csv.gz&#39;</span><span class="p">,</span> <span class="n">compression</span><span class="o">=</span><span class="s1">&#39;gzip&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">,</span> <span class="n">low_memory</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">hz_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;杭州.csv.gz&#39;</span><span class="p">,</span> <span class="n">compression</span><span class="o">=</span><span class="s1">&#39;gzip&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">,</span> <span class="n">low_memory</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1">#随机显示2条记录</span>
<span class="n">sjz_df</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</code></pre></div><p><img loading="lazy" src="img/df.png" alt=""  />
</p>
<br>
<h3 id="22-记录数">2.2 记录数</h3>
<p>石家庄.csv 企业记录数</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="nb">len</span><span class="p">(</span><span class="n">sjz_df</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">2010163
</code></pre></div><br>
<h3 id="23-所含字段">2.3 所含字段</h3>
<p>含有的字段有</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">sjz_df</span><span class="o">.</span><span class="n">columns</span>
</code></pre></div><pre><code>Index(['企业组织机构代码', '企业名称', '注册资本', '实缴资本', '纳税人识别号', '法定代表人', '企业状态', '所属行业',
       '企业名称', '英文名称', '统一社会信用代码', '企业类型', '经营状态', '成立日期', '核准日期', '法定代表人',
       '注册咨本', '实缴资本', '参保人数', '公司规模', '经营范围', '注册地址', '营业期限', '纳税人识别号', '工商注册号', '组织机构代码', '联系电话', '邮箱', '纳税人资质', '曾用名', '所属省份', '所属城市', '所属区县', '网站链接', '所属行业', '登记机关', '经度', '纬度'],
      dtype='object')
</code></pre>
<br>
<h3 id="24-日期转换">2.4 日期转换</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">sjz_df</span><span class="p">[</span><span class="s1">&#39;成立日期&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">sjz_df</span><span class="p">[</span><span class="s1">&#39;成立日期&#39;</span><span class="p">])</span>

<span class="c1">#石家庄数据集日期范围</span>
<span class="nb">print</span><span class="p">(</span><span class="n">sjz_df</span><span class="p">[</span><span class="s1">&#39;成立日期&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">sjz_df</span><span class="p">[</span><span class="s1">&#39;成立日期&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">1917-01-30 00:00:00
2023-09-19 00:00:00
</code></pre></div><br>
<p>查看成立日期为1917-01-30的信息</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">datetime</span>

<span class="n">sjz_df</span><span class="p">[</span><span class="n">sjz_df</span><span class="p">[</span><span class="s1">&#39;成立日期&#39;</span><span class="p">]</span><span class="o">==</span><span class="n">datetime</span><span class="o">.</span><span class="n">datetime</span><span class="p">(</span><span class="n">year</span><span class="o">=</span><span class="mi">1917</span><span class="p">,</span> <span class="n">month</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">day</span><span class="o">=</span><span class="mi">30</span><span class="p">)]</span><span class="o">.</span><span class="n">to_dict</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">{&#39;企业组织机构代码&#39;: {913555: &#39;81130000MC0611518K&#39;},
 &#39;企业名称&#39;: {913555: &#39;中国铁路工会石家庄站委员会&#39;},
 &#39;注册资本&#39;: {913555: &#39;276.5万元人民币&#39;},
 &#39;实缴资本&#39;: {913555: &#39;-&#39;},
 &#39;纳税人识别号&#39;: {913555: &#39;81130000MC0611518K&#39;},
 &#39;法定代表人&#39;: {913555: &#39;韩海峰&#39;},
 &#39;企业状态&#39;: {913555: &#39;暂无&#39;},
 &#39;所属行业&#39;: {913555: &#39;公共管理、社会保障和社会组织&#39;},
 &#39;统一社会信用代码&#39;: {913555: &#39;81130000MC0611518K&#39;},
 &#39;工商注册号&#39;: {913555: nan},
 &#39;组织机构代码&#39;: {913555: &#39;-&#39;},
 &#39;登记机关&#39;: {913555: &#39;河北省总工会&#39;},
 &#39;成立日期&#39;: {913555: Timestamp(&#39;1917-01-30 00:00:00&#39;)},
 &#39;核准日期&#39;: {913555: &#39;1949-10-01&#39;},
 &#39;企业类型&#39;: {913555: &#39;-&#39;},
 &#39;经营期限&#39;: {913555: &#39;2019-04-01 至 2022-02-09&#39;},
 &#39;注册所在地&#39;: {913555: nan},
 &#39;地区编码&#39;: {913555: &#39;130105&#39;},
 &#39;详细地址&#39;: {913555: &#39;石家庄市新华区大桥路2号&#39;},
 &#39;经营范围&#39;: {913555: &#39;-&#39;},
 &#39;参保人数&#39;: {913555: 478.0},
 &#39;企业电话&#39;: {913555: nan},
 &#39;企业座机&#39;: {913555: nan},
 &#39;企业邮箱&#39;: {913555: nan}}
</code></pre></div><p><br><br></p>
<h2 id="三可视化">三、可视化</h2>
<p>绘制一个1992-2023年的注册量折线图</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">matplotlib</span>
<span class="kn">import</span> <span class="nn">matplotlib_inline</span>
<span class="n">matplotlib_inline</span><span class="o">.</span><span class="n">backend_inline</span><span class="o">.</span><span class="n">set_matplotlib_formats</span><span class="p">(</span><span class="s1">&#39;png&#39;</span><span class="p">,</span> <span class="s1">&#39;svg&#39;</span><span class="p">)</span>
<span class="kn">import</span> <span class="nn">scienceplots</span>
<span class="kn">import</span> <span class="nn">platform</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">([</span><span class="s1">&#39;science&#39;</span><span class="p">,</span> <span class="s1">&#39;no-latex&#39;</span><span class="p">,</span> <span class="s1">&#39;cjk-sc-font&#39;</span><span class="p">])</span>
<span class="n">system</span> <span class="o">=</span> <span class="n">platform</span><span class="o">.</span><span class="n">system</span><span class="p">()</span>  <span class="c1"># 获取操作系统类型</span>

<span class="k">if</span> <span class="n">system</span> <span class="o">==</span> <span class="s1">&#39;Windows&#39;</span><span class="p">:</span>
    <span class="n">font</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;family&#39;</span><span class="p">:</span> <span class="s1">&#39;SimHei&#39;</span><span class="p">}</span>
<span class="k">elif</span> <span class="n">system</span> <span class="o">==</span> <span class="s1">&#39;Darwin&#39;</span><span class="p">:</span>
    <span class="n">font</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;family&#39;</span><span class="p">:</span> <span class="s1">&#39;Arial Unicode MS&#39;</span><span class="p">}</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">font</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;family&#39;</span><span class="p">:</span> <span class="s1">&#39;sans-serif&#39;</span><span class="p">}</span>
<span class="n">matplotlib</span><span class="o">.</span><span class="n">rc</span><span class="p">(</span><span class="s1">&#39;font&#39;</span><span class="p">,</span> <span class="o">**</span><span class="n">font</span><span class="p">)</span>  <span class="c1"># 设置全局字体</span>
    
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">years</span> <span class="o">=</span> <span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1992</span><span class="p">,</span> <span class="mi">2023</span><span class="p">)]</span>

<span class="n">sjz_df</span><span class="p">[</span><span class="s1">&#39;成立日期&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">slice</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="n">years</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;石家庄&#39;</span><span class="p">)</span>
<span class="n">cs_df</span><span class="p">[</span><span class="s1">&#39;成立日期&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">slice</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="n">years</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;长沙&#39;</span><span class="p">)</span>
<span class="n">hz_df</span><span class="p">[</span><span class="s1">&#39;成立日期&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">slice</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="n">years</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;杭州&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;工商企业注册量1992-2019年&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;年份&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;注册量&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper right&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>    
</code></pre></div><p><img loading="lazy" src="img/output_8_0.png" alt="svg"  />
</p>
<br>
<h2 id="四获取数据">四、获取数据</h2>
<p>内容为付费数据集， 100元， 加微信 372335839， 备注「姓名-学校-专业-工商数据集」</p>
<p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>Word Embeddings、Transformer与GPT：一文揭示三者关系</title>
      <link>https://textdata.cn/blog/2023-11-16-how-to-understand-the-meaning-of-gpt/</link>
      <pubDate>Thu, 16 Nov 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-11-16-how-to-understand-the-meaning-of-gpt/</guid>
      <description>&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;作者: 7号床
公众号: 7号床
原文  https://zhuanlan.zhihu.com/p/666206302
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;一gpt-的名词解释&#34;&gt;一、GPT 的名词解释&lt;/h2&gt;
&lt;p&gt;著名的 &lt;strong&gt;GPT&lt;/strong&gt; 这个名字全称是 &lt;strong&gt;Generative Pre-trained Transformer&lt;/strong&gt;。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Generative&lt;/strong&gt; 是&amp;quot;生成式&amp;quot;的意思，也就是说这个 AI 模型是用来生成内容的。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Pre-trained&lt;/strong&gt; 是“预训练”的意思，就是说这个 AI 模型能有很强的能力，是因为他事先做了大量的训练，台上一分钟台下十年功。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Transformer&lt;/strong&gt; , 就有点耐人寻味了，不仅普通人不理解，就连很多专业领域的人员理解起来也都是含混不清、似是而非。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/1.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;center&gt;ChatGPT 是 GPT 大模型在聊天对话领域的应用程序&lt;/center&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Transformer&lt;/strong&gt; 作为单词，翻译出来频率最高的意思是 &lt;strong&gt;变压器&lt;/strong&gt;，然后是 &lt;strong&gt;变形金刚&lt;/strong&gt; ，还有一些引申的含义是 &lt;strong&gt;转换器&lt;/strong&gt; 、&lt;strong&gt;促使变化者&lt;/strong&gt; 、&lt;strong&gt;转变者&lt;/strong&gt; 或 &lt;strong&gt;改革者&lt;/strong&gt;等等。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/2.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;center&gt;谷歌翻译上对 **Transformer** 的英译中翻译&lt;/center&gt;&lt;/p&gt;
&lt;p&gt;再把 &lt;strong&gt;Transformer&lt;/strong&gt; 放到  &lt;strong&gt;Chat Generative Pre-trained Transformer&lt;/strong&gt; 中看看，突然间变得奇怪了，难道 ChatGPT 借鉴了变压器的技术？还是说 ChatGPT 是一个变形金刚？或者索性就翻译成通用的安全的叫法 &lt;strong&gt;转换器&lt;/strong&gt; ？这让人百思不得其解。&lt;/p&gt;
&lt;p&gt;光光从 GPT 这三个字母的组合就能看出来， &lt;strong&gt;Generative&lt;/strong&gt; 与 &lt;strong&gt;Pre-trained&lt;/strong&gt; 都是定语，而 &lt;strong&gt;Transformer 才是 GPT 的主体，才是 GPT 的灵魂&lt;/strong&gt;所在。可以说，理解透了 &lt;strong&gt;Transformer&lt;/strong&gt; 的真正含义，才能初步地理解 GPT。另一方面， Transformer 这个词太重要了。它在这几年的人工智能领域大放异彩，不仅仅局限于 NLP 自然语言处理领域，它还有着更广阔的发展空间。 Transformer 目前已经进入到了多模态领域，比如音频与视觉，甚至数学公式、代码编程等领域，著名的 **Stable Diffusion 中也用到了 Transformer **。&lt;strong&gt;可以说，所有生成式人工智能领域的大模型中目前都有了这个 Transformer 的身影&lt;/strong&gt;。既然如此重要，那就让我们深入地探究一下 &lt;strong&gt;Transformer&lt;/strong&gt; 在人工智能领域最确切的最标准的含义到底是什么吧！&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Transformer&lt;/strong&gt; 最早是由 Google 的人工智能团队提出来的。在2017 年6月发表的论文**《Attention Is All You Need》中，他们首次提出了一种新的神经网络架构 Transformer**。Transformer 依赖于一个叫“自注意力机制”（ Self-Attention）的内部构件，可十分准确高效地对自然语言领域的问题进行处理，以完美地解决翻译、对话、论文协作甚至编程等复杂的问题。&lt;/p&gt;
&lt;p&gt;顺藤摸瓜可以看出，&lt;strong&gt;GTP 的核心是 Transformer，而 Transformer 的核心则是“自注意力机制”（ Self-Attention）&lt;/strong&gt;。那么这个“自注意力机制”又是什东西呢？让我们用语言翻译领域的几个简单易懂的例子来讲解一下。&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;二-transformer-的核心-self-attention&#34;&gt;二、 Transformer 的核心 Self-Attention&lt;/h2&gt;
&lt;p&gt;首先，看下面这两个短句：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;句子I&lt;/strong&gt;：The bank of the river.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;句子II&lt;/strong&gt;：Money in the bank.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在翻译成中文的过程中，机器算法是如何知道“句子I”中的“bank”指的是自然环境中的“岸边”，而“句子II”中的“bank”指的是金融体系中的“银行”呢？&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/3.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;center&gt;bank在不同句子中指代不同的事物&lt;/center&gt;&lt;/p&gt;
&lt;h3 id=&#34;21-人类脑中的翻译算法&#34;&gt;2.1 人类脑中的翻译算法&lt;/h3&gt;
&lt;p&gt;作为人类的我们当然会觉得这是一个再简单不过的事情了，那是因为我们的语言技能从幼儿发展到成年人后，早已烂熟于心了。但即使烂熟于心，也并不意味着在我们的大脑中没有对应的计算过程。&lt;strong&gt;实际上人工智能的翻译过程就是对我们人脑中的计算过程的模拟&lt;/strong&gt;。那么就让我们回想一下儿童时期学习语言时的情景吧，回想一下当时的我们是怎么知道一个多义词在某一句话中具体的含义的？&lt;/p&gt;
&lt;p&gt;人类做这件事的方法是根据 &lt;strong&gt;前后文的语义对照&lt;/strong&gt; 来确定结果，即看句子中其他相关联的单词是什么含义。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在 &lt;strong&gt;句子I&lt;/strong&gt; 中， &lt;em&gt;&lt;strong&gt;river&lt;/strong&gt;&lt;/em&gt; 这个词指明了自然环境，&lt;/li&gt;
&lt;li&gt;而在 &lt;strong&gt;句子II&lt;/strong&gt;中， &lt;em&gt;&lt;strong&gt;money&lt;/strong&gt;&lt;/em&gt; 这个词则指明了金融环境。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;所以两个句子中的多义词“bank”也就有了各自的定位。如果把这种方式总结成一种算法的话，这个算法就可以用于人工智能领域用于语言处理了。&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;22-机器算法模拟人脑中的翻译过程&#34;&gt;2.2 机器算法模拟人脑中的翻译过程&lt;/h3&gt;
&lt;p&gt;但人工智能作为一种计算机算法，它只能处理冷冰冰的数字，并不知道何为自然环境，何为金融环境，它又是怎么去判断 &lt;em&gt;&lt;strong&gt;river&lt;/strong&gt;&lt;/em&gt; 和 &lt;em&gt;&lt;strong&gt;money&lt;/strong&gt;&lt;/em&gt; 各自的含义呢。实际上，机器算法并不知道 &lt;em&gt;&lt;strong&gt;river&lt;/strong&gt;&lt;/em&gt; 和 &lt;em&gt;&lt;strong&gt;money&lt;/strong&gt;&lt;/em&gt; 的具体含义。但是机器可以通过某种数字的方式来表达 &lt;em&gt;&lt;strong&gt;river&lt;/strong&gt;&lt;/em&gt; 和 &lt;em&gt;&lt;strong&gt;money&lt;/strong&gt;&lt;/em&gt; ，同时，通过数字的方式还表达了许许多多其他的词汇，其中必然会有一些词汇会与 &lt;em&gt;&lt;strong&gt;river&lt;/strong&gt;&lt;/em&gt; 和 &lt;em&gt;&lt;strong&gt;money&lt;/strong&gt;&lt;/em&gt; 有着很紧密的语义上的逻辑关系。通过判断 &lt;em&gt;&lt;strong&gt;river&lt;/strong&gt;&lt;/em&gt; 和 &lt;em&gt;&lt;strong&gt;money&lt;/strong&gt;&lt;/em&gt; 各与哪些词汇在语义上有紧密的逻辑关系，便可以知道这两个词各属于什么领域了。&lt;/p&gt;
&lt;p&gt;（其实，不像人类会对某个领域有一个具体的名称来命名，在人工智能领域，机器最终也不知道这个领域的统称到底叫什么名字，但它却知道这个领域中都包括了哪些词、哪些概念和哪些逻辑。***机器不以单独名称来定义一个概念，它却可以用很多相关的概念与逻辑来圈定这一个概念！***这可能就是老子说的：道可道非常道，名可名非常名吧。）&lt;/p&gt;
&lt;br&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;独热编码法(One-hot Encoding)&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;那么就让我们看看这种数字表达方式具体是什么样子吧。&lt;/p&gt;
&lt;p&gt;假设这个世界上有100万个单词，每一个单词，我们都可以用一组 0 和 1 组成的向量（一组数字）来定义的话，那么每一个单词就可以被编码成100万个0或1组成的向量。如下图：&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/4.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;center&gt;独热编码示例&lt;/center&gt;&lt;/p&gt;
&lt;p&gt;这种单词编码方法叫 **独热编码法(One-hot Encoding)**法。可是这样一维的编码方法将导致向量占用的空间过大，1个单词用100万个单元的向量表达，世界上一共有100万个单词，那么就需要 1万亿（100万*100万）的体积来把它们表达出来，很明显这种臃肿的结构不利于电脑计算。&lt;/p&gt;
&lt;p&gt;但最大的问题还不在于这个体积问题，而是语义联系问题。独热编码使得单词与单词之间完全相互独立，从每个单词所编码成为的100万个单元的向量身上，根本看不出它与其他单词有何种语义内涵上的逻辑联系。比如，在这些数字中，我们无法知道 &lt;em&gt;&lt;strong&gt;apple&lt;/strong&gt;&lt;/em&gt; 和 &lt;em&gt;&lt;strong&gt;bag&lt;/strong&gt;&lt;/em&gt; 属于静物，区别于 cat 和 &lt;em&gt;&lt;strong&gt;dog&lt;/strong&gt;&lt;/em&gt;、&lt;em&gt;&lt;strong&gt;elephant&lt;/strong&gt;&lt;/em&gt; 属于动物且是哺乳动物，而 &lt;em&gt;&lt;strong&gt;cat&lt;/strong&gt;&lt;/em&gt;  和 &lt;em&gt;&lt;strong&gt;dog&lt;/strong&gt;&lt;/em&gt; 又属于小动物，且大多数为非野生，区别于 &lt;em&gt;&lt;strong&gt;elephant&lt;/strong&gt;&lt;/em&gt; 为大型的野生动物，等等等等，这些单词背后所蕴含的各种内在的逻辑联系和分类关系均无法从独热编码法中知晓。实际上独热编码是传统计算机数据库时代的产物，而在人工智能领域则采用另一种编码法。为了解决独热编码的问题， &lt;strong&gt;词嵌入编码法(Word Embedding)&lt;/strong&gt; 诞生了，如下图：&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/5.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;center&gt;Word Embedding 词嵌入编码示意，及 Embedding 空间&lt;/center&gt;&lt;/p&gt;
&lt;br&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;词嵌入编码法(Word Embedding)&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;**词嵌入编码法(Word Embedding)**将语义上相近的、有关联的词汇在 Embedding 空间中生成相近的位置定位。相对于 &lt;strong&gt;独热编码法&lt;/strong&gt; 超长的一维数据，词嵌入编码法(Word Embedding) 提升了数据的表达维度，它更像是在某一个 &lt;strong&gt;空间&lt;/strong&gt; 中对词汇进行编码。&lt;/p&gt;
&lt;p&gt;如上图（为了在此文章中表达方便，我们仅用二维空间来表达，实际上这个空间的维度很高，至少要在512维之上！一维二维三维的空间大家都可以在脑中想象出来对应的画面，但是四维以上以至于 512 维就难以图形化的想象了。），在 Embedding 的二维空间中 &lt;em&gt;&lt;strong&gt;dog&lt;/strong&gt;&lt;/em&gt;、 &lt;em&gt;&lt;strong&gt;cat&lt;/strong&gt;&lt;/em&gt; 、&lt;em&gt;&lt;strong&gt;rabbit&lt;/strong&gt;&lt;/em&gt; 三个向量的坐标点位排布，可以看到三个绿色的点距离很近，是因为他们三个相对于其他来说语义上更接近。tree 和 flower 则离它们较远，但是 &lt;em&gt;&lt;strong&gt;cat&lt;/strong&gt;&lt;/em&gt; 会因为在很多语言的文章中都会有“爬树”的词汇出现在同一句话中，所以导致  &lt;em&gt;&lt;strong&gt;cat&lt;/strong&gt;&lt;/em&gt;  会与  &lt;em&gt;&lt;strong&gt;tree&lt;/strong&gt;&lt;/em&gt;  离得较近一些。同时 &lt;em&gt;&lt;strong&gt;dog&lt;/strong&gt;&lt;/em&gt;、 &lt;em&gt;&lt;strong&gt;rabbit&lt;/strong&gt;&lt;/em&gt;  与  &lt;em&gt;&lt;strong&gt;tree&lt;/strong&gt;&lt;/em&gt; 的关系就较远。&lt;/p&gt;
&lt;p&gt;实际上，在 Embedding 空间中，词与词之间的关系还不仅仅限于语义上的分类所导致的定位远近这么简单。一个词所代表的事物与其他词所代表的事物之间能产生内在联系的往往有成百上千上万种之多。比如  &lt;em&gt;&lt;strong&gt;man&lt;/strong&gt;&lt;/em&gt;  和  &lt;em&gt;&lt;strong&gt;woman&lt;/strong&gt;&lt;/em&gt; ，他们之间的关系还会映射出  &lt;em&gt;&lt;strong&gt;king&lt;/strong&gt;&lt;/em&gt;  和  &lt;em&gt;&lt;strong&gt;queen&lt;/strong&gt;&lt;/em&gt;  之间的关系。同时，语法也会带来一定的联系，比如在一个三维空间中由  &lt;em&gt;&lt;strong&gt;walking&lt;/strong&gt;&lt;/em&gt;  到 &lt;em&gt;&lt;strong&gt;walked&lt;/strong&gt;&lt;/em&gt;  的距离与斜率竟然与  &lt;em&gt;&lt;strong&gt;swimming&lt;/strong&gt;&lt;/em&gt;  到 &lt;em&gt;&lt;strong&gt;swam&lt;/strong&gt;&lt;/em&gt; 的距离与斜率一致（即向量的长度与斜率一致），且距离几乎相等。因为这背后是两组动作单词的现在分词形式和过去分词形式的变化关系。我们可以尽情地想象，凡是事物或概念有逻辑联系的，甚至是逻辑与逻辑之间的联系的，在 Embedding 向量空间中都可以得到远近亲疏的空间表达。只不过这种空间要比我们能想象出的三维空间要高出很多维度。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/6.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;center&gt;在 Embedding 空间中隐含的内在逻辑关系&lt;/center&gt;&lt;/p&gt;
&lt;p&gt;Word Embedding 之所以能给每一个单词做这样有意义的向量空间的标注，是因为 AI 科学家们事先用了全球十多种主流语言的大量语料给它进行了训练。这些语料有小说、论文、学术期刊、网络文章、新闻报道、论坛对话记录等等等等，应有尽有，数以百亿到千亿计。可以说，这些海量的文字资料都是人类从古至今感受发现这个世界各个方面的文字总结和积累。现实世界中各种事物之间的逻辑关系都被人类用这些文字记录了下来，只是有的是用严谨的论文方式，有的是用写意的小说方式，有的使用类似维基百科这样的系统梳理，有的则是人们在网络论坛中的对话记录&amp;hellip;等等等等。但不管是什么方式，都是人类试图用语言对这个世界的描述。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;语言是人类最伟大的发明&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;笔者7号床曾经问过  ChatGPT  一个问题：&lt;em&gt;&lt;strong&gt;“人类最伟大的发明是什么”&lt;/strong&gt;&lt;/em&gt; ，ChatGPT的回答是：&lt;em&gt;&lt;strong&gt;“语言！”&lt;/strong&gt;&lt;/em&gt;。之后，ChatGPT 进一步回答，因为语言以及匹配语言的文字与符号，它们让人类把对世界的感受与理解记录下来，形成了知识宝库。方便全人类一代一代地不断完善这个宝库，并从中总结凝练、学习、创造、传承。语言是人类产生文明并开始与其他动物分道扬镳的分叉点。&lt;/p&gt;
&lt;p&gt;很多人曾经十分疑惑，人工智能吹得那么先进，却从一个 ChatGPT 聊天功能开始火爆起来。难道每天不干正事专门闲聊就证明了人工智能的先进性吗？现在看来，这个问题的答案已经浮出水面了，OpenAI 的团队选择通过聊天软件 ChatGPT 作为 GPT 启程的第一步是经过深思熟虑的。&lt;/p&gt;
&lt;p&gt;下面让我们回到正题。&lt;/p&gt;
&lt;p&gt;人类的知识宝库中存储着海量的信息
ChatGPT 所说的这个知识宝库现在变得越来越庞大、越来越复杂了。这世界上并不存在任何一个肉身的人类有能力做到对宝库中所有信息进行消化整理，因为内容体量过于庞大、过于复杂。而一个人的阅览进度却又是十分有限，以至于在他的有生之年，哪怕完成其中的万分之一都比登天还难。于是，迫不得已，人类才喊出了 &lt;em&gt;&lt;strong&gt;“闻道有先后，术业有专攻”&lt;/strong&gt;&lt;/em&gt; ，每个人类个体才转而去研究具体某一领域。&lt;/p&gt;
&lt;p&gt;另一方面，人类早期发明的纸张和印刷术，以至于后来的计算机芯片存储，倒是可以记录存储下来如此巨量的信息了，但却无法主动地、有机地分析汇总其中所有信息之间的内在逻辑。以至于计算机存储的这些数据越积越多，犹如汪洋大海。&lt;/p&gt;
&lt;p&gt;这个知识宝库的结构就好比一棵万米高的巨大知识树，人类如同蚂蚁一样在树上摸索前行。人类只能将有限的肉身算力资源集中在主要的枝干，对于无数的细枝末节尚无暇顾及，但随着发现的主要枝干越来越多，细枝末节的信息量将呈爆炸的方式展现出来。而对于这颗知识巨树的展示能力，却因为计算机时代的到来而大大加速了进程。但当发现知识树越来越庞大时，人类也认识到了自身的渺小。&lt;/p&gt;
&lt;p&gt;AI （Embedding）开启对知识宝库的挖掘
现在，这一探索知识巨树的任务落到了 AI 的身上，AI 的承载和运算能力超越了过往所有人类个体以及群体能力的总和。AI 通过事先的大量预训练，把这些海量文字用 Word Embedding 的方式抽象地汇总在了大模型之中。Word Embedding 词嵌入编码法，能让每一个单词之间产生应有的语义上的以及背后逻辑关系上的联系。这种联系越紧密，他们在 Embedding 空间中的位置距离越紧密，反之则越远。&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;23-attention-注意力机制&#34;&gt;2.3 Attention 注意力机制&lt;/h3&gt;
&lt;p&gt;想象一下，Google 用了至少千亿级的语料来训练单词在 Embedding 空间中的表达，其中包含了全世界几乎所有语言的词汇量。所以在回过头来考虑一下之前举例中的两句话时，就有了如下这样一副景象：&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/7.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;center&gt;在 Word Embedding 向量空间中 bank、 river 和 money 的向量表达&lt;/center&gt;&lt;/p&gt;
&lt;p&gt;如上图，我们用一个简单的位置关系图来展示一下&lt;em&gt;&lt;strong&gt;bank&lt;/strong&gt;&lt;/em&gt;、 &lt;em&gt;&lt;strong&gt;river&lt;/strong&gt;&lt;/em&gt; 和 &lt;em&gt;&lt;strong&gt;money&lt;/strong&gt;&lt;/em&gt; 这几个单词在 Embedding 空间中的位置关系（在实际 Embedding 空间中的关系要比这个图复杂数百倍，这里只是为了让大家更好地理解关键逻辑而做了简化）。&lt;/p&gt;
&lt;p&gt;由于 “bank” 是一个多义词，所以它在 Embedding 空间中的定位本来是有多个“分身”，我们取其中的两个分身，即“bank1”和“bank2”。那么，我们需要做的就是定位清晰“bank1”和“bank2”这两个单词在空间中到底各自离 &lt;em&gt;&lt;strong&gt;river&lt;/strong&gt;&lt;/em&gt; 和 &lt;em&gt;&lt;strong&gt;money&lt;/strong&gt;&lt;/em&gt; 的哪个单词更近一些。在图中很明显，“bank1”离 &lt;em&gt;&lt;strong&gt;river&lt;/strong&gt;&lt;/em&gt; 更近，而“bank2”离 &lt;em&gt;&lt;strong&gt;money&lt;/strong&gt;&lt;/em&gt; 更近，于是这两句话就变成了：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;**变形后的句子I：**The &lt;strong&gt;bank1&lt;/strong&gt; of the river.&lt;/li&gt;
&lt;li&gt;**变形后的句子II：**Money in the &lt;strong&gt;bank2&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如之前所说，虽然此时机器算法压根也不知道 &lt;em&gt;&lt;strong&gt;river&lt;/strong&gt;&lt;/em&gt; 和 &lt;em&gt;&lt;strong&gt;money&lt;/strong&gt;&lt;/em&gt; 到底是何物，但它知道在Embedding 空间中， &lt;em&gt;&lt;strong&gt;river&lt;/strong&gt;&lt;/em&gt; 周边有很多和大自然有关的词汇，比如  &lt;em&gt;&lt;strong&gt;water&lt;/strong&gt;&lt;/em&gt;、&lt;em&gt;&lt;strong&gt;tree&lt;/strong&gt;&lt;/em&gt;、&lt;em&gt;&lt;strong&gt;fish&lt;/strong&gt;&lt;/em&gt; 等等。而 &lt;em&gt;&lt;strong&gt;money&lt;/strong&gt;&lt;/em&gt; 周边有许多与金融有关的词汇，比如 &lt;em&gt;&lt;strong&gt;currency&lt;/strong&gt;&lt;/em&gt;,  &lt;em&gt;&lt;strong&gt;cash&lt;/strong&gt;&lt;/em&gt; ,  &lt;em&gt;&lt;strong&gt;withdraw&lt;/strong&gt;&lt;/em&gt; 等等。于是，机器算法知道了 &lt;em&gt;&lt;strong&gt;bank1&lt;/strong&gt;&lt;/em&gt; 代表的是与 &lt;em&gt;&lt;strong&gt;river&lt;/strong&gt;&lt;/em&gt; 有关的一个单词，与他们比较近的单词还有   &lt;em&gt;&lt;strong&gt;water&lt;/strong&gt;&lt;/em&gt;、&lt;em&gt;&lt;strong&gt;tree&lt;/strong&gt;&lt;/em&gt;、&lt;em&gt;&lt;strong&gt;fish&lt;/strong&gt;&lt;/em&gt; 等等，而“&lt;strong&gt;bank2&lt;/strong&gt;”代表的是与“&lt;strong&gt;money&lt;/strong&gt;”有关的一个单词，与他们比较接近的单词还有  &lt;em&gt;&lt;strong&gt;currency&lt;/strong&gt;&lt;/em&gt;,  &lt;em&gt;&lt;strong&gt;cash&lt;/strong&gt;&lt;/em&gt; ,  &lt;em&gt;&lt;strong&gt;withdraw&lt;/strong&gt;&lt;/em&gt;  等等。这就是**“Attention 注意力机制”的工作原理，也就是 Attention 让一个单词在句子中找到与它产生强语义联系的其他单词，并组成一个新的变体单词**：&lt;em&gt;&lt;strong&gt;bank1&lt;/strong&gt;&lt;/em&gt;、&lt;em&gt;&lt;strong&gt;bank2&lt;/strong&gt;&lt;/em&gt;。&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;24-self-attention-自注意力机制&#34;&gt;2.4 Self-Attention 自注意力机制&lt;/h3&gt;
&lt;p&gt;然后又有新的问题产生了，机器算法是如何知道一句话中只有 &lt;em&gt;&lt;strong&gt;river&lt;/strong&gt;&lt;/em&gt; 或 &lt;em&gt;&lt;strong&gt;money&lt;/strong&gt;&lt;/em&gt; 这两个词代表了上下文语义的强关联词汇，而不是 &lt;em&gt;&lt;strong&gt;The&lt;/strong&gt;&lt;/em&gt;、&lt;em&gt;&lt;strong&gt;in&lt;/strong&gt;&lt;/em&gt;、&lt;em&gt;&lt;strong&gt;of&lt;/strong&gt;&lt;/em&gt;或其他单词呢？实际上这依旧是 Embedding 空间中每一个单词的空间定位相近程度的问题。（实际上，在 Embedding 空间中，不仅仅名词有各自的位置，动词、介词、形容词等等都有自己的位置，甚至一个词组、一句话也会有自己的位置。）&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/8.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;全句中的每一个单词在 Embedding 空间中定位的相近度是这样来计算的。机器算法会对每一个单词与全句中其他单词逐一地配对，做语义关联程度的计算和比较，最终汇总到表格中，&lt;strong&gt;颜色越深代表语义关联程度越高&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/9.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;center&gt;一个句子中所有单词都做一遍“Attention 注意力机制”&lt;/center&gt;&lt;/p&gt;
&lt;p&gt;我们可以从表格中看出来：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;每一个单词与自己的相似度为最高分 1（一般用数值“1”来代表最大权重，这里的相似度用权重来表达）；&lt;/li&gt;
&lt;li&gt;互不相关的单词之间的语义关联度为 0（其实可能是 0.001 之类的很小的数字，这里做了简化，即值太小，以至于低于某一个阈值而归零处理）；&lt;/li&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;bank&lt;/strong&gt;&lt;/em&gt;  与   &lt;em&gt;&lt;strong&gt;river&lt;/strong&gt;&lt;/em&gt; 的相似度为 0.11；&lt;/li&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;bank&lt;/strong&gt;&lt;/em&gt; 与  &lt;em&gt;&lt;strong&gt;money&lt;/strong&gt;&lt;/em&gt; 的相似度为 0.25；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;每一个单词与自己的语义关联度为最高的 1（一般用数值“1”来代表最大权重，这里的相似度用权重来表达）；ention 自注意力机制”了。于是通过“自注意力机制”的语义关联比对后，我们便找出了 &lt;em&gt;&lt;strong&gt;river&lt;/strong&gt;&lt;/em&gt; 为 &lt;strong&gt;句子I&lt;/strong&gt; 全句中与 &lt;em&gt;&lt;strong&gt;bank&lt;/strong&gt;&lt;/em&gt; 关联度最大的词， &lt;em&gt;&lt;strong&gt;money&lt;/strong&gt;&lt;/em&gt; 为“句子II”全句中与“bank”关联度最大的单词，然后 &lt;strong&gt;句子I&lt;/strong&gt; 中的 &lt;em&gt;&lt;strong&gt;bank&lt;/strong&gt;&lt;/em&gt; 就被机器算法转换成了它的新变种 &lt;em&gt;&lt;strong&gt;bank1&lt;/strong&gt;&lt;/em&gt;（&lt;em&gt;&lt;strong&gt;river-bank&lt;/strong&gt;&lt;/em&gt;），而在 &lt;strong&gt;句子2&lt;/strong&gt; 中的 &lt;em&gt;&lt;strong&gt;bank&lt;/strong&gt;&lt;/em&gt; 则被机器算法转换成了它的新变种 &lt;em&gt;&lt;strong&gt;bank2&lt;/strong&gt;&lt;/em&gt;（“money-bank”）。然后机器算法就可以继续往后进行翻译工作了。&lt;/p&gt;
&lt;br&gt;
&lt;h2 id=&#34;25-transformer-最终实现准确的翻译&#34;&gt;2.5 Transformer 最终实现准确的翻译&lt;/h2&gt;
&lt;p&gt;Embedding 是一个全场景全维度的空间，它其中含有全世界的所有语言的单词。​在这同一空间中，不仅仅有英文，也有中文、法文、德文&amp;hellip;等等的 Embedding 词汇标注。​那么基于Embedding 空间表达的的翻译就变成了现实。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/10.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;center&gt;t-SNE visualization of the bilingual word embedding.（t-SNE 是一种高维数据可视化技术）&lt;/center&gt;&lt;/p&gt;
&lt;p&gt;比如，中文的 &lt;em&gt;&lt;strong&gt;河流&lt;/strong&gt;&lt;/em&gt; 和英文的 &lt;em&gt;&lt;strong&gt;river&lt;/strong&gt;&lt;/em&gt; 在 Embedding 空间中的位置基本是一样的，而 &lt;em&gt;&lt;strong&gt;钱&lt;/strong&gt;&lt;/em&gt; 和 &lt;em&gt;&lt;strong&gt;money&lt;/strong&gt;&lt;/em&gt; 的位置基本一样，&lt;em&gt;&lt;strong&gt;岸边&lt;/strong&gt;&lt;/em&gt; 和 &lt;em&gt;&lt;strong&gt;bank1&lt;/strong&gt;&lt;/em&gt; 的位置一样，&lt;em&gt;&lt;strong&gt;银行&lt;/strong&gt;&lt;/em&gt; 和 &lt;em&gt;&lt;strong&gt;bank2&lt;/strong&gt;&lt;/em&gt; 的位置一样。于是，把这些不同语言的定位一一找出来，就实现了十分正确的翻译结果了。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;句子I&lt;/strong&gt;：The &lt;em&gt;&lt;strong&gt;bank1&lt;/strong&gt;&lt;/em&gt; of the river.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;句子I翻译&lt;/strong&gt;：那个河流的岸边。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;句子II&lt;/strong&gt;：Money in the &lt;em&gt;&lt;strong&gt;bank2&lt;/strong&gt;&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;句子II翻译&lt;/strong&gt;：银行中的钱。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;至此，Transformer 和其中的核心部件 Self-Attention 对于语言翻译类信息处理的流程就被简要地讲清楚了。但像上面例子中 ***“The bank of the river.”***这样的句子太短太简单了，它甚至都无法称为一个完整的句子。在实际项目中，输入给 Transformer 的语句会更长更复杂，往往在一句话中有可能出现三个以上的单词有语义关联的关系，甚至更多。 比如这一句：“The animal did not cross the street because it was too tired. ”。很明显，在该句中和 &lt;em&gt;&lt;strong&gt;it&lt;/strong&gt;&lt;/em&gt; 有语义关系的词汇有两个，分别是 &lt;em&gt;&lt;strong&gt;animal&lt;/strong&gt;&lt;/em&gt; 和 &lt;em&gt;&lt;strong&gt;street&lt;/strong&gt;&lt;/em&gt;。&lt;/p&gt;
&lt;p&gt;对于这样的情况，处理机制和“The bank of the river.”的处理机制仍然是一样的。Self-Attention 一样会对全句中的所有单词都进行在 Embedding 空间中的距离比较，即语义关联权重的比较。&lt;/p&gt;
&lt;p&gt;在 &lt;em&gt;&lt;strong&gt;“The animal did not cross the street because it was too tired.”&lt;/strong&gt;&lt;/em&gt; 中 &lt;em&gt;&lt;strong&gt;it&lt;/strong&gt;&lt;/em&gt;与 &lt;em&gt;&lt;strong&gt;animal&lt;/strong&gt;&lt;/em&gt; 的语义关联权重比与 &lt;em&gt;&lt;strong&gt;street&lt;/strong&gt;&lt;/em&gt;的语义关联权重要高。因此，Self-Attention 自注意力机制处理后的结果将以 &lt;em&gt;&lt;strong&gt;animal&lt;/strong&gt;&lt;/em&gt; 为主导来生成新的单词 &lt;em&gt;&lt;strong&gt;it1&lt;/strong&gt;&lt;/em&gt; ，即 &lt;em&gt;&lt;strong&gt;it1 =“animal-it”&lt;/strong&gt;&lt;/em&gt;。此时就变成了 &lt;em&gt;&lt;strong&gt;“The animal did not cross the street becauseit1 was too tired. ”&lt;/strong&gt;&lt;/em&gt; 。翻译成法语为：“L‘animaln’a pas traverse la rue parceil était trop fatigue.” 。翻译成中文则为：“这只动物没有过马路，因为它太累了。”。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/11.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;center&gt;色块的深浅表明了与“it”语义关联权重的强弱。这里“it”与“animal”的语义关联权重最大&lt;/center&gt;&lt;/p&gt;
&lt;p&gt;在另一句话中，&lt;em&gt;&lt;strong&gt;“The animal did not cross the street because it was too wide.” &lt;em&gt;&lt;strong&gt;，只是一字之差， &lt;em&gt;&lt;strong&gt;tired&lt;/strong&gt;&lt;/em&gt; 变成了 &lt;em&gt;&lt;strong&gt;wide&lt;/strong&gt;&lt;/em&gt;，导致了全句的语义发生了很大的变化，尤其是 &lt;em&gt;&lt;strong&gt;it&lt;/strong&gt;&lt;/em&gt; 所指的对象由 &lt;em&gt;&lt;strong&gt;animal&lt;/strong&gt;&lt;/em&gt; 变成了&lt;/strong&gt;&lt;/em&gt;street&lt;/strong&gt;&lt;/em&gt;。此时 Self-Attention 同样按照以前的方法进行语义关联度匹配，结果是&lt;em&gt;&lt;strong&gt;animal&lt;/strong&gt;&lt;/em&gt; 和 &lt;em&gt;&lt;strong&gt;street&lt;/strong&gt;&lt;/em&gt; 的权重在全句中都很高，但是 &lt;em&gt;&lt;strong&gt;street&lt;/strong&gt;&lt;/em&gt; 是最高的，所以最终的结果将以 &lt;em&gt;&lt;strong&gt;street&lt;/strong&gt;&lt;/em&gt; 主导来生成新的 &lt;em&gt;&lt;strong&gt;it2&lt;/strong&gt;&lt;/em&gt; ，即 &lt;em&gt;&lt;strong&gt;it2=“street-it”&lt;/strong&gt;&lt;/em&gt;。此时就变成了“The animal did not cross the street becauseit2was too wide.” 。翻译成法语为：“L‘animal n’a pas traverse la rue parceelle était trop large. ”。翻译成中文为：“这只动物没有过马路，因为路太宽了。”&lt;strong&gt;（注意：这里用的是“路”，而不是“它”，稍后会解释）&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/12.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;center&gt;这里“it”与“street”的语义关联权重最大&lt;/center&gt;&lt;/p&gt;
&lt;p&gt;之所以 Self-Attention 可以把 Word Embedding 中的权重比较做得如此细腻，不仅是因为 Google 用了千亿级的语料来训练 Word Embedding。同时更是因为 Transformer 模型本身的架构核心 Self-Attention 也有与之匹配的超级强大的处理能力，它在超长语句上的处理能力远远超过了早先的 RNN （循环神经网络）和 CNN （卷积神经网络）（这两个著名的人工神经网络我会在之后的文章中一一介绍），它不仅仅能对一句中所有单词做 Self-Attention 自注意力机制的审核，它还可以对一整段话，甚至全篇文章做审核。这就是我们通常说的要结合上下文来理解语句并翻译。最新的 GPT-4 Turbo 一次可以处理大约 9.6 万个单词，比许多小说都长。此外，12.8万字（128K）的上下文长度可以导致更长的对话，而不会让人工智能在超长文的对话或翻译过程中迷失方向。&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;26-word-embedding-的进一步扩展-sentence-embedding&#34;&gt;2.6 Word Embedding 的进一步扩展 Sentence Embedding&lt;/h3&gt;
&lt;p&gt;这一强大的能力，同样也来源于 Word Embedding 的能力。它不仅仅可以对单个词语进行定位，它甚至还可以做到对句子进行逻辑定位，如下图中所示。这种能力被称为“Sentence Embedding”。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/13.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;center&gt;Sentence Embedding 可以表达句子与句子之间的关系&lt;/center&gt;&lt;/p&gt;
&lt;p&gt;Word Embedding 和 Sentence Embedding 是大语言模型（Large Language Models，LLMs）的重要基础组成部分。它们将人类语言转化为了计算机能够读懂的底层数字表达方式，并且通过多维度的空间定位捕捉了各个单词、短语、句子在语义上的细微差别，以及它们之间的逻辑联系。&lt;strong&gt;这种底层的数字表达已经跨越了不同的语系语言，成为了全人类共用的最底层语言逻辑，甚至成为了一种世界语——AI 世界语，这对于翻译、搜索和理解不同语言语种具有非常重要的作用。可以说，巴别塔的传说自此解决！！&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;既有“大力出奇迹”的训练内容，更有承载“大力出奇迹”的结构，最终导致 Transformer 必然产生了这样的“奇迹”，使它能够在机器翻译领域达到了人类翻译的“信达雅”的成就。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/14.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;center&gt;BLEU 英译德评分&lt;/center&gt;&lt;/p&gt;
&lt;br&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/15.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;center&gt;BLEU 英译法评分&lt;/center&gt;&lt;/p&gt;
&lt;p&gt;上两幅图中，在 BLEU 的英德翻译与英法翻译领域 Transformer 得分最高。 （ 注：BLEU，bilingual evaluation understudy，即：双语互译质量评估辅助工具。它是用来评估机器翻译质量的工具。BLEU的设计思想：机器翻译结果越接近专业人工翻译的结果则越好。）&lt;/p&gt;
&lt;p&gt;通过一个小例子就能看出它的优越性，正好说说为什么是“路”而不是“它”，之前这两句的翻译结果如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The animal did not cross the street because &lt;strong&gt;it1&lt;/strong&gt; was too tired.&lt;/li&gt;
&lt;li&gt;L&amp;rsquo;animal n&amp;rsquo;a pas traverse la rue parce &lt;strong&gt;il&lt;/strong&gt; était trop fatigue.&lt;/li&gt;
&lt;li&gt;这只动物没有过马路，因为&lt;strong&gt;它&lt;/strong&gt;太累了。&lt;/li&gt;
&lt;li&gt;———————————————&lt;/li&gt;
&lt;li&gt;The animal did not cross the street because &lt;strong&gt;it2&lt;/strong&gt; was too wide.&lt;/li&gt;
&lt;li&gt;L&amp;rsquo;animal n&amp;rsquo;a pas traverse la rue parce &lt;strong&gt;elle&lt;/strong&gt; était trop large.&lt;/li&gt;
&lt;li&gt;这只动物没有过马路，因为&lt;strong&gt;路&lt;/strong&gt;太宽了。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在法语中 il 和 elle 是明显不同的，因此他们可以在各自句子中指代出 &lt;em&gt;&lt;strong&gt;it&lt;/strong&gt;&lt;/em&gt; 的不同的翻译结果，不会引起语义模糊。这种在法语中明显的区别在翻译成中文时，就没有这么简单了。如果把两句话翻译成中文，&lt;em&gt;&lt;strong&gt;it&lt;/strong&gt;&lt;/em&gt; 都可以被粗糙地翻译成“它”，则第二句的语义将被普遍地认为不够精准，因为翻译成“它”会产生一定的语义模糊。取而代之，用“路”则更能达到“信达雅”的效果。大家可以用不同的翻译软件测试一下这两句话的英译中翻译，就知道哪些软件用了 Transformer 的底层技术，而哪些没用了！（你懂的 ）&lt;/p&gt;
&lt;p&gt;好了，绕了这么远，解释了这么多，终于可以说说这个 &lt;strong&gt;Transformer&lt;/strong&gt; 到底是什么意思了！&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;三ai-领域-transformer-的确切含义&#34;&gt;三、AI 领域 Transformer 的确切含义&lt;/h2&gt;
&lt;p&gt;**单词“X”转化为“X1”，“X”代表在 Transformer 处理之前一句话中的单词，而“X1”则代表了经过 Transformer 的 Slef-Attention 处理之后，附加了句子中其他具有强语义关联关系的单词后的“变种单词”。**其实，句子还是原来那个句子，单词还是那个单词，本质并没有变，但表达形式却变了。就如同“bank”被转变成了“bank1”一样。“bank1”的灵魂还是那个“bank”，但是“bank1”展示出来了隐藏在“bank”身体中的另一面“river-bank”。&lt;/p&gt;
&lt;p&gt;所以，用众所周知的  &lt;em&gt;&lt;strong&gt;变形金刚 Transformer&lt;/strong&gt;&lt;/em&gt; 来命名与解释就再贴切不过了~！ &lt;em&gt;&lt;strong&gt;bank&lt;/strong&gt;&lt;/em&gt; 变形成了 &lt;em&gt;&lt;strong&gt;bank1&lt;/strong&gt;&lt;/em&gt;， ***bank ***与 &lt;em&gt;&lt;strong&gt;bank1&lt;/strong&gt;&lt;/em&gt; 异体同身！&lt;em&gt;&lt;strong&gt;大黄蜂&lt;/strong&gt;&lt;/em&gt; 既是机器人，&lt;em&gt;&lt;strong&gt;大黄蜂&lt;/strong&gt;&lt;/em&gt; 也是跑车。由车变形到机器人，再由机器人变形到车，万变不离其宗，都是 &lt;em&gt;&lt;strong&gt;大黄蜂&lt;/strong&gt;&lt;/em&gt; ，本质上并没有改变，但是，外观变了，用途也就变了！&lt;/p&gt;
&lt;p&gt;在车的状态下，容易让人混淆（你本以为它是一辆车，但其实他是一个机器人，不变成人形，你还真认不出来）。就如同多义词一样，过往的翻译机制很难辨认出它在一句话中的确切含义，他们虽然也有上下文语义的兼顾理解能力，但是处理信息量还是太少，导致他们无法做到十分精准，经常造成单词虽然翻译对了，但放在句子里却容易产生含混不清甚至错误。但是通过 Transformer 的变形操作，“大黄蜂”的车状态就变形成了同样叫 &lt;em&gt;&lt;strong&gt;大黄蜂&lt;/strong&gt;&lt;/em&gt; 的机器人状态，再放回到句子中，则让它现了原型，于是一切水落石出！&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/16.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;center&gt;“大黄蜂”既是机器人，“大黄蜂”也是跑车，本质上都是同一个家伙，只是在不同的场合有不同的用途。&lt;/center&gt;&lt;/p&gt;
&lt;p&gt;Google 的技术团队就是用了“变形金刚 Transformer”这个梗。如此的诙谐幽默、简单直白，半开玩笑地就起了个技术名词。但也不得不承认“变形金刚 Transformer”这个词用在这里，用于这个技术名词的命名，也确实再贴切不过了，真正的名副其实！&lt;/p&gt;
&lt;p&gt;所以，当下次有人问你“GPT”到底是什么、翻译成中文又是什么意思时，你就可以明确地对他说：&lt;em&gt;&lt;strong&gt;“生成式预训练转换器”&lt;/strong&gt;&lt;/em&gt; 或者 &lt;em&gt;&lt;strong&gt;“生成式预训练变形金刚”&lt;/strong&gt;&lt;/em&gt;（前者翻译得其实也很含糊，所以我建议后者，虽然对方可能会嘲笑你几分钟，但也仅限这几分钟）。懂的人自然懂，不懂的也不用去解释！&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;广而告之&#34;&gt;广而告之&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/call_for_paper/&#34;&gt;长期征稿&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/we_need_you/&#34;&gt;长期招募小伙伴&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[付费视频课 | Python实证指标构建与文本分析](&lt;a href=&#34;https://textdata.cn/blog/&#34;&gt;https://textdata.cn/blog/&lt;/a&gt; &lt;em&gt;&lt;strong&gt;man&lt;/strong&gt;&lt;/em&gt; agement_python_course/)&lt;/li&gt;
&lt;/ul&gt;
</description>
      <content:encoded><![CDATA[<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">作者: 7号床
公众号: 7号床
原文  https://zhuanlan.zhihu.com/p/666206302
</code></pre></div><p><br><br></p>
<h2 id="一gpt-的名词解释">一、GPT 的名词解释</h2>
<p>著名的 <strong>GPT</strong> 这个名字全称是 <strong>Generative Pre-trained Transformer</strong>。</p>
<ul>
<li><strong>Generative</strong> 是&quot;生成式&quot;的意思，也就是说这个 AI 模型是用来生成内容的。</li>
<li><strong>Pre-trained</strong> 是“预训练”的意思，就是说这个 AI 模型能有很强的能力，是因为他事先做了大量的训练，台上一分钟台下十年功。</li>
<li><strong>Transformer</strong> , 就有点耐人寻味了，不仅普通人不理解，就连很多专业领域的人员理解起来也都是含混不清、似是而非。</li>
</ul>
<p><img loading="lazy" src="img/1.png" alt=""  />
</p>
<p><center>ChatGPT 是 GPT 大模型在聊天对话领域的应用程序</center></p>
<p><strong>Transformer</strong> 作为单词，翻译出来频率最高的意思是 <strong>变压器</strong>，然后是 <strong>变形金刚</strong> ，还有一些引申的含义是 <strong>转换器</strong> 、<strong>促使变化者</strong> 、<strong>转变者</strong> 或 <strong>改革者</strong>等等。</p>
<p><img loading="lazy" src="img/2.png" alt=""  />
</p>
<p><center>谷歌翻译上对 **Transformer** 的英译中翻译</center></p>
<p>再把 <strong>Transformer</strong> 放到  <strong>Chat Generative Pre-trained Transformer</strong> 中看看，突然间变得奇怪了，难道 ChatGPT 借鉴了变压器的技术？还是说 ChatGPT 是一个变形金刚？或者索性就翻译成通用的安全的叫法 <strong>转换器</strong> ？这让人百思不得其解。</p>
<p>光光从 GPT 这三个字母的组合就能看出来， <strong>Generative</strong> 与 <strong>Pre-trained</strong> 都是定语，而 <strong>Transformer 才是 GPT 的主体，才是 GPT 的灵魂</strong>所在。可以说，理解透了 <strong>Transformer</strong> 的真正含义，才能初步地理解 GPT。另一方面， Transformer 这个词太重要了。它在这几年的人工智能领域大放异彩，不仅仅局限于 NLP 自然语言处理领域，它还有着更广阔的发展空间。 Transformer 目前已经进入到了多模态领域，比如音频与视觉，甚至数学公式、代码编程等领域，著名的 **Stable Diffusion 中也用到了 Transformer **。<strong>可以说，所有生成式人工智能领域的大模型中目前都有了这个 Transformer 的身影</strong>。既然如此重要，那就让我们深入地探究一下 <strong>Transformer</strong> 在人工智能领域最确切的最标准的含义到底是什么吧！</p>
<p><strong>Transformer</strong> 最早是由 Google 的人工智能团队提出来的。在2017 年6月发表的论文**《Attention Is All You Need》中，他们首次提出了一种新的神经网络架构 Transformer**。Transformer 依赖于一个叫“自注意力机制”（ Self-Attention）的内部构件，可十分准确高效地对自然语言领域的问题进行处理，以完美地解决翻译、对话、论文协作甚至编程等复杂的问题。</p>
<p>顺藤摸瓜可以看出，<strong>GTP 的核心是 Transformer，而 Transformer 的核心则是“自注意力机制”（ Self-Attention）</strong>。那么这个“自注意力机制”又是什东西呢？让我们用语言翻译领域的几个简单易懂的例子来讲解一下。</p>
<p><br><br></p>
<h2 id="二-transformer-的核心-self-attention">二、 Transformer 的核心 Self-Attention</h2>
<p>首先，看下面这两个短句：</p>
<ul>
<li><strong>句子I</strong>：The bank of the river.</li>
<li><strong>句子II</strong>：Money in the bank.</li>
</ul>
<p>在翻译成中文的过程中，机器算法是如何知道“句子I”中的“bank”指的是自然环境中的“岸边”，而“句子II”中的“bank”指的是金融体系中的“银行”呢？</p>
<p><img loading="lazy" src="img/3.png" alt=""  />
</p>
<p><center>bank在不同句子中指代不同的事物</center></p>
<h3 id="21-人类脑中的翻译算法">2.1 人类脑中的翻译算法</h3>
<p>作为人类的我们当然会觉得这是一个再简单不过的事情了，那是因为我们的语言技能从幼儿发展到成年人后，早已烂熟于心了。但即使烂熟于心，也并不意味着在我们的大脑中没有对应的计算过程。<strong>实际上人工智能的翻译过程就是对我们人脑中的计算过程的模拟</strong>。那么就让我们回想一下儿童时期学习语言时的情景吧，回想一下当时的我们是怎么知道一个多义词在某一句话中具体的含义的？</p>
<p>人类做这件事的方法是根据 <strong>前后文的语义对照</strong> 来确定结果，即看句子中其他相关联的单词是什么含义。</p>
<ul>
<li>在 <strong>句子I</strong> 中， <em><strong>river</strong></em> 这个词指明了自然环境，</li>
<li>而在 <strong>句子II</strong>中， <em><strong>money</strong></em> 这个词则指明了金融环境。</li>
</ul>
<p>所以两个句子中的多义词“bank”也就有了各自的定位。如果把这种方式总结成一种算法的话，这个算法就可以用于人工智能领域用于语言处理了。</p>
<br>
<h3 id="22-机器算法模拟人脑中的翻译过程">2.2 机器算法模拟人脑中的翻译过程</h3>
<p>但人工智能作为一种计算机算法，它只能处理冷冰冰的数字，并不知道何为自然环境，何为金融环境，它又是怎么去判断 <em><strong>river</strong></em> 和 <em><strong>money</strong></em> 各自的含义呢。实际上，机器算法并不知道 <em><strong>river</strong></em> 和 <em><strong>money</strong></em> 的具体含义。但是机器可以通过某种数字的方式来表达 <em><strong>river</strong></em> 和 <em><strong>money</strong></em> ，同时，通过数字的方式还表达了许许多多其他的词汇，其中必然会有一些词汇会与 <em><strong>river</strong></em> 和 <em><strong>money</strong></em> 有着很紧密的语义上的逻辑关系。通过判断 <em><strong>river</strong></em> 和 <em><strong>money</strong></em> 各与哪些词汇在语义上有紧密的逻辑关系，便可以知道这两个词各属于什么领域了。</p>
<p>（其实，不像人类会对某个领域有一个具体的名称来命名，在人工智能领域，机器最终也不知道这个领域的统称到底叫什么名字，但它却知道这个领域中都包括了哪些词、哪些概念和哪些逻辑。***机器不以单独名称来定义一个概念，它却可以用很多相关的概念与逻辑来圈定这一个概念！***这可能就是老子说的：道可道非常道，名可名非常名吧。）</p>
<br>
<ul>
<li><strong>独热编码法(One-hot Encoding)</strong></li>
</ul>
<p>那么就让我们看看这种数字表达方式具体是什么样子吧。</p>
<p>假设这个世界上有100万个单词，每一个单词，我们都可以用一组 0 和 1 组成的向量（一组数字）来定义的话，那么每一个单词就可以被编码成100万个0或1组成的向量。如下图：</p>
<p><img loading="lazy" src="img/4.png" alt=""  />
</p>
<p><center>独热编码示例</center></p>
<p>这种单词编码方法叫 **独热编码法(One-hot Encoding)**法。可是这样一维的编码方法将导致向量占用的空间过大，1个单词用100万个单元的向量表达，世界上一共有100万个单词，那么就需要 1万亿（100万*100万）的体积来把它们表达出来，很明显这种臃肿的结构不利于电脑计算。</p>
<p>但最大的问题还不在于这个体积问题，而是语义联系问题。独热编码使得单词与单词之间完全相互独立，从每个单词所编码成为的100万个单元的向量身上，根本看不出它与其他单词有何种语义内涵上的逻辑联系。比如，在这些数字中，我们无法知道 <em><strong>apple</strong></em> 和 <em><strong>bag</strong></em> 属于静物，区别于 cat 和 <em><strong>dog</strong></em>、<em><strong>elephant</strong></em> 属于动物且是哺乳动物，而 <em><strong>cat</strong></em>  和 <em><strong>dog</strong></em> 又属于小动物，且大多数为非野生，区别于 <em><strong>elephant</strong></em> 为大型的野生动物，等等等等，这些单词背后所蕴含的各种内在的逻辑联系和分类关系均无法从独热编码法中知晓。实际上独热编码是传统计算机数据库时代的产物，而在人工智能领域则采用另一种编码法。为了解决独热编码的问题， <strong>词嵌入编码法(Word Embedding)</strong> 诞生了，如下图：</p>
<p><img loading="lazy" src="img/5.png" alt=""  />
</p>
<p><center>Word Embedding 词嵌入编码示意，及 Embedding 空间</center></p>
<br>
<ul>
<li><strong>词嵌入编码法(Word Embedding)</strong></li>
</ul>
<p>**词嵌入编码法(Word Embedding)**将语义上相近的、有关联的词汇在 Embedding 空间中生成相近的位置定位。相对于 <strong>独热编码法</strong> 超长的一维数据，词嵌入编码法(Word Embedding) 提升了数据的表达维度，它更像是在某一个 <strong>空间</strong> 中对词汇进行编码。</p>
<p>如上图（为了在此文章中表达方便，我们仅用二维空间来表达，实际上这个空间的维度很高，至少要在512维之上！一维二维三维的空间大家都可以在脑中想象出来对应的画面，但是四维以上以至于 512 维就难以图形化的想象了。），在 Embedding 的二维空间中 <em><strong>dog</strong></em>、 <em><strong>cat</strong></em> 、<em><strong>rabbit</strong></em> 三个向量的坐标点位排布，可以看到三个绿色的点距离很近，是因为他们三个相对于其他来说语义上更接近。tree 和 flower 则离它们较远，但是 <em><strong>cat</strong></em> 会因为在很多语言的文章中都会有“爬树”的词汇出现在同一句话中，所以导致  <em><strong>cat</strong></em>  会与  <em><strong>tree</strong></em>  离得较近一些。同时 <em><strong>dog</strong></em>、 <em><strong>rabbit</strong></em>  与  <em><strong>tree</strong></em> 的关系就较远。</p>
<p>实际上，在 Embedding 空间中，词与词之间的关系还不仅仅限于语义上的分类所导致的定位远近这么简单。一个词所代表的事物与其他词所代表的事物之间能产生内在联系的往往有成百上千上万种之多。比如  <em><strong>man</strong></em>  和  <em><strong>woman</strong></em> ，他们之间的关系还会映射出  <em><strong>king</strong></em>  和  <em><strong>queen</strong></em>  之间的关系。同时，语法也会带来一定的联系，比如在一个三维空间中由  <em><strong>walking</strong></em>  到 <em><strong>walked</strong></em>  的距离与斜率竟然与  <em><strong>swimming</strong></em>  到 <em><strong>swam</strong></em> 的距离与斜率一致（即向量的长度与斜率一致），且距离几乎相等。因为这背后是两组动作单词的现在分词形式和过去分词形式的变化关系。我们可以尽情地想象，凡是事物或概念有逻辑联系的，甚至是逻辑与逻辑之间的联系的，在 Embedding 向量空间中都可以得到远近亲疏的空间表达。只不过这种空间要比我们能想象出的三维空间要高出很多维度。</p>
<p><img loading="lazy" src="img/6.png" alt=""  />
</p>
<p><center>在 Embedding 空间中隐含的内在逻辑关系</center></p>
<p>Word Embedding 之所以能给每一个单词做这样有意义的向量空间的标注，是因为 AI 科学家们事先用了全球十多种主流语言的大量语料给它进行了训练。这些语料有小说、论文、学术期刊、网络文章、新闻报道、论坛对话记录等等等等，应有尽有，数以百亿到千亿计。可以说，这些海量的文字资料都是人类从古至今感受发现这个世界各个方面的文字总结和积累。现实世界中各种事物之间的逻辑关系都被人类用这些文字记录了下来，只是有的是用严谨的论文方式，有的是用写意的小说方式，有的使用类似维基百科这样的系统梳理，有的则是人们在网络论坛中的对话记录&hellip;等等等等。但不管是什么方式，都是人类试图用语言对这个世界的描述。</p>
<ul>
<li><strong>语言是人类最伟大的发明</strong></li>
</ul>
<p>笔者7号床曾经问过  ChatGPT  一个问题：<em><strong>“人类最伟大的发明是什么”</strong></em> ，ChatGPT的回答是：<em><strong>“语言！”</strong></em>。之后，ChatGPT 进一步回答，因为语言以及匹配语言的文字与符号，它们让人类把对世界的感受与理解记录下来，形成了知识宝库。方便全人类一代一代地不断完善这个宝库，并从中总结凝练、学习、创造、传承。语言是人类产生文明并开始与其他动物分道扬镳的分叉点。</p>
<p>很多人曾经十分疑惑，人工智能吹得那么先进，却从一个 ChatGPT 聊天功能开始火爆起来。难道每天不干正事专门闲聊就证明了人工智能的先进性吗？现在看来，这个问题的答案已经浮出水面了，OpenAI 的团队选择通过聊天软件 ChatGPT 作为 GPT 启程的第一步是经过深思熟虑的。</p>
<p>下面让我们回到正题。</p>
<p>人类的知识宝库中存储着海量的信息
ChatGPT 所说的这个知识宝库现在变得越来越庞大、越来越复杂了。这世界上并不存在任何一个肉身的人类有能力做到对宝库中所有信息进行消化整理，因为内容体量过于庞大、过于复杂。而一个人的阅览进度却又是十分有限，以至于在他的有生之年，哪怕完成其中的万分之一都比登天还难。于是，迫不得已，人类才喊出了 <em><strong>“闻道有先后，术业有专攻”</strong></em> ，每个人类个体才转而去研究具体某一领域。</p>
<p>另一方面，人类早期发明的纸张和印刷术，以至于后来的计算机芯片存储，倒是可以记录存储下来如此巨量的信息了，但却无法主动地、有机地分析汇总其中所有信息之间的内在逻辑。以至于计算机存储的这些数据越积越多，犹如汪洋大海。</p>
<p>这个知识宝库的结构就好比一棵万米高的巨大知识树，人类如同蚂蚁一样在树上摸索前行。人类只能将有限的肉身算力资源集中在主要的枝干，对于无数的细枝末节尚无暇顾及，但随着发现的主要枝干越来越多，细枝末节的信息量将呈爆炸的方式展现出来。而对于这颗知识巨树的展示能力，却因为计算机时代的到来而大大加速了进程。但当发现知识树越来越庞大时，人类也认识到了自身的渺小。</p>
<p>AI （Embedding）开启对知识宝库的挖掘
现在，这一探索知识巨树的任务落到了 AI 的身上，AI 的承载和运算能力超越了过往所有人类个体以及群体能力的总和。AI 通过事先的大量预训练，把这些海量文字用 Word Embedding 的方式抽象地汇总在了大模型之中。Word Embedding 词嵌入编码法，能让每一个单词之间产生应有的语义上的以及背后逻辑关系上的联系。这种联系越紧密，他们在 Embedding 空间中的位置距离越紧密，反之则越远。</p>
<br>
<h3 id="23-attention-注意力机制">2.3 Attention 注意力机制</h3>
<p>想象一下，Google 用了至少千亿级的语料来训练单词在 Embedding 空间中的表达，其中包含了全世界几乎所有语言的词汇量。所以在回过头来考虑一下之前举例中的两句话时，就有了如下这样一副景象：</p>
<p><img loading="lazy" src="img/7.png" alt=""  />
</p>
<p><center>在 Word Embedding 向量空间中 bank、 river 和 money 的向量表达</center></p>
<p>如上图，我们用一个简单的位置关系图来展示一下<em><strong>bank</strong></em>、 <em><strong>river</strong></em> 和 <em><strong>money</strong></em> 这几个单词在 Embedding 空间中的位置关系（在实际 Embedding 空间中的关系要比这个图复杂数百倍，这里只是为了让大家更好地理解关键逻辑而做了简化）。</p>
<p>由于 “bank” 是一个多义词，所以它在 Embedding 空间中的定位本来是有多个“分身”，我们取其中的两个分身，即“bank1”和“bank2”。那么，我们需要做的就是定位清晰“bank1”和“bank2”这两个单词在空间中到底各自离 <em><strong>river</strong></em> 和 <em><strong>money</strong></em> 的哪个单词更近一些。在图中很明显，“bank1”离 <em><strong>river</strong></em> 更近，而“bank2”离 <em><strong>money</strong></em> 更近，于是这两句话就变成了：</p>
<ul>
<li>**变形后的句子I：**The <strong>bank1</strong> of the river.</li>
<li>**变形后的句子II：**Money in the <strong>bank2</strong>.</li>
</ul>
<p>如之前所说，虽然此时机器算法压根也不知道 <em><strong>river</strong></em> 和 <em><strong>money</strong></em> 到底是何物，但它知道在Embedding 空间中， <em><strong>river</strong></em> 周边有很多和大自然有关的词汇，比如  <em><strong>water</strong></em>、<em><strong>tree</strong></em>、<em><strong>fish</strong></em> 等等。而 <em><strong>money</strong></em> 周边有许多与金融有关的词汇，比如 <em><strong>currency</strong></em>,  <em><strong>cash</strong></em> ,  <em><strong>withdraw</strong></em> 等等。于是，机器算法知道了 <em><strong>bank1</strong></em> 代表的是与 <em><strong>river</strong></em> 有关的一个单词，与他们比较近的单词还有   <em><strong>water</strong></em>、<em><strong>tree</strong></em>、<em><strong>fish</strong></em> 等等，而“<strong>bank2</strong>”代表的是与“<strong>money</strong>”有关的一个单词，与他们比较接近的单词还有  <em><strong>currency</strong></em>,  <em><strong>cash</strong></em> ,  <em><strong>withdraw</strong></em>  等等。这就是**“Attention 注意力机制”的工作原理，也就是 Attention 让一个单词在句子中找到与它产生强语义联系的其他单词，并组成一个新的变体单词**：<em><strong>bank1</strong></em>、<em><strong>bank2</strong></em>。</p>
<br>
<h3 id="24-self-attention-自注意力机制">2.4 Self-Attention 自注意力机制</h3>
<p>然后又有新的问题产生了，机器算法是如何知道一句话中只有 <em><strong>river</strong></em> 或 <em><strong>money</strong></em> 这两个词代表了上下文语义的强关联词汇，而不是 <em><strong>The</strong></em>、<em><strong>in</strong></em>、<em><strong>of</strong></em>或其他单词呢？实际上这依旧是 Embedding 空间中每一个单词的空间定位相近程度的问题。（实际上，在 Embedding 空间中，不仅仅名词有各自的位置，动词、介词、形容词等等都有自己的位置，甚至一个词组、一句话也会有自己的位置。）</p>
<p><img loading="lazy" src="img/8.png" alt=""  />
</p>
<p>全句中的每一个单词在 Embedding 空间中定位的相近度是这样来计算的。机器算法会对每一个单词与全句中其他单词逐一地配对，做语义关联程度的计算和比较，最终汇总到表格中，<strong>颜色越深代表语义关联程度越高</strong>。</p>
<p><img loading="lazy" src="img/9.png" alt=""  />
</p>
<p><center>一个句子中所有单词都做一遍“Attention 注意力机制”</center></p>
<p>我们可以从表格中看出来：</p>
<ul>
<li>每一个单词与自己的相似度为最高分 1（一般用数值“1”来代表最大权重，这里的相似度用权重来表达）；</li>
<li>互不相关的单词之间的语义关联度为 0（其实可能是 0.001 之类的很小的数字，这里做了简化，即值太小，以至于低于某一个阈值而归零处理）；</li>
<li><em><strong>bank</strong></em>  与   <em><strong>river</strong></em> 的相似度为 0.11；</li>
<li><em><strong>bank</strong></em> 与  <em><strong>money</strong></em> 的相似度为 0.25；</li>
</ul>
<p>每一个单词与自己的语义关联度为最高的 1（一般用数值“1”来代表最大权重，这里的相似度用权重来表达）；ention 自注意力机制”了。于是通过“自注意力机制”的语义关联比对后，我们便找出了 <em><strong>river</strong></em> 为 <strong>句子I</strong> 全句中与 <em><strong>bank</strong></em> 关联度最大的词， <em><strong>money</strong></em> 为“句子II”全句中与“bank”关联度最大的单词，然后 <strong>句子I</strong> 中的 <em><strong>bank</strong></em> 就被机器算法转换成了它的新变种 <em><strong>bank1</strong></em>（<em><strong>river-bank</strong></em>），而在 <strong>句子2</strong> 中的 <em><strong>bank</strong></em> 则被机器算法转换成了它的新变种 <em><strong>bank2</strong></em>（“money-bank”）。然后机器算法就可以继续往后进行翻译工作了。</p>
<br>
<h2 id="25-transformer-最终实现准确的翻译">2.5 Transformer 最终实现准确的翻译</h2>
<p>Embedding 是一个全场景全维度的空间，它其中含有全世界的所有语言的单词。​在这同一空间中，不仅仅有英文，也有中文、法文、德文&hellip;等等的 Embedding 词汇标注。​那么基于Embedding 空间表达的的翻译就变成了现实。</p>
<p><img loading="lazy" src="img/10.png" alt=""  />
</p>
<p><center>t-SNE visualization of the bilingual word embedding.（t-SNE 是一种高维数据可视化技术）</center></p>
<p>比如，中文的 <em><strong>河流</strong></em> 和英文的 <em><strong>river</strong></em> 在 Embedding 空间中的位置基本是一样的，而 <em><strong>钱</strong></em> 和 <em><strong>money</strong></em> 的位置基本一样，<em><strong>岸边</strong></em> 和 <em><strong>bank1</strong></em> 的位置一样，<em><strong>银行</strong></em> 和 <em><strong>bank2</strong></em> 的位置一样。于是，把这些不同语言的定位一一找出来，就实现了十分正确的翻译结果了。</p>
<ul>
<li><strong>句子I</strong>：The <em><strong>bank1</strong></em> of the river.</li>
<li><strong>句子I翻译</strong>：那个河流的岸边。</li>
<li><strong>句子II</strong>：Money in the <em><strong>bank2</strong></em>.</li>
<li><strong>句子II翻译</strong>：银行中的钱。</li>
</ul>
<p>至此，Transformer 和其中的核心部件 Self-Attention 对于语言翻译类信息处理的流程就被简要地讲清楚了。但像上面例子中 ***“The bank of the river.”***这样的句子太短太简单了，它甚至都无法称为一个完整的句子。在实际项目中，输入给 Transformer 的语句会更长更复杂，往往在一句话中有可能出现三个以上的单词有语义关联的关系，甚至更多。 比如这一句：“The animal did not cross the street because it was too tired. ”。很明显，在该句中和 <em><strong>it</strong></em> 有语义关系的词汇有两个，分别是 <em><strong>animal</strong></em> 和 <em><strong>street</strong></em>。</p>
<p>对于这样的情况，处理机制和“The bank of the river.”的处理机制仍然是一样的。Self-Attention 一样会对全句中的所有单词都进行在 Embedding 空间中的距离比较，即语义关联权重的比较。</p>
<p>在 <em><strong>“The animal did not cross the street because it was too tired.”</strong></em> 中 <em><strong>it</strong></em>与 <em><strong>animal</strong></em> 的语义关联权重比与 <em><strong>street</strong></em>的语义关联权重要高。因此，Self-Attention 自注意力机制处理后的结果将以 <em><strong>animal</strong></em> 为主导来生成新的单词 <em><strong>it1</strong></em> ，即 <em><strong>it1 =“animal-it”</strong></em>。此时就变成了 <em><strong>“The animal did not cross the street becauseit1 was too tired. ”</strong></em> 。翻译成法语为：“L‘animaln’a pas traverse la rue parceil était trop fatigue.” 。翻译成中文则为：“这只动物没有过马路，因为它太累了。”。</p>
<p><img loading="lazy" src="img/11.png" alt=""  />
</p>
<p><center>色块的深浅表明了与“it”语义关联权重的强弱。这里“it”与“animal”的语义关联权重最大</center></p>
<p>在另一句话中，<em><strong>“The animal did not cross the street because it was too wide.” <em><strong>，只是一字之差， <em><strong>tired</strong></em> 变成了 <em><strong>wide</strong></em>，导致了全句的语义发生了很大的变化，尤其是 <em><strong>it</strong></em> 所指的对象由 <em><strong>animal</strong></em> 变成了</strong></em>street</strong></em>。此时 Self-Attention 同样按照以前的方法进行语义关联度匹配，结果是<em><strong>animal</strong></em> 和 <em><strong>street</strong></em> 的权重在全句中都很高，但是 <em><strong>street</strong></em> 是最高的，所以最终的结果将以 <em><strong>street</strong></em> 主导来生成新的 <em><strong>it2</strong></em> ，即 <em><strong>it2=“street-it”</strong></em>。此时就变成了“The animal did not cross the street becauseit2was too wide.” 。翻译成法语为：“L‘animal n’a pas traverse la rue parceelle était trop large. ”。翻译成中文为：“这只动物没有过马路，因为路太宽了。”<strong>（注意：这里用的是“路”，而不是“它”，稍后会解释）</strong>。</p>
<p><img loading="lazy" src="img/12.png" alt=""  />
</p>
<p><center>这里“it”与“street”的语义关联权重最大</center></p>
<p>之所以 Self-Attention 可以把 Word Embedding 中的权重比较做得如此细腻，不仅是因为 Google 用了千亿级的语料来训练 Word Embedding。同时更是因为 Transformer 模型本身的架构核心 Self-Attention 也有与之匹配的超级强大的处理能力，它在超长语句上的处理能力远远超过了早先的 RNN （循环神经网络）和 CNN （卷积神经网络）（这两个著名的人工神经网络我会在之后的文章中一一介绍），它不仅仅能对一句中所有单词做 Self-Attention 自注意力机制的审核，它还可以对一整段话，甚至全篇文章做审核。这就是我们通常说的要结合上下文来理解语句并翻译。最新的 GPT-4 Turbo 一次可以处理大约 9.6 万个单词，比许多小说都长。此外，12.8万字（128K）的上下文长度可以导致更长的对话，而不会让人工智能在超长文的对话或翻译过程中迷失方向。</p>
<br>
<h3 id="26-word-embedding-的进一步扩展-sentence-embedding">2.6 Word Embedding 的进一步扩展 Sentence Embedding</h3>
<p>这一强大的能力，同样也来源于 Word Embedding 的能力。它不仅仅可以对单个词语进行定位，它甚至还可以做到对句子进行逻辑定位，如下图中所示。这种能力被称为“Sentence Embedding”。</p>
<p><img loading="lazy" src="img/13.png" alt=""  />
</p>
<p><center>Sentence Embedding 可以表达句子与句子之间的关系</center></p>
<p>Word Embedding 和 Sentence Embedding 是大语言模型（Large Language Models，LLMs）的重要基础组成部分。它们将人类语言转化为了计算机能够读懂的底层数字表达方式，并且通过多维度的空间定位捕捉了各个单词、短语、句子在语义上的细微差别，以及它们之间的逻辑联系。<strong>这种底层的数字表达已经跨越了不同的语系语言，成为了全人类共用的最底层语言逻辑，甚至成为了一种世界语——AI 世界语，这对于翻译、搜索和理解不同语言语种具有非常重要的作用。可以说，巴别塔的传说自此解决！！</strong></p>
<p>既有“大力出奇迹”的训练内容，更有承载“大力出奇迹”的结构，最终导致 Transformer 必然产生了这样的“奇迹”，使它能够在机器翻译领域达到了人类翻译的“信达雅”的成就。</p>
<p><img loading="lazy" src="img/14.png" alt=""  />
</p>
<p><center>BLEU 英译德评分</center></p>
<br>
<p><img loading="lazy" src="img/15.png" alt=""  />
</p>
<p><center>BLEU 英译法评分</center></p>
<p>上两幅图中，在 BLEU 的英德翻译与英法翻译领域 Transformer 得分最高。 （ 注：BLEU，bilingual evaluation understudy，即：双语互译质量评估辅助工具。它是用来评估机器翻译质量的工具。BLEU的设计思想：机器翻译结果越接近专业人工翻译的结果则越好。）</p>
<p>通过一个小例子就能看出它的优越性，正好说说为什么是“路”而不是“它”，之前这两句的翻译结果如下：</p>
<ul>
<li>The animal did not cross the street because <strong>it1</strong> was too tired.</li>
<li>L&rsquo;animal n&rsquo;a pas traverse la rue parce <strong>il</strong> était trop fatigue.</li>
<li>这只动物没有过马路，因为<strong>它</strong>太累了。</li>
<li>———————————————</li>
<li>The animal did not cross the street because <strong>it2</strong> was too wide.</li>
<li>L&rsquo;animal n&rsquo;a pas traverse la rue parce <strong>elle</strong> était trop large.</li>
<li>这只动物没有过马路，因为<strong>路</strong>太宽了。</li>
</ul>
<p>在法语中 il 和 elle 是明显不同的，因此他们可以在各自句子中指代出 <em><strong>it</strong></em> 的不同的翻译结果，不会引起语义模糊。这种在法语中明显的区别在翻译成中文时，就没有这么简单了。如果把两句话翻译成中文，<em><strong>it</strong></em> 都可以被粗糙地翻译成“它”，则第二句的语义将被普遍地认为不够精准，因为翻译成“它”会产生一定的语义模糊。取而代之，用“路”则更能达到“信达雅”的效果。大家可以用不同的翻译软件测试一下这两句话的英译中翻译，就知道哪些软件用了 Transformer 的底层技术，而哪些没用了！（你懂的 ）</p>
<p>好了，绕了这么远，解释了这么多，终于可以说说这个 <strong>Transformer</strong> 到底是什么意思了！</p>
<p><br><br></p>
<h2 id="三ai-领域-transformer-的确切含义">三、AI 领域 Transformer 的确切含义</h2>
<p>**单词“X”转化为“X1”，“X”代表在 Transformer 处理之前一句话中的单词，而“X1”则代表了经过 Transformer 的 Slef-Attention 处理之后，附加了句子中其他具有强语义关联关系的单词后的“变种单词”。**其实，句子还是原来那个句子，单词还是那个单词，本质并没有变，但表达形式却变了。就如同“bank”被转变成了“bank1”一样。“bank1”的灵魂还是那个“bank”，但是“bank1”展示出来了隐藏在“bank”身体中的另一面“river-bank”。</p>
<p>所以，用众所周知的  <em><strong>变形金刚 Transformer</strong></em> 来命名与解释就再贴切不过了~！ <em><strong>bank</strong></em> 变形成了 <em><strong>bank1</strong></em>， ***bank ***与 <em><strong>bank1</strong></em> 异体同身！<em><strong>大黄蜂</strong></em> 既是机器人，<em><strong>大黄蜂</strong></em> 也是跑车。由车变形到机器人，再由机器人变形到车，万变不离其宗，都是 <em><strong>大黄蜂</strong></em> ，本质上并没有改变，但是，外观变了，用途也就变了！</p>
<p>在车的状态下，容易让人混淆（你本以为它是一辆车，但其实他是一个机器人，不变成人形，你还真认不出来）。就如同多义词一样，过往的翻译机制很难辨认出它在一句话中的确切含义，他们虽然也有上下文语义的兼顾理解能力，但是处理信息量还是太少，导致他们无法做到十分精准，经常造成单词虽然翻译对了，但放在句子里却容易产生含混不清甚至错误。但是通过 Transformer 的变形操作，“大黄蜂”的车状态就变形成了同样叫 <em><strong>大黄蜂</strong></em> 的机器人状态，再放回到句子中，则让它现了原型，于是一切水落石出！</p>
<p><img loading="lazy" src="img/16.png" alt=""  />
</p>
<p><center>“大黄蜂”既是机器人，“大黄蜂”也是跑车，本质上都是同一个家伙，只是在不同的场合有不同的用途。</center></p>
<p>Google 的技术团队就是用了“变形金刚 Transformer”这个梗。如此的诙谐幽默、简单直白，半开玩笑地就起了个技术名词。但也不得不承认“变形金刚 Transformer”这个词用在这里，用于这个技术名词的命名，也确实再贴切不过了，真正的名副其实！</p>
<p>所以，当下次有人问你“GPT”到底是什么、翻译成中文又是什么意思时，你就可以明确地对他说：<em><strong>“生成式预训练转换器”</strong></em> 或者 <em><strong>“生成式预训练变形金刚”</strong></em>（前者翻译得其实也很含糊，所以我建议后者，虽然对方可能会嘲笑你几分钟，但也仅限这几分钟）。懂的人自然懂，不懂的也不用去解释！</p>
<p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li>[付费视频课 | Python实证指标构建与文本分析](<a href="https://textdata.cn/blog/">https://textdata.cn/blog/</a> <em><strong>man</strong></em> agement_python_course/)</li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>代码 | 使用LDA预测文本的话题类型</title>
      <link>https://textdata.cn/blog/2023-11-14-using-lda-to-predict-topic/</link>
      <pubDate>Tue, 14 Nov 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-11-14-using-lda-to-predict-topic/</guid>
      <description>&lt;h2 id=&#34;获取代码&#34;&gt;获取代码&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;lda-code.zip&#34;&gt;&lt;strong&gt;点击下载本文数据&amp;amp;代码&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/lda-model.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;如何用LDA预测文本的话题类型，本文将覆盖以下代码技术&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;csv数据读取&lt;/li&gt;
&lt;li&gt;文本预处理&lt;/li&gt;
&lt;li&gt;训练(保存)lda模型&lt;/li&gt;
&lt;li&gt;预测话题&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;一读取数据&#34;&gt;一、读取数据&lt;/h2&gt;
&lt;p&gt;本文使用的数据集来自于 之前分享的 &lt;a href=&#34;https://textdata.cn/blog/2023-04-25-zhihu-parent-child-relationship/&#34;&gt;网络爬虫 | 知乎热门话题「全职儿女」&lt;/a&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pandas&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pd&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read_csv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;data/知乎-全职儿女.csv&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;encoding&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;utf-8&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dropna&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;subset&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;content&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;inplace&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;记录数: &amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;head&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;记录数:  411
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/01-df.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;二清洗数据&#34;&gt;二、清洗数据&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;re&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;jieba&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;stoptext&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;open&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;data/stopwords.txt&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;encoding&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;utf-8&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;        
&lt;span class=&#34;n&#34;&gt;stopwords&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;stoptext&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;split&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\n&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;  


&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;clean_text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
    &lt;span class=&#34;c1&#34;&gt;# 用正则表达式提取中文文本&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;text&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;join&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;re&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;findall&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;[&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\u4e00&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\u9fa5&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;]+&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;   
    &lt;span class=&#34;n&#34;&gt;words&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;jieba&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;lcut&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;                               
    &lt;span class=&#34;n&#34;&gt;words&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;w&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;w&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;words&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;w&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;stopwords&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;   
    &lt;span class=&#34;c1&#34;&gt;#整理成用空格间隔词语的文本形式(类似西方语言)&lt;/span&gt;
    &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39; &amp;#39;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;join&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;words&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;


&lt;span class=&#34;n&#34;&gt;test_text&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;首先，我认为「全职儿女」不应该被简单地归为啃老。在目前社会环境下，随着经济、教育等发展，年轻...&amp;#34;&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;clean_text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;test_text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;    &amp;#39;全职 儿女 简单 地归为 啃 老 社会 环境 经济 教育 发展 年轻&amp;#39;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;clean_content&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;content&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;apply&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;clean_text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;head&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/02-df.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;三训练lda模型&#34;&gt;三、训练LDA模型&lt;/h2&gt;
&lt;h3 id=&#34;31-训练&#34;&gt;3.1 训练&lt;/h3&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/03-wordcloud.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;根据词云图， 假设对数据比较了解，可以直接设置话题数 n_components = 4&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;sklearn.feature_extraction.text&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;CountVectorizer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;TfidfVectorizer&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;sklearn.decomposition&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;LatentDirichletAllocation&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;# 构建词典，将词转为数字。将文档转为向量&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;vectorizer&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;TfidfVectorizer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;max_df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;0.5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;min_df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;20&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;   
&lt;span class=&#34;n&#34;&gt;doc_term_matrix&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;vectorizer&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fit_transform&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;clean_content&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;# 构建LDA话题模型&lt;/span&gt;
&lt;span class=&#34;c1&#34;&gt;# 初始化模型，设置话题数为4,随机状态码888&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;lda_model&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;LatentDirichletAllocation&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;n_components&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;random_state&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;888&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;       
&lt;span class=&#34;n&#34;&gt;lda_output&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;lda_model&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fit_transform&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;doc_term_matrix&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;lda_model&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h3 id=&#34;32-保存模型&#34;&gt;3.2 保存模型&lt;/h3&gt;
&lt;p&gt;如果训练过程非常久，保存模型，下次就可以跳过训练阶段，直接使用模型。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;joblib&lt;/span&gt;
&lt;span class=&#34;c1&#34;&gt;# # 保存模型&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;joblib&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dump&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;lda_model&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;output/全职儿女lda_model.pkl&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;[&#39;output/全职儿女lda_model.pkl&#39;]
&lt;/code&gt;&lt;/pre&gt;
&lt;br&gt;
&lt;h3 id=&#34;33-导入模型&#34;&gt;3.3 导入模型&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;joblib&lt;/span&gt;

&lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&amp;#34;导入保存的模型&amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;lda_model&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;joblib&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;load&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;output/全职儿女lda_model.pkl&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;lda_model&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/lda888.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;四使用lda模型&#34;&gt;四、使用LDA模型&lt;/h2&gt;
&lt;h3 id=&#34;41-查看话题特征词&#34;&gt;4.1 查看话题特征词&lt;/h3&gt;
&lt;p&gt;获得每个话题对应的的n个特征词，方便后续对每个话题命名和解读&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;numpy&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;np&lt;/span&gt;


&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;show_topics&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;vectorizer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;lda_model&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;top_n&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;30&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
    &lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&amp;#34;
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;    显示每个话题最重要的n个词语
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;    vectorizer: 词袋法或tfidf.基于前面代码这里使用TF-IDF法
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;    lda_model: 训练好的lda话题模型
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;    top_n: 设置最重要的n个特征词，默认30个.
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;    &amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;
    
    &lt;span class=&#34;n&#34;&gt;keywords&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;np&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;array&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;vectorizer&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;get_feature_names_out&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;())&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;topic_keywords&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt;
    &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;topic_weights&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;lda_model&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;components_&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
        &lt;span class=&#34;n&#34;&gt;top_keyword_locs&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;topic_weights&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;argsort&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()[:&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;top_n&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
        &lt;span class=&#34;n&#34;&gt;topic_keywords&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;append&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;keywords&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;take&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;top_keyword_locs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
    &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;topic_keywords&lt;/span&gt;


&lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&amp;#34;利用show_topics函数展示全职儿女文本中的4个话题，基于每个话题最重要的20个词语为每个话题命名&amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;topic_keywords&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;show_topics&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;vectorizer&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;vectorizer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;   &lt;span class=&#34;c1&#34;&gt;# 【可改动】vectorizer我们训练的词语空间&lt;/span&gt;
                             &lt;span class=&#34;n&#34;&gt;lda_model&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;lda_model&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;     &lt;span class=&#34;c1&#34;&gt;# 【可改动】lda_model训练的lda模型&lt;/span&gt;
                             &lt;span class=&#34;n&#34;&gt;top_n&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;20&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;                &lt;span class=&#34;c1&#34;&gt;# 【可改动】最重要的30个词语&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;df_topic_keywords&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;DataFrame&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;topic_keywords&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;df_topic_keywords&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;columns&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;Word-&amp;#39;&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;str&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;range&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df_topic_keywords&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;shape&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])]&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;df_topic_keywords&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;index&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;Topic-&amp;#39;&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;str&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;range&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df_topic_keywords&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;shape&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])]&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;df_topic_keywords&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/04-df.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;42-预测文本的话题id&#34;&gt;4.2 预测文本的话题id&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;numpy&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;np&lt;/span&gt;

&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;predict_topic&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;doc_term_matrix&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;vectorizer&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;transform&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;([&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;clean_text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)])&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;topic_term_prob_matrix&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;lda_model&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;transform&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;doc_term_matrix&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;topic_index&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;np&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;argmax&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;topic_term_prob_matrix&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;

    &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;topic_index&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;test_text2&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;最近，“全职儿女”话题受到舆论关注。“全职儿女”是指一种新型的脱产生活方式，年轻人脱产寄居父母生活，并通过付出一定的劳动换取经济支持，同时保持学习提升或发展副业的状态。这种生活方式既有其合理性和正当性，也有其问题和风险。我们不能一概而论，也不能一味否定或肯定。&amp;#34;&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;topic_index&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;predict_topic&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;test_text2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;该文本所属Topic: &amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;topic_index&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;    该文本所属Topic:  0
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;c1&#34;&gt;#批量预测&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;话题ID&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;clean_content&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;apply&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;predict_topic&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;head&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/05-predict.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;话题ID&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;value_counts&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;话题ID
0    214
1     88
3     84
2     25
Name: count, dtype: int64
&lt;/code&gt;&lt;/pre&gt;
&lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;c1&#34;&gt;#预测结果保存到csv、xlsx中。&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;to_csv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;output/话题预测结果.csv&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;index&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;False&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;to_excel&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;output/话题预测结果.xlsx&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;index&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;False&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/output.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;获取代码-1&#34;&gt;获取代码&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;lda-code.zip&#34;&gt;&lt;strong&gt;点击下载本文&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;广而告之&#34;&gt;广而告之&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/call_for_paper/&#34;&gt;长期征稿&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/we_need_you/&#34;&gt;长期招募小伙伴&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/management_python_course/&#34;&gt;付费视频课 | Python实证指标构建与文本分析&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
      <content:encoded><![CDATA[<h2 id="获取代码">获取代码</h2>
<p><a href="lda-code.zip"><strong>点击下载本文数据&amp;代码</strong></a></p>
<p><br><br></p>
<p><img loading="lazy" src="img/lda-model.png" alt=""  />
</p>
<p>如何用LDA预测文本的话题类型，本文将覆盖以下代码技术</p>
<ol>
<li>csv数据读取</li>
<li>文本预处理</li>
<li>训练(保存)lda模型</li>
<li>预测话题</li>
</ol>
<p><br><br></p>
<h2 id="一读取数据">一、读取数据</h2>
<p>本文使用的数据集来自于 之前分享的 <a href="https://textdata.cn/blog/2023-04-25-zhihu-parent-child-relationship/">网络爬虫 | 知乎热门话题「全职儿女」</a></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;data/知乎-全职儿女.csv&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">dropna</span><span class="p">(</span><span class="n">subset</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;content&#39;</span><span class="p">],</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;记录数: &#39;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">))</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</code></pre></div><pre><code>记录数:  411
</code></pre>
<p><img loading="lazy" src="img/01-df.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="二清洗数据">二、清洗数据</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">re</span>
<span class="kn">import</span> <span class="nn">jieba</span>

<span class="n">stoptext</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;data/stopwords.txt&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>        
<span class="n">stopwords</span> <span class="o">=</span> <span class="n">stoptext</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>  


<span class="k">def</span> <span class="nf">clean_text</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="c1"># 用正则表达式提取中文文本</span>
    <span class="n">text</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">re</span><span class="o">.</span><span class="n">findall</span><span class="p">(</span><span class="s1">&#39;[</span><span class="se">\u4e00</span><span class="s1">-</span><span class="se">\u9fa5</span><span class="s1">]+&#39;</span><span class="p">,</span> <span class="n">text</span><span class="p">))</span>   
    <span class="n">words</span> <span class="o">=</span> <span class="n">jieba</span><span class="o">.</span><span class="n">lcut</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>                               
    <span class="n">words</span> <span class="o">=</span> <span class="p">[</span><span class="n">w</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">words</span> <span class="k">if</span> <span class="n">w</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">stopwords</span><span class="p">]</span>   
    <span class="c1">#整理成用空格间隔词语的文本形式(类似西方语言)</span>
    <span class="k">return</span> <span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">words</span><span class="p">)</span>


<span class="n">test_text</span> <span class="o">=</span> <span class="s2">&#34;首先，我认为「全职儿女」不应该被简单地归为啃老。在目前社会环境下，随着经济、教育等发展，年轻...&#34;</span>
<span class="n">clean_text</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="n">test_text</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">    &#39;全职 儿女 简单 地归为 啃 老 社会 环境 经济 教育 发展 年轻&#39;
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df</span><span class="p">[</span><span class="s1">&#39;clean_content&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;content&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">clean_text</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div><p><img loading="lazy" src="img/02-df.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="三训练lda模型">三、训练LDA模型</h2>
<h3 id="31-训练">3.1 训练</h3>
<p><img loading="lazy" src="img/03-wordcloud.png" alt=""  />
</p>
<p>根据词云图， 假设对数据比较了解，可以直接设置话题数 n_components = 4</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">CountVectorizer</span><span class="p">,</span><span class="n">TfidfVectorizer</span>
<span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">LatentDirichletAllocation</span>

<span class="c1"># 构建词典，将词转为数字。将文档转为向量</span>
<span class="n">vectorizer</span> <span class="o">=</span> <span class="n">TfidfVectorizer</span><span class="p">(</span><span class="n">max_df</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">min_df</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>   
<span class="n">doc_term_matrix</span> <span class="o">=</span> <span class="n">vectorizer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;clean_content&#39;</span><span class="p">])</span>

<span class="c1"># 构建LDA话题模型</span>
<span class="c1"># 初始化模型，设置话题数为4,随机状态码888</span>
<span class="n">lda_model</span> <span class="o">=</span> <span class="n">LatentDirichletAllocation</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">888</span><span class="p">)</span>       
<span class="n">lda_output</span> <span class="o">=</span> <span class="n">lda_model</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">doc_term_matrix</span><span class="p">)</span>
<span class="n">lda_model</span>
</code></pre></div><br>
<h3 id="32-保存模型">3.2 保存模型</h3>
<p>如果训练过程非常久，保存模型，下次就可以跳过训练阶段，直接使用模型。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">joblib</span>
<span class="c1"># # 保存模型</span>
<span class="n">joblib</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">lda_model</span><span class="p">,</span> <span class="s1">&#39;output/全职儿女lda_model.pkl&#39;</span><span class="p">)</span>
</code></pre></div><pre><code>['output/全职儿女lda_model.pkl']
</code></pre>
<br>
<h3 id="33-导入模型">3.3 导入模型</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">joblib</span>

<span class="s2">&#34;&#34;&#34;导入保存的模型&#34;&#34;&#34;</span>
<span class="n">lda_model</span> <span class="o">=</span> <span class="n">joblib</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;output/全职儿女lda_model.pkl&#39;</span><span class="p">)</span>
<span class="n">lda_model</span>
</code></pre></div><p><img loading="lazy" src="img/lda888.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="四使用lda模型">四、使用LDA模型</h2>
<h3 id="41-查看话题特征词">4.1 查看话题特征词</h3>
<p>获得每个话题对应的的n个特征词，方便后续对每个话题命名和解读</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>


<span class="k">def</span> <span class="nf">show_topics</span><span class="p">(</span><span class="n">vectorizer</span><span class="p">,</span> <span class="n">lda_model</span><span class="p">,</span> <span class="n">top_n</span><span class="o">=</span><span class="mi">30</span><span class="p">):</span>
    <span class="s2">&#34;&#34;&#34;
</span><span class="s2">    显示每个话题最重要的n个词语
</span><span class="s2">    vectorizer: 词袋法或tfidf.基于前面代码这里使用TF-IDF法
</span><span class="s2">    lda_model: 训练好的lda话题模型
</span><span class="s2">    top_n: 设置最重要的n个特征词，默认30个.
</span><span class="s2">    &#34;&#34;&#34;</span>
    
    <span class="n">keywords</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">get_feature_names_out</span><span class="p">())</span>
    <span class="n">topic_keywords</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">topic_weights</span> <span class="ow">in</span> <span class="n">lda_model</span><span class="o">.</span><span class="n">components_</span><span class="p">:</span>
        <span class="n">top_keyword_locs</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="n">topic_weights</span><span class="p">)</span><span class="o">.</span><span class="n">argsort</span><span class="p">()[:</span><span class="n">top_n</span><span class="p">]</span>
        <span class="n">topic_keywords</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">keywords</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="n">top_keyword_locs</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">topic_keywords</span>


<span class="s2">&#34;&#34;&#34;利用show_topics函数展示全职儿女文本中的4个话题，基于每个话题最重要的20个词语为每个话题命名&#34;&#34;&#34;</span>
<span class="n">topic_keywords</span> <span class="o">=</span> <span class="n">show_topics</span><span class="p">(</span><span class="n">vectorizer</span><span class="o">=</span><span class="n">vectorizer</span><span class="p">,</span>   <span class="c1"># 【可改动】vectorizer我们训练的词语空间</span>
                             <span class="n">lda_model</span><span class="o">=</span><span class="n">lda_model</span><span class="p">,</span>     <span class="c1"># 【可改动】lda_model训练的lda模型</span>
                             <span class="n">top_n</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>                <span class="c1"># 【可改动】最重要的30个词语</span>

<span class="n">df_topic_keywords</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">topic_keywords</span><span class="p">)</span>
<span class="n">df_topic_keywords</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Word-&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">df_topic_keywords</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])]</span>
<span class="n">df_topic_keywords</span><span class="o">.</span><span class="n">index</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Topic-&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">df_topic_keywords</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])]</span>
<span class="n">df_topic_keywords</span>
</code></pre></div><p><img loading="lazy" src="img/04-df.png" alt=""  />
</p>
<br>
<h3 id="42-预测文本的话题id">4.2 预测文本的话题id</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="k">def</span> <span class="nf">predict_topic</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="n">doc_term_matrix</span> <span class="o">=</span> <span class="n">vectorizer</span><span class="o">.</span><span class="n">transform</span><span class="p">([</span><span class="n">clean_text</span><span class="p">(</span><span class="n">text</span><span class="p">)])</span>
    <span class="n">topic_term_prob_matrix</span> <span class="o">=</span> <span class="n">lda_model</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">doc_term_matrix</span><span class="p">)</span>
    <span class="n">topic_index</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">topic_term_prob_matrix</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">topic_index</span>

<span class="n">test_text2</span> <span class="o">=</span> <span class="s2">&#34;最近，“全职儿女”话题受到舆论关注。“全职儿女”是指一种新型的脱产生活方式，年轻人脱产寄居父母生活，并通过付出一定的劳动换取经济支持，同时保持学习提升或发展副业的状态。这种生活方式既有其合理性和正当性，也有其问题和风险。我们不能一概而论，也不能一味否定或肯定。&#34;</span>

<span class="n">topic_index</span> <span class="o">=</span> <span class="n">predict_topic</span><span class="p">(</span><span class="n">test_text2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&#34;该文本所属Topic: &#34;</span><span class="p">,</span> <span class="n">topic_index</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">    该文本所属Topic:  0
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#批量预测</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;话题ID&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;clean_content&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">predict_topic</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div><p><img loading="lazy" src="img/05-predict.png" alt=""  />
</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df</span><span class="p">[</span><span class="s1">&#39;话题ID&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<pre><code>话题ID
0    214
1     88
3     84
2     25
Name: count, dtype: int64
</code></pre>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#预测结果保存到csv、xlsx中。</span>
<span class="n">df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;output/话题预测结果.csv&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">to_excel</span><span class="p">(</span><span class="s1">&#39;output/话题预测结果.xlsx&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</code></pre></div><p><img loading="lazy" src="img/output.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="获取代码-1">获取代码</h2>
<p><a href="lda-code.zip"><strong>点击下载本文</strong></a></p>
<p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>不可不防的大模型“人肉搜索”能力</title>
      <link>https://textdata.cn/blog/2023-11-13-violatating-privacy-via-inference-with-large-language-model/</link>
      <pubDate>Mon, 13 Nov 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-11-13-violatating-privacy-via-inference-with-large-language-model/</guid>
      <description>今年10月的一项研究显示，语言大模型的推测能力，使其在“某些方面”的准确度几乎接近人类甚至超越人类。这引发了作者对大模型可能被用来“人肉搜索”的担忧。“开盒”从未如此简单？大模型是否会侵害我们的隐私？ 大语言模型(Large language Model,  LLM)可以从文本中准确推断个人属性。</description>
      <content:encoded><![CDATA[<iframe
    src="//player.bilibili.com/player.html?bvid=BV1T84y1X7Jv&page=1"
    scrolling="no"
    height="500px"
    width="800px"
    frameborder="no"
    framespacing="0"
    allowfullscreen="true"
>
</iframe>

<p>今年10月的一项研究显示，语言大模型的推测能力，使其在“某些方面”的准确度几乎接近人类甚至超越人类。这引发了作者对大模型可能被用来“人肉搜索”的担忧。“开盒”从未如此简单？大模型是否会侵害我们的隐私？ 大语言模型(Large language Model,  LLM)可以从文本中准确推断个人属性。</p>
<p><br><br></p>
<h2 id="声明">声明</h2>
<p>本文内容全文整理自 <a href="https://llm-privacy.org/">https://llm-privacy.org/</a></p>
<p>Staab, Robin, Mark Vero, Mislav Balunović, and Martin Vechev. &ldquo;Beyond Memorization: Violating Privacy Via Inference with Large Language Models.&rdquo; <em>arXiv preprint arXiv:2310.07298</em> (2023).</p>
<p><br><br></p>
<h2 id="演示案例">演示案例</h2>
<div align="center">   <p><strong>对照当前最先进的大语言模型（LLM）， 测试您的隐私推理技能！</strong></p> </div>
<p><img loading="lazy" src="img/01-guess.png" alt=""  />
</p>
<p><img loading="lazy" src="img/01-guess-answer.png" alt=""  />
</p>
<br>
<p><img loading="lazy" src="img/02-guess.png" alt=""  />
</p>
<p><img loading="lazy" src="img/02-guess-answer.png" alt=""  />
</p>
<br>
<p><img loading="lazy" src="img/03-guess.png" alt=""  />
</p>
<p><img loading="lazy" src="img/03-guess-answer.png" alt=""  />
</p>
<br>
<br>
<h2 id="qa">Q&amp;A</h2>
<h3 id="q1-有什么问题吗">Q1： 有什么问题吗？</h3>
<p><strong>LLM可以从文本中准确推断个人属性信息</strong>； 当前关于大语言模型（LLM）的隐私研究主要集中在提取记忆的训练数据的问题上。与此同时，模型的推理能力也大幅提升。这就提出了一个问题：<strong>当前的LLM是否能从给定文本推断作者个人属性信息</strong>。我们的<a href="https://llm-privacy.org/#paper">研究</a>表明，随着能力的增强，LLM能够从提供给他们的非结构化文本（例如公共论坛或社交网络帖子）中自动推断出广泛的<strong>个人作者属性</strong>（例如<strong>年龄、性别和出生地</strong>）。推理时间。特别是，我们发现当前的前沿模型（例如 GPT-4 ）在从文本推断此类属性时平均达到<strong>85%</strong> top-1 和<strong>95.8% top-3 的准确度</strong>。与此同时，LLM的快速发展大大降低了此类侵犯隐私推论的相关成本（&gt; 100 倍的金钱和 &gt; 240 倍的时间），使对手能够将侵犯隐私的推论规模远远超出以前通过昂贵的人力所能实现的范围。分析器。</p>
<blockquote>
<p>LLM的回答会有n个排序， 概率从高到低，一般我们收到(看到的)回答是top1， 其他回答是隐藏起来的。第一个回答猜对的概率达到85%，而前三个回答猜对的概率是95.8%。</p>
</blockquote>
<br>
<h3 id="q2-为什么这很重要">Q2： 为什么这很重要？</h3>
<p><strong>它可以直接影响用户隐私</strong>； 人们在互联网留下了大量文本——常常无意中泄露了他们不想透露的个人数据。欧盟的 GDPR 或加州 CCPA 等数据保护法规的制定是为了保护原始个人数据。仅当个人数据以明显的形式存在时，例如具有显式属性字段的私人配置文件，才能遵守此类法规。相比之下，<strong>我们的工作引入了一种威胁模型，其中私人信息是从其存在不明显的上下文中推断出来的</strong>。我们展示了恶意行为者如何通过将用户的在线帖子输入预先训练的LLM来推断出从未打算泄露的用户私人信息。众所周知，一半的美国人口可以通过位置、性别和出生日期等少量属性来唯一识别[<a href="https://dl.acm.org/doi/10.1142/S0218488502001648">Sweeney, &lsquo;02]</a>。LLM可以从互联网上发现的非结构化摘录中推断出其中一些属性，可以使用其他公开信息（例如美国的选民记录）来识别实际的人。这将允许这些行为者将从帖子中推断出的高度个人化的信息（例如，心理健康状况）与真实的人联系起来，并将其用于不良或非法活动，例如有针对性的政治运动、自动分析或跟踪。LLM的广泛可用性和快速发展带来了范式的变化，以前的 NLP 技术缺乏实现此类任务所需的自然语言理解水平。此外，我们还表明，进行侵犯隐私的推理的能力随着模型的大小而变化，预计在不久的将来会对用户隐私产生更大的影响。</p>
<p><img loading="lazy" src="img/04-accuracy.png" alt=""  />
</p>
<br>
<h3 id="q3-这在实践中是如何运作的">Q3: 这在实践中是如何运作的？</h3>
<p><strong>它具有可扩展性并且易于执行</strong>。 我们根据来自 500 多个个人资料的真实 Reddit 评论评估了当前几个 LLM 的隐私推理能力，包括整个 Llama-2 系列、Anthropic 的 Claude 2、Google 的 PaLM 2 和 GPT-4 。我们的实验表明（除了这些LLM取得了令人印象深刻的准确性这一事实之外），这种<strong>侵犯隐私的推论非常容易大规模执行</strong>。特别是，我们发现这是两个因素的结合：</p>
<ul>
<li>首先，我们观察到目前模型中**几乎没有有效的保护措施，这会使侵犯隐私的推论变得更加容易。**值得注意的是，这使我们能够使用简单的提示（仅使用 COT 等基本技术），从而节省了提示工程所需的大量时间和精力。只有在极少数情况下，我们发现模型（跨大型提供商，即 OpenAI、Google、Meta、Anthropic）会阻止请求，在这种情况下，人们将不得不诉诸更复杂的提示技术。</li>
<li>同时，这些模型广泛且易于使用，使对手能够以最小的前期成本大幅扩展。即使有 API 限制，我们的实验实现了 <strong>时间减少100 倍 、 成本减少240 倍</strong>。从那时起，我们联系了所有模型提供商，作为我们负责任的披露政策的一部分，积极讨论如何在未来防止此类推论。我们在这一领域看到了两种有前途的方法：（i）致力于在预先训练的LLM中针对侵犯隐私的推理请求提供具体的保障措施；（ii）为最终用户提供可以保护其生成的文本免受推理的工具。</li>
</ul>
<p><img loading="lazy" src="img/05-cost.png" alt=""  />
</p>
<br>
<h3 id="q4-我们使用匿名工具可以躲过llm的隐私推断吗">Q4: 我们使用匿名工具可以躲过LLM的隐私推断吗？</h3>
<p><strong>LLM的表现优于当前的匿名工具</strong>。 为了测试LLM在最先进的匿名化工具上的表现，我们对所有收集的数据进行了匿名化，重新运行我们的推论。事实证明，即使在应用了高度匿名化之后，文本中仍然保留了足够的相关上下文，供LLM重建部分个人信息。此外，这些工具完全无法解决更多被删除的线索，例如特定的语言特征，同时仍然为侵犯隐私的LLM推论提供了大量信息。<strong>这尤其令人担忧，因为在这些情况下，用户采取了明确的预防隐私泄露的措施，从而造成一种高隐私感的错觉</strong>。同时，使用当前的匿名工具，在匿名化和实用性之间存在显着的权衡。简单地用 <code>*</code>替换部分文本会严重影响数据本身的有用性。</p>
<p><img loading="lazy" src="img/06-privacy-tools.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>关于「滥用原创」， 大邓的一些说明</title>
      <link>https://textdata.cn/blog/2023-11-07-disclosure-about-illegal-copyright-content/</link>
      <pubDate>Tue, 07 Nov 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-11-07-disclosure-about-illegal-copyright-content/</guid>
      <description>&lt;p&gt;2023-11-06 16:27 ~ 2023-11-7 12:37， 公众号遭遇几个举报， 举报『&lt;strong&gt;公众号： 大邓和他的Python&lt;/strong&gt;』存在『&lt;strong&gt;滥用原创&lt;/strong&gt;』标记违规行为。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/1.pic.jpg&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;因微信公众号审核人员，一般不会花时间阅读几千上万字的学术性内容， 只要一遇到举报， 就会倾向于用户的举报。 这也是大邓自食恶果， 经过我的检查，被举报的这几个文章。 有以下2种类型&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;真原创 误判为 滥用原创&lt;/li&gt;
&lt;li&gt;假原创 判定为 滥用原创&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;一真原创-误判为-滥用原创&#34;&gt;一、真原创 误判为 滥用原创&lt;/h2&gt;
&lt;p&gt;我将真原创定义为，大邓自己生成的内容篇幅超过50%， 一般含大邓自己构造的实验数据、代码、截图、讲解等内容。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/2023-01-13-information-content-of-critical-audit/&#34;&gt;金融研究 | 使用Python构建「关键审计事项信息含量」&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/2023-09-08-earnings-communication-conference-forward-looking-statements-information/&#34;&gt;中国管理科学 | 使用业绩说明会文本数据测量上市公司前瞻性信息&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;二假原创-判定为-滥用原创&#34;&gt;二、假原创 判定为 滥用原创&lt;/h2&gt;
&lt;p&gt;假原创中， 有以下几种类型&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;无原创内容， 活该被举报类型&lt;/li&gt;
&lt;li&gt;有大邓工作量， 被举报标记为滥用原创&lt;/li&gt;
&lt;li&gt;翻译整理， 被标记为滥用原创
&lt;br&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;21-无原创内容-活该被举报类型&#34;&gt;2.1 无原创内容， 活该被举报类型&lt;/h3&gt;
&lt;p&gt;推文虽然标记作者姓名、论文出处，但100%搬运，大邓做工只有搬运这一行为， 工作仅仅是搜集内容和整理公众号格式，大概几十分钟出一篇。我这种行为， 推文活该被举报， 合情合理。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/2023-03-10-psychological-research-with-word-embeddings/&#34;&gt;转载 | 基于词嵌入技术的心理学研究: 方法及应用&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/2023-10-11-how-can-machine-learning-empower-management-research/&#34;&gt;管理世界 | 机器学习如何赋能管理学研究？——国内外前沿综述和未来展望&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/2023-10-10-measure-the-speed-of-policy-diffusion-from-top-to-down/&#34;&gt;管理科学学报 | 使用LDA算法计算政策扩散速度与扩散程度&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/2023-10-07-esg-measurement/&#34;&gt;企业ESG行为的文本度量法&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
&lt;h3 id=&#34;22-有大邓工作量-被举报标记为滥用原创&#34;&gt;2.2 有大邓工作量， 被举报标记为滥用原创&lt;/h3&gt;
&lt;p&gt;推文中包括摘要 、概念定义、文献梳理，基本摘自(翻译自)论文原文， 涉及到创新点和文本分析技术实现内容， 大部分是有大邓的理解加工和上手敲代码实验， 一般有实验数据、代码、截图、解说。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/2023-10-16-measurement-of-consumer-certainty-in-language/&#34;&gt;JMR | 测量消费者的语言确定性&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
&lt;h3 id=&#34;23-翻译整理-被标记为滥用原创&#34;&gt;2.3 翻译整理， 被标记为滥用原创&lt;/h3&gt;
&lt;p&gt;全文翻译， 翻译后总字数有约3w字， 虽然是使用谷歌翻译1min， 但为了增加可读性， 很多地方要调整语序， 对部分晦涩难懂的文本分析技术概念， 也会加入自己的理解。 全文整理下来5+小时。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://textdata.cn/blog/2023-11-03-organization-science-with-word-embeddings/&#34;&gt;OS2022 | 概念空间 | 词嵌入模型如何为组织科学中的测量和理论提供信息&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;最后&#34;&gt;最后&lt;/h2&gt;
&lt;p&gt;之前的活该被举报类型的推文，那是自己之前做的不妥不对， 我是知识产权利益相关方， 不能一方面用规则吃饭生活，另一方面却又在做破坏规则的事情。&lt;/p&gt;
&lt;p&gt;人在做，天在看，不是不报，时候未到！ 自己如果成为恶人，自有恶人来惩治自己。这次被批量举报， 心里感到郁闷， 但也提醒自己以后标记原创时要更加小心。&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;广而告之&#34;&gt;广而告之&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/call_for_paper/&#34;&gt;长期征稿&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/we_need_you/&#34;&gt;长期招募小伙伴&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/management_python_course/&#34;&gt;付费视频课 | Python实证指标构建与文本分析&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
      <content:encoded><![CDATA[<p>2023-11-06 16:27 ~ 2023-11-7 12:37， 公众号遭遇几个举报， 举报『<strong>公众号： 大邓和他的Python</strong>』存在『<strong>滥用原创</strong>』标记违规行为。</p>
<p><img loading="lazy" src="img/1.pic.jpg" alt=""  />
</p>
<p>因微信公众号审核人员，一般不会花时间阅读几千上万字的学术性内容， 只要一遇到举报， 就会倾向于用户的举报。 这也是大邓自食恶果， 经过我的检查，被举报的这几个文章。 有以下2种类型</p>
<ul>
<li>真原创 误判为 滥用原创</li>
<li>假原创 判定为 滥用原创</li>
</ul>
<p><br><br></p>
<h2 id="一真原创-误判为-滥用原创">一、真原创 误判为 滥用原创</h2>
<p>我将真原创定义为，大邓自己生成的内容篇幅超过50%， 一般含大邓自己构造的实验数据、代码、截图、讲解等内容。</p>
<ul>
<li><a href="https://textdata.cn/blog/2023-01-13-information-content-of-critical-audit/">金融研究 | 使用Python构建「关键审计事项信息含量」</a></li>
<li><a href="https://textdata.cn/blog/2023-09-08-earnings-communication-conference-forward-looking-statements-information/">中国管理科学 | 使用业绩说明会文本数据测量上市公司前瞻性信息</a></li>
</ul>
<p><br><br></p>
<h2 id="二假原创-判定为-滥用原创">二、假原创 判定为 滥用原创</h2>
<p>假原创中， 有以下几种类型</p>
<ul>
<li>无原创内容， 活该被举报类型</li>
<li>有大邓工作量， 被举报标记为滥用原创</li>
<li>翻译整理， 被标记为滥用原创
<br></li>
</ul>
<h3 id="21-无原创内容-活该被举报类型">2.1 无原创内容， 活该被举报类型</h3>
<p>推文虽然标记作者姓名、论文出处，但100%搬运，大邓做工只有搬运这一行为， 工作仅仅是搜集内容和整理公众号格式，大概几十分钟出一篇。我这种行为， 推文活该被举报， 合情合理。</p>
<ul>
<li><a href="https://textdata.cn/blog/2023-03-10-psychological-research-with-word-embeddings/">转载 | 基于词嵌入技术的心理学研究: 方法及应用</a></li>
<li><a href="https://textdata.cn/blog/2023-10-11-how-can-machine-learning-empower-management-research/">管理世界 | 机器学习如何赋能管理学研究？——国内外前沿综述和未来展望</a></li>
<li><a href="https://textdata.cn/blog/2023-10-10-measure-the-speed-of-policy-diffusion-from-top-to-down/">管理科学学报 | 使用LDA算法计算政策扩散速度与扩散程度</a></li>
<li><a href="https://textdata.cn/blog/2023-10-07-esg-measurement/">企业ESG行为的文本度量法</a></li>
</ul>
<br>
<h3 id="22-有大邓工作量-被举报标记为滥用原创">2.2 有大邓工作量， 被举报标记为滥用原创</h3>
<p>推文中包括摘要 、概念定义、文献梳理，基本摘自(翻译自)论文原文， 涉及到创新点和文本分析技术实现内容， 大部分是有大邓的理解加工和上手敲代码实验， 一般有实验数据、代码、截图、解说。</p>
<ul>
<li><a href="https://textdata.cn/blog/2023-10-16-measurement-of-consumer-certainty-in-language/">JMR | 测量消费者的语言确定性</a></li>
</ul>
<br>
<h3 id="23-翻译整理-被标记为滥用原创">2.3 翻译整理， 被标记为滥用原创</h3>
<p>全文翻译， 翻译后总字数有约3w字， 虽然是使用谷歌翻译1min， 但为了增加可读性， 很多地方要调整语序， 对部分晦涩难懂的文本分析技术概念， 也会加入自己的理解。 全文整理下来5+小时。</p>
<p><a href="https://textdata.cn/blog/2023-11-03-organization-science-with-word-embeddings/">OS2022 | 概念空间 | 词嵌入模型如何为组织科学中的测量和理论提供信息</a></p>
<p><br><br></p>
<h2 id="最后">最后</h2>
<p>之前的活该被举报类型的推文，那是自己之前做的不妥不对， 我是知识产权利益相关方， 不能一方面用规则吃饭生活，另一方面却又在做破坏规则的事情。</p>
<p>人在做，天在看，不是不报，时候未到！ 自己如果成为恶人，自有恶人来惩治自己。这次被批量举报， 心里感到郁闷， 但也提醒自己以后标记原创时要更加小心。</p>
<p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>OS2022 | 概念空间 | 词嵌入模型如何为组织科学中的测量和理论提供信息</title>
      <link>https://textdata.cn/blog/2023-11-03-organization-science-with-word-embeddings/</link>
      <pubDate>Fri, 03 Nov 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-11-03-organization-science-with-word-embeddings/</guid>
      <description>&lt;h2 id=&#34;相关内容&#34;&gt;相关内容&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/2022-04-09-literature-about-embeddings/&#34;&gt;文献汇总 | 词嵌入 与 社会科学中的偏见(态度)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/2023-03-15-39faq-about-word-embeddings-for-social-science/&#34;&gt;词嵌入技术在社会科学领域进行数据挖掘常见39个FAQ汇总&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/2022-04-07-word-embeddings-in-social-science/&#34;&gt;转载|大数据时代下社会科学研究方法的拓展——基于词嵌入技术的文本分析的应用&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/2023-12-28-visualize-the-culture-change-using-people-daily-dataset/&#34;&gt;可视化 | 人民日报语料反映七十年文化演变&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/2023-12-28-train-word2vec-using-renmin-gov-leader-board-dataset/&#34;&gt;词向量  | 使用&lt;strong&gt;人民网领导留言板&lt;/strong&gt;语料训练Word2Vec模型&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;Aceves, Pedro, and James A. Evans. &amp;ldquo;&lt;strong&gt;Mobilizing conceptual spaces: How word embedding models can inform measurement and theory within organization science.&lt;/strong&gt;&amp;rdquo; &lt;em&gt;Organization Science&lt;/em&gt; (2023).&lt;/p&gt;
&lt;br&gt;
&lt;h2 id=&#34;摘要&#34;&gt;摘要&lt;/h2&gt;
&lt;p&gt;词嵌入模型是一种表示多维概念空间的强大方法，在多维概念空间中，所传达的概念可以相互关联、组合和竞争。此类模型代表了机器学习的最新进展，使学者能够用大规模文本数据局部和全局的单词共现，以最小的语义失真程度， 有效地编码复杂的意义系统。尽管词嵌入的使用有可能扩大组织科学中的理论可能性，但嵌入对于组织学者来说很大程度上是未知的，未发挥出词嵌入应有的潜力。我们的目标是通过为用户提供实用的路线图来展示嵌入模型在组织科学中的前景，以在他们的研究中调动该方法，并为开展该类研究的学者提供理论指导。 我们首先明确定义 &lt;strong&gt;概念&lt;/strong&gt; 和 &lt;strong&gt;概念空间&lt;/strong&gt; 的概念，然后继续展示如何使用词嵌入模型来表示和测量这些概念，并指出该方法的优点和缺点。然后，我们提供一组嵌入测量及其理论解释和灵活的扩展。我们的目标是从词嵌入的技术处理中提取概念，并将其置于实践的理论框架中，以加速此类研究。&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;一介绍&#34;&gt;一、介绍&lt;/h2&gt;
&lt;p&gt;过去十年，文本作为数据的计算使用在组织科学中显着增长（Hasan 等人，2015 年；Goldberg 等人，2016 年；Srivastava 等人，2018 年；Hannigan 等人，2019 年）。这种增长的主要原因是文本编码的概念信息赋予个人、组织、经济和社会行为以意义（Evans 和 Aceves 2016，Gentzkow 等人 2019），并且在过去十年中，来自组织环境的文本数据急剧增长，大大提高了文本的可用性。然而，文本中编码的 &lt;strong&gt;概念意义&lt;/strong&gt; 本质上是高维的，这使得降低概念复杂性成为研究文本的学者的中心任务。&lt;strong&gt;词嵌入模型是由计算机科学家和语言学家开发的一个新兴工具系列，用于文本信息降维，以此提取概念及其数字表示&lt;/strong&gt;。词嵌入技术的发展使组织科学家依赖于文本数据进行理论构造， 相比之前，数据中信息的保真度更高，由此文本数据与组织研究交叉场景形成了新的理论研究路线。尽管词嵌入模型在组织科学之外得到广泛使用，但由于组织科学领域的学者缺乏对词嵌入技术的理解， 不知如何将它们纳入理论发展过程的原则框架，词嵌入模型对于理论发展的价值仍然被掩盖。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;词嵌入模型建立在高效的神经网络架构之上，并通过将复杂的语义系统有效编码到具有最小失真的稠密几何空间中，彻底改变了语义分析&lt;/strong&gt;。这些模型代表了数十到数百个维度的空间中的语义，相对于语言中的单词和概念的数量来说，这个维度较低； 但相对于正式社会和文化理论家之前试图呈现概念信息的两到三个维度来说，这个维度却很高（奥斯古德 1964 年，史密斯-洛文和海斯 1988 年）。出于组织科学的目的，这些嵌入模型创建了社会系统中个体所持有的集体知识的 &lt;strong&gt;数字替身&lt;/strong&gt; ， 嵌入可以解决文化上隐含类比（Mikolov et al. 2013b），回答文化偶然问题（Devlin et al. 2019，Radford et al. 2022），并预测未来的知识发现（Tshitoyan等人 2019；Sourati 和 Evans 2021）。组织科学长期以来一直借鉴人工智能（AI）的表征概念， 在这里，我们使用人工智能的表示机制来增强组织理论研究（Csaszar 和 Steinberger 2022）。&lt;/p&gt;
&lt;p&gt;然而，由于神经网络复杂，且难以理解的黑盒性质特性，围绕神经嵌入和人工智能方法对理论发展的价值存在争议。尽管预测能力很强，但此类方法往往缺乏可解释性（Knight 2017，Leavitt et al. 2021）。&lt;strong&gt;在组织科学领域中，学者缺乏此技术的理解，即&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;对于嵌入何时成为组织科学有用的方法论选择&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;如何在既定认识论标准内证明使用“复杂”神经嵌入方法的合理性&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;如何在各种嵌入中进行选择 等方法&lt;/strong&gt;（例如，静态词嵌入与上下文嵌入、预训练嵌入与自定义嵌入）&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;使用嵌入进行研究的适当步骤以及评估嵌入研究的相关标准&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;最值得注意的是，研究界，特别是那些研究组织认知、文化、知识和意义的人，似乎对嵌入方法 &lt;strong&gt;如何适应将方法论选择与理论发展联系起来&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
&lt;p&gt;我们的目的是通过两项贡献来解决这些问题。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;首先，我们的目标是提供一个理论指南，为嵌入模型提供一个原则性的概念框架，学者可以使用该框架为他们的模型注入意义，并使学者们能够在理论发展过程中运用这些模型。我们这里的主要论点是，词嵌入模型中的每个向量代表一个概念，整个嵌入模型代表生成文本数据的社会系统的概念空间&lt;/strong&gt;。嵌入模型所代表的概念空间是多维空间，其中从规范和知识到想法和发明的概念相互关联。这个框架使组织学者能够利用嵌入模型的概念空间，与组织科学的许多领域之间建立联系。例如，不同公司基于知识视角对该空间的差异化覆盖（Grant 1996），组织理论家在描述规范和制度（Scott 2003），类别学者援引在决定将一个物体归类到哪个概念时（Pontikes 和 Barnett 2015 ），创新学者直接理论化寻求测量发现和发明的新颖性（Fleming 和 Sorenson 2001，2004），并且团队研究人员寻求了解成员在空间中的不同立场如何影响创造力、协调性和绩效（Srikanth 等人，2016）。因为我们以 &lt;strong&gt;概念&lt;/strong&gt; 和 &lt;strong&gt;概念空间&lt;/strong&gt; 为中心的理论框架可以推广到组织理论的许多背景，所以我们希望嵌入模型所支持的研究将促进这些子领域之间更深入、更持久的对话。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;其次，我们的目标是为利用嵌入模型进行理论发展提供实用的路线图&lt;/strong&gt;。在此过程中，我们引导读者完成使用专利摘要语料库来实现词嵌入模型的过程，以表示现代技术创新的概念空间。我们解释了研究人员需要设置的模型参数，并逐步完成了他们应该采取的验证步骤，以评估模型是否有效地代表了他们感兴趣的概念空间，并提供了方法附录，其中包含实现所讨论的所有内容所需的代码。在注意到嵌入模型的可供性的同时，我们还讨论了它们不断发展的局限性，并提出了它们何时不适合组织分析的建议。然后，我们展示嵌入模型如何实现依赖于概念和概念空间的构造的理论化和测量。&lt;/p&gt;
&lt;br&gt;
&lt;p&gt;我们概述了两大类词嵌入使用方法&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;度量之内/之间进行标记&lt;/strong&gt;，我们提出了跟踪相关分析集内部和之间的概念关系的度量，以帮助我们跟踪与概念广度、概念距离和概念相似性&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;意义及其维度&lt;/strong&gt;，我们提出了四种衡量标准，为了解意义及其与组织的关系提供了不同的窗口。为找出这些测量机会的理论可能性，我们重点介绍了一些研究进展。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;本论文的一个核心主张是，在组织研究不同广度和深度，词嵌入工具现在使我们能够表示其概念空间，并且比以前更精细地表示细节&lt;/strong&gt;。有鉴于此，我们的目标是展示嵌入模型如何在与组织科学家相关的领域中操作概念空间，使研究人员能够扩展和完善现有理论。我们希望这一理论指南和实践路线图将促进组织科学内部的理论扩展，该扩展首先是扩大对文本数据的访问以及用于分析的随附计算工具（Kovács 等人，2013 年; Goldberg 等人; 2016年，Hannigan 等人, 2016年, 2019； Guo 等人，2020）。&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;二概念和概念空间&#34;&gt;二、概念和概念空间&lt;/h2&gt;
&lt;p&gt;概念是人类生活的一个基本特征，我们的日常思维很大程度上依赖于它们所代表的信息，使我们能够对周围的人、物体和事件进行分类，并将这些信息传达给其他人（Murphy 2002；Bergen 和 Feldman 2008 年； Cassanto 和 Lupyan，2015 年）。概念是将我们的精神世界粘合在一起的粘合剂（Murphy 2002），赋予精神和物质体验以意义（Hannan et al. 2019）。&lt;strong&gt;在认知科学和心理学的语言中，概念是“事物类别的「心理表征」”（Murphy 2002）。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;概念有两大功能：分类和交流（Medin and Rips 2005），这些功能都需要语言的帮助。实际上，我们通过在语言中分配一个单词或短语来表示一个稳定概念的信息内容。这就是为什么我们通过说出或写出 “&lt;em&gt;&lt;strong&gt;manager&lt;/strong&gt;&lt;/em&gt;” 一词来提及经理的概念，从而引出它所包含的概念信息，例如对他人的责任、做出决策以及相对于组织同行获得更高的薪水。然后，语言的单词分割并链接了社区的共享概念空间（Lupyan 和 Bergen 2015）。这样，“一个概念就是一个单词或短语的含义……[包括]像 ‘&lt;em&gt;&lt;strong&gt;red&lt;/strong&gt;&lt;/em&gt;’ 和 ‘&lt;em&gt;&lt;strong&gt;grasp&lt;/strong&gt;&lt;/em&gt;’这样的基本的、具体化的单词，以及像 ‘&lt;em&gt;&lt;strong&gt;goal&lt;/strong&gt;&lt;/em&gt;’ 和 ‘&lt;em&gt;&lt;strong&gt;continuity&lt;/strong&gt;&lt;/em&gt;’ 这样的抽象和技术单词”（卑尔根）和 Feldman 2008]）。&lt;/p&gt;
&lt;p&gt;概念并不作为唯一的信息单位存在于真空中。相反，概念之所以有意义，是因为它们彼此相关（Hannan et al. 2019），“通过相似性和上下文的关系紧密地缝合在一起”（Hofstadter and Sander 2013）。在这种多重概念关系中存在着“我们对世界的大部分知识，告诉我们存在什么以及它们具有什么属性”（Murphy 2002，p.1）。例如，概念 &lt;em&gt;&lt;strong&gt;resource&lt;/strong&gt;&lt;/em&gt;  与  &lt;em&gt;&lt;strong&gt;firm&lt;/strong&gt;&lt;/em&gt;、&lt;em&gt;&lt;strong&gt;constraint&lt;/strong&gt;&lt;/em&gt; 和 &lt;em&gt;&lt;strong&gt;natural&lt;/strong&gt;&lt;/em&gt; 等概念相关。在文化系统的层面上，概念之间的相互关系引发了表征概念之间宏观层面有意义的维度。 &lt;em&gt;&lt;strong&gt;manager&lt;/strong&gt;&lt;/em&gt; 概念在某些方面与 &lt;em&gt;&lt;strong&gt;coach&lt;/strong&gt;&lt;/em&gt; 和 &lt;em&gt;&lt;strong&gt;president&lt;/strong&gt;&lt;/em&gt; 的概念很接近，而在其他方面则与&lt;em&gt;&lt;strong&gt;employee&lt;/strong&gt;&lt;/em&gt; 和 &lt;em&gt;&lt;strong&gt;bureaucracy&lt;/strong&gt;&lt;/em&gt; 的概念很接近。将概念理解为存在于复杂几何空间中的点，使我们能够思考和测量概念之间的距离远近（Hannan 等人，2019）。例如，与  &lt;em&gt;&lt;strong&gt;playground&lt;/strong&gt;&lt;/em&gt; 或 &lt;em&gt;&lt;strong&gt;ice cream&lt;/strong&gt;&lt;/em&gt; 相比， &lt;em&gt;&lt;strong&gt;manager&lt;/strong&gt;&lt;/em&gt; 与&lt;em&gt;&lt;strong&gt;organization&lt;/strong&gt;&lt;/em&gt; 和 &lt;em&gt;&lt;strong&gt;leader&lt;/strong&gt;&lt;/em&gt; 概念的联系更加紧密。&lt;strong&gt;我们将这种概念相关的多维空间称为概念空间&lt;/strong&gt;（Hannan et al. 2019)&lt;/p&gt;
&lt;p&gt;重要的是我们用复数来指代概念空间。对于许多单词来说，它们会根据使用的上下文表现出不同的概念信息模式。首先，概念可能会根据使用它们的社会背景而有所不同。例如，如果在执行董事会议室、商品交易大厅或附近的储蓄和贷款机构的背景下说出 “&lt;em&gt;&lt;strong&gt;Bank&lt;/strong&gt;&lt;/em&gt;”，指的是银行而不是河流。概念也可能根据使用时间的不同而有所不同。例如，“&lt;em&gt;&lt;strong&gt;高科技&lt;/strong&gt;&lt;/em&gt;” 一词所引发的概念关系会根据我们研究的是 1960 年代、1990 年代还是今天而有所不同。最后，概念关系因使用它们的社区而异，因此 “&lt;em&gt;&lt;strong&gt;债务&lt;/strong&gt;&lt;/em&gt;” 所捕获的概念将根据其是由首席财务官还是低收入个人使用而有所不同。概念所含信息存在多样性， 正如 Hannan等人（2019）指出，“虽然有些概念可能是天生的或生物驱动的，但大多数都是社会构建的。”&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;三先前研究中的概念和概念空间&#34;&gt;三、先前研究中的概念和概念空间&lt;/h2&gt;
&lt;p&gt;概念以及扩展的概念空间是人类思维和交流的基础（Sperber 和 Wilson 1986；，Murphy 2002；Hofstadter 和 Sander 2013）。正因为如此，概念和概念空间对于许多组织理论框架来说或多或少是明确和关键的。在某些研究（例如类别研究）中，概念具有核心重要性并且已经被明确地理论化。然而，在其他情况下，（例如，公司基于知识视角）概念被隐含地假定，即使它们是决定许多理论期望的基本成分。鉴于概念无处不在，对组织科学所有领域使用概念信息进行全面回顾超出了本文的范围。我们将简短、非详尽的回顾集中在概念和概念空间概念的三个领域——&lt;strong&gt;类别、知识和文化&lt;/strong&gt;。通过嵌入技术处理并追踪存在于个人和社区头脑中的概念信息，研究其对组织行为和结果的影响。&lt;br&gt;&lt;/p&gt;
&lt;h3 id=&#34;31-类别&#34;&gt;3.1 类别&lt;/h3&gt;
&lt;p&gt;类别是具有共同特征和属性的实体组。如前所述，概念是类别的心理表征。对类别的研究主要集中在跨类别或模糊类别是否会增加或减少分类实体的估值。自Zuckerman（1999）以来的工作一直集中在消除歧义条件上，在这些条件下，类别跨越和模糊性会导致积极或消极的估值。许多研究表明，由于感知偏差（Durand et al. 2007）、不符合受众期望（Hsu 2006)、Hsu et al. 2009；Leung and Sharkey 2014） ，跨越模糊的类别会损害实体估值，或降低分类对比度（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B119&#34;&gt;Negro et al. 2010&lt;/a&gt;）。其他研究表明，跨越类别可以创造积极的估值结果，因为它表明非典型性可以放大良好的表现并缓冲不良表现（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B159&#34;&gt;Smith 2011&lt;/a&gt;），一个类别可以锚定认知，而另一个类别可以有益地修改认知（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B188&#34;&gt;Wry et al. 2014&lt;/a&gt;）。还有其他研究表明，效果取决于受众，有些人喜欢跨类别，而另一些人则不喜欢（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B135&#34;&gt;Pontikes 2012&lt;/a&gt;）。通过这些方式，类别可以通过影响有关类别成员资格的概念信息的解释方式，对行为和绩效产生积极或消极的影响。&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#fn5&#34;&gt;4&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;尽管类别范式的贡献历来是通过类别成员的集合和模糊集合理论（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B64&#34;&gt;Hannan et al. 2007&lt;/a&gt;）概念来实现的，但最近的工作开始纳入其多维性（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B65&#34;&gt;Hannan et al. 2019&lt;/a&gt;）和类别的分级归属感。组织学者感兴趣的许多现象都是由概念及其代表的类别之间的精确距离支撑的。例如，鉴于专利所贡献的技术领域，专利通常分为类别和子类。然而，专利中编码的想法可以传播到创新空间的广泛领域，即使只分类在一个类别中。正如我们稍后讨论的，转向概念的几何概念，使分析师能够考虑隶属度、重叠和连续距离影响底层实体评估判断的方式&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B65&#34;&gt;（Hannan 等人，2019 &lt;/a&gt;。&lt;br&gt;&lt;/p&gt;
&lt;h3 id=&#34;32-知识&#34;&gt;3.2 知识&lt;/h3&gt;
&lt;p&gt;众所周知，知识很难具体说明，并且在哲学、认知科学和社会科学领域，围绕其概念性质进行了长期而活跃的争论（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B166&#34;&gt;Steup 和 Neta 2020&lt;/a&gt;）。然而，过去几十年来，组织科学在微观、中观和宏观层面上进行了大量研究，解决有关知识及其在团队、组织和经济活动中的作用的问题。从对团队成员专业知识的研究（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B164&#34;&gt;Srikanth et al. 2016&lt;/a&gt;）到公司基于知识和注意力的观点（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B87&#34;&gt;Kogut and Zander 1992&lt;/a&gt;，&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B56&#34;&gt;Grant 1996&lt;/a&gt;，&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B123&#34;&gt;Ocasio 1997&lt;/a&gt;）；从交互记忆系统（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B143&#34;&gt;Ren 和 Argote，2011&lt;/a&gt;）到创新流程（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B50&#34;&gt;Garud 等，2013&lt;/a&gt;）；从组织设计（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B45&#34;&gt;Foss et al. 2013&lt;/a&gt;）到搜索和探索（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B93&#34;&gt;Lavie et al. 2010&lt;/a&gt;），知识在最近的组织理论化中发挥着核心作用。&lt;/p&gt;
&lt;p&gt;无论人们对知识的定义如何选择，命题性知识从根本上都与概念信息相关。&lt;em&gt;&lt;strong&gt;命题知识采取“ S [主体]知道p [命题]”&lt;/strong&gt;&lt;/em&gt; 的形式（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B80&#34;&gt;Ichikawa and Steup 2018&lt;/a&gt;）。在某种程度上，命题是由语言中的单词编码的，并且单词代表概念信息，命题知识依赖于概念以及它们如何在概念空间中交织（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B110&#34;&gt;McGrath and Frank 2020&lt;/a&gt;）。以命题“泰勒知道氢的主要工业应用是氨的制造”和“特里知道量子算法可以具有较低的时间复杂度”为例。这些知识命题中的每一个都代表了不同的概念意义，前面提到的领域将以不同的方式操作它们。例如，团队学者可能会强调，由泰勒和特里组成的专利团队将拥有多样化的基础知识。采取基于注意力观点的学者会注意到，泰勒和特里可能会以不同的方式关注知识空间，以应对组织变革。研究创新的人可能会注意到如果泰勒和特里共享办公空间，知识重组的潜力。研究搜索的人可能会假设，为了解决问题，泰勒和特里会以不同的方式搜索概念性解决方案。在所有这些情况下，就这些领域通过诉诸语言编码的命题知识来理论化知识动态而言，它们以基本和可测量的方式参与概念和概念空间。&lt;br&gt;&lt;/p&gt;
&lt;h3 id=&#34;33-文化&#34;&gt;3.3 文化&lt;/h3&gt;
&lt;p&gt;文化被不同地概念化为集体的共同价值观、故事、框架、工具包和类别（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B52&#34;&gt;Geertz 1973&lt;/a&gt;；&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B131&#34;&gt;Pettigrew 1979&lt;/a&gt;；&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B92&#34;&gt;Lamont 和 Small 2008&lt;/a&gt;；&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B158&#34;&gt;Small 等人 2010&lt;/a&gt;；&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B54&#34;&gt;Giorgi 等人 2015&lt;/a&gt;）。文化建构已成为组织研究的核心，在从个人和团队到组织和国家的各个层面的分析中都得到了运用（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B54&#34;&gt;Giorgi et al. 2015&lt;/a&gt;）。从理解文化如何塑造职业结构（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B195&#34;&gt;Glynn 2000&lt;/a&gt;）、组织领域（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B194&#34;&gt;Anteby 2010&lt;/a&gt;）和创业环境（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B106&#34;&gt;Lounsbury and Glynn 2001&lt;/a&gt;，&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B141&#34;&gt;Rao and Giorgi 2006&lt;/a&gt;）到它在讲故事（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B106&#34;&gt;Lounsbury and Glynn 2001&lt;/a&gt;）和身份建设中的作用（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B196&#34;&gt;Ravasi 和 Schultz 2006&lt;/a&gt;），从其对人际沟通的塑造（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B165&#34;&gt;Srivastava 等人，2018&lt;/a&gt;）到对组织绩效的影响（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B26&#34;&gt;Corritore 等人，2020&lt;/a&gt;），文化深深地受到概念及其互动方式的调节。文化以集体认知过程为基础（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B36&#34;&gt;DiMaggio 1997&lt;/a&gt;，&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B128&#34;&gt;Patterson 2014&lt;/a&gt;），很大程度上可以通过语言痕迹来获取。语言进入文化的窗口（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B55&#34;&gt;Goldberg et al. 2016&lt;/a&gt;，&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B165&#34;&gt;Srivastava et al. 2018&lt;/a&gt;，&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B26&#34;&gt;Corritore et al. 2020&lt;/a&gt;）很大程度上是通过它所表达的概念来呈现的，使得概念和概念空间成为组织文化研究的重要支柱。&lt;/p&gt;
&lt;p&gt;基于它们在形成范畴、知识和文化方面的关键作用，概念和概念空间已成为许多组织理论赖以建立的知识支架的重要组成部分。然而，概念和概念空间通常仅被用作缺乏精确和可扩展的经验表征的不明确的隐喻。这限制了研究使用粗粒度的代理测量或允许手动编码和解释的小数据集。接下来，我们提出词嵌入模型是一种最先进的工具，用于表示概念和概念空间，可以添加到组织学者工具包中。就组织学者寻求将概念和概念信息所支撑的结构操作化而言，他们将得到这类新模型的帮助。考虑到这一点，我们接下来介绍嵌入模型如何工作以及为什么它们可以作为概念和概念空间的有效表示。&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;四使用词嵌入来表示概念和概念空间&#34;&gt;四、使用词嵌入来表示概念和概念空间&lt;/h2&gt;
&lt;h3 id=&#34;41-越来越多地使用文本作为数据&#34;&gt;4.1 越来越多地使用文本作为数据&lt;/h3&gt;
&lt;p&gt;过去 10 年，通过计算工具和方法进行文本数据分析出现了爆炸性增长。从社会学（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B40&#34;&gt;Evans and Aceves 2016&lt;/a&gt;）到经济学（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B53&#34;&gt;Gentzkow et al. 2019&lt;/a&gt;）和政治学（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B58&#34;&gt;Grimmer and Stewart 2013&lt;/a&gt;），文本正迅速成为组织、经济和社会生活的中心观察站。文本数据提供了在线知识社区、财报电话会议和公司报告、产品评估、组织电子邮件和讨论板、历史档案、视频转录和电影字幕、医疗记录、电子商务、社交媒体等多种领域的丰富思想和行为痕迹。媒体平台、新闻文章、科学学科等等。总而言之，这些文本数据源比以往任何时候都更深入、更广泛地进入组织生活。正如&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B40&#34;&gt;Evans 和 Aceves（2016 年&lt;/a&gt;）指出的那样，文本数据现在使我们能够访问“有关正在玩的社交游戏的隐藏元素及其背后的社交世界”的深层信息。然而，这些语料库的庞大规模及其广泛的范围意味着，提取理论上有意义的信息信号越来越多地受到计算方法的帮助，利用信息技术方法获取大量非结构化文本数据，并将它们转换为有意义且相关的度量。&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#fn6&#34;&gt;5&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;文本数据与组织学者习惯使用的定量数据之间的一个主要区别是文本是高维的。正如&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B53&#34;&gt;Gentzkow 等人（2019 年&lt;/a&gt;）指出，“仅使用英语中一千个最常用单词的 30 个单词的 Twitter 消息样本 [&amp;hellip;] 的维度大致与宇宙中的原子一样多。” 因此，使用文本作为数据的学者的中心任务是通过对数据施加限制来降低维度。&lt;strong&gt;过去二十年里，组织科学中用于降低这一维度的一些最常用的计算工具是词典法、语义网络和主题模型。尽管这些方法有其优点，但一个主要缺点是它们无法对文本中存在的细粒度概念关系和关联进行编码&lt;/strong&gt; 。接下来，我们将展示嵌入模型如何利用文本中的局部和更广泛的信息来训练概念含义和概念空间的高保真表示。在此过程中，我们展示了词嵌入模型如何克服先前方法来表示文本中编码的含义的一些局限性，从而允许对理论结构进行更细粒度的测量，并实现新的理论可能性。&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;42-词嵌入&#34;&gt;4.2 词嵌入&lt;/h3&gt;
&lt;p&gt;我们之前解释过，概念是事物类别的心理表征，人类通过在词典中分配一个单词或短语来表示稳定的概念，并指出，概念只有在与跨多个维度的其他概念相关并为其提供信息时才有意义。密集的概念空间。在这里，我们认为词嵌入模型是最近开发的一类从机器学习应用于自然语言处理的模型，它使我们能够有效且高效地表示概念空间，并将这些空间用于追求组织科学。词嵌入模型是文本语料库中单词的连续表示，可以进行几何解释。&lt;strong&gt;词嵌入的方法论假设，一个词的含义很大程度上是由出现在其直接和更广泛上下文中的词所决定的，这一想法受到结构语言学家的启发，他们已经证明，含义的差异与局部分布相关（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B68&#34;&gt;Harris 1954&lt;/a&gt;）， 这个想法现在被称为 「分布式语义学」，Firth 的著名描述是：“观其伴而知其意”（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B42&#34;&gt;Firth 1957&lt;/a&gt;，you shall know a word by the company it keeps）， 一个单词所代表的概念或含义可以通过它周围的单词的分布来推断&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;以这种分布式方式思考概念和概念空间的底层计算架构可以追溯到 20 世纪 80 年代初期计算机科学家 Geoffrey Hinton 的工作（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B71&#34;&gt;Hinton 1986&lt;/a&gt; , &lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B72&#34;&gt;Hinton et al. 1986&lt;/a&gt;）以及认知科学家在这一时期研究的并行分布式处理模型（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B149&#34;&gt;Rumelhart 等人，1986a&lt;/a&gt;，&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B150&#34;&gt;b&lt;/a&gt;；&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B109&#34;&gt;McClelland 和 Rumelhart，1989&lt;/a&gt;）。分布式架构是当前嵌入语言模型的基础（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B115&#34;&gt;Mikolov et al. 2013b&lt;/a&gt;、&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B130&#34;&gt;Pennington et al. 2014&lt;/a&gt;、&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B35&#34;&gt;Devlin et al. 2019&lt;/a&gt;、&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B104&#34;&gt;Liu et al. 2019&lt;/a&gt;、&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B17&#34;&gt;Brown et al. 2020&lt;/a&gt;、&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B41&#34;&gt;Fedus et al. 2020）。 2021&lt;/a&gt;）， 嵌入模型 Word2Vec 算法(&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B115&#34;&gt;Mikolov 等 2013b&lt;/a&gt;) 相对简单易用，能够处理中等规模的语料库来。 &lt;strong&gt;Word2Vec 与  GloVe（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B130&#34;&gt;Pennington 等人，2014 年&lt;/a&gt;）和 FastText（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B13&#34;&gt;Bojanowski 等人，2017 年&lt;/a&gt;）等嵌入算法，是 ChatGPT 和相关模型的基础&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;找个例子来帮助理解算法， 现在我们要创建过去 50 年创新的概念空间表示。首先需要概念活动领域的文本数据， 美国专利局数据提供了创新活动的踪迹，其中包括所有专利的文本、摘要、描述和权利要求。在整篇论文中，我们使用这个专利摘要语料库来指导读者完成训练这个概念空间和构建相关概念测量的过程。数据是从&lt;a href=&#34;https://patentsview.org/&#34;&gt;Patentsview.org&lt;/a&gt;免费下载的，使用 1976 年至 2019 年间发布的所有专利来构建本文中发现的词嵌入模型和测量相关指标。&lt;/p&gt;
&lt;p&gt;想象一下，专利语料库中的每个独特单词都是从放置在巨大冰箱上的随机放置的 &lt;strong&gt;“word magnet”&lt;/strong&gt; 开始的（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B76&#34;&gt;Hovy 2020&lt;/a&gt;）。当连续词袋 (CBOW) 算法滚动浏览语料库时，使用每个目标词周围的单词词(滑动窗口的上下文)来预测目标词（更多内容见下文）。该算法的最终目标是产生一种语义模型，其中出现在相似上下文中的单词彼此接近，而来自不同上下文的单词则相距很远。由于用2维概念空间不足以捕获每个单词的全部含义，因此该算法改为在更高的（100-1,000）维空间内捕捉语义。通过这种方式，目标单词的概念信息是从它周围的单词中归纳出来的，将语料库中的每个单词绘制为&lt;em&gt;n&lt;/em&gt;维空间中的坐标或向量。正是单词在这个&lt;em&gt;n&lt;/em&gt;维向量空间中的相对位置，使我们能够将词嵌入模型可以描述代表人类概念活动区域的概念空间。&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#fn7&#34;&gt;6&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;概念意义的识别假定了嵌入空间的可解释性。接下来，我们提出了对这些概念空间的一系列提示和测量，作为从中产生结构化解释的方法。这很像心理学家使用 &lt;strong&gt;心理测量调查&lt;/strong&gt; 将概念印象转化为可解释的观点（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B112&#34;&gt;Michael Furr 2021&lt;/a&gt;）。或者&lt;strong&gt;认知人类学家如何使用结构化任务，例如排序和排名（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B163&#34;&gt;Spradley 2016&lt;/a&gt;），将概念性的世界观转变为可解释的世界观&lt;/strong&gt;。我们认为嵌入模型必须接受结构化测量（就像向人类受试者提供的心理测量问卷）使他们的 **概念景观(conceptual landscape)**变得可解释。接下来，我们将引导读者如何用专利语料库训练创新概念空间表示的过程。之后， 我们概述了该方法的优点和局限性，并指出这些方法与先前的文本分析方法和组织研究实践的关系。&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;43-选择语料库&#34;&gt;4.3 选择语料库&lt;/h3&gt;
&lt;p&gt;学者可以根据应用使用两种词嵌入模型。一方面，研究人员可以使用自有文本语料库来训练表示， 据此了解文本所涉主体(个人、团体、社会)行为的概念空间是什么样子， 以及概念关系揭示人类活动背景。在我们的示例中，专利创新在专利语料库中得到了很好的体现，因此我们在下面展示了如何从头开始训练概念空间表示, 以及它揭示了哪些概念联系。研究人员可以从头开始训练语料库的其他例子包括在线社区（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B18&#34;&gt;Burtch et al. 2021&lt;/a&gt;、&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B2&#34;&gt;Aceves et al. 2022&lt;/a&gt;、&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B23&#34;&gt;Chambers et al. 2022&lt;/a&gt;）、学术学科（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B74&#34;&gt;Hofstra et al. 2020&lt;/a&gt;、&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B102&#34;&gt;Lin et al. 2022&lt;/a&gt;） 、劳动力市场（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B9&#34;&gt;Bana 2022&lt;/a&gt;）、公共记录（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B6&#34;&gt;Arseniev-Koehler et al. 2022&lt;/a&gt;）、产品和公司描述（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B61&#34;&gt;Guzman and Li 2023&lt;/a&gt;）以及财报电话会议和公开演讲（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B85&#34;&gt;Kirgil and Voyer 2022&lt;/a&gt;）。&lt;/p&gt;
&lt;p&gt;或者，如果研究人员想要在较小的语料库中追踪概念动态，而该语料库的大小不足以训练独特的、特定于上下文的嵌入，那么研究者可以使用预训练嵌入模型，需要注意，训练预训练嵌入模型的文本与研究者小语料库在内容、场景要有相似性。广泛使用的预训练嵌入已经在来自海量语料库的文本上进行了训练，例如新闻（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B4&#34;&gt;Google 2013&lt;/a&gt;）、维基百科（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B35&#34;&gt;Devlin et al. 2019&lt;/a&gt;、&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B57&#34;&gt;Grave et al. 2018&lt;/a&gt;）。训练这些预训练嵌入模型的文本语料体量很大， 内容题材往往包含我们较小文本样本中存在的概念。因此使用预训练嵌入对这些概念的信息进行编码，并可用于近似相关距离。政治和历史语义背景下的研究发现，预训练嵌入提供的结果与特定于上下文的嵌入相当（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B89&#34;&gt;Kozlowski et al. 2019&lt;/a&gt;，&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B145&#34;&gt;Rodriguez and Spirling 2022&lt;/a&gt;）。如果有理由相信研究项目中包含的概念和想法没有在这些大量预训练嵌入中得到很好的体现，研究人员可以使用较小语料库中的文本对其进行 &lt;strong&gt;微调（Fine-Tune）&lt;/strong&gt;（ &lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B104&#34;&gt;Liu et al. 2019，Burtch et al.2019&lt;/a&gt;）&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B18&#34;&gt;， 2021&lt;/a&gt;）。微调将预训练的概念空间扭曲为与样本一致（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B104&#34;&gt;Liu et al. 2019&lt;/a&gt;），更好地反映概念之间的关系。&lt;/p&gt;
&lt;p&gt;最后，使用哪一种嵌入(自己训练的嵌入、 预训练的嵌入、微调的嵌入)将取决于研究人员的目的以及他们寻求追踪的概念动态的类型。接下来，我们将重点描述从头开始训练和验证嵌入模型的过程。在接下来的部分中，我们讨论不同参数设置和策略之间的权衡，并鼓励读者遵循文章文本和在线附录。&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;44-清理语料库&#34;&gt;4.4 清理语料库&lt;/h3&gt;
&lt;p&gt;训练嵌入模型的第一步是使用 Python 等编程语言录入文本语料库， 首先获取每个专利摘要中的文本， 并将连续的文本进行切词，转化为单词列表 。然后，我们将文本小写，删除标点符号和数字字符串，并将每个摘要转换为称为token的单词列表。但是这可能破坏一些词组语义，这里使用 &lt;em&gt;&lt;strong&gt;bi-gram&lt;/strong&gt;&lt;/em&gt;， 识别高频共现的词组成词组，例如当 &lt;em&gt;&lt;strong&gt;“electric”&lt;/strong&gt;&lt;/em&gt; 和 &lt;em&gt;&lt;strong&gt;“vehicle”&lt;/strong&gt;&lt;/em&gt; 这两个词在某些上下文中一起出现时，它们将被统一形成短语和概念 &lt;em&gt;&lt;strong&gt;“electric_vehicle”&lt;/strong&gt;&lt;/em&gt; 。建立单词或短语列表后，执行单词嵌入算法来学习单词或二元组及其语言上下文之间的最佳距离，以保留语言中单词和短语的概念空间。&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;45-训练嵌入模型&#34;&gt;4.5 训练嵌入模型&lt;/h3&gt;
&lt;p&gt;第一步是选择词嵌入算法， 浅层神经网络构建的单词表示（例如，Word2Vec、FastText；&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B115&#34;&gt;Mikolov 等人，2013b&lt;/a&gt;）、共现矩阵的低秩近似（GloVe；&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B130&#34;&gt;Pennington 等人，2014&lt;/a&gt;） ，或来自 Transformer 的深度上下文嵌入（例如 BERT、&lt;em&gt;GPT&lt;/em&gt;；&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B35&#34;&gt;Devlin 等人 2019&lt;/a&gt;、&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B139&#34;&gt;Radford 等人 2022&lt;/a&gt;）。这些不同算法输出，都可以被解释为&lt;em&gt;n&lt;/em&gt;维概念空间，其中单词或短语由空间内的向量位置表示。本文我们只介绍 Word2Vec 算法， word2vec 是一种广泛使用的训练概念空间的算法（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B113&#34;&gt;Mikolov 等人，2013a&lt;/a&gt;，&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B115&#34;&gt;b&lt;/a&gt;）。&lt;/p&gt;
&lt;p&gt;Word2Vec 算法的一种流行实现算法是连续词袋 (CBOW) 算法，可以在 Gensim python 库中轻松访问，该算法使用目标单词的语言上下文来预测被扣掉的目标词 (可以简单的理解为让机器做完形填空题) ， 比较适合小规模数据集。 Word2Vec 还实现了另一种 Skip-Gram 算法，该算法通过从目标单词预测上下文单词来反转 CBOW 的预测任务，比较适合大规模数据集。相比之下，skip-gram 将每个上下文目标对（例如，T：“房子”，C：“宽敞”）视为单独的观察，因此可以更好地捕获精确的语义，但需要更大的语料库才能获得卓越的性能。&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;46-维数&#34;&gt;4.6 维数&lt;/h3&gt;
&lt;p&gt;考虑维数很有必要。朴素的模型可以将不重复总词数作为维度， 例如包含 100,000 个不重复单词的语料库， 任何单词都需要  100,000 维才能准确表示。然而，当单词从上下文中被识别为相似时，可以一定范围内减少维度数。&lt;strong&gt;维度过多会导致内存需求和冗余增加，并降低可解释性；维度太少会扭曲距离并且无法解释语言的不及物性&lt;/strong&gt;。通过这种方式，通过具有至少足够的维度来捕获所讨论的复杂语义关系，可以获得准确的预测。&lt;/p&gt;
&lt;p&gt;在实践中，300 维已经成为一个标准，很大程度上源于最初的 Word2Vec 论文之后的惯例，该论文通过交叉验证确定了最佳维数，以减少预测屏蔽词任务中的错误。大多数后续分析都是建立在较小、多样性较低的文本集合上，需要较少的维度，因此 300 通常被用作上限。最近的工作表明，应根据语料库统计数据选择维度 - 语料库词汇表中成对等距单词的数量提供了维度数量的下限，低于此界限通常会导致单词嵌入质量下降（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B127&#34;&gt;帕特尔和巴塔查亚 2017&lt;/a&gt;）。&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B74&#34;&gt;霍夫斯特拉等人。(2020)&lt;/a&gt;使用 100、200 和 300 维的模型找到了稳健的结果。&lt;/p&gt;
&lt;p&gt;如果分析师寻求实现维度可解释性，他们必须以最小失真来确定表示数据所需的维度数。 但这最后一步一半很少执行，因为维度的优化需要大量的时间和计算资源。&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;47-窗口尺寸&#34;&gt;4.7 窗口尺寸&lt;/h3&gt;
&lt;p&gt;回想一下，窗口大小是指算法将用来焦点目标词（或其邻居）之前和之后的单词数量。该窗口最小可以是 1。对于较小的窗口，算法将倾向于对句法关系进行编码（例如，名词后跟动词）。&lt;strong&gt;随着窗口大小的增加，更多的含义和语义被编码到模型输出中&lt;/strong&gt;。&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B145&#34;&gt;考虑Rodriguez 和 Spirling (2022)&lt;/a&gt;的示例，其中包含两个句子的语料库：(1)“狮子吃肉”和 (2)“牛吃草”。当窗口大小为一时，我们会知道牛和狮子都吃东西，从这个意义上说，牛和狮子在语法上是等价的，因为我们没有足够的信息来区分两者。然而，随着窗口的增加，算法开始对牛与狮子的含义进行更多编码。&lt;strong&gt;与维度数量一样，这里的回报也递减，窗口大于五个字的模型性能略有改善&lt;/strong&gt;（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B145&#34;&gt;Rodriguez 和 Spirling 2022&lt;/a&gt;）。 &lt;strong&gt;BERT 和 GPT 系列等上下文模型具有更大的窗口，这些窗口通过注意力过程进行驯服，算法通过该过程识别哪些上下文单词对于解释焦点单词的含义很重要&lt;/strong&gt;（Vaswani 等人，2017 年&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B176&#34;&gt;）&lt;/a&gt;。&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;48-验证模型&#34;&gt;4.8 验证模型&lt;/h3&gt;
&lt;p&gt;最后一步是验证词嵌入模型，这样做是为了确认算法学习的表示与文本数据所承载的真实人类活动的概念空间表示尽可能相近。论文附录第 2 节描述了关于专利嵌入的七个详细验证程序，表明该模型有效地学习了创新空间的表示。这些包括（1）邻近嵌入词的语义相似性；(2)具有嵌入距离的语义梯度；(3)嵌入簇与语义域之间的对应关系；（4）物理世界距离与嵌入之间的相关性；(5) 社会距离与嵌入之间的相关性；(6) 嵌入空间类比推理的准确性；(7)嵌入文档的语义一致性。我们还讨论了第八个“额外”测试，即图灵测试（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B174&#34;&gt;Turing 1950&lt;/a&gt;）。由 Transformer 支持的现代上下文嵌入的评估标准是它们是否能够与人类毫无区别地参与任何分类、关联、意义生成或集成任务，包括普通对话和专家教程。OpenAI 的 ChatGPT 和许多竞争的聊天机器人已经展示了如此强大的性能，以至于图灵测试正在迅速从上限转变为基线基准。这些验证步骤与论文最后部分的测量相结合，作为嵌入模型的有用提示prompt和测量，使研究人员能够对其编码的概念空间提供结构化解释。&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;49-词嵌入方法的优点和缺点&#34;&gt;4.9 词嵌入方法的优点和缺点&lt;/h3&gt;
&lt;h4 id=&#34;491--无需正式指定相关尺寸&#34;&gt;4.9.1  无需正式指定相关尺寸&lt;/h4&gt;
&lt;p&gt;对概念建模的正式尝试试图通过逻辑演绎方法清楚地枚举概念的相关维度（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B47&#34;&gt;Gärdenfors 2004&lt;/a&gt;、&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B48&#34;&gt;Gardenfors 2014&lt;/a&gt;、&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B65&#34;&gt;Hannan 等人 2019&lt;/a&gt;）。尽管这种方法对于理解限定领域内的概念很有用，但即使如此，它也可能不切实际且难以衡量，因为很难先验地陈述分析师应预期的相关维度&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B73&#34;&gt;（Hofstadter 和 Sander 2013 ）&lt;/a&gt;。 &lt;strong&gt;词嵌入的优点在于，概念之间的关系以及对任何给定概念重要的相关维度可以从语言的使用方式中推断出来，因此不需要事前指定&lt;/strong&gt;。鉴于在分析之前没有必要陈述相关维度，即使是最复杂的组织行为剧场也变得易于分析处理。正如其他人所指出的，“词嵌入为语言中包含的多个维度的含义提供了全面且有意义的见解，这是以前的方法无法捕获的”（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B105&#34;&gt;Lix 等人，2022 年&lt;/a&gt;，第 8434 页）。在某种程度上，这种优势源于这样一个事实：神经网络架构能高效地记录意义的维度。&lt;/p&gt;
&lt;br&gt;
&lt;h4 id=&#34;492-更大的有效维度&#34;&gt;4.9.2 更大的有效维度。&lt;/h4&gt;
&lt;p&gt;嵌入通常由 100 到 1,000 个密集编码维度表示。&lt;strong&gt;编码的密度意味着每个词向量在所有建模维度上都有一个非零坐标&lt;/strong&gt;。正如附录中所指出的，主题模型可能具有相同数量的主题（例如，100-1,000），但这些主题被稀疏编码以方便人类解释，使得主题仅具有一些基本上非零的单词加载，并且文档仅具有少量非零的主题负载。&lt;strong&gt;因此，主题模型是为了描述而构建的，但代价是迫使其表示的有效维度从数百个减少到几个，从而扭曲了本来可以在主题空间内计算的距离。相比主体模型， 词嵌入使用密集编码，每维度的嵌入很难理解和描述，但距离具有更大的自由度，可以更精确地编码含义&lt;/strong&gt;。通过这种方式，相对于低维理论和测量，嵌入为分析师提供了“大量潜在轴，个人和社会群体可以沿着这些轴竞争、合作、分裂或合并”（Kozlowski et al. 2019，p.27 &lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B89&#34;&gt;）&lt;/a&gt;。&lt;/p&gt;
&lt;br&gt;
&lt;h4 id=&#34;493-无监督训练&#34;&gt;4.9.3 无监督训练。&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;词嵌入还有一个特殊优点，即训练模型时， 以看似无监督或自监督的方式进行，从而避免了手动编码文本语义内容的繁琐，完全由机器学习&lt;/strong&gt;。在我们的创新示例中，向量空间由我们专利语料库中的每个发明人按照他们所写句子的数量和长度的比例进行监督。每个单词的滑动窗口都是为了向专利审查员和未来的发明者传达一种含义而构建的，该算法用于构建向量空间并以概念上适当的方式定位单词。因此，学者们可以利用专利语料库来训练 &lt;strong&gt;技术创新&lt;/strong&gt; 的概念空间，利用财报电话会议记录和新闻稿来训练 &lt;strong&gt;上市公司沟通&lt;/strong&gt; 的概念空间，利用分析师报告来训练 &lt;strong&gt;投资分析&lt;/strong&gt; 的概念空间，或者特定领域的概念空间。使用内部通信（例如 Slack 和电子邮件）来了解公司的知识。这些概念空间可以在最少的监督下进行训练，因此很快成为有价值的观察站，用于追踪组织科学家关注的组织生活的静态和动态（Hofstra et al. 2020，Whalen et al. 2020，&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B74&#34;&gt;Burtch&lt;/a&gt; et &lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B184&#34;&gt;al&lt;/a&gt; . &lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B18&#34;&gt;2021&lt;/a&gt;，&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B177&#34;&gt;Waller 和 Anderson 2021&lt;/a&gt;、&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B2&#34;&gt;Aceves 等人 2022&lt;/a&gt;、&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B20&#34;&gt;Carlson 2022&lt;/a&gt;、&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B23&#34;&gt;Chambers 等人 2022&lt;/a&gt;、&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B61&#34;&gt;Guzman 和 Li 2023&lt;/a&gt;、&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B94&#34;&gt;Lawson 等人 2022&lt;/a&gt;、&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B105&#34;&gt;Lix 等人 2022&lt;/a&gt;）。&lt;/p&gt;
&lt;br&gt;
&lt;h4 id=&#34;494-共现是不必要的&#34;&gt;4.9.4 共现是不必要的。&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;这些模型的另一个优点是，两个概念不必在任何文档中同时出现，就可以将它们编码为相似的向量&lt;/strong&gt;。所需要的只是它们与相似的概念同时出现。例如，我们可以先验地指出 &lt;em&gt;&lt;strong&gt;医生&lt;/strong&gt;&lt;/em&gt; 和 &lt;em&gt;&lt;strong&gt;律师&lt;/strong&gt;&lt;/em&gt; 在某些方面非常相似（例如，他们需要高级学位，具有高收入水平等），但他们可能永远不会同时出现在语料库的同一文档中。尽管彼此之间缺乏共现性，但它们很可能都独立地与高收入*、&lt;em&gt;高学历&lt;/em&gt;、*白领等概念同时出现，从而最终拥有编码这些相似性的接近向量。&lt;strong&gt;因此，嵌入模型的底层计算架构可以更好地近似社会和文化含义，而无需求助于严格的共现&lt;/strong&gt;。&lt;/p&gt;
&lt;br&gt;
&lt;h4 id=&#34;495-上下文相关的含义结构&#34;&gt;4.9.5 上下文相关的含义结构。&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;使用定制训练的嵌入模型的一个优点是它将捕获上下文相关的含义结构&lt;/strong&gt;。例如，&lt;em&gt;&lt;strong&gt;“甜”&lt;/strong&gt;&lt;/em&gt; 的含义在软件团队的背景下与 &lt;em&gt;&lt;strong&gt;烹饪&lt;/strong&gt;&lt;/em&gt; 的背景下会有所不同。正如&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B105&#34;&gt;Lix 等人。（2022）&lt;/a&gt;指出，在软件团队的背景下，与 &lt;em&gt;&lt;strong&gt;“甜蜜”&lt;/strong&gt;&lt;/em&gt; 最接近的术语是 &lt;em&gt;&lt;strong&gt;“强烈”&lt;/strong&gt;&lt;/em&gt;、 &lt;em&gt;&lt;strong&gt;“兴奋”&lt;/strong&gt;&lt;/em&gt; 和 &lt;em&gt;&lt;strong&gt;“耶”&lt;/strong&gt;&lt;/em&gt;。此外，就同一个单词编码不同概念（一词多义）而言，单词每种含义的概念信息都位于单词嵌入内的线性叠加（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B5&#34;&gt;Arora et al. 2018&lt;/a&gt;）。这意味着编码诸如 &lt;em&gt;&lt;strong&gt;“Bank”&lt;/strong&gt;&lt;/em&gt; 之类的单词的&lt;em&gt;n&lt;/em&gt;维向量包含其代表的所有概念的概念信息，例如 &lt;em&gt;&lt;strong&gt;河边&lt;/strong&gt;&lt;/em&gt; 或 &lt;em&gt;&lt;strong&gt;金融机构&lt;/strong&gt;&lt;/em&gt;。通过这种方式，即使在多义词的情况下，单词的上下文相关含义也会被编码到模型中。当这些上下文相关的含义不仅不同，而且是排他的或相反的时，来自转换器的上下文相关嵌入可以为上下文中的每个单词呈现不同的单词向量。&lt;/p&gt;
&lt;br&gt;
&lt;h4 id=&#34;496-几何有助于概念人群体和组织的细粒度表示&#34;&gt;4.9.6 几何有助于概念、人、群体和组织的细粒度表示。&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;我们认为，词嵌入模型可以在训练的语料库范围内产生人类活动概念空间的细粒度表示&lt;/strong&gt;。&lt;strong&gt;这意味着，从概念空间内编码的信息中，我们可以恢复个人、群体和组织本身的细粒度表示&lt;/strong&gt;。以我们的创新案例为例，&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#F1&#34;&gt;图 1&lt;/a&gt;描述了在说明性二维空间中这是如何实现的。学习到的概念空间将由单词或短语w表示的概念作为其最原子的分析级别。我们的限制性示例显示了在2维空间中排列的九个单词。单词 1-3 由发明人 1 使用，单词 4-6 由发明人 2 使用，单词 7-9 由发明人 3 使用。&lt;strong&gt;通过获取每个人的单词向量的质心向量，我们可以得出每个发明人在创新的概念空间&lt;/strong&gt;。&lt;strong&gt;将这个过程提升到团队和组织级别，我们可以在发明人团队和组织的概念空间内得出独特的向量&lt;/strong&gt;。因此，词嵌入架构不仅在概念的最原子级别上是细粒度的，而且还可以在更聚合级别上提供细粒度的表示。相对于团队多样性、组织差异化和注意力等结构的粗粒度代理，这形成了显着的测量改进，这些结构在嵌入特定概念空间时是有意义的。&lt;/p&gt;
&lt;br&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/figure-1.jpeg&#34; alt=&#34;&#34;  /&gt;
&lt;strong&gt;图 1.嵌入作为概念、人员、群体和组织的细粒度表示&lt;/strong&gt;&lt;/p&gt;
&lt;br&gt;
&lt;h4 id=&#34;497-细粒度几何减少了上下文信息的丢失&#34;&gt;4.9.7 细粒度几何减少了上下文信息的丢失。&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;由于粗糙、粗粒度的代理指标无法承载相关信息，在实证分析和相关理论构建中就无法利用这些信息&lt;/strong&gt;。嵌入模型的优势在于其独特的信息表征，可以携带更多的信息，信息的粒度更小，保存的信息量更多。&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#F2&#34;&gt;图 2&lt;/a&gt;使用团队多样性的示例来说明如何实现这一点。&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#F2&#34;&gt;图 2(a)&lt;/a&gt;显示了两个团队，1 和 2，每个团队要么通过熵（一种标准的、集合论多样性的理论度量（顶行））来表示，要么通过概念广度（基于底层概念的细粒度度量）来表示。团队调动的信息（底行）。团队 1 和团队 2 都有四名成员，团队 1 由两名生物化学家、一名化学家和一名分析化学家组成，团队 2 由两名生物化学家、一名海洋学家和一名计算机科学家组成。&lt;strong&gt;由于两个团队的团队成员类型比例相同，因此它们都被编码为具有相同的团队多样性熵度量 1.5&lt;/strong&gt;。**然而，当考虑团队成员的概念信息时，我们发现它们是本质上不同类型的团队，团队 1 的多样性或概念范围远不如团队 2 **。这表明粗粒度的测量可能会留下未开发的有价值的上下文信息（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B187&#34;&gt;Wolpert et al. 2014&lt;/a&gt;，&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B33&#34;&gt;DeDeo 2017&lt;/a&gt;）。因此，我们应该看到更细粒度的衡量标准与相关的、理论上的绩效结果之间的联系更加紧密和一致。&lt;/p&gt;
&lt;br&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/figure-2.jpeg&#34; alt=&#34;&#34;  /&gt;
&lt;strong&gt;图 2.（在线彩色)细粒度表示可防止有价值的信息丢失&lt;/strong&gt;&lt;/p&gt;
&lt;br&gt;
&lt;p&gt;专利数据集使我们能够通过三种构建的措施来说明这一主张。首先，集合论团队多样性度量，使用团队先前专利在专利主要类别中的分布（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B79&#34;&gt;Huo 等人，2019&lt;/a&gt;）。第二种替代措施使用专利子类，以便它们提供相对于第一种更细粒度的措施。第三个衡量标准依赖于团队成员先前专利在创新概念空间内的&lt;strong&gt;概念广度&lt;/strong&gt;。&lt;/p&gt;
&lt;br&gt;
&lt;h4 id=&#34;498-词嵌入的局限&#34;&gt;4.9.8 词嵌入的局限。&lt;/h4&gt;
&lt;p&gt;到目前为止，我们的注意力仅限于讨论嵌入模型的结构，描述它们与概念空间的关系，并注意到它们的优点。在这里我们将说明其局限性，讨论它们的严重性、改善方式，以及何时不要用词嵌入的意外情况。我们讨论三类限制。第一个源于神经网络模型一般复杂的“黑匣子”性质，以及这带来的具体挑战，涉及输入数据的偏差，以及模型正确推理的范围，特别是那些对超出分析师背景的数据进行预训练的模型。第二个与这些模型的大小以及训练它们所需的数据量有关。第三个问题涉及词嵌入模型的具体局限性以及从脱离韵律和表达上下文的文本数据中分析含义的挑战。&lt;/p&gt;
&lt;p&gt;许多学者首先担心的是，多级神经网络模型显得复杂且在统计上难以理解，&lt;strong&gt;经常被批评为“黑匣子”方法&lt;/strong&gt;，无法“打开”以询问其性能背后的机制（Knight 2017，Leavitt et &lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B86&#34;&gt;al&lt;/a&gt; . &lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B95&#34;&gt;2021&lt;/a&gt;） 。现代神经网络词嵌入模型通常作为自监督模型实现，该模型启发式搜索单词之间的依赖关系空间以预测屏蔽词的身份。&lt;strong&gt;自从第一个高性能嵌入发布（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B115&#34;&gt;Mikolov 等人，2013b&lt;/a&gt;）以来，对其黑盒性质的一些担忧已经减弱，因为数学家发现最流行的“浅”词嵌入模型（如 Word2Vec 和 FastText）获得了很大的优势&lt;/strong&gt;。其强大功能来自于近似易于理解的矩阵分解方法的运算，例如因子分析、主成分分析和对应分析（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B100&#34;&gt;Levy 和 Goldberg 2014&lt;/a&gt;）。&lt;/p&gt;
&lt;p&gt;“黑盒”输入输出方法带来的一个相关潜在限制是，&lt;strong&gt;输入的偏差将转化为输出中的偏差&lt;/strong&gt;——用于训练嵌入的语料库的偏差将被编码在生成的单词嵌入模型中（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B14&#34;&gt;Bolukbasi等人，2016&lt;/a&gt;）。当模型用于现实世界的下游应用程序（例如推荐服务）时，这可能是有害的。例如，硬编码到嵌入中的种族和性别刻板印象可能会导致有偏见的建议（例如，评估是否适合招聘职位或预测财务违约的可能性），并导致不公平和不道德的决定（例如，拒绝工作或信贷） 。学者们应该根据他们的研究问题和设计，主动考虑这种负外部性是否可能，并在对人类造成伤害的可能性足够高时，偶然放弃嵌入。&lt;strong&gt;然而，在某种程度上，理解社区和研究背景中概念关联的本质是核心，研究人员将需要这些偏见进行分析。如果不包括它们，模型以及研究设计就会错过表征其研究背景的关键社会和文化规律。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;如果分析人员对生成语料库的上下文没有清晰的了解，就会出现另一个相关的限制，这样他们最终可能会做出不适用和不相关的推论&lt;/strong&gt;。例如，强调意义随时间变化的研究（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B19&#34;&gt;Caliskan et al. 2017&lt;/a&gt;、&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B49&#34;&gt;Garg et al. 2018&lt;/a&gt;、&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B89&#34;&gt;Kozlowski et al. 2019&lt;/a&gt;）的特点是词义表现出来自外源冲击的间断变化，从而重新配置了概念关联的结构。穿过空间。想一想 2005 年卡特里娜飓风之后“卡特里娜”的含义发生了怎样的变化。2009 年金融危机之后，金融术语的含义发生了重新配置，部分原因是添加了“问题资产救助计划”等许多新术语。忽略外源冲击可能会导致对后面和验证部分中描述的措施的错误解释，将其视为仅由进化产生的结果，从而导致错误的推论。这是一个特别成问题的问题，因为许多最准确的词嵌入模型都是在从网络上提取的大量文本语料库上进行预训练的。此类模型可用于引导非常小的文本数据之间的有意义距离，这是一项常见任务，但&lt;strong&gt;如果预训练数据是异构的，则距离可能无法反映焦点文本的概念世界&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;接下来的两个限制必然是其嵌入优势的另一面。词嵌入模型产生的细粒度信息会带来特定研究可能或可能无法维持的成本。首先是模型尺寸。&lt;strong&gt;每个单词的数百个维度的细粒度信息或上下文嵌入需要比简单的字典计数或潜在狄利克雷分配主题模型更大的存储空间&lt;/strong&gt;。这与通常用于将数据维度减少到两个或三个的因子和主成分分析形成鲜明对比。词嵌入模型使用更多维度（通常为 200-500）来更准确地预测数据的屏蔽部分。尽管如此，当前个人计算机的计算能力和存储能力现在允许训练合理大小的嵌入。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;与此相关的是，词嵌入模型需要比先前模型更多的文本才能稳健地估计概念空间&lt;/strong&gt;。当大型语料库与研究主题相似并且可以用作理论相关文档或微调过程的初始化的代理时，可以通过迁移学习来弥补这一挑战。&lt;strong&gt;然而，有时相关语言在内容、目的或形式上与模型预训练的数据有很大不同，它需要独立建模，但又足够小，无法维持对嵌入模型的稳健估计。在这种情况下，使用字典计数或主题模型可能会更好，因为数据只能维持粗粒度的关联，而这些方法旨在捕获粗粒度的关联。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;最后一类通常涉及词嵌入和文本方法的特殊限制。首先，静态词嵌入本身并不处理一词多义，即一个词（例如 &lt;em&gt;&lt;strong&gt;“bank”&lt;/strong&gt;&lt;/em&gt; ）编码多个概念（例如金融机构、河边、侧向倾斜）的情况。尽管多义词的存在可能会影响后续一些指标的测量，但也存在抵消的力量。一方面，研究发现多义词的含义以相互线性叠加的方式编码在单词向量内（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B5&#34;&gt;Arora et al. 2018&lt;/a&gt;）。这意味着该算法通过同时考虑单词的所有含义来对单词在概念空间中的位置进行编码，从而克服了原本可能存在的严重缺陷。另一方面，上下文嵌入架构（在线附录中有更详细的描述）通过根据焦点词周围的上下文输出不同的向量来明确解决多义词的问题。每个单词不是单个向量，而是根据用途而变化的向量云。如果分析师怀疑一词多义可能是特定分析的严重问题，他们可以偶然使用上下文嵌入并规避这种担忧。&lt;/p&gt;
&lt;p&gt;最后一个潜在的限制是文本方法的一般特征。只要文本数据是转录语音话语的产物（例如，欧洲央行或美联储主席演讲、政治演讲、财报电话会议、电视或电影文字记录、对话互动），语音的语调、语气和音色将没有纳入到嵌入表示中。考虑到。&lt;strong&gt;鉴于某些语言（例如中文）更严重地依赖语调来传达含义，这可能或多或少存在问题，具体取决于话语发生的社会背景及其表达语言&lt;/strong&gt;。因此，在语调和语气在语料库中发挥重要作用的情况下，学者们应该讨论他们的嵌入模型选择和解释决策的后果。&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;410-在研究中使用词嵌入模型的路线图&#34;&gt;4.10 在研究中使用词嵌入模型的路线图&lt;/h3&gt;
&lt;p&gt;现在我们大脑对词嵌入模型是什么、如何表示概念空间、如何训练、优点和局限性有了框架性的认知，接下来可以将它们整合到研究和理论构建的标准方法中。&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#T1&#34;&gt;表 1&lt;/a&gt;列出了如何将嵌入模型集成到科学流程中的路线图。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;步骤 1-3 是研究过程中的标准步骤，包括确定一个可行且有趣的研究问题，通过在适当的实证背景下进行评估，为重要的理论问题提供信息（Weick 1989 &lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B179&#34;&gt;）&lt;/a&gt;。&lt;/li&gt;
&lt;li&gt;步骤 4-9 总结了本文到目前为止对嵌入模型的讨论。&lt;/li&gt;
&lt;li&gt;步骤 10 和 11 ，与下一节指标度量有关，通过标准定量和定性方法调动该度量。&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
&lt;p&gt;&lt;strong&gt;表 1.在研究中使用词嵌入模型的路线图&lt;/strong&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;步骤&lt;/th&gt;
&lt;th&gt;活动&lt;/th&gt;
&lt;th&gt;基本原理&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;1. &lt;strong&gt;确定研究问题&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;如果研究问题至关重要，请确定文本数据是否有助于在理论研究上有帮助。&lt;/td&gt;
&lt;td&gt;吸引研究人员把注意力聚焦在理论问题、词嵌入构建研究构念回答问题的交叉点。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2. &lt;strong&gt;理论建立及相关理论构建&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;确定使用哪种理论框架来解决研究问题以及通过嵌入模型来操作哪种理论构念。&lt;/td&gt;
&lt;td&gt;理论构念与其词嵌入指标(构念的衡量）之间的紧密联系能够实现累积的理论发展。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;3. &lt;strong&gt;定义经验背景&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;选择适当的实证背景，在其中回答研究问题并动员理论框架和构念。&lt;/td&gt;
&lt;td&gt;确保研究问题、理论框架和用构念以逻辑方式相互加强。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;4.&lt;strong&gt;指定将用于表示经验背景的概念空间的文本数据&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;描述将用于训练词嵌入模型和测量感兴趣的理论构念的文本数据的范围。 数据是否有效地涵盖了您想要得出理论结论的经验背景下的行为活动范围？&lt;/td&gt;
&lt;td&gt;确保用于计算理论构造度量的词嵌入模型在逻辑上映射到并有效地代表所提出的理论框架内的实证研究背景。 文本数据的范围应该在逻辑上映射到所讲述的理论故事的范围。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;5.&lt;strong&gt;确定文本数据的大小和范围&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;数据是否足够大以学习相关概念空间的准确表示？&lt;/td&gt;
&lt;td&gt;文本数据的大小将决定是否应该训练自定义嵌入，或者是否应该使用可用数据对现成的嵌入进行微调。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;6. &lt;strong&gt;给定数据大小，要么训练独特的词嵌入模型，要么微调现有模型&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;如果文本数据足够大，则训练自定义嵌入来表示感兴趣的经验上下文的概念空间。 如果文本数据不够大，请使用这些数据来微调现有的现成嵌入模型。&lt;/td&gt;
&lt;td&gt;确保用于测量理论结构的嵌入模型能够有效地表示经验背景的相关概念空间。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;7. &lt;strong&gt;如果训练独特的模型，请选择一种算法&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;在连续词袋 (CBOW) 或 Skip-Gram 模型之间进行选择。&lt;/td&gt;
&lt;td&gt;CBOW：在较小的数据集上可以有更好的性能。 &lt;br&gt;Skip-gram：可以更好地捕获语义。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;8. &lt;strong&gt;如果训练独特的模型，确定相关参数&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;选择窗口大小和维数。&lt;/td&gt;
&lt;td&gt;窗口大小：标准做法是 5。较小的窗口可以更大程度地捕获语法，较大的窗口可以更大程度地捕获语义，但收益递减并增加计算成本。 维度数：标准做法是 300，超过此点后性能回报递减。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;9. &lt;strong&gt;验证词嵌入模型&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;请遵循在线附录中的验证程序。&lt;/td&gt;
&lt;td&gt;确认嵌入模型准确有效地表示了经验背景的概念空间。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;10. &lt;strong&gt;计算相关度量&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;通过确定将用于实施感兴趣的理论构念的相关概念集，创建“实际措施和应用”部分中的措施之一。&lt;/td&gt;
&lt;td&gt;使学者能够将该测量用于定量或定性分析。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;11. &lt;strong&gt;在标准定性或定量方法中使用计算的度量&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;对于定量分析，该度量要么成为自变量，要么成为因变量。 对于定性分析，学者可以提供解释性分析，因为它们可能适用于其他类型的档案、民族志或视听数据。&lt;/td&gt;
&lt;td&gt;嵌入模型表示对生成数据的社会背景的概念空间的描述。&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;五实际措施与应用&#34;&gt;五、实际措施与应用&lt;/h2&gt;
&lt;p&gt;现在已经正式定义了 &lt;strong&gt;概念&lt;/strong&gt; 和 &lt;strong&gt;概念空间&lt;/strong&gt; 的含义，并说明了先前的文献如何处理概念信息,  介绍了嵌入模型表示能力的底层逻辑，并在在线附录中完成了支持这种直觉的几个验证步骤。也评论了嵌入模型给概念信息分析带来的几个优点和相关缺点。&lt;/p&gt;
&lt;p&gt;在本章中，我们将介绍一些新研究， 学习他们如何用嵌入生成独特指标。&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#T2&#34;&gt;表 2&lt;/a&gt;总结了这些指标及示例应用。&lt;/p&gt;
&lt;br&gt;
&lt;p&gt;&lt;strong&gt;表 2.词嵌入测量和示例应用&lt;/strong&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;措施&lt;/th&gt;
&lt;th&gt;研究性学习&lt;/th&gt;
&lt;th&gt;关键构念&lt;/th&gt;
&lt;th&gt;研究问题&lt;/th&gt;
&lt;th&gt;代表性调查结果&lt;/th&gt;
&lt;th&gt;嵌入在这种情况下的优点&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;1. &lt;strong&gt;概念广度&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B105&#34;&gt;利克斯等人。(2022)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;话语多样性——在一组给定的互动中，群体成员所传达的含义彼此分歧的程度。&lt;/td&gt;
&lt;td&gt;一个群体的话语多样性如何影响其绩效？&lt;/td&gt;
&lt;td&gt;高绩效团队会调整他们的共享认知以匹配任务的要求（例如，构思与协调）。&lt;/td&gt;
&lt;td&gt;能够随着时间的推移以细粒度的细节和动态地追踪小组对话的概念广度，使学者们能够追踪话语多样性的新理论构造。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2.&lt;strong&gt;概念距离和相似度&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B74&#34;&gt;霍夫斯特拉等人。(2020)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;语义遥远的科学新颖性：博士论文中新链接概念的语义距离。&lt;/td&gt;
&lt;td&gt;代表性不足的群体是否更有可能产生科学创新？&lt;/td&gt;
&lt;td&gt;相对于男性，女性引入了更遥远的新奇事物。 然而，这种语义上遥远的新颖性在该学科中很少受到关注。&lt;/td&gt;
&lt;td&gt;能够追踪新概念组合的概念距离，使学者不仅可以研究是否做出了新组合，还可以研究这些组合的语义距离最终如何影响其影响。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;3.&lt;strong&gt;概念X性&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B94&#34;&gt;劳森等人。(2022)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;性别刻板印象：男性（而非女性）与以成就为导向的代理特征（例如自信和果断）相关的程度。&lt;/td&gt;
&lt;td&gt;雇用女性首席执行官和董事会成员是否与组织对代理语言的性别使用发生变化有关？&lt;/td&gt;
&lt;td&gt;当组织雇用女性首席执行官和董事会成员时，女性的语义与代理的语义变得更加一致。&lt;/td&gt;
&lt;td&gt;对 22 家标准普尔 500 强公司的 43,000 多份文件（包含超过 12 亿字）进行分析，深入细致地研究女性的含义如何因聘用女性领导者而发生变化。否则这样的分析是不可能的。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;4.概念意义&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B63&#34;&gt;汉密尔顿等人。(2016)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;词语的文化意义：词语的含义随时间变化的程度。&lt;/td&gt;
&lt;td&gt;语义演化的可能驱动因素是什么？&lt;/td&gt;
&lt;td&gt;跨历史时期的语义变化率与词频的逆幂律成正比。 与频率无关，具有更多含义的单词具有更高的语义变化率。&lt;/td&gt;
&lt;td&gt;能够探索跨多个知识和文化领域的大型历史时期和大量文本中的语义变化。例如，他们可以详细追踪同性恋这个词的含义如何从&lt;em&gt;快乐&lt;/em&gt;和&lt;em&gt;艳丽&lt;/em&gt;等概念转向&lt;em&gt;同性恋&lt;/em&gt;和&lt;em&gt;女同性恋&lt;/em&gt;等概念。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;5. &lt;strong&gt;文化和知识连续体中的概念立场&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B89&#34;&gt;科兹洛夫斯基等人。(2019)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;社会阶层标记：区分社会阶层维度的概念。&lt;/td&gt;
&lt;td&gt;20世纪社会阶级的标志是如何变化的？&lt;/td&gt;
&lt;td&gt;尽管社会阶级维度在历史上保持稳定，但阶级文化标记在每个维度中的定位方式却不断发生变化（例如，员工从士兵和肌肉等概念转变&lt;em&gt;为&lt;/em&gt;白领&lt;em&gt;和&lt;/em&gt;中产阶级&lt;em&gt;等&lt;/em&gt;概念*）*。&lt;/td&gt;
&lt;td&gt;能够将文化相关的概念投射到文化相关的兴趣连续体上，从而使研究人员不仅可以在单个历史时期内而且可以在其历史演变过程中了解广泛共享的社会关联。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;6. &lt;strong&gt;概念维度&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B89&#34;&gt;科兹洛夫斯基等人。(2019)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;阶级的文化维度：理解社会阶级的维度（富裕、教育、修养、地位、就业、道德、性别）&lt;/td&gt;
&lt;td&gt;20 世纪文化阶层的规模有多稳定？&lt;/td&gt;
&lt;td&gt;20世纪，尽管发生了巨大的经济转型，阶级规模仍然非常稳定。&lt;/td&gt;
&lt;td&gt;能够对阶级的多个概念维度进行实证分析，从而理解 20 世纪美国它们之间的相互关系。&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;br&gt;
&lt;h3 id=&#34;51-概念广度&#34;&gt;5.1 概念广度&lt;/h3&gt;
&lt;h4 id=&#34;511-指标&#34;&gt;5.1.1 指标&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;可以测量文档中单词之间的距离来计算它们在概念空间中的分布范围&lt;/strong&gt;。文档可以是从专利到个人电子邮件通信的任何内容。我们可以测量每个单词与其他单词的平均距离有多远。&lt;strong&gt;获取文档内元素的平均距离（或每个单词与文档质心之间的距离）可以衡量该文档内的「概念宽度」&lt;/strong&gt;。例如，我们衡量每项专利的概念广度， 可以从两个简单的文档开始，&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;doc1 =  [&amp;#34;biochemistry&amp;#34;, &amp;#34;chemistry&amp;#34;, &amp;#34;analytical_chemistry&amp;#34;]
doc2 =  [&amp;#34;chemistry&amp;#34;, &amp;#34;oceanography&amp;#34;, &amp;#34;computer&amp;#34;]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;使用我们的专利嵌入模型，我们得到第一组(doc1)的平均宽度为 29，第二组（doc2）平均宽度为 47。这表明第二组在概念上比第一组更广泛。&lt;/p&gt;
&lt;p&gt;当我们衡量文档集合而不是单词的概念广度时，同样的逻辑也适用。例如，我们想了解发明者团队的广度。在这种情况下，我们可以将团队中的每个发明人视为嵌入概念空间中的“文档”，参考如图&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#F1&#34;&gt;1&lt;/a&gt; , 从下往上，依次是词概念空间、发明人概念空间、团队概念空间、组织概念空间。一个发明人团队的成员已经在涉及纳米技术、生物技术和软件的概念空间领域发表了先前的专利，那么在概念上将被认为比所有成员只发表了纳米技术专利的团队更广泛。即使所有发明人都将其公开的专利限制在一个类别内，该指标仍然会提供显着的变化。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/figure-1.jpeg&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;h4 id=&#34;512--应用&#34;&gt;5.1.2  应用&lt;/h4&gt;
&lt;p&gt;这种概念广度的度量已在最近的工作中用于追踪各种理论构念。&lt;strong&gt;&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B105&#34;&gt;利克斯等人。(2022)&lt;/a&gt;衡量团队成员在参与软件项目的不同阶段时的 话语广度&lt;/strong&gt;。&lt;strong&gt;他们能够追踪每个独特项目阶段概念参与的多样性，发现表现最好的团队有能力改变他们的认知以适应手头不断变化的任务，在提出新想法时表现出更大的话语广度，而在转换时表现出较低的广度依赖于协调的任务。这种细粒度的知识参与概念很难用以前的文本分析方法来追踪&lt;/strong&gt;。 详细内容可阅读大邓近期推文 &lt;a href=&#34;https://textdata.cn/blog/2023-11-02-measure-cognitive-diversity-through-language-discursive-diversity/&#34;&gt;MS2022 | 使用语言差异性测量团队认知差异性&lt;/a&gt; 。&lt;/p&gt;
&lt;p&gt;另外，研究人员使用概念广度来追踪在线社区成员根据状态变化分配注意力的范围，发现状态和注意力广度之间存在 U 形关系（Aceves et al. 2022 &lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B2&#34;&gt;）&lt;/a&gt;。这些研究人员训练了 150 个知识领域的概念空间，从而能够追踪不同知识领域的相似注意力动态，从计算机编程和数学到育儿和园艺。由于他们有能力在数百个社区的文本中大规模部署算法，因此他们能够计算出超过 2000 万成员如何在这些问答社区上发布的 2300 万个问题中分配注意力。&lt;/p&gt;
&lt;p&gt;其他工作在整个语言中实施了这种方法，追踪语言在所有知识领域具有更宽或更窄的概念空间的程度（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B1&#34;&gt;Aceves 和 Evans 2021&lt;/a&gt;）。使用圣经、电影字幕和以多种语言编写的政治文件等文本的并行翻译（包含相同的信息但以不同的语言编码），他们能够追踪概念在不同语言中相互关联的程度存在显着差异。他们发现，尽管一些语言将不同的概念子空间紧密地联系在一起，并将不同的概念领域编织在一起，但其他语言却稀疏且更加支离破碎，更强烈地分隔了不同的意义域。然后，他们观察概念空间的语言密度如何塑造数百种语言的真实对话和维基百科文章的概念广度。&lt;/p&gt;
&lt;p&gt;所有三篇论文都为不同文献的研究开辟了新的理论途径，例证了该方法的潜力。如果没有概念空间的概念及其通过嵌入模型的表示，这些新的研究途径将很难实施。&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;52-概念距离和相似度&#34;&gt;5.2 概念距离和相似度&lt;/h3&gt;
&lt;h4 id=&#34;521-指标&#34;&gt;5.2.1 指标&lt;/h4&gt;
&lt;p&gt;当我们的分析重点在于集合内的元素时，前面描述的概念广度构念是相关的。当我们的分析重点是不同集合之间的关系时，可以使用相同的基础度量。在这种情况下，我们将指的是概念距离或相似性，而不是概念广度。&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#fn14&#34;&gt;13&lt;/a&gt;形式上，如果我们有至少两个集合，每个集合中至少有一个元素，我们可以计算这些集合之间的&lt;strong&gt;概念距离，作为每个集合的质心或多维平均值之间的距离&lt;/strong&gt;。最基本的是，我们可以计算两个集合之间的概念距离，每个集合包含一个单词。这无非是衡量这些词之间的概念距离。随着元素数量和集合数量的增加，底层计算保持不变，但理论可能性的范围扩大。还可以通过训练文档嵌入模型来计算这种距离/相似性度量，该模型在嵌入空间中为每个文档分配一个向量，其权重按照单词共现的相同逻辑进行训练（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B96&#34;&gt;Le 和 Mikolov 2014&lt;/a&gt;），将文档本身视为文档中的另一个单词，将这些单词用作与其共现的单词。&lt;/p&gt;
&lt;p&gt;通过将概念相似性与衡量专利相似性的现有技术进行比较，我们可以一睹该衡量标准的潜力。首先，研究人员可以通过查看专利授予机构使用的官方分类来追踪专利的相似性，同一类别的专利被认为比不同类别的专利更相似（Singh 和 Marx 2013，Aharonson 和&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B157&#34;&gt;Schilling&lt;/a&gt; 2016 &lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B3&#34;&gt;）&lt;/a&gt;）。这种方法的局限性在于分类度量是粗粒度的，并且不太可能考虑所有相关的技术特征，特别是当类别边界必然滞后于技术进化时（Thompson 和 Melanie Fox-Kean 2005，Singh&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B172&#34;&gt;和&lt;/a&gt;Agrawal &lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B155&#34;&gt;2011&lt;/a&gt;，&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B7&#34;&gt;Arts 等人，2018&lt;/a&gt;）。其次，研究人员可以获取两项专利并测量它们之间的单词重叠（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B7&#34;&gt;Arts et al. 2018&lt;/a&gt;）。然而，这种方法是有限的，因为它仅适用于成对的文档，无法确定专利相对于整个知识体系的位置。&lt;/p&gt;
&lt;p&gt;概念相似性解决了这些限制（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B184&#34;&gt;Whalen 等人，2020&lt;/a&gt;）。首先，它允许我们追踪专利在相关知识空间中的精确位置，从而访问知识系统中的所有相关的细粒度信息。其次，我们能够精确量化任何专利或专利组相对于任何其他专利或专利组的位置。&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#fn15&#34;&gt;14&lt;/a&gt;第三，随着新知识进入系统，知识的性质和结构不断演变，随着时间的推移重塑 &lt;strong&gt;概念边界&lt;/strong&gt; 和关联。&lt;strong&gt;嵌入使我们能够衡量专利发布时存在的概念空间内的专利相似性，使我们能够摆脱使用滞后的、周期性偏离的类别，并可能对连续的发明概念空间强加类别差异&lt;/strong&gt;。概念距离的所有这些优点都适用于其他知识和文化领域，在这些领域中，我们寻求测量思想、个人、群体或组织之间的距离或相似性，从而扩展现有的跨研究领域并开辟新的理论领域。&lt;/p&gt;
&lt;h4 id=&#34;522-应用&#34;&gt;5.2.2 应用&lt;/h4&gt;
&lt;p&gt;正如我们上面所做的那样，这种&lt;strong&gt;概念相似性的衡量方法最近被用来描述专利数据中的创新空间&lt;/strong&gt;（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B184&#34;&gt;Whalen 等人，2020&lt;/a&gt;）。研究人员使用  &lt;strong&gt;doc2vec&lt;/strong&gt;  框架计算了超过 6 亿个专利对的相似度。在生成这些知识相似性度量时，作者还使用这些分数提出了有趣的辅助度量，包括可操作的度量（a）现有技术接近度——专利引用与其自身相似或不相似的现有技术的程度，（b）现有技术同质性——一项专利引用知识空间领域彼此远离的程度，(c) 影响邻近性——一项专利被与其自身相似或不相似的未来专利引用的程度，以及(d) 影响同质性——一项专利通过其前向引用与一组不同的未来专利相关的程度。&lt;/p&gt;
&lt;p&gt;学者们也使用了这一衡量标准，重点关注概念距离。&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B18&#34;&gt;伯奇等人。(2021)&lt;/a&gt;使用概念距离的 &lt;strong&gt;doc2vec&lt;/strong&gt; 实现来调查同行奖励是否会影响在线社区内贡献的新颖性。这里的&lt;strong&gt;新颖性是根据社区成员获奖前后贡献的距离来衡量的&lt;/strong&gt;。作者发现，获奖后，奖项会导致知识空间内的新颖性减少，剥削行为增多。同样，&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B74&#34;&gt;霍夫斯特拉等人。（2020）&lt;/a&gt;使用 Word2Vec 距离度量来捕获科学论文将新颖性引入科学文献的程度，发现来自代表性不足群体的学生负责将最具新颖性引入系统。&lt;/p&gt;
&lt;p&gt;其他人则利用这一措施来实施公司差异化。在发展中国家微型企业的背景下，&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B20&#34;&gt;Carlson（2022）&lt;/a&gt;使用 BERT 架构（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B35&#34;&gt;Devlin et al. 2019&lt;/a&gt;，&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B142&#34;&gt;Reimers and Gurevych 2020&lt;/a&gt;）来计算其数据集中所有微型企业的成对余弦距离。通过这些距离，他们能够估计八个发展中国家的 10,000 家微型企业的差异化与收入和利润的增加相关。同样，&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B61&#34;&gt;Guzman 和 Li（2023）&lt;/a&gt;使用距离的 doc2vec 实现来使用 Crunchbase 数据来衡量初创公司的创始战略差异化。作者发现与&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B20&#34;&gt;Carlson (2022)&lt;/a&gt;类似的结果，即差异化经验的新公司在早期融资和股权结果方面有所增加。&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;53-概念x&#34;&gt;5.3 概念X&lt;/h3&gt;
&lt;h4 id=&#34;531-指标&#34;&gt;5.3.1 指标&lt;/h4&gt;
&lt;p&gt;文档距离的另一个用途是追踪语料库中的任何文档与捕获感兴趣的构念X的焦点(原型）的相似性， 这样的测量将捕获任何观察的 &lt;strong&gt;概念X性&lt;/strong&gt;( Conceptual X-ness)。这种测量的第一步是描述与我们寻求尽可能精确测量的结构相关的概念信息。例如，如果我们想要捕获专利与 &lt;strong&gt;时间&lt;/strong&gt; 或 &lt;strong&gt;几何&lt;/strong&gt; 等概念相关的程度，我们可以构建一个我们认为映射到、定义或与这些概念相关的单词列表 。对于每个列表，我们计算其质心向量 (c#27)，然后测量任何给定专利距离 &lt;strong&gt;时间&lt;/strong&gt; 和 &lt;strong&gt;几何&lt;/strong&gt; 概念有多远。&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#fn16&#34;&gt;15&lt;/a&gt; 对于附录表 A2 中使用的专利，我们可以看到，与头颈约束装置专利相关的前两项专利更接近时间概念，正如所预期的那样光和时间在概念上交织的程度。概念性的&lt;em&gt;X&lt;/em&gt;度度量可用于追踪思想、个人、团体、组织或任何其他相关聚集的组成。&lt;/p&gt;
&lt;h4 id=&#34;532-应用&#34;&gt;5.3.2 应用&lt;/h4&gt;
&lt;p&gt;最近在一篇论文中使用了这种方法，该论文追踪了雇用女性担任高级领导角色对女性在这些组织中意味着什么的影响（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B94&#34;&gt;Lawson 等人，2022&lt;/a&gt;）。作者首先使用 SEC 文件和财报电话会议记录训练了 Word2Vec 嵌入。然后，他们创建并验证了一组 100 个单词来捕捉 &lt;strong&gt;代理概念&lt;/strong&gt; 的含义（例如，有能力、独立、主导），并观察了内部任命高级女性领导前后 &lt;strong&gt;代理概念&lt;/strong&gt; 与 &lt;strong&gt;女性&lt;/strong&gt; 概念之间的距离。该组织发现，在 &lt;strong&gt;女性&lt;/strong&gt; 被任命为高层管理人员之后的一段时间内，女性的含义在概念空间中更加接近于机构职位。作者使用不同的嵌入超参数和维度大小复制了他们的结果，说明了嵌入模型的鲁棒性，条件是具有捕获概念空间内语义变化的最小必要维度。&lt;/p&gt;
&lt;p&gt;这里有趣的理论机会包括更深入地参与理论传统的可能性，这些理论传统在组织科学以外的领域具有影响力，但由于缺乏可行的方法来以原则性的方式量化其理论构造，因此这些理论传统仍然处于我们的领域之外。依赖文学解释。正如我们所提出的，测量 &lt;strong&gt;概念X性&lt;/strong&gt; 使得扩大与理想形式（* &lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B134&#34;&gt;Plato Bloom 1968&lt;/a&gt;）、理想类型（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B178&#34;&gt;Weber 2011&lt;/a&gt;）、家族相似性（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B186&#34;&gt;Wittgenstein 2010&lt;/a&gt;）和原型（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B147&#34;&gt;Rosch 1973&lt;/a&gt;）相关的理论构造的测量成为可能。以一致、有原则和可复制的方式。在这方面，概念性的&lt;em&gt;X&lt;/em&gt;性代表着开放大量的认知和社会理论，以便在组织的背景下进行实证检验和扩展。&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;54-语义转变和漂移&#34;&gt;5.4 语义转变和漂移&lt;/h3&gt;
&lt;h4 id=&#34;541-指标&#34;&gt;5.4.1 指标&lt;/h4&gt;
&lt;p&gt;概念空间使我们能够识别术语的含义如何随着时间和空间的变化而变化。探索概念意义的一种方法是为不同的个人、公司、行业、地理位置或时间段创建独特的嵌入模型，以了解它们之间的含义有何不同（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B148&#34;&gt;Roy 等人，2019 年&lt;/a&gt;；&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B181&#34;&gt;Welch 等人，2020a&lt;/a&gt;，&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B182&#34;&gt;b&lt;/a&gt;）。一旦识别出相关的兴趣分歧，我们就可以采用相关的语料库（例如，专利、财报电话会议、报纸）并为数据中的每个语料库训练概念空间。&lt;strong&gt;在我们的专利示例中，我们可能会训练两种嵌入模型，一种是 1990 年功能性磁共振成像技术发明之前的时期，另一种是 1990 年之后的时期&lt;/strong&gt;。然后我们可以探索与大脑和神经科学相关的概念的含义如何随着这一创新而改变。例如，在功能性磁共振成像发明之前和之后与不同大脑区域最相关的术语是什么。接下来，我们可以比较不同公司或国家的含义变化有何不同，以及这种变化的格局如何影响所涉及的公司和行业的组织和市场结果。显式动态词嵌入允许嵌入之间具有更大的可比性，但必然会忽略特殊的词和用途（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B63&#34;&gt;Hamilton et al. 2016&lt;/a&gt;、&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B192&#34;&gt;Zhang et al. 2016&lt;/a&gt;、&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B190&#34;&gt;Yao et al. 2018&lt;/a&gt;、&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B103&#34;&gt;Liu et al. 2020&lt;/a&gt;）。这些算法的输出带有时间戳词向量包含特定时期的语义信息，但在历史上保持可比性。&lt;/p&gt;
&lt;br&gt;
&lt;h4 id=&#34;54-2-应用&#34;&gt;5.4. 2 应用&lt;/h4&gt;
&lt;p&gt;第一篇在社会科学背景下使用词嵌入方法的主要论文就是使用这种方法来研究意义（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B63&#34;&gt;Hamilton et al. 2016&lt;/a&gt;、&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B19&#34;&gt;Caliskan et al. 2017&lt;/a&gt;、&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B49&#34;&gt;Garg et al. 2018&lt;/a&gt;、&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B89&#34;&gt;Kozlowski et al. 2019&lt;/a&gt;）。在第一篇论文中，研究人员使用四种语言的六个历史语料库，通过观察概念空间中最近的单词在过去几十年中如何变化来追踪单词含义随时间的变化（Hamilton et al. 2016 &lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B63&#34;&gt;）&lt;/a&gt;。使用 Word2Vec 嵌入，他们追踪了 &lt;strong&gt;同性恋&lt;/strong&gt;  概念的含义如何从 1900 年代围绕 &lt;strong&gt;“愚蠢”&lt;/strong&gt;、**“甜蜜” **和 **“开朗”  **等术语的含义转变为围绕 1950 年代 &lt;strong&gt;“嬉闹”&lt;/strong&gt;、 &lt;strong&gt;“机智”&lt;/strong&gt; 和 &lt;strong&gt;“聪明”&lt;/strong&gt; 等术语的含义，并且最终以 20 世纪 90 年代女同性恋、双性恋和同性恋等术语的含义结束。在另一篇论文中，研究人员研究了词嵌入中的刻板关联之间的关系及其与当代社会经验数据的关系（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B19&#34;&gt;Caliskan et al. 2017&lt;/a&gt;）。例如，他们追踪了职业的性别刻板印象，发现职业具有女性意义，因为它们与女性参与劳动力市场相关。在另一项研究中，&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B49&#34;&gt;Garg 等人。(2018)使用预先训练的 Google News Word2Vec 模型（ &lt;/a&gt;&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B4&#34;&gt;Google 2013&lt;/a&gt; ）量化了美国 100 多年历史中的性别和种族刻板印象，阐明了不同的形容词和职业如何或多或少地与不同人群（例如，男性与女性）密切相关，白人与亚洲人与西班牙裔）随着时间的推移。&lt;/p&gt;
&lt;p&gt;最近通过词嵌入追踪含义的工作已经使用这种方法更深入地研究了特定的上下文。一项研究使用 19 世纪第一人称叙述的语料库来追踪黑人和白人男性和女性的交叉身份如何映射到五个社会机构，包括政治、经济、文化、家庭领域和权威关系（Nelson 2021 &lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B120&#34;&gt;）&lt;/a&gt;。&lt;strong&gt;举论文中的一个例子，作者测量了与“精致”概念的距离，发现它与白人女性的联系最密切，而与黑人男性的联系最少&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;在其他工作中，研究人员利用这种方法来衡量政治领导人的 &lt;strong&gt;集体意向性&lt;/strong&gt; （人们参与集体推理和行动的能力），并比较共和党和民主党领导人如何以不同的方式动员集体意向性（Kirgil and Voyer 2022 &lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B85&#34;&gt;）&lt;/a&gt;。他们通过创建复数代词（我们，我们的）、复数常量（国家名称）和复数名词（人）的复合列表来测量集体意向性。然后，使用词嵌入模型，他们找到了各州集体意向向量最接近的术语，使他们能够比较不同领导人如何不同地动员集体意向。总的来说，这些意义研究表明，就语言为我们提供了解文化的窗口而言（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B55&#34;&gt;Goldberg et al. 2016&lt;/a&gt;、&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B165&#34;&gt;Srivastava et al. 2018&lt;/a&gt;、&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B26&#34;&gt;Corritore et al. 2020&lt;/a&gt;），嵌入模型为我们提供了一种独特的表达方式透过那扇窗户看到的照片。&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;55-文化和知识连续性中的概念地位&#34;&gt;5.5 文化和知识连续性中的概念地位&lt;/h3&gt;
&lt;h4 id=&#34;551-指标&#34;&gt;5.5.1 指标&lt;/h4&gt;
&lt;p&gt;另一种新颖的测量方法可以通过追踪概念相对于感兴趣的概念维度的位置来创建。如前所述，嵌入模型可用于解决类比推理任务，例如**“国王”-“男人”+“女人”=“女王”&lt;strong&gt;。 该架构可用于定义概念空间内任何感兴趣的维度。&lt;strong&gt;在国王-王后的例子中，性别维度通过“男人”-“女人”和“国王”-“女王”向量进行操作。&lt;/strong&gt;&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B89&#34;&gt;科兹洛夫斯基等人。（2019）&lt;/a&gt;详细介绍了如何在概念空间内构建此类维度。首先，研究人员需要确定感兴趣的维度。对于我们这里的例子，我们将把不同的概念投射到男性-女性性别维度上。为此&lt;/strong&gt;，我们首先确定定义性别维度的相关术语**。这里我们使用集合 [&amp;lsquo;man&amp;rsquo;, &amp;lsquo;him&amp;rsquo;, &amp;lsquo;he&amp;rsquo;, &amp;lsquo;male&amp;rsquo;, &amp;lsquo;men&amp;rsquo;] 和 [&amp;lsquo;woman&amp;rsquo;, &amp;lsquo;her&amp;rsquo;, &amp;lsquo;she&amp;rsquo;, &amp;lsquo;female&amp;rsquo;, &amp;lsquo;women&amp;rsquo;]。 &lt;strong&gt;然后我们计算不同概念在这个男性-女性概念轴(维度)上的正交投影。&lt;/strong&gt; 在线附录中的图 A4 将每个概念投射到 &lt;strong&gt;男性-女性概念轴&lt;/strong&gt;。 更消极的预测表明与女性气质的关联更强，而更积极的预测表明与男性气质的相关性相当。如图 A4 所示，这些预测与关于这些概念的性别状态的一般直觉一致，使我们能够明确说明每个概念相对于其他概念在这个维度中的位置。正如预期的那样，&lt;strong&gt;军事&lt;/strong&gt; 和 &lt;strong&gt;农业&lt;/strong&gt; 与 &lt;strong&gt;男性气质&lt;/strong&gt; 的联系最为密切，而 &lt;strong&gt;卫生棉条&lt;/strong&gt; 和 &lt;strong&gt;口红则&lt;/strong&gt; 与 女性气质的联系最为密切。按照这个程序，学者们现在可以测量任何概念在任何感兴趣的维度和任何文本丰富的时空背景中的位置。此外，不同语言的语料库可以独立训练和对齐，或者同时训练和对齐，以方便国际分析（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B81&#34;&gt;Johnson et al. 2017&lt;/a&gt;，&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B116&#34;&gt;Milbauer et al. 2021&lt;/a&gt;）。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;双极概念维度的投影方法可以进一步扩展到锚定具有多种含义的低维子空间，其中单词和概念可以被绘制并理解为这些含义的混合&lt;/strong&gt;。这可以通过理论上选择“原型”的集合来执行，即具有已知且广泛共享含义的极值点，并在这些极值锚定义的子空间中绘制所有相关单词或概念。[例如，在对一个新的基于信息技术的创业企业进行分类时，人们可能会问它在 Uber、亚马逊、谷歌或比特币所刻画的空间中适合什么位置(Breiman 1994，Eugster 2012，Damle 和 Sun 2017）。&lt;/p&gt;
&lt;br&gt;
&lt;h4 id=&#34;552-应用&#34;&gt;5.5.2 应用&lt;/h4&gt;
&lt;p&gt;这项措施的制定和运用是为了研究 20 世纪和 21 世纪社会阶层的演变（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B89&#34;&gt;Kozlowski 等人，2019&lt;/a&gt;）。他们研究了根据 20 世纪出版的数百万本书的文本训练的嵌入，按照上述程序操作了阶级的维度，试图了解社会阶级的底层维度在 20 世纪是如何变化的。为此，他们提出了以下理论上的&lt;strong&gt;概念轴(维度)&lt;/strong&gt;：富裕程度（富人与穷人）、教育程度（受过教育与未受教育）、修养（有教养与未受教育）、地位（有声望与无声望）、道德（善与恶）、就业（雇主-雇员）和性别（男人-女人），分别嵌入 20 世纪的每个十年。然后，他们可以在这些维度上投射不同类别的概念，例如音乐风格、体育和职业，以了解这些概念在本世纪的过程中如何演变和发展。&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B6&#34;&gt;研究人员应用这种方法来研究健康、道德（ Arseniev-Koehler et al. 2022&lt;/a&gt;）、政治意识形态（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B171&#34;&gt;Taylor and Stoltz 2021&lt;/a&gt;）和地位（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B129&#34;&gt;Peng et al. 2021&lt;/a&gt; ）等背景下的其他类型的文化关联。&lt;/p&gt;
&lt;p&gt;研究人员不仅将概念投射到这些概念轴(维度)上，而且将整个文档投射到这些维度上，从而推动了测量的可能性（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B170&#34;&gt;Taylor 和 Stoltz 2020&lt;/a&gt;）。此外，尽管以前的措施依赖于研究人员指定感兴趣的连续体的相关维度，但最近的工作已经转向自动识别这些连续体（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B116&#34;&gt;Milbauer et al. 2021&lt;/a&gt;）。&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B116&#34;&gt;Milbauer 等人&lt;/a&gt;利用 Reddit 社区的内容。&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B116&#34;&gt;（2021）&lt;/a&gt;创建了一个无监督的程序来识别社区中的多个意识形态极点，使他们能够超越静态的左右意识形态维度，发现现代话语中发挥作用的许多两极分化和意识形态差异的轴。人们可以想象在许多组织环境中使用这种方法来识别团队、小组、单位或部门之间存在的许多潜在冲突来源。&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;56-概念维度&#34;&gt;5.6 概念维度&lt;/h3&gt;
&lt;p&gt;之前，我们讨论了研究人员如何调查关键术语在相关文化维度上的位置，描述概念的位置在性别维度上的差异。然而，这并不是概念轴(维度)的唯一用途，因为概念空间还允许我们测量和理解相关维度本身如何相互关联。该措施的扩展是使用空间内的编码维度并将它们相互比较。例如，&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B89&#34;&gt;科兹洛夫斯基等人。（2019）&lt;/a&gt;利用他们既定的阶级维度来追踪整个 20 世纪每个维度如何与其他维度相关，例如，表明随着世纪的发展，富裕与教育的关系变得更加密切，而与教育的关系无关。栽培。通过这种方式，组织学者可以理解相关维度之间的关系在相关概念空间中可能有何不同。例如，学者可以研究不同文化维度在组织或行业内部和之间紧密或松散联系的程度。&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;六讨论&#34;&gt;六、讨论&lt;/h2&gt;
&lt;p&gt;最后，我们简要讨论了一些利用嵌入模型进行思考的新兴方法，然后讨论了我们认为理论、方法论和组织的有价值的机会，这些机会源于将这些模型理解为概念空间的细粒度表示。这个讨论必然是说明性的，但暗示了现在这些精致的意义模型的可操作性的广泛可能性。&lt;/p&gt;
&lt;h3 id=&#34;61-词嵌入方法的富有成果的扩展&#34;&gt;6.1 词嵌入方法的富有成果的扩展&lt;/h3&gt;
&lt;p&gt;词嵌入的底层计算架构最近经历了扩展，可以在与之前讨论的不同方向上动员组织研究。我们简要提到三个，并在在线附录中提供更详细的描述。首先，概念和语言的层次结构在“直线”、欧几里得几何中很难得到体现，需要许多难以理解的维度来用标准嵌入来捕获。然而，层次结构可以用负弯曲双曲嵌入来原生表示（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B90&#34;&gt;Krioukov et al. 2010&lt;/a&gt;，&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B126&#34;&gt;Papadopoulos et al. 2012&lt;/a&gt;，&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B22&#34;&gt;Chamberlain et al. 2017&lt;/a&gt;，&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B121&#34;&gt;Nickel and Kiela 2017&lt;/a&gt;），为探索复杂现代的交叉层次结构提供了新的测量可能性。组织。例如，将公司名称嵌入双曲空间中将能够直接发现典型的“中心公司”，并在商业新闻语料库中与所有其他公司进行比较。额外的双曲维度将揭示子层次结构，反映商业评论员所持有的概念和比较价值的不同维度。&lt;/p&gt;
&lt;p&gt;其次，模型语言的深度学习方法为词嵌入增加了关键的上下文敏感性。考虑像 BERT ( &lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B35&#34;&gt;Devlin et al. 2019&lt;/a&gt; ) 和 GPT 系列模型 ( &lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B140&#34;&gt;Radford et al. 2019&lt;/a&gt; ) 这样的大规模模型，它们使用“注意力”的神经网络机制来识别影响焦点词含义的上下文词 ( &lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B176&#34;&gt;Vaswani ) et al. 2017&lt;/a&gt;），组装成一个称为转换器的架构，可以将问题转换为答案，将文本转换为翻译，将请求转换为响应。这种模型产生的内容可以被描述为上下文嵌入，这样每个单词不是由单个向量表示，而是由向量云表示，每个向量代表不同上下文中的该单词。“google”上下文中的“Apple”与“orange”上下文中的“apple”具有不同的值。这些模型极大地提高了预测能力，并进一步扩展了我们对概念空间进行精确建模的能力，但代价是复杂性和计算量更大。&lt;/p&gt;
&lt;p&gt;最后，嵌入架构可以扩展到在序列或更高维上下文中排列的任意符号集。例如，图像已被用来衡量抽象艺术图像的新颖性和创造力（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B10&#34;&gt;Banerjee and Ingram 2022&lt;/a&gt;，&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B11&#34;&gt;Banerjee and Kaplan 2022&lt;/a&gt;），分析警察预约照片（大头照），并识别与司法拒绝保释相关的先前未概念化的紧急特征听证会（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B107&#34;&gt;Ludwig 和 Mullainathan 2022&lt;/a&gt;）。&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B101&#34;&gt;音乐（ Liang et al. 2020&lt;/a&gt;）、音频剪辑（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B70&#34;&gt;Hershey et al. 2017&lt;/a&gt;、&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B189&#34;&gt;Xie and Virtanen 2019&lt;/a&gt;）和视频（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B191&#34;&gt;Zellers et al. 2021&lt;/a&gt; ）的多维空间是使用audio2vec（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B168&#34;&gt;Taglisacchi et al. 2020&lt;/a&gt;）等工具构建的。 、signal2vec（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B118&#34;&gt;Nalmpantis 和 Vrakas 2019&lt;/a&gt;）和 video2vec（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B62&#34;&gt;Habibian 等人 2017&lt;/a&gt;），为组织学者接触代表组织生活视听体验的新型媒体打开了大门。&lt;/p&gt;
&lt;p&gt;最近对双曲线、上下文、图像和音频嵌入的扩展表明，嵌入模型的底层计算框架的持续改进和扩展将继续下去，为组织科学中持续的实证、测量和理论创新奠定了基础。&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;62-词嵌入和组织理论&#34;&gt;6.2 词嵌入和组织理论&lt;/h3&gt;
&lt;p&gt;在理论层面上，将嵌入模型理解为概念空间的有原则的、细粒度的表示有可能刺激新的理论发展并完善现有理论。例如，意义研究中的经典陈述影响了文学理论和文化社会学等其他领域，但未能在组织科学中站稳脚跟。自20 世纪初德索绪尔 ( &lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B32&#34;&gt;de Saussure 1986&lt;/a&gt; )的著作带来语言学的结构转向以来，许多人都试图将意义在组织和社会生活中的作用理论化。列维-斯特劳斯汇集了来自全球各地的多样而广泛的民族志，以向世界文化所特有的表面混乱提出深层的文化秩序，并认为复杂的意义是从有意义的元素的结合中产生的（列维-斯特劳斯 2016 &lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B99&#34;&gt;）&lt;/a&gt;。福柯理论化了话语和权力如何紧密相连，权力和知识如何以自我强化的联盟结合在一起（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B46&#34;&gt;Foucault 2012&lt;/a&gt;）。&lt;em&gt;布迪厄将惯习&lt;/em&gt;的概念阐述为“持久的、可互换的处置系统，倾向于充当结构结构的结构化结构，即作为实践的生成和结构的原则”（Bourdieu 1977，第72页&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B16&#34;&gt;）&lt;/a&gt;。尽管这些理论很有吸引力，但迄今为止它们只能进行松散且间接的测试。如果没有可靠的实证立足点，他们就永远无法在管理和组织理论中取得突出地位。然而，概念空间的实证操作化现在使得这些文化理论基础著作的参与和扩展变得容易处理，其中的许多结构现在可以辩护地测量。嵌入模型将使这些理论与管理和组织理论相关。&lt;/p&gt;
&lt;p&gt;我们还希望嵌入模型能够对现有理论框架进行更深入的研究和锐化。一组能够受益的文献是那些与知识相关的文献。鉴于组织学者可以获得的大部分知识都被编码在语言的符号概念系统中，现在可以通过更多可用的文本数据源来获取知识，并且可以通过嵌入模型的概念空间来表示。材料科学领域的最新工作已经使用此类模型来有效预测未来的知识发现，比科学家提出的知识发现早几十年（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B173&#34;&gt;Tshitoyan 等人，2019 年&lt;/a&gt;；&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B161&#34;&gt;Sourati 和 Evans，2021 年&lt;/a&gt;）。其他工作表明，这些发现可以推广到生物和物理科学（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B154&#34;&gt;Shi 和 Evans 2023&lt;/a&gt;）。概念空间的明确表示可以对整个社会系统中知识的特征和结构进行详细的调查。一方面，这些模型就像望远镜一样，打开了知识的天空，使其大规模结构变得可见，以供研究、理论发展和完善。另一方面，这些模型充当显微镜，使我们能够更深入地观察构成更大知识系统的意义原子结构。测量方面的这一进步将丰富对定义人类和组织经验的大型多维知识系统中的机制的测试。它还将使我们能够递归地评估管理和组织奖学金的知识，从而刺激创新。&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;63-词嵌入和实证研究&#34;&gt;6.3 词嵌入和实证研究&lt;/h3&gt;
&lt;p&gt;在&lt;em&gt;实证层面&lt;/em&gt;，词嵌入模型可以提高组织科学不同领域的测量保真度，从而在实证结果与理论主张和框架之间实现更好的映射。我们用团队和群体内部多样性研究的例子来说明这一点。据说，不同群体所获得的许多好处是由于群体中的个人代表问题和解决方案的方式不同而产生的（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B75&#34;&gt;Hong 和 Page 2004&lt;/a&gt;）。由具有不同方法的个人组成的小组将更好地执行各种任务，因为他们将拥有更广泛的知识、观点和可供借鉴的信息资源（Cox et al. 1991，&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B27&#34;&gt;Williams&lt;/a&gt; and &lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B185&#34;&gt;O&amp;rsquo;Reilly 1998&lt;/a&gt;）。然而，由于测量困难，对团队多样性的研究很少测量问题和解决方案空间的不同概念。相反，它假设解决问题的团队成员的身份多样性（人口、文化、种族或经验）与其功能多样性（团队成员如何代表和解决问题）之间存在联系（Nisbett 和 Ross 1980，Hong&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B122&#34;&gt;和&lt;/a&gt;Page &lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B75&#34;&gt;2004&lt;/a&gt;，&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B175&#34;&gt;van Dijk 等人，2017&lt;/a&gt;）。&lt;/p&gt;
&lt;p&gt;由于缺乏高保真方法来访问团队成员在问题和解决方案的概念空间中的位置，因此通常假定身份和功能多样性之间存在联系。用于操作研究的身份多样性和用于理论化的功能多样性之间脱节的一个重要后果是，虽然理论积极使用功能多样性的思想和术语（从根本上讲是几何和高维的），但测试依赖于集合-与身份成员资格相关的理论概念。&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B175&#34;&gt;我们预测，这将解释团队多样性文献（ van Dijk et al. 2017&lt;/a&gt; ）结果中的大部分歧义，因为研究设计忽视了功能多样性和身份多样性之间的同源性。然而，诸如概念广度之类的衡量标准可以阐明这一理论交叉点上的悬而未决的问题。我们现在可以指定（1）团队的基本概念广度，以及（2）这种基本广度可能驱动结果的程度。解决这些问题可以为许多分析层面的研究提供信息，从个人和团队的成功（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B164&#34;&gt;Srikanth 等人，2016 年&lt;/a&gt;，&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B175&#34;&gt;van Dijk 等人，2017 年&lt;/a&gt;）到公司和行业绩效（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B144&#34;&gt;Roberson 等人，2017 年&lt;/a&gt;）。我们希望我们的插图能够激发在组织研究领域生成细粒度意义测量的新可能性。&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;64-组织内部的词嵌入&#34;&gt;6.4 组织内部的词嵌入&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;最后，我们认为词嵌入方法将对我们研究的组织产生影响&lt;/strong&gt;。我们说明了在劳动力市场背景下潜在的嵌入必须塑造组织行为。从招聘到工作设计，从培训到晋升，人力资源管理的一个核心挑战是有效地将个人与组织内的角色、工作、情况和任务相匹配（Weller et al. 2019 &lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B183&#34;&gt;）&lt;/a&gt;。随着比赛质量的提高，各种绩效指标也会提高，包括工作满意度（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B8&#34;&gt;Ashforth 和 Saks 1996&lt;/a&gt;）、个人生产力（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B125&#34;&gt;Paauwe 2009&lt;/a&gt;）和组织绩效（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B38&#34;&gt;Dyer 和 Reeves 1995&lt;/a&gt;）。有效匹配的一个问题是不同维度的匹配的重要性程度。在一家公司中，技能可能最为重要，而在其他公司中，技能可能是文化契合度、态度、技能和经验的相互作用。由于嵌入模型捕获了所有这些维度，管理者可以为每个相关维度嵌入不同的原型描述，同时还嵌入个人资料和其他相关通信（例如电子邮件、松弛消息等），以衡量每个人与每个相关维度之间的匹配接近度。这样做可以让管理者更好地识别高维匹配及其对员工、社区和公司绩效的影响。&lt;/p&gt;
&lt;p&gt;嵌入模型旨在为人力资源的宏观管理提供新的视角（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B183&#34;&gt;Weller et al. 2019&lt;/a&gt;）。来自大型组织的相关信息存储在人力资源经理、一线经理、员工、同事和外部招聘人员中。然而，无法集中访问这些信息。通过嵌入，组织可以从所有数字面包屑的文本（电子邮件、聊天、工作描述、正式报告、绩效管理记录等）构建概念空间。这样做并使用相似性分析将使公司能够绘制和了解相关人力资本的位置位于公司对面。管理人员可以利用这些系统来准确了解任何员工的概念职位与任何给定的公司要求的差距有多大。这不仅可以为招聘、雇用、员工流动和流动等流程提供信息，还可以为培训、社交、工作设计和公司重组提供信息。因此，在劳动力市场和组织适应的背景下，嵌入模型可以产生有用的创新。人们可以想象许多其他组织实践和结构可以从这些模型及其测量可能性中受益，包括产品设计、市场分析和战略生成。&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;结论&#34;&gt;结论&lt;/h2&gt;
&lt;p&gt;我们同意&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B65&#34;&gt;Hanan等人的观点。（2019&lt;/a&gt;，第 2 页）当他们观察到，考虑到概念和分类对几乎所有人类行为和社会互动的中心地位，人们对概念如何运作的关注如此之少，这是多么令人惊讶。现代组织内部及其周围进行的许多活动都需要概念信息的激活和传播。当一个人解决新问题、提出新想法或与他人合作时，就会发生这种情况。从围绕饮水机的良性闲聊到重新配置全球资本主义秩序或将人类登陆火星，概念及其所嵌入的概念空间发挥着核心、关键的作用。&lt;/p&gt;
&lt;p&gt;正如本文所示，我们现在拥有一系列重要的工具，可以为广泛而深入的理论想象和实证研究打开&lt;strong&gt;概念世界&lt;/strong&gt;和&lt;strong&gt;概念空间&lt;/strong&gt;。我们希望本文能够激发对嵌入可以提供信息的大量问题和理论的学术探索。&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;广而告之&#34;&gt;广而告之&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/call_for_paper/&#34;&gt;长期征稿&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/we_need_you/&#34;&gt;长期招募小伙伴&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/management_python_course/&#34;&gt;付费视频课 | Python实证指标构建与文本分析&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
      <content:encoded><![CDATA[<h2 id="相关内容">相关内容</h2>
<ul>
<li><a href="https://textdata.cn/blog/2022-04-09-literature-about-embeddings/">文献汇总 | 词嵌入 与 社会科学中的偏见(态度)</a></li>
<li><a href="https://textdata.cn/blog/2023-03-15-39faq-about-word-embeddings-for-social-science/">词嵌入技术在社会科学领域进行数据挖掘常见39个FAQ汇总</a></li>
<li><a href="https://textdata.cn/blog/2022-04-07-word-embeddings-in-social-science/">转载|大数据时代下社会科学研究方法的拓展——基于词嵌入技术的文本分析的应用</a></li>
<li><a href="https://textdata.cn/blog/2023-12-28-visualize-the-culture-change-using-people-daily-dataset/">可视化 | 人民日报语料反映七十年文化演变</a></li>
<li><a href="https://textdata.cn/blog/2023-12-28-train-word2vec-using-renmin-gov-leader-board-dataset/">词向量  | 使用<strong>人民网领导留言板</strong>语料训练Word2Vec模型</a></li>
</ul>
<p><br><br></p>
<p>Aceves, Pedro, and James A. Evans. &ldquo;<strong>Mobilizing conceptual spaces: How word embedding models can inform measurement and theory within organization science.</strong>&rdquo; <em>Organization Science</em> (2023).</p>
<br>
<h2 id="摘要">摘要</h2>
<p>词嵌入模型是一种表示多维概念空间的强大方法，在多维概念空间中，所传达的概念可以相互关联、组合和竞争。此类模型代表了机器学习的最新进展，使学者能够用大规模文本数据局部和全局的单词共现，以最小的语义失真程度， 有效地编码复杂的意义系统。尽管词嵌入的使用有可能扩大组织科学中的理论可能性，但嵌入对于组织学者来说很大程度上是未知的，未发挥出词嵌入应有的潜力。我们的目标是通过为用户提供实用的路线图来展示嵌入模型在组织科学中的前景，以在他们的研究中调动该方法，并为开展该类研究的学者提供理论指导。 我们首先明确定义 <strong>概念</strong> 和 <strong>概念空间</strong> 的概念，然后继续展示如何使用词嵌入模型来表示和测量这些概念，并指出该方法的优点和缺点。然后，我们提供一组嵌入测量及其理论解释和灵活的扩展。我们的目标是从词嵌入的技术处理中提取概念，并将其置于实践的理论框架中，以加速此类研究。</p>
<p><br><br></p>
<h2 id="一介绍">一、介绍</h2>
<p>过去十年，文本作为数据的计算使用在组织科学中显着增长（Hasan 等人，2015 年；Goldberg 等人，2016 年；Srivastava 等人，2018 年；Hannigan 等人，2019 年）。这种增长的主要原因是文本编码的概念信息赋予个人、组织、经济和社会行为以意义（Evans 和 Aceves 2016，Gentzkow 等人 2019），并且在过去十年中，来自组织环境的文本数据急剧增长，大大提高了文本的可用性。然而，文本中编码的 <strong>概念意义</strong> 本质上是高维的，这使得降低概念复杂性成为研究文本的学者的中心任务。<strong>词嵌入模型是由计算机科学家和语言学家开发的一个新兴工具系列，用于文本信息降维，以此提取概念及其数字表示</strong>。词嵌入技术的发展使组织科学家依赖于文本数据进行理论构造， 相比之前，数据中信息的保真度更高，由此文本数据与组织研究交叉场景形成了新的理论研究路线。尽管词嵌入模型在组织科学之外得到广泛使用，但由于组织科学领域的学者缺乏对词嵌入技术的理解， 不知如何将它们纳入理论发展过程的原则框架，词嵌入模型对于理论发展的价值仍然被掩盖。</p>
<p><strong>词嵌入模型建立在高效的神经网络架构之上，并通过将复杂的语义系统有效编码到具有最小失真的稠密几何空间中，彻底改变了语义分析</strong>。这些模型代表了数十到数百个维度的空间中的语义，相对于语言中的单词和概念的数量来说，这个维度较低； 但相对于正式社会和文化理论家之前试图呈现概念信息的两到三个维度来说，这个维度却很高（奥斯古德 1964 年，史密斯-洛文和海斯 1988 年）。出于组织科学的目的，这些嵌入模型创建了社会系统中个体所持有的集体知识的 <strong>数字替身</strong> ， 嵌入可以解决文化上隐含类比（Mikolov et al. 2013b），回答文化偶然问题（Devlin et al. 2019，Radford et al. 2022），并预测未来的知识发现（Tshitoyan等人 2019；Sourati 和 Evans 2021）。组织科学长期以来一直借鉴人工智能（AI）的表征概念， 在这里，我们使用人工智能的表示机制来增强组织理论研究（Csaszar 和 Steinberger 2022）。</p>
<p>然而，由于神经网络复杂，且难以理解的黑盒性质特性，围绕神经嵌入和人工智能方法对理论发展的价值存在争议。尽管预测能力很强，但此类方法往往缺乏可解释性（Knight 2017，Leavitt et al. 2021）。<strong>在组织科学领域中，学者缺乏此技术的理解，即</strong></p>
<ul>
<li><strong>对于嵌入何时成为组织科学有用的方法论选择</strong></li>
<li><strong>如何在既定认识论标准内证明使用“复杂”神经嵌入方法的合理性</strong></li>
<li><strong>如何在各种嵌入中进行选择 等方法</strong>（例如，静态词嵌入与上下文嵌入、预训练嵌入与自定义嵌入）</li>
<li><strong>使用嵌入进行研究的适当步骤以及评估嵌入研究的相关标准</strong></li>
<li>最值得注意的是，研究界，特别是那些研究组织认知、文化、知识和意义的人，似乎对嵌入方法 <strong>如何适应将方法论选择与理论发展联系起来</strong></li>
</ul>
<br>
<p>我们的目的是通过两项贡献来解决这些问题。</p>
<p><strong>首先，我们的目标是提供一个理论指南，为嵌入模型提供一个原则性的概念框架，学者可以使用该框架为他们的模型注入意义，并使学者们能够在理论发展过程中运用这些模型。我们这里的主要论点是，词嵌入模型中的每个向量代表一个概念，整个嵌入模型代表生成文本数据的社会系统的概念空间</strong>。嵌入模型所代表的概念空间是多维空间，其中从规范和知识到想法和发明的概念相互关联。这个框架使组织学者能够利用嵌入模型的概念空间，与组织科学的许多领域之间建立联系。例如，不同公司基于知识视角对该空间的差异化覆盖（Grant 1996），组织理论家在描述规范和制度（Scott 2003），类别学者援引在决定将一个物体归类到哪个概念时（Pontikes 和 Barnett 2015 ），创新学者直接理论化寻求测量发现和发明的新颖性（Fleming 和 Sorenson 2001，2004），并且团队研究人员寻求了解成员在空间中的不同立场如何影响创造力、协调性和绩效（Srikanth 等人，2016）。因为我们以 <strong>概念</strong> 和 <strong>概念空间</strong> 为中心的理论框架可以推广到组织理论的许多背景，所以我们希望嵌入模型所支持的研究将促进这些子领域之间更深入、更持久的对话。</p>
<p><strong>其次，我们的目标是为利用嵌入模型进行理论发展提供实用的路线图</strong>。在此过程中，我们引导读者完成使用专利摘要语料库来实现词嵌入模型的过程，以表示现代技术创新的概念空间。我们解释了研究人员需要设置的模型参数，并逐步完成了他们应该采取的验证步骤，以评估模型是否有效地代表了他们感兴趣的概念空间，并提供了方法附录，其中包含实现所讨论的所有内容所需的代码。在注意到嵌入模型的可供性的同时，我们还讨论了它们不断发展的局限性，并提出了它们何时不适合组织分析的建议。然后，我们展示嵌入模型如何实现依赖于概念和概念空间的构造的理论化和测量。</p>
<br>
<p>我们概述了两大类词嵌入使用方法</p>
<ul>
<li><strong>度量之内/之间进行标记</strong>，我们提出了跟踪相关分析集内部和之间的概念关系的度量，以帮助我们跟踪与概念广度、概念距离和概念相似性</li>
<li><strong>意义及其维度</strong>，我们提出了四种衡量标准，为了解意义及其与组织的关系提供了不同的窗口。为找出这些测量机会的理论可能性，我们重点介绍了一些研究进展。</li>
</ul>
<p><strong>本论文的一个核心主张是，在组织研究不同广度和深度，词嵌入工具现在使我们能够表示其概念空间，并且比以前更精细地表示细节</strong>。有鉴于此，我们的目标是展示嵌入模型如何在与组织科学家相关的领域中操作概念空间，使研究人员能够扩展和完善现有理论。我们希望这一理论指南和实践路线图将促进组织科学内部的理论扩展，该扩展首先是扩大对文本数据的访问以及用于分析的随附计算工具（Kovács 等人，2013 年; Goldberg 等人; 2016年，Hannigan 等人, 2016年, 2019； Guo 等人，2020）。</p>
<p><br><br></p>
<h2 id="二概念和概念空间">二、概念和概念空间</h2>
<p>概念是人类生活的一个基本特征，我们的日常思维很大程度上依赖于它们所代表的信息，使我们能够对周围的人、物体和事件进行分类，并将这些信息传达给其他人（Murphy 2002；Bergen 和 Feldman 2008 年； Cassanto 和 Lupyan，2015 年）。概念是将我们的精神世界粘合在一起的粘合剂（Murphy 2002），赋予精神和物质体验以意义（Hannan et al. 2019）。<strong>在认知科学和心理学的语言中，概念是“事物类别的「心理表征」”（Murphy 2002）。</strong></p>
<p>概念有两大功能：分类和交流（Medin and Rips 2005），这些功能都需要语言的帮助。实际上，我们通过在语言中分配一个单词或短语来表示一个稳定概念的信息内容。这就是为什么我们通过说出或写出 “<em><strong>manager</strong></em>” 一词来提及经理的概念，从而引出它所包含的概念信息，例如对他人的责任、做出决策以及相对于组织同行获得更高的薪水。然后，语言的单词分割并链接了社区的共享概念空间（Lupyan 和 Bergen 2015）。这样，“一个概念就是一个单词或短语的含义……[包括]像 ‘<em><strong>red</strong></em>’ 和 ‘<em><strong>grasp</strong></em>’这样的基本的、具体化的单词，以及像 ‘<em><strong>goal</strong></em>’ 和 ‘<em><strong>continuity</strong></em>’ 这样的抽象和技术单词”（卑尔根）和 Feldman 2008]）。</p>
<p>概念并不作为唯一的信息单位存在于真空中。相反，概念之所以有意义，是因为它们彼此相关（Hannan et al. 2019），“通过相似性和上下文的关系紧密地缝合在一起”（Hofstadter and Sander 2013）。在这种多重概念关系中存在着“我们对世界的大部分知识，告诉我们存在什么以及它们具有什么属性”（Murphy 2002，p.1）。例如，概念 <em><strong>resource</strong></em>  与  <em><strong>firm</strong></em>、<em><strong>constraint</strong></em> 和 <em><strong>natural</strong></em> 等概念相关。在文化系统的层面上，概念之间的相互关系引发了表征概念之间宏观层面有意义的维度。 <em><strong>manager</strong></em> 概念在某些方面与 <em><strong>coach</strong></em> 和 <em><strong>president</strong></em> 的概念很接近，而在其他方面则与<em><strong>employee</strong></em> 和 <em><strong>bureaucracy</strong></em> 的概念很接近。将概念理解为存在于复杂几何空间中的点，使我们能够思考和测量概念之间的距离远近（Hannan 等人，2019）。例如，与  <em><strong>playground</strong></em> 或 <em><strong>ice cream</strong></em> 相比， <em><strong>manager</strong></em> 与<em><strong>organization</strong></em> 和 <em><strong>leader</strong></em> 概念的联系更加紧密。<strong>我们将这种概念相关的多维空间称为概念空间</strong>（Hannan et al. 2019)</p>
<p>重要的是我们用复数来指代概念空间。对于许多单词来说，它们会根据使用的上下文表现出不同的概念信息模式。首先，概念可能会根据使用它们的社会背景而有所不同。例如，如果在执行董事会议室、商品交易大厅或附近的储蓄和贷款机构的背景下说出 “<em><strong>Bank</strong></em>”，指的是银行而不是河流。概念也可能根据使用时间的不同而有所不同。例如，“<em><strong>高科技</strong></em>” 一词所引发的概念关系会根据我们研究的是 1960 年代、1990 年代还是今天而有所不同。最后，概念关系因使用它们的社区而异，因此 “<em><strong>债务</strong></em>” 所捕获的概念将根据其是由首席财务官还是低收入个人使用而有所不同。概念所含信息存在多样性， 正如 Hannan等人（2019）指出，“虽然有些概念可能是天生的或生物驱动的，但大多数都是社会构建的。”</p>
<p><br><br></p>
<h2 id="三先前研究中的概念和概念空间">三、先前研究中的概念和概念空间</h2>
<p>概念以及扩展的概念空间是人类思维和交流的基础（Sperber 和 Wilson 1986；，Murphy 2002；Hofstadter 和 Sander 2013）。正因为如此，概念和概念空间对于许多组织理论框架来说或多或少是明确和关键的。在某些研究（例如类别研究）中，概念具有核心重要性并且已经被明确地理论化。然而，在其他情况下，（例如，公司基于知识视角）概念被隐含地假定，即使它们是决定许多理论期望的基本成分。鉴于概念无处不在，对组织科学所有领域使用概念信息进行全面回顾超出了本文的范围。我们将简短、非详尽的回顾集中在概念和概念空间概念的三个领域——<strong>类别、知识和文化</strong>。通过嵌入技术处理并追踪存在于个人和社区头脑中的概念信息，研究其对组织行为和结果的影响。<br></p>
<h3 id="31-类别">3.1 类别</h3>
<p>类别是具有共同特征和属性的实体组。如前所述，概念是类别的心理表征。对类别的研究主要集中在跨类别或模糊类别是否会增加或减少分类实体的估值。自Zuckerman（1999）以来的工作一直集中在消除歧义条件上，在这些条件下，类别跨越和模糊性会导致积极或消极的估值。许多研究表明，由于感知偏差（Durand et al. 2007）、不符合受众期望（Hsu 2006)、Hsu et al. 2009；Leung and Sharkey 2014） ，跨越模糊的类别会损害实体估值，或降低分类对比度（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B119">Negro et al. 2010</a>）。其他研究表明，跨越类别可以创造积极的估值结果，因为它表明非典型性可以放大良好的表现并缓冲不良表现（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B159">Smith 2011</a>），一个类别可以锚定认知，而另一个类别可以有益地修改认知（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B188">Wry et al. 2014</a>）。还有其他研究表明，效果取决于受众，有些人喜欢跨类别，而另一些人则不喜欢（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B135">Pontikes 2012</a>）。通过这些方式，类别可以通过影响有关类别成员资格的概念信息的解释方式，对行为和绩效产生积极或消极的影响。<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#fn5">4</a></p>
<p>尽管类别范式的贡献历来是通过类别成员的集合和模糊集合理论（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B64">Hannan et al. 2007</a>）概念来实现的，但最近的工作开始纳入其多维性（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B65">Hannan et al. 2019</a>）和类别的分级归属感。组织学者感兴趣的许多现象都是由概念及其代表的类别之间的精确距离支撑的。例如，鉴于专利所贡献的技术领域，专利通常分为类别和子类。然而，专利中编码的想法可以传播到创新空间的广泛领域，即使只分类在一个类别中。正如我们稍后讨论的，转向概念的几何概念，使分析师能够考虑隶属度、重叠和连续距离影响底层实体评估判断的方式<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B65">（Hannan 等人，2019 </a>。<br></p>
<h3 id="32-知识">3.2 知识</h3>
<p>众所周知，知识很难具体说明，并且在哲学、认知科学和社会科学领域，围绕其概念性质进行了长期而活跃的争论（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B166">Steup 和 Neta 2020</a>）。然而，过去几十年来，组织科学在微观、中观和宏观层面上进行了大量研究，解决有关知识及其在团队、组织和经济活动中的作用的问题。从对团队成员专业知识的研究（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B164">Srikanth et al. 2016</a>）到公司基于知识和注意力的观点（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B87">Kogut and Zander 1992</a>，<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B56">Grant 1996</a>，<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B123">Ocasio 1997</a>）；从交互记忆系统（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B143">Ren 和 Argote，2011</a>）到创新流程（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B50">Garud 等，2013</a>）；从组织设计（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B45">Foss et al. 2013</a>）到搜索和探索（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B93">Lavie et al. 2010</a>），知识在最近的组织理论化中发挥着核心作用。</p>
<p>无论人们对知识的定义如何选择，命题性知识从根本上都与概念信息相关。<em><strong>命题知识采取“ S [主体]知道p [命题]”</strong></em> 的形式（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B80">Ichikawa and Steup 2018</a>）。在某种程度上，命题是由语言中的单词编码的，并且单词代表概念信息，命题知识依赖于概念以及它们如何在概念空间中交织（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B110">McGrath and Frank 2020</a>）。以命题“泰勒知道氢的主要工业应用是氨的制造”和“特里知道量子算法可以具有较低的时间复杂度”为例。这些知识命题中的每一个都代表了不同的概念意义，前面提到的领域将以不同的方式操作它们。例如，团队学者可能会强调，由泰勒和特里组成的专利团队将拥有多样化的基础知识。采取基于注意力观点的学者会注意到，泰勒和特里可能会以不同的方式关注知识空间，以应对组织变革。研究创新的人可能会注意到如果泰勒和特里共享办公空间，知识重组的潜力。研究搜索的人可能会假设，为了解决问题，泰勒和特里会以不同的方式搜索概念性解决方案。在所有这些情况下，就这些领域通过诉诸语言编码的命题知识来理论化知识动态而言，它们以基本和可测量的方式参与概念和概念空间。<br></p>
<h3 id="33-文化">3.3 文化</h3>
<p>文化被不同地概念化为集体的共同价值观、故事、框架、工具包和类别（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B52">Geertz 1973</a>；<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B131">Pettigrew 1979</a>；<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B92">Lamont 和 Small 2008</a>；<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B158">Small 等人 2010</a>；<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B54">Giorgi 等人 2015</a>）。文化建构已成为组织研究的核心，在从个人和团队到组织和国家的各个层面的分析中都得到了运用（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B54">Giorgi et al. 2015</a>）。从理解文化如何塑造职业结构（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B195">Glynn 2000</a>）、组织领域（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B194">Anteby 2010</a>）和创业环境（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B106">Lounsbury and Glynn 2001</a>，<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B141">Rao and Giorgi 2006</a>）到它在讲故事（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B106">Lounsbury and Glynn 2001</a>）和身份建设中的作用（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B196">Ravasi 和 Schultz 2006</a>），从其对人际沟通的塑造（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B165">Srivastava 等人，2018</a>）到对组织绩效的影响（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B26">Corritore 等人，2020</a>），文化深深地受到概念及其互动方式的调节。文化以集体认知过程为基础（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B36">DiMaggio 1997</a>，<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B128">Patterson 2014</a>），很大程度上可以通过语言痕迹来获取。语言进入文化的窗口（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B55">Goldberg et al. 2016</a>，<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B165">Srivastava et al. 2018</a>，<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B26">Corritore et al. 2020</a>）很大程度上是通过它所表达的概念来呈现的，使得概念和概念空间成为组织文化研究的重要支柱。</p>
<p>基于它们在形成范畴、知识和文化方面的关键作用，概念和概念空间已成为许多组织理论赖以建立的知识支架的重要组成部分。然而，概念和概念空间通常仅被用作缺乏精确和可扩展的经验表征的不明确的隐喻。这限制了研究使用粗粒度的代理测量或允许手动编码和解释的小数据集。接下来，我们提出词嵌入模型是一种最先进的工具，用于表示概念和概念空间，可以添加到组织学者工具包中。就组织学者寻求将概念和概念信息所支撑的结构操作化而言，他们将得到这类新模型的帮助。考虑到这一点，我们接下来介绍嵌入模型如何工作以及为什么它们可以作为概念和概念空间的有效表示。</p>
<p><br><br></p>
<h2 id="四使用词嵌入来表示概念和概念空间">四、使用词嵌入来表示概念和概念空间</h2>
<h3 id="41-越来越多地使用文本作为数据">4.1 越来越多地使用文本作为数据</h3>
<p>过去 10 年，通过计算工具和方法进行文本数据分析出现了爆炸性增长。从社会学（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B40">Evans and Aceves 2016</a>）到经济学（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B53">Gentzkow et al. 2019</a>）和政治学（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B58">Grimmer and Stewart 2013</a>），文本正迅速成为组织、经济和社会生活的中心观察站。文本数据提供了在线知识社区、财报电话会议和公司报告、产品评估、组织电子邮件和讨论板、历史档案、视频转录和电影字幕、医疗记录、电子商务、社交媒体等多种领域的丰富思想和行为痕迹。媒体平台、新闻文章、科学学科等等。总而言之，这些文本数据源比以往任何时候都更深入、更广泛地进入组织生活。正如<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B40">Evans 和 Aceves（2016 年</a>）指出的那样，文本数据现在使我们能够访问“有关正在玩的社交游戏的隐藏元素及其背后的社交世界”的深层信息。然而，这些语料库的庞大规模及其广泛的范围意味着，提取理论上有意义的信息信号越来越多地受到计算方法的帮助，利用信息技术方法获取大量非结构化文本数据，并将它们转换为有意义且相关的度量。<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#fn6">5</a></p>
<p>文本数据与组织学者习惯使用的定量数据之间的一个主要区别是文本是高维的。正如<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B53">Gentzkow 等人（2019 年</a>）指出，“仅使用英语中一千个最常用单词的 30 个单词的 Twitter 消息样本 [&hellip;] 的维度大致与宇宙中的原子一样多。” 因此，使用文本作为数据的学者的中心任务是通过对数据施加限制来降低维度。<strong>过去二十年里，组织科学中用于降低这一维度的一些最常用的计算工具是词典法、语义网络和主题模型。尽管这些方法有其优点，但一个主要缺点是它们无法对文本中存在的细粒度概念关系和关联进行编码</strong> 。接下来，我们将展示嵌入模型如何利用文本中的局部和更广泛的信息来训练概念含义和概念空间的高保真表示。在此过程中，我们展示了词嵌入模型如何克服先前方法来表示文本中编码的含义的一些局限性，从而允许对理论结构进行更细粒度的测量，并实现新的理论可能性。</p>
<br>
<h3 id="42-词嵌入">4.2 词嵌入</h3>
<p>我们之前解释过，概念是事物类别的心理表征，人类通过在词典中分配一个单词或短语来表示稳定的概念，并指出，概念只有在与跨多个维度的其他概念相关并为其提供信息时才有意义。密集的概念空间。在这里，我们认为词嵌入模型是最近开发的一类从机器学习应用于自然语言处理的模型，它使我们能够有效且高效地表示概念空间，并将这些空间用于追求组织科学。词嵌入模型是文本语料库中单词的连续表示，可以进行几何解释。<strong>词嵌入的方法论假设，一个词的含义很大程度上是由出现在其直接和更广泛上下文中的词所决定的，这一想法受到结构语言学家的启发，他们已经证明，含义的差异与局部分布相关（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B68">Harris 1954</a>）， 这个想法现在被称为 「分布式语义学」，Firth 的著名描述是：“观其伴而知其意”（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B42">Firth 1957</a>，you shall know a word by the company it keeps）， 一个单词所代表的概念或含义可以通过它周围的单词的分布来推断</strong>。</p>
<p>以这种分布式方式思考概念和概念空间的底层计算架构可以追溯到 20 世纪 80 年代初期计算机科学家 Geoffrey Hinton 的工作（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B71">Hinton 1986</a> , <a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B72">Hinton et al. 1986</a>）以及认知科学家在这一时期研究的并行分布式处理模型（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B149">Rumelhart 等人，1986a</a>，<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B150">b</a>；<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B109">McClelland 和 Rumelhart，1989</a>）。分布式架构是当前嵌入语言模型的基础（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B115">Mikolov et al. 2013b</a>、<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B130">Pennington et al. 2014</a>、<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B35">Devlin et al. 2019</a>、<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B104">Liu et al. 2019</a>、<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B17">Brown et al. 2020</a>、<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B41">Fedus et al. 2020）。 2021</a>）， 嵌入模型 Word2Vec 算法(<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B115">Mikolov 等 2013b</a>) 相对简单易用，能够处理中等规模的语料库来。 <strong>Word2Vec 与  GloVe（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B130">Pennington 等人，2014 年</a>）和 FastText（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B13">Bojanowski 等人，2017 年</a>）等嵌入算法，是 ChatGPT 和相关模型的基础</strong>。</p>
<p>找个例子来帮助理解算法， 现在我们要创建过去 50 年创新的概念空间表示。首先需要概念活动领域的文本数据， 美国专利局数据提供了创新活动的踪迹，其中包括所有专利的文本、摘要、描述和权利要求。在整篇论文中，我们使用这个专利摘要语料库来指导读者完成训练这个概念空间和构建相关概念测量的过程。数据是从<a href="https://patentsview.org/">Patentsview.org</a>免费下载的，使用 1976 年至 2019 年间发布的所有专利来构建本文中发现的词嵌入模型和测量相关指标。</p>
<p>想象一下，专利语料库中的每个独特单词都是从放置在巨大冰箱上的随机放置的 <strong>“word magnet”</strong> 开始的（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B76">Hovy 2020</a>）。当连续词袋 (CBOW) 算法滚动浏览语料库时，使用每个目标词周围的单词词(滑动窗口的上下文)来预测目标词（更多内容见下文）。该算法的最终目标是产生一种语义模型，其中出现在相似上下文中的单词彼此接近，而来自不同上下文的单词则相距很远。由于用2维概念空间不足以捕获每个单词的全部含义，因此该算法改为在更高的（100-1,000）维空间内捕捉语义。通过这种方式，目标单词的概念信息是从它周围的单词中归纳出来的，将语料库中的每个单词绘制为<em>n</em>维空间中的坐标或向量。正是单词在这个<em>n</em>维向量空间中的相对位置，使我们能够将词嵌入模型可以描述代表人类概念活动区域的概念空间。<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#fn7">6</a></p>
<p>概念意义的识别假定了嵌入空间的可解释性。接下来，我们提出了对这些概念空间的一系列提示和测量，作为从中产生结构化解释的方法。这很像心理学家使用 <strong>心理测量调查</strong> 将概念印象转化为可解释的观点（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B112">Michael Furr 2021</a>）。或者<strong>认知人类学家如何使用结构化任务，例如排序和排名（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B163">Spradley 2016</a>），将概念性的世界观转变为可解释的世界观</strong>。我们认为嵌入模型必须接受结构化测量（就像向人类受试者提供的心理测量问卷）使他们的 **概念景观(conceptual landscape)**变得可解释。接下来，我们将引导读者如何用专利语料库训练创新概念空间表示的过程。之后， 我们概述了该方法的优点和局限性，并指出这些方法与先前的文本分析方法和组织研究实践的关系。</p>
<br>
<h3 id="43-选择语料库">4.3 选择语料库</h3>
<p>学者可以根据应用使用两种词嵌入模型。一方面，研究人员可以使用自有文本语料库来训练表示， 据此了解文本所涉主体(个人、团体、社会)行为的概念空间是什么样子， 以及概念关系揭示人类活动背景。在我们的示例中，专利创新在专利语料库中得到了很好的体现，因此我们在下面展示了如何从头开始训练概念空间表示, 以及它揭示了哪些概念联系。研究人员可以从头开始训练语料库的其他例子包括在线社区（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B18">Burtch et al. 2021</a>、<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B2">Aceves et al. 2022</a>、<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B23">Chambers et al. 2022</a>）、学术学科（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B74">Hofstra et al. 2020</a>、<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B102">Lin et al. 2022</a>） 、劳动力市场（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B9">Bana 2022</a>）、公共记录（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B6">Arseniev-Koehler et al. 2022</a>）、产品和公司描述（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B61">Guzman and Li 2023</a>）以及财报电话会议和公开演讲（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B85">Kirgil and Voyer 2022</a>）。</p>
<p>或者，如果研究人员想要在较小的语料库中追踪概念动态，而该语料库的大小不足以训练独特的、特定于上下文的嵌入，那么研究者可以使用预训练嵌入模型，需要注意，训练预训练嵌入模型的文本与研究者小语料库在内容、场景要有相似性。广泛使用的预训练嵌入已经在来自海量语料库的文本上进行了训练，例如新闻（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B4">Google 2013</a>）、维基百科（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B35">Devlin et al. 2019</a>、<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B57">Grave et al. 2018</a>）。训练这些预训练嵌入模型的文本语料体量很大， 内容题材往往包含我们较小文本样本中存在的概念。因此使用预训练嵌入对这些概念的信息进行编码，并可用于近似相关距离。政治和历史语义背景下的研究发现，预训练嵌入提供的结果与特定于上下文的嵌入相当（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B89">Kozlowski et al. 2019</a>，<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B145">Rodriguez and Spirling 2022</a>）。如果有理由相信研究项目中包含的概念和想法没有在这些大量预训练嵌入中得到很好的体现，研究人员可以使用较小语料库中的文本对其进行 <strong>微调（Fine-Tune）</strong>（ <a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B104">Liu et al. 2019，Burtch et al.2019</a>）<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B18">， 2021</a>）。微调将预训练的概念空间扭曲为与样本一致（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B104">Liu et al. 2019</a>），更好地反映概念之间的关系。</p>
<p>最后，使用哪一种嵌入(自己训练的嵌入、 预训练的嵌入、微调的嵌入)将取决于研究人员的目的以及他们寻求追踪的概念动态的类型。接下来，我们将重点描述从头开始训练和验证嵌入模型的过程。在接下来的部分中，我们讨论不同参数设置和策略之间的权衡，并鼓励读者遵循文章文本和在线附录。</p>
<br>
<h3 id="44-清理语料库">4.4 清理语料库</h3>
<p>训练嵌入模型的第一步是使用 Python 等编程语言录入文本语料库， 首先获取每个专利摘要中的文本， 并将连续的文本进行切词，转化为单词列表 。然后，我们将文本小写，删除标点符号和数字字符串，并将每个摘要转换为称为token的单词列表。但是这可能破坏一些词组语义，这里使用 <em><strong>bi-gram</strong></em>， 识别高频共现的词组成词组，例如当 <em><strong>“electric”</strong></em> 和 <em><strong>“vehicle”</strong></em> 这两个词在某些上下文中一起出现时，它们将被统一形成短语和概念 <em><strong>“electric_vehicle”</strong></em> 。建立单词或短语列表后，执行单词嵌入算法来学习单词或二元组及其语言上下文之间的最佳距离，以保留语言中单词和短语的概念空间。</p>
<br>
<h3 id="45-训练嵌入模型">4.5 训练嵌入模型</h3>
<p>第一步是选择词嵌入算法， 浅层神经网络构建的单词表示（例如，Word2Vec、FastText；<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B115">Mikolov 等人，2013b</a>）、共现矩阵的低秩近似（GloVe；<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B130">Pennington 等人，2014</a>） ，或来自 Transformer 的深度上下文嵌入（例如 BERT、<em>GPT</em>；<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B35">Devlin 等人 2019</a>、<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B139">Radford 等人 2022</a>）。这些不同算法输出，都可以被解释为<em>n</em>维概念空间，其中单词或短语由空间内的向量位置表示。本文我们只介绍 Word2Vec 算法， word2vec 是一种广泛使用的训练概念空间的算法（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B113">Mikolov 等人，2013a</a>，<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B115">b</a>）。</p>
<p>Word2Vec 算法的一种流行实现算法是连续词袋 (CBOW) 算法，可以在 Gensim python 库中轻松访问，该算法使用目标单词的语言上下文来预测被扣掉的目标词 (可以简单的理解为让机器做完形填空题) ， 比较适合小规模数据集。 Word2Vec 还实现了另一种 Skip-Gram 算法，该算法通过从目标单词预测上下文单词来反转 CBOW 的预测任务，比较适合大规模数据集。相比之下，skip-gram 将每个上下文目标对（例如，T：“房子”，C：“宽敞”）视为单独的观察，因此可以更好地捕获精确的语义，但需要更大的语料库才能获得卓越的性能。</p>
<br>
<h3 id="46-维数">4.6 维数</h3>
<p>考虑维数很有必要。朴素的模型可以将不重复总词数作为维度， 例如包含 100,000 个不重复单词的语料库， 任何单词都需要  100,000 维才能准确表示。然而，当单词从上下文中被识别为相似时，可以一定范围内减少维度数。<strong>维度过多会导致内存需求和冗余增加，并降低可解释性；维度太少会扭曲距离并且无法解释语言的不及物性</strong>。通过这种方式，通过具有至少足够的维度来捕获所讨论的复杂语义关系，可以获得准确的预测。</p>
<p>在实践中，300 维已经成为一个标准，很大程度上源于最初的 Word2Vec 论文之后的惯例，该论文通过交叉验证确定了最佳维数，以减少预测屏蔽词任务中的错误。大多数后续分析都是建立在较小、多样性较低的文本集合上，需要较少的维度，因此 300 通常被用作上限。最近的工作表明，应根据语料库统计数据选择维度 - 语料库词汇表中成对等距单词的数量提供了维度数量的下限，低于此界限通常会导致单词嵌入质量下降（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B127">帕特尔和巴塔查亚 2017</a>）。<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B74">霍夫斯特拉等人。(2020)</a>使用 100、200 和 300 维的模型找到了稳健的结果。</p>
<p>如果分析师寻求实现维度可解释性，他们必须以最小失真来确定表示数据所需的维度数。 但这最后一步一半很少执行，因为维度的优化需要大量的时间和计算资源。</p>
<br>
<h3 id="47-窗口尺寸">4.7 窗口尺寸</h3>
<p>回想一下，窗口大小是指算法将用来焦点目标词（或其邻居）之前和之后的单词数量。该窗口最小可以是 1。对于较小的窗口，算法将倾向于对句法关系进行编码（例如，名词后跟动词）。<strong>随着窗口大小的增加，更多的含义和语义被编码到模型输出中</strong>。<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B145">考虑Rodriguez 和 Spirling (2022)</a>的示例，其中包含两个句子的语料库：(1)“狮子吃肉”和 (2)“牛吃草”。当窗口大小为一时，我们会知道牛和狮子都吃东西，从这个意义上说，牛和狮子在语法上是等价的，因为我们没有足够的信息来区分两者。然而，随着窗口的增加，算法开始对牛与狮子的含义进行更多编码。<strong>与维度数量一样，这里的回报也递减，窗口大于五个字的模型性能略有改善</strong>（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B145">Rodriguez 和 Spirling 2022</a>）。 <strong>BERT 和 GPT 系列等上下文模型具有更大的窗口，这些窗口通过注意力过程进行驯服，算法通过该过程识别哪些上下文单词对于解释焦点单词的含义很重要</strong>（Vaswani 等人，2017 年<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B176">）</a>。</p>
<br>
<h3 id="48-验证模型">4.8 验证模型</h3>
<p>最后一步是验证词嵌入模型，这样做是为了确认算法学习的表示与文本数据所承载的真实人类活动的概念空间表示尽可能相近。论文附录第 2 节描述了关于专利嵌入的七个详细验证程序，表明该模型有效地学习了创新空间的表示。这些包括（1）邻近嵌入词的语义相似性；(2)具有嵌入距离的语义梯度；(3)嵌入簇与语义域之间的对应关系；（4）物理世界距离与嵌入之间的相关性；(5) 社会距离与嵌入之间的相关性；(6) 嵌入空间类比推理的准确性；(7)嵌入文档的语义一致性。我们还讨论了第八个“额外”测试，即图灵测试（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B174">Turing 1950</a>）。由 Transformer 支持的现代上下文嵌入的评估标准是它们是否能够与人类毫无区别地参与任何分类、关联、意义生成或集成任务，包括普通对话和专家教程。OpenAI 的 ChatGPT 和许多竞争的聊天机器人已经展示了如此强大的性能，以至于图灵测试正在迅速从上限转变为基线基准。这些验证步骤与论文最后部分的测量相结合，作为嵌入模型的有用提示prompt和测量，使研究人员能够对其编码的概念空间提供结构化解释。</p>
<br>
<h3 id="49-词嵌入方法的优点和缺点">4.9 词嵌入方法的优点和缺点</h3>
<h4 id="491--无需正式指定相关尺寸">4.9.1  无需正式指定相关尺寸</h4>
<p>对概念建模的正式尝试试图通过逻辑演绎方法清楚地枚举概念的相关维度（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B47">Gärdenfors 2004</a>、<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B48">Gardenfors 2014</a>、<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B65">Hannan 等人 2019</a>）。尽管这种方法对于理解限定领域内的概念很有用，但即使如此，它也可能不切实际且难以衡量，因为很难先验地陈述分析师应预期的相关维度<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B73">（Hofstadter 和 Sander 2013 ）</a>。 <strong>词嵌入的优点在于，概念之间的关系以及对任何给定概念重要的相关维度可以从语言的使用方式中推断出来，因此不需要事前指定</strong>。鉴于在分析之前没有必要陈述相关维度，即使是最复杂的组织行为剧场也变得易于分析处理。正如其他人所指出的，“词嵌入为语言中包含的多个维度的含义提供了全面且有意义的见解，这是以前的方法无法捕获的”（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B105">Lix 等人，2022 年</a>，第 8434 页）。在某种程度上，这种优势源于这样一个事实：神经网络架构能高效地记录意义的维度。</p>
<br>
<h4 id="492-更大的有效维度">4.9.2 更大的有效维度。</h4>
<p>嵌入通常由 100 到 1,000 个密集编码维度表示。<strong>编码的密度意味着每个词向量在所有建模维度上都有一个非零坐标</strong>。正如附录中所指出的，主题模型可能具有相同数量的主题（例如，100-1,000），但这些主题被稀疏编码以方便人类解释，使得主题仅具有一些基本上非零的单词加载，并且文档仅具有少量非零的主题负载。<strong>因此，主题模型是为了描述而构建的，但代价是迫使其表示的有效维度从数百个减少到几个，从而扭曲了本来可以在主题空间内计算的距离。相比主体模型， 词嵌入使用密集编码，每维度的嵌入很难理解和描述，但距离具有更大的自由度，可以更精确地编码含义</strong>。通过这种方式，相对于低维理论和测量，嵌入为分析师提供了“大量潜在轴，个人和社会群体可以沿着这些轴竞争、合作、分裂或合并”（Kozlowski et al. 2019，p.27 <a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B89">）</a>。</p>
<br>
<h4 id="493-无监督训练">4.9.3 无监督训练。</h4>
<p><strong>词嵌入还有一个特殊优点，即训练模型时， 以看似无监督或自监督的方式进行，从而避免了手动编码文本语义内容的繁琐，完全由机器学习</strong>。在我们的创新示例中，向量空间由我们专利语料库中的每个发明人按照他们所写句子的数量和长度的比例进行监督。每个单词的滑动窗口都是为了向专利审查员和未来的发明者传达一种含义而构建的，该算法用于构建向量空间并以概念上适当的方式定位单词。因此，学者们可以利用专利语料库来训练 <strong>技术创新</strong> 的概念空间，利用财报电话会议记录和新闻稿来训练 <strong>上市公司沟通</strong> 的概念空间，利用分析师报告来训练 <strong>投资分析</strong> 的概念空间，或者特定领域的概念空间。使用内部通信（例如 Slack 和电子邮件）来了解公司的知识。这些概念空间可以在最少的监督下进行训练，因此很快成为有价值的观察站，用于追踪组织科学家关注的组织生活的静态和动态（Hofstra et al. 2020，Whalen et al. 2020，<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B74">Burtch</a> et <a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B184">al</a> . <a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B18">2021</a>，<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B177">Waller 和 Anderson 2021</a>、<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B2">Aceves 等人 2022</a>、<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B20">Carlson 2022</a>、<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B23">Chambers 等人 2022</a>、<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B61">Guzman 和 Li 2023</a>、<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B94">Lawson 等人 2022</a>、<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B105">Lix 等人 2022</a>）。</p>
<br>
<h4 id="494-共现是不必要的">4.9.4 共现是不必要的。</h4>
<p><strong>这些模型的另一个优点是，两个概念不必在任何文档中同时出现，就可以将它们编码为相似的向量</strong>。所需要的只是它们与相似的概念同时出现。例如，我们可以先验地指出 <em><strong>医生</strong></em> 和 <em><strong>律师</strong></em> 在某些方面非常相似（例如，他们需要高级学位，具有高收入水平等），但他们可能永远不会同时出现在语料库的同一文档中。尽管彼此之间缺乏共现性，但它们很可能都独立地与高收入*、<em>高学历</em>、*白领等概念同时出现，从而最终拥有编码这些相似性的接近向量。<strong>因此，嵌入模型的底层计算架构可以更好地近似社会和文化含义，而无需求助于严格的共现</strong>。</p>
<br>
<h4 id="495-上下文相关的含义结构">4.9.5 上下文相关的含义结构。</h4>
<p><strong>使用定制训练的嵌入模型的一个优点是它将捕获上下文相关的含义结构</strong>。例如，<em><strong>“甜”</strong></em> 的含义在软件团队的背景下与 <em><strong>烹饪</strong></em> 的背景下会有所不同。正如<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B105">Lix 等人。（2022）</a>指出，在软件团队的背景下，与 <em><strong>“甜蜜”</strong></em> 最接近的术语是 <em><strong>“强烈”</strong></em>、 <em><strong>“兴奋”</strong></em> 和 <em><strong>“耶”</strong></em>。此外，就同一个单词编码不同概念（一词多义）而言，单词每种含义的概念信息都位于单词嵌入内的线性叠加（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B5">Arora et al. 2018</a>）。这意味着编码诸如 <em><strong>“Bank”</strong></em> 之类的单词的<em>n</em>维向量包含其代表的所有概念的概念信息，例如 <em><strong>河边</strong></em> 或 <em><strong>金融机构</strong></em>。通过这种方式，即使在多义词的情况下，单词的上下文相关含义也会被编码到模型中。当这些上下文相关的含义不仅不同，而且是排他的或相反的时，来自转换器的上下文相关嵌入可以为上下文中的每个单词呈现不同的单词向量。</p>
<br>
<h4 id="496-几何有助于概念人群体和组织的细粒度表示">4.9.6 几何有助于概念、人、群体和组织的细粒度表示。</h4>
<p><strong>我们认为，词嵌入模型可以在训练的语料库范围内产生人类活动概念空间的细粒度表示</strong>。<strong>这意味着，从概念空间内编码的信息中，我们可以恢复个人、群体和组织本身的细粒度表示</strong>。以我们的创新案例为例，<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#F1">图 1</a>描述了在说明性二维空间中这是如何实现的。学习到的概念空间将由单词或短语w表示的概念作为其最原子的分析级别。我们的限制性示例显示了在2维空间中排列的九个单词。单词 1-3 由发明人 1 使用，单词 4-6 由发明人 2 使用，单词 7-9 由发明人 3 使用。<strong>通过获取每个人的单词向量的质心向量，我们可以得出每个发明人在创新的概念空间</strong>。<strong>将这个过程提升到团队和组织级别，我们可以在发明人团队和组织的概念空间内得出独特的向量</strong>。因此，词嵌入架构不仅在概念的最原子级别上是细粒度的，而且还可以在更聚合级别上提供细粒度的表示。相对于团队多样性、组织差异化和注意力等结构的粗粒度代理，这形成了显着的测量改进，这些结构在嵌入特定概念空间时是有意义的。</p>
<br>
<p><img loading="lazy" src="img/figure-1.jpeg" alt=""  />
<strong>图 1.嵌入作为概念、人员、群体和组织的细粒度表示</strong></p>
<br>
<h4 id="497-细粒度几何减少了上下文信息的丢失">4.9.7 细粒度几何减少了上下文信息的丢失。</h4>
<p><strong>由于粗糙、粗粒度的代理指标无法承载相关信息，在实证分析和相关理论构建中就无法利用这些信息</strong>。嵌入模型的优势在于其独特的信息表征，可以携带更多的信息，信息的粒度更小，保存的信息量更多。<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#F2">图 2</a>使用团队多样性的示例来说明如何实现这一点。<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#F2">图 2(a)</a>显示了两个团队，1 和 2，每个团队要么通过熵（一种标准的、集合论多样性的理论度量（顶行））来表示，要么通过概念广度（基于底层概念的细粒度度量）来表示。团队调动的信息（底行）。团队 1 和团队 2 都有四名成员，团队 1 由两名生物化学家、一名化学家和一名分析化学家组成，团队 2 由两名生物化学家、一名海洋学家和一名计算机科学家组成。<strong>由于两个团队的团队成员类型比例相同，因此它们都被编码为具有相同的团队多样性熵度量 1.5</strong>。**然而，当考虑团队成员的概念信息时，我们发现它们是本质上不同类型的团队，团队 1 的多样性或概念范围远不如团队 2 **。这表明粗粒度的测量可能会留下未开发的有价值的上下文信息（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B187">Wolpert et al. 2014</a>，<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B33">DeDeo 2017</a>）。因此，我们应该看到更细粒度的衡量标准与相关的、理论上的绩效结果之间的联系更加紧密和一致。</p>
<br>
<p><img loading="lazy" src="img/figure-2.jpeg" alt=""  />
<strong>图 2.（在线彩色)细粒度表示可防止有价值的信息丢失</strong></p>
<br>
<p>专利数据集使我们能够通过三种构建的措施来说明这一主张。首先，集合论团队多样性度量，使用团队先前专利在专利主要类别中的分布（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B79">Huo 等人，2019</a>）。第二种替代措施使用专利子类，以便它们提供相对于第一种更细粒度的措施。第三个衡量标准依赖于团队成员先前专利在创新概念空间内的<strong>概念广度</strong>。</p>
<br>
<h4 id="498-词嵌入的局限">4.9.8 词嵌入的局限。</h4>
<p>到目前为止，我们的注意力仅限于讨论嵌入模型的结构，描述它们与概念空间的关系，并注意到它们的优点。在这里我们将说明其局限性，讨论它们的严重性、改善方式，以及何时不要用词嵌入的意外情况。我们讨论三类限制。第一个源于神经网络模型一般复杂的“黑匣子”性质，以及这带来的具体挑战，涉及输入数据的偏差，以及模型正确推理的范围，特别是那些对超出分析师背景的数据进行预训练的模型。第二个与这些模型的大小以及训练它们所需的数据量有关。第三个问题涉及词嵌入模型的具体局限性以及从脱离韵律和表达上下文的文本数据中分析含义的挑战。</p>
<p>许多学者首先担心的是，多级神经网络模型显得复杂且在统计上难以理解，<strong>经常被批评为“黑匣子”方法</strong>，无法“打开”以询问其性能背后的机制（Knight 2017，Leavitt et <a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B86">al</a> . <a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B95">2021</a>） 。现代神经网络词嵌入模型通常作为自监督模型实现，该模型启发式搜索单词之间的依赖关系空间以预测屏蔽词的身份。<strong>自从第一个高性能嵌入发布（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B115">Mikolov 等人，2013b</a>）以来，对其黑盒性质的一些担忧已经减弱，因为数学家发现最流行的“浅”词嵌入模型（如 Word2Vec 和 FastText）获得了很大的优势</strong>。其强大功能来自于近似易于理解的矩阵分解方法的运算，例如因子分析、主成分分析和对应分析（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B100">Levy 和 Goldberg 2014</a>）。</p>
<p>“黑盒”输入输出方法带来的一个相关潜在限制是，<strong>输入的偏差将转化为输出中的偏差</strong>——用于训练嵌入的语料库的偏差将被编码在生成的单词嵌入模型中（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B14">Bolukbasi等人，2016</a>）。当模型用于现实世界的下游应用程序（例如推荐服务）时，这可能是有害的。例如，硬编码到嵌入中的种族和性别刻板印象可能会导致有偏见的建议（例如，评估是否适合招聘职位或预测财务违约的可能性），并导致不公平和不道德的决定（例如，拒绝工作或信贷） 。学者们应该根据他们的研究问题和设计，主动考虑这种负外部性是否可能，并在对人类造成伤害的可能性足够高时，偶然放弃嵌入。<strong>然而，在某种程度上，理解社区和研究背景中概念关联的本质是核心，研究人员将需要这些偏见进行分析。如果不包括它们，模型以及研究设计就会错过表征其研究背景的关键社会和文化规律。</strong></p>
<p><strong>如果分析人员对生成语料库的上下文没有清晰的了解，就会出现另一个相关的限制，这样他们最终可能会做出不适用和不相关的推论</strong>。例如，强调意义随时间变化的研究（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B19">Caliskan et al. 2017</a>、<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B49">Garg et al. 2018</a>、<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B89">Kozlowski et al. 2019</a>）的特点是词义表现出来自外源冲击的间断变化，从而重新配置了概念关联的结构。穿过空间。想一想 2005 年卡特里娜飓风之后“卡特里娜”的含义发生了怎样的变化。2009 年金融危机之后，金融术语的含义发生了重新配置，部分原因是添加了“问题资产救助计划”等许多新术语。忽略外源冲击可能会导致对后面和验证部分中描述的措施的错误解释，将其视为仅由进化产生的结果，从而导致错误的推论。这是一个特别成问题的问题，因为许多最准确的词嵌入模型都是在从网络上提取的大量文本语料库上进行预训练的。此类模型可用于引导非常小的文本数据之间的有意义距离，这是一项常见任务，但<strong>如果预训练数据是异构的，则距离可能无法反映焦点文本的概念世界</strong>。</p>
<p>接下来的两个限制必然是其嵌入优势的另一面。词嵌入模型产生的细粒度信息会带来特定研究可能或可能无法维持的成本。首先是模型尺寸。<strong>每个单词的数百个维度的细粒度信息或上下文嵌入需要比简单的字典计数或潜在狄利克雷分配主题模型更大的存储空间</strong>。这与通常用于将数据维度减少到两个或三个的因子和主成分分析形成鲜明对比。词嵌入模型使用更多维度（通常为 200-500）来更准确地预测数据的屏蔽部分。尽管如此，当前个人计算机的计算能力和存储能力现在允许训练合理大小的嵌入。</p>
<p><strong>与此相关的是，词嵌入模型需要比先前模型更多的文本才能稳健地估计概念空间</strong>。当大型语料库与研究主题相似并且可以用作理论相关文档或微调过程的初始化的代理时，可以通过迁移学习来弥补这一挑战。<strong>然而，有时相关语言在内容、目的或形式上与模型预训练的数据有很大不同，它需要独立建模，但又足够小，无法维持对嵌入模型的稳健估计。在这种情况下，使用字典计数或主题模型可能会更好，因为数据只能维持粗粒度的关联，而这些方法旨在捕获粗粒度的关联。</strong></p>
<p>最后一类通常涉及词嵌入和文本方法的特殊限制。首先，静态词嵌入本身并不处理一词多义，即一个词（例如 <em><strong>“bank”</strong></em> ）编码多个概念（例如金融机构、河边、侧向倾斜）的情况。尽管多义词的存在可能会影响后续一些指标的测量，但也存在抵消的力量。一方面，研究发现多义词的含义以相互线性叠加的方式编码在单词向量内（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B5">Arora et al. 2018</a>）。这意味着该算法通过同时考虑单词的所有含义来对单词在概念空间中的位置进行编码，从而克服了原本可能存在的严重缺陷。另一方面，上下文嵌入架构（在线附录中有更详细的描述）通过根据焦点词周围的上下文输出不同的向量来明确解决多义词的问题。每个单词不是单个向量，而是根据用途而变化的向量云。如果分析师怀疑一词多义可能是特定分析的严重问题，他们可以偶然使用上下文嵌入并规避这种担忧。</p>
<p>最后一个潜在的限制是文本方法的一般特征。只要文本数据是转录语音话语的产物（例如，欧洲央行或美联储主席演讲、政治演讲、财报电话会议、电视或电影文字记录、对话互动），语音的语调、语气和音色将没有纳入到嵌入表示中。考虑到。<strong>鉴于某些语言（例如中文）更严重地依赖语调来传达含义，这可能或多或少存在问题，具体取决于话语发生的社会背景及其表达语言</strong>。因此，在语调和语气在语料库中发挥重要作用的情况下，学者们应该讨论他们的嵌入模型选择和解释决策的后果。</p>
<br>
<h3 id="410-在研究中使用词嵌入模型的路线图">4.10 在研究中使用词嵌入模型的路线图</h3>
<p>现在我们大脑对词嵌入模型是什么、如何表示概念空间、如何训练、优点和局限性有了框架性的认知，接下来可以将它们整合到研究和理论构建的标准方法中。<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#T1">表 1</a>列出了如何将嵌入模型集成到科学流程中的路线图。</p>
<ul>
<li>步骤 1-3 是研究过程中的标准步骤，包括确定一个可行且有趣的研究问题，通过在适当的实证背景下进行评估，为重要的理论问题提供信息（Weick 1989 <a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B179">）</a>。</li>
<li>步骤 4-9 总结了本文到目前为止对嵌入模型的讨论。</li>
<li>步骤 10 和 11 ，与下一节指标度量有关，通过标准定量和定性方法调动该度量。</li>
</ul>
<br>
<p><strong>表 1.在研究中使用词嵌入模型的路线图</strong></p>
<table>
<thead>
<tr>
<th>步骤</th>
<th>活动</th>
<th>基本原理</th>
</tr>
</thead>
<tbody>
<tr>
<td>1. <strong>确定研究问题</strong></td>
<td>如果研究问题至关重要，请确定文本数据是否有助于在理论研究上有帮助。</td>
<td>吸引研究人员把注意力聚焦在理论问题、词嵌入构建研究构念回答问题的交叉点。</td>
</tr>
<tr>
<td>2. <strong>理论建立及相关理论构建</strong></td>
<td>确定使用哪种理论框架来解决研究问题以及通过嵌入模型来操作哪种理论构念。</td>
<td>理论构念与其词嵌入指标(构念的衡量）之间的紧密联系能够实现累积的理论发展。</td>
</tr>
<tr>
<td>3. <strong>定义经验背景</strong></td>
<td>选择适当的实证背景，在其中回答研究问题并动员理论框架和构念。</td>
<td>确保研究问题、理论框架和用构念以逻辑方式相互加强。</td>
</tr>
<tr>
<td>4.<strong>指定将用于表示经验背景的概念空间的文本数据</strong></td>
<td>描述将用于训练词嵌入模型和测量感兴趣的理论构念的文本数据的范围。 数据是否有效地涵盖了您想要得出理论结论的经验背景下的行为活动范围？</td>
<td>确保用于计算理论构造度量的词嵌入模型在逻辑上映射到并有效地代表所提出的理论框架内的实证研究背景。 文本数据的范围应该在逻辑上映射到所讲述的理论故事的范围。</td>
</tr>
<tr>
<td>5.<strong>确定文本数据的大小和范围</strong></td>
<td>数据是否足够大以学习相关概念空间的准确表示？</td>
<td>文本数据的大小将决定是否应该训练自定义嵌入，或者是否应该使用可用数据对现成的嵌入进行微调。</td>
</tr>
<tr>
<td>6. <strong>给定数据大小，要么训练独特的词嵌入模型，要么微调现有模型</strong></td>
<td>如果文本数据足够大，则训练自定义嵌入来表示感兴趣的经验上下文的概念空间。 如果文本数据不够大，请使用这些数据来微调现有的现成嵌入模型。</td>
<td>确保用于测量理论结构的嵌入模型能够有效地表示经验背景的相关概念空间。</td>
</tr>
<tr>
<td>7. <strong>如果训练独特的模型，请选择一种算法</strong></td>
<td>在连续词袋 (CBOW) 或 Skip-Gram 模型之间进行选择。</td>
<td>CBOW：在较小的数据集上可以有更好的性能。 <br>Skip-gram：可以更好地捕获语义。</td>
</tr>
<tr>
<td>8. <strong>如果训练独特的模型，确定相关参数</strong></td>
<td>选择窗口大小和维数。</td>
<td>窗口大小：标准做法是 5。较小的窗口可以更大程度地捕获语法，较大的窗口可以更大程度地捕获语义，但收益递减并增加计算成本。 维度数：标准做法是 300，超过此点后性能回报递减。</td>
</tr>
<tr>
<td>9. <strong>验证词嵌入模型</strong></td>
<td>请遵循在线附录中的验证程序。</td>
<td>确认嵌入模型准确有效地表示了经验背景的概念空间。</td>
</tr>
<tr>
<td>10. <strong>计算相关度量</strong></td>
<td>通过确定将用于实施感兴趣的理论构念的相关概念集，创建“实际措施和应用”部分中的措施之一。</td>
<td>使学者能够将该测量用于定量或定性分析。</td>
</tr>
<tr>
<td>11. <strong>在标准定性或定量方法中使用计算的度量</strong></td>
<td>对于定量分析，该度量要么成为自变量，要么成为因变量。 对于定性分析，学者可以提供解释性分析，因为它们可能适用于其他类型的档案、民族志或视听数据。</td>
<td>嵌入模型表示对生成数据的社会背景的概念空间的描述。</td>
</tr>
</tbody>
</table>
<p><br><br></p>
<h2 id="五实际措施与应用">五、实际措施与应用</h2>
<p>现在已经正式定义了 <strong>概念</strong> 和 <strong>概念空间</strong> 的含义，并说明了先前的文献如何处理概念信息,  介绍了嵌入模型表示能力的底层逻辑，并在在线附录中完成了支持这种直觉的几个验证步骤。也评论了嵌入模型给概念信息分析带来的几个优点和相关缺点。</p>
<p>在本章中，我们将介绍一些新研究， 学习他们如何用嵌入生成独特指标。<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#T2">表 2</a>总结了这些指标及示例应用。</p>
<br>
<p><strong>表 2.词嵌入测量和示例应用</strong></p>
<table>
<thead>
<tr>
<th>措施</th>
<th>研究性学习</th>
<th>关键构念</th>
<th>研究问题</th>
<th>代表性调查结果</th>
<th>嵌入在这种情况下的优点</th>
</tr>
</thead>
<tbody>
<tr>
<td>1. <strong>概念广度</strong></td>
<td><a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B105">利克斯等人。(2022)</a></td>
<td>话语多样性——在一组给定的互动中，群体成员所传达的含义彼此分歧的程度。</td>
<td>一个群体的话语多样性如何影响其绩效？</td>
<td>高绩效团队会调整他们的共享认知以匹配任务的要求（例如，构思与协调）。</td>
<td>能够随着时间的推移以细粒度的细节和动态地追踪小组对话的概念广度，使学者们能够追踪话语多样性的新理论构造。</td>
</tr>
<tr>
<td>2.<strong>概念距离和相似度</strong></td>
<td><a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B74">霍夫斯特拉等人。(2020)</a></td>
<td>语义遥远的科学新颖性：博士论文中新链接概念的语义距离。</td>
<td>代表性不足的群体是否更有可能产生科学创新？</td>
<td>相对于男性，女性引入了更遥远的新奇事物。 然而，这种语义上遥远的新颖性在该学科中很少受到关注。</td>
<td>能够追踪新概念组合的概念距离，使学者不仅可以研究是否做出了新组合，还可以研究这些组合的语义距离最终如何影响其影响。</td>
</tr>
<tr>
<td>3.<strong>概念X性</strong></td>
<td><a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B94">劳森等人。(2022)</a></td>
<td>性别刻板印象：男性（而非女性）与以成就为导向的代理特征（例如自信和果断）相关的程度。</td>
<td>雇用女性首席执行官和董事会成员是否与组织对代理语言的性别使用发生变化有关？</td>
<td>当组织雇用女性首席执行官和董事会成员时，女性的语义与代理的语义变得更加一致。</td>
<td>对 22 家标准普尔 500 强公司的 43,000 多份文件（包含超过 12 亿字）进行分析，深入细致地研究女性的含义如何因聘用女性领导者而发生变化。否则这样的分析是不可能的。</td>
</tr>
<tr>
<td><strong>4.概念意义</strong></td>
<td><a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B63">汉密尔顿等人。(2016)</a></td>
<td>词语的文化意义：词语的含义随时间变化的程度。</td>
<td>语义演化的可能驱动因素是什么？</td>
<td>跨历史时期的语义变化率与词频的逆幂律成正比。 与频率无关，具有更多含义的单词具有更高的语义变化率。</td>
<td>能够探索跨多个知识和文化领域的大型历史时期和大量文本中的语义变化。例如，他们可以详细追踪同性恋这个词的含义如何从<em>快乐</em>和<em>艳丽</em>等概念转向<em>同性恋</em>和<em>女同性恋</em>等概念。</td>
</tr>
<tr>
<td>5. <strong>文化和知识连续体中的概念立场</strong></td>
<td><a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B89">科兹洛夫斯基等人。(2019)</a></td>
<td>社会阶层标记：区分社会阶层维度的概念。</td>
<td>20世纪社会阶级的标志是如何变化的？</td>
<td>尽管社会阶级维度在历史上保持稳定，但阶级文化标记在每个维度中的定位方式却不断发生变化（例如，员工从士兵和肌肉等概念转变<em>为</em>白领<em>和</em>中产阶级<em>等</em>概念*）*。</td>
<td>能够将文化相关的概念投射到文化相关的兴趣连续体上，从而使研究人员不仅可以在单个历史时期内而且可以在其历史演变过程中了解广泛共享的社会关联。</td>
</tr>
<tr>
<td>6. <strong>概念维度</strong></td>
<td><a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B89">科兹洛夫斯基等人。(2019)</a></td>
<td>阶级的文化维度：理解社会阶级的维度（富裕、教育、修养、地位、就业、道德、性别）</td>
<td>20 世纪文化阶层的规模有多稳定？</td>
<td>20世纪，尽管发生了巨大的经济转型，阶级规模仍然非常稳定。</td>
<td>能够对阶级的多个概念维度进行实证分析，从而理解 20 世纪美国它们之间的相互关系。</td>
</tr>
</tbody>
</table>
<br>
<h3 id="51-概念广度">5.1 概念广度</h3>
<h4 id="511-指标">5.1.1 指标</h4>
<p><strong>可以测量文档中单词之间的距离来计算它们在概念空间中的分布范围</strong>。文档可以是从专利到个人电子邮件通信的任何内容。我们可以测量每个单词与其他单词的平均距离有多远。<strong>获取文档内元素的平均距离（或每个单词与文档质心之间的距离）可以衡量该文档内的「概念宽度」</strong>。例如，我们衡量每项专利的概念广度， 可以从两个简单的文档开始，</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">doc1 =  [&#34;biochemistry&#34;, &#34;chemistry&#34;, &#34;analytical_chemistry&#34;]
doc2 =  [&#34;chemistry&#34;, &#34;oceanography&#34;, &#34;computer&#34;]
</code></pre></div><p>使用我们的专利嵌入模型，我们得到第一组(doc1)的平均宽度为 29，第二组（doc2）平均宽度为 47。这表明第二组在概念上比第一组更广泛。</p>
<p>当我们衡量文档集合而不是单词的概念广度时，同样的逻辑也适用。例如，我们想了解发明者团队的广度。在这种情况下，我们可以将团队中的每个发明人视为嵌入概念空间中的“文档”，参考如图<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#F1">1</a> , 从下往上，依次是词概念空间、发明人概念空间、团队概念空间、组织概念空间。一个发明人团队的成员已经在涉及纳米技术、生物技术和软件的概念空间领域发表了先前的专利，那么在概念上将被认为比所有成员只发表了纳米技术专利的团队更广泛。即使所有发明人都将其公开的专利限制在一个类别内，该指标仍然会提供显着的变化。</p>
<p><img loading="lazy" src="img/figure-1.jpeg" alt=""  />
</p>
<br>
<h4 id="512--应用">5.1.2  应用</h4>
<p>这种概念广度的度量已在最近的工作中用于追踪各种理论构念。<strong><a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B105">利克斯等人。(2022)</a>衡量团队成员在参与软件项目的不同阶段时的 话语广度</strong>。<strong>他们能够追踪每个独特项目阶段概念参与的多样性，发现表现最好的团队有能力改变他们的认知以适应手头不断变化的任务，在提出新想法时表现出更大的话语广度，而在转换时表现出较低的广度依赖于协调的任务。这种细粒度的知识参与概念很难用以前的文本分析方法来追踪</strong>。 详细内容可阅读大邓近期推文 <a href="https://textdata.cn/blog/2023-11-02-measure-cognitive-diversity-through-language-discursive-diversity/">MS2022 | 使用语言差异性测量团队认知差异性</a> 。</p>
<p>另外，研究人员使用概念广度来追踪在线社区成员根据状态变化分配注意力的范围，发现状态和注意力广度之间存在 U 形关系（Aceves et al. 2022 <a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B2">）</a>。这些研究人员训练了 150 个知识领域的概念空间，从而能够追踪不同知识领域的相似注意力动态，从计算机编程和数学到育儿和园艺。由于他们有能力在数百个社区的文本中大规模部署算法，因此他们能够计算出超过 2000 万成员如何在这些问答社区上发布的 2300 万个问题中分配注意力。</p>
<p>其他工作在整个语言中实施了这种方法，追踪语言在所有知识领域具有更宽或更窄的概念空间的程度（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B1">Aceves 和 Evans 2021</a>）。使用圣经、电影字幕和以多种语言编写的政治文件等文本的并行翻译（包含相同的信息但以不同的语言编码），他们能够追踪概念在不同语言中相互关联的程度存在显着差异。他们发现，尽管一些语言将不同的概念子空间紧密地联系在一起，并将不同的概念领域编织在一起，但其他语言却稀疏且更加支离破碎，更强烈地分隔了不同的意义域。然后，他们观察概念空间的语言密度如何塑造数百种语言的真实对话和维基百科文章的概念广度。</p>
<p>所有三篇论文都为不同文献的研究开辟了新的理论途径，例证了该方法的潜力。如果没有概念空间的概念及其通过嵌入模型的表示，这些新的研究途径将很难实施。</p>
<br>
<h3 id="52-概念距离和相似度">5.2 概念距离和相似度</h3>
<h4 id="521-指标">5.2.1 指标</h4>
<p>当我们的分析重点在于集合内的元素时，前面描述的概念广度构念是相关的。当我们的分析重点是不同集合之间的关系时，可以使用相同的基础度量。在这种情况下，我们将指的是概念距离或相似性，而不是概念广度。<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#fn14">13</a>形式上，如果我们有至少两个集合，每个集合中至少有一个元素，我们可以计算这些集合之间的<strong>概念距离，作为每个集合的质心或多维平均值之间的距离</strong>。最基本的是，我们可以计算两个集合之间的概念距离，每个集合包含一个单词。这无非是衡量这些词之间的概念距离。随着元素数量和集合数量的增加，底层计算保持不变，但理论可能性的范围扩大。还可以通过训练文档嵌入模型来计算这种距离/相似性度量，该模型在嵌入空间中为每个文档分配一个向量，其权重按照单词共现的相同逻辑进行训练（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B96">Le 和 Mikolov 2014</a>），将文档本身视为文档中的另一个单词，将这些单词用作与其共现的单词。</p>
<p>通过将概念相似性与衡量专利相似性的现有技术进行比较，我们可以一睹该衡量标准的潜力。首先，研究人员可以通过查看专利授予机构使用的官方分类来追踪专利的相似性，同一类别的专利被认为比不同类别的专利更相似（Singh 和 Marx 2013，Aharonson 和<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B157">Schilling</a> 2016 <a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B3">）</a>）。这种方法的局限性在于分类度量是粗粒度的，并且不太可能考虑所有相关的技术特征，特别是当类别边界必然滞后于技术进化时（Thompson 和 Melanie Fox-Kean 2005，Singh<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B172">和</a>Agrawal <a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B155">2011</a>，<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B7">Arts 等人，2018</a>）。其次，研究人员可以获取两项专利并测量它们之间的单词重叠（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B7">Arts et al. 2018</a>）。然而，这种方法是有限的，因为它仅适用于成对的文档，无法确定专利相对于整个知识体系的位置。</p>
<p>概念相似性解决了这些限制（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B184">Whalen 等人，2020</a>）。首先，它允许我们追踪专利在相关知识空间中的精确位置，从而访问知识系统中的所有相关的细粒度信息。其次，我们能够精确量化任何专利或专利组相对于任何其他专利或专利组的位置。<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#fn15">14</a>第三，随着新知识进入系统，知识的性质和结构不断演变，随着时间的推移重塑 <strong>概念边界</strong> 和关联。<strong>嵌入使我们能够衡量专利发布时存在的概念空间内的专利相似性，使我们能够摆脱使用滞后的、周期性偏离的类别，并可能对连续的发明概念空间强加类别差异</strong>。概念距离的所有这些优点都适用于其他知识和文化领域，在这些领域中，我们寻求测量思想、个人、群体或组织之间的距离或相似性，从而扩展现有的跨研究领域并开辟新的理论领域。</p>
<h4 id="522-应用">5.2.2 应用</h4>
<p>正如我们上面所做的那样，这种<strong>概念相似性的衡量方法最近被用来描述专利数据中的创新空间</strong>（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B184">Whalen 等人，2020</a>）。研究人员使用  <strong>doc2vec</strong>  框架计算了超过 6 亿个专利对的相似度。在生成这些知识相似性度量时，作者还使用这些分数提出了有趣的辅助度量，包括可操作的度量（a）现有技术接近度——专利引用与其自身相似或不相似的现有技术的程度，（b）现有技术同质性——一项专利引用知识空间领域彼此远离的程度，(c) 影响邻近性——一项专利被与其自身相似或不相似的未来专利引用的程度，以及(d) 影响同质性——一项专利通过其前向引用与一组不同的未来专利相关的程度。</p>
<p>学者们也使用了这一衡量标准，重点关注概念距离。<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B18">伯奇等人。(2021)</a>使用概念距离的 <strong>doc2vec</strong> 实现来调查同行奖励是否会影响在线社区内贡献的新颖性。这里的<strong>新颖性是根据社区成员获奖前后贡献的距离来衡量的</strong>。作者发现，获奖后，奖项会导致知识空间内的新颖性减少，剥削行为增多。同样，<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B74">霍夫斯特拉等人。（2020）</a>使用 Word2Vec 距离度量来捕获科学论文将新颖性引入科学文献的程度，发现来自代表性不足群体的学生负责将最具新颖性引入系统。</p>
<p>其他人则利用这一措施来实施公司差异化。在发展中国家微型企业的背景下，<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B20">Carlson（2022）</a>使用 BERT 架构（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B35">Devlin et al. 2019</a>，<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B142">Reimers and Gurevych 2020</a>）来计算其数据集中所有微型企业的成对余弦距离。通过这些距离，他们能够估计八个发展中国家的 10,000 家微型企业的差异化与收入和利润的增加相关。同样，<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B61">Guzman 和 Li（2023）</a>使用距离的 doc2vec 实现来使用 Crunchbase 数据来衡量初创公司的创始战略差异化。作者发现与<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B20">Carlson (2022)</a>类似的结果，即差异化经验的新公司在早期融资和股权结果方面有所增加。</p>
<br>
<h3 id="53-概念x">5.3 概念X</h3>
<h4 id="531-指标">5.3.1 指标</h4>
<p>文档距离的另一个用途是追踪语料库中的任何文档与捕获感兴趣的构念X的焦点(原型）的相似性， 这样的测量将捕获任何观察的 <strong>概念X性</strong>( Conceptual X-ness)。这种测量的第一步是描述与我们寻求尽可能精确测量的结构相关的概念信息。例如，如果我们想要捕获专利与 <strong>时间</strong> 或 <strong>几何</strong> 等概念相关的程度，我们可以构建一个我们认为映射到、定义或与这些概念相关的单词列表 。对于每个列表，我们计算其质心向量 (c#27)，然后测量任何给定专利距离 <strong>时间</strong> 和 <strong>几何</strong> 概念有多远。<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#fn16">15</a> 对于附录表 A2 中使用的专利，我们可以看到，与头颈约束装置专利相关的前两项专利更接近时间概念，正如所预期的那样光和时间在概念上交织的程度。概念性的<em>X</em>度度量可用于追踪思想、个人、团体、组织或任何其他相关聚集的组成。</p>
<h4 id="532-应用">5.3.2 应用</h4>
<p>最近在一篇论文中使用了这种方法，该论文追踪了雇用女性担任高级领导角色对女性在这些组织中意味着什么的影响（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B94">Lawson 等人，2022</a>）。作者首先使用 SEC 文件和财报电话会议记录训练了 Word2Vec 嵌入。然后，他们创建并验证了一组 100 个单词来捕捉 <strong>代理概念</strong> 的含义（例如，有能力、独立、主导），并观察了内部任命高级女性领导前后 <strong>代理概念</strong> 与 <strong>女性</strong> 概念之间的距离。该组织发现，在 <strong>女性</strong> 被任命为高层管理人员之后的一段时间内，女性的含义在概念空间中更加接近于机构职位。作者使用不同的嵌入超参数和维度大小复制了他们的结果，说明了嵌入模型的鲁棒性，条件是具有捕获概念空间内语义变化的最小必要维度。</p>
<p>这里有趣的理论机会包括更深入地参与理论传统的可能性，这些理论传统在组织科学以外的领域具有影响力，但由于缺乏可行的方法来以原则性的方式量化其理论构造，因此这些理论传统仍然处于我们的领域之外。依赖文学解释。正如我们所提出的，测量 <strong>概念X性</strong> 使得扩大与理想形式（* <a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B134">Plato Bloom 1968</a>）、理想类型（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B178">Weber 2011</a>）、家族相似性（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B186">Wittgenstein 2010</a>）和原型（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B147">Rosch 1973</a>）相关的理论构造的测量成为可能。以一致、有原则和可复制的方式。在这方面，概念性的<em>X</em>性代表着开放大量的认知和社会理论，以便在组织的背景下进行实证检验和扩展。</p>
<br>
<h3 id="54-语义转变和漂移">5.4 语义转变和漂移</h3>
<h4 id="541-指标">5.4.1 指标</h4>
<p>概念空间使我们能够识别术语的含义如何随着时间和空间的变化而变化。探索概念意义的一种方法是为不同的个人、公司、行业、地理位置或时间段创建独特的嵌入模型，以了解它们之间的含义有何不同（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B148">Roy 等人，2019 年</a>；<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B181">Welch 等人，2020a</a>，<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B182">b</a>）。一旦识别出相关的兴趣分歧，我们就可以采用相关的语料库（例如，专利、财报电话会议、报纸）并为数据中的每个语料库训练概念空间。<strong>在我们的专利示例中，我们可能会训练两种嵌入模型，一种是 1990 年功能性磁共振成像技术发明之前的时期，另一种是 1990 年之后的时期</strong>。然后我们可以探索与大脑和神经科学相关的概念的含义如何随着这一创新而改变。例如，在功能性磁共振成像发明之前和之后与不同大脑区域最相关的术语是什么。接下来，我们可以比较不同公司或国家的含义变化有何不同，以及这种变化的格局如何影响所涉及的公司和行业的组织和市场结果。显式动态词嵌入允许嵌入之间具有更大的可比性，但必然会忽略特殊的词和用途（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B63">Hamilton et al. 2016</a>、<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B192">Zhang et al. 2016</a>、<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B190">Yao et al. 2018</a>、<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B103">Liu et al. 2020</a>）。这些算法的输出带有时间戳词向量包含特定时期的语义信息，但在历史上保持可比性。</p>
<br>
<h4 id="54-2-应用">5.4. 2 应用</h4>
<p>第一篇在社会科学背景下使用词嵌入方法的主要论文就是使用这种方法来研究意义（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B63">Hamilton et al. 2016</a>、<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B19">Caliskan et al. 2017</a>、<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B49">Garg et al. 2018</a>、<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B89">Kozlowski et al. 2019</a>）。在第一篇论文中，研究人员使用四种语言的六个历史语料库，通过观察概念空间中最近的单词在过去几十年中如何变化来追踪单词含义随时间的变化（Hamilton et al. 2016 <a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B63">）</a>。使用 Word2Vec 嵌入，他们追踪了 <strong>同性恋</strong>  概念的含义如何从 1900 年代围绕 <strong>“愚蠢”</strong>、**“甜蜜” **和 **“开朗”  **等术语的含义转变为围绕 1950 年代 <strong>“嬉闹”</strong>、 <strong>“机智”</strong> 和 <strong>“聪明”</strong> 等术语的含义，并且最终以 20 世纪 90 年代女同性恋、双性恋和同性恋等术语的含义结束。在另一篇论文中，研究人员研究了词嵌入中的刻板关联之间的关系及其与当代社会经验数据的关系（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B19">Caliskan et al. 2017</a>）。例如，他们追踪了职业的性别刻板印象，发现职业具有女性意义，因为它们与女性参与劳动力市场相关。在另一项研究中，<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B49">Garg 等人。(2018)使用预先训练的 Google News Word2Vec 模型（ </a><a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B4">Google 2013</a> ）量化了美国 100 多年历史中的性别和种族刻板印象，阐明了不同的形容词和职业如何或多或少地与不同人群（例如，男性与女性）密切相关，白人与亚洲人与西班牙裔）随着时间的推移。</p>
<p>最近通过词嵌入追踪含义的工作已经使用这种方法更深入地研究了特定的上下文。一项研究使用 19 世纪第一人称叙述的语料库来追踪黑人和白人男性和女性的交叉身份如何映射到五个社会机构，包括政治、经济、文化、家庭领域和权威关系（Nelson 2021 <a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B120">）</a>。<strong>举论文中的一个例子，作者测量了与“精致”概念的距离，发现它与白人女性的联系最密切，而与黑人男性的联系最少</strong>。</p>
<p>在其他工作中，研究人员利用这种方法来衡量政治领导人的 <strong>集体意向性</strong> （人们参与集体推理和行动的能力），并比较共和党和民主党领导人如何以不同的方式动员集体意向性（Kirgil and Voyer 2022 <a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B85">）</a>。他们通过创建复数代词（我们，我们的）、复数常量（国家名称）和复数名词（人）的复合列表来测量集体意向性。然后，使用词嵌入模型，他们找到了各州集体意向向量最接近的术语，使他们能够比较不同领导人如何不同地动员集体意向。总的来说，这些意义研究表明，就语言为我们提供了解文化的窗口而言（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B55">Goldberg et al. 2016</a>、<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B165">Srivastava et al. 2018</a>、<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B26">Corritore et al. 2020</a>），嵌入模型为我们提供了一种独特的表达方式透过那扇窗户看到的照片。</p>
<br>
<h3 id="55-文化和知识连续性中的概念地位">5.5 文化和知识连续性中的概念地位</h3>
<h4 id="551-指标">5.5.1 指标</h4>
<p>另一种新颖的测量方法可以通过追踪概念相对于感兴趣的概念维度的位置来创建。如前所述，嵌入模型可用于解决类比推理任务，例如**“国王”-“男人”+“女人”=“女王”<strong>。 该架构可用于定义概念空间内任何感兴趣的维度。<strong>在国王-王后的例子中，性别维度通过“男人”-“女人”和“国王”-“女王”向量进行操作。</strong><a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B89">科兹洛夫斯基等人。（2019）</a>详细介绍了如何在概念空间内构建此类维度。首先，研究人员需要确定感兴趣的维度。对于我们这里的例子，我们将把不同的概念投射到男性-女性性别维度上。为此</strong>，我们首先确定定义性别维度的相关术语**。这里我们使用集合 [&lsquo;man&rsquo;, &lsquo;him&rsquo;, &lsquo;he&rsquo;, &lsquo;male&rsquo;, &lsquo;men&rsquo;] 和 [&lsquo;woman&rsquo;, &lsquo;her&rsquo;, &lsquo;she&rsquo;, &lsquo;female&rsquo;, &lsquo;women&rsquo;]。 <strong>然后我们计算不同概念在这个男性-女性概念轴(维度)上的正交投影。</strong> 在线附录中的图 A4 将每个概念投射到 <strong>男性-女性概念轴</strong>。 更消极的预测表明与女性气质的关联更强，而更积极的预测表明与男性气质的相关性相当。如图 A4 所示，这些预测与关于这些概念的性别状态的一般直觉一致，使我们能够明确说明每个概念相对于其他概念在这个维度中的位置。正如预期的那样，<strong>军事</strong> 和 <strong>农业</strong> 与 <strong>男性气质</strong> 的联系最为密切，而 <strong>卫生棉条</strong> 和 <strong>口红则</strong> 与 女性气质的联系最为密切。按照这个程序，学者们现在可以测量任何概念在任何感兴趣的维度和任何文本丰富的时空背景中的位置。此外，不同语言的语料库可以独立训练和对齐，或者同时训练和对齐，以方便国际分析（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B81">Johnson et al. 2017</a>，<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B116">Milbauer et al. 2021</a>）。</p>
<p><strong>双极概念维度的投影方法可以进一步扩展到锚定具有多种含义的低维子空间，其中单词和概念可以被绘制并理解为这些含义的混合</strong>。这可以通过理论上选择“原型”的集合来执行，即具有已知且广泛共享含义的极值点，并在这些极值锚定义的子空间中绘制所有相关单词或概念。[例如，在对一个新的基于信息技术的创业企业进行分类时，人们可能会问它在 Uber、亚马逊、谷歌或比特币所刻画的空间中适合什么位置(Breiman 1994，Eugster 2012，Damle 和 Sun 2017）。</p>
<br>
<h4 id="552-应用">5.5.2 应用</h4>
<p>这项措施的制定和运用是为了研究 20 世纪和 21 世纪社会阶层的演变（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B89">Kozlowski 等人，2019</a>）。他们研究了根据 20 世纪出版的数百万本书的文本训练的嵌入，按照上述程序操作了阶级的维度，试图了解社会阶级的底层维度在 20 世纪是如何变化的。为此，他们提出了以下理论上的<strong>概念轴(维度)</strong>：富裕程度（富人与穷人）、教育程度（受过教育与未受教育）、修养（有教养与未受教育）、地位（有声望与无声望）、道德（善与恶）、就业（雇主-雇员）和性别（男人-女人），分别嵌入 20 世纪的每个十年。然后，他们可以在这些维度上投射不同类别的概念，例如音乐风格、体育和职业，以了解这些概念在本世纪的过程中如何演变和发展。<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B6">研究人员应用这种方法来研究健康、道德（ Arseniev-Koehler et al. 2022</a>）、政治意识形态（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B171">Taylor and Stoltz 2021</a>）和地位（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B129">Peng et al. 2021</a> ）等背景下的其他类型的文化关联。</p>
<p>研究人员不仅将概念投射到这些概念轴(维度)上，而且将整个文档投射到这些维度上，从而推动了测量的可能性（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B170">Taylor 和 Stoltz 2020</a>）。此外，尽管以前的措施依赖于研究人员指定感兴趣的连续体的相关维度，但最近的工作已经转向自动识别这些连续体（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B116">Milbauer et al. 2021</a>）。<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B116">Milbauer 等人</a>利用 Reddit 社区的内容。<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B116">（2021）</a>创建了一个无监督的程序来识别社区中的多个意识形态极点，使他们能够超越静态的左右意识形态维度，发现现代话语中发挥作用的许多两极分化和意识形态差异的轴。人们可以想象在许多组织环境中使用这种方法来识别团队、小组、单位或部门之间存在的许多潜在冲突来源。</p>
<br>
<h3 id="56-概念维度">5.6 概念维度</h3>
<p>之前，我们讨论了研究人员如何调查关键术语在相关文化维度上的位置，描述概念的位置在性别维度上的差异。然而，这并不是概念轴(维度)的唯一用途，因为概念空间还允许我们测量和理解相关维度本身如何相互关联。该措施的扩展是使用空间内的编码维度并将它们相互比较。例如，<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B89">科兹洛夫斯基等人。（2019）</a>利用他们既定的阶级维度来追踪整个 20 世纪每个维度如何与其他维度相关，例如，表明随着世纪的发展，富裕与教育的关系变得更加密切，而与教育的关系无关。栽培。通过这种方式，组织学者可以理解相关维度之间的关系在相关概念空间中可能有何不同。例如，学者可以研究不同文化维度在组织或行业内部和之间紧密或松散联系的程度。</p>
<p><br><br></p>
<h2 id="六讨论">六、讨论</h2>
<p>最后，我们简要讨论了一些利用嵌入模型进行思考的新兴方法，然后讨论了我们认为理论、方法论和组织的有价值的机会，这些机会源于将这些模型理解为概念空间的细粒度表示。这个讨论必然是说明性的，但暗示了现在这些精致的意义模型的可操作性的广泛可能性。</p>
<h3 id="61-词嵌入方法的富有成果的扩展">6.1 词嵌入方法的富有成果的扩展</h3>
<p>词嵌入的底层计算架构最近经历了扩展，可以在与之前讨论的不同方向上动员组织研究。我们简要提到三个，并在在线附录中提供更详细的描述。首先，概念和语言的层次结构在“直线”、欧几里得几何中很难得到体现，需要许多难以理解的维度来用标准嵌入来捕获。然而，层次结构可以用负弯曲双曲嵌入来原生表示（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B90">Krioukov et al. 2010</a>，<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B126">Papadopoulos et al. 2012</a>，<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B22">Chamberlain et al. 2017</a>，<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B121">Nickel and Kiela 2017</a>），为探索复杂现代的交叉层次结构提供了新的测量可能性。组织。例如，将公司名称嵌入双曲空间中将能够直接发现典型的“中心公司”，并在商业新闻语料库中与所有其他公司进行比较。额外的双曲维度将揭示子层次结构，反映商业评论员所持有的概念和比较价值的不同维度。</p>
<p>其次，模型语言的深度学习方法为词嵌入增加了关键的上下文敏感性。考虑像 BERT ( <a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B35">Devlin et al. 2019</a> ) 和 GPT 系列模型 ( <a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B140">Radford et al. 2019</a> ) 这样的大规模模型，它们使用“注意力”的神经网络机制来识别影响焦点词含义的上下文词 ( <a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B176">Vaswani ) et al. 2017</a>），组装成一个称为转换器的架构，可以将问题转换为答案，将文本转换为翻译，将请求转换为响应。这种模型产生的内容可以被描述为上下文嵌入，这样每个单词不是由单个向量表示，而是由向量云表示，每个向量代表不同上下文中的该单词。“google”上下文中的“Apple”与“orange”上下文中的“apple”具有不同的值。这些模型极大地提高了预测能力，并进一步扩展了我们对概念空间进行精确建模的能力，但代价是复杂性和计算量更大。</p>
<p>最后，嵌入架构可以扩展到在序列或更高维上下文中排列的任意符号集。例如，图像已被用来衡量抽象艺术图像的新颖性和创造力（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B10">Banerjee and Ingram 2022</a>，<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B11">Banerjee and Kaplan 2022</a>），分析警察预约照片（大头照），并识别与司法拒绝保释相关的先前未概念化的紧急特征听证会（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B107">Ludwig 和 Mullainathan 2022</a>）。<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B101">音乐（ Liang et al. 2020</a>）、音频剪辑（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B70">Hershey et al. 2017</a>、<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B189">Xie and Virtanen 2019</a>）和视频（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B191">Zellers et al. 2021</a> ）的多维空间是使用audio2vec（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B168">Taglisacchi et al. 2020</a>）等工具构建的。 、signal2vec（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B118">Nalmpantis 和 Vrakas 2019</a>）和 video2vec（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B62">Habibian 等人 2017</a>），为组织学者接触代表组织生活视听体验的新型媒体打开了大门。</p>
<p>最近对双曲线、上下文、图像和音频嵌入的扩展表明，嵌入模型的底层计算框架的持续改进和扩展将继续下去，为组织科学中持续的实证、测量和理论创新奠定了基础。</p>
<br>
<h3 id="62-词嵌入和组织理论">6.2 词嵌入和组织理论</h3>
<p>在理论层面上，将嵌入模型理解为概念空间的有原则的、细粒度的表示有可能刺激新的理论发展并完善现有理论。例如，意义研究中的经典陈述影响了文学理论和文化社会学等其他领域，但未能在组织科学中站稳脚跟。自20 世纪初德索绪尔 ( <a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B32">de Saussure 1986</a> )的著作带来语言学的结构转向以来，许多人都试图将意义在组织和社会生活中的作用理论化。列维-斯特劳斯汇集了来自全球各地的多样而广泛的民族志，以向世界文化所特有的表面混乱提出深层的文化秩序，并认为复杂的意义是从有意义的元素的结合中产生的（列维-斯特劳斯 2016 <a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B99">）</a>。福柯理论化了话语和权力如何紧密相连，权力和知识如何以自我强化的联盟结合在一起（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B46">Foucault 2012</a>）。<em>布迪厄将惯习</em>的概念阐述为“持久的、可互换的处置系统，倾向于充当结构结构的结构化结构，即作为实践的生成和结构的原则”（Bourdieu 1977，第72页<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B16">）</a>。尽管这些理论很有吸引力，但迄今为止它们只能进行松散且间接的测试。如果没有可靠的实证立足点，他们就永远无法在管理和组织理论中取得突出地位。然而，概念空间的实证操作化现在使得这些文化理论基础著作的参与和扩展变得容易处理，其中的许多结构现在可以辩护地测量。嵌入模型将使这些理论与管理和组织理论相关。</p>
<p>我们还希望嵌入模型能够对现有理论框架进行更深入的研究和锐化。一组能够受益的文献是那些与知识相关的文献。鉴于组织学者可以获得的大部分知识都被编码在语言的符号概念系统中，现在可以通过更多可用的文本数据源来获取知识，并且可以通过嵌入模型的概念空间来表示。材料科学领域的最新工作已经使用此类模型来有效预测未来的知识发现，比科学家提出的知识发现早几十年（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B173">Tshitoyan 等人，2019 年</a>；<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B161">Sourati 和 Evans，2021 年</a>）。其他工作表明，这些发现可以推广到生物和物理科学（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B154">Shi 和 Evans 2023</a>）。概念空间的明确表示可以对整个社会系统中知识的特征和结构进行详细的调查。一方面，这些模型就像望远镜一样，打开了知识的天空，使其大规模结构变得可见，以供研究、理论发展和完善。另一方面，这些模型充当显微镜，使我们能够更深入地观察构成更大知识系统的意义原子结构。测量方面的这一进步将丰富对定义人类和组织经验的大型多维知识系统中的机制的测试。它还将使我们能够递归地评估管理和组织奖学金的知识，从而刺激创新。</p>
<br>
<h3 id="63-词嵌入和实证研究">6.3 词嵌入和实证研究</h3>
<p>在<em>实证层面</em>，词嵌入模型可以提高组织科学不同领域的测量保真度，从而在实证结果与理论主张和框架之间实现更好的映射。我们用团队和群体内部多样性研究的例子来说明这一点。据说，不同群体所获得的许多好处是由于群体中的个人代表问题和解决方案的方式不同而产生的（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B75">Hong 和 Page 2004</a>）。由具有不同方法的个人组成的小组将更好地执行各种任务，因为他们将拥有更广泛的知识、观点和可供借鉴的信息资源（Cox et al. 1991，<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B27">Williams</a> and <a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B185">O&rsquo;Reilly 1998</a>）。然而，由于测量困难，对团队多样性的研究很少测量问题和解决方案空间的不同概念。相反，它假设解决问题的团队成员的身份多样性（人口、文化、种族或经验）与其功能多样性（团队成员如何代表和解决问题）之间存在联系（Nisbett 和 Ross 1980，Hong<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B122">和</a>Page <a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B75">2004</a>，<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B175">van Dijk 等人，2017</a>）。</p>
<p>由于缺乏高保真方法来访问团队成员在问题和解决方案的概念空间中的位置，因此通常假定身份和功能多样性之间存在联系。用于操作研究的身份多样性和用于理论化的功能多样性之间脱节的一个重要后果是，虽然理论积极使用功能多样性的思想和术语（从根本上讲是几何和高维的），但测试依赖于集合-与身份成员资格相关的理论概念。<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B175">我们预测，这将解释团队多样性文献（ van Dijk et al. 2017</a> ）结果中的大部分歧义，因为研究设计忽视了功能多样性和身份多样性之间的同源性。然而，诸如概念广度之类的衡量标准可以阐明这一理论交叉点上的悬而未决的问题。我们现在可以指定（1）团队的基本概念广度，以及（2）这种基本广度可能驱动结果的程度。解决这些问题可以为许多分析层面的研究提供信息，从个人和团队的成功（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B164">Srikanth 等人，2016 年</a>，<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B175">van Dijk 等人，2017 年</a>）到公司和行业绩效（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B144">Roberson 等人，2017 年</a>）。我们希望我们的插图能够激发在组织研究领域生成细粒度意义测量的新可能性。</p>
<br>
<h3 id="64-组织内部的词嵌入">6.4 组织内部的词嵌入</h3>
<p><strong>最后，我们认为词嵌入方法将对我们研究的组织产生影响</strong>。我们说明了在劳动力市场背景下潜在的嵌入必须塑造组织行为。从招聘到工作设计，从培训到晋升，人力资源管理的一个核心挑战是有效地将个人与组织内的角色、工作、情况和任务相匹配（Weller et al. 2019 <a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B183">）</a>。随着比赛质量的提高，各种绩效指标也会提高，包括工作满意度（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B8">Ashforth 和 Saks 1996</a>）、个人生产力（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B125">Paauwe 2009</a>）和组织绩效（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B38">Dyer 和 Reeves 1995</a>）。有效匹配的一个问题是不同维度的匹配的重要性程度。在一家公司中，技能可能最为重要，而在其他公司中，技能可能是文化契合度、态度、技能和经验的相互作用。由于嵌入模型捕获了所有这些维度，管理者可以为每个相关维度嵌入不同的原型描述，同时还嵌入个人资料和其他相关通信（例如电子邮件、松弛消息等），以衡量每个人与每个相关维度之间的匹配接近度。这样做可以让管理者更好地识别高维匹配及其对员工、社区和公司绩效的影响。</p>
<p>嵌入模型旨在为人力资源的宏观管理提供新的视角（<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B183">Weller et al. 2019</a>）。来自大型组织的相关信息存储在人力资源经理、一线经理、员工、同事和外部招聘人员中。然而，无法集中访问这些信息。通过嵌入，组织可以从所有数字面包屑的文本（电子邮件、聊天、工作描述、正式报告、绩效管理记录等）构建概念空间。这样做并使用相似性分析将使公司能够绘制和了解相关人力资本的位置位于公司对面。管理人员可以利用这些系统来准确了解任何员工的概念职位与任何给定的公司要求的差距有多大。这不仅可以为招聘、雇用、员工流动和流动等流程提供信息，还可以为培训、社交、工作设计和公司重组提供信息。因此，在劳动力市场和组织适应的背景下，嵌入模型可以产生有用的创新。人们可以想象许多其他组织实践和结构可以从这些模型及其测量可能性中受益，包括产品设计、市场分析和战略生成。</p>
<p><br><br></p>
<h2 id="结论">结论</h2>
<p>我们同意<a href="https://pubsonline.informs.org/doi/full/10.1287/orsc.2023.1686#B65">Hanan等人的观点。（2019</a>，第 2 页）当他们观察到，考虑到概念和分类对几乎所有人类行为和社会互动的中心地位，人们对概念如何运作的关注如此之少，这是多么令人惊讶。现代组织内部及其周围进行的许多活动都需要概念信息的激活和传播。当一个人解决新问题、提出新想法或与他人合作时，就会发生这种情况。从围绕饮水机的良性闲聊到重新配置全球资本主义秩序或将人类登陆火星，概念及其所嵌入的概念空间发挥着核心、关键的作用。</p>
<p>正如本文所示，我们现在拥有一系列重要的工具，可以为广泛而深入的理论想象和实证研究打开<strong>概念世界</strong>和<strong>概念空间</strong>。我们希望本文能够激发对嵌入可以提供信息的大量问题和理论的学术探索。</p>
<p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>MS2022 | 使用语言差异性测量团队认知差异性</title>
      <link>https://textdata.cn/blog/2023-11-02-measure-cognitive-diversity-through-language-discursive-diversity/</link>
      <pubDate>Thu, 02 Nov 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-11-02-measure-cognitive-diversity-through-language-discursive-diversity/</guid>
      <description>&lt;p&gt;词嵌入在经管中的应用很多，但大多数是训练词嵌入模型，依据词嵌入构建或扩展词典。 今天我们将分享一篇用词嵌入测量团队认知多样性。&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/paper-cover-discursive-diversity.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;h2 id=&#34;一研究&#34;&gt;一、研究&lt;/h2&gt;
&lt;p&gt;Lix, Katharina, Amir Goldberg, Sameer B. Srivastava, and Melissa A. Valentine. &amp;ldquo;&lt;strong&gt;Aligning differences: Discursive diversity and team performance.&lt;/strong&gt;&amp;rdquo; &lt;em&gt;Management Science&lt;/em&gt; 68, no. 11 (2022): 8430-8448.&lt;/p&gt;
&lt;h3 id=&#34;11-摘要&#34;&gt;1.1 摘要&lt;/h3&gt;
&lt;p&gt;团队中的认知多样性如何影响其绩效？先前的研究表明，团队的认知多样性存在绩效权衡：多样性团队在创造力和创新方面表现出色，但在协调行动方面则有困难。基于团队认知不是静态的，而是动态互动产生的观点，我们引入了 &lt;strong&gt;话语多样性&lt;/strong&gt; 的概念，这是团队认知多样性的一种表现，反映了在一组互动中团队成员传达的含义在多大程度上相互不同。&lt;strong&gt;我们提出，高绩效团队是那些具有调节共享认知以适应不断变化的任务要求的集体能力的团队：在进行构思任务时，它们表现出更高的话语多样性，在执行协调任务时，表现出较低的话语多样性&lt;/strong&gt;。我们进一步认为，表现出一致调节的团队——即，在成员对不断变化的任务要求的个人语义变化中团队层面方差较低的团队——更有可能取得成功，而不是由成员之间存在不一致的调节。我们利用 &lt;strong&gt;计算语言学&lt;/strong&gt; 工具来衡量话语多样性，并借助一组新型纵向数据，包括117个在线平台 &lt;a href=&#34;http://www.gigster.com&#34;&gt;www.gigster.com&lt;/a&gt; 上的远程软件开发团队的团内电子通信和绩效结果，得出了对我们理论的支持。我们的研究结果表明，团队认知多样性的绩效权衡并非不可避免：团队可以通过将话语多样性水平与任务要求相匹配以及在进行这些调整时使成员保持一致来应对这一权衡。&lt;/p&gt;
&lt;h3 id=&#34;12-创新点&#34;&gt;1.2 创新点&lt;/h3&gt;
&lt;p&gt;这篇论文的创新点主要包括以下几个方面：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;研究了团队内部的差异对团队绩效的影响&lt;/strong&gt;：该论文通过分析团队成员之间的差异，探讨了这些差异对团队绩效的影响。这一研究角度对于理解团队内部动态和绩效提升具有重要意义。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;引入了阶段性的话语差异概念&lt;/strong&gt;：论文提出了阶段性的话语差异概念，即团队成员在不同阶段的沟通中所表现出的差异。这一概念有助于更好地理解团队内部沟通的动态过程。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;探讨了团队内部沟通差异的调节作用&lt;/strong&gt;：论文研究了团队内部沟通差异与团队绩效之间的关系，并发现团队内部沟通差异在不同阶段对团队绩效的影响存在差异。这一发现为团队管理和绩效提升提供了重要的启示。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;结合了多个学科领域的理论和方法&lt;/strong&gt;：该论文综合运用了心理学、经济学和组织学等多个学科领域的理论和方法，从多个角度深入研究了团队内部差异和绩效之间的关系，为相关领域的研究提供了新的视角和方法。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;二文献梳理&#34;&gt;二、文献梳理&lt;/h2&gt;
&lt;h3 id=&#34;21-认知多样性&#34;&gt;2.1 认知多样性&lt;/h3&gt;
&lt;p&gt;认知多样性(cognitive diversity)对团队绩效的影响是一个长期存在的问题。以往的研究表明，团队的认知多样性存在绩效权衡：多样性团队在创造力和创新方面表现出色，但在协调行动方面存在困难。然而，&lt;strong&gt;最近的研究提出了一种新的观点，即团队的「认知多样性」可以通过调节团队的「共享认知」来实现绩效的平衡。这意味着团队可以根据任务要求调整其认知多样性的水平，以在创造性任务和协调任务之间找到平衡点&lt;/strong&gt;。高绩效团队具备调节团队认知的能力，使其能够在创造性任务中展现较高的认知多样性，在协调任务中展现较低的认知多样性。这种能力使团队能够在创新和执行之间找到平衡，从而提高绩效。&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;22-话语多样性&#34;&gt;2.2 话语多样性&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;话语多样性(discursive diversity) 是指团队成员在交流和讨论中表达的观点、意见和想法的多样性程度。它反映了团队成员在思考和表达上的差异程度。话语多样性可以包括词汇选择、句子结构、表达方式等方面的差异&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;话语多样性对团队的协调行动有影响。在协调任务中，团队成员需要相互理解、协调行动，达成共识并共同努力实现共同目标。如果团队成员的话语多样性过高，意味着他们在表达观点和意见时存在较大的差异，这可能导致沟通困难、理解不一致和冲突的产生，从而影响团队的协调行动。&lt;/p&gt;
&lt;p&gt;因此，在协调任务中，团队成员的话语多样性应该相对较低，以便更好地理解和协调彼此的行动。相反，在创意和思考任务中，话语多样性可以促进团队成员的创新和思考，帮助他们从不同的角度和观点来解决问题，从而提高团队的创造力和创新能力。总之，话语多样性在团队中起着重要的作用，它需要根据任务的性质和要求进行调节，以实现团队的协调行动和创新能力。&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;23-两者关系&#34;&gt;2.3 两者关系&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;在这篇论文中，话语多样性被用来衡量认知多样性&lt;/strong&gt;。研究人员使用计算语言学的工具来推导出话语多样性的度量，并将其应用于团队的电子沟通数据中。他们认为，团队的话语多样性可以反映成员之间的认知多样性，即在思维方式、知识和技能等方面的差异程度。通过分析团队的话语多样性，研究人员试图探索团队在不同任务要求下的表现，并研究团队如何调节共享认知以适应任务需求的变化。因此，话语多样性被视为一种衡量团队认知多样性的指标。&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;三数据及方法&#34;&gt;三、数据及方法&lt;/h2&gt;
&lt;h3 id=&#34;31-数据&#34;&gt;3.1 数据&lt;/h3&gt;
&lt;p&gt;Gigster(&lt;a href=&#34;http://www.gigster.com&#34;&gt;www.gigster.com&lt;/a&gt;),是一个在线平台， 自由软件开发人员可以在该平台上为个人和企业客户制作按需软件。该平台将个人自由职业开发人员组装成由团队领导领导的临时团队，并将他们分配给需要复杂、相互依赖的长期项目。该平台上的自由职业者分布在全球各地，从事从移动到网络应用程序开发的各种项目。这些项目通常是知识密集型的，需要高水平的创造力、技术问题解决能力和人际协调能力。软件项目规模巨大，成本从数万美元到数十万美元不等（极端情况下可达一百万美元以上）。&lt;/p&gt;
&lt;p&gt;我们的数据集由 117 个团队组成，代表 421 个不同的个体（36% 为女性），时间跨度从 2015 年初到 2017 年底。一个典型的团队有 5 名成员，其中包括一名项目经理；至少一名后端、前端或“全栈”工程师；设计师；和用户界面专家。根据项目类型，团队有时还包括作家、自然语言处理工程师和其他类型的专业人士。在我们数据中的团队中，项目平均持续 159 天（中位数：150 天），并分为平均持续两周的里程碑阶段（平均：14 天；中位数：14 天）。要加入该平台，专业人士必须通过旨在验证其专业知识的各种技术面试。平均而言，单个团队的成员代表 3.6 个国家/地区（中位数：3 个）。在我们的样本中，42% 的人将其原籍国列为北美。另外 13% 来自亚洲，其次是 12% 来自欧洲。其余 23% 居住在拉丁美洲、非洲和世界其他地区。&lt;/p&gt;
&lt;p&gt;由于地理位置分散且缺乏实体办公空间，团队成员几乎完全通过名为 Slack 的在线即时通讯工具进行沟通。我们可以访问整个团队的 Slack 档案——超过 800,000 条消息。每条消息都带有时间戳并可归因（通过匿名标识符）其作者。团队在整个生命周期中平均在公共渠道中交换 1,873 条 Slack 消息（中位数：1,220 条）。我们对 Gigster 的高级领导和团队领导进行了非正式采访，他们一致表示团队沟通几乎完全通过 Slack 进行。一位高级领导描述了其中的原因：“几乎所有团队对话都发生在 Slack 上。这是一个有用的工具，因为我们运营全球团队，而且 Slack 允许在一个平台内进行实时和异步通信。它还允许轻松地共享项目文件。” 多位知情人士强调，团队成员始终依赖 Slack，而不是其他工具，因为“一切都在一个地方”对于促进团队协作非常重要。知情人士还表示，团队成员有动力使用 Slack，因为它提供了团队流程和事件的透明档案，可用于对一些罕见的争议案例进行分类。&lt;/p&gt;
&lt;p&gt;除了 Slack 消息之外，我们还可以获得有关团队成员特征（职能角色、性别和原籍国）的数据，以及团队在实现各个项目里程碑方面的整体绩效。这些数据共同构成了团队内部动态和结果的丰富且连续的历史记录。&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;32-计算话语多样性&#34;&gt;3.2 计算话语多样性&lt;/h3&gt;
&lt;p&gt;之前的工作表明，词嵌入模型对于捕获单词之间的语义关系特别有用， 例如，(2018) 证明，根据应用于 20 世纪出版的英语书籍的词嵌入模型推断出的不同职业的语义性别关联与这些职业的历史性别构成相对应。同样，科兹洛夫斯基等人(2019)说明了不同的生活方式活动如何与阶级、种族和性别认同相关。因此，词嵌入为语言中包含的众多意义维度提供了全面且有意义的见解，而这是以前的方法无法捕获的。因此，本论文使用词嵌入模型开发了话语多样性度量。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;我们首先对 Slack 数据进行预处理，并使用 Word2Vec（连续词袋词嵌入模型的流行实现）来训练词嵌入模型。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;按照标准实践，窗口大小设置为10， 维度设置成200来训练word2vec模型（&lt;a href=&#34;https://pubsonline.informs.org/doi/full/10.1287/mnsc.2021.4274#B54&#34;&gt;Mikolov 等人，2013&lt;/a&gt;）。从这个训练过程中，我们获得了语料库中每个单词的一个 200 维坐标向量，表示该单词在语义空间中的位置。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;窗口大小&lt;/strong&gt;: 每个词的上下文范围。 人阅读书籍，一般视野只有十来个词，逐行阅读。 跟人类似， 在计算机中训练词嵌入模型时候，数据不是一次性灌入习得词语的向量，而是像人一样是有上下文范围的，这个范围叫做窗口。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;如前所述，嵌入空间的维度表示训练语料库中语言使用的潜在特征。尽管这些维度本身不具有定性可解释的含义，但这些维度是提供信息的，因为具有更相似含义的单词彼此更接近。&lt;strong&gt;下图(a)是从聊天消息构建词嵌入向量的过程&lt;/strong&gt;:&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/01-compute-discursive-diverisity-with-embeddings.jpeg&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;**使用词嵌入模型，我们就可以把词语、每句话、某人某时期的话、某团队某时期的话、所有团队所有的话，通过一定的计算，都表征为200维的向量。**上图 (b) 从聊天消息构建团队话语多样性得分(Discursive Diversity)。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;通过公式1，计算出两个人差异性。通过公式2， 计算出团队话语多样性。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/03-formular-1.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/04-formular-2.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;p&gt;假设团队只有三个人， 低话语多样性 与 高话语多样性， 分别对应下图的左侧和右侧。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/02-low-and-high-examples-of-discursive-diversity.jpeg&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;四python伪码&#34;&gt;四、Python伪码&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;numpy&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;np&lt;/span&gt;

&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;discursive_diversity_score&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;words&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
    &lt;span class=&#34;c1&#34;&gt;# wv: 词嵌入模型; gensim.models.keyedvectors.KeyedVectors&lt;/span&gt;
    &lt;span class=&#34;c1&#34;&gt;# words: 一个时间窗口内的词语列表&lt;/span&gt;
    
    &lt;span class=&#34;c1&#34;&gt;# 计算词嵌入向量的平均值&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;embedding_vectors&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;word&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;word&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;words&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;centroid&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;np&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mean&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;embedding_vectors&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;axis&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
    
    &lt;span class=&#34;c1&#34;&gt;# 计算词嵌入向量之间的余弦相似度&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;pairwise_distances&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;np&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dot&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;centroid&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;embedding&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;/&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;np&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;linalg&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;norm&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;centroid&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;np&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;linalg&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;norm&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;embedding&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;embedding&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;embedding_vectors&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
    
    &lt;span class=&#34;c1&#34;&gt;# 计算语言多样性得分&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;diversity_score&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;np&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mean&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;pairwise_distances&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
    
    &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;diversity_score&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;函数 &lt;em&gt;&lt;strong&gt;discursive_diversity_score&lt;/strong&gt;&lt;/em&gt; 已内置到 cntext2.x 版本中。 对cntext2.x 感兴趣，可阅读 &lt;a href=&#34;https://textdata.cn/blog/2024-04-27-cntext2x-usage-tutorial/&#34;&gt;文本分析库cntext2.x使用手册&lt;/a&gt;&lt;/p&gt;
&lt;br&gt;
&lt;br&gt;
&lt;h2 id=&#34;五词嵌入应用文献&#34;&gt;五、词嵌入应用文献&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;# 使用词嵌入技术构建词典
[1]胡楠, 薛付婧 and 王昊楠, 2021. **管理者短视主义影响企业长期投资吗———基于文本分析和机器学习**. *管理世界*, *37*(5), pp.139-156.    
[2]Kai Li, Feng Mai, Rui Shen, Xinyan Yan, **Measuring Corporate Culture Using Machine Learning**, *The Review of Financial Studies*,2020


# 使用词嵌入测量偏见(刻板印象)、认知
[3]Lawson, M. Asher, Ashley E. Martin, Imrul Huda, and Sandra C. Matz. &amp;#34;**Hiring women into senior leadership positions is associated with a reduction in gender stereotypes in organizational language.**&amp;#34; _Proceedings of the National Academy of Sciences_ 119, no. 9 (2022): e2026443119.
[4]Lix, Katharina, Amir Goldberg, Sameer B. Srivastava, and Melissa A. Valentine. &amp;#34;**Aligning differences: Discursive diversity and team performance.**&amp;#34; *Management Science* 68, no. 11 (2022): 8430-8448.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;六广告&#34;&gt;六、广告&lt;/h2&gt;
&lt;p&gt;对词嵌入技术在经管中的应用，大邓也一直持续追踪。 课程 &lt;a href=&#34;https://textdata.cn/blog/management_python_course/&#34;&gt;&lt;strong&gt;Python实证指标与文本分析&lt;/strong&gt;&lt;/a&gt;中有词嵌入相关知识点和代码，对该类文本分析技术感兴趣同学，欢迎报名课程。&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;广而告之&#34;&gt;广而告之&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/call_for_paper/&#34;&gt;长期征稿&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/we_need_you/&#34;&gt;长期招募小伙伴&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/management_python_course/&#34;&gt;付费视频课 | Python实证指标构建与文本分析&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
      <content:encoded><![CDATA[<p>词嵌入在经管中的应用很多，但大多数是训练词嵌入模型，依据词嵌入构建或扩展词典。 今天我们将分享一篇用词嵌入测量团队认知多样性。</p>
<p><br><br></p>
<p><img loading="lazy" src="img/paper-cover-discursive-diversity.png" alt=""  />
</p>
<h2 id="一研究">一、研究</h2>
<p>Lix, Katharina, Amir Goldberg, Sameer B. Srivastava, and Melissa A. Valentine. &ldquo;<strong>Aligning differences: Discursive diversity and team performance.</strong>&rdquo; <em>Management Science</em> 68, no. 11 (2022): 8430-8448.</p>
<h3 id="11-摘要">1.1 摘要</h3>
<p>团队中的认知多样性如何影响其绩效？先前的研究表明，团队的认知多样性存在绩效权衡：多样性团队在创造力和创新方面表现出色，但在协调行动方面则有困难。基于团队认知不是静态的，而是动态互动产生的观点，我们引入了 <strong>话语多样性</strong> 的概念，这是团队认知多样性的一种表现，反映了在一组互动中团队成员传达的含义在多大程度上相互不同。<strong>我们提出，高绩效团队是那些具有调节共享认知以适应不断变化的任务要求的集体能力的团队：在进行构思任务时，它们表现出更高的话语多样性，在执行协调任务时，表现出较低的话语多样性</strong>。我们进一步认为，表现出一致调节的团队——即，在成员对不断变化的任务要求的个人语义变化中团队层面方差较低的团队——更有可能取得成功，而不是由成员之间存在不一致的调节。我们利用 <strong>计算语言学</strong> 工具来衡量话语多样性，并借助一组新型纵向数据，包括117个在线平台 <a href="http://www.gigster.com">www.gigster.com</a> 上的远程软件开发团队的团内电子通信和绩效结果，得出了对我们理论的支持。我们的研究结果表明，团队认知多样性的绩效权衡并非不可避免：团队可以通过将话语多样性水平与任务要求相匹配以及在进行这些调整时使成员保持一致来应对这一权衡。</p>
<h3 id="12-创新点">1.2 创新点</h3>
<p>这篇论文的创新点主要包括以下几个方面：</p>
<ol>
<li>
<p><strong>研究了团队内部的差异对团队绩效的影响</strong>：该论文通过分析团队成员之间的差异，探讨了这些差异对团队绩效的影响。这一研究角度对于理解团队内部动态和绩效提升具有重要意义。</p>
</li>
<li>
<p><strong>引入了阶段性的话语差异概念</strong>：论文提出了阶段性的话语差异概念，即团队成员在不同阶段的沟通中所表现出的差异。这一概念有助于更好地理解团队内部沟通的动态过程。</p>
</li>
<li>
<p><strong>探讨了团队内部沟通差异的调节作用</strong>：论文研究了团队内部沟通差异与团队绩效之间的关系，并发现团队内部沟通差异在不同阶段对团队绩效的影响存在差异。这一发现为团队管理和绩效提升提供了重要的启示。</p>
</li>
<li>
<p><strong>结合了多个学科领域的理论和方法</strong>：该论文综合运用了心理学、经济学和组织学等多个学科领域的理论和方法，从多个角度深入研究了团队内部差异和绩效之间的关系，为相关领域的研究提供了新的视角和方法。</p>
</li>
</ol>
<p><br><br></p>
<h2 id="二文献梳理">二、文献梳理</h2>
<h3 id="21-认知多样性">2.1 认知多样性</h3>
<p>认知多样性(cognitive diversity)对团队绩效的影响是一个长期存在的问题。以往的研究表明，团队的认知多样性存在绩效权衡：多样性团队在创造力和创新方面表现出色，但在协调行动方面存在困难。然而，<strong>最近的研究提出了一种新的观点，即团队的「认知多样性」可以通过调节团队的「共享认知」来实现绩效的平衡。这意味着团队可以根据任务要求调整其认知多样性的水平，以在创造性任务和协调任务之间找到平衡点</strong>。高绩效团队具备调节团队认知的能力，使其能够在创造性任务中展现较高的认知多样性，在协调任务中展现较低的认知多样性。这种能力使团队能够在创新和执行之间找到平衡，从而提高绩效。</p>
<br>
<h3 id="22-话语多样性">2.2 话语多样性</h3>
<p><strong>话语多样性(discursive diversity) 是指团队成员在交流和讨论中表达的观点、意见和想法的多样性程度。它反映了团队成员在思考和表达上的差异程度。话语多样性可以包括词汇选择、句子结构、表达方式等方面的差异</strong>。</p>
<p>话语多样性对团队的协调行动有影响。在协调任务中，团队成员需要相互理解、协调行动，达成共识并共同努力实现共同目标。如果团队成员的话语多样性过高，意味着他们在表达观点和意见时存在较大的差异，这可能导致沟通困难、理解不一致和冲突的产生，从而影响团队的协调行动。</p>
<p>因此，在协调任务中，团队成员的话语多样性应该相对较低，以便更好地理解和协调彼此的行动。相反，在创意和思考任务中，话语多样性可以促进团队成员的创新和思考，帮助他们从不同的角度和观点来解决问题，从而提高团队的创造力和创新能力。总之，话语多样性在团队中起着重要的作用，它需要根据任务的性质和要求进行调节，以实现团队的协调行动和创新能力。</p>
<br>
<h3 id="23-两者关系">2.3 两者关系</h3>
<p><strong>在这篇论文中，话语多样性被用来衡量认知多样性</strong>。研究人员使用计算语言学的工具来推导出话语多样性的度量，并将其应用于团队的电子沟通数据中。他们认为，团队的话语多样性可以反映成员之间的认知多样性，即在思维方式、知识和技能等方面的差异程度。通过分析团队的话语多样性，研究人员试图探索团队在不同任务要求下的表现，并研究团队如何调节共享认知以适应任务需求的变化。因此，话语多样性被视为一种衡量团队认知多样性的指标。</p>
<p><br><br></p>
<h2 id="三数据及方法">三、数据及方法</h2>
<h3 id="31-数据">3.1 数据</h3>
<p>Gigster(<a href="http://www.gigster.com">www.gigster.com</a>),是一个在线平台， 自由软件开发人员可以在该平台上为个人和企业客户制作按需软件。该平台将个人自由职业开发人员组装成由团队领导领导的临时团队，并将他们分配给需要复杂、相互依赖的长期项目。该平台上的自由职业者分布在全球各地，从事从移动到网络应用程序开发的各种项目。这些项目通常是知识密集型的，需要高水平的创造力、技术问题解决能力和人际协调能力。软件项目规模巨大，成本从数万美元到数十万美元不等（极端情况下可达一百万美元以上）。</p>
<p>我们的数据集由 117 个团队组成，代表 421 个不同的个体（36% 为女性），时间跨度从 2015 年初到 2017 年底。一个典型的团队有 5 名成员，其中包括一名项目经理；至少一名后端、前端或“全栈”工程师；设计师；和用户界面专家。根据项目类型，团队有时还包括作家、自然语言处理工程师和其他类型的专业人士。在我们数据中的团队中，项目平均持续 159 天（中位数：150 天），并分为平均持续两周的里程碑阶段（平均：14 天；中位数：14 天）。要加入该平台，专业人士必须通过旨在验证其专业知识的各种技术面试。平均而言，单个团队的成员代表 3.6 个国家/地区（中位数：3 个）。在我们的样本中，42% 的人将其原籍国列为北美。另外 13% 来自亚洲，其次是 12% 来自欧洲。其余 23% 居住在拉丁美洲、非洲和世界其他地区。</p>
<p>由于地理位置分散且缺乏实体办公空间，团队成员几乎完全通过名为 Slack 的在线即时通讯工具进行沟通。我们可以访问整个团队的 Slack 档案——超过 800,000 条消息。每条消息都带有时间戳并可归因（通过匿名标识符）其作者。团队在整个生命周期中平均在公共渠道中交换 1,873 条 Slack 消息（中位数：1,220 条）。我们对 Gigster 的高级领导和团队领导进行了非正式采访，他们一致表示团队沟通几乎完全通过 Slack 进行。一位高级领导描述了其中的原因：“几乎所有团队对话都发生在 Slack 上。这是一个有用的工具，因为我们运营全球团队，而且 Slack 允许在一个平台内进行实时和异步通信。它还允许轻松地共享项目文件。” 多位知情人士强调，团队成员始终依赖 Slack，而不是其他工具，因为“一切都在一个地方”对于促进团队协作非常重要。知情人士还表示，团队成员有动力使用 Slack，因为它提供了团队流程和事件的透明档案，可用于对一些罕见的争议案例进行分类。</p>
<p>除了 Slack 消息之外，我们还可以获得有关团队成员特征（职能角色、性别和原籍国）的数据，以及团队在实现各个项目里程碑方面的整体绩效。这些数据共同构成了团队内部动态和结果的丰富且连续的历史记录。</p>
<br>
<h3 id="32-计算话语多样性">3.2 计算话语多样性</h3>
<p>之前的工作表明，词嵌入模型对于捕获单词之间的语义关系特别有用， 例如，(2018) 证明，根据应用于 20 世纪出版的英语书籍的词嵌入模型推断出的不同职业的语义性别关联与这些职业的历史性别构成相对应。同样，科兹洛夫斯基等人(2019)说明了不同的生活方式活动如何与阶级、种族和性别认同相关。因此，词嵌入为语言中包含的众多意义维度提供了全面且有意义的见解，而这是以前的方法无法捕获的。因此，本论文使用词嵌入模型开发了话语多样性度量。</p>
<p><strong>我们首先对 Slack 数据进行预处理，并使用 Word2Vec（连续词袋词嵌入模型的流行实现）来训练词嵌入模型。</strong></p>
<p>按照标准实践，窗口大小设置为10， 维度设置成200来训练word2vec模型（<a href="https://pubsonline.informs.org/doi/full/10.1287/mnsc.2021.4274#B54">Mikolov 等人，2013</a>）。从这个训练过程中，我们获得了语料库中每个单词的一个 200 维坐标向量，表示该单词在语义空间中的位置。</p>
<blockquote>
<p><strong>窗口大小</strong>: 每个词的上下文范围。 人阅读书籍，一般视野只有十来个词，逐行阅读。 跟人类似， 在计算机中训练词嵌入模型时候，数据不是一次性灌入习得词语的向量，而是像人一样是有上下文范围的，这个范围叫做窗口。</p>
</blockquote>
<p>如前所述，嵌入空间的维度表示训练语料库中语言使用的潜在特征。尽管这些维度本身不具有定性可解释的含义，但这些维度是提供信息的，因为具有更相似含义的单词彼此更接近。<strong>下图(a)是从聊天消息构建词嵌入向量的过程</strong>:</p>
<p><img loading="lazy" src="img/01-compute-discursive-diverisity-with-embeddings.jpeg" alt=""  />
</p>
<p>**使用词嵌入模型，我们就可以把词语、每句话、某人某时期的话、某团队某时期的话、所有团队所有的话，通过一定的计算，都表征为200维的向量。**上图 (b) 从聊天消息构建团队话语多样性得分(Discursive Diversity)。</p>
<p><strong>通过公式1，计算出两个人差异性。通过公式2， 计算出团队话语多样性。</strong></p>
<p><img loading="lazy" src="img/03-formular-1.png" alt=""  />
</p>
<p><img loading="lazy" src="img/04-formular-2.png" alt=""  />
</p>
<br>
<p>假设团队只有三个人， 低话语多样性 与 高话语多样性， 分别对应下图的左侧和右侧。</p>
<p><img loading="lazy" src="img/02-low-and-high-examples-of-discursive-diversity.jpeg" alt=""  />
</p>
<p><br><br></p>
<h2 id="四python伪码">四、Python伪码</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="k">def</span> <span class="nf">discursive_diversity_score</span><span class="p">(</span><span class="n">wv</span><span class="p">,</span> <span class="n">words</span><span class="p">):</span>
    <span class="c1"># wv: 词嵌入模型; gensim.models.keyedvectors.KeyedVectors</span>
    <span class="c1"># words: 一个时间窗口内的词语列表</span>
    
    <span class="c1"># 计算词嵌入向量的平均值</span>
    <span class="n">embedding_vectors</span> <span class="o">=</span> <span class="p">[</span><span class="n">wv</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">words</span><span class="p">]</span>
    <span class="n">centroid</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">embedding_vectors</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    
    <span class="c1"># 计算词嵌入向量之间的余弦相似度</span>
    <span class="n">pairwise_distances</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">centroid</span><span class="p">,</span> <span class="n">embedding</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">centroid</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">embedding</span><span class="p">))</span> <span class="k">for</span> <span class="n">embedding</span> <span class="ow">in</span> <span class="n">embedding_vectors</span><span class="p">]</span>
    
    <span class="c1"># 计算语言多样性得分</span>
    <span class="n">diversity_score</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">pairwise_distances</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">diversity_score</span>
</code></pre></div><p>函数 <em><strong>discursive_diversity_score</strong></em> 已内置到 cntext2.x 版本中。 对cntext2.x 感兴趣，可阅读 <a href="https://textdata.cn/blog/2024-04-27-cntext2x-usage-tutorial/">文本分析库cntext2.x使用手册</a></p>
<br>
<br>
<h2 id="五词嵌入应用文献">五、词嵌入应用文献</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"># 使用词嵌入技术构建词典
[1]胡楠, 薛付婧 and 王昊楠, 2021. **管理者短视主义影响企业长期投资吗———基于文本分析和机器学习**. *管理世界*, *37*(5), pp.139-156.    
[2]Kai Li, Feng Mai, Rui Shen, Xinyan Yan, **Measuring Corporate Culture Using Machine Learning**, *The Review of Financial Studies*,2020


# 使用词嵌入测量偏见(刻板印象)、认知
[3]Lawson, M. Asher, Ashley E. Martin, Imrul Huda, and Sandra C. Matz. &#34;**Hiring women into senior leadership positions is associated with a reduction in gender stereotypes in organizational language.**&#34; _Proceedings of the National Academy of Sciences_ 119, no. 9 (2022): e2026443119.
[4]Lix, Katharina, Amir Goldberg, Sameer B. Srivastava, and Melissa A. Valentine. &#34;**Aligning differences: Discursive diversity and team performance.**&#34; *Management Science* 68, no. 11 (2022): 8430-8448.
</code></pre></div><p><br><br></p>
<h2 id="六广告">六、广告</h2>
<p>对词嵌入技术在经管中的应用，大邓也一直持续追踪。 课程 <a href="https://textdata.cn/blog/management_python_course/"><strong>Python实证指标与文本分析</strong></a>中有词嵌入相关知识点和代码，对该类文本分析技术感兴趣同学，欢迎报名课程。</p>
<p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>案例代码 | 使用正则表达式判别微博用户mbti类型</title>
      <link>https://textdata.cn/blog/2023-10-30-raw-mbti-users/</link>
      <pubDate>Mon, 30 Oct 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-10-30-raw-mbti-users/</guid>
      <description>&lt;p&gt;使用Python爬虫采集「微博搜索」中含mbti信息的推文， 使用正则表达式判别用户mbti类型。 相比实验室做实验或者发调查问卷，这种方式收集到的用户类别是非常自然且真实的。今日爬虫不是今日主题，就不做分享了。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;code.ipynb&#34;&gt;&lt;strong&gt;点击下载code.ipynb&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;mbti_test.csv&#34;&gt;&lt;strong&gt;点击下载mbti_test.csv&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/weibo.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pandas&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pd&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;#采集自微博搜索中含mbti类型的推文&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read_csv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;mbti_test.csv&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;c1&#34;&gt;#剔除content列中的nan数据&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dropna&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;inplace&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;subset&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;content&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/1.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;正则练习&#34;&gt;正则练习&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;提取含有mbti的记录&lt;/li&gt;
&lt;li&gt;提取出含mbti类型出现的前后5个字符的文本(前5个字符，后5个字符， 含mbti本身， 窗体最长的长度是14)&lt;/li&gt;
&lt;li&gt;识别出含mbti的记录中对应的mbti类型， 未识别的标记为&amp;quot;未识别&amp;quot;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;一-提取含有mbti的记录&#34;&gt;一、 提取含有mbti的记录&lt;/h2&gt;
&lt;p&gt;实现方法有两种&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;pd.Series.str.contains(regex_pattern)&lt;/li&gt;
&lt;li&gt;定义一个正则处理函数regex_func， 使用pd.Series.apply(regex_func)&lt;/li&gt;
&lt;/ol&gt;
&lt;br&gt;
&lt;p&gt;&lt;strong&gt;正则表达式含义&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;mbtis&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;[infj|entp|intp|intj|entj|enfj|infp|enfp|isfp|istp|isfj|istj|estp|esfp|estj|esfj]&amp;#39;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;[ 和 ]&lt;/code&gt;：这是字符类（character class）的起始和结束标记，表示要匹配方括号内的任何字符。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;infj|entp|intp|intj|entj|enfj|infp|enfp|isfp|istp|isfj|istj|estp|esfp|estj|esfj&lt;/code&gt;：这是一个字符类内的字符集合，用于匹配MBTI类型词汇。每个MBTI类型词汇都以竖线 | 分隔，表示“或”的关系。这意味着正则表达式会匹配其中任何一个MBTI类型词汇。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;+&lt;/code&gt;：这是一个量词，表示匹配前面的字符集合（MBTI类型词汇）一次或多次。它使正则表达式可以匹配包含一个或多个MBTI类型词汇的文本。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;mbtis&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;[infj|entp|intp|intj|entj|enfj|infp|enfp|isfp|istp|isfj|istj|estp|esfp|estj|esfj]&amp;#39;&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;content&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;str&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;contains&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mbtis&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;0       True
1       True
2       True
3       True
4       True
       ...  
495    False
496    False
497    False
498    False
499    False
Name: content, Length: 497, dtype: bool
&lt;/code&gt;&lt;/pre&gt;
&lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;re&lt;/span&gt;


&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;has_mbti&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;mbtis&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;[infj|entp|intp|intj|entj|enfj|infp|enfp|isfp|istp|isfj|istj|estp|esfp|estj|esfj]+&amp;#39;&lt;/span&gt;

    &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;re&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;findall&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mbtis&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
        &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;
    &lt;span class=&#34;k&#34;&gt;else&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
        &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;False&lt;/span&gt;
    
    
&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;content&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;apply&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;has_mbti&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;0       True
1       True
2       True
3       True
4       True
       ...  
495    False
496    False
497     True
498    False
499     True
Name: content, Length: 497, dtype: bool
&lt;/code&gt;&lt;/pre&gt;
&lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;c1&#34;&gt;#将结果存储到df中&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;hasMBTI&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;content&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;apply&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;has_mbti&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/2.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;二mbti前后内容&#34;&gt;二、mbti前后内容&lt;/h2&gt;
&lt;p&gt;提取出含mbti类型出现的前后5个字符的文本(前5个字符，后5个字符， 含mbti本身， 窗体最长的长度是14)。&lt;/p&gt;
&lt;p&gt;这样后续的分析任务，就可以通过查看mbti字眼前后出现的字符，来更新正则表达式。&lt;/p&gt;
&lt;br&gt;
&lt;p&gt;&lt;strong&gt;正则表达式含义&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;mbti_win = &amp;#34;(.{0,5}(?:infj|entp|intp|intj|entj|enfj|infp|enfp|isfp|istp|isfj|istj|estp|esfp|estj|esfj).{0,5})&amp;#34;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;&lt;code&gt;(&lt;/code&gt; 和 &lt;code&gt;)&lt;/code&gt;这些括号用于将整个匹配结果捕获为一个分组&lt;/li&gt;
&lt;li&gt;&lt;code&gt;.{0,5}&lt;/code&gt; ：这是一个量词，表示匹配前面的字符（.表示匹配任意字符）零次到五次。这部分用于匹配前面的文本，确保最多匹配前面的五个字符。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;(?:infj|entp|intp|intj|entj|enfj|infp|enfp|isfp|istp|isfj|istj|estp|esfp|estj|esfj)&lt;/code&gt;：这是一个非捕获分组，用于将多个MBTI类型词汇用 | 连接起来，表示匹配其中任何一个。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;.{0,5}&lt;/code&gt; ：这部分同样是一个量词，表示匹配后面的字符，确保最多匹配后面的五个字符。&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;mbti_window&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
    &lt;span class=&#34;c1&#34;&gt;#识别mbti的正则表达式 &lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;mbti_win&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;(.{0,5}(?:infj|entp|intp|intj|entj|enfj|infp|enfp|isfp|istp|isfj|istj|estp|esfp|estj|esfj).{0,5})&amp;#34;&lt;/span&gt;

    &lt;span class=&#34;k&#34;&gt;try&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
        &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;re&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;findall&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mbti_win&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
    &lt;span class=&#34;k&#34;&gt;except&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
        &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;未识别&amp;#34;&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;MBTI_win&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;content&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;apply&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mbti_window&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/3.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;三识别mbti类型&#34;&gt;三、识别mbti类型&lt;/h2&gt;
&lt;p&gt;刚刚的代码比较粗糙，只能判断文本中是否有mbti信息，但并不能判断该用户是否为某种mbti类型。&lt;/p&gt;
&lt;p&gt;微博文本中，只有 &lt;code&gt;//@&lt;/code&gt; 前字符内容是微博用户所写内容。为了识别用户的mbti类型，可以先将我们看到的表达方式列举一下&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;``我是[mbti]&lt;/li&gt;
&lt;li&gt;&lt;code&gt;自己是[mbti]&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;从[mbti]变为[mbti]&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;一直是[mbti]&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;[mbti]我&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;本[mbti]&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&amp;hellip;&amp;hellip;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;可以基于此设计一个严格的正则表达式，能识别到的记录，肯定能判断该用户的mbti类型。 未识别到的标记为 &amp;ldquo;未识别&amp;rdquo;&lt;/p&gt;
&lt;br&gt;
&lt;p&gt;&lt;strong&gt;正则表达式含义&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;mbti_regex&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;[我|自己|变成|一直|是|本]*(infj|entp|intp|intj|entj|enfj|infp|enfp|isfp|istp|isfj|istj|estp|esfp|estj|esfj)[我|俺|本|自己]*&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;&lt;code&gt;[我|自己|变成|一直|是|本]*&lt;/code&gt;：这部分是一个字符集合，用于匹配前面的字符（关键词）。方括号 &lt;code&gt;[...]&lt;/code&gt; 表示字符类，其中的字符是可选的，并且 * 表示匹配零次或多次。这意味着它可以匹配零个或多个出现在方括号中的字符，例如可以匹配&amp;quot;我&amp;quot;、&amp;ldquo;自己&amp;rdquo;、&amp;ldquo;变成&amp;rdquo;、&amp;ldquo;一直&amp;rdquo;、&amp;ldquo;是&amp;rdquo;、&amp;ldquo;本&amp;quot;等这些关键词。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;(infj|entp|intp|intj|entj|enfj|infp|enfp|isfp|istp|isfj|istj|estp|esfp|estj|esfj)&lt;/code&gt; ：这是一个分组，其中包含了MBTI类型词汇，用竖线 &lt;code&gt;|&lt;/code&gt; 分隔，表示&amp;quot;或&amp;quot;的关系。这部分用于匹配任意一个MBTI类型词汇。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;[我|俺|本|自己]*&lt;/code&gt; ：这部分与第1部分类似，是一个字符集合，用于匹配后面的字符（关键词）。同样，方括号 &lt;code&gt;[...]&lt;/code&gt; 表示字符类，其中的字符是可选的，并且 &lt;code&gt;*&lt;/code&gt; 表示匹配零次或多次。&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;
&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;identify_mbti&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
    &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;//@&amp;#39;&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
        &lt;span class=&#34;n&#34;&gt;new_text&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;split&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;//@&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
    &lt;span class=&#34;k&#34;&gt;else&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
        &lt;span class=&#34;n&#34;&gt;new_text&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;text&lt;/span&gt;

    &lt;span class=&#34;c1&#34;&gt;#识别mbti的正则表达式 &lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;mbti_regex&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;[我|自己|变成|一直|是|本]*(infj|entp|intp|intj|entj|enfj|infp|enfp|isfp|istp|isfj|istj|estp|esfp|estj|esfj)[我|俺|本|自己]*&amp;#34;&lt;/span&gt;

    &lt;span class=&#34;k&#34;&gt;try&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
        &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;re&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;findall&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mbti_regex&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
    &lt;span class=&#34;k&#34;&gt;except&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
        &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;未识别&amp;#34;&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;#mbti类型&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;MBTI_Cat&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;content&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;apply&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;identify_mbti&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/4.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;c1&#34;&gt;#各类型记录数&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;MBTI_Cat&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;value_counts&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;MBTI_Cat
未识别     297
infp     35
isfj     20
enfp     18
intp     17
isfp     16
intj     14
entp     12
entj     11
infj     11
enfj      8
estj      8
istp      8
istj      7
esfp      6
estp      5
esfj      4
Name: count, dtype: int64
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;广而告之&#34;&gt;广而告之&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/call_for_paper/&#34;&gt;长期征稿&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/we_need_you/&#34;&gt;长期招募小伙伴&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/management_python_course/&#34;&gt;付费视频课 | Python实证指标构建与文本分析&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
      <content:encoded><![CDATA[<p>使用Python爬虫采集「微博搜索」中含mbti信息的推文， 使用正则表达式判别用户mbti类型。 相比实验室做实验或者发调查问卷，这种方式收集到的用户类别是非常自然且真实的。今日爬虫不是今日主题，就不做分享了。</p>
<ul>
<li><a href="code.ipynb"><strong>点击下载code.ipynb</strong></a></li>
<li><a href="mbti_test.csv"><strong>点击下载mbti_test.csv</strong></a></li>
</ul>
<br>
<p><img loading="lazy" src="img/weibo.png" alt=""  />
</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="c1">#采集自微博搜索中含mbti类型的推文</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;mbti_test.csv&#39;</span><span class="p">)</span>
<span class="c1">#剔除content列中的nan数据</span>
<span class="n">df</span><span class="o">.</span><span class="n">dropna</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">subset</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;content&#39;</span><span class="p">])</span>
<span class="n">df</span>
</code></pre></div><p><img loading="lazy" src="img/1.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="正则练习">正则练习</h2>
<ol>
<li>提取含有mbti的记录</li>
<li>提取出含mbti类型出现的前后5个字符的文本(前5个字符，后5个字符， 含mbti本身， 窗体最长的长度是14)</li>
<li>识别出含mbti的记录中对应的mbti类型， 未识别的标记为&quot;未识别&quot;</li>
</ol>
<p><br><br></p>
<h2 id="一-提取含有mbti的记录">一、 提取含有mbti的记录</h2>
<p>实现方法有两种</p>
<ol>
<li>pd.Series.str.contains(regex_pattern)</li>
<li>定义一个正则处理函数regex_func， 使用pd.Series.apply(regex_func)</li>
</ol>
<br>
<p><strong>正则表达式含义</strong></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">mbtis</span> <span class="o">=</span> <span class="s1">&#39;[infj|entp|intp|intj|entj|enfj|infp|enfp|isfp|istp|isfj|istj|estp|esfp|estj|esfj]&#39;</span>
</code></pre></div><ul>
<li>
<p><code>[ 和 ]</code>：这是字符类（character class）的起始和结束标记，表示要匹配方括号内的任何字符。</p>
</li>
<li>
<p><code>infj|entp|intp|intj|entj|enfj|infp|enfp|isfp|istp|isfj|istj|estp|esfp|estj|esfj</code>：这是一个字符类内的字符集合，用于匹配MBTI类型词汇。每个MBTI类型词汇都以竖线 | 分隔，表示“或”的关系。这意味着正则表达式会匹配其中任何一个MBTI类型词汇。</p>
</li>
<li>
<p><code>+</code>：这是一个量词，表示匹配前面的字符集合（MBTI类型词汇）一次或多次。它使正则表达式可以匹配包含一个或多个MBTI类型词汇的文本。</p>
</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">mbtis</span> <span class="o">=</span> <span class="s1">&#39;[infj|entp|intp|intj|entj|enfj|infp|enfp|isfp|istp|isfj|istj|estp|esfp|estj|esfj]&#39;</span>

<span class="n">df</span><span class="o">.</span><span class="n">content</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="n">mbtis</span><span class="p">)</span>
</code></pre></div><pre><code>0       True
1       True
2       True
3       True
4       True
       ...  
495    False
496    False
497    False
498    False
499    False
Name: content, Length: 497, dtype: bool
</code></pre>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">re</span>


<span class="k">def</span> <span class="nf">has_mbti</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="n">mbtis</span> <span class="o">=</span> <span class="s1">&#39;[infj|entp|intp|intj|entj|enfj|infp|enfp|isfp|istp|isfj|istj|estp|esfp|estj|esfj]+&#39;</span>

    <span class="k">if</span> <span class="n">re</span><span class="o">.</span><span class="n">findall</span><span class="p">(</span><span class="n">mbtis</span><span class="p">,</span> <span class="n">text</span><span class="p">):</span>
        <span class="k">return</span> <span class="kc">True</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">False</span>
    
    
<span class="n">df</span><span class="o">.</span><span class="n">content</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">has_mbti</span><span class="p">)</span>
</code></pre></div><pre><code>0       True
1       True
2       True
3       True
4       True
       ...  
495    False
496    False
497     True
498    False
499     True
Name: content, Length: 497, dtype: bool
</code></pre>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#将结果存储到df中</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;hasMBTI&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;content&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">has_mbti</span><span class="p">)</span>
<span class="n">df</span>
</code></pre></div><p><img loading="lazy" src="img/2.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="二mbti前后内容">二、mbti前后内容</h2>
<p>提取出含mbti类型出现的前后5个字符的文本(前5个字符，后5个字符， 含mbti本身， 窗体最长的长度是14)。</p>
<p>这样后续的分析任务，就可以通过查看mbti字眼前后出现的字符，来更新正则表达式。</p>
<br>
<p><strong>正则表达式含义</strong></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">mbti_win = &#34;(.{0,5}(?:infj|entp|intp|intj|entj|enfj|infp|enfp|isfp|istp|isfj|istj|estp|esfp|estj|esfj).{0,5})&#34;
</code></pre></div><ul>
<li><code>(</code> 和 <code>)</code>这些括号用于将整个匹配结果捕获为一个分组</li>
<li><code>.{0,5}</code> ：这是一个量词，表示匹配前面的字符（.表示匹配任意字符）零次到五次。这部分用于匹配前面的文本，确保最多匹配前面的五个字符。</li>
<li><code>(?:infj|entp|intp|intj|entj|enfj|infp|enfp|isfp|istp|isfj|istj|estp|esfp|estj|esfj)</code>：这是一个非捕获分组，用于将多个MBTI类型词汇用 | 连接起来，表示匹配其中任何一个。</li>
<li><code>.{0,5}</code> ：这部分同样是一个量词，表示匹配后面的字符，确保最多匹配后面的五个字符。</li>
</ul>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">mbti_window</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="c1">#识别mbti的正则表达式 </span>
    <span class="n">mbti_win</span> <span class="o">=</span> <span class="s2">&#34;(.{0,5}(?:infj|entp|intp|intj|entj|enfj|infp|enfp|isfp|istp|isfj|istj|estp|esfp|estj|esfj).{0,5})&#34;</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">re</span><span class="o">.</span><span class="n">findall</span><span class="p">(</span><span class="n">mbti_win</span><span class="p">,</span> <span class="n">text</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">except</span><span class="p">:</span>
        <span class="k">return</span> <span class="s2">&#34;未识别&#34;</span>

<span class="n">df</span><span class="p">[</span><span class="s1">&#39;MBTI_win&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;content&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">mbti_window</span><span class="p">)</span>
<span class="n">df</span>
</code></pre></div><p><img loading="lazy" src="img/3.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="三识别mbti类型">三、识别mbti类型</h2>
<p>刚刚的代码比较粗糙，只能判断文本中是否有mbti信息，但并不能判断该用户是否为某种mbti类型。</p>
<p>微博文本中，只有 <code>//@</code> 前字符内容是微博用户所写内容。为了识别用户的mbti类型，可以先将我们看到的表达方式列举一下</p>
<ul>
<li>``我是[mbti]</li>
<li><code>自己是[mbti]</code></li>
<li><code>从[mbti]变为[mbti]</code></li>
<li><code>一直是[mbti]</code></li>
<li><code>[mbti]我</code></li>
<li><code>本[mbti]</code></li>
<li>&hellip;&hellip;</li>
</ul>
<p>可以基于此设计一个严格的正则表达式，能识别到的记录，肯定能判断该用户的mbti类型。 未识别到的标记为 &ldquo;未识别&rdquo;</p>
<br>
<p><strong>正则表达式含义</strong></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">mbti_regex</span> <span class="o">=</span> <span class="s2">&#34;[我|自己|变成|一直|是|本]*(infj|entp|intp|intj|entj|enfj|infp|enfp|isfp|istp|isfj|istj|estp|esfp|estj|esfj)[我|俺|本|自己]*&#34;</span>
</code></pre></div><ul>
<li><code>[我|自己|变成|一直|是|本]*</code>：这部分是一个字符集合，用于匹配前面的字符（关键词）。方括号 <code>[...]</code> 表示字符类，其中的字符是可选的，并且 * 表示匹配零次或多次。这意味着它可以匹配零个或多个出现在方括号中的字符，例如可以匹配&quot;我&quot;、&ldquo;自己&rdquo;、&ldquo;变成&rdquo;、&ldquo;一直&rdquo;、&ldquo;是&rdquo;、&ldquo;本&quot;等这些关键词。</li>
<li><code>(infj|entp|intp|intj|entj|enfj|infp|enfp|isfp|istp|isfj|istj|estp|esfp|estj|esfj)</code> ：这是一个分组，其中包含了MBTI类型词汇，用竖线 <code>|</code> 分隔，表示&quot;或&quot;的关系。这部分用于匹配任意一个MBTI类型词汇。</li>
<li><code>[我|俺|本|自己]*</code> ：这部分与第1部分类似，是一个字符集合，用于匹配后面的字符（关键词）。同样，方括号 <code>[...]</code> 表示字符类，其中的字符是可选的，并且 <code>*</code> 表示匹配零次或多次。</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python">
<span class="k">def</span> <span class="nf">identify_mbti</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="k">if</span> <span class="s1">&#39;//@&#39;</span> <span class="ow">in</span> <span class="n">text</span><span class="p">:</span>
        <span class="n">new_text</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;//@&#39;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">new_text</span> <span class="o">=</span> <span class="n">text</span>

    <span class="c1">#识别mbti的正则表达式 </span>
    <span class="n">mbti_regex</span> <span class="o">=</span> <span class="s2">&#34;[我|自己|变成|一直|是|本]*(infj|entp|intp|intj|entj|enfj|infp|enfp|isfp|istp|isfj|istj|estp|esfp|estj|esfj)[我|俺|本|自己]*&#34;</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">re</span><span class="o">.</span><span class="n">findall</span><span class="p">(</span><span class="n">mbti_regex</span><span class="p">,</span> <span class="n">text</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">except</span><span class="p">:</span>
        <span class="k">return</span> <span class="s2">&#34;未识别&#34;</span>

<span class="c1">#mbti类型</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;MBTI_Cat&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;content&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">identify_mbti</span><span class="p">)</span>
<span class="n">df</span>
</code></pre></div><p><img loading="lazy" src="img/4.png" alt=""  />
</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#各类型记录数</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;MBTI_Cat&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</code></pre></div><pre><code>MBTI_Cat
未识别     297
infp     35
isfj     20
enfp     18
intp     17
isfp     16
intj     14
entp     12
entj     11
infj     11
enfj      8
estj      8
istp      8
istj      7
esfp      6
estp      5
esfj      4
Name: count, dtype: int64
</code></pre>
<p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>GTE中文通用文本向量表示模型</title>
      <link>https://textdata.cn/blog/2023-10-27-nlp_gte_sentence-embedding_chinese/</link>
      <pubDate>Fri, 27 Oct 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-10-27-nlp_gte_sentence-embedding_chinese/</guid>
      <description>&lt;h2 id=&#34;gte中文通用文本表示模型&#34;&gt;GTE中文通用文本表示模型&lt;/h2&gt;
&lt;p&gt;文本表示是自然语言处理(NLP)领域的核心问题, 其在很多NLP、信息检索的下游任务中发挥着非常重要的作用。近几年, 随着深度学习的发展，尤其是预训练语言模型的出现极大的推动了文本表示技术的效果, 基于预训练语言模型的文本表示模型在学术研究数据、工业实际应用中都明显优于传统的基于统计模型(词袋法、TF-IDF) 或者浅层神经网络的文本表示模型。这里, 我们主要关注基于预训练语言模型的文本表示。GTE项目地址&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;https://modelscope.cn/models/damo/nlp_gte_sentence-embedding_chinese-small/summary
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;p&gt;文本表示示例, 输入一个句子, 输入一个固定维度的连续向量:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;输入: &lt;code&gt;吃完海鲜可以喝牛奶吗?&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;输出: &lt;code&gt;[0.27162,-0.66159,0.33031,0.24121,0.46122,...]&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;文本的向量表示通常可以用于&lt;strong&gt;文本聚类&lt;/strong&gt;、&lt;strong&gt;文本相似度计算&lt;/strong&gt;等下游任务中。&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;二文本表示模型&#34;&gt;二、文本表示模型&lt;/h2&gt;
&lt;p&gt;基于监督数据训练的文本表示模型通常采用Dual Encoder框架, 如下图所示。在Dual Encoder框架中, Query和Document文本通过预训练语言模型编码后, 通常采用预训练语言模型[CLS]位置的向量作为最终的文本向量表示。基于标注数据的标签, 通过计算query-document之间的cosine距离度量两者之间的相关性。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/repo.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;GTE-zh模型使用&lt;a href=&#34;https://arxiv.org/abs/2205.12035&#34;&gt;retromae&lt;/a&gt;初始化训练模型，之后利用两阶段训练方法训练模型：第一阶段利用大规模弱弱监督文本对数据训练模型，第二阶段利用高质量精标文本对数据以及挖掘的难负样本数据训练模型。具体训练方法请参考论文&lt;a href=&#34;https://arxiv.org/abs/2308.03281&#34;&gt;Towards General Text Embeddings with Multi-stage Contrastive Learning&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;二使用方式和范围&#34;&gt;二、使用方式和范围&lt;/h2&gt;
&lt;p&gt;使用方式:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;直接推理, 对给定文本计算其对应的文本向量表示，向量维度512&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;使用范围:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;本模型可以使用在通用领域的文本向量表示及其下游应用场景, 包括 &lt;strong&gt;两文档间文本相似度计算&lt;/strong&gt;、&lt;strong&gt;query&amp;amp;多doc候选的相似度排序&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;21-如何使用&#34;&gt;2.1 如何使用&lt;/h3&gt;
&lt;p&gt;在ModelScope框架上，提供输入文本(默认最长文本长度为128)，即可以通过简单的Pipeline调用来使用GTE文本向量表示模型。ModelScope封装了统一的接口对外提供&lt;strong&gt;单文档向量表示&lt;/strong&gt;、&lt;strong&gt;双文档文本相似度&lt;/strong&gt;、&lt;strong&gt;多候选相似度计算&lt;/strong&gt;等功能&lt;/p&gt;
&lt;h3 id=&#34;22-安装&#34;&gt;2.2 安装&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;pip3 install torch
pip3 install transformers
pip3 install modelscope
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;三代码示例&#34;&gt;三、代码示例&lt;/h2&gt;
&lt;p&gt;为方便实验，选择体积较小的模型文件 &lt;strong&gt;damo/nlp_gte_sentence-embedding_chinese-small&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;modelscope.models&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Model&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;modelscope.pipelines&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pipeline&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;modelscope.utils.constant&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Tasks&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;#&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;model_id&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;damo/nlp_gte_sentence-embedding_chinese-small&amp;#34;&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;#57M&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;model_id&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;damo/nlp_gte_sentence-embedding_chinese-large&amp;#34;&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;#621M&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;pipeline_se&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pipeline&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Tasks&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sentence_embedding&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                       &lt;span class=&#34;n&#34;&gt;model&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;model_id&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;# 当输入包含“soure_sentence”与“sentences_to_compare”时，会输出source_sentence中首个句子与sentences_to_compare中每个句子的向量表示，以及source_sentence中首个句子与sentences_to_compare中每个句子的相似度。&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;inputs&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
        &lt;span class=&#34;s2&#34;&gt;&amp;#34;source_sentence&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;吃完海鲜可以喝牛奶吗?&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;
        &lt;span class=&#34;s2&#34;&gt;&amp;#34;sentences_to_compare&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;
            &lt;span class=&#34;s2&#34;&gt;&amp;#34;不可以，早晨喝牛奶不科学&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
            &lt;span class=&#34;s2&#34;&gt;&amp;#34;吃了海鲜后是不能再喝牛奶的，因为牛奶中含得有维生素C，如果海鲜喝牛奶一起服用会对人体造成一定的伤害&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
            &lt;span class=&#34;s2&#34;&gt;&amp;#34;吃海鲜是不能同时喝牛奶吃水果，这个至少间隔6小时以上才可以。&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
            &lt;span class=&#34;s2&#34;&gt;&amp;#34;吃海鲜是不可以吃柠檬的因为其中的维生素C会和海鲜中的矿物质形成砷&amp;#34;&lt;/span&gt;
        &lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
    &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;result&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pipeline_se&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;input&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;inputs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;result&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;{&amp;#39;text_embedding&amp;#39;: array([[-0.03317244, -0.0419106 , -0.03626636, ..., -0.0132677 ,
         -0.02028614, -0.01542077],
        [-0.04563809, -0.06220782, -0.03775004, ...,  0.01267119,
         -0.01111769, -0.03390383],
        [-0.02073098, -0.04639562, -0.04818704, ..., -0.00754705,
         -0.00731624, -0.02740852],
        [-0.00037597, -0.05922904, -0.0459275 , ..., -0.00697823,
         -0.02154762, -0.02951157],
        [-0.00491675, -0.02552056, -0.03427778, ..., -0.00760836,
         -0.00404084, -0.0509829 ]], dtype=float32),
 &amp;#39;scores&amp;#39;: [0.8542333245277405,
  0.9613471031188965,
  0.947378396987915,
  0.8620702028274536]}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;默认向量维度512,  两个向量做内积距离计算得到score&lt;/strong&gt;
&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 当输入仅含有soure_sentence时，会输出source_sentence中每个句子的向量表示。&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;inputs2&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
        &lt;span class=&#34;s2&#34;&gt;&amp;#34;source_sentence&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;
            &lt;span class=&#34;s2&#34;&gt;&amp;#34;不可以，早晨喝牛奶不科学&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
            &lt;span class=&#34;s2&#34;&gt;&amp;#34;吃了海鲜后是不能再喝牛奶的，因为牛奶中含得有维生素C，如果海鲜喝牛奶一起服用会对人体造成一定的伤害&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
            &lt;span class=&#34;s2&#34;&gt;&amp;#34;吃海鲜是不能同时喝牛奶吃水果，这个至少间隔6小时以上才可以。&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
            &lt;span class=&#34;s2&#34;&gt;&amp;#34;吃海鲜是不可以吃柠檬的因为其中的维生素C会和海鲜中的矿物质形成砷&amp;#34;&lt;/span&gt;
        &lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;result&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pipeline_se&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;input&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;inputs2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;result&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;{&amp;#39;text_embedding&amp;#39;: array([[-0.04563809, -0.06220782, -0.03775004, ...,  0.01267119,
        -0.01111769, -0.03390383],
       [-0.02073098, -0.04639562, -0.04818704, ..., -0.00754705,
        -0.00731624, -0.02740852],
       [-0.00037597, -0.05922904, -0.0459275 , ..., -0.00697823,
        -0.02154762, -0.02951157],
       [-0.00491675, -0.02552056, -0.03427778, ..., -0.00760836,
        -0.00404084, -0.0509829 ]], dtype=float32), &amp;#39;scores&amp;#39;: []}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;广而告之&#34;&gt;广而告之&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/call_for_paper/&#34;&gt;长期征稿&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/we_need_you/&#34;&gt;长期招募小伙伴&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/management_python_course/&#34;&gt;付费视频课 | Python实证指标构建与文本分析&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
      <content:encoded><![CDATA[<h2 id="gte中文通用文本表示模型">GTE中文通用文本表示模型</h2>
<p>文本表示是自然语言处理(NLP)领域的核心问题, 其在很多NLP、信息检索的下游任务中发挥着非常重要的作用。近几年, 随着深度学习的发展，尤其是预训练语言模型的出现极大的推动了文本表示技术的效果, 基于预训练语言模型的文本表示模型在学术研究数据、工业实际应用中都明显优于传统的基于统计模型(词袋法、TF-IDF) 或者浅层神经网络的文本表示模型。这里, 我们主要关注基于预训练语言模型的文本表示。GTE项目地址</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">https://modelscope.cn/models/damo/nlp_gte_sentence-embedding_chinese-small/summary
</code></pre></div><br>
<p>文本表示示例, 输入一个句子, 输入一个固定维度的连续向量:</p>
<ul>
<li>输入: <code>吃完海鲜可以喝牛奶吗?</code></li>
<li>输出: <code>[0.27162,-0.66159,0.33031,0.24121,0.46122,...]</code></li>
</ul>
<p>文本的向量表示通常可以用于<strong>文本聚类</strong>、<strong>文本相似度计算</strong>等下游任务中。</p>
<p><br><br></p>
<h2 id="二文本表示模型">二、文本表示模型</h2>
<p>基于监督数据训练的文本表示模型通常采用Dual Encoder框架, 如下图所示。在Dual Encoder框架中, Query和Document文本通过预训练语言模型编码后, 通常采用预训练语言模型[CLS]位置的向量作为最终的文本向量表示。基于标注数据的标签, 通过计算query-document之间的cosine距离度量两者之间的相关性。</p>
<p><img loading="lazy" src="img/repo.png" alt=""  />
</p>
<p>GTE-zh模型使用<a href="https://arxiv.org/abs/2205.12035">retromae</a>初始化训练模型，之后利用两阶段训练方法训练模型：第一阶段利用大规模弱弱监督文本对数据训练模型，第二阶段利用高质量精标文本对数据以及挖掘的难负样本数据训练模型。具体训练方法请参考论文<a href="https://arxiv.org/abs/2308.03281">Towards General Text Embeddings with Multi-stage Contrastive Learning</a>。</p>
<p><br><br></p>
<h2 id="二使用方式和范围">二、使用方式和范围</h2>
<p>使用方式:</p>
<ul>
<li>直接推理, 对给定文本计算其对应的文本向量表示，向量维度512</li>
</ul>
<p>使用范围:</p>
<ul>
<li>本模型可以使用在通用领域的文本向量表示及其下游应用场景, 包括 <strong>两文档间文本相似度计算</strong>、<strong>query&amp;多doc候选的相似度排序</strong></li>
</ul>
<h3 id="21-如何使用">2.1 如何使用</h3>
<p>在ModelScope框架上，提供输入文本(默认最长文本长度为128)，即可以通过简单的Pipeline调用来使用GTE文本向量表示模型。ModelScope封装了统一的接口对外提供<strong>单文档向量表示</strong>、<strong>双文档文本相似度</strong>、<strong>多候选相似度计算</strong>等功能</p>
<h3 id="22-安装">2.2 安装</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">pip3 install torch
pip3 install transformers
pip3 install modelscope
</code></pre></div><p><br><br></p>
<h2 id="三代码示例">三、代码示例</h2>
<p>为方便实验，选择体积较小的模型文件 <strong>damo/nlp_gte_sentence-embedding_chinese-small</strong></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">modelscope.models</span> <span class="kn">import</span> <span class="n">Model</span>
<span class="kn">from</span> <span class="nn">modelscope.pipelines</span> <span class="kn">import</span> <span class="n">pipeline</span>
<span class="kn">from</span> <span class="nn">modelscope.utils.constant</span> <span class="kn">import</span> <span class="n">Tasks</span>

<span class="c1">#</span>
<span class="n">model_id</span> <span class="o">=</span> <span class="s2">&#34;damo/nlp_gte_sentence-embedding_chinese-small&#34;</span> <span class="c1">#57M</span>
<span class="n">model_id</span> <span class="o">=</span> <span class="s2">&#34;damo/nlp_gte_sentence-embedding_chinese-large&#34;</span> <span class="c1">#621M</span>
<span class="n">pipeline_se</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span><span class="n">Tasks</span><span class="o">.</span><span class="n">sentence_embedding</span><span class="p">,</span>
                       <span class="n">model</span><span class="o">=</span><span class="n">model_id</span><span class="p">)</span>

<span class="c1"># 当输入包含“soure_sentence”与“sentences_to_compare”时，会输出source_sentence中首个句子与sentences_to_compare中每个句子的向量表示，以及source_sentence中首个句子与sentences_to_compare中每个句子的相似度。</span>
<span class="n">inputs</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&#34;source_sentence&#34;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&#34;吃完海鲜可以喝牛奶吗?&#34;</span><span class="p">],</span>
        <span class="s2">&#34;sentences_to_compare&#34;</span><span class="p">:</span> <span class="p">[</span>
            <span class="s2">&#34;不可以，早晨喝牛奶不科学&#34;</span><span class="p">,</span>
            <span class="s2">&#34;吃了海鲜后是不能再喝牛奶的，因为牛奶中含得有维生素C，如果海鲜喝牛奶一起服用会对人体造成一定的伤害&#34;</span><span class="p">,</span>
            <span class="s2">&#34;吃海鲜是不能同时喝牛奶吃水果，这个至少间隔6小时以上才可以。&#34;</span><span class="p">,</span>
            <span class="s2">&#34;吃海鲜是不可以吃柠檬的因为其中的维生素C会和海鲜中的矿物质形成砷&#34;</span>
        <span class="p">]</span>
    <span class="p">}</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline_se</span><span class="p">(</span><span class="nb">input</span><span class="o">=</span><span class="n">inputs</span><span class="p">)</span>
<span class="nb">print</span> <span class="p">(</span><span class="n">result</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">{&#39;text_embedding&#39;: array([[-0.03317244, -0.0419106 , -0.03626636, ..., -0.0132677 ,
         -0.02028614, -0.01542077],
        [-0.04563809, -0.06220782, -0.03775004, ...,  0.01267119,
         -0.01111769, -0.03390383],
        [-0.02073098, -0.04639562, -0.04818704, ..., -0.00754705,
         -0.00731624, -0.02740852],
        [-0.00037597, -0.05922904, -0.0459275 , ..., -0.00697823,
         -0.02154762, -0.02951157],
        [-0.00491675, -0.02552056, -0.03427778, ..., -0.00760836,
         -0.00404084, -0.0509829 ]], dtype=float32),
 &#39;scores&#39;: [0.8542333245277405,
  0.9613471031188965,
  0.947378396987915,
  0.8620702028274536]}
</code></pre></div><p><strong>默认向量维度512,  两个向量做内积距离计算得到score</strong>
<br><br></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1"># 当输入仅含有soure_sentence时，会输出source_sentence中每个句子的向量表示。</span>
<span class="n">inputs2</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&#34;source_sentence&#34;</span><span class="p">:</span> <span class="p">[</span>
            <span class="s2">&#34;不可以，早晨喝牛奶不科学&#34;</span><span class="p">,</span>
            <span class="s2">&#34;吃了海鲜后是不能再喝牛奶的，因为牛奶中含得有维生素C，如果海鲜喝牛奶一起服用会对人体造成一定的伤害&#34;</span><span class="p">,</span>
            <span class="s2">&#34;吃海鲜是不能同时喝牛奶吃水果，这个至少间隔6小时以上才可以。&#34;</span><span class="p">,</span>
            <span class="s2">&#34;吃海鲜是不可以吃柠檬的因为其中的维生素C会和海鲜中的矿物质形成砷&#34;</span>
        <span class="p">]</span>
<span class="p">}</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline_se</span><span class="p">(</span><span class="nb">input</span><span class="o">=</span><span class="n">inputs2</span><span class="p">)</span>
<span class="nb">print</span> <span class="p">(</span><span class="n">result</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">{&#39;text_embedding&#39;: array([[-0.04563809, -0.06220782, -0.03775004, ...,  0.01267119,
        -0.01111769, -0.03390383],
       [-0.02073098, -0.04639562, -0.04818704, ..., -0.00754705,
        -0.00731624, -0.02740852],
       [-0.00037597, -0.05922904, -0.0459275 , ..., -0.00697823,
        -0.02154762, -0.02951157],
       [-0.00491675, -0.02552056, -0.03427778, ..., -0.00760836,
        -0.00404084, -0.0509829 ]], dtype=float32), &#39;scores&#39;: []}
</code></pre></div><p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>心理科学进展 | 语义距离与创造性思维关系的元分析</title>
      <link>https://textdata.cn/blog/2023-10-18-the-relationship-between-semantic-distance-with-creativity/</link>
      <pubDate>Wed, 18 Oct 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-10-18-the-relationship-between-semantic-distance-with-creativity/</guid>
      <description>自然语言处理的发展为探究语义距离与创造性思维的关系提供了可靠且有效的研究方法。 近些年关于两者之间关系的研究逐渐增多, 但研究结论并不一致。本研究基于创造力联想理论及扩散激活模型, 通过元分析的方法探讨了语义距离与创造性思维的整体关系, 并且分析了以往研究结论不一致的原因。 结果显示：语义距离与创造性思维存在中等程度的正相关，二者的相关强度受到被试年龄和创造性思维不同测量指标的调节。 研究结果表明语义距离与创造性思维关系 密切, 同时解释了以往研究结论不一致的原因。 上述结果不仅能为更深入地探讨创造性思维的认知神经机制 提供新的研究视角和理论解释, 而且有助于更全面地理解语义距离与创造性思维二者的关系及其边界条件, 为更好地解释、预测和提升创造力提供科学依据和重要启示。</description>
      <content:encoded><![CDATA[<p>博客之前分享过 <a href="https://textdata.cn/blog/2022-11-14-pnas_naming_unrelated_words_predicts_creativity/"><strong>PNAS(含代码) | 使用语义距离测量一个人的创新力(发散思维)得分</strong></a>  , 通过语义距离测量创新力， 该教程含Python代码。今天摘抄一篇&lt;心理科学进展&gt;的论文， 帮助大家更深入了解语义距离与创造性思维之间的关系。</p>
<p><br><br></p>
<h2 id="一文献">一、文献</h2>
<p>李亚丹,杜颖,谢聪,刘春宇,杨毅隆,李阳萍,邱江.<strong>语义距离与创造性思维关系的元分析</strong>[J].心理科学进展,2023,31(04):519-534.</p>
<p>摘要:  自然语言处理的发展为探究 <strong>语义距离</strong> 与 <strong>创造性思维</strong> 的关系提供了可靠且有效的研究方法。近些年关于两者之间关系的研究逐渐增多,但研究结论并不一致。本研究基于 <strong>创造力联想理论</strong> 及扩散激活模型, 通过元分析的方法探讨了语义距离与创造性思维的整体关系,并且分析了以往研究结论不一致的原因。本文经过文献检索和筛选后获得14项研究,提取r值作为效应值(共53个效应值,4729个独立样本),并使用随机效应模型进行了元分析。**结果显示：语义距离与创造性思维存在中等程度的正相关(r=0.379, 95%CI [0.300, 0.452]); 二者的相关强度受到被试年龄和创造性思维不同测量指标的调节。**研究结果表明语义距离与创造性思维关系密切, 同时解释了以往研究结论不一致的原因。上述结果不仅能为更深入地探讨创造性思维的认知神经机制提供新的研究视角和理论解释,而且有助于更全面地理解语义距离与创造性思维二者的关系及其边界条件,为更好地解释、预测和提升创造力提供科学依据和重要启示。</p>
<p><br><br></p>
<p><strong>创造性思维</strong> 是一种高层次的思维活动, 对科学进步和社会发展具有深远的影响, 其核心的认知成分之一就是基于语义记忆的 <strong>联想能力</strong>(Acar &amp; Runco, 2014; Marron et al., 2018)。 个体的联想能力及其在进行创造性活动时的联想过程均可以通过语义距离(semantic distance)表现出来(Beaty et al., 2014; Benedek &amp; Neubauer, 2013)。因此, 语义距离是帮助我们理解创造性思维和创造性认知过程的重要手段。</p>
<p>在认知科学领域, 通常利用 <strong>心理词典</strong> (mental lexicon) 所构成的语义网络 (semantic network) 来表征语义记忆结构 (Christensen &amp; Kenett, 2021)。在语义网络中, 概念被表示为通过 “边(edge)”相互连结的“节点(node)”, 语义距离则用来表示概念与概念之间的距离, 即语义相似性 (Paulsen et al., 1996)。</p>
<p>在实证研究中研究者们常用发散思维测验(Divergent Thinking Test)来衡量创造性思维, 但发散思维测验的评分存在着一些不足, 如流畅性和独特性有较高程度的相关致使得分极易混淆、独特性评分依赖于样本等问题(Silvia et al.,2008)。因此, 除了对原有测量技术的优化和改进, 还需要提升创造力测量的客观性和准确性。 目前 已有学者提出使用语义距离来测量创造性思维, <strong>但是使用语义距离测量创造性思维这一方法的有效性还存在着争议</strong>(Marron et al., 2018; Wang et al., 2018)。</p>
<br>
<br>
<h2 id="二创造性思维及其度量">二、创造性思维及其度量</h2>
<p>创造力(creativity)是指产生新颖(original)且 适 宜 (appropriate) 产品的能力 (Kaufman &amp; Sternberg, 2010; Runco, 2002)。发散思维(Divergent Thinking)是个体针对给 定问题或提示产生多个原创想法的心理能力 (Acar &amp; Runco, 2019; Forthmann, Wilken et al., 2019), 长期以来一直是创造性思维研究中的一个 重要内容(Hocevar, 1980)。发散思维测验是迄今为止创造力研究中使用最多、应用最为广泛的主流测验形式(Plucker &amp; Makel, 2010; Reiter-Palmon et al., 2019)。</p>
<p>在以往研究中, Guilford (1950)的 <strong>多用途任务</strong> (Alternate Use Task, AUT)和 Torrance (1972) 的 <strong>创造性思维测试</strong> (Torrance Tests of Creative Thinking, TTCT)使用频率较高。<strong>发散思维通常包括 4 个维度, 即流畅性、灵活性、独特性(或 独创性)和精致性</strong>。其中, 流畅性(fluency)指给出 的想法或解决方案的数量; 灵活性(flexibility)指 想法的多样性; 独特性(originality)指想法的不寻 常或唯一性; 精致性(elaboration)指给出想法或答案的详细程度(Torrance, 1965, 1988)。 在评分时, 发散思维测验也常从这四个维度来计分, 并由此衡量被试答案的创造性水平。但发散思维测试存在一些潜在问题，如无法进一步探讨创造性思维过程的手段(Hass, 2017; Marron et al., 2018)。其次， 四个主要的评价指标， 除了流畅性能够被客观测量，其余三个指标的传统评分方法存在一定弊端。第三， 在发散思维测验计分时， 流畅性和独创性的得分容易混淆。以上三点导致发散思维测验的客观性、信度饱受争议(Benedek &amp; Neubauer, 2013)。</p>
<p><br><br></p>
<h2 id="三语义距离与创造性思维的关系">三、语义距离与创造性思维的关系</h2>
<p>语义距离这个概念来源于 Collins 和 Loftus (1975)提出的<strong>扩散激活模型</strong>(Spreading-Activation Model)。 在概念与概念之间, 共同的定义性特征 越多, 它们之间的关系就越近, 这个关系就称为 语义距离(Volle, 2018)。例如, “雪”和“白”经常共同出现在文本中, 所以语义距离较小; 相反, “雪”和 “石油”很少同时出现, 因此二者之间具有较大的 语义距离。</p>
<p>Mednick 在 1962 年提出了 <strong>创造力联想理论</strong> (Associative Theory of Creativity), 该理论解释了创造性思维与语义记忆结构之间的关系(Mednick, 1962)。 该理论认为,  创造性思维涉及将弱相关或远距离概念联接成新颖且有用的概念的认知过程。 如果某些概念在语义层面相距越远, 由它们所产生的新的组合就越有创意, 新颖度越高。</p>
<p>Benedek 等人(2012)在 Mednick (1962)的理论 基础上提出, 解离能力(dissociative ability)和联想整合能力(associative combination ability)是与创造性思维密切相关的基本认知能力。</p>
<ul>
<li><strong>解离能力</strong> 是指生成不相关的概念的能力, 也可以被理解为一 种语义抑制能力, 它有助于人们获得新的语义距离遥远的概念。</li>
<li><strong>联想整合能力</strong> 指的是对看似不相关的概念形成合理联想的能力。</li>
</ul>
<p>据此我们可以推断, 语义距离作为概念与概念之间关系的量化指 标(Volle, 2018), 也即衡量个体联想能力的指标, 可以有效反映个体以联想过程为基础的创造性思维。 扩散激活模型也提到, 有创造力的人拥有更加复杂(Collins &amp; Loftus, 1975; Gruszka &amp; Necka, 2002; Kenett, 2019) 、 更加灵活的语义网络 (Schilling, 2005)。</p>
<p>近年来语义距离也开始作为测量创造性表现 的指标。 研究者们(Green et al., 2012; Prabhakaran et al., 2014; Weinberger et al., 2016)在探究状态创 造力(state creativity)时, 通常将语义距离作为创 造力水平高低的测量指标。 状态创造力即被试在 不同指导语或线索提示下所表现出的不同创造力 水平。也有研究利用语义距离来测量创造性思维, 结果显示相比较传统测量方法, 基于语义距离的 测量方法在创造性思维各指标间有着更好的区分 效度和结构信度(Dumas &amp; Dunbar, 2014)。</p>
<p>此外, 通过对语义距离的应用,  研究者能够对创造性思维的质量有更为客观的认识, 从而更 好地探讨创造性思维的认知神经机制。 人们普遍认为, 创造性思维认知过程需要 <strong>联想过程</strong> (associative processes) 与 <strong>执行过程</strong> (executive processes)的耦合(Silvia et al., 2013)。 目前, 大多 数创造性思维任务并未区分这两种认知过程 (Mednick, 1968; Runco et al., 2016), 而对这两种 认知过程的细分有助于我们更深入地理解创造性思维和创造性认知过程(Fox et al., 2015)。 而语义距离作为联想能力的衡量指标, 可以更好地反映 出个体在进行创造性思维任务时的联想过程 (Beaty, Nusbaum et al., 2014; Beaty, Silvia et al., 2014; Marron et al., 2018)。因此, 语义距离也被用来作为认知神经科学研究中创造性思维的测量指标, 它不仅可以用于比较个体在产生不同创造性 水平的答案时其大脑激活模式的差异(Beaty et al., 2017; Green et al., 2015; Tempest &amp; Radel, 2019)及个体的创造性表现随时间动态变化 (Green, 2016), 还可以用来研究不同个体之间的创造力水平差异(Green, 2016)。</p>
<p><br><br></p>
<h2 id="四年龄可能调节语义距离与创造性思维关系">四、年龄可能调节语义距离与创造性思维关系</h2>
<p>近几年, 国内外开展了一些语义距离与创造性思维关系的研究, 但是研究结果却不尽相同。 这可能与研究对象的人口学因素(年龄)和评估创 造性思维时所使用的测量指标有关。</p>
<p>根据已有研究, 年龄可能会影响语义距离与创造性思维之间的关系。</p>
<p><strong>首先</strong>, 年龄与语言能力和词汇量有关。 老年人的词汇量及语义知识存储与年轻人相比更加丰富(Kavé &amp; Halamish, 2015; Verhaeghen, 2003), 而语言能力较强、词汇量较多 的个体在表达想法时更不容易受到表达能力的限制, 因此往往在言语创造性任务中表现得更好。 语言能力较强的个体也可能会有更多的认知资源用来产生创造性想法(Wu et al., 2005)。  <strong>其次</strong>, 不同年龄被试的语义结构和语义记忆也是不同的, 例如, 老年人语义记忆中的概念更加模块化, 也更分散(Dubossarsky et al., 2017; Wulff et al., 2019; Zortea et al., 2014)。因此, 样本群体的年龄 可能会影响语义距离与创造性思维之间的关系。</p>
<p><br><br></p>
<h2 id="五元分析结果">五、元分析结果</h2>
<h3 id="51-语义距离测量创造性思维的有效性">5.1 语义距离测量创造性思维的有效性</h3>
<p><strong>本研究结果显示 , 语义距离与创造性思维呈显著正相关 (r = 0.379, p &lt; 0.001), 与以往研究结 果一致 (Hass, 2017; Heinen &amp; Johnson, 2018) 。该结果进一步验证了 Mednick (1962)提出的创造力联想理论 , 即如果某些概念在语义层面相距越远 , 由它们所产生的新的组合就越有创意新颖性越高</strong>。</p>
<p>语义距离作为一种连续变量 , 可以更精准地反映出创造性思维的定量变化 , 而不仅仅是二元对比 ( 例如 , 创造性与非创造性条件 ) (Kenett et al., 2017; Kenett, 2018; Kenett, 2019)。 因此 , 语义距离具有测量创造性思维的独特优势 (Green, 2016)。</p>
<p>然而 , 本研究发现 , 语义距离与创造性思维 关系的效应值为 0.379, 仍处于中等程度的正相关 (Cohen, 1988) 。 这说明尽管使用语义距离测量创 造性思维有一定的有效性 , 但是语义距离对创造 性思维的代表程度有限。</p>
<br>
<h3 id="52-语义距离与创造性思维关系中存在的调节效应">5.2 语义距离与创造性思维关系中存在的调节效应</h3>
<p><strong>被试年龄对语义距离与创造性思维的关系具有显著的调节作用，二者的相关性随着年龄的增加而逐渐降低</strong>。 原因可能在于 , 随着年龄的增长 , 个体的语义记忆结构和知识储备也在逐渐发生改变 , 从而影响了语义距离与创造性思维的关系。首先是语义记忆结 构的变化。 个体的语义记忆结构会随着年龄的增 长而逐渐变得稀疏 (Dubossarsky et al., 2017; Wulff et al., 2019; Zortea et al., 2014)。其次 是个体的知识储备和生活经验的变化。 常见的言语类创造性思维任务介于现实问题任务和图形任 务之间 , 完成这类任务需要一定的知识储备 (Wu et al., 2005)。</p>
<p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>数据集 | 谷歌地图美国区域内poi、评论信息等信息</title>
      <link>https://textdata.cn/blog/2023-10-18-google-local-data/</link>
      <pubDate>Wed, 18 Oct 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-10-18-google-local-data/</guid>
      <description>&lt;h2 id=&#34;一数据介绍&#34;&gt;一、数据介绍&lt;/h2&gt;
&lt;p&gt;该数据集从谷歌地图采集了美国范围内一些信息(截止日期为 2021 年 9 月)，数据规模&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;666,324,103&lt;/strong&gt; 条评论（评级、文本、图片等）&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;113,643,107&lt;/strong&gt; 位用户信息&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;4,963,111&lt;/strong&gt;  条企业元数据（地址、地理信息、描述、类别信息、价格、营业时间和其他信息）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;数据集地址&lt;/strong&gt; &lt;a href=&#34;https://datarepo.eng.ucsd.edu/mcauley_group/gdrive/googlelocal/&#34;&gt;https://datarepo.eng.ucsd.edu/mcauley_group/gdrive/googlelocal/&lt;/a&gt;&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;11-完整评论数据&#34;&gt;1.1 完整评论数据&lt;/h3&gt;
&lt;p&gt;请仅在确实需要时下载这些（大！）文件。我们建议使用较小的数据集（即 k-core 和 CSV 文件），如下一节所示。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/1.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&amp;hellip;&amp;hellip;&lt;/p&gt;
&lt;h3 id=&#34;12-小的评论数据&#34;&gt;1.2 小的评论数据&lt;/h3&gt;
&lt;p&gt;如果您要在课堂项目（或类似项目）中使用这些数据，请考虑在申请大文件之前使用下面这些较小的数据集。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;10-cores&lt;/strong&gt; 经过缩减，以剩下的每个用户和每个项目都有 10 条评论。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ratings only&lt;/strong&gt;：这些数据集不包含元数据或评论，只有（企业、用户、评分、时间戳）元组。因此，它们适合与 mymedialite（或类似）软件包一起使用。&lt;/p&gt;
&lt;p&gt;您可以直接下载以下按类别划分的较小数据集。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/2.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;h2 id=&#34;二数据格式&#34;&gt;二、数据格式&lt;/h2&gt;
&lt;p&gt;格式为 json 格式的每行一篇评论。如需进一步帮助阅读数据，请参阅下面的示例。&lt;/p&gt;
&lt;h3 id=&#34;21-评论样本&#34;&gt;2.1 评论样本&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;{
  &amp;#39;user_id&amp;#39;: &amp;#39;106533466896145407182&amp;#39;, 
  &amp;#39;name&amp;#39;: &amp;#39;Amy VG&amp;#39;, 
  &amp;#39;time&amp;#39;: 1568748357166, 
  &amp;#39;rating&amp;#39;: 5, 
  &amp;#39;text&amp;#39;: &amp;#34;I can&amp;#39;t say I&amp;#39;ve ever been excited about a dentist visit before, but there&amp;#39;s a first for everything! Loved my experience at Lush today. Every person in the office was friendly and personable- plus the office itself is gorgeous! Great experience, I highly recommend!&amp;#34;, 
  &amp;#39;pics&amp;#39;: [
  {
    &amp;#39;url&amp;#39;: [&amp;#39;https://lh5.googleusercontent.com/p/AF1QipMBzN4BJV9YCObcw_ifNzFPm-u38hO3oimOA8Fb=w150-h150-k-no-p&amp;#39;]
  }, 
  {
    &amp;#39;url&amp;#39;: [&amp;#39;https://lh5.googleusercontent.com/p/AF1QipNS1PEXEvadfUlhRkRDJ09id
    Mxh3CveZGZYuTo5=w150-h150-k-no-p&amp;#39;]
  }
  ], 
  &amp;#39;resp&amp;#39;: {
    &amp;#39;time&amp;#39;: 1568770503975, 
    &amp;#39;text&amp;#39;: &amp;#39;We love getting to meet new patients like yourself.  Thanks for giving our office a chance to take care of your dental needs and thanks for the nice review!&amp;#39;
  }, 
  &amp;#39;gmap_id&amp;#39;: &amp;#39;0x87ec2394c2cd9d2d:0xd1119cfbee0da6f3&amp;#39;
}
{
  &amp;#39;user_id&amp;#39;: &amp;#39;101463350189962023774&amp;#39;, 
  &amp;#39;name&amp;#39;: &amp;#39;Jordan Adams&amp;#39;, 
  &amp;#39;time&amp;#39;: 1627750414677, 
  &amp;#39;rating&amp;#39;: 5, 
  &amp;#39;text&amp;#39;: &amp;#39;Cool place, great people, awesome dentist!&amp;#39;, 
  &amp;#39;pics&amp;#39;: [
  {
    &amp;#39;url&amp;#39;: [&amp;#39;https://lh5.googleusercontent.com/p/AF1QipNq2nZC5TH4_M7h5xRAd
    61hoTgvY1o9lozABguI=w150-h150-k-no-p&amp;#39;]
  }
  ], 
  &amp;#39;resp&amp;#39;: {
    &amp;#39;time&amp;#39;: 1628455067818, 
    &amp;#39;text&amp;#39;: &amp;#39;Thank you for your five-star review! -Dr. Blake&amp;#39;
  }, 
  &amp;#39;gmap_id&amp;#39;: &amp;#39;0x87ec2394c2cd9d2d:0xd1119cfbee0da6f3&amp;#39;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;其中&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;user_id - 审稿人的 ID
name - 审阅人姓名
time - 审核时间（UNIX 时间）
rating - 企业评级
text - 评论的文字
pics - 评论的图片
resp - 企业对评论的回复，包括 unix 时间和回复文本
gmap_id - 企业 ID
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h3 id=&#34;22-元数据样本&#34;&gt;2.2 元数据样本&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;{
  &amp;#39;name&amp;#39;: &amp;#39;Walgreens Pharmacy&amp;#39;, 
  &amp;#39;address&amp;#39;: &amp;#39;Walgreens Pharmacy, 124 E North St, Kendallville, IN 46755&amp;#39;, 
  &amp;#39;gmap_id&amp;#39;: &amp;#39;0x881614ce7c13acbb:0x5c7b18bbf6ec4f7e&amp;#39;, 
  &amp;#39;description&amp;#39;: &amp;#39;Department of the Walgreens chain providing prescription medications &amp;amp; other health-related items.&amp;#39;, 
  &amp;#39;latitude&amp;#39;: 41.451859999999996, 
  &amp;#39;longitude&amp;#39;: -85.2666757, 
  &amp;#39;category&amp;#39;: [&amp;#39;Pharmacy&amp;#39;], 
  &amp;#39;avg_rating&amp;#39;: 4.2, 
  &amp;#39;num_of_reviews&amp;#39;: 5, 
  &amp;#39;price&amp;#39;: &amp;#39;$$&amp;#39;, 
  &amp;#39;hours&amp;#39;: [[&amp;#39;Thursday&amp;#39;, &amp;#39;8AM–1:30PM&amp;#39;], [&amp;#39;Friday&amp;#39;, &amp;#39;8AM–1:30PM&amp;#39;], [&amp;#39;Saturday&amp;#39;, &amp;#39;9AM–1:30PM&amp;#39;], [&amp;#39;Sunday&amp;#39;, &amp;#39;10AM–1:30PM&amp;#39;], [&amp;#39;Monday&amp;#39;, &amp;#39;8AM–1:30PM&amp;#39;], [&amp;#39;Tuesday&amp;#39;, &amp;#39;8AM–1:30PM&amp;#39;], [&amp;#39;Wednesday&amp;#39;, &amp;#39;8AM–1:30PM&amp;#39;]], 
  &amp;#39;MISC&amp;#39;: {
    &amp;#39;Service options&amp;#39;: [&amp;#39;Curbside pickup&amp;#39;, &amp;#39;Drive-through&amp;#39;, &amp;#39;In-store pickup&amp;#39;, &amp;#39;In-store shopping&amp;#39;], 
    &amp;#39;Health &amp;amp; safety&amp;#39;: [&amp;#39;Mask required&amp;#39;, &amp;#39;Staff wear masks&amp;#39;, &amp;#39;Staff get temperature checks&amp;#39;], 
    &amp;#39;Accessibility&amp;#39;: [&amp;#39;Wheelchair accessible entrance&amp;#39;, &amp;#39;Wheelchair accessible parking lot&amp;#39;], 
    &amp;#39;Planning&amp;#39;: [&amp;#39;Quick visit&amp;#39;], 
    &amp;#39;Payments&amp;#39;: [&amp;#39;Checks&amp;#39;, &amp;#39;Debit cards&amp;#39;]
  }, 
  &amp;#39;state&amp;#39;: &amp;#39;Closes soon ⋅ 1:30PM ⋅ Reopens 2PM&amp;#39;, 
  &amp;#39;relative_results&amp;#39;: [&amp;#39;0x881614cd49e4fa33:0x2d507c24ff4f1c74&amp;#39;, &amp;#39;0x8816145bf5141c89:0x535c1d605109f94b&amp;#39;, &amp;#39;0x881614cda24cc591:0xca426e3a9b826432&amp;#39;, &amp;#39;0x88162894d98b91ef:0xd139b34de70d3e03&amp;#39;, &amp;#39;0x881615400b5e57f9:0xc56d17dbe420a67f&amp;#39;], 
  &amp;#39;url&amp;#39;: &amp;#39;https://www.google.com/maps/place//data=!4m2!3m1!1s0x881614ce7c13acb
  b:0x5c7b18bbf6ec4f7e?authuser=-1&amp;amp;hl=en&amp;amp;gl=us&amp;#39;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;其中&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;name - 企业名称
address - 企业地址
gmap_id - 企业 ID
description - 企业描述
latitude - 企业的纬度
longitude - 企业的经度
category - 企业类别
avg_rating - 企业的平均评分
num_of_reviews - 评价数量
price - 商店的价格
hours - 营业时间
MISC - 其他信息
state - 企业的当前状态（例如，永久关闭）
relative_results - 谷歌推荐的相关企业
url - 企业的 URL
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;br&gt;
&lt;h2 id=&#34;三获取数据集&#34;&gt;三、获取数据集&lt;/h2&gt;
&lt;p&gt;数据集地址
&lt;a href=&#34;https://datarepo.eng.ucsd.edu/mcauley_group/gdrive/googlelocal/&#34;&gt;https://datarepo.eng.ucsd.edu/mcauley_group/gdrive/googlelocal/&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;31-引用&#34;&gt;3.1 引用&lt;/h3&gt;
&lt;p&gt;如果您以任何方式使用这些数据，请引用以下论文：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;Li, Jiacheng, Jingbo Shang, and Julian McAuley. &amp;#34;Uctopic: Unsupervised contrastive learning for phrase representations and topic mining.&amp;#34; *arXiv preprint arXiv:2202.13469* (2022).

Yan, An, Zhankui He, Jiacheng Li, Tianyang Zhang, and Julian McAuley. &amp;#34;Personalized Showcases: Generating multi-modal explanations for recommendations.&amp;#34; In *Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval*, pp. 2251-2255. 2023.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h3 id=&#34;32-联系方式&#34;&gt;3.2 联系方式&lt;/h3&gt;
&lt;p&gt;Jiacheng Li (&lt;a href=&#34;mailto:j9li@eng.ucsd.edu&#34;&gt;j9li@eng.ucsd.edu&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;广而告之&#34;&gt;广而告之&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/call_for_paper/&#34;&gt;长期征稿&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/we_need_you/&#34;&gt;长期招募小伙伴&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/management_python_course/&#34;&gt;付费视频课 | Python实证指标构建与文本分析&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
      <content:encoded><![CDATA[<h2 id="一数据介绍">一、数据介绍</h2>
<p>该数据集从谷歌地图采集了美国范围内一些信息(截止日期为 2021 年 9 月)，数据规模</p>
<ul>
<li><strong>666,324,103</strong> 条评论（评级、文本、图片等）</li>
<li><strong>113,643,107</strong> 位用户信息</li>
<li><strong>4,963,111</strong>  条企业元数据（地址、地理信息、描述、类别信息、价格、营业时间和其他信息）</li>
</ul>
<p><strong>数据集地址</strong> <a href="https://datarepo.eng.ucsd.edu/mcauley_group/gdrive/googlelocal/">https://datarepo.eng.ucsd.edu/mcauley_group/gdrive/googlelocal/</a></p>
<br>
<h3 id="11-完整评论数据">1.1 完整评论数据</h3>
<p>请仅在确实需要时下载这些（大！）文件。我们建议使用较小的数据集（即 k-core 和 CSV 文件），如下一节所示。</p>
<p><img loading="lazy" src="img/1.png" alt=""  />
</p>
<p>&hellip;&hellip;</p>
<h3 id="12-小的评论数据">1.2 小的评论数据</h3>
<p>如果您要在课堂项目（或类似项目）中使用这些数据，请考虑在申请大文件之前使用下面这些较小的数据集。</p>
<p><strong>10-cores</strong> 经过缩减，以剩下的每个用户和每个项目都有 10 条评论。</p>
<p><strong>ratings only</strong>：这些数据集不包含元数据或评论，只有（企业、用户、评分、时间戳）元组。因此，它们适合与 mymedialite（或类似）软件包一起使用。</p>
<p>您可以直接下载以下按类别划分的较小数据集。</p>
<p><img loading="lazy" src="img/2.png" alt=""  />
</p>
<br>
<h2 id="二数据格式">二、数据格式</h2>
<p>格式为 json 格式的每行一篇评论。如需进一步帮助阅读数据，请参阅下面的示例。</p>
<h3 id="21-评论样本">2.1 评论样本</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">{
  &#39;user_id&#39;: &#39;106533466896145407182&#39;, 
  &#39;name&#39;: &#39;Amy VG&#39;, 
  &#39;time&#39;: 1568748357166, 
  &#39;rating&#39;: 5, 
  &#39;text&#39;: &#34;I can&#39;t say I&#39;ve ever been excited about a dentist visit before, but there&#39;s a first for everything! Loved my experience at Lush today. Every person in the office was friendly and personable- plus the office itself is gorgeous! Great experience, I highly recommend!&#34;, 
  &#39;pics&#39;: [
  {
    &#39;url&#39;: [&#39;https://lh5.googleusercontent.com/p/AF1QipMBzN4BJV9YCObcw_ifNzFPm-u38hO3oimOA8Fb=w150-h150-k-no-p&#39;]
  }, 
  {
    &#39;url&#39;: [&#39;https://lh5.googleusercontent.com/p/AF1QipNS1PEXEvadfUlhRkRDJ09id
    Mxh3CveZGZYuTo5=w150-h150-k-no-p&#39;]
  }
  ], 
  &#39;resp&#39;: {
    &#39;time&#39;: 1568770503975, 
    &#39;text&#39;: &#39;We love getting to meet new patients like yourself.  Thanks for giving our office a chance to take care of your dental needs and thanks for the nice review!&#39;
  }, 
  &#39;gmap_id&#39;: &#39;0x87ec2394c2cd9d2d:0xd1119cfbee0da6f3&#39;
}
{
  &#39;user_id&#39;: &#39;101463350189962023774&#39;, 
  &#39;name&#39;: &#39;Jordan Adams&#39;, 
  &#39;time&#39;: 1627750414677, 
  &#39;rating&#39;: 5, 
  &#39;text&#39;: &#39;Cool place, great people, awesome dentist!&#39;, 
  &#39;pics&#39;: [
  {
    &#39;url&#39;: [&#39;https://lh5.googleusercontent.com/p/AF1QipNq2nZC5TH4_M7h5xRAd
    61hoTgvY1o9lozABguI=w150-h150-k-no-p&#39;]
  }
  ], 
  &#39;resp&#39;: {
    &#39;time&#39;: 1628455067818, 
    &#39;text&#39;: &#39;Thank you for your five-star review! -Dr. Blake&#39;
  }, 
  &#39;gmap_id&#39;: &#39;0x87ec2394c2cd9d2d:0xd1119cfbee0da6f3&#39;
}
</code></pre></div><p>其中</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">user_id - 审稿人的 ID
name - 审阅人姓名
time - 审核时间（UNIX 时间）
rating - 企业评级
text - 评论的文字
pics - 评论的图片
resp - 企业对评论的回复，包括 unix 时间和回复文本
gmap_id - 企业 ID
</code></pre></div><br>
<h3 id="22-元数据样本">2.2 元数据样本</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">{
  &#39;name&#39;: &#39;Walgreens Pharmacy&#39;, 
  &#39;address&#39;: &#39;Walgreens Pharmacy, 124 E North St, Kendallville, IN 46755&#39;, 
  &#39;gmap_id&#39;: &#39;0x881614ce7c13acbb:0x5c7b18bbf6ec4f7e&#39;, 
  &#39;description&#39;: &#39;Department of the Walgreens chain providing prescription medications &amp; other health-related items.&#39;, 
  &#39;latitude&#39;: 41.451859999999996, 
  &#39;longitude&#39;: -85.2666757, 
  &#39;category&#39;: [&#39;Pharmacy&#39;], 
  &#39;avg_rating&#39;: 4.2, 
  &#39;num_of_reviews&#39;: 5, 
  &#39;price&#39;: &#39;$$&#39;, 
  &#39;hours&#39;: [[&#39;Thursday&#39;, &#39;8AM–1:30PM&#39;], [&#39;Friday&#39;, &#39;8AM–1:30PM&#39;], [&#39;Saturday&#39;, &#39;9AM–1:30PM&#39;], [&#39;Sunday&#39;, &#39;10AM–1:30PM&#39;], [&#39;Monday&#39;, &#39;8AM–1:30PM&#39;], [&#39;Tuesday&#39;, &#39;8AM–1:30PM&#39;], [&#39;Wednesday&#39;, &#39;8AM–1:30PM&#39;]], 
  &#39;MISC&#39;: {
    &#39;Service options&#39;: [&#39;Curbside pickup&#39;, &#39;Drive-through&#39;, &#39;In-store pickup&#39;, &#39;In-store shopping&#39;], 
    &#39;Health &amp; safety&#39;: [&#39;Mask required&#39;, &#39;Staff wear masks&#39;, &#39;Staff get temperature checks&#39;], 
    &#39;Accessibility&#39;: [&#39;Wheelchair accessible entrance&#39;, &#39;Wheelchair accessible parking lot&#39;], 
    &#39;Planning&#39;: [&#39;Quick visit&#39;], 
    &#39;Payments&#39;: [&#39;Checks&#39;, &#39;Debit cards&#39;]
  }, 
  &#39;state&#39;: &#39;Closes soon ⋅ 1:30PM ⋅ Reopens 2PM&#39;, 
  &#39;relative_results&#39;: [&#39;0x881614cd49e4fa33:0x2d507c24ff4f1c74&#39;, &#39;0x8816145bf5141c89:0x535c1d605109f94b&#39;, &#39;0x881614cda24cc591:0xca426e3a9b826432&#39;, &#39;0x88162894d98b91ef:0xd139b34de70d3e03&#39;, &#39;0x881615400b5e57f9:0xc56d17dbe420a67f&#39;], 
  &#39;url&#39;: &#39;https://www.google.com/maps/place//data=!4m2!3m1!1s0x881614ce7c13acb
  b:0x5c7b18bbf6ec4f7e?authuser=-1&amp;hl=en&amp;gl=us&#39;
}
</code></pre></div><p>其中</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">name - 企业名称
address - 企业地址
gmap_id - 企业 ID
description - 企业描述
latitude - 企业的纬度
longitude - 企业的经度
category - 企业类别
avg_rating - 企业的平均评分
num_of_reviews - 评价数量
price - 商店的价格
hours - 营业时间
MISC - 其他信息
state - 企业的当前状态（例如，永久关闭）
relative_results - 谷歌推荐的相关企业
url - 企业的 URL
</code></pre></div><br>
<br>
<h2 id="三获取数据集">三、获取数据集</h2>
<p>数据集地址
<a href="https://datarepo.eng.ucsd.edu/mcauley_group/gdrive/googlelocal/">https://datarepo.eng.ucsd.edu/mcauley_group/gdrive/googlelocal/</a></p>
<h3 id="31-引用">3.1 引用</h3>
<p>如果您以任何方式使用这些数据，请引用以下论文：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">Li, Jiacheng, Jingbo Shang, and Julian McAuley. &#34;Uctopic: Unsupervised contrastive learning for phrase representations and topic mining.&#34; *arXiv preprint arXiv:2202.13469* (2022).

Yan, An, Zhankui He, Jiacheng Li, Tianyang Zhang, and Julian McAuley. &#34;Personalized Showcases: Generating multi-modal explanations for recommendations.&#34; In *Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval*, pp. 2251-2255. 2023.
</code></pre></div><br>
<h3 id="32-联系方式">3.2 联系方式</h3>
<p>Jiacheng Li (<a href="mailto:j9li@eng.ucsd.edu">j9li@eng.ucsd.edu</a>)</p>
<p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>JMR | 测量消费者的语言确定性</title>
      <link>https://textdata.cn/blog/2023-10-16-measurement-of-consumer-certainty-in-language/</link>
      <pubDate>Mon, 16 Oct 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-10-16-measurement-of-consumer-certainty-in-language/</guid>
      <description>情感分析从根本上改变了市场营销者评估消费者意见的能力。的确，通过自然语言测量态度已经影响了市场营销在日常实践中的方式。**然而，最近的研究发现，情感分析目前强调测量情感的正负面（即积极或消极）可能会产生不完整、不准确甚至误导性的见解**。从概念上讲，这项研究挑战情感分析超越对情感正负面的侧重。作者识别出消费者情感的确定性或信心是一个特别有力的评估方面。从经验上，**他们开发了一种新的计算语言中确定性的测量工具——确定性词典（Certainty Lexicon）**，并验证了其与情感分析的使用。为了构建和验证这种测量，作者使用了来自1160万人的文本，他们生成了数十亿的词汇，数百万的在线评论，以及在线预测市场的数十万条记录。在社交媒体数据集、实验室实验和在线评论中，作者发现与其他工具相比，确定性词典在其测量中更为全面、可推广和准确。作者还展示了对市场营销者来说，测量情感确定性的价值：确定性预测了广告的实际成功，而传统的情感分析则未能做到这一点。</description>
      <content:encoded><![CDATA[<h2 id="一文献">一、文献</h2>
<p>Rocklage Matthew D.,He Sharlene,Rucker Derek D.,Nordgren Loran F..<strong>Beyond Sentiment: The Value and Measurement of Consumer Certainty in Language</strong>[J].<strong>Journal of Marketing Research</strong>,2023,60(5).</p>
<p><strong>摘要(译文)</strong>:  情感分析从根本上改变了市场营销者评估消费者意见的能力。的确，通过自然语言测量态度已经影响了市场营销在日常实践中的方式。<strong>然而，最近的研究发现，情感分析目前强调测量情感的正负面（即积极或消极）可能会产生不完整、不准确甚至误导性的见解</strong>。从概念上讲，这项研究挑战情感分析超越对情感正负面的侧重。作者识别出消费者情感的确定性或信心是一个特别有力的评估方面。从经验上，<strong>他们开发了一种新的计算语言中确定性的测量工具——「确定性词典（Certainty Lexicon）</strong>，并验证了其与情感分析的使用。为了构建和验证这种测量，作者使用了来自1160万人的文本，他们生成了数十亿的词汇，数百万的在线评论，以及在线预测市场的数十万条记录。在社交媒体数据集、实验室实验和在线评论中，作者发现与其他工具相比，确定性词典在其测量中更为全面、可推广和准确。作者还展示了对市场营销者来说，测量情感确定性的价值：确定性预测了广告的实际成功，而传统的情感分析则未能做到这一点。</p>
<p><img loading="lazy" src="img/paper.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="二消费者的确定性">二、消费者的确定性</h2>
<p>为了更好地理解消费者情绪，<strong>我们认为消费者持有该情绪的确定性是至关重要的。确定性是个人对信心或信仰的主观感觉（Petrocelli, Tormala, 和 Rucker 2007）。态度研究的结果表明，消费者对所持有的态度或信仰的确定性越强，该态度或信仰驱动行为的可能性就越大</strong>（参见 Tormala 和 Rucker 2018）。例如，研究表明，当态度持有更大的确定性时，态度和行为意图之间的关联更强（r = .89），而确定性较低时关联较弱（r = .68；Tormala 和 Petty [2002], 实验 4；参见也有 Franc [1999]）。同样，持有更大确定性的想法更能预测人们对这些想法的依赖（Briñol, Petty, 和 Tormala 2004）。在态度文献中，大量的研究表明，持有更大确定性的态度更可能随着时间的推移而持续，并抵御变化（Rucker, Petty, 和 Briñol 2008；Tormala 2016；Tormala 和 Petty 2002）。</p>
<p><strong>确定性还与情感值（sentiment, 即它是积极还是消极）和情感效价（valence, 即情感的价值是多么的正或多么的负）有所不同</strong>（Clarkson, Tormala, 和 Leone 2011；Petty 和 Krosnick 1995）。<strong>虽然更极端的情感值通常与更确定的态度相关联，但这种关联并不强烈</strong>（例如，r ∼ .50；Krosnick 等人 1993）。即使文本中情感效价是相同的，但语言中的确定性的差异也可能很普遍（参见 Rucker 和 Petty 2004；Tormala 和 Petty 2002）。此外，极端态度可能持有的确定性较低（Litt 和 Tormala 2010），并且不太可能随着时间的推移而持续（Rocklage 和 Luttrell 2021）。<strong>因此，确定性 和 情感效价极端性 是不同的</strong>。</p>
<p>举例来说，考虑两位顾客访问同一家餐厅并给予其完美的五星评级。尽管他们对餐厅的态度都是一样的正面，但其中一位可能对其态度更有确定感，因为他们的许多朋友持有类似的态度（Tormala 和 DeSensi 2009）。<strong>尽管态度的情感值完全相同，但确定性更强的顾客更有可能再次光顾餐厅并将其推荐给他人</strong>（例如，Barden 和 Petty 2008）。确定性的差异可以由社交共识的数量或直接的个人经验等因素产生。更普遍地说，确定性可以源于任何影响消费者感觉其态度或信仰背后的信息是准确、完整、相关、合法或重要的因素（Rucker 等人 2014）。</p>
<p><strong>鉴于确定性是态度的一个重要和突出的方面，它是扩展消费者情感评估的理想候选指标</strong>。目前，情感分析主要集中在测量价值上，但忽略了与该价值相关的确定性。此外，研究表明，因为大多数在线表达的消费者情感都是积极的，所以市场营销人员经常面临一个“<strong>positivity problem</strong>”（Rocklage, Rucker, 和 Nordgren 2021b）。这种正面信息的过剩导致了价值的受限范围，仅基于价值或价值极端性就很难获得洞察。<strong>在这些情境中，确定性的测量可能特别有用，确定性可能比情感价更准地预测消费者行为</strong>。</p>
<p><br><br></p>
<h2 id="三语言中的确定性测量">三、语言中的确定性测量</h2>
<h3 id="31-已有测量工具">3.1 已有测量工具</h3>
<p>语言中确定性的两个最突出的度量来自Linguistic Inquiry and Word Count (LIWC; Pennebaker等人2015) 和 DICTION (Hart和Carroll 2015) 软件程序。这两个程序都提供了用于评估文本属性（如其情感）的测量方法。尽管它们也包含与确定性相关的测量，但这些测量在其有效性、普遍性以及它们用于量化语言的方法上都存在局限性。</p>
<p><strong>首先，LIWC 和 DICTION 都没有得到足够的实证验证来测量确定性，也没有经过验证以评估情感确定性</strong>。例如，这两个工具都是基于研究者对哪些词会表示个人的确定性的直觉来创建的，而不是一个更正式或基于数据的方法（Hart 1976；Pennebaker 和 Francis 1996）。LIWC包含两个名为“确定性”和“犹豫”的确定性度量。然而，“<strong>certainty</strong>”测量尚未得到直接验证（Petrie, Booth, 和 Pennebaker 1998），而“<strong>tentativeness</strong>”测量仅在一组35名写有关其大学经历的大学生中得到验证（Pennebaker和Francis 1996）。同样，DICTION的确定性测量尚未直接得到验证（Hart 1976, 1984）。尽管它们有可能作为情感确定性的测量工具，但其有效性和普遍性仍然不清晰。</p>
<p><br><br></p>
<h3 id="32已有工具不足">3.2已有工具不足</h3>
<p>首先，它们都依赖于词频计数方法。考虑LIWC如何量化以下两个句子：（1）“<em>I&rsquo;ve often dislikeed my experience with that brand.</em>”和（2）“<em>I&rsquo;ve sorta dislikeed my experience with that brand.</em>” 。其中 “<strong>often</strong>”和“<strong>sorta</strong>”都出现在LIWC的“<strong>tentativeness</strong>”（<strong>certainty</strong>）词汇表中。根据LIWC的词频计数方法，这两个句子因此都被给予了12.50%的分数（即，八个词中有一个词表示不确定性）。因此， “<strong>often</strong>”和“<strong>sorta</strong>”被计为表示相同程度的不确定性。同样，DICTION给这些句子在确定性上同样的分数。通过简单地计算每个句子中的词，词频计数方法将给定词汇表中的所有词都视为表示相同的确定性。</p>
<p>其次，在测量短文本时候表现较差。这是因为短文本包含的信息相对较少，因此通常只有一个与确定性相关的关键词（Pennebaker等人2015）。鉴于词频计数方法假设给定词典中的所有词都表示相同程度的确定性，这些测量方法可能导致数据中的大偏斜（观察变化小），从而产生大量噪音，因此得到的结果无信息性或甚至具有误导性（Garten等人2018；Rocklage和Rucker 2019；Sterling, Jost, 和 Bonneau 2020）。鉴于市场营销人员依赖社交媒体来了解消费者情感，这一限制对他们尤为重要（Schaefer 2015）。</p>
<p>第三， 只能分析单个词汇，不能处理词组短语。例如，LIWC和DICTION都会将短语“<strong>i&rsquo;m not sure</strong>”视为表示高确定性，因为它包含单词“<strong>sure</strong>”；这些方法无法识别关键短语“<strong>not sure</strong>”。同样，它们会将“<strong>likely</strong>”和“<strong>extremely likely</strong>”视为表示相同程度的确定性。</p>
<p><img loading="lazy" src="img/1-table1.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="四构建确定性词典certainty-lexicon">四、构建确定性词典(Certainty Lexicon)</h2>
<h3 id="41-构建词典步骤">4.1 构建词典步骤</h3>
<p>这篇论文测量消费者确定性的词典叫做Certainty Lexicon， 该词典构建方法及步骤如下</p>
<p><strong>Phase-1</strong> 准备候选词表； 根据LIWC和Diction中的相关词，并生成近义词、ngram词组，以扩充确定性词的候选范围。</p>
<p><strong>Phase-2</strong> 初始剔除工作； 基于真实场景，剔除掉使用低频的词语与词组， 剔除掉人工阅读后觉得不符合确定性这个概念的词。</p>
<p><strong>Phase-3</strong>量化每个词的确定性； 设计9-likert量表(0 = “very uncertain,” and 9 = “very certain”; see Web Appendix B)，通过MTurk在线网站， 发放调查问卷。问题如。收到515多个参与者的问卷，最终保留489有效问卷。</p>
<p><strong>Phase-4</strong> 验证词典有效性;</p>
<p><img loading="lazy" src="img/2-table3.png" alt=""  />
</p>
<h3 id="42-确定性词典">4.2 确定性词典</h3>
<p>论文团队开发了 <strong>LexiconSuite</strong> 文本分析工具，内置了<strong>Evaluate Lexicon</strong>、<strong>Certainty Lexicon</strong>，可以用来分析文本的情感、确定性，工具是开源免费的，下载地址 <a href="http://www.lexicalsuite.com/">http://www.lexicalsuite.com/</a> 。 在LexiconSuite软件安装目录中，经过探索我找到了软件内置的词典txt文件。以本文介绍的<strong>确定性词典</strong>(Certainty Lexicon) ，对应的文件是 <a href="Certainty.txt"><strong>Certainty.txt</strong></a> ，</p>
<p><img loading="lazy" src="img/dict.png" alt=""  />
</p>
<p>打开txt如上图，使用Python读取发现一共有 <strong>3485</strong> 个词语(组)</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_table</span><span class="p">(</span><span class="s1">&#39;Certainty.txt&#39;</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s1">&#39;,&#39;</span><span class="p">)</span>
<span class="n">df</span>
</code></pre></div><p><img loading="lazy" src="img/df.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="四计算文本的确定性">四、计算文本的确定性</h2>
<p>根据确定性词典(Certainty Lexicon), 就可以计算文本的确定性指标， 我在mac安装了<strong>LexiconSuite</strong>并且做了测试，导入了一个<a href="certainty_test.csv"><strong>csv文件</strong></a>。</p>
<p><img loading="lazy" src="img/certainty_test.png" alt=""  />
</p>
<p><img loading="lazy" src="img/ls-1.png" alt=""  />
<br>
<img loading="lazy" src="img/ls-2.png" alt=""  />
<br>
<img loading="lazy" src="img/ls-3.png" alt=""  />
<br>点击<strong>Run New Analysis</strong>
<img loading="lazy" src="img/ls-4.png" alt=""  />
<br>软件运行结果与论文中的Table-1数值是一样的。(额， 准备的实验数据中单词dislike我拼写成了dislikeed的。)
<br>
<img loading="lazy" src="img/ls-6.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>管理世界 | 机器学习如何赋能管理学研究？——国内外前沿综述和未来展望</title>
      <link>https://textdata.cn/blog/2023-10-11-how-can-machine-learning-empower-management-research/</link>
      <pubDate>Wed, 11 Oct 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-10-11-how-can-machine-learning-empower-management-research/</guid>
      <description>机器学习正在深刻改变管理学的研究范式与方法。如何运用机器学习更好地赋能管理学研究已经成为学术界关注的前沿热点议题。然而，机器学习在中国管理学研究中的应用仍处于初级阶段。**本文基于1999～2021年发表在工商管理和会计财务两大研究领域的国内外顶级期刊的学术文献，识别了学术界借助机器学习开展管理学实证研究的4种核心途径：变量测量、事件预测（包括事件分类）、因果推断和理论构建**；梳理了每个途径的代表性文献的研究主题、研究问题、数据集、机器学习算法和研究结论；提出了使用机器学习赋能管理学研究的主要策略，并讨论了中国学者运用机器学习开展中国特色管理理论研究的未来机会。本文显示：将机器学习与传统计量经济学相结合有助于做出更加精准的因果推断；机器学习能够在模式发现这一理论构建的关键步骤中发挥重要作用；将机器学习与多案例分析相结合有助于富有成效地开展理论构建。本文为如何采用机器学习提升管理学研究质量、推进管理学研究范式变革和构建中国特色管理理论提供了方法论指引和方向性启示。</description>
      <content:encoded><![CDATA[<h2 id="一论文">一、论文</h2>
<p>刘景江,郑畅然,洪永淼.<strong>机器学习如何赋能管理学研究？——国内外前沿综述和未来展望</strong>[J].<strong>管理世界</strong>,2023,39(09):191-216.</p>
<p>摘要: 机器学习正在深刻改变管理学的研究范式与方法。如何运用机器学习更好地赋能管理学研究已经成为学术界关注的前沿热点议题。然而，机器学习在中国管理学研究中的应用仍处于初级阶段。<strong>本文基于1999～2021年发表在工商管理和会计财务两大研究领域的国内外顶级期刊的学术文献，识别了学术界借助机器学习开展管理学实证研究的4种核心途径：变量测量、事件预测（包括事件分类）、因果推断和理论构建</strong>；梳理了每个途径的代表性文献的研究主题、研究问题、数据集、机器学习算法和研究结论；提出了使用机器学习赋能管理学研究的主要策略，并讨论了中国学者运用机器学习开展中国特色管理理论研究的未来机会。本文显示：将机器学习与传统计量经济学相结合有助于做出更加精准的因果推断；机器学习能够在模式发现这一理论构建的关键步骤中发挥重要作用；将机器学习与多案例分析相结合有助于富有成效地开展理论构建。本文为如何采用机器学习提升管理学研究质量、推进管理学研究范式变革和构建中国特色管理理论提供了方法论指引和方向性启示。</p>
<br>
<br>
<h2 id="二文献范围">二、文献范围</h2>
<p>首先，本文选取 <strong>UTD-24</strong> 期刊，以“machine learning”、“decision tree”、“support vector machine”、“random forest”、“artificial neural network”和“deep learning”等为关键词，对目标期刊的所有在库文章进 行全篇检索，把正式发表时间限定到 2021 年 12 月末，得到一张包含 1258 篇文献的初步文献清单。其中，会计 领域 52 篇，财务领域 72 篇，信息系统领域 322 篇，营销领域 208 篇，管理科学领域 522 篇，工商管理领域 82 篇。 <strong>考虑到篇幅有限和用途梳理的全面性，本文只关注工商管理和会计财务两大研究领域</strong>  。</p>
<p>接着，类似地，本文选取“2021 中国最具国际影响力学术期刊（人文社会科学）”前 20 名中的管理学期刊， 用相似的关键词，搜寻到 2004~2021 年且运用机器学习方法进行实证研究的文章， 符合标准的论文，有工商管理 15 篇，会计财务 28 篇。</p>
<p><img loading="lazy" src="img/20231011-%e5%8f%91%e6%96%87%e8%b6%8b%e5%8a%bf-%e5%9b%bd%e9%99%85.png" alt=""  />
</p>
<p><img loading="lazy" src="img/20231011-%e5%8f%91%e6%96%87%e8%b6%8b%e5%8a%bf-%e5%9b%bd%e5%86%85.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="三机器学习4大核心用途">三、机器学习4大核心用途</h2>
<p>在确定研究目标后，我们按照以下 3 个步骤对 数据进行编码和文献分析。 第一步，根据以往理论和实证研究，我们总结出机器学习方法在管理学实证研究中的 4 种核心用途: <strong>变量测量、事件预测、因果推断和理论构建</strong>，如图 3 所示。</p>
<p><img loading="lazy" src="img/20231011-%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a04%e5%a4%a7%e6%a0%b8%e5%bf%83%e7%94%a8%e9%80%94.png" alt=""  />
</p>
<ul>
<li>
<p><strong>变量测量</strong>是根据一种规则，用数量的方法描述研究对象所具备的某种特征或行为，其目标是对变量之间的关系进行量化推断（陈晓萍等，2008）。</p>
</li>
<li>
<p><strong>事件预测</strong>是使用已掌握的经验或知识，预先推知和判断事物未来发 展状况（阿西，2019），其目标是预料来自不同观测总体的样本已经或将要在未来实现的结果（格里默等， 2021）。</p>
</li>
<li>
<p><strong>因果推断</strong>是借助理论和对制度细节的深入了解，估计事件和选择对给定结果的影响（坎宁安，2021）， 其目标是比较在同一干预措施下不同反事实（Counterfactual）结果之间的差异（格里默等，2021）。</p>
</li>
<li>
<p><strong>理论构建</strong>是 构建概念及其相互关系，以展示一种现象是如何和为什么发生的过程（焦亚、皮特雷，1990；科利、焦亚，2011； 克里斯蒂安森、钱丹，2017），其目标是建立稳健且具有可解释性的理论。</p>
</li>
</ul>
<p>变量测量、事件预测、因果推断和理论构建是管理学实证研究的 4 项关键任务。 它们既相互区别又紧密关 联。 理论构建在管理学实证研究中占据着核心地位（班伯格，2018）。 管理学顶级期刊格外强调文章的理论贡献（科利、焦亚，2011）。 实证研究的核心目标是理论构建。 衡量一个“好”的实证研究的首要标准是它能够建立稳健且具有可解释性的理论。 因果推断是理论构建的先决条件。 事件预测是因果推断的必要前提。 变量 测量是开展管理学实证研究的根基。 <strong>总之，这 4 个途径相辅相成，构成目的与手段的关系，「变量测量」 是  「事件预测、因果推断和理论构建」 的基础。</strong></p>
<p><br><br></p>
<h2 id="四机器学习在管理学研究中的应用">四、机器学习在管理学研究中的应用</h2>
<p>工商管理和会计财务作为管理学的两大核心研究领域，包含大量来自个人、企业和政府的文本、图像、音 频、视频等极具信息价值的非结构化数据。 传统方法无法对这些非结构化数据进行量化分析，只能进行定性分析。 借助机器学习方法，学者们可以从这些非结构化数据中挖掘、提取和构建诸如高管人格特质、管理者自恋、公司文化、媒体文章语调和投资者情绪等有意义的变量（洪永淼、汪寿阳，2021a，2021b），运用灵活的函数形式和降维技术来实现更精准的预测（洪永淼、汪寿阳，2021b，2021c），利用正则化和交叉验证方法提高模型泛化能力以帮助因果推断和理论构建（蒂德尔、艾森哈特，2020；蒂芬，2019；乔杜里等，2021；瓦里安，2014），从而更好地开展这两大领域中关键问题的实证研究。 因此，本部分以这两大研究领域为例，以机器学习赋能管理学研究的 4 种核心用途为主线，全面回顾和系统梳理 UTD-24 期刊和国内顶级管理学期刊于 1999~2021 年正式发表的文章。 具体来说，本文遵循重点性原则和典型性原则，按照这些领域和用途，总结归纳了代表性文献 的研究主题、研究问题、数据集、机器学习算法和研究结论 ⑧ 。</p>
<h3 id="41-工商管理">4.1 工商管理</h3>
<p><img loading="lazy" src="img/20231011-table-1.png" alt=""  />
</p>
<p><img loading="lazy" src="img/20231011-table-2.png" alt=""  />
</p>
<h3 id="42-会计学">4.2 会计学</h3>
<p><img loading="lazy" src="img/20231011-table-3.png" alt=""  />
</p>
<p><img loading="lazy" src="img/20231011-table-4.png" alt=""  />
</p>
<p><img loading="lazy" src="img/20231011-table-5.png" alt=""  />
</p>
<p><br><br></p>
<p>&hellip;&hellip;</p>
<h2 id="五结论与讨论">五、结论与讨论</h2>
<p>以弥补管理学研究传统上所存在的短板为目标，本研究采用 1999~2021 年发表在工商管理和会计财务两 大研究领域的国内外顶级期刊的学术文献，识别了学术界借助机器学习赋能管理学实证研究的核心途径；从 多个角度系统梳理了这些途径的代表性文献；详细阐述了机器学习赋能管理学研究的主要策略，并重点讨论 了中国学者运用机器学习开展中国特色管理理论研究的未来机会（主题方向、重要问题、实施策略和主要建议）。 本研究得出如表 6 所示的主要结论。 可以预见的是，在未来，变量测量、事件预测、因果推断、理论构建等 4 种核心途径的融合将日益紧密。 它们的融合为机器学习赋能管理学研究提供了更加具有深度和广度的未来机会。 例如，事件预测可以用来揭示数据中难以假设的复杂和未知关系，开发新的理论构念及其测量，或者按照预测的相对精准度比较竞争理论（克鲁帕、米努蒂-梅扎，2022），从而更好地进行理论构建。</p>
<p><img loading="lazy" src="img/20231011-table-6.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>管理科学学报 | 使用LDA算法计算政策扩散速度与扩散程度</title>
      <link>https://textdata.cn/blog/2023-10-10-measure-the-speed-of-policy-diffusion-from-top-to-down/</link>
      <pubDate>Tue, 10 Oct 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-10-10-measure-the-speed-of-policy-diffusion-from-top-to-down/</guid>
      <description>价值不断提升的政府网站内容数据不仅可以描绘政策注意力，也为中央政策向地方层级扩散的测量与评估提供了新的机遇.在我国多层级政府组织治理模式下，地方政府对中央政策的贯彻落地是政策生效的前提条件.对纵向政策扩散的有效测量和评估将有助于理解政策扩散机制，提升政策落地效果.本文基于全国省、市级政府门户网站每日内容更新数据，通过**概率主题建模方法建构主题概率矩阵，刻画政府对不同主题的注意力分配差异，并基于概率主题建模结果构建函数测量地方政府对中央政策的扩散速度与扩散程度。本文讨论了测度建构的原理和细节，并引入机器学习方法进行鲁棒性检验**，通过多政策主题扩散的混合回归分析了影响短周期政策层级扩散的因素.研究以测度建构为突破口打通文本数据挖掘到有价值公共管理知识的“中间层”,对政策信息学在政策扩散及评估监测中的应用前景进行了初步探索.</description>
      <content:encoded><![CDATA[<h2 id="一文献">一、文献</h2>
<p>张楠,黄梅银,罗亚,马宝君.<strong>全国政府网站内容数据中的知识发现：从注意力分配到政策层级扩散</strong>[J].<strong>管理科学学报</strong>,2023,26(05):154-173.</p>
<p>摘要:价值不断提升的政府网站内容数据不仅可以描绘政策注意力，也为中央政策向地方层级扩散的测量与评估提供了新的机遇.在我国多层级政府组织治理模式下，地方政府对中央政策的贯彻落地是政策生效的前提条件.对纵向政策扩散的有效测量和评估将有助于理解政策扩散机制，提升政策落地效果.本文基于全国省、市级政府门户网站每日内容更新数据，通过<strong>概率主题建模方法建构主题概率矩阵，刻画政府对不同主题的注意力分配差异，并基于概率主题建模结果构建函数测量地方政府对中央政策的扩散速度与扩散程度。本文讨论了测度建构的原理和细节，并引入机器学习方法进行鲁棒性检验</strong>，通过多政策主题扩散的混合回归分析了影响短周期政策层级扩散的因素.研究以测度建构为突破口打通文本数据挖掘到有价值公共管理知识的“中间层”,对政策信息学在政策扩散及评估监测中的应用前景进行了初步探索.</p>
<p><br><br></p>
<h2 id="二数据处理">二、数据处理</h2>
<h3 id="21-数据准备">2.1. 数据准备</h3>
<p>基于获取到的 170 万余条政府网站内容数据， 本文选择潜在狄利克雷分配模型 (LDA)进行数据分析，以获取网络政府的政策议题注意力分布情况，数据处理路径见图 １．</p>
<p>数据抓取单位为政府门户网站每一个页面的内容信息， 包括页 面 ＵＲＬ 地址、标题、发布时间、文章发布单位或转载来源、关键词、作者、摘要、具体内容等． 数据入库前，还通过元素提取（如网页名称、大小、日期、 标题、文字内容等）、数据排重和信息过滤（广告过滤、ＵＲＬ 过滤等）等前期处理工作．</p>
<p><img loading="lazy" src="img/20231010-%e5%9f%ba%e4%ba%8eLDA%e7%9a%84%e6%94%bf%e5%ba%9c%e6%b3%a8%e6%84%8f%e5%8a%9b%e5%88%86%e9%85%8d%e6%95%b0%e6%8d%ae%e5%a4%84%e7%90%86%e8%b7%af%e5%be%84.png" alt=""  />
</p>
<br>
<h3 id="22-lda建模">2.2. LDA建模</h3>
<p>LDA建模有两个步骤</p>
<ol>
<li>首先最关键的是确定<strong>文档主题数</strong>，即平均困惑度。论文中平均困惑度为120。</li>
<li>确定好<strong>文档主题数</strong>即可开展LDA训练， 对170w训练出LDA模型，同时得到<strong>文档-主题概率矩阵</strong>， 该矩阵的形状，有120列， 170多万行。<br>
<img loading="lazy" src="img/20231010-%e7%a1%ae%e5%ae%9aLDA%e5%b9%b3%e5%9d%87%e5%9b%b0%e6%83%91%e5%ba%a6%e5%80%bc.png" alt=""  />
</li>
</ol>
<p>训练完LDA模型，虽然文档主题数设置为120， 但经过甄别，最终确定有112个主题具有可解释性。
<img loading="lazy" src="img/20231010-LDA%e4%b8%bb%e9%a2%98%e5%88%97%e8%a1%a8.png" alt=""  />
</p>
<p>下图是主题含义，及概率占比(面积大小)。
<img loading="lazy" src="img/20231010-%e6%94%bf%e5%ba%9c%e7%bd%91%e7%ab%99%e5%af%b9%e4%b8%8d%e5%90%8c%e4%b8%bb%e9%a2%98%e7%9a%84%e6%b3%a8%e6%84%8f%e5%8a%9b%e5%88%86%e9%85%8d%e6%83%85%e5%86%b5.png" alt=""  />
</p>
<br>
<h2 id="23-扩散速度与扩散程度函数构建">2.3. 扩散速度与扩散程度函数构建</h2>
<p><img loading="lazy" src="img/20231010-%e6%94%bf%e7%ad%96%e6%bf%80%e5%8a%b1%e5%93%8d%e5%ba%94%e6%97%b6%e9%97%b4%e7%82%b9.png" alt=""  />
</p>
<p><br><img loading="lazy" src="img/20231010-%e6%94%bf%e7%ad%96%e6%89%a9%e6%95%a3%e9%80%9f%e5%ba%a6.png" alt=""  />

<br><img loading="lazy" src="img/20231010-%e5%93%8d%e5%ba%94%e6%94%bf%e7%ad%96%e7%9a%84%e6%8c%81%e7%bb%ad%e6%80%a7%e5%9b%9e%e5%ba%94%e7%a8%8b%e5%ba%a61.png" alt=""  />
</p>
<p><img loading="lazy" src="img/20231010-%e5%93%8d%e5%ba%94%e6%94%bf%e7%ad%96%e7%9a%84%e6%8c%81%e7%bb%ad%e6%80%a7%e5%9b%9e%e5%ba%94%e7%a8%8b%e5%ba%a62.png" alt=""  />
<br></p>
<p>面对中央政府希望通过政府网站和其他网络政府入口监测政策落实、督查政府履职、评估回应能力的一系列需求， 本文尝试基于网络政 府大数据的对中央政策扩散情况展开分析． 图４ 展示了 2018 年地级市对中央 １３ 项政策的回应扩散速度情况． <strong>曲线越扁平，地级市政府扩散响应 时间越短， 层级扩散速度越快</strong>． 平均扩散速度为 20.04 天，意味着中央出台政策后地级市政府网站 上平均 20 天就会对中央政策予以回应． 其中， 地 级市政府回应最快的是医疗卫生监管主题， 平均 扩散时间为 12.07  天，最慢的是土地使用权主题，达 25.11 天． 从 0.5 分位数来看，当不同政策主题的中央政策激励产生后， 超过一半的城市在 20 天内快速响应中央政策， 不同政策主题扩散速度存在差异．</p>
<p><img loading="lazy" src="img/20231010-%e6%94%bf%e5%ba%9c%e5%93%8d%e5%ba%94%e9%80%9f%e5%ba%a6.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>企业ESG行为的文本度量法</title>
      <link>https://textdata.cn/blog/2023-10-07-esg-measurement/</link>
      <pubDate>Sat, 07 Oct 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-10-07-esg-measurement/</guid>
      <description>本文一个关键的贡献是使用机器学习方法从文本数据中评估初创公司环境、社会和治理（ESG）属性</description>
      <content:encoded><![CDATA[<h2 id="文献">文献</h2>
<p>Mansouri S, Momtaz P P. Financing sustainable entrepreneurship: ESG measurement, valuation, and performance[J]. <em>Journal of Business Venturing</em>, 2022, 37(6):106258.</p>
<br>
<h2 id="摘要">摘要</h2>
<p>可持续发展导向对初创企业的初始估值有积极影响，但对其融资后财务业绩有负面影响。 在其他条件相同的情况下，将可持续发展方向提高一个标准差将使初创公司的融资金额增加 28%，并将投资者每个融资后年度的异常回报减少 16%。 结果适用于基于区块链的众筹活动（也称为首次代币发行（ICO）或代币发行）的大量样本。<strong>本文一个关键的贡献是使用机器学习方法从文本数据中评估初创公司环境、社会和治理（ESG）属性</strong></p>
<br>
<br>
<h2 id="量化初创企业的esg属性">量化初创企业的ESG属性</h2>
<p>现有研究对如何衡量初创企业的ESG属性还未形成统一框架，且存在以下两个问题：（1）现有的ESG指标主要由几个数据供应商提供，而供应商之间的相关性非常低；（2）现有的ESG评级不适用于初创企业，即存在数据缺失。因此，本文采用一种机器学习的方法，量化初创企业的ESG属性：</p>
<ol>
<li>
<p><strong>文本预处理</strong>： 获取数据及预处理从公司网站等收集ICO白皮书后，使用斯坦福大学开发的CoreNLP管道生成句子的依赖性表示，并识别一些搭配词；</p>
</li>
<li>
<p><strong>建立种子词</strong>：收集《金融时报》中所有带有“ESG投资、道德金钱”标签的文章，采用标准的词袋模型提炼出现频率最高的二元组、三元组词汇，然后对这些词汇进行人工筛查，并在此基础上手动添加一些与代币发行有关的词汇，得到三个维度的种子词数为：70、38、46；</p>
</li>
<li>
<p><strong>选取联想词</strong>：使用Word2vec模型扩充种子词，为ESG的每个维度挑选500个最为相近的术语，经再次筛查后，得到三个维度的词典数量为：508、463、524；</p>
</li>
<li>
<p><strong>计算ESG分数</strong></p>
<p><img loading="lazy" src="formular.png" alt=""  />
</p>
<p>在（1）式中，代表白皮书i中术语的计数，c(n)是相应的单词列表的大小，即用频率来表征企业在某一维度的得分，然后将三个维度的得分加总得到最终的ESG分数；</p>
</li>
</ol>
<p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>可视化 | 2021年幸福指数&amp;人口数据可视化最佳实践</title>
      <link>https://textdata.cn/blog/2023-08-31-data_eda_2021_happiness_and_population/</link>
      <pubDate>Thu, 31 Aug 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-08-31-data_eda_2021_happiness_and_population/</guid>
      <description>&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;作者: JOSH
原文: https://www.kaggle.com/code/joshuaswords/awesome-eda-2021-happiness-population/notebook
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h2 id=&#34;幸福指数&#34;&gt;幸福指数&lt;/h2&gt;
&lt;p&gt;本笔记本纯粹是一项探索性数据分析，目的是看看我能否找出使一个国家感到幸福或不幸的因素。为此，我将分析和探索&lt;strong&gt;2021年的世界幸福指数&lt;/strong&gt;，以及&lt;strong&gt;自2005年以来的历史世界幸福指数数据&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;我希望在这个过程中能学到一些东西，也希望读到这篇文章的任何人也能如此。&lt;/p&gt;
&lt;p&gt;另外，我会引入人口数据来研究这是否与幸福水平有明显的联系。&lt;/p&gt;
&lt;p&gt;我还将探索各国是否能够随着时间的推移改善其排名，或者这些排名是否基本保持不变。&lt;/p&gt;
&lt;p&gt;最后，我将使用K均值和肘部方法正式地对我们的数据进行聚类，以查看我们是否可以根据数据集中各种指标的分数将国家分组在一起。&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;准备工作&#34;&gt;准备工作&lt;/h2&gt;
&lt;p&gt;安装必要的包&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;pip3 install pywaffle, geopandas, pycountry 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;本文代码较多， 只展示部分代码，&lt;a href=&#34;code.zip&#34;&gt;点击完整的代码&amp;amp;数据&lt;/a&gt;，请前往textdata.cn下载&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;&lt;br&gt; 导入数据&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pandas&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pd&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;warnings&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;warnings&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;filterwarnings&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;ignore&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;        
&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;matplotlib&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;plt&lt;/span&gt;


&lt;span class=&#34;c1&#34;&gt;#get data&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read_csv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;data/world-happiness-report-2021.csv&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;df2&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read_csv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;data/world-happiness-report.csv&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;pop&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read_csv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;data/population_by_country_2020.csv&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;safety&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;copy&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;# 统一不同数据中的字段名renaming columns for easier merge later&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;rename&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;columns&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;Country name&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;Country&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;},&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;inplace&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;df2&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;rename&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;columns&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;Country name&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;Country&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;},&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;inplace&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;pop&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;rename&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;columns&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;Country (or dependency)&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;Country&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;},&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;inplace&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;#might use later &lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;temporal&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;df2&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;groupby&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;([&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;year&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;Country&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;Life Ladder&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mean&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;unstack&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;T&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;temporal&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;temporal&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fillna&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;astype&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;int&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;# colours&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;low_c&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;#dd4124&amp;#39;&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;high_c&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;#009473&amp;#39;&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;plt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;rcParams&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;font.family&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;monospace&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;初始概览&#34;&gt;初始概览&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# inspiration ; https://www.kaggle.com/gaetanlopez/how-to-make-clean-visualizations&lt;/span&gt;
&lt;span class=&#34;c1&#34;&gt;# changed code signif.&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;fig&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;plt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;figure&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;figsize&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;6&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dpi&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;150&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;gs&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;fig&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;add_gridspec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;gs&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;update&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wspace&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;0.2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;hspace&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;0.4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;ax0&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;fig&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;add_subplot&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;gs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;background_color&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;#fafafa&amp;#34;&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;fig&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;patch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;set_facecolor&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;background_color&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# figure background color&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;ax0&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;set_facecolor&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;background_color&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; 

&lt;span class=&#34;n&#34;&gt;ax0&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;1.167&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;0.85&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;2021 World Happiness Index&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;color&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;#323232&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fontsize&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;28&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;fontweight&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;bold&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;fontfamily&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;sanserif&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ha&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;center&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;ax0&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;1.13&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;0.35&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;stand-out facts&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;color&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;lightgray&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fontsize&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;28&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;fontweight&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;bold&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;fontfamily&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;monospace&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ha&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;center&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;ax0&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;0.4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Finland&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;color&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;high_c&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fontsize&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;25&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;fontweight&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;bold&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;fontfamily&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;monospace&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ha&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;center&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;ax0&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;0.1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Happiest&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;color&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;gray&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fontsize&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;15&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;fontfamily&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;monospace&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ha&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;center&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;ax0&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;0.77&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;0.4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;9 of top 10&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;color&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;high_c&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fontsize&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;25&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;fontweight&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;bold&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;fontfamily&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;monospace&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ha&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;center&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;ax0&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;0.75&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;0.1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;in Europe&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;color&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;gray&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fontsize&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;15&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;fontfamily&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;monospace&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ha&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;center&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;ax0&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;1.5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;0.4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;7 of bottom 10&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;color&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;low_c&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fontsize&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;25&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;fontweight&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;bold&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;fontfamily&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;monospace&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ha&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;center&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;ax0&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;1.5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;0.1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;in Africa&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;color&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;gray&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fontsize&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;15&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;fontfamily&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;monospace&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ha&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;center&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;ax0&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;2.25&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;0.4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Afghanistan&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;color&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;low_c&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fontsize&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;25&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;fontweight&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;bold&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;fontfamily&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;monospace&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ha&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;center&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;ax0&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;2.25&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;0.1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Unhappiest&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;color&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;gray&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fontsize&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;15&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;fontfamily&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;monospace&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ha&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;center&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;ax0&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;set_yticklabels&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;ax0&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;set_xticklabels&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;ax0&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;tick_params&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;axis&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;both&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;length&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;

&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;s&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;top&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;right&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;left&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;bottom&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]:&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;ax0&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;spines&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;s&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;set_visible&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;False&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
    
&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;matplotlib.lines&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;lines&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;l1&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;lines&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Line2D&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;([&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;0.15&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;1.95&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;0.67&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;0.67&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;transform&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fig&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;transFigure&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;figure&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fig&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;color&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;gray&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;linestyle&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;-&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;linewidth&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;1.1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;alpha&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;.5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;fig&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;lines&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;extend&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;([&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;l1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;l2&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;lines&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Line2D&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;([&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;0.15&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;1.95&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;0.07&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;0.07&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;transform&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fig&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;transFigure&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;figure&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fig&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;color&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;gray&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;linestyle&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;-&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;linewidth&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;1.1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;alpha&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;.5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;fig&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;lines&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;extend&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;([&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;l2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
    
&lt;span class=&#34;n&#34;&gt;plt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;show&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/output_4_1.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;世界上最幸福的国家是哪些&#34;&gt;世界上最幸福的国家是哪些？&lt;/h2&gt;
&lt;p&gt;对我来说，&#39;&lt;strong&gt;幸福&lt;/strong&gt;&amp;lsquo;似乎是一个个体化的指标，很难进行概括。然而，有些国家在幸福指数排名中表现始终稳定。&lt;/p&gt;
&lt;p&gt;我们还注意到，前10名中有9个是欧洲国家，而后10名中有7个是非洲国家。&lt;/p&gt;
&lt;p&gt;让我们看看目前位于列表顶端的国家，以及那些位于底部的国家。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/output_6_0.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
现在让我们把前10名和后10名并排放置，以便从另一个角度观察。
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/output_8_0.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;p&gt;乍一看，我们发现世界上最幸福的许多国家确实位于欧洲。&lt;/p&gt;
&lt;p&gt;另一个额外的观察是，位于前10名的欧洲国家都是北欧国家。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;happiness_mean&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;Ladder score&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mean&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;lower_happy&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;Ladder score&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;apply&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;lambda&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;happiness_mean&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;else&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;这种情况经常发生吗&#34;&gt;这种情况经常发生吗？&lt;/h2&gt;
&lt;p&gt;稍后我将更深入地探索时间上的变化，但现在，让我们看一下这些年来排在前20名的国家。&lt;/p&gt;
&lt;p&gt;这个图展示了从2005年至今，前20名国家的所有分数，特别突出了它们的平均分和2021年的分数。&lt;/p&gt;
&lt;p&gt;值得注意的是，尽管有疫情的影响，许多国家在2021年的分数比他们的平均分还要高。&lt;/p&gt;
&lt;p&gt;尽管这些分数确实有所不同，但它们仍然相对较高。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/output_12_1.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;为什么会有差异&#34;&gt;为什么会有差异？&lt;/h2&gt;
&lt;p&gt;我们现在了解到，北欧国家一直位居榜首。&lt;/p&gt;
&lt;p&gt;让我们更仔细地探究一下欧洲与世界其他地区之间的这些差异。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/output_14_1.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;幸福程度较高的国家往往是那些预期寿命更长、GDP更高的国家。这也基本上包括了西欧。&lt;/p&gt;
&lt;p&gt;现在让我们明确地关注一下非洲&amp;hellip;&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/output_16_1.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;总体而言，非洲国家有更低的预期寿命、更低的GDP，最终也有更低的幸福指数分数。&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;其他因素&#34;&gt;其他因素&lt;/h2&gt;
&lt;p&gt;因此，GDP和预期寿命是影响因素。还有什么其他因素可以考虑呢？&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/output_18_1.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;正如我在图中指出的，自由和腐败是成反比的关系：更高的腐败通常伴随着更低的自由度。&lt;/p&gt;
&lt;p&gt;然而，有趣的是需要注意的是，几个欧洲国家也有高度认知的腐败水平。&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;大陆视角&#34;&gt;大陆视角&lt;/h2&gt;
&lt;p&gt;让我们将这些国家按照各自所属的大陆分类，看看我们能否了解更多。&lt;/p&gt;
&lt;p&gt;当然，我们预期西欧会排名很高，但是在幸福排名中，还有没有其他表现特别好或特别差的大陆？&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/output_20_1.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;p&gt;可以清晰地看到有三个大陆群体。稍后将对此进行更多讨论&amp;hellip;&lt;/p&gt;
&lt;p&gt;撒哈拉以南非洲和南亚的分数最低。而西欧以及北美和澳新（ANZ）则遥遥领先，位于榜单的顶端。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;continent_score&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;groupby&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;Regional indicator&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)[[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;Healthy life expectancy&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;Logged GDP per capita&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;Perceptions of corruption&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;Freedom to make life choices&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;Ladder score&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mean&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mean&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;axis&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sort_values&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ascending&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)[:&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;df_bottom&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;groupby&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;Country&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)[[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;Logged GDP per capita&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;Perceptions of corruption&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;Freedom to make life choices&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;Social support&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;Ladder score&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mean&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sort_values&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;by&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;Ladder score&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ascending&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)[:&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;df_bottom&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;Logged GDP per capita&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;df_bottom&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;Logged GDP per capita&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;df_bottom&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;Ladder score&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;df_bottom&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;Ladder score&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;categorical&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;var&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;var&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;columns&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;var&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dtype&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;==&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;O&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;continuous&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;var&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;var&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;columns&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;var&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dtype&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;!=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;O&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;#refined&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;continuous&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;Logged GDP per capita&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
 &lt;span class=&#34;s1&#34;&gt;&amp;#39;Social support&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
 &lt;span class=&#34;s1&#34;&gt;&amp;#39;Healthy life expectancy&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
 &lt;span class=&#34;s1&#34;&gt;&amp;#39;Freedom to make life choices&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
 &lt;span class=&#34;s1&#34;&gt;&amp;#39;Generosity&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
 &lt;span class=&#34;s1&#34;&gt;&amp;#39;Perceptions of corruption&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;高于和低于平均幸福水平的差异&#34;&gt;高于和低于平均幸福水平的差异&lt;/h2&gt;
&lt;p&gt;让我们一次绘制多个特征，按照平均幸福水平进行划分。如往常一样，最幸福的国家以绿色显示。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/output_24_1.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;上面的图表确认了我们之前看到的一些内容，并带有一些值得注意的特点，比如社会支持。&lt;/p&gt;
&lt;p&gt;在不太幸福的国家中，慷慨度被认为更高，这非常有趣。&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;全球视角&#34;&gt;全球视角&lt;/h2&gt;
&lt;p&gt;我们现在已经看到了基于多个因素不同国家之间明显的差异。&lt;/p&gt;
&lt;p&gt;现在让我们从全球角度来看这个问题。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/output_26_1.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;这张图确认了我们之前的发现，南亚和非洲处于红色区域。&lt;/p&gt;
&lt;p&gt;但它也突出了我们可以进一步调查的地区。例如，中国和印度都在红色区域，它们的人口都超过了10亿。我们能否研究人口与幸福水平之间的关系？
&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;人口&#34;&gt;人口&lt;/h2&gt;
&lt;p&gt;让我们引入更多的因素——比如人口。&lt;/p&gt;
&lt;p&gt;这是否会影响幸福水平？&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/output_28_1.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;我们清晰地看到，更幸福的国家往往年龄更大，人口更少。&lt;/p&gt;
&lt;p&gt;我加入了欧洲作为参考。&lt;/p&gt;
&lt;p&gt;那么生育率呢？&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/output_30_1.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;正如我所怀疑的，更幸福的国家通常也有更少的孩子。这很可能是由于可以更容易地获得避孕方法。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/output_32_1.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;我很惊讶人口密度并不影响幸福感——尽管这可能是因为个人偏好！&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;随着时间的推移有没有变化&#34;&gt;随着时间的推移，有没有变化？&lt;/h2&gt;
&lt;p&gt;不快乐的人会变得更快乐吗？&lt;/p&gt;
&lt;p&gt;这仅仅是一个时间点的快照吗？还是这些趋势更加持久？&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/output_34_1.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;p&gt;令人关注的是，不快乐的人依然不快乐，更糟糕的是，他们似乎变得更加不快乐。&lt;/p&gt;
&lt;p&gt;这种趋势是持续的吗？或者某些国家的分数会随着时间的推移而提高？&lt;/p&gt;
&lt;p&gt;让我们更多地探讨一下随时间变化的情况。&lt;/p&gt;
&lt;p&gt;在上面，我选取了几个国家作为样本。让我们用一个斜率图来绘制他们从2007年到2020年的变化，看看我们能否从中学到什么。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/output_36_1.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;p&gt;显然，多年来确实有很多变化。&lt;/p&gt;
&lt;p&gt;哪些国家经历了最大的变化？&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/output_38_0.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/output_39_0.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;p&gt;让我们比较在幸福指数得分方面增长最多和下降最多的两个国家：保加利亚和约旦。&lt;/p&gt;
&lt;p&gt;我们将对比他们多年来的表现。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/output_41_0.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;p&gt;当我探究这个关于时间变化的观点时，我想从大陆的角度来看。&lt;/p&gt;
&lt;p&gt;例如，西欧的所有国家都“幸福”吗？&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/output_43_1.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;广而告之&#34;&gt;广而告之&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/call_for_paper/&#34;&gt;长期征稿&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/we_need_you/&#34;&gt;长期招募小伙伴&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/management_python_course/&#34;&gt;付费视频课 | Python实证指标构建与文本分析&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
      <content:encoded><![CDATA[<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">作者: JOSH
原文: https://www.kaggle.com/code/joshuaswords/awesome-eda-2021-happiness-population/notebook
</code></pre></div><br>
<h2 id="幸福指数">幸福指数</h2>
<p>本笔记本纯粹是一项探索性数据分析，目的是看看我能否找出使一个国家感到幸福或不幸的因素。为此，我将分析和探索<strong>2021年的世界幸福指数</strong>，以及<strong>自2005年以来的历史世界幸福指数数据</strong>。</p>
<p>我希望在这个过程中能学到一些东西，也希望读到这篇文章的任何人也能如此。</p>
<p>另外，我会引入人口数据来研究这是否与幸福水平有明显的联系。</p>
<p>我还将探索各国是否能够随着时间的推移改善其排名，或者这些排名是否基本保持不变。</p>
<p>最后，我将使用K均值和肘部方法正式地对我们的数据进行聚类，以查看我们是否可以根据数据集中各种指标的分数将国家分组在一起。</p>
<p><br><br></p>
<h2 id="准备工作">准备工作</h2>
<p>安装必要的包</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">pip3 install pywaffle, geopandas, pycountry 
</code></pre></div><p><strong>本文代码较多， 只展示部分代码，<a href="code.zip">点击完整的代码&amp;数据</a>，请前往textdata.cn下载</strong>。</p>
<p><br> 导入数据</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&#34;ignore&#34;</span><span class="p">)</span>        
<span class="kn">import</span> <span class="nn">matplotlib</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>


<span class="c1">#get data</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;data/world-happiness-report-2021.csv&#39;</span><span class="p">)</span>
<span class="n">df2</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;data/world-happiness-report.csv&#39;</span><span class="p">)</span>
<span class="n">pop</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;data/population_by_country_2020.csv&#39;</span><span class="p">)</span>

<span class="n">safety</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

<span class="c1"># 统一不同数据中的字段名renaming columns for easier merge later</span>
<span class="n">df</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;Country name&#39;</span><span class="p">:</span> <span class="s1">&#39;Country&#39;</span><span class="p">},</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">df2</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;Country name&#39;</span><span class="p">:</span> <span class="s1">&#39;Country&#39;</span><span class="p">},</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">pop</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;Country (or dependency)&#39;</span><span class="p">:</span> <span class="s1">&#39;Country&#39;</span><span class="p">},</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1">#might use later </span>
<span class="n">temporal</span> <span class="o">=</span> <span class="n">df2</span><span class="o">.</span><span class="n">groupby</span><span class="p">([</span><span class="s1">&#39;year&#39;</span><span class="p">,</span><span class="s1">&#39;Country&#39;</span><span class="p">])[</span><span class="s1">&#39;Life Ladder&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">unstack</span><span class="p">()</span><span class="o">.</span><span class="n">T</span>
<span class="n">temporal</span> <span class="o">=</span> <span class="n">temporal</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>

<span class="c1"># colours</span>
<span class="n">low_c</span> <span class="o">=</span> <span class="s1">&#39;#dd4124&#39;</span>
<span class="n">high_c</span> <span class="o">=</span> <span class="s1">&#39;#009473&#39;</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s2">&#34;font.family&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&#34;monospace&#34;</span>
</code></pre></div><p><br><br></p>
<h2 id="初始概览">初始概览</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1"># inspiration ; https://www.kaggle.com/gaetanlopez/how-to-make-clean-visualizations</span>
<span class="c1"># changed code signif.</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span><span class="n">dpi</span><span class="o">=</span><span class="mi">150</span><span class="p">)</span>
<span class="n">gs</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_gridspec</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">gs</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.4</span><span class="p">)</span>
<span class="n">ax0</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="n">gs</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>

<span class="n">background_color</span> <span class="o">=</span> <span class="s2">&#34;#fafafa&#34;</span>
<span class="n">fig</span><span class="o">.</span><span class="n">patch</span><span class="o">.</span><span class="n">set_facecolor</span><span class="p">(</span><span class="n">background_color</span><span class="p">)</span> <span class="c1"># figure background color</span>
<span class="n">ax0</span><span class="o">.</span><span class="n">set_facecolor</span><span class="p">(</span><span class="n">background_color</span><span class="p">)</span> 

<span class="n">ax0</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">1.167</span><span class="p">,</span><span class="mf">0.85</span><span class="p">,</span><span class="s2">&#34;2021 World Happiness Index&#34;</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;#323232&#39;</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">28</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">,</span> <span class="n">fontfamily</span><span class="o">=</span><span class="s1">&#39;sanserif&#39;</span><span class="p">,</span><span class="n">ha</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">)</span>
<span class="n">ax0</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">1.13</span><span class="p">,</span><span class="o">-</span><span class="mf">0.35</span><span class="p">,</span><span class="s2">&#34;stand-out facts&#34;</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;lightgray&#39;</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">28</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">,</span> <span class="n">fontfamily</span><span class="o">=</span><span class="s1">&#39;monospace&#39;</span><span class="p">,</span><span class="n">ha</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">)</span>

<span class="n">ax0</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mf">0.4</span><span class="p">,</span><span class="s2">&#34;Finland&#34;</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="n">high_c</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">,</span> <span class="n">fontfamily</span><span class="o">=</span><span class="s1">&#39;monospace&#39;</span><span class="p">,</span><span class="n">ha</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">)</span>
<span class="n">ax0</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mf">0.1</span><span class="p">,</span><span class="s2">&#34;Happiest&#34;</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">fontfamily</span><span class="o">=</span><span class="s1">&#39;monospace&#39;</span><span class="p">,</span><span class="n">ha</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">)</span>

<span class="n">ax0</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">0.77</span><span class="p">,</span><span class="mf">0.4</span><span class="p">,</span><span class="s2">&#34;9 of top 10&#34;</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="n">high_c</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">,</span> <span class="n">fontfamily</span><span class="o">=</span><span class="s1">&#39;monospace&#39;</span><span class="p">,</span><span class="n">ha</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">)</span>
<span class="n">ax0</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">0.75</span><span class="p">,</span><span class="mf">0.1</span><span class="p">,</span><span class="s2">&#34;in Europe&#34;</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">fontfamily</span><span class="o">=</span><span class="s1">&#39;monospace&#39;</span><span class="p">,</span><span class="n">ha</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">)</span>

<span class="n">ax0</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">0.4</span><span class="p">,</span><span class="s2">&#34;7 of bottom 10&#34;</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="n">low_c</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">,</span> <span class="n">fontfamily</span><span class="o">=</span><span class="s1">&#39;monospace&#39;</span><span class="p">,</span><span class="n">ha</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">)</span>
<span class="n">ax0</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">0.1</span><span class="p">,</span><span class="s2">&#34;in Africa&#34;</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">fontfamily</span><span class="o">=</span><span class="s1">&#39;monospace&#39;</span><span class="p">,</span><span class="n">ha</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">)</span>

<span class="n">ax0</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">2.25</span><span class="p">,</span><span class="mf">0.4</span><span class="p">,</span><span class="s2">&#34;Afghanistan&#34;</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="n">low_c</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">,</span> <span class="n">fontfamily</span><span class="o">=</span><span class="s1">&#39;monospace&#39;</span><span class="p">,</span><span class="n">ha</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">)</span>
<span class="n">ax0</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">2.25</span><span class="p">,</span><span class="mf">0.1</span><span class="p">,</span><span class="s2">&#34;Unhappiest&#34;</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">fontfamily</span><span class="o">=</span><span class="s1">&#39;monospace&#39;</span><span class="p">,</span><span class="n">ha</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">)</span>

<span class="n">ax0</span><span class="o">.</span><span class="n">set_yticklabels</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
<span class="n">ax0</span><span class="o">.</span><span class="n">set_xticklabels</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
<span class="n">ax0</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s1">&#39;both&#39;</span><span class="p">,</span><span class="n">length</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;top&#39;</span><span class="p">,</span><span class="s1">&#39;right&#39;</span><span class="p">,</span><span class="s1">&#39;left&#39;</span><span class="p">,</span><span class="s1">&#39;bottom&#39;</span><span class="p">]:</span>
    <span class="n">ax0</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="n">s</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
    
<span class="kn">import</span> <span class="nn">matplotlib.lines</span> <span class="k">as</span> <span class="nn">lines</span>
<span class="n">l1</span> <span class="o">=</span> <span class="n">lines</span><span class="o">.</span><span class="n">Line2D</span><span class="p">([</span><span class="mf">0.15</span><span class="p">,</span> <span class="mf">1.95</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.67</span><span class="p">,</span> <span class="mf">0.67</span><span class="p">],</span> <span class="n">transform</span><span class="o">=</span><span class="n">fig</span><span class="o">.</span><span class="n">transFigure</span><span class="p">,</span> <span class="n">figure</span><span class="o">=</span><span class="n">fig</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;gray&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;-&#39;</span><span class="p">,</span><span class="n">linewidth</span> <span class="o">=</span> <span class="mf">1.1</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">.5</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">lines</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="n">l1</span><span class="p">])</span>
<span class="n">l2</span> <span class="o">=</span> <span class="n">lines</span><span class="o">.</span><span class="n">Line2D</span><span class="p">([</span><span class="mf">0.15</span><span class="p">,</span> <span class="mf">1.95</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.07</span><span class="p">,</span> <span class="mf">0.07</span><span class="p">],</span> <span class="n">transform</span><span class="o">=</span><span class="n">fig</span><span class="o">.</span><span class="n">transFigure</span><span class="p">,</span> <span class="n">figure</span><span class="o">=</span><span class="n">fig</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;gray&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;-&#39;</span><span class="p">,</span><span class="n">linewidth</span> <span class="o">=</span> <span class="mf">1.1</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">.5</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">lines</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="n">l2</span><span class="p">])</span>
    
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/output_4_1.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="世界上最幸福的国家是哪些">世界上最幸福的国家是哪些？</h2>
<p>对我来说，'<strong>幸福</strong>&lsquo;似乎是一个个体化的指标，很难进行概括。然而，有些国家在幸福指数排名中表现始终稳定。</p>
<p>我们还注意到，前10名中有9个是欧洲国家，而后10名中有7个是非洲国家。</p>
<p>让我们看看目前位于列表顶端的国家，以及那些位于底部的国家。</p>
<p><img loading="lazy" src="img/output_6_0.png" alt=""  />
</p>
<br>
现在让我们把前10名和后10名并排放置，以便从另一个角度观察。
<p><img loading="lazy" src="img/output_8_0.png" alt=""  />
</p>
<br>
<p>乍一看，我们发现世界上最幸福的许多国家确实位于欧洲。</p>
<p>另一个额外的观察是，位于前10名的欧洲国家都是北欧国家。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">happiness_mean</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Ladder score&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

<span class="n">df</span><span class="p">[</span><span class="s1">&#39;lower_happy&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Ladder score&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="mi">0</span> <span class="k">if</span> <span class="n">x</span> <span class="o">&lt;</span> <span class="n">happiness_mean</span> <span class="k">else</span> <span class="mi">1</span><span class="p">)</span>
</code></pre></div><p><br><br></p>
<h2 id="这种情况经常发生吗">这种情况经常发生吗？</h2>
<p>稍后我将更深入地探索时间上的变化，但现在，让我们看一下这些年来排在前20名的国家。</p>
<p>这个图展示了从2005年至今，前20名国家的所有分数，特别突出了它们的平均分和2021年的分数。</p>
<p>值得注意的是，尽管有疫情的影响，许多国家在2021年的分数比他们的平均分还要高。</p>
<p>尽管这些分数确实有所不同，但它们仍然相对较高。</p>
<p><img loading="lazy" src="img/output_12_1.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="为什么会有差异">为什么会有差异？</h2>
<p>我们现在了解到，北欧国家一直位居榜首。</p>
<p>让我们更仔细地探究一下欧洲与世界其他地区之间的这些差异。</p>
<p><img loading="lazy" src="img/output_14_1.png" alt=""  />
</p>
<p>幸福程度较高的国家往往是那些预期寿命更长、GDP更高的国家。这也基本上包括了西欧。</p>
<p>现在让我们明确地关注一下非洲&hellip;</p>
<p><img loading="lazy" src="img/output_16_1.png" alt=""  />
</p>
<p>总体而言，非洲国家有更低的预期寿命、更低的GDP，最终也有更低的幸福指数分数。</p>
<p><br><br></p>
<h2 id="其他因素">其他因素</h2>
<p>因此，GDP和预期寿命是影响因素。还有什么其他因素可以考虑呢？</p>
<p><img loading="lazy" src="img/output_18_1.png" alt=""  />
</p>
<p>正如我在图中指出的，自由和腐败是成反比的关系：更高的腐败通常伴随着更低的自由度。</p>
<p>然而，有趣的是需要注意的是，几个欧洲国家也有高度认知的腐败水平。</p>
<p><br><br></p>
<h2 id="大陆视角">大陆视角</h2>
<p>让我们将这些国家按照各自所属的大陆分类，看看我们能否了解更多。</p>
<p>当然，我们预期西欧会排名很高，但是在幸福排名中，还有没有其他表现特别好或特别差的大陆？</p>
<p><img loading="lazy" src="img/output_20_1.png" alt=""  />
</p>
<br>
<p>可以清晰地看到有三个大陆群体。稍后将对此进行更多讨论&hellip;</p>
<p>撒哈拉以南非洲和南亚的分数最低。而西欧以及北美和澳新（ANZ）则遥遥领先，位于榜单的顶端。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">continent_score</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;Regional indicator&#39;</span><span class="p">)[[</span><span class="s1">&#39;Healthy life expectancy&#39;</span><span class="p">,</span><span class="s1">&#39;Logged GDP per capita&#39;</span><span class="p">,</span><span class="s1">&#39;Perceptions of corruption&#39;</span><span class="p">,</span><span class="s1">&#39;Freedom to make life choices&#39;</span><span class="p">,</span><span class="s1">&#39;Ladder score&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="kc">True</span><span class="p">)[:</span><span class="mi">10</span><span class="p">]</span>

<span class="n">df_bottom</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;Country&#39;</span><span class="p">)[[</span><span class="s1">&#39;Logged GDP per capita&#39;</span><span class="p">,</span><span class="s1">&#39;Perceptions of corruption&#39;</span><span class="p">,</span><span class="s1">&#39;Freedom to make life choices&#39;</span><span class="p">,</span><span class="s1">&#39;Social support&#39;</span><span class="p">,</span><span class="s1">&#39;Ladder score&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="s1">&#39;Ladder score&#39;</span><span class="p">,</span><span class="n">ascending</span><span class="o">=</span><span class="kc">True</span><span class="p">)[:</span><span class="mi">10</span><span class="p">]</span>

<span class="n">df_bottom</span><span class="p">[</span><span class="s1">&#39;Logged GDP per capita&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_bottom</span><span class="p">[</span><span class="s1">&#39;Logged GDP per capita&#39;</span><span class="p">]</span><span class="o">/</span><span class="mi">10</span>
<span class="n">df_bottom</span><span class="p">[</span><span class="s1">&#39;Ladder score&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_bottom</span><span class="p">[</span><span class="s1">&#39;Ladder score&#39;</span><span class="p">]</span><span class="o">/</span><span class="mi">5</span>

<span class="n">categorical</span> <span class="o">=</span> <span class="p">[</span><span class="n">var</span> <span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span> <span class="k">if</span> <span class="n">df</span><span class="p">[</span><span class="n">var</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span><span class="o">==</span><span class="s1">&#39;O&#39;</span><span class="p">]</span>
<span class="n">continuous</span> <span class="o">=</span> <span class="p">[</span><span class="n">var</span> <span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span> <span class="k">if</span> <span class="n">df</span><span class="p">[</span><span class="n">var</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span><span class="o">!=</span><span class="s1">&#39;O&#39;</span><span class="p">]</span>

<span class="c1">#refined</span>
<span class="n">continuous</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Logged GDP per capita&#39;</span><span class="p">,</span>
 <span class="s1">&#39;Social support&#39;</span><span class="p">,</span>
 <span class="s1">&#39;Healthy life expectancy&#39;</span><span class="p">,</span>
 <span class="s1">&#39;Freedom to make life choices&#39;</span><span class="p">,</span>
 <span class="s1">&#39;Generosity&#39;</span><span class="p">,</span>
 <span class="s1">&#39;Perceptions of corruption&#39;</span><span class="p">]</span>
</code></pre></div><p><br><br></p>
<h2 id="高于和低于平均幸福水平的差异">高于和低于平均幸福水平的差异</h2>
<p>让我们一次绘制多个特征，按照平均幸福水平进行划分。如往常一样，最幸福的国家以绿色显示。</p>
<p><img loading="lazy" src="img/output_24_1.png" alt=""  />
</p>
<p>上面的图表确认了我们之前看到的一些内容，并带有一些值得注意的特点，比如社会支持。</p>
<p>在不太幸福的国家中，慷慨度被认为更高，这非常有趣。</p>
<p><br><br></p>
<h2 id="全球视角">全球视角</h2>
<p>我们现在已经看到了基于多个因素不同国家之间明显的差异。</p>
<p>现在让我们从全球角度来看这个问题。</p>
<p><img loading="lazy" src="img/output_26_1.png" alt=""  />
</p>
<p>这张图确认了我们之前的发现，南亚和非洲处于红色区域。</p>
<p>但它也突出了我们可以进一步调查的地区。例如，中国和印度都在红色区域，它们的人口都超过了10亿。我们能否研究人口与幸福水平之间的关系？
<br><br></p>
<h2 id="人口">人口</h2>
<p>让我们引入更多的因素——比如人口。</p>
<p>这是否会影响幸福水平？</p>
<p><img loading="lazy" src="img/output_28_1.png" alt=""  />
</p>
<p>我们清晰地看到，更幸福的国家往往年龄更大，人口更少。</p>
<p>我加入了欧洲作为参考。</p>
<p>那么生育率呢？</p>
<p><img loading="lazy" src="img/output_30_1.png" alt=""  />
</p>
<p>正如我所怀疑的，更幸福的国家通常也有更少的孩子。这很可能是由于可以更容易地获得避孕方法。</p>
<p><img loading="lazy" src="img/output_32_1.png" alt=""  />
</p>
<p>我很惊讶人口密度并不影响幸福感——尽管这可能是因为个人偏好！</p>
<p><br><br></p>
<h2 id="随着时间的推移有没有变化">随着时间的推移，有没有变化？</h2>
<p>不快乐的人会变得更快乐吗？</p>
<p>这仅仅是一个时间点的快照吗？还是这些趋势更加持久？</p>
<p><img loading="lazy" src="img/output_34_1.png" alt=""  />
</p>
<br>
<p>令人关注的是，不快乐的人依然不快乐，更糟糕的是，他们似乎变得更加不快乐。</p>
<p>这种趋势是持续的吗？或者某些国家的分数会随着时间的推移而提高？</p>
<p>让我们更多地探讨一下随时间变化的情况。</p>
<p>在上面，我选取了几个国家作为样本。让我们用一个斜率图来绘制他们从2007年到2020年的变化，看看我们能否从中学到什么。</p>
<p><img loading="lazy" src="img/output_36_1.png" alt=""  />
</p>
<br>
<p>显然，多年来确实有很多变化。</p>
<p>哪些国家经历了最大的变化？</p>
<p><img loading="lazy" src="img/output_38_0.png" alt=""  />
</p>
<p><img loading="lazy" src="img/output_39_0.png" alt=""  />
</p>
<br>
<p>让我们比较在幸福指数得分方面增长最多和下降最多的两个国家：保加利亚和约旦。</p>
<p>我们将对比他们多年来的表现。</p>
<p><img loading="lazy" src="img/output_41_0.png" alt=""  />
</p>
<br>
<p>当我探究这个关于时间变化的观点时，我想从大陆的角度来看。</p>
<p>例如，西欧的所有国家都“幸福”吗？</p>
<p><img loading="lazy" src="img/output_43_1.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>可视化 | 使用geopandas可视化地图数据</title>
      <link>https://textdata.cn/blog/2023-08-31-data-visualization-how-to-plot-a-map-with-geopandas/</link>
      <pubDate>Thu, 31 Aug 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-08-31-data-visualization-how-to-plot-a-map-with-geopandas/</guid>
      <description>GeoDataFrame是GeoPandas中的核心数据结构，可以存储几何列并执行空间操作。GeoSeries 数据结构可以包含任何几何类型，例如点、线、多边形等。</description>
      <content:encoded><![CDATA[<h2 id="本文代码codezip"><a href="code.zip">本文代码</a></h2>
<p><br><br></p>
<p>Pandas 可能是最流行的用于数据分析的 Python 库。GeoPandas 扩展了 Pandas 的数据类型，使我们能够更轻松地在 Python 中处理地理空间数据。它目前有两种数据类型结构：GeoSeries 和 GeoDataFrame，它们分别是 pandas.Series 和 pandas.DataFrame 的子类。</p>
<p><strong>GeoDataFrame</strong> 是 <strong>GeoPandas</strong> 中的核心数据结构，可以存储几何列并执行空间操作。GeoSeries 数据结构可以包含任何几何类型，例如点、线、多边形等。</p>
<p>总体上，GeoDataFrame 是 pandas.Series 和 geopandas.GeoSeries 的组合。</p>
<p>为了按照本文中的方法进行操作，您需要从 ArcGIS Hub 下载一个世界国家的 Shapefile (<a href="https://hub.arcgis.com/datasets/esri::world-countries-generalized/">https://hub.arcgis.com/datasets/esri::world-countries-generalized/</a>)。 如果您已经有自己的 Shapefile 数据，也可以使用您自己的数据。</p>
<p><img loading="lazy" src="img/01-arcgis.png" alt=""  />
</p>
<h2 id="heading"></h2>
<p><br><br></p>
<h2 id="一安装geopandas">一、安装GeoPandas</h2>
<p>GeoPandas库是纯 Python 编写的，但是它的一些依赖库是用 C 编写的，比如 GEOS、GDAL、PROJ。有时在 Windows 上安装这些 C 库并不容易。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="err">!</span><span class="n">pip3</span> <span class="n">install</span> <span class="n">pyogrio</span>
<span class="err">!</span><span class="n">pip3</span> <span class="n">install</span> <span class="n">pyproj</span>
<span class="err">!</span><span class="n">pip3</span> <span class="n">install</span> <span class="n">rtree</span>
<span class="err">!</span><span class="n">pip3</span> <span class="n">install</span> <span class="n">shapely</span>
<span class="err">!</span><span class="n">pip3</span> <span class="n">install</span> <span class="n">geopandas</span>
</code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">geopandas</span> <span class="k">as</span> <span class="nn">gpd</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Geopandas版本号: &#39;</span><span class="p">,</span> <span class="n">gpd</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span>
</code></pre></div><pre><code>Geopandas版本号:  0.13.2
</code></pre>
<p><br><br></p>
<h2 id="二读写数据">二、读写数据</h2>
<h3 id="21-读入数据">2.1 读入数据</h3>
<p>geopandas库支持多种数据格式</p>
<ul>
<li>shp</li>
<li>geojson</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">os</span>

<span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="s1">&#39;data&#39;</span><span class="p">)</span>
</code></pre></div><pre><code>['.DS_Store',
 'World_Countries_Generalized',
 'World_Countries_Generalized.geojson',
 'world-population.geo.json']
</code></pre>
<h4 id="211-shp">2.1.1 shp</h4>
<p><img loading="lazy" src="img/02-shp_data.png" alt=""  />
</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">geopandas</span> <span class="k">as</span> <span class="nn">gpd</span>

<span class="c1">#shp必须与shx同处于一个文件夹内</span>
<span class="n">gdf</span> <span class="o">=</span> <span class="n">gpd</span><span class="o">.</span><span class="n">read_file</span><span class="p">(</span><span class="s1">&#39;data/World_Countries_Generalized/World_Countries_Generalized.shp&#39;</span><span class="p">)</span>
<span class="n">gdf</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/df.png" alt=""  />
</p>
<br>
<h3 id="212-geojson">2.1.2 geojson</h3>
<p>GeoJson是Json文件，所以该类数据文件尾缀名一般为<code>.geojson</code> 或  <code>.json</code></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">geopandas</span> <span class="k">as</span> <span class="nn">gpd</span>

<span class="n">gdf2</span> <span class="o">=</span> <span class="n">gpd</span><span class="o">.</span><span class="n">read_file</span><span class="p">(</span><span class="s1">&#39;data/world-population.geo.json&#39;</span><span class="p">)</span>
<span class="n">gdf2</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/df2.png" alt=""  />
</p>
<p><br><br></p>
<h3 id="22-保存数据">2.2 保存数据</h3>
<p>我们可以使用 GeoDataFrame.to_file() 将切片或修改后的 GeoDataFrame 写回文件。</p>
<ul>
<li>gdf.to_file(&lsquo;shp文件路径&rsquo;)</li>
<li>gdf.to_file(&lsquo;GeoJson文件路径&rsquo;, driver=&lsquo;GeoJSON&rsquo;)</li>
</ul>
<p>默认的文件格式是 Shapefile，但我们可以使用 driver 关键字指定其他格式。例如，让我们将 DataFrame 保存为 GeoJSON 格式。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">gdf2</span><span class="o">.</span><span class="n">to_file</span><span class="p">(</span><span class="s1">&#39;output/World_Countries_Generalized.shp&#39;</span><span class="p">)</span>
<span class="n">gdf2</span><span class="o">.</span><span class="n">to_file</span><span class="p">(</span><span class="s1">&#39;output/World_Countries_Generalized.geojson&#39;</span><span class="p">,</span> <span class="n">driver</span><span class="o">=</span><span class="s1">&#39;GeoJSON&#39;</span><span class="p">)</span>
</code></pre></div><p><br><br></p>
<h2 id="三geodataframe数据类型">三、GeoDataFrame数据类型</h2>
<p>让我们以 gdf GeoDataFrame 为例。大多数用于 pandas 的方法在 GeoPandas 中仍然适用。在本节中，我们只会看到一些示例。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#数据形状</span>
<span class="n">gdf2</span><span class="o">.</span><span class="n">shape</span>
</code></pre></div><pre><code>(211, 10)
</code></pre>
<p>211行，8列，最后一列是多边形几何数据</p>
<br>
<h3 id="31-坐标参考系统crs">3.1 坐标参考系统（CRS）</h3>
<p>通常我们使用一个二维坐标系统，其中经度（垂直的南北线）和纬度（东西方向的水平线）用于标识地球表面上的位置。</p>
<p>GeoDataFrame 包含了将几何列中定义的多边形映射到地球表面的CRS信息。要检查CRS，我们使用 .crs 方法。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">gdf2</span><span class="o">.</span><span class="n">crs</span>
</code></pre></div><pre><code>&lt;Geographic 2D CRS: EPSG:4326&gt;
Name: WGS 84
Axis Info [ellipsoidal]:
- Lat[north]: Geodetic latitude (degree)
- Lon[east]: Geodetic longitude (degree)
Area of Use:
- name: World.
- bounds: (-180.0, -90.0, 180.0, 90.0)
Datum: World Geodetic System 1984 ensemble
- Ellipsoid: WGS 84
- Prime Meridian: Greenwich
</code></pre>
<br>
<h3 id="32-筛选">3.2 筛选</h3>
<p>筛选出中国的数据</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">gdf2</span><span class="p">[</span><span class="n">gdf2</span><span class="p">[</span><span class="s1">&#39;NAME&#39;</span><span class="p">]</span><span class="o">==</span><span class="s1">&#39;China&#39;</span><span class="p">]</span>
</code></pre></div><p><img loading="lazy" src="img/df3.png" alt=""  />
</p>
<br>
<h3 id="32-中心">3.2 中心</h3>
<p>每个记录所代码实体(国家、省州、城市)的地理中心</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">gdf2</span><span class="o">.</span><span class="n">centroid</span>
</code></pre></div><pre><code>0       POINT (66.02695 33.83959)
1       POINT (20.06466 41.14350)
2        POINT (2.63167 28.16258)
3        POINT (1.58730 42.54147)
4      POINT (17.54495 -12.29359)
                  ...            
206     POINT (47.59134 15.77731)
207     POINT (20.80471 44.02662)
208     POINT (23.65690 -2.87535)
209    POINT (27.79925 -13.45302)
210    POINT (29.87045 -19.00312)
Length: 211, dtype: geometry
</code></pre>
<br>
<h3 id="33-投影">3.3 投影</h3>
<p>几何数据（多边形）转换到 EPSG 3857 坐标参考系统，并计算每个多边形的中心点（centroid）。 EPSG 3857 通常被称为 「Web Mercator 投影」，用于在 Web 地图上呈现地理数据。转换为此坐标参考系统可以用于生成更适合在 Web 地图上显示的数据。</p>
<p>根据代码运行提示， 更改代码。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">gdf2</span><span class="o">.</span><span class="n">to_crs</span><span class="p">(</span><span class="mi">3857</span><span class="p">)</span><span class="o">.</span><span class="n">centroid</span>
</code></pre></div><pre><code>0       POINT (7354486.896 4017736.603)
1       POINT (2233478.912 5035365.825)
2        POINT (292615.786 3302567.699)
3        POINT (176697.417 5242446.985)
4      POINT (1953402.929 -1385745.990)
                     ...               
206     POINT (5299033.934 1780605.357)
207     POINT (2315093.566 5473720.440)
208     POINT (2633886.156 -323258.251)
209    POINT (3092719.338 -1515282.005)
210    POINT (3325201.834 -2158042.585)
Length: 211, dtype: geometry
</code></pre>
<br>
<h3 id="34-计算区域面积">3.4 计算区域面积</h3>
<p>数据已经包含了一个 SHAPE_Area 列。假设没有这样的列，我们可以通过几何数据来计算面积。为了获得正确的面积，您必须使用<strong>等面积投影</strong>。适用于您的代码的投影是 EPSG 6933。它是柱面等面积投影。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">gdf2</span><span class="o">.</span><span class="n">to_crs</span><span class="p">(</span><span class="mi">6933</span><span class="p">)</span><span class="o">.</span><span class="n">area</span>
</code></pre></div><pre><code>0      6.419639e+11
1      2.875576e+10
2      2.318240e+12
3      4.702513e+08
4      1.247851e+12
           ...     
206    3.990873e+11
207    8.856234e+10
208    2.325712e+12
209    7.521495e+11
210    3.892279e+11
Length: 211, dtype: float64
</code></pre>
<p><br><br></p>
<h2 id="四可视化">四、可视化</h2>
<p>因为geopandas绘图功能是在matplotlib的基础上实现的，gdf.plot()一行代码就能绘图</p>
<h3 id="41-最简地图">4.1 最简地图</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">gdf2</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/output_26_1.png" alt=""  />
</p>
<br>
<h3 id="42-更改颜色">4.2 更改颜色</h3>
<p>图的颜色和边界的颜色的更改</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">gdf2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;green&#39;</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">)</span>
</code></pre></div><p><img loading="lazy" src="img/output_28_1.png" alt=""  />
</p>
<br>
<h3 id="43-colormap">4.3 colormap</h3>
<p>使用matplotlib的colormaps配色</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">gdf2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;jet&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">,</span> <span class="n">column</span><span class="o">=</span><span class="s1">&#39;NAME&#39;</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
</code></pre></div><p><img loading="lazy" src="img/output_30_1.png" alt=""  />
</p>
<br>
<h3 id="44-legend-colorbar">4.4 Legend Colorbar</h3>
<p>图例配色</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">gdf2</span><span class="p">[</span><span class="s1">&#39;POP2005&#39;</span><span class="p">]</span><span class="o">=</span><span class="n">gdf2</span><span class="p">[</span><span class="s1">&#39;POP2005&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>

<span class="n">gdf2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;hot&#39;</span><span class="p">,</span><span class="n">linewidth</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">,</span><span class="n">column</span><span class="o">=</span><span class="s1">&#39;POP2005&#39;</span><span class="p">,</span><span class="n">legend</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;World Population&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/output_32_0.png" alt=""  />
</p>
<br>
<h3 id="45-局部">4.5 局部</h3>
<p>使用gdf2除了可以绘制全世界地图，还可以绘制局部地图，如美国地图</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">gdf2</span><span class="p">[</span><span class="n">gdf2</span><span class="p">[</span><span class="s1">&#39;NAME&#39;</span><span class="p">]</span><span class="o">==</span><span class="s1">&#39;China&#39;</span><span class="p">]</span>
</code></pre></div><p><img loading="lazy" src="img/df3.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">china_mainland</span> <span class="o">=</span> <span class="n">gdf2</span><span class="p">[</span><span class="n">gdf2</span><span class="p">[</span><span class="s1">&#39;NAME&#39;</span><span class="p">]</span> <span class="o">==</span><span class="s1">&#39;China&#39;</span><span class="p">]</span>
<span class="n">china_taiwan</span> <span class="o">=</span> <span class="n">gdf2</span><span class="p">[</span><span class="n">gdf2</span><span class="p">[</span><span class="s1">&#39;NAME&#39;</span><span class="p">]</span> <span class="o">==</span><span class="s1">&#39;Taiwan&#39;</span><span class="p">]</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>

<span class="n">china_mainland</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span> 
<span class="n">china_taiwan</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Map of China&#39;</span><span class="p">)</span>
</code></pre></div><p><img loading="lazy" src="img/output_35_1.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>CAR2023 | 文本分析在会计中的应用</title>
      <link>https://textdata.cn/blog/2023-08-26-text-analysis-in-accounting/</link>
      <pubDate>Sat, 26 Aug 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-08-26-text-analysis-in-accounting/</guid>
      <description>&lt;h2 id=&#34;一文本分析在会计领域中的应用&#34;&gt;一、文本分析在会计领域中的应用&lt;/h2&gt;
&lt;p&gt;Bochkay, Khrystyna, Stephen V. Brown, Andrew J. Leone, and Jennifer Wu Tucker. &amp;ldquo;Textual analysis in accounting: What&amp;rsquo;s next?.&amp;rdquo; &lt;em&gt;Contemporary accounting research&lt;/em&gt; 40, no. 2 (2023): 765-805.&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;11-摘要&#34;&gt;1.1 摘要&lt;/h3&gt;
&lt;p&gt;自然语言是商务沟通的重要形式。 文本分析是指用自然语言处理（NLP）技术处理文本数据，从而得到某些感兴趣的测量值(信息)。 我们调查了顶级会计期刊的出版物，并描述了会计文本分析的趋势和现状。 我们将可用的 NLP 方法组织在一个统一的框架中。 会计研究者经常使用文本分析来衡量披露情绪、可读性和披露数量； 比较披露信息以确定相似性或差异；识别前瞻性信息； 并检测主题。 对于每一项任务，我们都解释了传统方法和基于机器学习（尤其是深度学习）的新方法。 我们讨论如何建立基于文本的测量的构造有效性以及研究人员在实施 NLP 模型时面临的典型决策。 最后，我们讨论了未来研究的机会。 我们的结论是：(i) 文本分析已发展成为一种重要的研究方法，(ii) 会计研究人员应该增加对机器学习（尤其是深度学习）的了解和使用，以进行文本分析。&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;12-发文趋势&#34;&gt;1.2 发文趋势&lt;/h3&gt;
&lt;p&gt;会计顶刊文本分析发文量如下图&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The Accounting Review(TAR),&lt;/p&gt;
&lt;p&gt;Journal of Accounting Research(JAR),&lt;/p&gt;
&lt;p&gt;Journal of Accounting andEconomics(JAE),&lt;/p&gt;
&lt;p&gt;Contemporary Accounting Research(CAR),&lt;/p&gt;
&lt;p&gt;Review of Accounting Studies(RAST),&lt;/p&gt;
&lt;p&gt;Accounting, Organizations,and Society(AOS),&lt;/p&gt;
&lt;p&gt;ManagementScience(MS).&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/fig-1.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/fig-2.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;13-数据源所用指标&#34;&gt;1.3 数据源&amp;amp;所用指标&lt;/h3&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/fig-3.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;二文本分析操作方法&#34;&gt;二、文本分析操作方法&lt;/h2&gt;
&lt;p&gt;文本分析各方法指南&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;数据获取&amp;amp;预处理步骤&lt;/li&gt;
&lt;li&gt;词典选择(构建)步骤&lt;/li&gt;
&lt;li&gt;监督机器学习步骤&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;21-数据获取预处理&#34;&gt;2.1 数据获取&amp;amp;预处理&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;数据获取&lt;/strong&gt; 使用人工手动或爬虫从EDGAR、公司网站、社交媒体等数据源采集下载&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;数据清洗&lt;/strong&gt;  剔除HTML中的标签、非文本字符、特殊字符(如&amp;amp; ￥ $ 等)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;分词&lt;/strong&gt; 将文本转为颗粒度为词语的成分&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;文档筛选&lt;/strong&gt;  字符数太短的文档删除掉&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;停用词&lt;/strong&gt; 剔除文本中的停用词，如(中文如“的他呢了地”，英文如 the、in、a)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;合并同类项(stemming&amp;amp;lemmatization)&lt;/strong&gt;  文本中出现的increasing, increases, and increased，都整理为increase。&lt;/li&gt;
&lt;/ol&gt;
&lt;br&gt;
&lt;h3 id=&#34;22-词典选择构建步骤&#34;&gt;2.2 词典选择(构建)步骤&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;选择词典&lt;/strong&gt; 选择符合研究目的的词典，如做文本的情感分析，可以选择用积极词典和消极词典。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;词频统计&lt;/strong&gt;  统计词语是否出现，还是统计词语出现次数&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;词语权重&lt;/strong&gt;  确定所有计数是否具有相同的权重，或者某些单词或短语应获得更高或更低的权重（例如，更常见的单词获得更低的权重）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;词典验证&lt;/strong&gt; 将字典在识别相关内容方面的表现与人工注释者进行比较。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;确定指标&lt;/strong&gt; 确定最终感兴趣变量的标量（例如，文档中的总单词数）&lt;/li&gt;
&lt;/ol&gt;
&lt;br&gt;
&lt;h3 id=&#34;23-监督机器学习步骤&#34;&gt;2.3 监督机器学习步骤&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;结果变量&lt;/strong&gt;  决定如何表示感兴趣的变量：(i) 连续变量或 (ii) 分类变量&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;标注数据集&lt;/strong&gt;  收集带标注信息的样本数据（例如，带标签的单词、句子、段落或文章）。标注平台（例如，Prodigy、Amazon Mechanical Turk、TagEditor、SMART 和 piaf）&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;分为训练集、测试集&lt;/strong&gt;  将带标注的数据集拆分为子样本以进行训练、验证和测试。 确保感兴趣的变量的每个类别都有很好的代表性&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;模型选择&lt;/strong&gt;  如果采用深度学习模型，请决定模型（例如 BERT）以及是否对模型进行微调。 如果使用传统机器学习，请选择特定模型（例如 NB、SVM 或 RF）&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;文本特征工程&lt;/strong&gt; 使用词袋法或者词嵌入&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;评估模型&lt;/strong&gt;  确定评估模型性能的指标。 选项包括准确度、精确度、召回率、F 分数和 ROC-AUC&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;模型拟合&lt;/strong&gt;  使用带注释的数据拟合模型，检查验证数据上的模型性能，并确定是否需要更多带注释的示例。 这是一个迭代的过程&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;确定指标&lt;/strong&gt; 确定最终感兴趣变量的标量（例如，文档中的总单词数）&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;广而告之&#34;&gt;广而告之&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/call_for_paper/&#34;&gt;长期征稿&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/we_need_you/&#34;&gt;长期招募小伙伴&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/management_python_course/&#34;&gt;付费视频课 | Python实证指标构建与文本分析&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
      <content:encoded><![CDATA[<h2 id="一文本分析在会计领域中的应用">一、文本分析在会计领域中的应用</h2>
<p>Bochkay, Khrystyna, Stephen V. Brown, Andrew J. Leone, and Jennifer Wu Tucker. &ldquo;Textual analysis in accounting: What&rsquo;s next?.&rdquo; <em>Contemporary accounting research</em> 40, no. 2 (2023): 765-805.</p>
<br>
<h3 id="11-摘要">1.1 摘要</h3>
<p>自然语言是商务沟通的重要形式。 文本分析是指用自然语言处理（NLP）技术处理文本数据，从而得到某些感兴趣的测量值(信息)。 我们调查了顶级会计期刊的出版物，并描述了会计文本分析的趋势和现状。 我们将可用的 NLP 方法组织在一个统一的框架中。 会计研究者经常使用文本分析来衡量披露情绪、可读性和披露数量； 比较披露信息以确定相似性或差异；识别前瞻性信息； 并检测主题。 对于每一项任务，我们都解释了传统方法和基于机器学习（尤其是深度学习）的新方法。 我们讨论如何建立基于文本的测量的构造有效性以及研究人员在实施 NLP 模型时面临的典型决策。 最后，我们讨论了未来研究的机会。 我们的结论是：(i) 文本分析已发展成为一种重要的研究方法，(ii) 会计研究人员应该增加对机器学习（尤其是深度学习）的了解和使用，以进行文本分析。</p>
<br>
<h3 id="12-发文趋势">1.2 发文趋势</h3>
<p>会计顶刊文本分析发文量如下图</p>
<blockquote>
<p>The Accounting Review(TAR),</p>
<p>Journal of Accounting Research(JAR),</p>
<p>Journal of Accounting andEconomics(JAE),</p>
<p>Contemporary Accounting Research(CAR),</p>
<p>Review of Accounting Studies(RAST),</p>
<p>Accounting, Organizations,and Society(AOS),</p>
<p>ManagementScience(MS).</p>
</blockquote>
<p><img loading="lazy" src="img/fig-1.png" alt=""  />
</p>
<p><img loading="lazy" src="img/fig-2.png" alt=""  />
</p>
<br>
<h3 id="13-数据源所用指标">1.3 数据源&amp;所用指标</h3>
<p><img loading="lazy" src="img/fig-3.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="二文本分析操作方法">二、文本分析操作方法</h2>
<p>文本分析各方法指南</p>
<ol>
<li>数据获取&amp;预处理步骤</li>
<li>词典选择(构建)步骤</li>
<li>监督机器学习步骤</li>
</ol>
<h3 id="21-数据获取预处理">2.1 数据获取&amp;预处理</h3>
<ol>
<li><strong>数据获取</strong> 使用人工手动或爬虫从EDGAR、公司网站、社交媒体等数据源采集下载</li>
<li><strong>数据清洗</strong>  剔除HTML中的标签、非文本字符、特殊字符(如&amp; ￥ $ 等)</li>
<li><strong>分词</strong> 将文本转为颗粒度为词语的成分</li>
<li><strong>文档筛选</strong>  字符数太短的文档删除掉</li>
<li><strong>停用词</strong> 剔除文本中的停用词，如(中文如“的他呢了地”，英文如 the、in、a)</li>
<li><strong>合并同类项(stemming&amp;lemmatization)</strong>  文本中出现的increasing, increases, and increased，都整理为increase。</li>
</ol>
<br>
<h3 id="22-词典选择构建步骤">2.2 词典选择(构建)步骤</h3>
<ol>
<li><strong>选择词典</strong> 选择符合研究目的的词典，如做文本的情感分析，可以选择用积极词典和消极词典。</li>
<li><strong>词频统计</strong>  统计词语是否出现，还是统计词语出现次数</li>
<li><strong>词语权重</strong>  确定所有计数是否具有相同的权重，或者某些单词或短语应获得更高或更低的权重（例如，更常见的单词获得更低的权重）。</li>
<li><strong>词典验证</strong> 将字典在识别相关内容方面的表现与人工注释者进行比较。</li>
<li><strong>确定指标</strong> 确定最终感兴趣变量的标量（例如，文档中的总单词数）</li>
</ol>
<br>
<h3 id="23-监督机器学习步骤">2.3 监督机器学习步骤</h3>
<ol>
<li><strong>结果变量</strong>  决定如何表示感兴趣的变量：(i) 连续变量或 (ii) 分类变量</li>
<li><strong>标注数据集</strong>  收集带标注信息的样本数据（例如，带标签的单词、句子、段落或文章）。标注平台（例如，Prodigy、Amazon Mechanical Turk、TagEditor、SMART 和 piaf）</li>
<li><strong>分为训练集、测试集</strong>  将带标注的数据集拆分为子样本以进行训练、验证和测试。 确保感兴趣的变量的每个类别都有很好的代表性</li>
<li><strong>模型选择</strong>  如果采用深度学习模型，请决定模型（例如 BERT）以及是否对模型进行微调。 如果使用传统机器学习，请选择特定模型（例如 NB、SVM 或 RF）</li>
<li><strong>文本特征工程</strong> 使用词袋法或者词嵌入</li>
<li><strong>评估模型</strong>  确定评估模型性能的指标。 选项包括准确度、精确度、召回率、F 分数和 ROC-AUC</li>
<li><strong>模型拟合</strong>  使用带注释的数据拟合模型，检查验证数据上的模型性能，并确定是否需要更多带注释的示例。 这是一个迭代的过程</li>
<li><strong>确定指标</strong> 确定最终感兴趣变量的标量（例如，文档中的总单词数）</li>
</ol>
<p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>文本分析 | 使用「软余弦相似度」测量业绩说明会「答非所问程度」</title>
      <link>https://textdata.cn/blog/2023-05-23-soft-cosine-similarity/</link>
      <pubDate>Wed, 24 May 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-05-23-soft-cosine-similarity/</guid>
      <description>&lt;h2 id=&#34;一答非所问相关文献&#34;&gt;一、「答非所问」相关文献&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;问:“公司的核心竞争力?”
答:“企业未来的发力肯定是围绕品牌和渠道发力，品牌又是重中之重．”
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;回答与问题之间的相似度越高，则回答与问题就越契合 ，回答质量越高。因此，在会计财经领域的研究中，&lt;strong&gt;答非所问程度&lt;/strong&gt;是一个很有使用价值的指标。&lt;/p&gt;
&lt;p&gt;卞世博,管之凡,阎志鹏.&lt;strong&gt;答非所问与市场反应:基于业绩说明会的研究&lt;/strong&gt;[J].管理科学学报,2021,24(04):109-126.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;摘要:对上市公司业绩说明会中投资者与管理层问答互动中管理层答非所问的现象进行了研究.本文以中小板和创业板上市公司召开的业绩说明会作为研究样本,利用文本分析方法对业绩说明会中管理层在回答投资者提问时答非所问的程度进行度量,进而实证分析了管理层的答非所问与市场反应和公司未来业绩表现之间的可能关联.结果发现:在控制其它因素之后,管理层的答非所问与市场反应之间呈现显著的负相关关系,即公司管理层的答非所问程度越高,随后公司股票的市场表现则就会越差,并且对于那些低分析师关注的公司尤为明显;而在公司未来业绩表现方面,管理层答非所问的程度越高,则公司未来的业绩表现则会越差.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;br&gt;
&lt;p&gt;郭照蕊,袁嘉浩,傅毅.&lt;strong&gt;上市公司“答非所问”程度与审计费用——基于年报问询函与回函的综合研究&lt;/strong&gt;[J].审计研究,2023,No.231(01):99-111.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;摘要:年报问询函是证券交易所向年报披露存疑的上市公司发出的函件，有问有答才构成一次有效的问询回合，因此综合考察年报问询函和回函的经济后果更具意义。本文通过对2015-2020年间年报问询函及上市公司相应回函的文本分析构建了“答非所问”程度指数并实证考察了其对审计费用的影响，结果发现，“答非所问”程度指数越高，上市公司支付的审计费用越高，进而表明，有针对性的释疑能够降低审计费用，回函质量的高低直接影响上市公司因问询函而支付的审计费用“溢价”。该现象受到一系列公司内外部特征的影响，相对于问询函回函长度越长、内部治理水平和外部制度环境越差，审计费用受“答非所问”程度影响而提升得越明显。本文从审计费用的视角证实了高质量的回函对上市公司发挥了积极作用。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;二为什么使用软余弦相似度测量答非所问&#34;&gt;二、为什么使用「软余弦相似度」测量「答非所问」&lt;/h2&gt;
&lt;p&gt;关于「软余弦相似度」测量， 本质上其实就是两个文本的相似程度，相似程度越低， 答非所问程度越高。 但问答是一种特殊的场景， 直接使用余弦相似度测量会很不准，目前主要使用软余弦相似度进行测量。 原因有以下几点：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;考虑语义关系：软余弦相似度能够考虑词语之间的语义关系，而在问询和业绩说明会问答环节中，问题和答案之间可能存在词语的近义词、同义词以及语义相似的情况。软余弦相似度通过使用词向量来捕捉词语的语义信息，能够更好地度量问题和答案之间的语义相似度，从而更准确地判断它们之间的相似程度。&lt;/li&gt;
&lt;li&gt;考虑词语权重：软余弦相似度通常使用TF-IDF来计算词语的权重，这能够在计算相似度时对词语进行加权，更加准确地反映词语在问题和答案中的重要性。在问询和业绩说明会问答环节中，问题和答案中的词语可能具有不同的重要性，某些关键词可能对于判断相似度起着重要作用。软余弦相似度能够考虑这种权重差异，从而更好地衡量问题和答案之间的相似度。&lt;/li&gt;
&lt;li&gt;考虑词语变体和同义词：在问询和业绩说明会问答环节中，问题和答案之间可能存在词语的变体或同义词。软余弦相似度在词向量的计算过程中，能够通过训练语料库中的上下文信息，将相似的词语映射到相似的向量表示，从而能够更好地处理词语的变体和同义词，提高相似度计算的准确性。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;综上所述，软余弦相似度在问询和业绩说明会问答环节的相似度计算中具有优势，能够更好地考虑语义关系、词语权重以及词语变体和同义词等因素，从而提高问答相似度的准确性和可靠性。&lt;/p&gt;
&lt;p&gt;需要注意， &lt;strong&gt;答非所问程度 = 1 - 软余弦相似度&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;三答非所问代码&#34;&gt;三、「答非所问」代码&lt;/h2&gt;
&lt;p&gt;文件树结构&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;软余弦相似度-答非所问
 |--Word2Vec
    |--mda01-22.200.6.bin
    |--mda01-22.200.6.bin.vectors.npy
    |--mda01-22.200.6.bin.syn1neg.npy
 |--问答数据.csv
 |--代码.ipynb
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;p&gt;除 **&lt;a href=&#34;https://textdata.cn/blog/2023-03-24-load-w2v-and-expand-your-concpet-dicitonary/&#34;&gt;Word2Vec/mda01-22.200.6.bin**&lt;/a&gt; 是付费内容， 其余内容均都是公开的。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;100元   Word2Vec相关模型文件(mda01-22.200.6.bin)

加微信 372335839， 备注「姓名-学校-专业-word2vec」
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h3 id=&#34;31-环境准备&#34;&gt;3.1 环境准备&lt;/h3&gt;
&lt;p&gt;打开命令行， 执行以下安装命令&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;pip3 install gensim==4.3.2
pip3 install jieba==0.42.1
pip3 install pandas==2.0.3
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h3 id=&#34;32-计算一个问答答非所问程度&#34;&gt;3.2 计算一个问答「答非所问程度」&lt;/h3&gt;
&lt;p&gt;谷歌搜 「&lt;strong&gt;soft cosine similarity&lt;/strong&gt;」，能找到相关代码，我使用gensim提供的英文文本的「软余弦相似度」，更改适配成中文的代码。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/01-screen.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;如果问答数据量很大，可以把所有文本堆到一个txt中，训练出对应的word2vec模型&lt;/strong&gt;。这里大邓偷懒，找一个财经领域的语料训练出的word2vec模型。 之前分享过 &lt;a href=&#34;https://textdata.cn/blog/2023-03-24-load-w2v-and-expand-your-concpet-dicitonary/&#34;&gt;词向量(付费) | 使用MD&amp;amp;A2001-2022语料训练Word2Vec模型&lt;/a&gt; ， 购买后可得到财经语料的 Word2Vec模型文件 &lt;strong&gt;mda01-22.200.6.bin&lt;/strong&gt;。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;gensim.corpora&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Dictionary&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;gensim.models&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;TfidfModel&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;gensim.similarities&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;SparseTermSimilarityMatrix&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;WordEmbeddingSimilarityIndex&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;gensim.models&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;KeyedVectors&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;jieba&lt;/span&gt;




&lt;span class=&#34;c1&#34;&gt;#导入预训练word2vec模型&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;w2v_model&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;KeyedVectors&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;load&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;Word2Vec/mda01-22.200.6.bin&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;#软余弦相似度&lt;/span&gt;
&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;soft_cosine&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;row&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;question&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;jieba&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;lcut&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;row&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;question&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;answer&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;jieba&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;lcut&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;row&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;answer&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;docs&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;question&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;answer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;DICTION&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Dictionary&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;docs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;docs2&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;DICTION&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;doc2bow&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;doc&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;doc&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;docs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;TFIDF&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;TfidfModel&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;docs2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;termsim_index&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;WordEmbeddingSimilarityIndex&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;w2v_model&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;termsim_matrix&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;SparseTermSimilarityMatrix&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;termsim_index&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;DICTION&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;TFIDF&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;similarity&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;termsim_matrix&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;inner_product&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;docs2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;docs2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;normalized&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
    &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;similarity&lt;/span&gt;


&lt;span class=&#34;n&#34;&gt;row&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;question&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;公司的核心竞争力?&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
       &lt;span class=&#34;s1&#34;&gt;&amp;#39;answer&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;企业未来的发力肯定是围绕品牌和渠道发力，品牌又是重中之重．&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;


&lt;span class=&#34;c1&#34;&gt;#该问答的软余弦相似度&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;soft_cosine&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;row&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;0.17236403
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;该问答的软余弦相似度为0.17236403， 则答非所问程度1-0.17236403 = 0.82763597&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;需要注意， &lt;strong&gt;答非所问程度 = 1 - 软余弦相似度&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;br&gt;
&lt;h3 id=&#34;33-计算多个问答答非所问程度&#34;&gt;3.3 计算多个问答「答非所问程度」&lt;/h3&gt;
&lt;p&gt;点击下载本文实验数据 &lt;a href=&#34;%E9%97%AE%E7%AD%94%E6%95%B0%E6%8D%AE.csv&#34;&gt;&lt;em&gt;&lt;strong&gt;问答数据.csv&lt;/strong&gt;&lt;/em&gt;&lt;/a&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-Python&#34; data-lang=&#34;Python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pandas&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pd&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;#问答实验数据&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read_csv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;问答数据.csv&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/02-df.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;p&gt;建议各位将问答数据整理到csv或者xlsx格式， 第一列question字段， 第二列为answer字段，保证字段名与本代码一致。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pandas&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pd&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;gensim.corpora&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Dictionary&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;gensim.models&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;TfidfModel&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;gensim.similarities&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;SparseTermSimilarityMatrix&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;WordEmbeddingSimilarityIndex&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;gensim.models&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;KeyedVectors&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;jieba&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;#导入预训练word2vec模型&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;w2v_model&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;KeyedVectors&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;load&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;Word2Vec/mda01-22.200.6.bin&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;


&lt;span class=&#34;c1&#34;&gt;#软余弦相似度&lt;/span&gt;
&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;soft_cosine&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;row&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;question&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;jieba&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;lcut&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;row&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;question&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;answer&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;jieba&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;lcut&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;row&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;answer&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;docs&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;question&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;answer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;DICTION&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Dictionary&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;docs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;docs2&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;DICTION&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;doc2bow&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;doc&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;doc&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;docs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;TFIDF&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;TfidfModel&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;docs2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;termsim_index&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;WordEmbeddingSimilarityIndex&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;w2v_model&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;termsim_matrix&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;SparseTermSimilarityMatrix&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;termsim_index&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;DICTION&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;TFIDF&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;similarity&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;termsim_matrix&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;inner_product&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;docs2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;docs2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;normalized&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
    &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;similarity&lt;/span&gt;
  


&lt;span class=&#34;c1&#34;&gt;#批量计算&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read_csv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;问答数据.csv&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;similarity&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;apply&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;soft_cosine&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;axis&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;答非所问&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;similarity&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/03-df.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;四资料获取&#34;&gt;四、资料获取&lt;/h2&gt;
&lt;p&gt;除 **&lt;a href=&#34;https://textdata.cn/blog/2023-03-24-load-w2v-and-expand-your-concpet-dicitonary/&#34;&gt;Word2Vec/mda01-22.200.6.bin**&lt;/a&gt; 是付费内容， 其余内容均都是公开的。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;100元   Word2Vec相关模型文件(mda01-22.200.6.bin)

加微信 372335839， 备注「姓名-学校-专业-word2vec」
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;广而告之&#34;&gt;广而告之&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/call_for_paper/&#34;&gt;长期征稿&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/we_need_you/&#34;&gt;长期招募小伙伴&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/management_python_course/&#34;&gt;付费视频课 | Python实证指标构建与文本分析&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
      <content:encoded><![CDATA[<h2 id="一答非所问相关文献">一、「答非所问」相关文献</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">问:“公司的核心竞争力?”
答:“企业未来的发力肯定是围绕品牌和渠道发力，品牌又是重中之重．”
</code></pre></div><p>回答与问题之间的相似度越高，则回答与问题就越契合 ，回答质量越高。因此，在会计财经领域的研究中，<strong>答非所问程度</strong>是一个很有使用价值的指标。</p>
<p>卞世博,管之凡,阎志鹏.<strong>答非所问与市场反应:基于业绩说明会的研究</strong>[J].管理科学学报,2021,24(04):109-126.</p>
<blockquote>
<p>摘要:对上市公司业绩说明会中投资者与管理层问答互动中管理层答非所问的现象进行了研究.本文以中小板和创业板上市公司召开的业绩说明会作为研究样本,利用文本分析方法对业绩说明会中管理层在回答投资者提问时答非所问的程度进行度量,进而实证分析了管理层的答非所问与市场反应和公司未来业绩表现之间的可能关联.结果发现:在控制其它因素之后,管理层的答非所问与市场反应之间呈现显著的负相关关系,即公司管理层的答非所问程度越高,随后公司股票的市场表现则就会越差,并且对于那些低分析师关注的公司尤为明显;而在公司未来业绩表现方面,管理层答非所问的程度越高,则公司未来的业绩表现则会越差.</p>
</blockquote>
<br>
<p>郭照蕊,袁嘉浩,傅毅.<strong>上市公司“答非所问”程度与审计费用——基于年报问询函与回函的综合研究</strong>[J].审计研究,2023,No.231(01):99-111.</p>
<blockquote>
<p>摘要:年报问询函是证券交易所向年报披露存疑的上市公司发出的函件，有问有答才构成一次有效的问询回合，因此综合考察年报问询函和回函的经济后果更具意义。本文通过对2015-2020年间年报问询函及上市公司相应回函的文本分析构建了“答非所问”程度指数并实证考察了其对审计费用的影响，结果发现，“答非所问”程度指数越高，上市公司支付的审计费用越高，进而表明，有针对性的释疑能够降低审计费用，回函质量的高低直接影响上市公司因问询函而支付的审计费用“溢价”。该现象受到一系列公司内外部特征的影响，相对于问询函回函长度越长、内部治理水平和外部制度环境越差，审计费用受“答非所问”程度影响而提升得越明显。本文从审计费用的视角证实了高质量的回函对上市公司发挥了积极作用。</p>
</blockquote>
<p><br><br></p>
<h2 id="二为什么使用软余弦相似度测量答非所问">二、为什么使用「软余弦相似度」测量「答非所问」</h2>
<p>关于「软余弦相似度」测量， 本质上其实就是两个文本的相似程度，相似程度越低， 答非所问程度越高。 但问答是一种特殊的场景， 直接使用余弦相似度测量会很不准，目前主要使用软余弦相似度进行测量。 原因有以下几点：</p>
<ol>
<li>考虑语义关系：软余弦相似度能够考虑词语之间的语义关系，而在问询和业绩说明会问答环节中，问题和答案之间可能存在词语的近义词、同义词以及语义相似的情况。软余弦相似度通过使用词向量来捕捉词语的语义信息，能够更好地度量问题和答案之间的语义相似度，从而更准确地判断它们之间的相似程度。</li>
<li>考虑词语权重：软余弦相似度通常使用TF-IDF来计算词语的权重，这能够在计算相似度时对词语进行加权，更加准确地反映词语在问题和答案中的重要性。在问询和业绩说明会问答环节中，问题和答案中的词语可能具有不同的重要性，某些关键词可能对于判断相似度起着重要作用。软余弦相似度能够考虑这种权重差异，从而更好地衡量问题和答案之间的相似度。</li>
<li>考虑词语变体和同义词：在问询和业绩说明会问答环节中，问题和答案之间可能存在词语的变体或同义词。软余弦相似度在词向量的计算过程中，能够通过训练语料库中的上下文信息，将相似的词语映射到相似的向量表示，从而能够更好地处理词语的变体和同义词，提高相似度计算的准确性。</li>
</ol>
<p>综上所述，软余弦相似度在问询和业绩说明会问答环节的相似度计算中具有优势，能够更好地考虑语义关系、词语权重以及词语变体和同义词等因素，从而提高问答相似度的准确性和可靠性。</p>
<p>需要注意， <strong>答非所问程度 = 1 - 软余弦相似度</strong></p>
<p><br><br></p>
<h2 id="三答非所问代码">三、「答非所问」代码</h2>
<p>文件树结构</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">软余弦相似度-答非所问
 |--Word2Vec
    |--mda01-22.200.6.bin
    |--mda01-22.200.6.bin.vectors.npy
    |--mda01-22.200.6.bin.syn1neg.npy
 |--问答数据.csv
 |--代码.ipynb
</code></pre></div><br>
<p>除 **<a href="https://textdata.cn/blog/2023-03-24-load-w2v-and-expand-your-concpet-dicitonary/">Word2Vec/mda01-22.200.6.bin**</a> 是付费内容， 其余内容均都是公开的。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">100元   Word2Vec相关模型文件(mda01-22.200.6.bin)

加微信 372335839， 备注「姓名-学校-专业-word2vec」
</code></pre></div><br>
<h3 id="31-环境准备">3.1 环境准备</h3>
<p>打开命令行， 执行以下安装命令</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">pip3 install gensim==4.3.2
pip3 install jieba==0.42.1
pip3 install pandas==2.0.3
</code></pre></div><br>
<h3 id="32-计算一个问答答非所问程度">3.2 计算一个问答「答非所问程度」</h3>
<p>谷歌搜 「<strong>soft cosine similarity</strong>」，能找到相关代码，我使用gensim提供的英文文本的「软余弦相似度」，更改适配成中文的代码。</p>
<p><img loading="lazy" src="img/01-screen.png" alt=""  />
</p>
<p><strong>如果问答数据量很大，可以把所有文本堆到一个txt中，训练出对应的word2vec模型</strong>。这里大邓偷懒，找一个财经领域的语料训练出的word2vec模型。 之前分享过 <a href="https://textdata.cn/blog/2023-03-24-load-w2v-and-expand-your-concpet-dicitonary/">词向量(付费) | 使用MD&amp;A2001-2022语料训练Word2Vec模型</a> ， 购买后可得到财经语料的 Word2Vec模型文件 <strong>mda01-22.200.6.bin</strong>。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">gensim.corpora</span> <span class="kn">import</span> <span class="n">Dictionary</span>
<span class="kn">from</span> <span class="nn">gensim.models</span> <span class="kn">import</span> <span class="n">TfidfModel</span>
<span class="kn">from</span> <span class="nn">gensim.similarities</span> <span class="kn">import</span> <span class="n">SparseTermSimilarityMatrix</span><span class="p">,</span> <span class="n">WordEmbeddingSimilarityIndex</span>
<span class="kn">from</span> <span class="nn">gensim.models</span> <span class="kn">import</span> <span class="n">KeyedVectors</span>
<span class="kn">import</span> <span class="nn">jieba</span>




<span class="c1">#导入预训练word2vec模型</span>
<span class="n">w2v_model</span> <span class="o">=</span> <span class="n">KeyedVectors</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;Word2Vec/mda01-22.200.6.bin&#39;</span><span class="p">)</span>

<span class="c1">#软余弦相似度</span>
<span class="k">def</span> <span class="nf">soft_cosine</span><span class="p">(</span><span class="n">row</span><span class="p">):</span>
    <span class="n">question</span> <span class="o">=</span> <span class="n">jieba</span><span class="o">.</span><span class="n">lcut</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="s1">&#39;question&#39;</span><span class="p">])</span>
    <span class="n">answer</span> <span class="o">=</span> <span class="n">jieba</span><span class="o">.</span><span class="n">lcut</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="s1">&#39;answer&#39;</span><span class="p">])</span>
    <span class="n">docs</span> <span class="o">=</span> <span class="p">[</span><span class="n">question</span><span class="p">,</span> <span class="n">answer</span><span class="p">]</span>
    <span class="n">DICTION</span> <span class="o">=</span> <span class="n">Dictionary</span><span class="p">(</span><span class="n">docs</span><span class="p">)</span>
    <span class="n">docs2</span> <span class="o">=</span> <span class="p">[</span><span class="n">DICTION</span><span class="o">.</span><span class="n">doc2bow</span><span class="p">(</span><span class="n">doc</span><span class="p">)</span> <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">docs</span><span class="p">]</span>
    <span class="n">TFIDF</span> <span class="o">=</span> <span class="n">TfidfModel</span><span class="p">(</span><span class="n">docs2</span><span class="p">)</span>
    <span class="n">termsim_index</span> <span class="o">=</span> <span class="n">WordEmbeddingSimilarityIndex</span><span class="p">(</span><span class="n">w2v_model</span><span class="o">.</span><span class="n">wv</span><span class="p">)</span>
    <span class="n">termsim_matrix</span> <span class="o">=</span> <span class="n">SparseTermSimilarityMatrix</span><span class="p">(</span><span class="n">termsim_index</span><span class="p">,</span> <span class="n">DICTION</span><span class="p">,</span> <span class="n">TFIDF</span><span class="p">)</span>
    <span class="n">similarity</span> <span class="o">=</span> <span class="n">termsim_matrix</span><span class="o">.</span><span class="n">inner_product</span><span class="p">(</span><span class="n">docs2</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">docs2</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">normalized</span><span class="o">=</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">similarity</span>


<span class="n">row</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;question&#39;</span><span class="p">:</span><span class="s1">&#39;公司的核心竞争力?&#39;</span><span class="p">,</span> 
       <span class="s1">&#39;answer&#39;</span><span class="p">:</span> <span class="s1">&#39;企业未来的发力肯定是围绕品牌和渠道发力，品牌又是重中之重．&#39;</span><span class="p">}</span>


<span class="c1">#该问答的软余弦相似度</span>
<span class="n">soft_cosine</span><span class="p">(</span><span class="n">row</span><span class="p">)</span>

</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">0.17236403
</code></pre></div><p>该问答的软余弦相似度为0.17236403， 则答非所问程度1-0.17236403 = 0.82763597</p>
<blockquote>
<p>需要注意， <strong>答非所问程度 = 1 - 软余弦相似度</strong></p>
</blockquote>
<br>
<h3 id="33-计算多个问答答非所问程度">3.3 计算多个问答「答非所问程度」</h3>
<p>点击下载本文实验数据 <a href="%E9%97%AE%E7%AD%94%E6%95%B0%E6%8D%AE.csv"><em><strong>问答数据.csv</strong></em></a></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-Python" data-lang="Python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="c1">#问答实验数据</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;问答数据.csv&#39;</span><span class="p">)</span>
<span class="n">df</span>
</code></pre></div><p><img loading="lazy" src="img/02-df.png" alt=""  />
</p>
<br>
<p>建议各位将问答数据整理到csv或者xlsx格式， 第一列question字段， 第二列为answer字段，保证字段名与本代码一致。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">gensim.corpora</span> <span class="kn">import</span> <span class="n">Dictionary</span>
<span class="kn">from</span> <span class="nn">gensim.models</span> <span class="kn">import</span> <span class="n">TfidfModel</span>
<span class="kn">from</span> <span class="nn">gensim.similarities</span> <span class="kn">import</span> <span class="n">SparseTermSimilarityMatrix</span><span class="p">,</span> <span class="n">WordEmbeddingSimilarityIndex</span>
<span class="kn">from</span> <span class="nn">gensim.models</span> <span class="kn">import</span> <span class="n">KeyedVectors</span>
<span class="kn">import</span> <span class="nn">jieba</span>

<span class="c1">#导入预训练word2vec模型</span>
<span class="n">w2v_model</span> <span class="o">=</span> <span class="n">KeyedVectors</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;Word2Vec/mda01-22.200.6.bin&#39;</span><span class="p">)</span>


<span class="c1">#软余弦相似度</span>
<span class="k">def</span> <span class="nf">soft_cosine</span><span class="p">(</span><span class="n">row</span><span class="p">):</span>
    <span class="n">question</span> <span class="o">=</span> <span class="n">jieba</span><span class="o">.</span><span class="n">lcut</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="s1">&#39;question&#39;</span><span class="p">])</span>
    <span class="n">answer</span> <span class="o">=</span> <span class="n">jieba</span><span class="o">.</span><span class="n">lcut</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="s1">&#39;answer&#39;</span><span class="p">])</span>
    <span class="n">docs</span> <span class="o">=</span> <span class="p">[</span><span class="n">question</span><span class="p">,</span> <span class="n">answer</span><span class="p">]</span>
    <span class="n">DICTION</span> <span class="o">=</span> <span class="n">Dictionary</span><span class="p">(</span><span class="n">docs</span><span class="p">)</span>
    <span class="n">docs2</span> <span class="o">=</span> <span class="p">[</span><span class="n">DICTION</span><span class="o">.</span><span class="n">doc2bow</span><span class="p">(</span><span class="n">doc</span><span class="p">)</span> <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">docs</span><span class="p">]</span>
    <span class="n">TFIDF</span> <span class="o">=</span> <span class="n">TfidfModel</span><span class="p">(</span><span class="n">docs2</span><span class="p">)</span>
    <span class="n">termsim_index</span> <span class="o">=</span> <span class="n">WordEmbeddingSimilarityIndex</span><span class="p">(</span><span class="n">w2v_model</span><span class="o">.</span><span class="n">wv</span><span class="p">)</span>
    <span class="n">termsim_matrix</span> <span class="o">=</span> <span class="n">SparseTermSimilarityMatrix</span><span class="p">(</span><span class="n">termsim_index</span><span class="p">,</span> <span class="n">DICTION</span><span class="p">,</span> <span class="n">TFIDF</span><span class="p">)</span>
    <span class="n">similarity</span> <span class="o">=</span> <span class="n">termsim_matrix</span><span class="o">.</span><span class="n">inner_product</span><span class="p">(</span><span class="n">docs2</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">docs2</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">normalized</span><span class="o">=</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">similarity</span>
  


<span class="c1">#批量计算</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;问答数据.csv&#39;</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;similarity&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">soft_cosine</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;答非所问&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;similarity&#39;</span><span class="p">]</span>

<span class="n">df</span>
</code></pre></div><p><img loading="lazy" src="img/03-df.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="四资料获取">四、资料获取</h2>
<p>除 **<a href="https://textdata.cn/blog/2023-03-24-load-w2v-and-expand-your-concpet-dicitonary/">Word2Vec/mda01-22.200.6.bin**</a> 是付费内容， 其余内容均都是公开的。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">100元   Word2Vec相关模型文件(mda01-22.200.6.bin)

加微信 372335839， 备注「姓名-学校-专业-word2vec」
</code></pre></div><p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>从3571w条专利数据集「匹配」上市公司的专利信息</title>
      <link>https://textdata.cn/blog/2023-04-26-matching-listed-corporate-with-patent-dataset/</link>
      <pubDate>Wed, 26 Apr 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-04-26-matching-listed-corporate-with-patent-dataset/</guid>
      <description>3571万专利申请全量数据(1985-2022年)数据</description>
      <content:encoded><![CDATA[<h2 id="一问题">一、问题</h2>
<p>之前分享过 <a href="https://textdata.cn/blog/2023-04-13-3571w-patent-dataset-in-china-mainland/">数据集(付费) | 3571万条专利申请数据集(1985-2022年)</a> ， 没有涉及匹配数据的问题。 <strong>有学员反映，该数据集是否支持匹配上市公司。或者上市公司的专利数量等信息能否从该数据集中抽取， 答案是可以的</strong>。 如果对数据集了解，可以直接看第二部分，不熟悉的建议看下数据集大致信息。</p>
<br>
<h3 id="11-专利申请数据集">1.1 专利申请数据集</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">- 数据集名称：省份版知识产权局专利
- 时间跨度：1985-2022，专利申请总量3571万
- 文件格式: csv
- 数据来源：『国家知识产权局』
- 数据整理: 『公众号:大邓和他的Python』
</code></pre></div><p><img loading="lazy" src="img/screen-datasets2.png" alt=""  />
</p>
<br>
<h3 id="12-字段">1.2 字段</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"> -  专利公开号
 -  专利名称
 -  专利类型
 -  专利摘要
 -  【申请人】
 -  专利申请号
 -  申请日
 -  申请公布日
 -  授权公布号
 -  授权公布日
 -  申请地址
 -  主权项
 -  发明人
 -  分类号
 -  主分类号
 -  代理机构
 -  分案原申请号
 -  优先权
 -  国际申请
 -  国际公布
 -  代理人
 -  省份或国家代码
 -  法律状态
 -  专利领域
 -  专利学科
 -  多次公布
</code></pre></div><br>
<h3 id="13-数据集大小">1.3 数据集大小</h3>
<p>把所有的 <em><strong>gz</strong></em> 压缩文件解压后， 数据集大概70G，</p>
<p><img loading="lazy" src="img/screen-datasets.png" alt=""  />
</p>
<br>
<h3 id="13-分省统计">1.3 分省统计</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">| 省份(区域)       |  专利数  |
| :---------------| :------ |
| 广东省           | 5728705 |
| 江苏省           | 4879171 |
| 浙江省           | 3706820 |
| 山东省           | 2064446 |
| 北京市           | 2069913 |
| 四川省           | 1159551 |
| 天津市           | 712932  |
| 上海市           | 1548278 |
| 贵州省           | 265512  |
| 陕西省           | 655837  |
| 吉林省           | 232264  |
| 辽宁省           | 637853  |
| 湖北省           | 966384  |
| 山西省           | 233418  |
| 宁夏回族自治区    | 66919   |
| 西藏自治区        | 9911    |
| 广西壮族自治区    | 377658  |
| 江西省           | 519584  |
| 湖南省           | 743828  |
| 黑龙江省         | 357881  |
| 海南省           | 59202   |
| 福建省           | 1046473 |
| 安徽省           | 1342364 |
| 河北省           | 645420  |
| 重庆市           | 592382  |
| 内蒙古自治区      | 133277  |
| 云南省           | 252407  |
| 甘肃省           | 164274  |
| 新疆维吾尔自治区   | 124734  |
| 河南省           | 966477  |
| 青海省           | 34127   |
| 台湾省           | 401555  |
| 香港特别行政区    | 61636   |
| 澳门特别行政区    | 2010    |
| 其他国家         | 2948557 |
</code></pre></div><p><br><br></p>
<h2 id="二读取数据">二、读取数据</h2>
<p>数据集中的个别csv文件较大，例如 <em><strong>广东省.csv</strong></em> 体积10G。 我们就以建议分析的时候， 电脑内存大于等于16G的， 每次分析时不要开其他软件。</p>
<p>为了演示， 我选择用较小的 黑龙江省.csv 为例。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;黑龙江省.csv.gz&#39;</span><span class="p">,</span> <span class="n">compression</span><span class="o">=</span><span class="s1">&#39;gzip&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">,</span> <span class="n">low_memory</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="c1">#解压后，读取csv的方法</span>
<span class="c1">#df = pd.read_csv(&#39;黑龙江省.csv&#39;, encoding=&#39;utf-8&#39;, low_memory=False)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<p><img loading="lazy" src="img/df.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;黑龙江省专利数量: &#39;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">))</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">河北省: 357881
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#数据集中的字段含</span>
<span class="n">df</span><span class="o">.</span><span class="n">columns</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">Index([&#39;专利公开号&#39;, &#39;专利名称&#39;, &#39;专利类型&#39;, &#39;专利摘要&#39;, 
&#39;申请人&#39;, &#39;专利申请号&#39;, &#39;申请日&#39;, &#39;申请公布日&#39;, 
&#39;授权公布号&#39;, &#39;授权公布日&#39;, &#39;申请地址&#39;, &#39;主权项&#39;, &#39;发明人&#39;,
&#39;分类号&#39;, &#39;主分类号&#39;, &#39;代理机构&#39;, &#39;分案原申请号&#39;, &#39;优先权&#39;, 
&#39;国际申请&#39;, &#39;国际公布&#39;, &#39;代理人&#39;, &#39;省份或国家代码&#39;,
&#39;法律状态&#39;, &#39;专利领域&#39;, &#39;专利学科&#39;, &#39;多次公布&#39;],
dtype=&#39;object&#39;)
</code></pre></div><p><br><br></p>
<p>大邓现在在大东北，知道黑龙江的上市公司有哈药集团和北大荒。 我们就查一下 「黑龙江省.csv」 专利申请的数据中是否有北大荒和哈药集团。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;北大荒专利数: &#39;</span><span class="p">,</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;申请人&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="s1">&#39;北大荒集团&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;哈药集团专利数: &#39;</span><span class="p">,</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;申请人&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="s1">&#39;哈药集团&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">北大荒专利数:  4
哈药集团专利数:  712
</code></pre></div><p>还真有!!! so， 这个  <a href="">数据集 | 3571万条专利申请数据集(1985-2022年)</a> 是真的可以匹配上市公司，做一些有价值的变量。 感叹完毕， 继续写点没营养的代码。</p>
<br>
<h2 id="三匹配公司">三、匹配公司</h2>
<p>从上面可以看出哈药集团专利数很多，咱们继续检查哈药集团的专利数据。那么如何筛选出某公司的所有专利申请记录数据呢？这里会用到DataFrame的布尔条件筛选，把值为True的筛选出来。</p>
<ol>
<li>宽松条件  <code>「申请人」含「哈药集团」字眼的</code></li>
<li>严格条件 <code>「申请人」所含字眼就是「哈药集团」四个字</code></li>
</ol>
<br>
<h3 id="31-宽松条件">3.1 宽松条件</h3>
<p>把「申请人」含「哈药集团」字眼的记录筛选出来</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df2</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;申请人&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="s1">&#39;哈药集团&#39;</span><span class="p">)</span><span class="o">==</span><span class="kc">True</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">df2</span><span class="p">))</span>
<span class="n">df2</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/df2.png" alt=""  />
</p>
<p>返回结果可以看到，申请人主体是有很多个不同的主体，都是「哈药集团」附属的子公司或分厂。</p>
<br>
<h3 id="31-严格条件">3.1 严格条件</h3>
<p>「申请人」所含字眼就是「哈药集团」四个字</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df3</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;申请人&#39;</span><span class="p">]</span><span class="o">==</span><span class="s1">&#39;哈药集团&#39;</span><span class="p">]</span>

<span class="n">df3</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/df3.png" alt=""  />
</p>
<p>严格条件筛选后，符合的记录数量为0 。 「哈药集团」这四个字是上市公司名称的缩写简写，所以直接这样做筛选，一般得到的结果都是0。  实际上，一个完整的公司名一般是 「属地+公司名+股份有限公司」。例如，</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df4</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;申请人&#39;</span><span class="p">]</span><span class="o">==</span><span class="s1">&#39;哈药集团三精制药四厂有限公司&#39;</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">df4</span><span class="p">))</span>
<span class="n">df4</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">28
</code></pre></div><p><img loading="lazy" src="img/df4.png" alt=""  />
</p>
<br>
<br>
<h2 id="四其他操作">四、其他操作</h2>
<h3 id="41-类型字段">4.1 类型字段</h3>
<p>想了解「哈药集团」相关公司「专利领域」的分布情况</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df3</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;申请人&#39;</span><span class="p">]</span><span class="o">==</span><span class="s1">&#39;哈药集团&#39;</span><span class="p">]</span>

<span class="n">df3</span><span class="p">[</span><span class="s1">&#39;专利领域&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">工程科技Ⅱ辑            265
医药卫生科技            250
工程科技Ⅰ辑            157
基础科学               34
农业科技                5
工程科技Ⅰ辑; 工程科技Ⅱ辑      1
Name: 专利领域, dtype: int64
</code></pre></div><p>可以看到 「哈药集团」 在医药相关的领域布局较多，农业科技只有5个，从中可以看出 「哈药集团」还是一个技术很专注的企业。</p>
<br>
<h3 id="42-如何剔除nan">4.2 如何剔除Nan</h3>
<p>如果对某个字段感兴趣， 比如「国际申请」</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df</span><span class="p">[</span><span class="s1">&#39;国际申请&#39;</span><span class="p">]</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">0         NaN
1         NaN
2         NaN
3         NaN
4         NaN
         ... 
357876    NaN
357877    NaN
357878    NaN
357879    NaN
357880    NaN
Name: 国际申请, Length: 357881, dtype: object
</code></pre></div><p>但肉眼所见全是Nan， <strong>如何剔除掉Nan， 显露出非Nan的记录呢？</strong></p>
<p>解决办法依然是使用DataFrame的逻辑布尔筛选数据。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df</span><span class="p">[</span><span class="o">~</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;国际申请&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">isna</span><span class="p">()]</span>
</code></pre></div><p><img loading="lazy" src="img/df5.png" alt=""  />

<br></p>
<br>
<h2 id="五获取3751w专利数据集">五、获取3751w专利数据集</h2>
<p>该数据集为付费数据集， 如需数据，点击该链接 <a href="https://textdata.cn/blog/2023-04-13-3571w-patent-dataset-in-china-mainland/">数据集(付费) | 3571万条专利申请数据集(1985-2022年)</a> 进行购买。</p>
<p><br><br></p>
<h2 id="相关资料">相关资料</h2>
<ul>
<li>
<p><a href="https://textdata.cn/blog/2023-12-22-patent-transform-exchange-dataset/">数据集 | 专利转让数据集(1985-2021)</a></p>
</li>
<li>
<p><a href="https://textdata.cn/blog/2023-12-07-patent-application-dataset-of-listed-company-in-china-a-market/">数据集 | 上市公司 208 万条专利数据集 (1991-2022)</a></p>
</li>
<li>
<p><a href="https://textdata.cn/blog/2028-12-18-how-to-extract-data-from-patent-application-dataset/"><strong>代码 | 使用3571w专利申请数据集构造「面板数据」</strong></a></p>
</li>
<li>
<p><a href="https://textdata.cn/blog/2023-04-26-matching-listed-corporate-with-patent-dataset/">从3571w条专利数据集「匹配」上市公司的专利信息</a></p>
</li>
</ul>
<p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>实验 | 互联网黑话与MD&amp;A</title>
      <link>https://textdata.cn/blog/2023-04-26-chinese-it-industry-slangs-words/</link>
      <pubDate>Wed, 26 Apr 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-04-26-chinese-it-industry-slangs-words/</guid>
      <description>&lt;p&gt;最近大邓意外发现，使用mda预训练语言模型扩展互联网黑近义词，模型返回的有鼻子有眼的，这意味着上市公司高管在md&amp;amp;a中可能频繁使用了互联网黑话。&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;一互联网黑话&#34;&gt;一、互联网黑话&lt;/h2&gt;
&lt;h3 id=&#34;二字动词&#34;&gt;二字动词&lt;/h3&gt;
&lt;p&gt;复盘，赋能，沉淀，倒逼，落地，串联，协同，反晡，兼容，包装，重组，履约，晌应，量化，发力，布局，联动，细分，梳理，输出，加速，共建，支撑，融合，聚合，集成，对齐，对标，对焦，拆解，拉通，抽象，摸索，提炼，打通，打透，吃透，迁移，分发，分层，分装，穿梭，辐射，围绕，复用，渗透，扩展，开拓。&lt;/p&gt;
&lt;h3 id=&#34;二字名词&#34;&gt;二字名词&lt;/h3&gt;
&lt;p&gt;漏斗，中台，闭环，打法，拉通，纽带，矩阵，刺激，规模，场景，聚焦，维度，格局，形态，生态，话术，体系，抓手，赛道，认知，玩法，体感，感知，调性，心智，战役，合力，心力。&lt;/p&gt;
&lt;h3 id=&#34;三字名词&#34;&gt;三字名词&lt;/h3&gt;
&lt;p&gt;颗粒度，感知度，方法论，组合拳，引爆点，点线面，精细化，差异化，平台化，结构化，影响力，耦合性，易用性，一致性，端到端，短平快。&lt;/p&gt;
&lt;h3 id=&#34;四字名词&#34;&gt;四字名词&lt;/h3&gt;
&lt;p&gt;生命周期，价值转化，强化认知，资源倾斜，完善逻辑，抽离透传，复用打法，商业模式，快速响应，定性定量，关键路径，去中心化，结果导向，垂直领域，如何收口，归因分析，体验度量，信息屏障。&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;二模型近义词&#34;&gt;二、模型近义词&lt;/h2&gt;
&lt;p&gt;之前分享过一个中文金融领域的word2vec预训练语言模型，这里就不详细介绍模型参数。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://textdata.cn/blog/2023-03-24-load-w2v-and-expand-your-concpet-dicitonary/&#34;&gt;使用中文MD&amp;amp;A数据集训练word2vec预训练模型， 可扩展或新建会计金融等领域的情感词典&lt;/a&gt;&lt;/p&gt;
&lt;br&gt;
&lt;p&gt;文本分析最常用的方法是词典法(例如，LIWC)，而词向量模型可以帮助我们扩展或者构建概念情感词典。&lt;/p&gt;
&lt;p&gt;现在给大家演示只给一个词，返回topn个语义最相关的词。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 与 seedwords 最相关的前topn个词&lt;/span&gt;
&lt;span class=&#34;c1&#34;&gt;# wv是预训练语言模型&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;expand_dictionary&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
                  &lt;span class=&#34;n&#34;&gt;seedwords&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;复盘&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;
                  &lt;span class=&#34;n&#34;&gt;topn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;[&amp;#39;复盘&amp;#39;,
 &amp;#39;检视&amp;#39;,
 &amp;#39;检讨&amp;#39;,
 &amp;#39;KPI&amp;#39;,
 &amp;#39;考核评估&amp;#39;,
 &amp;#39;量化考核&amp;#39;,
 &amp;#39;跟踪考核&amp;#39;,
 &amp;#39;纠偏&amp;#39;,
 &amp;#39;过程跟踪&amp;#39;,
 &amp;#39;分析总结&amp;#39;,
 &amp;#39;KPI指标&amp;#39;]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;expand_dictionary&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
                  &lt;span class=&#34;n&#34;&gt;seedwords&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;赋能&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;
                  &lt;span class=&#34;n&#34;&gt;topn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;[&amp;#39;赋能&amp;#39;,
 &amp;#39;技术赋能&amp;#39;,
 &amp;#39;全面赋能&amp;#39;,
 &amp;#39;平台赋能&amp;#39;,
 &amp;#39;科技赋能&amp;#39;,
 &amp;#39;助力&amp;#39;,
 &amp;#39;数字化赋能&amp;#39;,
 &amp;#39;数据赋能&amp;#39;,
 &amp;#39;数智化&amp;#39;,
 &amp;#39;数据驱动&amp;#39;,
 &amp;#39;生态构建&amp;#39;]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;expand_dictionary&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
                  &lt;span class=&#34;n&#34;&gt;seedwords&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;感知度&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;
                  &lt;span class=&#34;n&#34;&gt;topn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;[&amp;#39;感知度&amp;#39;,
 &amp;#39;体验度&amp;#39;,
 &amp;#39;产品认知度&amp;#39;,
 &amp;#39;知晓度&amp;#39;,
 &amp;#39;购买率&amp;#39;,
 &amp;#39;品牌黏性&amp;#39;,
 &amp;#39;满意度忠诚度&amp;#39;,
 &amp;#39;忠诚度美誉度&amp;#39;,
 &amp;#39;消费者满意度&amp;#39;,
 &amp;#39;体验满意度&amp;#39;,
 &amp;#39;好感度&amp;#39;]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;expand_dictionary&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
                  &lt;span class=&#34;n&#34;&gt;seedwords&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;倒逼&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;
                  &lt;span class=&#34;n&#34;&gt;topn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;[&amp;#39;倒逼&amp;#39;, 
&amp;#39;倒逼企业&amp;#39;, 
&amp;#39;势在必行&amp;#39;, 
&amp;#39;迫使&amp;#39;, 
&amp;#39;大势所趋&amp;#39;, 
&amp;#39;促使&amp;#39;, 
&amp;#39;优胜劣汰&amp;#39;, 
&amp;#39;加速淘汰&amp;#39;, 
&amp;#39;势必&amp;#39;, 
&amp;#39;趋严&amp;#39;, 
&amp;#39;成为常态&amp;#39;]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;expand_dictionary&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
                  &lt;span class=&#34;n&#34;&gt;seedwords&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;闭环&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;
                  &lt;span class=&#34;n&#34;&gt;topn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;[&amp;#39;闭环&amp;#39;,
&amp;#39;完整闭环&amp;#39;, 
&amp;#39;全链路&amp;#39;, 
&amp;#39;全链条&amp;#39;, 
&amp;#39;全流程&amp;#39;, 
&amp;#39;闭环式&amp;#39;, 
&amp;#39;端端&amp;#39;, 
&amp;#39;端到端&amp;#39;, 
&amp;#39;服务闭环&amp;#39;, 
&amp;#39;全周期&amp;#39;, 
&amp;#39;闭环管理&amp;#39;]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;expand_dictionary&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
                  &lt;span class=&#34;n&#34;&gt;seedwords&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;端到端&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;
                  &lt;span class=&#34;n&#34;&gt;topn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;[&amp;#39;端到端&amp;#39;,
 &amp;#39;端端&amp;#39;,
 &amp;#39;端到端的&amp;#39;,
 &amp;#39;全链路&amp;#39;,
 &amp;#39;端端的&amp;#39;,
 &amp;#39;数字化运营&amp;#39;,
 &amp;#39;全业务流程&amp;#39;,
 &amp;#39;场景全&amp;#39;,
 &amp;#39;全链条&amp;#39;,
 &amp;#39;敏捷&amp;#39;,
 &amp;#39;全价值链&amp;#39;]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;可以看到， 返回的近义词都是挺互联网范儿的。 只有较为频繁使用， 语言模型才有可能捕捉到这种语义关系。这从侧面反映了近年来互联网高级黑话影响力之大。&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;三获取模型&#34;&gt;三、获取模型&lt;/h2&gt;
&lt;p&gt;模型训练不易， 为付费资源，如需使用请 &lt;a href=&#34;https://mp.weixin.qq.com/s/zle9-BR-ei1V8Nmul19_7w&#34;&gt;&lt;strong&gt;点击进入跳转购买链接&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;期待合作&#34;&gt;期待合作&lt;/h2&gt;
&lt;p&gt;cntext目前仍在技术迭代，版本2.0.0综合了训练语言模型&amp;amp;多语言模型对齐， 有较大的应用价值，期待有独特文本数据集交流合作。&lt;/p&gt;
&lt;p&gt;通过cntext2.0.0，理论上可以对文本所涉社会主体进行计算，适合企业文化、品牌印象、旅游目的地形象、国家形象等&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;同主体不同时间段， 文本中蕴含的文化态度认知变迁，&lt;/li&gt;
&lt;li&gt;或同时间段，不同主体的大样本文本蕴含的差异性&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;广而告之&#34;&gt;广而告之&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/call_for_paper/&#34;&gt;长期征稿&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/we_need_you/&#34;&gt;长期招募小伙伴&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/management_python_course/&#34;&gt;付费视频课 | Python实证指标构建与文本分析&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
      <content:encoded><![CDATA[<p>最近大邓意外发现，使用mda预训练语言模型扩展互联网黑近义词，模型返回的有鼻子有眼的，这意味着上市公司高管在md&amp;a中可能频繁使用了互联网黑话。</p>
<p><br><br></p>
<h2 id="一互联网黑话">一、互联网黑话</h2>
<h3 id="二字动词">二字动词</h3>
<p>复盘，赋能，沉淀，倒逼，落地，串联，协同，反晡，兼容，包装，重组，履约，晌应，量化，发力，布局，联动，细分，梳理，输出，加速，共建，支撑，融合，聚合，集成，对齐，对标，对焦，拆解，拉通，抽象，摸索，提炼，打通，打透，吃透，迁移，分发，分层，分装，穿梭，辐射，围绕，复用，渗透，扩展，开拓。</p>
<h3 id="二字名词">二字名词</h3>
<p>漏斗，中台，闭环，打法，拉通，纽带，矩阵，刺激，规模，场景，聚焦，维度，格局，形态，生态，话术，体系，抓手，赛道，认知，玩法，体感，感知，调性，心智，战役，合力，心力。</p>
<h3 id="三字名词">三字名词</h3>
<p>颗粒度，感知度，方法论，组合拳，引爆点，点线面，精细化，差异化，平台化，结构化，影响力，耦合性，易用性，一致性，端到端，短平快。</p>
<h3 id="四字名词">四字名词</h3>
<p>生命周期，价值转化，强化认知，资源倾斜，完善逻辑，抽离透传，复用打法，商业模式，快速响应，定性定量，关键路径，去中心化，结果导向，垂直领域，如何收口，归因分析，体验度量，信息屏障。</p>
<p><br><br></p>
<h2 id="二模型近义词">二、模型近义词</h2>
<p>之前分享过一个中文金融领域的word2vec预训练语言模型，这里就不详细介绍模型参数。</p>
<p><a href="https://textdata.cn/blog/2023-03-24-load-w2v-and-expand-your-concpet-dicitonary/">使用中文MD&amp;A数据集训练word2vec预训练模型， 可扩展或新建会计金融等领域的情感词典</a></p>
<br>
<p>文本分析最常用的方法是词典法(例如，LIWC)，而词向量模型可以帮助我们扩展或者构建概念情感词典。</p>
<p>现在给大家演示只给一个词，返回topn个语义最相关的词。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1"># 与 seedwords 最相关的前topn个词</span>
<span class="c1"># wv是预训练语言模型</span>
<span class="n">expand_dictionary</span><span class="p">(</span><span class="n">wv</span><span class="o">=</span><span class="n">wv</span><span class="p">,</span> 
                  <span class="n">seedwords</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;复盘&#39;</span><span class="p">],</span>
                  <span class="n">topn</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">[&#39;复盘&#39;,
 &#39;检视&#39;,
 &#39;检讨&#39;,
 &#39;KPI&#39;,
 &#39;考核评估&#39;,
 &#39;量化考核&#39;,
 &#39;跟踪考核&#39;,
 &#39;纠偏&#39;,
 &#39;过程跟踪&#39;,
 &#39;分析总结&#39;,
 &#39;KPI指标&#39;]
</code></pre></div> <br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">expand_dictionary</span><span class="p">(</span><span class="n">wv</span><span class="o">=</span><span class="n">wv</span><span class="p">,</span> 
                  <span class="n">seedwords</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;赋能&#39;</span><span class="p">],</span>
                  <span class="n">topn</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">[&#39;赋能&#39;,
 &#39;技术赋能&#39;,
 &#39;全面赋能&#39;,
 &#39;平台赋能&#39;,
 &#39;科技赋能&#39;,
 &#39;助力&#39;,
 &#39;数字化赋能&#39;,
 &#39;数据赋能&#39;,
 &#39;数智化&#39;,
 &#39;数据驱动&#39;,
 &#39;生态构建&#39;]
</code></pre></div> <br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">expand_dictionary</span><span class="p">(</span><span class="n">wv</span><span class="o">=</span><span class="n">wv</span><span class="p">,</span> 
                  <span class="n">seedwords</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;感知度&#39;</span><span class="p">],</span>
                  <span class="n">topn</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">[&#39;感知度&#39;,
 &#39;体验度&#39;,
 &#39;产品认知度&#39;,
 &#39;知晓度&#39;,
 &#39;购买率&#39;,
 &#39;品牌黏性&#39;,
 &#39;满意度忠诚度&#39;,
 &#39;忠诚度美誉度&#39;,
 &#39;消费者满意度&#39;,
 &#39;体验满意度&#39;,
 &#39;好感度&#39;]
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">expand_dictionary</span><span class="p">(</span><span class="n">wv</span><span class="o">=</span><span class="n">wv</span><span class="p">,</span> 
                  <span class="n">seedwords</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;倒逼&#39;</span><span class="p">],</span>
                  <span class="n">topn</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">[&#39;倒逼&#39;, 
&#39;倒逼企业&#39;, 
&#39;势在必行&#39;, 
&#39;迫使&#39;, 
&#39;大势所趋&#39;, 
&#39;促使&#39;, 
&#39;优胜劣汰&#39;, 
&#39;加速淘汰&#39;, 
&#39;势必&#39;, 
&#39;趋严&#39;, 
&#39;成为常态&#39;]
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">expand_dictionary</span><span class="p">(</span><span class="n">wv</span><span class="o">=</span><span class="n">wv</span><span class="p">,</span> 
                  <span class="n">seedwords</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;闭环&#39;</span><span class="p">],</span>
                  <span class="n">topn</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">[&#39;闭环&#39;,
&#39;完整闭环&#39;, 
&#39;全链路&#39;, 
&#39;全链条&#39;, 
&#39;全流程&#39;, 
&#39;闭环式&#39;, 
&#39;端端&#39;, 
&#39;端到端&#39;, 
&#39;服务闭环&#39;, 
&#39;全周期&#39;, 
&#39;闭环管理&#39;]
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">expand_dictionary</span><span class="p">(</span><span class="n">wv</span><span class="o">=</span><span class="n">wv</span><span class="p">,</span> 
                  <span class="n">seedwords</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;端到端&#39;</span><span class="p">],</span>
                  <span class="n">topn</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">[&#39;端到端&#39;,
 &#39;端端&#39;,
 &#39;端到端的&#39;,
 &#39;全链路&#39;,
 &#39;端端的&#39;,
 &#39;数字化运营&#39;,
 &#39;全业务流程&#39;,
 &#39;场景全&#39;,
 &#39;全链条&#39;,
 &#39;敏捷&#39;,
 &#39;全价值链&#39;]
</code></pre></div><p>可以看到， 返回的近义词都是挺互联网范儿的。 只有较为频繁使用， 语言模型才有可能捕捉到这种语义关系。这从侧面反映了近年来互联网高级黑话影响力之大。</p>
<p><br><br></p>
<h2 id="三获取模型">三、获取模型</h2>
<p>模型训练不易， 为付费资源，如需使用请 <a href="https://mp.weixin.qq.com/s/zle9-BR-ei1V8Nmul19_7w"><strong>点击进入跳转购买链接</strong></a></p>
<p><br><br></p>
<h2 id="期待合作">期待合作</h2>
<p>cntext目前仍在技术迭代，版本2.0.0综合了训练语言模型&amp;多语言模型对齐， 有较大的应用价值，期待有独特文本数据集交流合作。</p>
<p>通过cntext2.0.0，理论上可以对文本所涉社会主体进行计算，适合企业文化、品牌印象、旅游目的地形象、国家形象等</p>
<ul>
<li>同主体不同时间段， 文本中蕴含的文化态度认知变迁，</li>
<li>或同时间段，不同主体的大样本文本蕴含的差异性</li>
</ul>
<p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>数据集 | 3.3万 Instagram Influencer的 1018万条推文数据</title>
      <link>https://textdata.cn/blog/2023-12-24-instagram-influencer-dataset/</link>
      <pubDate>Wed, 26 Apr 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-12-24-instagram-influencer-dataset/</guid>
      <description>3.3万 Instagram Influencer的 1018万条推文数据</description>
      <content:encoded><![CDATA[<h2 id="一数据集概况">一、数据集概况</h2>
<p><a href="https://sites.google.com/site/sbkimcv/dataset/instagram-influencer-dataset">https://sites.google.com/site/sbkimcv/dataset/instagram-influencer-dataset</a></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">- 33,935 位 Instagram 影响者（分为 9 个类别）
- 10,180,500 个 Instagram 帖子
- 发布元数据（JSON 文件）：~37 GB
- 图像（JPEG 文件）：~189 GB
</code></pre></div><p>作者很nice的，点击 上方链接 给作者留下你的信息，两三天就收到数据集下载链接(谷歌网盘)。</p>
<br> 
<p>作为 <a href="https://sites.google.com/site/sbkimcv/research"><strong>AI for Influencer Marketing</strong></a> 的一部分，我从 Instagram 收集了数据并出于研究目的进行分享。该数据集包含 33,935 位影响者及其 10,180,500 个 Instagram 帖子（每个影响者 300 个帖子）。该数据集包括两种类型的文件： <em><strong>帖子元数据</strong></em> 和 <em><strong>图像文件</strong></em> 。</p>
<p>帖子元数据文件采用 JSON 格式，包含以下信息：<em><strong>标题、用户标签、主题标签、时间戳、赞助、点赞、评论</strong></em>等。图像文件采用 JPEG 格式，数据集包含 12,933,406 个图像文件，因为一篇帖子可以有多个图像文件图像文件。如果一篇文章只有一个图像文件，则 JSON 文件和相应的图像文件具有相同的名称。但是，如果一篇文章包含多个图像，则 JSON 文件和相应的图像文件具有不同的名称。因此，我们还提供了一个 JSON-Image_mapping 文件，该文件显示与帖子元数据对应的图像文件列表。</p>
<p>影响者分为以下九类：</p>
<ol>
<li>Beauty</li>
<li>Family</li>
<li>Fashion</li>
<li>Fitness</li>
<li>Food</li>
<li>Interior</li>
<li>Pet</li>
<li>Travel</li>
<li>Other</li>
</ol>
<p><img loading="lazy" src="img/01-category.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="二引用说明">二、引用说明</h2>
<p>使用  <a href="https://sites.google.com/site/sbkimcv/dataset/instagram-influencer-dataset"><strong>Instagram Influencer Dataset</strong> </a>,  需声明数据来源，</p>
<p>&ldquo;Multimodal Post Attentive Profiling for Influencer Marketing,&rdquo; Seungbae Kim, Jyun-Yu Jiang, Masaki Nakada, Jinyoung Han and Wei Wang. In Proceedings of The Web Conference (WWW &lsquo;20), ACM, 2020.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">@inproceedings{kim2020multimodal,
  title={Multimodal Post Attentive Profiling for Influencer Marketing},
  author={Kim, Seungbae and Jiang, Jyun-Yu and Nakada, Masaki and Han, Jinyoung and Wang, Wei},
  booktitle={Proceedings of The Web Conference 2020},
  pages={2878--2884},
  year={2020}
}
</code></pre></div><p><br><br></p>
<h2 id="三其他营销数据">三、其他营销数据</h2>
<ul>
<li><a href="https://textdata.cn/blog/2023-11-22-1000w-github-developer-dataset/">数据集 | 1000万 Github 用户数据</a></li>
<li><a href="https://textdata.cn/blog/2023-11-22-open-dataset-gharchive-org/">2T数据集 | 使用GH Archive获取Github社区用户数据</a></li>
<li><a href="https://textdata.cn/blog/2023-12-24-instagram-influencer-dataset/">数据集 | 3.3万 Instagram Influencer的 1018万条推文数据</a></li>
<li><a href="https://textdata.cn/blog/yelpdataset_10g/">10G数据集 | YelpDaset酒店管理类数据集</a></li>
<li><a href="https://textdata.cn/blog/2022-12-08-indiegogo-dataset/">1.5G数据集 | 200万条Indiegogo众筹项目信息</a></li>
<li><a href="https://textdata.cn/blog/2022-12-04-kickstarters_dataset/">12G数据集 | 23w条Kickstarter项目信息</a></li>
<li><a href="https://textdata.cn/blog/2023-05-10-100m-bilibili-user-info-dataset/">数据集 | B站/哔哩哔哩 1 亿用户数据</a></li>
<li><a href="https://textdata.cn/blog/2023-03-06-zhihurec-dataset/">数据集 | 80w知乎用户问答数据</a></li>
</ul>
<p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>数据集(付费) | 2014年-2022年监管问询函</title>
      <link>https://textdata.cn/blog/2023-04-17-china-a-market-inquiry-letter-datasets/</link>
      <pubDate>Mon, 17 Apr 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-04-17-china-a-market-inquiry-letter-datasets/</guid>
      <description>本文只是分享Python代码，大家可以结合之前公众号内的分享，做情感分析、词频统计、情感分析等。</description>
      <content:encoded><![CDATA[<p><strong>问询函</strong>，是指上海证券交易所和深圳证券交易所在审核上市公司相关公告过程中如果发现未达到“直接监管标准”(一般表现为信息披露不准确或内容不全)的问题时，会针对财务报告、并购重组、关联交易、股票异常波动和媒体报道的社会热点等事件发出问询函，要求上市公司在规定时间内书面回函并公开披露。倘若上市公司仍存在信息披露不准确或不全的问题，交易所会再次问询。</p>
<br>
<h2 id="一数据集详情">一、数据集详情</h2>
<p><strong>问询数据集</strong>，有 <strong>13454</strong> 条问询记录， 时间范围  <strong>2014.12~2022.12</strong>, 该数据集xlsx文件有159M 。</p>
<table>
<thead>
<tr>
<th>字段</th>
<th>含义</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>code</strong></td>
<td>股票代码</td>
</tr>
<tr>
<td><strong>corp_name</strong></td>
<td>上市公司简称</td>
</tr>
<tr>
<td><strong>let_cat</strong></td>
<td><strong>监管机构</strong>发出的问询函所属类别</td>
</tr>
<tr>
<td><strong>inq_title</strong></td>
<td>问询函的标题</td>
</tr>
<tr>
<td><strong>inq_content</strong></td>
<td>问询函中询问的具体内容</td>
</tr>
<tr>
<td><strong>reply_content</strong></td>
<td>上市公司回复的详细内容</td>
</tr>
<tr>
<td><strong>inq_date</strong></td>
<td>监管机构发函日期</td>
</tr>
<tr>
<td><strong>ddl_date</strong></td>
<td>规定限期回复日期</td>
</tr>
<tr>
<td><strong>reply_date</strong></td>
<td>公司实际回复日期</td>
</tr>
</tbody>
</table>
<p>本文只是小作演示，大家可以结合之前公众号内的分享，做情感分析、词频统计、情感分析等。</p>
<p><br><br></p>
<h2 id="二导入数据">二、导入数据</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>


<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_excel</span><span class="p">(</span><span class="s1">&#39;监管问询2014-2022.xlsx&#39;</span><span class="p">)</span>  
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/df.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#字段含</span>
<span class="n">df</span><span class="o">.</span><span class="n">columns</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">Index([&#39;code&#39;, &#39;corp_name&#39;, &#39;let_cat&#39;, &#39;inq_title&#39;, &#39;inq_content&#39;,
       &#39;reply_content&#39;, &#39;inq_date&#39;, &#39;ddl_date&#39;, &#39;reply_date&#39;],
          dtype=&#39;object&#39;)
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#数据量</span>
<span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">13454
</code></pre></div><p><br><br></p>
<h2 id="三数据分析">三、数据分析</h2>
<h3 id="31-更改日期格式">3.1 更改日期格式</h3>
<p>将日期字符串数据改为datetime类型数据，即可做日期间隔的计算。这里只演示公司回复日期与监管机构发函日期时间间隔。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df</span><span class="p">[</span><span class="s1">&#39;inq_date&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;inq_date&#39;</span><span class="p">])</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;ddl_date&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;ddl_date&#39;</span><span class="p">])</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;reply_date&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;reply_date&#39;</span><span class="p">])</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;duration1&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;reply_date&#39;</span><span class="p">]</span> <span class="o">-</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;inq_date&#39;</span><span class="p">]</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/df2.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#数据集的时间跨度</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;inq_date&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;inq_date&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">2014-12-04 00:00:00
2022-12-31 00:00:00
</code></pre></div><br>
<h3 id="32-问询量年度变化">3.2 问询量年度变化</h3>
<p>随着我国金融市场发展，监管越来越到位，再加上上市公司会越来越多， 问询量年度变化应该是越来越多。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">matplotlib</span>
<span class="kn">import</span> <span class="nn">matplotlib_inline</span>
<span class="n">matplotlib_inline</span><span class="o">.</span><span class="n">backend_inline</span><span class="o">.</span><span class="n">set_matplotlib_formats</span><span class="p">(</span><span class="s1">&#39;png&#39;</span><span class="p">,</span> <span class="s1">&#39;svg&#39;</span><span class="p">)</span>
<span class="kn">import</span> <span class="nn">scienceplots</span>
<span class="kn">import</span> <span class="nn">platform</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">([</span><span class="s1">&#39;science&#39;</span><span class="p">,</span> <span class="s1">&#39;no-latex&#39;</span><span class="p">,</span> <span class="s1">&#39;cjk-sc-font&#39;</span><span class="p">])</span>
<span class="n">system</span> <span class="o">=</span> <span class="n">platform</span><span class="o">.</span><span class="n">system</span><span class="p">()</span>  <span class="c1"># 获取操作系统类型</span>

<span class="k">if</span> <span class="n">system</span> <span class="o">==</span> <span class="s1">&#39;Windows&#39;</span><span class="p">:</span>
    <span class="n">font</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;family&#39;</span><span class="p">:</span> <span class="s1">&#39;SimHei&#39;</span><span class="p">}</span>
<span class="k">elif</span> <span class="n">system</span> <span class="o">==</span> <span class="s1">&#39;Darwin&#39;</span><span class="p">:</span>
    <span class="n">font</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;family&#39;</span><span class="p">:</span> <span class="s1">&#39;Arial Unicode MS&#39;</span><span class="p">}</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">font</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;family&#39;</span><span class="p">:</span> <span class="s1">&#39;sans-serif&#39;</span><span class="p">}</span>
<span class="n">matplotlib</span><span class="o">.</span><span class="n">rc</span><span class="p">(</span><span class="s1">&#39;font&#39;</span><span class="p">,</span> <span class="o">**</span><span class="n">font</span><span class="p">)</span>  <span class="c1"># 设置全局字体</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>


<span class="n">df</span><span class="p">[</span><span class="s1">&#39;inq_date&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">dt</span><span class="o">.</span><span class="n">year</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span><span class="o">.</span><span class="n">sort_index</span><span class="p">()</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s1">&#39;bar&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;监管机构发起问询量年度变化&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;问询量&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">13</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;年份&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">13</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</code></pre></div><p><img loading="lazy" src="img/output_8_1.svg" alt="svg"  />
</p>
<br>
<h3 id="33-问询回复间隔">3.3 问询回复间隔</h3>
<p>从监管机构发起问询与公司回复之间的时间差， 按道理</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df</span><span class="p">[</span><span class="s1">&#39;duration1&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;duration1&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">dt</span><span class="o">.</span><span class="n">days</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/df3.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">sz_mean</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;code&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;A0&#39;</span><span class="p">)]</span><span class="o">.</span><span class="n">duration1</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="n">sh_mean</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;code&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;A6&#39;</span><span class="p">)]</span><span class="o">.</span><span class="n">duration1</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;深市平均回复时间&#39;</span><span class="p">,</span> <span class="n">sz_mean</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;沪市平均回复时间&#39;</span><span class="p">,</span> <span class="n">sh_mean</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">深市平均回复时间 14.203594945719878
沪市平均回复时间 24.311458333333334
</code></pre></div><p>似乎沪市的上市公司回复的更慢</p>
<br>
<h3 id="34-公司回复问询函速度">3.4 公司回复问询函速度</h3>
<p>公司回复问询函的速度是越来越快还是越来越久？</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;inq_date&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">dt</span><span class="o">.</span><span class="n">year</span><span class="p">)[</span><span class="s1">&#39;duration1&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s1">&#39;line&#39;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;公司为回复监管机构问询函所需准备的时间(单位: 天)&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;准备天数&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">13</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;年份&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">13</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</code></pre></div><p><img loading="lazy" src="img/output_13_1.svg" alt="svg"  />

​</p>
<br>
<h3 id="34-文本长度静态对比">3.4 文本长度静态对比</h3>
<p>不考虑时间，比较沪深问询函内容及回复内容文本长度</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df</span><span class="p">[</span><span class="s1">&#39;inq_len&#39;</span><span class="p">]</span> <span class="o">=</span>  <span class="n">df</span><span class="p">[</span><span class="s1">&#39;inq_content&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">len</span><span class="p">()</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;reply_len&#39;</span><span class="p">]</span> <span class="o">=</span>  <span class="n">df</span><span class="p">[</span><span class="s1">&#39;reply_content&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">len</span><span class="p">()</span>


<span class="n">sz_inq_len_mean</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;code&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;A0&#39;</span><span class="p">)]</span><span class="o">.</span><span class="n">inq_len</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="n">sh_inq_len_mean</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;code&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;A6&#39;</span><span class="p">)]</span><span class="o">.</span><span class="n">inq_len</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;深市-监管机构平均问询函内容长度&#39;</span><span class="p">,</span> <span class="n">sz_inq_len_mean</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;沪市-监管机构平均问询函内容长度&#39;</span><span class="p">,</span> <span class="n">sh_inq_len_mean</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;-&#39;</span><span class="o">*</span><span class="mi">40</span><span class="p">,</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>


<span class="n">sz_reply_len_mean</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;code&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;A0&#39;</span><span class="p">)]</span><span class="o">.</span><span class="n">reply_len</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="n">sh_reply_len_mean</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;code&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;A6&#39;</span><span class="p">)]</span><span class="o">.</span><span class="n">reply_len</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;深市公司平均回复长度&#39;</span><span class="p">,</span> <span class="n">sz_reply_len_mean</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;沪市公司平均回复时间&#39;</span><span class="p">,</span> <span class="n">sh_reply_len_mean</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">
深市-监管机构平均问询函内容长度 1941.5452176578785
沪市-监管机构平均问询函内容长度 2037.675310033822
---------------------------------------- 

深市公司平均回复长度 14070.28757080973
沪市公司平均回复时间 17207.44938271604
</code></pre></div><p>似乎监管机构对沪市公司发起的问询内容更长， 而沪市的上市公司对应回应问询的内容也更长。</p>
<br>
<h3 id="35-随时间文本长度变化">3.5 随时间文本长度变化</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;inq_date&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">dt</span><span class="o">.</span><span class="n">year</span><span class="p">)[</span><span class="s1">&#39;inq_len&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s1">&#39;line&#39;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;监管机构问询函内容长度随时间的变化趋势&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;问询函长度&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;年份&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</code></pre></div><p><img loading="lazy" src="img/output_17_1.svg" alt="svg"  />

​</p>
<br>
<h2 id="数据集获取">数据集获取</h2>
<p>数据整理不易，需要的话， <a href="https://mp.weixin.qq.com/s/0NvFFJvkW2T9mTd1h4KxBw">点击链接进入购买页面</a>， 有疑问，加微信372335839， 备注「姓名-学校-专业」</p>
 <br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>数据集 | 3571万条专利申请数据集(1985-2022年)</title>
      <link>https://textdata.cn/blog/2023-04-13-3571w-patent-dataset-in-china-mainland/</link>
      <pubDate>Thu, 13 Apr 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-04-13-3571w-patent-dataset-in-china-mainland/</guid>
      <description>3571万专利申请全量数据(1985-2022年)数据</description>
      <content:encoded><![CDATA[<h2 id="相关推文">相关推文</h2>
<p><a href="https://textdata.cn/blog/2023-04-26-matching-listed-corporate-with-patent-dataset/">从3571w条专利数据集「匹配」上市公司的专利信息</a></p>
<p><a href="https://textdata.cn/blog/2023-11-17-how-handle-mega-csv-that-far-exceed-memory/">推荐 | 如何处理远超电脑内存的csv文件</a></p>
<p><br><br></p>
<p>3571万专利申请全量数据(<strong>1985.01 ~ 2022.5</strong>)数据，解压后整个文件夹大概 20 G。</p>
<p><img loading="lazy" src="img/screen-datasets.png" alt=""  />
</p>
<br>
<p>为了方便各位下载，对数据进行了压缩，压缩后整个文件夹体积大概20G 。gz可以用常见的解压软件解压，如 bandizip、winrar。</p>
<p><img loading="lazy" src="img/screen-datasets2.png" alt=""  />
</p>
<br>
<h2 id="一数据介绍">一、数据介绍</h2>
<h3 id="11-数据集概况">1.1 数据集概况</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">- 数据集名称：省份版知识产权局专利
- 时间跨度：1985.1-2022.5，专利申请总量3571万
- 数据来源：『国家知识产权局』
- 数据整理: 『公众号:大邓和他的Python』
</code></pre></div><p><span style="font-size: 18px;color: green;">1. 付费数据集，100元；加微信 372335839， 备注「姓名-学校-专业」。</span></p>
<p><span style="font-size: 18px;color: green;">2. 数据是虚拟产品，一经售出，不再退还！</span></p>
<p><span style="font-size: 18px;color: green;">3. 大家时间其实都很宝贵，请仔细阅读推文内容， 确认无误再加微信详谈购买事宜 </span></p>
<br>
<h3 id="12-分省统计">1.2 分省统计</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">| 省份(区域)       |  专利数  |
| :---------------| :------ |
| 广东省           | 5728705 |
| 江苏省           | 4879171 |
| 浙江省           | 3706820 |
| 山东省           | 2064446 |
| 北京市           | 2069913 |
| 四川省           | 1159551 |
| 天津市           | 712932  |
| 上海市           | 1548278 |
| 贵州省           | 265512  |
| 陕西省           | 655837  |
| 吉林省           | 232264  |
| 辽宁省           | 637853  |
| 湖北省           | 966384  |
| 山西省           | 233418  |
| 宁夏回族自治区    | 66919   |
| 西藏自治区        | 9911    |
| 广西壮族自治区    | 377658  |
| 江西省           | 519584  |
| 湖南省           | 743828  |
| 黑龙江省         | 357881  |
| 海南省           | 59202   |
| 福建省           | 1046473 |
| 安徽省           | 1342364 |
| 河北省           | 645420  |
| 重庆市           | 592382  |
| 内蒙古自治区      | 133277  |
| 云南省           | 252407  |
| 甘肃省           | 164274  |
| 新疆维吾尔自治区   | 124734  |
| 河南省           | 966477  |
| 青海省           | 34127   |
| 台湾省           | 401555  |
| 香港特别行政区    | 61636   |
| 澳门特别行政区    | 2010    |
| 其他国家         | 2948557 |
</code></pre></div><br>
<h3 id="13-字段">1.3 字段</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"> -  专利公开号
 -  专利名称
 -  专利类型
 -  专利摘要
 -  申请人(自然人、法人；可以是多个主题并列，用;间隔申请人主体)
 -  专利申请号
 -  申请日
 -  申请公布日
 -  授权公布号
 -  授权公布日
 -  申请地址
 -  主权项
 -  发明人
 -  分类号
 -  主分类号
 -  代理机构
 -  分案原申请号
 -  优先权
 -  国际申请
 -  国际公布
 -  代理人
 -  省份或国家代码
 -  法律状态
 -  专利领域
 -  专利学科
 -  多次公布
</code></pre></div><p><br><br></p>
<h2 id="二实验代码">二、实验代码</h2>
<h3 id="21-读取数据">2.1 读取数据</h3>
<p>数据集中的个别csv文件较大，例如 <strong>广东省.csv.gz</strong>体积2.47 G , 解压得到的 <strong>广东省.csv</strong> 10G。 建议直接读取 <em><strong>.csv.gz</strong></em>，这样会节省内存消耗。需要注意每次分析时不要开其他软件，如Word/PPT/Excel/WPS。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;河北省.csv.gz&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">,</span> <span class="n">compression</span><span class="o">=</span><span class="s1">&#39;gzip&#39;</span><span class="p">,</span> <span class="n">low_memory</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="c1">#df = pd.read_csv(&#39;河北省.csv&#39;, encoding=&#39;utf-8&#39;, low_memory=False)</span>

<span class="n">df</span><span class="p">[</span><span class="s1">&#39;申请日&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;申请日&#39;</span><span class="p">])</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p>Run
<img loading="lazy" src="img/df.png" alt=""  />
</p>
<br>
<h3 id="22-记录数">2.2 记录数</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;河北省: &#39;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">))</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">河北省: 645420
</code></pre></div><br>
<h3 id="2-3-覆盖日期">2. 3 覆盖日期</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;申请日&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;申请日&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">1985-01-28 00:00:00
2022-05-24 00:00:00
</code></pre></div><br>
<h3 id="24-字段">2.4 字段</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df</span><span class="o">.</span><span class="n">columns</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">Index([&#39;专利公开号&#39;, &#39;专利名称&#39;, &#39;专利类型&#39;, &#39;专利摘要&#39;, 
&#39;申请人&#39;, &#39;专利申请号&#39;, &#39;申请日&#39;, &#39;申请公布日&#39;, 
&#39;授权公布号&#39;, &#39;授权公布日&#39;, &#39;申请地址&#39;, &#39;主权项&#39;, &#39;发明人&#39;,
&#39;分类号&#39;, &#39;主分类号&#39;, &#39;代理机构&#39;, &#39;分案原申请号&#39;, &#39;优先权&#39;, 
&#39;国际申请&#39;, &#39;国际公布&#39;, &#39;代理人&#39;, &#39;省份或国家代码&#39;,
&#39;法律状态&#39;, &#39;专利领域&#39;, &#39;专利学科&#39;, &#39;多次公布&#39;],
dtype=&#39;object&#39;)
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python">
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">实用新型 361832
发明公开 155084
外观设计 107905
发明授权 20599
</code></pre></div><p><br><br></p>
<h2 id="三查看字段详情">三、查看字段详情</h2>
<p>每个字段都含哪些信息</p>
<h3 id="31-专利类型">3.1 专利类型</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">df[&#39;专利类型&#39;].unique()
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">array([&#39;外观设计&#39;, &#39;实用新型&#39;, &#39;发明公开&#39;, &#39;发明授权&#39;], dtype=object)
专利领域
</code></pre></div><br>
<h3 id="32-发明人">3.2 发明人</h3>
<p>发明人一般是自然人，但是极少数情况也可以是法人。发明人可以是多个自然人，一般以  <code>; </code>间隔</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">df[&#39;发明人&#39;]
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">0                              温绍强
1                              谭红建
2                              梁京京
3                              谭达兴
4                         魏国兴; 陈定祥
                    ...           
5728700                        邓晓明
5728701                        杨峰铭
5728702    赵富荣; 彭新春; 秦何军; 黄领才; 陈立伟
5728703                   周燕莉; 卢建兰
5728704                        曾文华
Name: 发明人, Length: 5728705, dtype: object
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#整个广东省，只有这几个专利是法人发明</span>
<span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;发明人&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="s1">&#39;公司&#39;</span><span class="p">)][[</span><span class="s1">&#39;专利名称&#39;</span><span class="p">,</span> <span class="s1">&#39;发明人&#39;</span><span class="p">]]</span>
</code></pre></div><p><img loading="lazy" src="img/df3.png" alt=""  />
</p>
<br>
<h3 id="33-申请人">3.3 申请人</h3>
<p>注意，申请人可以是自然人、法人、多个(自然人、法人),  一般以  <code>; </code>间隔。我们先直接看 <code>申请人</code></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df</span><span class="p">[</span><span class="s1">&#39;申请人&#39;</span><span class="p">]</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">0                      温绍强
1          台山市国际交通器材配件有限公司
2            深圳市时代设计印务有限公司
3           东莞高端精密电子股份有限公司
4           东莞凤岗嘉安塑胶五金有限公司
                ...       
5728700     佛山肯富来安德里兹泵有限公司
5728701        东莞全方位傢俱有限公司
5728702        中航通飞研究院有限公司
5728703         南方医科大学南方医院
5728704    深圳市金键精密五金制品有限公司
Name: 申请人, Length: 5728705, dtype: object
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;申请人&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="s1">&#39;;&#39;</span><span class="p">)][[</span><span class="s1">&#39;专利名称&#39;</span><span class="p">,</span> <span class="s1">&#39;申请人&#39;</span><span class="p">]]</span>
</code></pre></div><p><img loading="lazy" src="img/df4.png" alt=""  />
</p>
<br>
<h3 id="34-分类号">3.4 分类号</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df</span><span class="p">[</span><span class="s1">&#39;分类号&#39;</span><span class="p">]</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">0                                                 08-06
1                                                 12-16
2                                              B65D6/14
3                                   H01R13/40;H01R13/02
4          B65C9/02;B65C9/40;B65C9/26;B07C5/34;B07C5/36
                               ...                     
5728700                                           15-02
5728701                                           06-03
5728702                                       B64C35/00
5728703                                       A61G7/053
5728704                               F16B5/00;F16B5/10
Name: 分类号, Length: 5728705, dtype: object
</code></pre></div><br>
<h3 id="35-主分类号">3.5 主分类号</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">df[&#39;主分类号&#39;]
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">0              08-06
1              12-16
2           B65D6/14
3          H01R13/40
4           B65C9/02
             ...    
5728700        15-02
5728701        06-03
5728702    B64C35/00
5728703    A61G7/053
5728704     F16B5/00
Name: 主分类号, Length: 5728705, dtype: object
</code></pre></div><br>
<h3 id="36-专利领域">3.6 专利领域</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">df[&#39;专利领域&#39;]
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">0                  工程科技Ⅰ辑
1                  工程科技Ⅱ辑
2                  工程科技Ⅱ辑
3                  工程科技Ⅱ辑
4                  工程科技Ⅱ辑
                ...      
5728700            工程科技Ⅱ辑
5728701            工程科技Ⅰ辑
5728702            工程科技Ⅱ辑
5728703    医药卫生科技; 工程科技Ⅱ辑
5728704            工程科技Ⅱ辑
Name: 专利领域, Length: 5728705, dtype: object
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">df[&#39;专利领域&#39;].unique()
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">array([&#39;工程科技Ⅰ辑&#39;, &#39;工程科技Ⅱ辑&#39;, &#39;农业科技&#39;, &#39;医药卫生科技&#39;, &#39;医药卫生科技; 工程科技Ⅱ辑&#39;, &#39;信息科技&#39;,
       &#39;工程科技Ⅱ辑; 信息科技&#39;, &#39;工程科技Ⅰ辑; 工程科技Ⅱ辑&#39;, &#39;工程科技Ⅱ辑; 工程科技Ⅰ辑&#39;,
       &#39;工程科技Ⅱ辑; 医药卫生科技&#39;, &#39;基础科学&#39;, &#39;社会科学Ⅱ辑&#39;, &#39;基础科学; 信息科技&#39;, &#39;信息科技; 工程科技Ⅰ辑&#39;,
       &#39;工程科技Ⅰ辑; 信息科技&#39;, &#39;基础科学; 工程科技Ⅰ辑&#39;, &#39;工程科技Ⅰ辑; 农业科技&#39;, &#39;工程科技Ⅰ辑; 医药卫生科技&#39;,
       &#39;农业科技; 工程科技Ⅰ辑&#39;, &#39;工程科技Ⅱ辑; 哲学与人文科学&#39;], dtype=object)
</code></pre></div><br>
<h3 id="37-专利学科">3.7 专利学科</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df</span><span class="p">[</span><span class="s1">&#39;专利学科&#39;</span><span class="p">]</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">0                                   轻工业手工业
1                                     汽车工业
2                                工业通用技术及设备
3                                     电力工业
4                                工业通用技术及设备
                        ...               
5728700                               机械工业
5728701                             轻工业手工业
5728702                          航空航天科学与工程
5728703    医药卫生方针政策与法律法规研究; 生物医学工程; 仪器仪表工业
5728704                               机械工业
Name: 专利学科, Length: 5728705, dtype: object
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">array</span><span class="p">([</span><span class="s1">&#39;轻工业手工业&#39;</span><span class="p">,</span> <span class="s1">&#39;汽车工业&#39;</span><span class="p">,</span> <span class="s1">&#39;工业通用技术及设备&#39;</span><span class="p">,</span> <span class="s1">&#39;电力工业&#39;</span><span class="p">,</span> <span class="s1">&#39;园艺&#39;</span><span class="p">,</span> <span class="s1">&#39;机械工业&#39;</span><span class="p">,</span>
       <span class="s1">&#39;医药卫生方针政策与法律法规研究; 中医学&#39;</span><span class="p">,</span> <span class="s1">&#39;医药卫生方针政策与法律法规研究; 生物医学工程; 仪器仪表工业&#39;</span><span class="p">,</span>
       <span class="s1">&#39;金属学及金属工艺&#39;</span><span class="p">,</span> <span class="s1">&#39;电信技术&#39;</span><span class="p">,</span> <span class="s1">&#39;外科学&#39;</span><span class="p">,</span> <span class="s1">&#39;无线电电子学&#39;</span><span class="p">,</span> <span class="s1">&#39;建筑科学与工程&#39;</span><span class="p">,</span> <span class="s1">&#39;船舶工业&#39;</span><span class="p">,</span> <span class="s1">&#39;材料科学&#39;</span><span class="p">,</span>
       <span class="s1">&#39;仪器仪表工业&#39;</span><span class="p">,</span> <span class="s1">&#39;动力工程&#39;</span><span class="p">,</span> <span class="s1">&#39;生物医学工程&#39;</span><span class="p">,</span> <span class="s1">&#39;一般服务业&#39;</span><span class="p">,</span> <span class="s1">&#39;有机化工&#39;</span><span class="p">,</span> <span class="s1">&#39;水产和渔业&#39;</span><span class="p">,</span> <span class="s1">&#39;自动化技术&#39;</span><span class="p">,</span>
       <span class="s1">&#39;有机化工; 无机化工&#39;</span><span class="p">,</span> <span class="s1">&#39;武器工业与军事技术&#39;</span><span class="p">,</span> <span class="s1">&#39;计算机硬件技术&#39;</span><span class="p">,</span> <span class="s1">&#39;工业通用技术及设备; 电信技术&#39;</span><span class="p">,</span>
       <span class="s1">&#39;环境科学与资源利用&#39;</span><span class="p">,</span> <span class="s1">&#39;水利水电工程&#39;</span><span class="p">,</span> <span class="s1">&#39;一般化学工业&#39;</span><span class="p">,</span> <span class="s1">&#39;公路与水路运输&#39;</span><span class="p">,</span> <span class="s1">&#39;有机化工; 无机化工; 矿业工程&#39;</span><span class="p">,</span>
       <span class="s1">&#39;眼科与耳鼻咽喉科&#39;</span><span class="p">,</span> <span class="s1">&#39;口腔科学&#39;</span><span class="p">,</span> <span class="s1">&#39;园艺; 林业&#39;</span><span class="p">,</span> <span class="s1">&#39;新能源&#39;</span><span class="p">,</span> <span class="s1">&#39;无机化工&#39;</span><span class="p">,</span> <span class="s1">&#39;无机化工; 有机化工&#39;</span><span class="p">,</span>
       <span class="s1">&#39;临床医学; 生物医学工程&#39;</span><span class="p">,</span> <span class="s1">&#39;有机化工; 无机化工; 工业通用技术及设备&#39;</span><span class="p">,</span> <span class="s1">&#39;生物医学工程; 仪器仪表工业&#39;</span><span class="p">,</span> <span class="s1">&#39;化学&#39;</span><span class="p">,</span>
       <span class="s1">&#39;航空航天科学与工程&#39;</span><span class="p">,</span> <span class="s1">&#39;畜牧与动物医学&#39;</span><span class="p">,</span> <span class="s1">&#39;农业工程; 畜牧与动物医学&#39;</span><span class="p">,</span> <span class="s1">&#39;临床医学&#39;</span><span class="p">,</span> <span class="s1">&#39;轻工业手工业; 仪器仪表工业&#39;</span><span class="p">,</span>
       <span class="s1">&#39;计算机软件及计算机应用&#39;</span><span class="p">,</span> <span class="s1">&#39;蚕蜂与野生动物保护; 农业工程&#39;</span><span class="p">,</span> <span class="s1">&#39;农业工程&#39;</span><span class="p">,</span> <span class="s1">&#39;中医学&#39;</span><span class="p">,</span> <span class="s1">&#39;有机化工; 矿业工程&#39;</span><span class="p">,</span>
       <span class="s1">&#39;建筑科学与工程; 环境科学与资源利用&#39;</span><span class="p">,</span> <span class="s1">&#39;仪器仪表工业; 医药卫生方针政策与法律法规研究; 生物医学工程&#39;</span><span class="p">,</span>
       <span class="s1">&#39;建筑科学与工程; 公路与水路运输&#39;</span><span class="p">,</span> <span class="s1">&#39;矿业工程&#39;</span><span class="p">,</span> <span class="s1">&#39;药学&#39;</span><span class="p">,</span> <span class="s1">&#39;安全科学与灾害防治&#39;</span><span class="p">,</span> <span class="s1">&#39;农艺学&#39;</span><span class="p">,</span> <span class="s1">&#39;化学; 无机化工&#39;</span><span class="p">,</span>
       <span class="s1">&#39;冶金工业&#39;</span><span class="p">,</span> <span class="s1">&#39;核科学技术&#39;</span><span class="p">,</span> <span class="s1">&#39;铁路运输; 公路与水路运输&#39;</span><span class="p">,</span> <span class="s1">&#39;泌尿科学&#39;</span><span class="p">,</span> <span class="s1">&#39;外科学; 生物医学工程&#39;</span><span class="p">,</span>
       <span class="s1">&#39;蚕蜂与野生动物保护&#39;</span><span class="p">,</span> <span class="s1">&#39;医药卫生方针政策与法律法规研究&#39;</span><span class="p">,</span> <span class="s1">&#39;物理学&#39;</span><span class="p">,</span> <span class="s1">&#39;工业通用技术及设备; 机械工业&#39;</span><span class="p">,</span> <span class="s1">&#39;铁路运输&#39;</span><span class="p">,</span>
       <span class="s1">&#39;体育&#39;</span><span class="p">,</span> <span class="s1">&#39;预防医学与卫生学; 生物医学工程&#39;</span><span class="p">,</span> <span class="s1">&#39;物理学; 无线电电子学&#39;</span><span class="p">,</span> <span class="s1">&#39;预防医学与卫生学&#39;</span><span class="p">,</span> <span class="s1">&#39;植物保护&#39;</span><span class="p">,</span>
       <span class="s1">&#39;呼吸系统疾病&#39;</span><span class="p">,</span> <span class="s1">&#39;无线电电子学; 轻工业手工业&#39;</span><span class="p">,</span> <span class="s1">&#39;畜牧与动物医学; 水产和渔业&#39;</span><span class="p">,</span> <span class="s1">&#39;气象学&#39;</span><span class="p">,</span> <span class="s1">&#39;特种医学&#39;</span><span class="p">,</span>
       <span class="s1">&#39;消化系统疾病&#39;</span><span class="p">,</span> <span class="s1">&#39;无机化工; 有机化工; 工业通用技术及设备&#39;</span><span class="p">,</span> <span class="s1">&#39;农业基础科学&#39;</span><span class="p">,</span> <span class="s1">&#39;金属学及金属工艺; 轻工业手工业&#39;</span><span class="p">,</span>
       <span class="s1">&#39;水产和渔业; 畜牧与动物医学&#39;</span><span class="p">,</span> <span class="s1">&#39;燃料化工&#39;</span><span class="p">,</span> <span class="s1">&#39;林业&#39;</span><span class="p">,</span> <span class="s1">&#39;生物学&#39;</span><span class="p">,</span> <span class="s1">&#39;轻工业手工业; 出版&#39;</span><span class="p">,</span>
       <span class="s1">&#39;医药卫生方针政策与法律法规研究; 生物医学工程&#39;</span><span class="p">,</span> <span class="s1">&#39;有机化工; 轻工业手工业&#39;</span><span class="p">,</span> <span class="s1">&#39;公路与水路运输; 矿业工程&#39;</span><span class="p">,</span>
       <span class="s1">&#39;轻工业手工业; 计算机硬件技术&#39;</span><span class="p">,</span> <span class="s1">&#39;地质学&#39;</span><span class="p">,</span> <span class="s1">&#39;海洋学&#39;</span><span class="p">,</span> <span class="s1">&#39;地质学; 石油天然气工业&#39;</span><span class="p">,</span> <span class="s1">&#39;公路与水路运输; 铁路运输&#39;</span><span class="p">,</span>
       <span class="s1">&#39;有机化工; 化学&#39;</span><span class="p">,</span> <span class="s1">&#39;特种医学; 生物医学工程&#39;</span><span class="p">,</span> <span class="s1">&#39;自然地理学和测绘学&#39;</span><span class="p">,</span> <span class="s1">&#39;轻工业手工业; 林业&#39;</span><span class="p">,</span> <span class="s1">&#39;中药学&#39;</span><span class="p">,</span>
       <span class="s1">&#39;一般化学工业; 轻工业手工业&#39;</span><span class="p">,</span> <span class="s1">&#39;妇产科学&#39;</span><span class="p">,</span> <span class="s1">&#39;中西医结合&#39;</span><span class="p">,</span> <span class="s1">&#39;临床医学; 特种医学&#39;</span><span class="p">,</span> <span class="s1">&#39;燃料化工; 轻工业手工业&#39;</span><span class="p">,</span>
       <span class="s1">&#39;地球物理学&#39;</span><span class="p">,</span> <span class="s1">&#39;化学; 有机化工&#39;</span><span class="p">,</span> <span class="s1">&#39;公路与水路运输; 建筑科学与工程&#39;</span><span class="p">,</span> <span class="s1">&#39;轻工业手工业; 水产和渔业&#39;</span><span class="p">,</span>
       <span class="s1">&#39;石油天然气工业&#39;</span><span class="p">,</span> <span class="s1">&#39;眼科与耳鼻咽喉科; 口腔科学&#39;</span><span class="p">,</span> <span class="s1">&#39;肿瘤学&#39;</span><span class="p">,</span> <span class="s1">&#39;环境科学与资源利用; 建筑科学与工程&#39;</span><span class="p">,</span> <span class="s1">&#39;基础医学&#39;</span><span class="p">,</span>
       <span class="s1">&#39;急救医学&#39;</span><span class="p">,</span> <span class="s1">&#39;仪器仪表工业; 生物医学工程&#39;</span><span class="p">,</span> <span class="s1">&#39;心血管系统疾病&#39;</span><span class="p">,</span> <span class="s1">&#39;互联网技术&#39;</span><span class="p">,</span> <span class="s1">&#39;矿业工程; 公路与水路运输&#39;</span><span class="p">,</span>
       <span class="s1">&#39;农作物&#39;</span><span class="p">,</span> <span class="s1">&#39;公路与水路运输; 水利水电工程&#39;</span><span class="p">,</span> <span class="s1">&#39;水利水电工程; 电力工业&#39;</span><span class="p">,</span> <span class="s1">&#39;畜牧与动物医学; 农业工程&#39;</span><span class="p">,</span>
       <span class="s1">&#39;材料科学; 生物医学工程&#39;</span><span class="p">,</span> <span class="s1">&#39;安全科学与灾害防治; 建筑科学与工程&#39;</span><span class="p">,</span> <span class="s1">&#39;植物保护; 农艺学&#39;</span><span class="p">,</span>
       <span class="s1">&#39;轻工业手工业; 一般化学工业&#39;</span><span class="p">,</span> <span class="s1">&#39;消化系统疾病; 外科学&#39;</span><span class="p">,</span> <span class="s1">&#39;水产和渔业; 轻工业手工业&#39;</span><span class="p">,</span>
       <span class="s1">&#39;建筑科学与工程; 安全科学与灾害防治&#39;</span><span class="p">,</span> <span class="s1">&#39;农作物; 园艺&#39;</span><span class="p">,</span> <span class="s1">&#39;急救医学; 生物医学工程&#39;</span><span class="p">,</span> <span class="s1">&#39;水利水电工程; 公路与水路运输&#39;</span><span class="p">,</span>
       <span class="s1">&#39;皮肤病与性病&#39;</span><span class="p">,</span> <span class="s1">&#39;工业通用技术及设备; 戏剧电影与电视艺术&#39;</span><span class="p">,</span> <span class="s1">&#39;眼科与耳鼻咽喉科; 生物医学工程&#39;</span><span class="p">,</span> <span class="s1">&#39;人才学与劳动科学&#39;</span><span class="p">,</span>
       <span class="s1">&#39;外科学; 口腔科学; 生物医学工程&#39;</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">object</span><span class="p">)</span>
</code></pre></div><p><br><br></p>
<h2 id="四可视化">四、可视化</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="c1">#为减轻内存压力，可以选择需要的字段读取</span>
<span class="n">cols</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;申请日&#39;</span><span class="p">,</span> <span class="s1">&#39;授权公布日&#39;</span><span class="p">]</span>

<span class="c1">#读取数据</span>
<span class="n">guangdong_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;广东省.csv.gz&#39;</span><span class="p">,</span> <span class="n">compression</span><span class="o">=</span><span class="s1">&#39;gzip&#39;</span><span class="p">,</span> <span class="n">usecols</span><span class="o">=</span><span class="n">cols</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">,</span> <span class="n">low_memory</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">jiangsu_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;江苏省.csv.gz&#39;</span><span class="p">,</span> <span class="n">compression</span><span class="o">=</span><span class="s1">&#39;gzip&#39;</span><span class="p">,</span> <span class="n">usecols</span><span class="o">=</span><span class="n">cols</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">,</span> <span class="n">low_memory</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">shandong_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;山东省.csv.gz&#39;</span><span class="p">,</span> <span class="n">compression</span><span class="o">=</span><span class="s1">&#39;gzip&#39;</span><span class="p">,</span> <span class="n">usecols</span><span class="o">=</span><span class="n">cols</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">,</span> <span class="n">low_memory</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">zhejiang_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;浙江省.csv.gz&#39;</span><span class="p">,</span> <span class="n">compression</span><span class="o">=</span><span class="s1">&#39;gzip&#39;</span><span class="p">,</span> <span class="n">usecols</span><span class="o">=</span><span class="n">cols</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">,</span> <span class="n">low_memory</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">beijing_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;北京市.csv.gz&#39;</span><span class="p">,</span> <span class="n">compression</span><span class="o">=</span><span class="s1">&#39;gzip&#39;</span><span class="p">,</span> <span class="n">usecols</span><span class="o">=</span><span class="n">cols</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">,</span> <span class="n">low_memory</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">shanghai_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;上海市.csv.gz&#39;</span><span class="p">,</span> <span class="n">compression</span><span class="o">=</span><span class="s1">&#39;gzip&#39;</span><span class="p">,</span> <span class="n">usecols</span><span class="o">=</span><span class="n">cols</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">,</span> <span class="n">low_memory</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1">#显示前5行</span>
<span class="n">shanghai_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/df2.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">matplotlib</span>
<span class="kn">import</span> <span class="nn">matplotlib_inline</span>
<span class="n">matplotlib_inline</span><span class="o">.</span><span class="n">backend_inline</span><span class="o">.</span><span class="n">set_matplotlib_formats</span><span class="p">(</span><span class="s1">&#39;png&#39;</span><span class="p">,</span> <span class="s1">&#39;svg&#39;</span><span class="p">)</span>
<span class="kn">import</span> <span class="nn">scienceplots</span>
<span class="kn">import</span> <span class="nn">platform</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">([</span><span class="s1">&#39;science&#39;</span><span class="p">,</span> <span class="s1">&#39;no-latex&#39;</span><span class="p">,</span> <span class="s1">&#39;cjk-sc-font&#39;</span><span class="p">])</span>
<span class="n">system</span> <span class="o">=</span> <span class="n">platform</span><span class="o">.</span><span class="n">system</span><span class="p">()</span>  <span class="c1"># 获取操作系统类型</span>

<span class="k">if</span> <span class="n">system</span> <span class="o">==</span> <span class="s1">&#39;Windows&#39;</span><span class="p">:</span>
    <span class="n">font</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;family&#39;</span><span class="p">:</span> <span class="s1">&#39;SimHei&#39;</span><span class="p">}</span>
<span class="k">elif</span> <span class="n">system</span> <span class="o">==</span> <span class="s1">&#39;Darwin&#39;</span><span class="p">:</span>
    <span class="n">font</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;family&#39;</span><span class="p">:</span> <span class="s1">&#39;Arial Unicode MS&#39;</span><span class="p">}</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">font</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;family&#39;</span><span class="p">:</span> <span class="s1">&#39;sans-serif&#39;</span><span class="p">}</span>
<span class="n">matplotlib</span><span class="o">.</span><span class="n">rc</span><span class="p">(</span><span class="s1">&#39;font&#39;</span><span class="p">,</span> <span class="o">**</span><span class="n">font</span><span class="p">)</span>  <span class="c1"># 设置全局字体</span>
    
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">years</span> <span class="o">=</span> <span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2000</span><span class="p">,</span> <span class="mi">2020</span><span class="p">)]</span>


<span class="n">guangdong_df</span><span class="p">[</span><span class="s1">&#39;申请日&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">slice</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="n">years</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;广东&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">jiangsu_df</span><span class="p">[</span><span class="s1">&#39;申请日&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">slice</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="n">years</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;江苏&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">zhejiang_df</span><span class="p">[</span><span class="s1">&#39;申请日&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">slice</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="n">years</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;浙江&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">shandong_df</span><span class="p">[</span><span class="s1">&#39;申请日&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">slice</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="n">years</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;山东&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">beijing_df</span><span class="p">[</span><span class="s1">&#39;申请日&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">slice</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="n">years</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;北京&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">shanghai_df</span><span class="p">[</span><span class="s1">&#39;申请日&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">slice</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="n">years</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;上海&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">hebei_df</span><span class="p">[</span><span class="s1">&#39;申请日&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">slice</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="n">years</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;河北&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>



<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;七省市专利申请量(2000年-2019年)&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;年份(按申请日统计)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;申请量&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper right&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>    
</code></pre></div><p><img loading="lazy" src="img/output_7_0.png" alt=""  />
</p>
<ul>
<li>
<p>2012年， 申请量开始下降， 直至2014年，触底反弹。这个时期国内外宏观经济发生了什么？</p>
</li>
<li>
<p>不考虑人口规模， 在专利申请量可以看出广东、江苏、浙江体量还是比北京、上海、河北要高的。</p>
</li>
<li>
<p>2015年开始， 广东触底反弹后， 拉开了与江苏、浙江的体量。</p>
</li>
</ul>
<p><br><br></p>
<h2 id="五获取数据">五、获取数据</h2>
<p><span style="font-size: 18px;color: green;">1. 付费数据集，100元；加微信 372335839， 备注「姓名-学校-专业」。</span></p>
<p><span style="font-size: 18px;color: green;">2. 数据是虚拟产品，一经售出，不再退还！</span></p>
<p><span style="font-size: 18px;color: green;">3. 大家时间其实都很宝贵，请仔细阅读推文内容， 确认无误再加微信详谈购买事宜 </span></p>
<p><br><br></p>
<h2 id="六相关文献">六、相关文献</h2>
<p>使用专利数据做研究的文献</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">[1]Bellstam, Gustaf, Sanjai Bhagat, and J. Anthony Cookson. &#34;A text-based analysis of corporate innovation.&#34; _Management Science_ 67, no. 7 (2021): 4004-4031.
[2]Arts, Sam, Bruno Cassiman, and Jianan Hou. &#34;Position and Differentiation of Firms in Technology Space.&#34; Management Science (2023).
</code></pre></div><p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>词向量(付费) | 使用MD&amp;A2001-2022语料训练Word2Vec模型</title>
      <link>https://textdata.cn/blog/2023-03-24-load-w2v-and-expand-your-concpet-dicitonary/</link>
      <pubDate>Fri, 24 Mar 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-03-24-load-w2v-and-expand-your-concpet-dicitonary/</guid>
      <description>&lt;h2 id=&#34;相关内容&#34;&gt;相关内容&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/the_text_analysis_list_about_ms/&#34;&gt;LIST | 社科(经管)文本挖掘文献汇总&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/text_analysis_code_list_about_ms/&#34;&gt;LIST | 文本分析代码汇总&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/datasets_available_for_management_science/&#34;&gt;LIST | 可供社科(经管)领域使用的数据集&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/management_python_course/&#34;&gt;Python实证指标构建与文本分析&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/2023-11-20-word2vec-by-year-by-province/&#34;&gt;使用3751w专利申请数据集按年份(按省份)训练词向量&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/2023-11-10-training-word2vec-model-using-china-3751w-patent-application-dataset/&#34;&gt;预训练模型 | 使用1000w专利摘要训练word2vec模型，可用于开发词典&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;相关文献&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;[0]刘景江,郑畅然,洪永淼.机器学习如何赋能管理学研究？——国内外前沿综述和未来展望[J].管理世界,2023,39(09):191-216.
[1]冉雅璇,李志强,刘佳妮,张逸石.大数据时代下社会科学研究方法的拓展——基于词嵌入技术的文本分析的应用[J].南开管理评论:1-27.
[3]胡楠,薛付婧,王昊楠.管理者短视主义影响企业长期投资吗？——基于文本分析和机器学习[J].管理世界,2021,37(05):139-156+11+19-21.
[4]Kai Li, Feng Mai, Rui Shen, Xinyan Yan, Measuring Corporate Culture Using Machine Learning, *The Review of Financial Studies*,2020
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;一训练&#34;&gt;一、训练&lt;/h2&gt;
&lt;h3 id=&#34;11-导入mda数据&#34;&gt;1.1 导入mda数据&lt;/h3&gt;
&lt;p&gt;读取 &lt;a href=&#34;https://textdata.cn/blog/2023-03-23-china-a-share-market-dataset-mda-from-01-to-21/&#34;&gt;&lt;strong&gt;数据集 | 2001-2022年A股上市公司年报&amp;amp;管理层讨论与分析&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pandas&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pd&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read_excel&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;mda01-22.csv.gz&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;compression&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;gzip&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;c1&#34;&gt;#gz解压后读取csv&lt;/span&gt;
&lt;span class=&#34;c1&#34;&gt;#df = pd.read_excel(&amp;#39;mda01-22.csv&amp;#39;)&lt;/span&gt;

&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;head&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;55439
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/df.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;12-构造语料&#34;&gt;1.2 构造语料&lt;/h3&gt;
&lt;p&gt;从 &lt;strong&gt;mda01-22.xlsx&lt;/strong&gt; 数据中抽取出所有文本，写入到 &lt;strong&gt;mda01-22.txt&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;k&#34;&gt;with&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;open&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;mda01-22.txt&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;a+&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;encoding&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;utf-8&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;text&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;join&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;text&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;write&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h3 id=&#34;13-配置cntext环境&#34;&gt;1.3 配置cntext环境&lt;/h3&gt;
&lt;p&gt;使用2.1.1版本 cntext 库(该版本暂不开源，需付费购买)。 将得到的 &lt;strong&gt;cntext-2.1.1-py3-none-any.whl&lt;/strong&gt; 文件放置于电脑桌面，  win系统打开&lt;strong&gt;cmd&lt;/strong&gt;(Mac打开terminal)， 输入如下命令(将工作环境切换至桌面)&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;cd desktop
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;个别Win用户如无效，试试&lt;code&gt;cd Desktop&lt;/code&gt; 。&lt;/p&gt;
&lt;p&gt;继续在cmd (terminal) 中执行如下命令安装cntext2.1.1&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;pip3 install distinctiveness
pip3 install cntext-2.1.1-py3-none-any.whl 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h3 id=&#34;14-训练word2vec&#34;&gt;1.4 训练word2vec&lt;/h3&gt;
&lt;p&gt;设置模型参数配置&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;mda01-22 使用2001-2022年度mda数据训练&lt;/li&gt;
&lt;li&gt;200 嵌入的维度数，即每个词的向量长度是200&lt;/li&gt;
&lt;li&gt;6 词语上下文的窗口是6&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;o&#34;&gt;%%&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;time&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;#程序结束后，可查看总的运行时间&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;cntext&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;ct&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;w2v&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ct&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;W2VModel&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;corpus_file&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;mda01-22.txt&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;w2v&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;train&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;vector_size&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;200&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;window_size&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;6&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;min_count&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;6&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;save_dir&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;Word2Vec&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;Building prefix dict from the default dictionary ...
Start Preprocessing Corpus...
Dumping model to file cache /var/folders/y0/4gqxky0s2t94x1c1qhlwr6100000gn/T/jieba.cache
Loading model cost 0.278 seconds.
Prefix dict has been built successfully.
Start Training! This may take a while. Please be patient...

Training word2vec model took 3532 seconds

Note: The Word2Vec model has been saved to output/Word2Vec

CPU times: user 1h 30min 45s, sys: 30.1 s, total: 1h 31min 15s
Wall time: 58min 57s
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;经过不到两个小时时间， 训练出的中国A股市场词向量模型(如下截图)，词汇量 914058， 模型文件 1.49G。模型可广泛用于经济管理等领域概念(情感)词典的构建或扩展。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;mda01-22.200.6.bin&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;mda01-22.200.6.bin.syn1neg.npy&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;mda01-22.200.6.bin.wv.vectors.npy&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/pretained-screen.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;为什么这样确定200和6，可以看这篇 &lt;a href=&#34;https://textdata.cn/blog/2023-03-15-39faq-about-word-embeddings-for-social-science&#34;&gt;词嵌入技术在社会科学领域进行数据挖掘常见39个FAQ汇总&lt;/a&gt;&lt;/p&gt;
&lt;br&gt;
&lt;br&gt;
&lt;h2 id=&#34;二导入模型&#34;&gt;二、导入模型&lt;/h2&gt;
&lt;p&gt;需要用到两个自定义函数load_w2v、expand_dictionary，源代码太长，为了提高阅读体验， 放在文末。大家记得用这两个函数前一定要先导入。&lt;a href=&#34;mda_pretained_model_code.ipynb&#34;&gt;&lt;strong&gt;点击代码&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;c1&#34;&gt;#先导入load_w2v、expand_dictionary函数源代码&lt;/span&gt;


&lt;span class=&#34;c1&#34;&gt;#读取模型文件&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;w2v_model&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;load_w2v&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;w2v_path&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;Word2Vec/mda01-22.200.6.bin&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;w2v_model&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Loading word2vec model...
&amp;lt;gensim.models.word2vec.Word2Vec at 0x310dd9990&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;br&gt;
&lt;h2 id=&#34;注意&#34;&gt;注意&lt;/h2&gt;
&lt;p&gt;之前购买过mda01-22.100.6.bin的可以留意下， &amp;lt;gensim.models.word2vec.Word2Vec&amp;gt;和&amp;lt;gensim.models.keyedvectors.KeyedVectors&amp;gt;
是有区别的。&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h3 id=&#34;三w2v_model的使用&#34;&gt;三、w2v_model的使用&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;查看词汇量&lt;/li&gt;
&lt;li&gt;查询某词向量&lt;/li&gt;
&lt;li&gt;查看多个词的均值向量&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;更多内容，建议查看下gensim库的文档&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;c1&#34;&gt;#词汇量&lt;/span&gt;
&lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;w2v_model&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;index_to_key&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;914058  
&lt;/code&gt;&lt;/pre&gt;
&lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;c1&#34;&gt;#查询某词的词向量&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;w2v_model&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;get_vector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;创新&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;array([-1.36441350e-01, -2.02002168e+00, -1.49168205e+00,  2.65202689e+00,
        1.49721682e+00,  2.14851022e+00, -1.54925853e-01, -2.25241160e+00,
       -3.58773202e-01,  1.54530525e+00, -7.62950361e-01, -9.77181852e-01,
        6.70365512e-01, -3.20203233e+00,  3.18079638e+00,  1.66510820e+00,
        9.80131567e-01,  1.62199986e+00,  1.80585206e+00,  4.08179426e+00,
       -1.26518166e+00,  3.75929743e-01,  5.72038591e-01,  1.16134119e+00,
        2.55617023e+00, -2.25110960e+00, -2.61538339e+00, -5.71992218e-01,
        8.70356798e-01, -1.85045290e+00, -2.85597444e-01, -9.15628672e-01,
       -2.03667688e+00,  2.11716801e-01,  2.94088912e+00, -2.32688546e+00,
        2.20858502e+00,  8.81347775e-01, -7.99135566e-01, -8.61206651e-01,
       -4.45446587e+00, -1.73757005e+00, -3.36678886e+00, -2.82611530e-02,
       -1.62726247e+00, -8.49750221e-01,  4.13731128e-01, -1.62519825e+00,
        3.03865957e+00, -1.39746085e-01,  8.22233260e-01, -7.97697455e-02,
        1.72468078e+00,  2.94929433e+00,  9.72453177e-01, -1.12741642e-01,
        8.18425417e-01, -9.05264139e-01,  2.61516261e+00,  8.02830994e-01,
        2.40420485e+00,  8.85799348e-01, -1.08665645e+00,  8.21912348e-01,
       -4.39456075e-01, -2.57663131e+00,  2.38062453e+00, -4.58515882e-01,
        2.12767506e+00, -2.01356173e-01,  2.71096081e-01,  9.51708496e-01,
       -3.05705309e+00, -6.06385887e-01, -1.38406023e-01,  2.36809158e+00,
       -2.49158549e+00,  2.71105647e+00, -3.07211792e-03,  1.04273570e+00,
        1.44201803e+00, -5.65704823e-01,  2.85488725e-01,  1.43495277e-01,
       -1.39421299e-01,  9.24086392e-01,  4.25374925e-01, -1.56690669e+00,
        1.67641795e+00, -1.03729677e+00, -1.45472065e-01, -2.11022258e+00,
       -1.81541741e+00, -8.66766050e-02,  8.72350857e-02,  1.17173791e+00,
       -3.07721123e-02,  5.84330797e-01,  1.47265148e+00, -1.76913440e+00,
       -8.48391712e-01, -3.25056529e+00,  7.14846313e-01, -2.98076987e-01,
        1.13966620e+00, -1.42698896e+00,  6.93505168e-01, -2.04717040e+00,
       -1.53559577e+00,  1.01942134e+00, -1.58283603e+00,  9.08654630e-01,
       -1.90529859e+00, -9.43309963e-01,  4.12964225e-01, -2.50713086e+00,
       -4.24056143e-01, -4.10613680e+00,  3.60615468e+00, -4.19765860e-01,
       -2.41174579e+00,  6.80675328e-01,  2.99834704e+00,  1.05610855e-01,
       -7.84325838e-01,  3.24065971e+00, -1.85072863e+00, -2.12448812e+00,
       -2.83468294e+00, -5.77759802e-01, -3.13433480e+00, -6.91670418e-01,
        2.99401569e+00, -5.16145706e-01,  9.09552336e-01, -5.52680910e-01,
       -2.88360894e-01,  1.11991334e+00, -1.11737549e+00,  1.15479147e+00,
       -4.63319182e-01,  1.38351321e+00, -3.02179503e+00,  1.24334955e+00,
        1.93393975e-01, -8.27962995e-01, -2.37227559e+00, -9.26931739e-01,
        6.72517180e-01,  1.27736795e+00,  1.98695862e+00,  1.41960573e+00,
       -3.73892736e+00, -3.14201683e-01, -7.19093859e-01,  1.86080355e-02,
       -2.68105698e+00,  1.04344964e+00,  9.46133554e-01, -2.06151366e+00,
       -2.84214950e+00,  1.17004764e+00,  1.24577022e+00, -1.10806060e+00,
        9.93207514e-01,  8.46789181e-01, -3.09691691e+00,  2.12616014e+00,
       -1.49274826e+00, -1.53214395e+00, -9.95470941e-01,  1.23463202e+00,
       -2.18907285e+00, -4.94913310e-01,  2.80939412e+00,  1.68149090e+00,
        1.48991072e+00,  3.83729649e+00,  4.72325265e-01,  1.37606680e+00,
        2.14257884e+00,  3.18186909e-01,  5.98093605e+00,  1.46744043e-01,
       -2.37729326e-01,  1.20463884e+00, -1.55812174e-01, -5.03088772e-01,
        4.53981996e-01,  1.95544350e+00, -2.32564354e+00, -4.09389853e-01,
        1.89125270e-01,  2.62835431e+00,  9.81123984e-01, -9.51041043e-01,
       -1.14294410e-01,  1.10983588e-01,  9.30419266e-02, -9.84693542e-02],
      dtype=float32)
&lt;/code&gt;&lt;/pre&gt;
&lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;c1&#34;&gt;#查询多个词的词向量&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;w2v_model&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;get_mean_vector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;([&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;创新&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;研发&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Ruj&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;array([ 0.03019853, -0.01928307, -0.05371316,  0.00053774,  0.02516318,
        0.10103251, -0.03914721, -0.08307559,  0.00444389,  0.09456791,
       -0.05761364, -0.03459097,  0.04394419, -0.10181106,  0.1418381 ,
        0.05334964,  0.01820264,  0.01493831,  0.01626587,  0.17402864,
       -0.02859601,  0.04538149,  0.03768233,  0.05431981,  0.15405464,
       -0.03632693, -0.08566202, -0.00595666,  0.08378439, -0.11071078,
       -0.05904576, -0.06451955, -0.1076955 ,  0.05141645,  0.11710279,
       -0.09403889,  0.08633652, -0.06743232,  0.00328483,  0.01589498,
       -0.11226317, -0.05367877, -0.057222  , -0.00685401, -0.04531868,
       -0.02090884,  0.01426806, -0.04787309,  0.1325518 , -0.00498158,
        0.01912023, -0.02292867,  0.08855374,  0.07697155,  0.01407153,
       -0.02378988,  0.03745927,  0.00889686,  0.12555045,  0.04007044,
        0.06247196,  0.04912657, -0.06158784,  0.06346396,  0.00197599,
       -0.04995281,  0.05125345, -0.01584197,  0.07572784,  0.02580263,
       -0.02904062, -0.0008835 , -0.08365948, -0.05539802, -0.07523517,
        0.04622741, -0.12007375,  0.05453204, -0.02054051,  0.02937108,
        0.10272598, -0.0089594 ,  0.05172383,  0.00588922, -0.0010917 ,
        0.02603476, -0.01580217, -0.07810815,  0.06964722, -0.04709972,
       -0.0316673 , -0.05055645, -0.05096703,  0.02772727, -0.03495743,
        0.09567484, -0.0071935 , -0.01266821,  0.00074132, -0.07593331,
       -0.02928162, -0.12574387,  0.02437552, -0.0228716 , -0.03047204,
       -0.03948782,  0.07722469, -0.07440004, -0.00951135,  0.05531401,
       -0.03240326,  0.00389662, -0.05632257, -0.05030375,  0.02883579,
       -0.06157173,  0.00584065, -0.16594191,  0.1108149 , -0.00243916,
       -0.09964953,  0.02029083,  0.03522225, -0.01167114, -0.04048527,
        0.08301719, -0.04682562, -0.0714631 , -0.07355815, -0.0496731 ,
       -0.05303175, -0.03625978,  0.06879813, -0.09117774,  0.0323513 ,
       -0.01808765, -0.01746182,  0.02472609, -0.00873791, -0.00951474,
       -0.02176155,  0.02394484, -0.07035318,  0.10963078,  0.01004294,
       -0.02269555, -0.09929934, -0.02897175,  0.02157164,  0.05608977,
        0.09083252, -0.00525982, -0.09866816, -0.02736895, -0.02923711,
        0.05582205, -0.04462272,  0.01932517,  0.04468061,  0.00317996,
       -0.04182415,  0.03061792,  0.04278665,  0.02939183,  0.03475334,
       -0.00898206, -0.08902986,  0.08294971, -0.00942507, -0.02125597,
       -0.01008157,  0.04477865, -0.08366893, -0.00074587,  0.08328778,
        0.02653155,  0.04581301,  0.10532658, -0.04637942,  0.04722971,
        0.06853952, -0.00235328,  0.18312256, -0.0457427 ,  0.00874868,
        0.08945092, -0.01135547, -0.04203002,  0.02408407,  0.0594779 ,
       -0.05467811,  0.01946783,  0.07095537,  0.04226222, -0.0018304 ,
       -0.00086302,  0.04624099,  0.01009499,  0.04783599,  0.02535392],
      dtype=float32)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;有了每个词或者概念的向量，可以结合cntext旧版本单语言模型内的态度偏见的度量。&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;四扩展词典&#34;&gt;四、扩展词典&lt;/h2&gt;
&lt;p&gt;做词典法的文本分析，最重要的是有自己的领域词典。之前受限于技术难度，文科生的我也一直在用形容词的通用情感词典。现在依托word2vec技术， 可以加速人工构建的准确率和效率。&lt;/p&gt;
&lt;p&gt;下面是在 mda01-22.200.6.bin 上做的词典扩展测试，函数expand_dictionary会根据种子词选取最准确的topn个词。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;c1&#34;&gt;#短视主义词  实验&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;expand_dictionary&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;w2v_model&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
                  &lt;span class=&#34;n&#34;&gt;seedwords&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;抓紧&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;立刻&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;月底&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;年底&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;年终&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;争取&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;力争&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;
                  &lt;span class=&#34;n&#34;&gt;topn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;30&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[&#39;抓紧&#39;,
 &#39;立刻&#39;,
 &#39;月底&#39;,
 &#39;年底&#39;,
 &#39;年终&#39;,
 &#39;争取&#39;,
 &#39;力争&#39;,
 &#39;争取&#39;,
 &#39;力争&#39;,
 &#39;年底&#39;,
 &#39;月底&#39;,
 &#39;3月底&#39;,
 &#39;尽快&#39;,
 &#39;上半年&#39;,
 &#39;努力争取&#39;,
 &#39;年内实现&#39;,
 &#39;抓紧&#39;,
 &#39;工作争取&#39;,
 &#39;尽早&#39;,
 &#39;6月底&#39;,
 &#39;工作力争&#39;,
 &#39;7月份&#39;,
 &#39;年底完成&#39;,
 &#39;确保&#39;,
 &#39;早日&#39;,
 &#39;有望&#39;,
 &#39;全力&#39;,
 &#39;创造条件&#39;,
 &#39;3月份&#39;,
 &#39;加紧&#39;,
 &#39;力争实现&#39;,
 &#39;力争今年&#39;,
 &#39;月底前&#39;,
 &#39;10月底&#39;,
 &#39;4月份&#39;,
 &#39;继续&#39;,
 &#39;月初&#39;]
&lt;/code&gt;&lt;/pre&gt;
&lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;expand_dictionary&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;w2v_model&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
                  &lt;span class=&#34;n&#34;&gt;seedwords&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;团结&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;拼搏&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;  &lt;span class=&#34;s1&#34;&gt;&amp;#39;克服&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;  &lt;span class=&#34;s1&#34;&gt;&amp;#39;勇攀高峰&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;  &lt;span class=&#34;s1&#34;&gt;&amp;#39;友善&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;  &lt;span class=&#34;s1&#34;&gt;&amp;#39;进取&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;
                  &lt;span class=&#34;n&#34;&gt;topn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;30&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[&#39;团结&#39;,
 &#39;拼搏&#39;,
 &#39;克服&#39;,
 &#39;勇攀高峰&#39;,
 &#39;友善&#39;,
 &#39;进取&#39;,
 &#39;拼搏&#39;,
 &#39;艰苦奋斗&#39;,
 &#39;团结拼搏&#39;,
 &#39;勇于担当&#39;,
 &#39;锐意进取&#39;,
 &#39;勇气&#39;,
 &#39;团结&#39;,
 &#39;团结奋进&#39;,
 &#39;团结一致&#39;,
 &#39;顽强拼搏&#39;,
 &#39;上下一心&#39;,
 &#39;实干&#39;,
 &#39;拼搏进取&#39;,
 &#39;积极进取&#39;,
 &#39;奋力拼搏&#39;,
 &#39;奋进&#39;,
 &#39;坚定信念&#39;,
 &#39;团结一心&#39;,
 &#39;精诚团结&#39;,
 &#39;顽强&#39;,
 &#39;踏实&#39;,
 &#39;团结协作&#39;,
 &#39;求真务实&#39;,
 &#39;团结奋斗&#39;,
 &#39;奋发有为&#39;,
 &#39;同心协力&#39;,
 &#39;脚踏实地&#39;,
 &#39;开拓进取&#39;,
 &#39;进取&#39;,
 &#39;勇于&#39;]
&lt;/code&gt;&lt;/pre&gt;
&lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;expand_dictionary&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;w2v_model&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
                  &lt;span class=&#34;n&#34;&gt;seedwords&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;创新&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;科技&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;  &lt;span class=&#34;s1&#34;&gt;&amp;#39;研发&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;  &lt;span class=&#34;s1&#34;&gt;&amp;#39;技术&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;  &lt;span class=&#34;s1&#34;&gt;&amp;#39;标准&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;
                  &lt;span class=&#34;n&#34;&gt;topn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;30&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[&#39;创新&#39;,
 &#39;科技&#39;,
 &#39;研发&#39;,
 &#39;技术&#39;,
 &#39;标准&#39;,
 &#39;技术创新&#39;,
 &#39;技术研发&#39;,
 &#39;先进技术&#39;,
 &#39;关键技术&#39;,
 &#39;创新性&#39;,
 &#39;前沿技术&#39;,
 &#39;科技创新&#39;,
 &#39;技术应用&#39;,
 &#39;产品开发&#39;,
 &#39;自主创新&#39;,
 &#39;新技术&#39;,
 &#39;科研&#39;,
 &#39;产品研发&#39;,
 &#39;自主研发&#39;,
 &#39;技术开发&#39;,
 &#39;工艺技术&#39;,
 &#39;技术标准&#39;,
 &#39;基础研究&#39;,
 &#39;集成创新&#39;,
 &#39;核心技术&#39;,
 &#39;成熟技术&#39;,
 &#39;研发创新&#39;,
 &#39;理论技术&#39;,
 &#39;前沿技术研发&#39;,
 &#39;工艺&#39;,
 &#39;科技成果&#39;,
 &#39;技术研究&#39;,
 &#39;标准制定&#39;,
 &#39;技术装备&#39;,
 &#39;技术相结合&#39;]
&lt;/code&gt;&lt;/pre&gt;
&lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;expand_dictionary&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;w2v_model&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
                  &lt;span class=&#34;n&#34;&gt;seedwords&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;竞争&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;竞争力&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;
                  &lt;span class=&#34;n&#34;&gt;topn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;30&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[&#39;竞争&#39;,
 &#39;竞争力&#39;,
 &#39;竞争能力&#39;,
 &#39;市场竞争&#39;,
 &#39;竞争优势&#39;,
 &#39;市场竞争力&#39;,
 &#39;竞&#39;,
 &#39;竞争实力&#39;,
 &#39;激烈竞争&#39;,
 &#39;参与市场竞争&#39;,
 &#39;国际竞争&#39;,
 &#39;市场竞争能力&#39;,
 &#39;竞争态势&#39;,
 &#39;市场竞争优势&#39;,
 &#39;行业竞争&#39;,
 &#39;综合竞争力&#39;,
 &#39;竞争对手&#39;,
 &#39;未来市场竞争&#39;,
 &#39;产品竞争力&#39;,
 &#39;之间竞争&#39;,
 &#39;核心竞争力&#39;,
 &#39;参与竞争&#39;,
 &#39;核心竞争能力&#39;,
 &#39;竞争日趋激烈&#39;,
 &#39;国际化竞争&#39;,
 &#39;国际竞争力&#39;,
 &#39;竟争力&#39;,
 &#39;市场化竞争&#39;,
 &#39;同质化竞争&#39;,
 &#39;竞争力关键&#39;,
 &#39;价格竞争&#39;,
 &#39;整体竞争力&#39;]
&lt;/code&gt;&lt;/pre&gt;
&lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;expand_dictionary&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;w2v_model&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
                  &lt;span class=&#34;n&#34;&gt;seedwords&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;疫情&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;扩散&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;防控&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;反复&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;冲击&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;
                  &lt;span class=&#34;n&#34;&gt;topn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;30&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[&#39;疫情&#39;,
 &#39;扩散&#39;,
 &#39;防控&#39;,
 &#39;反复&#39;,
 &#39;冲击&#39;,
 &#39;蔓延&#39;,
 &#39;疫情&#39;,
 &#39;疫情爆发&#39;,
 &#39;疫情冲击&#39;,
 &#39;新冠疫情&#39;,
 &#39;肆虐&#39;,
 &#39;新冠肺炎&#39;,
 &#39;疫情蔓延&#39;,
 &#39;本次疫情&#39;,
 &#39;散发&#39;,
 &#39;疫情扩散&#39;,
 &#39;疫情影响&#39;,
 &#39;疫情反复&#39;,
 &#39;疫情传播&#39;,
 &#39;肺炎疫情&#39;,
 &#39;国内疫情&#39;,
 &#39;击&#39;,
 &#39;各地疫情&#39;,
 &#39;疫情全球&#39;,
 &#39;疫情多点&#39;,
 &#39;全球疫情&#39;,
 &#39;持续蔓延&#39;,
 &#39;多点散发&#39;,
 &#39;疫情导致&#39;,
 &#39;疫情暴发&#39;,
 &#39;病毒疫情&#39;,
 &#39;疫情持续&#39;,
 &#39;疫情初期&#39;,
 &#39;疫情出现&#39;,
 &#39;防控措施&#39;]
&lt;/code&gt;&lt;/pre&gt;
&lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;expand_dictionary&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;w2v_model&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
                  &lt;span class=&#34;n&#34;&gt;seedwords&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;旧&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;老&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;后&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;落后&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;
                  &lt;span class=&#34;n&#34;&gt;topn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;30&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[&#39;旧&#39;,
 &#39;老&#39;,
 &#39;后&#39;,
 &#39;落后&#39;,
 &#39;老&#39;,
 &#39;旧&#39;,
 &#39;陈旧&#39;,
 &#39;老旧&#39;,
 &#39;淘汰&#39;,
 &#39;低效率&#39;,
 &#39;低效&#39;,
 &#39;部分老旧&#39;,
 &#39;进行改造&#39;,
 &#39;老旧设备&#39;,
 &#39;工艺落后&#39;,
 &#39;设备陈旧&#39;,
 &#39;能耗高&#39;,
 &#39;更新改造&#39;,
 &#39;落后工艺&#39;,
 &#39;技术落后&#39;,
 &#39;改造&#39;,
 &#39;翻新&#39;,
 &#39;简陋&#39;,
 &#39;旧设备&#39;,
 &#39;拆除&#39;,
 &#39;现象严重&#39;,
 &#39;原有&#39;,
 &#39;相对落后&#39;,
 &#39;产能淘汰&#39;,
 &#39;加快淘汰&#39;,
 &#39;搬&#39;,
 &#39;替换&#39;,
 &#39;大批&#39;,
 &#39;迁&#39;]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;五源代码&#34;&gt;五、源代码&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;gensim.models&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;KeyedVectors&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pathlib&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Path&lt;/span&gt;


&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;load_w2v&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;w2v_path&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
    &lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&amp;#34;
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;    Load word2vec model
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;    Args:
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;        w2v_path (str): path of word2vec model
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;    Returns:
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;        model: word2vec model
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;    &amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;
    &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;Loading word2vec model...&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;model&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;KeyedVectors&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;load&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;w2v_path&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
    &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;model&lt;/span&gt;


&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;expand_dictionary&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;seedwords&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;topn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;100&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
    &lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&amp;#34;
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;    According to the seed word file, select the top n words with the most similar semantics and save them in the directory save_dir.
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;    
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;    Args:
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;        wv (Word2VecKeyedVectors): the word embedding model
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;        seedwords (list): 种子词
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;        topn (int, optional): Set the number of most similar words to retrieve to topn. Defaults to 100.
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;        save_dir (str, optional): the directory to save the candidate words. Defaults to &amp;#39;Word2Vec&amp;#39;.
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;    
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;    Returns:
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;    &amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;simidx_scores&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt;

    &lt;span class=&#34;n&#34;&gt;similars_candidate_idxs&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;#the candidate words of seedwords&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;dictionary&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;key_to_index&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;seedidxs&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;#transform word to index&lt;/span&gt;
    &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;seed&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;seedwords&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
        &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;seed&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;dictionary&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
            &lt;span class=&#34;n&#34;&gt;seedidx&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;dictionary&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;seed&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
            &lt;span class=&#34;n&#34;&gt;seedidxs&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;append&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;seedidx&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
    &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;seedidx&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;seedidxs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
        &lt;span class=&#34;c1&#34;&gt;# sims_words such as [(&amp;#39;by&amp;#39;, 0.99984), (&amp;#39;or&amp;#39;, 0.99982), (&amp;#39;an&amp;#39;, 0.99981), (&amp;#39;up&amp;#39;, 0.99980)]&lt;/span&gt;
        &lt;span class=&#34;n&#34;&gt;sims_words&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;similar_by_word&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;seedidx&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;topn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;topn&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
        &lt;span class=&#34;c1&#34;&gt;#Convert words to index and store them&lt;/span&gt;
        &lt;span class=&#34;n&#34;&gt;similars_candidate_idxs&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;extend&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;([&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dictionary&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sim&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]]&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sim&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sims_words&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;similars_candidate_idxs&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;set&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;similars_candidate_idxs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
    
    &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;idx&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;similars_candidate_idxs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
        &lt;span class=&#34;n&#34;&gt;score&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;n_similarity&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;([&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;idx&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;seedidxs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
        &lt;span class=&#34;n&#34;&gt;simidx_scores&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;append&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;((&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;idx&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;score&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;simidxs&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;w&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;w&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;sorted&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;simidx_scores&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;key&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;lambda&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;k&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;k&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;reverse&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)]&lt;/span&gt;

    &lt;span class=&#34;n&#34;&gt;simwords&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;str&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;index_to_key&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;idx&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;idx&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;simidxs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;][:&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;topn&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;

    &lt;span class=&#34;n&#34;&gt;resultwords&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;resultwords&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;extend&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;seedwords&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;resultwords&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;extend&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;simwords&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
    
    &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;resultwords&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;六获取模型&#34;&gt;六、获取模型&lt;/h2&gt;
&lt;p&gt;内容创作不易， 本文为付费内容，&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;- 100元    2001-2022年报 &amp;amp; 管理层讨论与分析

- 100元    cntext-2.1.1-py3-none-any.whl

- 100元   Word2Vec相关模型文件(mda01-22.200.6.bin)

- 200元   
    - 2001-2022年报 &amp;amp; 管理层讨论与分析
    - cntext-2.1.1-py3-none-any.whl  
    - Word2Vec相关模型文件(mda01-22.200.6.bin)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;加微信 372335839， 备注「姓名-学校-专业-word2vec」&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;广而告之&#34;&gt;广而告之&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/call_for_paper/&#34;&gt;长期征稿&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/we_need_you/&#34;&gt;长期招募小伙伴&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/management_python_course/&#34;&gt;付费视频课 | Python实证指标构建与文本分析&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
      <content:encoded><![CDATA[<h2 id="相关内容">相关内容</h2>
<ul>
<li><a href="https://textdata.cn/blog/the_text_analysis_list_about_ms/">LIST | 社科(经管)文本挖掘文献汇总</a></li>
<li><a href="https://textdata.cn/blog/text_analysis_code_list_about_ms/">LIST | 文本分析代码汇总</a></li>
<li><a href="https://textdata.cn/blog/datasets_available_for_management_science/">LIST | 可供社科(经管)领域使用的数据集</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">Python实证指标构建与文本分析</a></li>
<li><a href="https://textdata.cn/blog/2023-11-20-word2vec-by-year-by-province/">使用3751w专利申请数据集按年份(按省份)训练词向量</a></li>
<li><a href="https://textdata.cn/blog/2023-11-10-training-word2vec-model-using-china-3751w-patent-application-dataset/">预训练模型 | 使用1000w专利摘要训练word2vec模型，可用于开发词典</a></li>
</ul>
<p>相关文献</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">[0]刘景江,郑畅然,洪永淼.机器学习如何赋能管理学研究？——国内外前沿综述和未来展望[J].管理世界,2023,39(09):191-216.
[1]冉雅璇,李志强,刘佳妮,张逸石.大数据时代下社会科学研究方法的拓展——基于词嵌入技术的文本分析的应用[J].南开管理评论:1-27.
[3]胡楠,薛付婧,王昊楠.管理者短视主义影响企业长期投资吗？——基于文本分析和机器学习[J].管理世界,2021,37(05):139-156+11+19-21.
[4]Kai Li, Feng Mai, Rui Shen, Xinyan Yan, Measuring Corporate Culture Using Machine Learning, *The Review of Financial Studies*,2020
</code></pre></div><p><br><br></p>
<h2 id="一训练">一、训练</h2>
<h3 id="11-导入mda数据">1.1 导入mda数据</h3>
<p>读取 <a href="https://textdata.cn/blog/2023-03-23-china-a-share-market-dataset-mda-from-01-to-21/"><strong>数据集 | 2001-2022年A股上市公司年报&amp;管理层讨论与分析</strong></a></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_excel</span><span class="p">(</span><span class="s1">&#39;mda01-22.csv.gz&#39;</span><span class="p">,</span> <span class="n">compression</span><span class="o">=</span><span class="s1">&#39;gzip&#39;</span><span class="p">)</span>
<span class="c1">#gz解压后读取csv</span>
<span class="c1">#df = pd.read_excel(&#39;mda01-22.csv&#39;)</span>

<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">))</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">55439
</code></pre></div><p><img loading="lazy" src="img/df.png" alt=""  />
</p>
<br>
<h3 id="12-构造语料">1.2 构造语料</h3>
<p>从 <strong>mda01-22.xlsx</strong> 数据中抽取出所有文本，写入到 <strong>mda01-22.txt</strong></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;mda01-22.txt&#39;</span><span class="p">,</span> <span class="s1">&#39;a+&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">text</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">])</span>
    <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
</code></pre></div><br>
<h3 id="13-配置cntext环境">1.3 配置cntext环境</h3>
<p>使用2.1.1版本 cntext 库(该版本暂不开源，需付费购买)。 将得到的 <strong>cntext-2.1.1-py3-none-any.whl</strong> 文件放置于电脑桌面，  win系统打开<strong>cmd</strong>(Mac打开terminal)， 输入如下命令(将工作环境切换至桌面)</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">cd desktop
</code></pre></div><p>个别Win用户如无效，试试<code>cd Desktop</code> 。</p>
<p>继续在cmd (terminal) 中执行如下命令安装cntext2.1.1</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">pip3 install distinctiveness
pip3 install cntext-2.1.1-py3-none-any.whl 
</code></pre></div><br>
<h3 id="14-训练word2vec">1.4 训练word2vec</h3>
<p>设置模型参数配置</p>
<ul>
<li>mda01-22 使用2001-2022年度mda数据训练</li>
<li>200 嵌入的维度数，即每个词的向量长度是200</li>
<li>6 词语上下文的窗口是6</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="o">%%</span><span class="n">time</span>  <span class="c1">#程序结束后，可查看总的运行时间</span>
<span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>

<span class="n">w2v</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">W2VModel</span><span class="p">(</span><span class="n">corpus_file</span><span class="o">=</span><span class="s1">&#39;mda01-22.txt&#39;</span><span class="p">)</span>
<span class="n">w2v</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">vector_size</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">window_size</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">min_count</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">save_dir</span><span class="o">=</span><span class="s1">&#39;Word2Vec&#39;</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">Building prefix dict from the default dictionary ...
Start Preprocessing Corpus...
Dumping model to file cache /var/folders/y0/4gqxky0s2t94x1c1qhlwr6100000gn/T/jieba.cache
Loading model cost 0.278 seconds.
Prefix dict has been built successfully.
Start Training! This may take a while. Please be patient...

Training word2vec model took 3532 seconds

Note: The Word2Vec model has been saved to output/Word2Vec

CPU times: user 1h 30min 45s, sys: 30.1 s, total: 1h 31min 15s
Wall time: 58min 57s
</code></pre></div><p>经过不到两个小时时间， 训练出的中国A股市场词向量模型(如下截图)，词汇量 914058， 模型文件 1.49G。模型可广泛用于经济管理等领域概念(情感)词典的构建或扩展。</p>
<ul>
<li><strong>mda01-22.200.6.bin</strong></li>
<li><strong>mda01-22.200.6.bin.syn1neg.npy</strong></li>
<li><strong>mda01-22.200.6.bin.wv.vectors.npy</strong></li>
</ul>
<p><img loading="lazy" src="img/pretained-screen.png" alt=""  />
</p>
<p>为什么这样确定200和6，可以看这篇 <a href="https://textdata.cn/blog/2023-03-15-39faq-about-word-embeddings-for-social-science">词嵌入技术在社会科学领域进行数据挖掘常见39个FAQ汇总</a></p>
<br>
<br>
<h2 id="二导入模型">二、导入模型</h2>
<p>需要用到两个自定义函数load_w2v、expand_dictionary，源代码太长，为了提高阅读体验， 放在文末。大家记得用这两个函数前一定要先导入。<a href="mda_pretained_model_code.ipynb"><strong>点击代码</strong></a></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#先导入load_w2v、expand_dictionary函数源代码</span>


<span class="c1">#读取模型文件</span>
<span class="n">w2v_model</span> <span class="o">=</span> <span class="n">load_w2v</span><span class="p">(</span><span class="n">w2v_path</span><span class="o">=</span><span class="s1">&#39;Word2Vec/mda01-22.200.6.bin&#39;</span><span class="p">)</span>
<span class="n">w2v_model</span>
</code></pre></div><pre><code>Loading word2vec model...
&lt;gensim.models.word2vec.Word2Vec at 0x310dd9990&gt;
</code></pre>
<br>
<h2 id="注意">注意</h2>
<p>之前购买过mda01-22.100.6.bin的可以留意下， &lt;gensim.models.word2vec.Word2Vec&gt;和&lt;gensim.models.keyedvectors.KeyedVectors&gt;
是有区别的。</p>
<p><br><br></p>
<h3 id="三w2v_model的使用">三、w2v_model的使用</h3>
<ul>
<li>查看词汇量</li>
<li>查询某词向量</li>
<li>查看多个词的均值向量</li>
</ul>
<p>更多内容，建议查看下gensim库的文档</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#词汇量</span>
<span class="nb">len</span><span class="p">(</span><span class="n">w2v_model</span><span class="o">.</span><span class="n">wv</span><span class="o">.</span><span class="n">index_to_key</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<pre><code>914058  
</code></pre>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#查询某词的词向量</span>
<span class="n">w2v_model</span><span class="o">.</span><span class="n">wv</span><span class="o">.</span><span class="n">get_vector</span><span class="p">(</span><span class="s1">&#39;创新&#39;</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<pre><code>array([-1.36441350e-01, -2.02002168e+00, -1.49168205e+00,  2.65202689e+00,
        1.49721682e+00,  2.14851022e+00, -1.54925853e-01, -2.25241160e+00,
       -3.58773202e-01,  1.54530525e+00, -7.62950361e-01, -9.77181852e-01,
        6.70365512e-01, -3.20203233e+00,  3.18079638e+00,  1.66510820e+00,
        9.80131567e-01,  1.62199986e+00,  1.80585206e+00,  4.08179426e+00,
       -1.26518166e+00,  3.75929743e-01,  5.72038591e-01,  1.16134119e+00,
        2.55617023e+00, -2.25110960e+00, -2.61538339e+00, -5.71992218e-01,
        8.70356798e-01, -1.85045290e+00, -2.85597444e-01, -9.15628672e-01,
       -2.03667688e+00,  2.11716801e-01,  2.94088912e+00, -2.32688546e+00,
        2.20858502e+00,  8.81347775e-01, -7.99135566e-01, -8.61206651e-01,
       -4.45446587e+00, -1.73757005e+00, -3.36678886e+00, -2.82611530e-02,
       -1.62726247e+00, -8.49750221e-01,  4.13731128e-01, -1.62519825e+00,
        3.03865957e+00, -1.39746085e-01,  8.22233260e-01, -7.97697455e-02,
        1.72468078e+00,  2.94929433e+00,  9.72453177e-01, -1.12741642e-01,
        8.18425417e-01, -9.05264139e-01,  2.61516261e+00,  8.02830994e-01,
        2.40420485e+00,  8.85799348e-01, -1.08665645e+00,  8.21912348e-01,
       -4.39456075e-01, -2.57663131e+00,  2.38062453e+00, -4.58515882e-01,
        2.12767506e+00, -2.01356173e-01,  2.71096081e-01,  9.51708496e-01,
       -3.05705309e+00, -6.06385887e-01, -1.38406023e-01,  2.36809158e+00,
       -2.49158549e+00,  2.71105647e+00, -3.07211792e-03,  1.04273570e+00,
        1.44201803e+00, -5.65704823e-01,  2.85488725e-01,  1.43495277e-01,
       -1.39421299e-01,  9.24086392e-01,  4.25374925e-01, -1.56690669e+00,
        1.67641795e+00, -1.03729677e+00, -1.45472065e-01, -2.11022258e+00,
       -1.81541741e+00, -8.66766050e-02,  8.72350857e-02,  1.17173791e+00,
       -3.07721123e-02,  5.84330797e-01,  1.47265148e+00, -1.76913440e+00,
       -8.48391712e-01, -3.25056529e+00,  7.14846313e-01, -2.98076987e-01,
        1.13966620e+00, -1.42698896e+00,  6.93505168e-01, -2.04717040e+00,
       -1.53559577e+00,  1.01942134e+00, -1.58283603e+00,  9.08654630e-01,
       -1.90529859e+00, -9.43309963e-01,  4.12964225e-01, -2.50713086e+00,
       -4.24056143e-01, -4.10613680e+00,  3.60615468e+00, -4.19765860e-01,
       -2.41174579e+00,  6.80675328e-01,  2.99834704e+00,  1.05610855e-01,
       -7.84325838e-01,  3.24065971e+00, -1.85072863e+00, -2.12448812e+00,
       -2.83468294e+00, -5.77759802e-01, -3.13433480e+00, -6.91670418e-01,
        2.99401569e+00, -5.16145706e-01,  9.09552336e-01, -5.52680910e-01,
       -2.88360894e-01,  1.11991334e+00, -1.11737549e+00,  1.15479147e+00,
       -4.63319182e-01,  1.38351321e+00, -3.02179503e+00,  1.24334955e+00,
        1.93393975e-01, -8.27962995e-01, -2.37227559e+00, -9.26931739e-01,
        6.72517180e-01,  1.27736795e+00,  1.98695862e+00,  1.41960573e+00,
       -3.73892736e+00, -3.14201683e-01, -7.19093859e-01,  1.86080355e-02,
       -2.68105698e+00,  1.04344964e+00,  9.46133554e-01, -2.06151366e+00,
       -2.84214950e+00,  1.17004764e+00,  1.24577022e+00, -1.10806060e+00,
        9.93207514e-01,  8.46789181e-01, -3.09691691e+00,  2.12616014e+00,
       -1.49274826e+00, -1.53214395e+00, -9.95470941e-01,  1.23463202e+00,
       -2.18907285e+00, -4.94913310e-01,  2.80939412e+00,  1.68149090e+00,
        1.48991072e+00,  3.83729649e+00,  4.72325265e-01,  1.37606680e+00,
        2.14257884e+00,  3.18186909e-01,  5.98093605e+00,  1.46744043e-01,
       -2.37729326e-01,  1.20463884e+00, -1.55812174e-01, -5.03088772e-01,
        4.53981996e-01,  1.95544350e+00, -2.32564354e+00, -4.09389853e-01,
        1.89125270e-01,  2.62835431e+00,  9.81123984e-01, -9.51041043e-01,
       -1.14294410e-01,  1.10983588e-01,  9.30419266e-02, -9.84693542e-02],
      dtype=float32)
</code></pre>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#查询多个词的词向量</span>
<span class="n">w2v_model</span><span class="o">.</span><span class="n">wv</span><span class="o">.</span><span class="n">get_mean_vector</span><span class="p">([</span><span class="s1">&#39;创新&#39;</span><span class="p">,</span> <span class="s1">&#39;研发&#39;</span><span class="p">])</span>
</code></pre></div><p>Ruj</p>
<pre><code>array([ 0.03019853, -0.01928307, -0.05371316,  0.00053774,  0.02516318,
        0.10103251, -0.03914721, -0.08307559,  0.00444389,  0.09456791,
       -0.05761364, -0.03459097,  0.04394419, -0.10181106,  0.1418381 ,
        0.05334964,  0.01820264,  0.01493831,  0.01626587,  0.17402864,
       -0.02859601,  0.04538149,  0.03768233,  0.05431981,  0.15405464,
       -0.03632693, -0.08566202, -0.00595666,  0.08378439, -0.11071078,
       -0.05904576, -0.06451955, -0.1076955 ,  0.05141645,  0.11710279,
       -0.09403889,  0.08633652, -0.06743232,  0.00328483,  0.01589498,
       -0.11226317, -0.05367877, -0.057222  , -0.00685401, -0.04531868,
       -0.02090884,  0.01426806, -0.04787309,  0.1325518 , -0.00498158,
        0.01912023, -0.02292867,  0.08855374,  0.07697155,  0.01407153,
       -0.02378988,  0.03745927,  0.00889686,  0.12555045,  0.04007044,
        0.06247196,  0.04912657, -0.06158784,  0.06346396,  0.00197599,
       -0.04995281,  0.05125345, -0.01584197,  0.07572784,  0.02580263,
       -0.02904062, -0.0008835 , -0.08365948, -0.05539802, -0.07523517,
        0.04622741, -0.12007375,  0.05453204, -0.02054051,  0.02937108,
        0.10272598, -0.0089594 ,  0.05172383,  0.00588922, -0.0010917 ,
        0.02603476, -0.01580217, -0.07810815,  0.06964722, -0.04709972,
       -0.0316673 , -0.05055645, -0.05096703,  0.02772727, -0.03495743,
        0.09567484, -0.0071935 , -0.01266821,  0.00074132, -0.07593331,
       -0.02928162, -0.12574387,  0.02437552, -0.0228716 , -0.03047204,
       -0.03948782,  0.07722469, -0.07440004, -0.00951135,  0.05531401,
       -0.03240326,  0.00389662, -0.05632257, -0.05030375,  0.02883579,
       -0.06157173,  0.00584065, -0.16594191,  0.1108149 , -0.00243916,
       -0.09964953,  0.02029083,  0.03522225, -0.01167114, -0.04048527,
        0.08301719, -0.04682562, -0.0714631 , -0.07355815, -0.0496731 ,
       -0.05303175, -0.03625978,  0.06879813, -0.09117774,  0.0323513 ,
       -0.01808765, -0.01746182,  0.02472609, -0.00873791, -0.00951474,
       -0.02176155,  0.02394484, -0.07035318,  0.10963078,  0.01004294,
       -0.02269555, -0.09929934, -0.02897175,  0.02157164,  0.05608977,
        0.09083252, -0.00525982, -0.09866816, -0.02736895, -0.02923711,
        0.05582205, -0.04462272,  0.01932517,  0.04468061,  0.00317996,
       -0.04182415,  0.03061792,  0.04278665,  0.02939183,  0.03475334,
       -0.00898206, -0.08902986,  0.08294971, -0.00942507, -0.02125597,
       -0.01008157,  0.04477865, -0.08366893, -0.00074587,  0.08328778,
        0.02653155,  0.04581301,  0.10532658, -0.04637942,  0.04722971,
        0.06853952, -0.00235328,  0.18312256, -0.0457427 ,  0.00874868,
        0.08945092, -0.01135547, -0.04203002,  0.02408407,  0.0594779 ,
       -0.05467811,  0.01946783,  0.07095537,  0.04226222, -0.0018304 ,
       -0.00086302,  0.04624099,  0.01009499,  0.04783599,  0.02535392],
      dtype=float32)
</code></pre>
<p>有了每个词或者概念的向量，可以结合cntext旧版本单语言模型内的态度偏见的度量。</p>
<p><br><br></p>
<h2 id="四扩展词典">四、扩展词典</h2>
<p>做词典法的文本分析，最重要的是有自己的领域词典。之前受限于技术难度，文科生的我也一直在用形容词的通用情感词典。现在依托word2vec技术， 可以加速人工构建的准确率和效率。</p>
<p>下面是在 mda01-22.200.6.bin 上做的词典扩展测试，函数expand_dictionary会根据种子词选取最准确的topn个词。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#短视主义词  实验</span>
<span class="n">expand_dictionary</span><span class="p">(</span><span class="n">wv</span><span class="o">=</span><span class="n">w2v_model</span><span class="o">.</span><span class="n">wv</span><span class="p">,</span> 
                  <span class="n">seedwords</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;抓紧&#39;</span><span class="p">,</span> <span class="s1">&#39;立刻&#39;</span><span class="p">,</span> <span class="s1">&#39;月底&#39;</span><span class="p">,</span> <span class="s1">&#39;年底&#39;</span><span class="p">,</span> <span class="s1">&#39;年终&#39;</span><span class="p">,</span> <span class="s1">&#39;争取&#39;</span><span class="p">,</span> <span class="s1">&#39;力争&#39;</span><span class="p">],</span>
                  <span class="n">topn</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<pre><code>['抓紧',
 '立刻',
 '月底',
 '年底',
 '年终',
 '争取',
 '力争',
 '争取',
 '力争',
 '年底',
 '月底',
 '3月底',
 '尽快',
 '上半年',
 '努力争取',
 '年内实现',
 '抓紧',
 '工作争取',
 '尽早',
 '6月底',
 '工作力争',
 '7月份',
 '年底完成',
 '确保',
 '早日',
 '有望',
 '全力',
 '创造条件',
 '3月份',
 '加紧',
 '力争实现',
 '力争今年',
 '月底前',
 '10月底',
 '4月份',
 '继续',
 '月初']
</code></pre>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">expand_dictionary</span><span class="p">(</span><span class="n">wv</span><span class="o">=</span><span class="n">w2v_model</span><span class="o">.</span><span class="n">wv</span><span class="p">,</span> 
                  <span class="n">seedwords</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;团结&#39;</span><span class="p">,</span> <span class="s1">&#39;拼搏&#39;</span><span class="p">,</span>  <span class="s1">&#39;克服&#39;</span><span class="p">,</span>  <span class="s1">&#39;勇攀高峰&#39;</span><span class="p">,</span>  <span class="s1">&#39;友善&#39;</span><span class="p">,</span>  <span class="s1">&#39;进取&#39;</span><span class="p">],</span>
                  <span class="n">topn</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<pre><code>['团结',
 '拼搏',
 '克服',
 '勇攀高峰',
 '友善',
 '进取',
 '拼搏',
 '艰苦奋斗',
 '团结拼搏',
 '勇于担当',
 '锐意进取',
 '勇气',
 '团结',
 '团结奋进',
 '团结一致',
 '顽强拼搏',
 '上下一心',
 '实干',
 '拼搏进取',
 '积极进取',
 '奋力拼搏',
 '奋进',
 '坚定信念',
 '团结一心',
 '精诚团结',
 '顽强',
 '踏实',
 '团结协作',
 '求真务实',
 '团结奋斗',
 '奋发有为',
 '同心协力',
 '脚踏实地',
 '开拓进取',
 '进取',
 '勇于']
</code></pre>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">expand_dictionary</span><span class="p">(</span><span class="n">wv</span><span class="o">=</span><span class="n">w2v_model</span><span class="o">.</span><span class="n">wv</span><span class="p">,</span> 
                  <span class="n">seedwords</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;创新&#39;</span><span class="p">,</span> <span class="s1">&#39;科技&#39;</span><span class="p">,</span>  <span class="s1">&#39;研发&#39;</span><span class="p">,</span>  <span class="s1">&#39;技术&#39;</span><span class="p">,</span>  <span class="s1">&#39;标准&#39;</span><span class="p">],</span>
                  <span class="n">topn</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<pre><code>['创新',
 '科技',
 '研发',
 '技术',
 '标准',
 '技术创新',
 '技术研发',
 '先进技术',
 '关键技术',
 '创新性',
 '前沿技术',
 '科技创新',
 '技术应用',
 '产品开发',
 '自主创新',
 '新技术',
 '科研',
 '产品研发',
 '自主研发',
 '技术开发',
 '工艺技术',
 '技术标准',
 '基础研究',
 '集成创新',
 '核心技术',
 '成熟技术',
 '研发创新',
 '理论技术',
 '前沿技术研发',
 '工艺',
 '科技成果',
 '技术研究',
 '标准制定',
 '技术装备',
 '技术相结合']
</code></pre>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">expand_dictionary</span><span class="p">(</span><span class="n">wv</span><span class="o">=</span><span class="n">w2v_model</span><span class="o">.</span><span class="n">wv</span><span class="p">,</span> 
                  <span class="n">seedwords</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;竞争&#39;</span><span class="p">,</span> <span class="s1">&#39;竞争力&#39;</span><span class="p">],</span>
                  <span class="n">topn</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<pre><code>['竞争',
 '竞争力',
 '竞争能力',
 '市场竞争',
 '竞争优势',
 '市场竞争力',
 '竞',
 '竞争实力',
 '激烈竞争',
 '参与市场竞争',
 '国际竞争',
 '市场竞争能力',
 '竞争态势',
 '市场竞争优势',
 '行业竞争',
 '综合竞争力',
 '竞争对手',
 '未来市场竞争',
 '产品竞争力',
 '之间竞争',
 '核心竞争力',
 '参与竞争',
 '核心竞争能力',
 '竞争日趋激烈',
 '国际化竞争',
 '国际竞争力',
 '竟争力',
 '市场化竞争',
 '同质化竞争',
 '竞争力关键',
 '价格竞争',
 '整体竞争力']
</code></pre>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">expand_dictionary</span><span class="p">(</span><span class="n">wv</span><span class="o">=</span><span class="n">w2v_model</span><span class="o">.</span><span class="n">wv</span><span class="p">,</span> 
                  <span class="n">seedwords</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;疫情&#39;</span><span class="p">,</span> <span class="s1">&#39;扩散&#39;</span><span class="p">,</span> <span class="s1">&#39;防控&#39;</span><span class="p">,</span> <span class="s1">&#39;反复&#39;</span><span class="p">,</span> <span class="s1">&#39;冲击&#39;</span><span class="p">],</span>
                  <span class="n">topn</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<pre><code>['疫情',
 '扩散',
 '防控',
 '反复',
 '冲击',
 '蔓延',
 '疫情',
 '疫情爆发',
 '疫情冲击',
 '新冠疫情',
 '肆虐',
 '新冠肺炎',
 '疫情蔓延',
 '本次疫情',
 '散发',
 '疫情扩散',
 '疫情影响',
 '疫情反复',
 '疫情传播',
 '肺炎疫情',
 '国内疫情',
 '击',
 '各地疫情',
 '疫情全球',
 '疫情多点',
 '全球疫情',
 '持续蔓延',
 '多点散发',
 '疫情导致',
 '疫情暴发',
 '病毒疫情',
 '疫情持续',
 '疫情初期',
 '疫情出现',
 '防控措施']
</code></pre>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">expand_dictionary</span><span class="p">(</span><span class="n">wv</span><span class="o">=</span><span class="n">w2v_model</span><span class="o">.</span><span class="n">wv</span><span class="p">,</span> 
                  <span class="n">seedwords</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;旧&#39;</span><span class="p">,</span> <span class="s1">&#39;老&#39;</span><span class="p">,</span> <span class="s1">&#39;后&#39;</span><span class="p">,</span> <span class="s1">&#39;落后&#39;</span><span class="p">],</span>
                  <span class="n">topn</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<pre><code>['旧',
 '老',
 '后',
 '落后',
 '老',
 '旧',
 '陈旧',
 '老旧',
 '淘汰',
 '低效率',
 '低效',
 '部分老旧',
 '进行改造',
 '老旧设备',
 '工艺落后',
 '设备陈旧',
 '能耗高',
 '更新改造',
 '落后工艺',
 '技术落后',
 '改造',
 '翻新',
 '简陋',
 '旧设备',
 '拆除',
 '现象严重',
 '原有',
 '相对落后',
 '产能淘汰',
 '加快淘汰',
 '搬',
 '替换',
 '大批',
 '迁']
</code></pre>
<p><br><br></p>
<h2 id="五源代码">五、源代码</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">gensim.models</span> <span class="kn">import</span> <span class="n">KeyedVectors</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>


<span class="k">def</span> <span class="nf">load_w2v</span><span class="p">(</span><span class="n">w2v_path</span><span class="p">):</span>
    <span class="s2">&#34;&#34;&#34;
</span><span class="s2">    Load word2vec model
</span><span class="s2">
</span><span class="s2">    Args:
</span><span class="s2">        w2v_path (str): path of word2vec model
</span><span class="s2">
</span><span class="s2">    Returns:
</span><span class="s2">        model: word2vec model
</span><span class="s2">    &#34;&#34;&#34;</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Loading word2vec model...&#39;</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">KeyedVectors</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">w2v_path</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">model</span>


<span class="k">def</span> <span class="nf">expand_dictionary</span><span class="p">(</span><span class="n">wv</span><span class="p">,</span> <span class="n">seedwords</span><span class="p">,</span> <span class="n">topn</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
    <span class="s2">&#34;&#34;&#34;
</span><span class="s2">    According to the seed word file, select the top n words with the most similar semantics and save them in the directory save_dir.
</span><span class="s2">    
</span><span class="s2">    Args:
</span><span class="s2">        wv (Word2VecKeyedVectors): the word embedding model
</span><span class="s2">        seedwords (list): 种子词
</span><span class="s2">        topn (int, optional): Set the number of most similar words to retrieve to topn. Defaults to 100.
</span><span class="s2">        save_dir (str, optional): the directory to save the candidate words. Defaults to &#39;Word2Vec&#39;.
</span><span class="s2">    
</span><span class="s2">    Returns:
</span><span class="s2">    &#34;&#34;&#34;</span>
    <span class="n">simidx_scores</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="n">similars_candidate_idxs</span> <span class="o">=</span> <span class="p">[]</span> <span class="c1">#the candidate words of seedwords</span>
    <span class="n">dictionary</span> <span class="o">=</span> <span class="n">wv</span><span class="o">.</span><span class="n">key_to_index</span>
    <span class="n">seedidxs</span> <span class="o">=</span> <span class="p">[]</span> <span class="c1">#transform word to index</span>
    <span class="k">for</span> <span class="n">seed</span> <span class="ow">in</span> <span class="n">seedwords</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">seed</span> <span class="ow">in</span> <span class="n">dictionary</span><span class="p">:</span>
            <span class="n">seedidx</span> <span class="o">=</span> <span class="n">dictionary</span><span class="p">[</span><span class="n">seed</span><span class="p">]</span>
            <span class="n">seedidxs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">seedidx</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">seedidx</span> <span class="ow">in</span> <span class="n">seedidxs</span><span class="p">:</span>
        <span class="c1"># sims_words such as [(&#39;by&#39;, 0.99984), (&#39;or&#39;, 0.99982), (&#39;an&#39;, 0.99981), (&#39;up&#39;, 0.99980)]</span>
        <span class="n">sims_words</span> <span class="o">=</span> <span class="n">wv</span><span class="o">.</span><span class="n">similar_by_word</span><span class="p">(</span><span class="n">seedidx</span><span class="p">,</span> <span class="n">topn</span><span class="o">=</span><span class="n">topn</span><span class="p">)</span>
        <span class="c1">#Convert words to index and store them</span>
        <span class="n">similars_candidate_idxs</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="n">dictionary</span><span class="p">[</span><span class="n">sim</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span> <span class="k">for</span> <span class="n">sim</span> <span class="ow">in</span> <span class="n">sims_words</span><span class="p">])</span>
    <span class="n">similars_candidate_idxs</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">similars_candidate_idxs</span><span class="p">)</span>
    
    <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">similars_candidate_idxs</span><span class="p">:</span>
        <span class="n">score</span> <span class="o">=</span> <span class="n">wv</span><span class="o">.</span><span class="n">n_similarity</span><span class="p">([</span><span class="n">idx</span><span class="p">],</span> <span class="n">seedidxs</span><span class="p">)</span>
        <span class="n">simidx_scores</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">idx</span><span class="p">,</span> <span class="n">score</span><span class="p">))</span>
    <span class="n">simidxs</span> <span class="o">=</span> <span class="p">[</span><span class="n">w</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">simidx_scores</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">k</span><span class="p">:</span><span class="n">k</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)]</span>

    <span class="n">simwords</span> <span class="o">=</span> <span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">wv</span><span class="o">.</span><span class="n">index_to_key</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">simidxs</span><span class="p">][:</span><span class="n">topn</span><span class="p">]</span>

    <span class="n">resultwords</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">resultwords</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">seedwords</span><span class="p">)</span>
    <span class="n">resultwords</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">simwords</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">resultwords</span>
</code></pre></div><p><br><br></p>
<h2 id="六获取模型">六、获取模型</h2>
<p>内容创作不易， 本文为付费内容，</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">- 100元    2001-2022年报 &amp; 管理层讨论与分析

- 100元    cntext-2.1.1-py3-none-any.whl

- 100元   Word2Vec相关模型文件(mda01-22.200.6.bin)

- 200元   
    - 2001-2022年报 &amp; 管理层讨论与分析
    - cntext-2.1.1-py3-none-any.whl  
    - Word2Vec相关模型文件(mda01-22.200.6.bin)
</code></pre></div><p>加微信 372335839， 备注「姓名-学校-专业-word2vec」</p>
<p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>借助chatGPT更高效地学习「Python实证指标构建与文本分析」</title>
      <link>https://textdata.cn/blog/2023-03-15-how-to-learn-python-data-mining-with-chatgpt/</link>
      <pubDate>Wed, 15 Mar 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-03-15-how-to-learn-python-data-mining-with-chatgpt/</guid>
      <description>借助chatGPT更高效地学习「Python实证指标构建与文本分析」学一门含有Python语法、代码技术、科研应用三类内容的课程，如【Python实证指标构建文本分析】，掌握并内化最少必要知识量。明白原理，会把需求转化成问题，向chatGPT提问。如果把社科数据分析需求比作城堡， 我们需要掌握拆解成多个小积木的能力，之后每个小积木让chatGPT帮我实现。我们要做的是</description>
      <content:encoded><![CDATA[<p>对编程0基础的人而言，三个痛点及解决办法</p>
<table>
<thead>
<tr>
<th>学习痛点</th>
<th>解决办法</th>
</tr>
</thead>
<tbody>
<tr>
<td>软件安装配置环境</td>
<td>淘宝搜【python环境配置】，30min，30元左右搞定</td>
</tr>
<tr>
<td>敲代码遇到问题，缺乏及时的答疑解惑</td>
<td>会正确上网，向chatGPT(实时应答的编程教练)提问</td>
</tr>
<tr>
<td>如何使用编程语言解决社科类科研数据挖掘问题</td>
<td>学一门含有Python语法、代码技术、科研应用三类内容的课程，如【Python实证指标构建文本分析】，掌握并内化 <strong>最少必要知识量</strong>。明白原理，会把需求转化成问题，向chatGPT提问。</td>
</tr>
</tbody>
</table>
<p>三种痛点及解决办法，可以将Python文本分析开展社科类科研数据挖掘的门槛大大降低。</p>
<br>
<h2 id="用术语提问">用术语提问</h2>
<p>如果把社科数据分析需求比作城堡， 我们需要掌握拆解成多个小积木的能力，之后每个小积木让chatGPT帮我实现。我们要做的是</p>
<ul>
<li>心中有施工蓝图，把大城堡拆解成多个小积木</li>
<li>每个小积木，要尽量用术语向chatGPT提问</li>
<li>对chatGPT回答进行检查和实验</li>
<li>最后，按施工蓝图把多个小积木搭成城堡。</li>
</ul>
<p>这需要我们掌握最少必要知识， Python语法，如数据类型、逻辑语句、常用库、常用函数、科研应用案例。</p>
<br>
<h2 id="提问案例">提问案例</h2>
<p>多观察代码，学会基本提问， 例如</p>
<ol>
<li>我是Python初学者，正在学Python。希望你当做我的Python解释器，我输入代码，你帮我运行并返回中文解释。</li>
<li>如何用Python写for循环</li>
<li>我想用Python统计某个词语列表中某些关键词的词频</li>
<li>如何用Python读取csv</li>
<li>我的代码出现UnicodeDecode错误， 这是源代码xxxx,这是报错提示，请解释问题，告诉我解决办法。</li>
<li>&hellip;&hellip;</li>
</ol>
<p>借助chatGPT写代码应用案例</p>
<ul>
<li><a href="https://textdata.cn/blog/2023-02-15-write-web-scraper-with-chatgpt/">使用 chatGPT 写 Python 网络爬虫</a></li>
<li><a href="https://textdata.cn/blog/2023-02-12-regex-expression-generated-by-chatgpt/">数据清洗 | 借助 chatGPT 设计正则表达式</a></li>
<li><a href="https://textdata.cn/blog/2023-02-11-chatgpt-plus-for-text-mining/">使用 chatGPT 做词频统计&amp;词云图</a></li>
</ul>
<br>
<h2 id="注册chatgpt">注册chatGPT</h2>
<p>科学上网、使用chatGPT都不难的，相关操作，可以参考大邓这篇博文</p>
<p><a href="https://textdata.cn/blog/2023-02-15-how-to-sign-up-the-chatgpt-accout-and-upgrade-to-plus/">https://textdata.cn/blog/2023-02-15-how-to-sign-up-the-chatgpt-accout-and-upgrade-to-plus/</a></p>
<br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>近年《经济研究》中「文本分析」相关论文</title>
      <link>https://textdata.cn/blog/2023-01-16-papers-using-text-mining-tech-in-journal-of-economic-research/</link>
      <pubDate>Mon, 16 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-01-16-papers-using-text-mining-tech-in-journal-of-economic-research/</guid>
      <description>使用机器学习、文本分析方法，发表在《经济研究》的相关论文</description>
      <content:encoded><![CDATA[<p>张叶青, 陆瑶, 李乐芸. <strong>大数据应用对中国企业市场价值的影响——来自中国上市公司年报文本分析的证据</strong>[J]. 经济研究, 2021, 56(12):18.</p>
<p>摘要：推进大数据与实体经济的深度融合成为中国新一轮的经济增长点.本文通过对A股上市公司的年报进行<strong>文本分析</strong>, <strong>构建了衡量公司层面&quot;大数据&quot;应用程度的指标</strong>,探讨了企业大数据应用的发展状况及决定因素,检验了大数据应用对公司市场价值的影响.研究发现:第一,规模较大,有形资产比例较低,盈利能力较强,以及所在地区市场化程度较高的公司更可能在生产经营过程中应用大数据;第二,大数据的应用可以显著提高公司的市场价值;第三,主要的影响机制在于大数据的应用显著提高了公司的生产效率和研发投入,而相关技术和人才供给的不足可能会阻碍大数据对市场价值的积极影响.本文结论对中国未来大数据相关的政策设计具有参考价值,为推动实体企业生产经营与大数据的高效融合提供了经验证据和指导建议.</p>
 <br> 
<p>李晓溪,杨国超,饶品贵.<strong>交易所问询函有监管作用吗?——基于并购重组报告书的文本分析</strong>[J].经济研究,2019,54(05):181-198.</p>
<p>摘要:在国务院大力强调优化兼并重组市场环境的形势下,2014年以来交易所广泛使用的并购问询函制度能否发挥监管作用,成为并购重组服务实体经济能力的重要影响因素。为此,本文研究交易所问询函是否降低并购重组信息不对称进而提升并购绩效。研究结果表明,交易所问询函能够识别并购重组中的潜在风险,表现为信息不对称程度较高、报告书信息披露质量较差的并购重组交易更可能收到问询函。进一步地,被问询样本在收到问询函之后的买卖价差、分析师盈余预测误差以及分析师乐观程度较低。 <strong>针对具体作用机制,本文采用文本分析法比较修订前后的并购重组报告书,发现新修订报告书中标的方历史信息和前瞻信息的内容均更多,且更详细,表明问询函制度通过改善信息披露缓解了并购交易的信息不对称问题</strong>。经济后果方面,本文发现信息披露改善较多的被问询样本重组成功的可能性更大,未来市场业绩也更好。本文研究不仅丰富了问询函经济后果的相关研究,也为问询监管政策缓解并购重组信息不对称提供了理论参考。</p>
 <br> 
<p>张成思, 孙宇辰, 阮睿. <strong>宏观经济感知,货币政策与微观企业投融资行为</strong>[J]. 经济研究, 2021, 56(10):17.</p>
<p>摘要：<strong>本文基于中国上市公司年报文本信息,首次构建了中国微观企业宏观经济感知指数</strong>,并通过一个三期理论模型阐释货币政策在不同宏观经济感知情形下如何影响微观企业投融资行为.实证分析表明,当央行实施积极货币政策时,对宏观经济感知更乐观的企业更积极地响应政策刺激,表现为投融资行为增加.进一步将宏观经济感知指数分解为预期指数和回顾指数,分析结果表明:宏观经济感知指数的影响主要由反映企业未来预期的宏观经济预期指数引致,而反映历史信息的宏观经济回顾指数则没有显著影响.区分企业所有制的结果还表明,持有积极宏观经济感知的民营企业仅在积极货币政策状态下增加投资和提高杠杆率,而宏观经济感知对国有企业投融资行为的作用则未受货币政策状态影响.</p>
<br> 
<p>林建浩, 陈良源, 罗子豪,等. <strong>央行沟通有助于改善宏观经济预测吗?——基于文本数据的高维稀疏建模</strong>[J]. 经济研究, 2021,56(03).</p>
<p>摘要： 宏观经济预测是宏观调控精准施策的重要前提,一直以来是方法论研究的前沿议题.随着央行沟通在预期管理中的频繁使用,其传达的信息受到普遍关注,<strong>本文致力于利用央行沟通文本进行宏观经济预测.首先生成符合央行沟通表达习惯的专用词典用于构建完整语料库,继而利用栅栏分布式多项回归模型从高维和稀疏的语料库中提取有效信息</strong>,得到央行沟通测度.基于152个指标构建基准动态因子模型,进一步引入央行沟通测度作为新的预测因子,结果显示央行沟通测度有助于提升模型样本内拟合效果.考察样本外预测效果,在不包括预测变量历史信息时,央行沟通测度能够使得不同期限的预测精度提高6.80％-16.65％;包含预测变量历史信息时则出现分化,在期限较短时,央行沟通未能提升预测精度,这是因为主要沟通信息与预测变量历史信息重叠;当期限较长时,预测精度有所提升,表明沟通中少量的前瞻性指引具有持续的预测能力.本文研究从预测角度验证了中国央行沟通在预期管理中的作用,并为进一步利用非结构化的文本大数据提升中国宏观经济实时预测能力提供了新思路.</p>
 <br> 
<p>曹廷求, 张光利. <strong>自愿性信息披露与股价崩盘风险:基于电话会议的研究</strong>[J]. 经济研究, 2020, 55(11):17.</p>
<p>摘要：<strong>电话会议已经成为中国上市企业自愿性信息披露的重要渠道</strong>,本文从股价崩盘风险的视角探讨了电话会议的信息披露效果.实证结果表明,电话会议能够显著降低企业股价崩盘风险,在控制反向因果和遗漏变量导致的内生性问题之后,该结论依然成立.电话会议影响股价崩盘风险的程度受到企业异质性和外部信息环境的影响,具体而言,我们发现当企业的信息披露质量越高,机构投资者持股比例越高,被分析师关注程度越高,投资者对企业信息的需求越强时,电话会议对企业股价崩盘风险的影响越强.另外,我们分别从<strong>电话会议信息含量</strong>,投资者反应周期,<strong>高管语言特征</strong>,会议主题的视角讨论了电话会议影响股价崩盘风险的机制.本文的研究对于全面认识电话会议在资本市场中的信息披露效果以及如何降低股价崩盘风险具有重要的理论和现实意义。</p>
<br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>转载 | 国外会计文本信息实证研究述评与展望</title>
      <link>https://textdata.cn/blog/2023-01-12-review_about_accounting_text_mining/</link>
      <pubDate>Thu, 12 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-01-12-review_about_accounting_text_mining/</guid>
      <description>近年来，文本信息逐渐成为国外会计实证研究的热点，许多学者开始致力于 运用文本分析方法来解决会计与财务问题，并取得了众多有价值的研究成果。与之相比，国 内的此类研究却相当缺乏。为了弥补国内研究的不足，本文对国外近十年来取得的研究成果 进行了系统的梳理和述评。首先，系统阐述了会计文本信息的定义、特征及其测量方法；其 次，从不同层面出发，总结并分析了会计文本信息的影响因素及其作用结果；再次，指出了 现今国外研究中存在的不足。在此基础上，本文提出了一个未来研究的框架，分别从基础、 引入、拓展三个方向来展望国内研究，具体包括如何构建适合中文会计语言的文本分析方 法、国外现有理论与问题在我国的本土化检验以及在中国情境下可以拓展的独创性研究。In recent years, text information has gradually become a hot spot in foreign accounting empirical research. Many scholars have begun to use text analysis methods to solve accounting and financial problems, and have achieved many valuable research results. In contrast, such research in China is quite lacking. In order to make up for the lack of domestic research, this paper systematically sorts out and reviews the research achievements abroad in the past ten years. Firstly, it systematically expounds the definition, characteristics and measurement methods of accounting textual information; secondly, it summarizes and analyzes the influencing factors and results of accounting textual information from different levels; thirdly, it points out the deficiencies in current foreign research . On this basis, this paper proposes a framework for future research, looking forward to domestic research from the three directions of foundation, introduction, and expansion, including how to construct a text analysis method suitable for Chinese accounting language, and the existing foreign theories and problems in my country. Indigenous testing and original research that can be extended in the Chinese context.</description>
      <content:encoded><![CDATA[<br>
<p>肖浩,詹雷,王征.国外会计文本信息实证研究述评与展望[J].外国经济与管理,2016,38(09):93-112.</p>
<br>
<p><img loading="lazy" src="img/%e5%9b%bd%e5%a4%96%e4%bc%9a%e8%ae%a1%e6%96%87%e6%9c%ac%e4%bf%a1%e6%81%af%e5%ae%9e%e8%af%81%e7%a0%94%e7%a9%b6%e8%bf%b0%e8%af%84%e4%b8%8e%e5%b1%95%e6%9c%9b_%e8%82%96%e6%b5%a9-01.png" alt=""  />

<img loading="lazy" src="img/%e5%9b%bd%e5%a4%96%e4%bc%9a%e8%ae%a1%e6%96%87%e6%9c%ac%e4%bf%a1%e6%81%af%e5%ae%9e%e8%af%81%e7%a0%94%e7%a9%b6%e8%bf%b0%e8%af%84%e4%b8%8e%e5%b1%95%e6%9c%9b_%e8%82%96%e6%b5%a9-02.png" alt=""  />

<img loading="lazy" src="img/%e5%9b%bd%e5%a4%96%e4%bc%9a%e8%ae%a1%e6%96%87%e6%9c%ac%e4%bf%a1%e6%81%af%e5%ae%9e%e8%af%81%e7%a0%94%e7%a9%b6%e8%bf%b0%e8%af%84%e4%b8%8e%e5%b1%95%e6%9c%9b_%e8%82%96%e6%b5%a9-03.png" alt=""  />

<img loading="lazy" src="img/%e5%9b%bd%e5%a4%96%e4%bc%9a%e8%ae%a1%e6%96%87%e6%9c%ac%e4%bf%a1%e6%81%af%e5%ae%9e%e8%af%81%e7%a0%94%e7%a9%b6%e8%bf%b0%e8%af%84%e4%b8%8e%e5%b1%95%e6%9c%9b_%e8%82%96%e6%b5%a9-04.png" alt=""  />

<img loading="lazy" src="img/%e5%9b%bd%e5%a4%96%e4%bc%9a%e8%ae%a1%e6%96%87%e6%9c%ac%e4%bf%a1%e6%81%af%e5%ae%9e%e8%af%81%e7%a0%94%e7%a9%b6%e8%bf%b0%e8%af%84%e4%b8%8e%e5%b1%95%e6%9c%9b_%e8%82%96%e6%b5%a9-05.png" alt=""  />

<img loading="lazy" src="img/%e5%9b%bd%e5%a4%96%e4%bc%9a%e8%ae%a1%e6%96%87%e6%9c%ac%e4%bf%a1%e6%81%af%e5%ae%9e%e8%af%81%e7%a0%94%e7%a9%b6%e8%bf%b0%e8%af%84%e4%b8%8e%e5%b1%95%e6%9c%9b_%e8%82%96%e6%b5%a9-06.png" alt=""  />

<img loading="lazy" src="img/%e5%9b%bd%e5%a4%96%e4%bc%9a%e8%ae%a1%e6%96%87%e6%9c%ac%e4%bf%a1%e6%81%af%e5%ae%9e%e8%af%81%e7%a0%94%e7%a9%b6%e8%bf%b0%e8%af%84%e4%b8%8e%e5%b1%95%e6%9c%9b_%e8%82%96%e6%b5%a9-07.png" alt=""  />

<img loading="lazy" src="img/%e5%9b%bd%e5%a4%96%e4%bc%9a%e8%ae%a1%e6%96%87%e6%9c%ac%e4%bf%a1%e6%81%af%e5%ae%9e%e8%af%81%e7%a0%94%e7%a9%b6%e8%bf%b0%e8%af%84%e4%b8%8e%e5%b1%95%e6%9c%9b_%e8%82%96%e6%b5%a9-08.png" alt=""  />

<img loading="lazy" src="img/%e5%9b%bd%e5%a4%96%e4%bc%9a%e8%ae%a1%e6%96%87%e6%9c%ac%e4%bf%a1%e6%81%af%e5%ae%9e%e8%af%81%e7%a0%94%e7%a9%b6%e8%bf%b0%e8%af%84%e4%b8%8e%e5%b1%95%e6%9c%9b_%e8%82%96%e6%b5%a9-09.png" alt=""  />

<img loading="lazy" src="img/%e5%9b%bd%e5%a4%96%e4%bc%9a%e8%ae%a1%e6%96%87%e6%9c%ac%e4%bf%a1%e6%81%af%e5%ae%9e%e8%af%81%e7%a0%94%e7%a9%b6%e8%bf%b0%e8%af%84%e4%b8%8e%e5%b1%95%e6%9c%9b_%e8%82%96%e6%b5%a9-10.png" alt=""  />

<img loading="lazy" src="img/%e5%9b%bd%e5%a4%96%e4%bc%9a%e8%ae%a1%e6%96%87%e6%9c%ac%e4%bf%a1%e6%81%af%e5%ae%9e%e8%af%81%e7%a0%94%e7%a9%b6%e8%bf%b0%e8%af%84%e4%b8%8e%e5%b1%95%e6%9c%9b_%e8%82%96%e6%b5%a9-11.png" alt=""  />

<img loading="lazy" src="img/%e5%9b%bd%e5%a4%96%e4%bc%9a%e8%ae%a1%e6%96%87%e6%9c%ac%e4%bf%a1%e6%81%af%e5%ae%9e%e8%af%81%e7%a0%94%e7%a9%b6%e8%bf%b0%e8%af%84%e4%b8%8e%e5%b1%95%e6%9c%9b_%e8%82%96%e6%b5%a9-12.png" alt=""  />

<img loading="lazy" src="img/%e5%9b%bd%e5%a4%96%e4%bc%9a%e8%ae%a1%e6%96%87%e6%9c%ac%e4%bf%a1%e6%81%af%e5%ae%9e%e8%af%81%e7%a0%94%e7%a9%b6%e8%bf%b0%e8%af%84%e4%b8%8e%e5%b1%95%e6%9c%9b_%e8%82%96%e6%b5%a9-13.png" alt=""  />

<img loading="lazy" src="img/%e5%9b%bd%e5%a4%96%e4%bc%9a%e8%ae%a1%e6%96%87%e6%9c%ac%e4%bf%a1%e6%81%af%e5%ae%9e%e8%af%81%e7%a0%94%e7%a9%b6%e8%bf%b0%e8%af%84%e4%b8%8e%e5%b1%95%e6%9c%9b_%e8%82%96%e6%b5%a9-14.png" alt=""  />

<img loading="lazy" src="img/%e5%9b%bd%e5%a4%96%e4%bc%9a%e8%ae%a1%e6%96%87%e6%9c%ac%e4%bf%a1%e6%81%af%e5%ae%9e%e8%af%81%e7%a0%94%e7%a9%b6%e8%bf%b0%e8%af%84%e4%b8%8e%e5%b1%95%e6%9c%9b_%e8%82%96%e6%b5%a9-15.png" alt=""  />

<img loading="lazy" src="img/%e5%9b%bd%e5%a4%96%e4%bc%9a%e8%ae%a1%e6%96%87%e6%9c%ac%e4%bf%a1%e6%81%af%e5%ae%9e%e8%af%81%e7%a0%94%e7%a9%b6%e8%bf%b0%e8%af%84%e4%b8%8e%e5%b1%95%e6%9c%9b_%e8%82%96%e6%b5%a9-16.png" alt=""  />

<img loading="lazy" src="img/%e5%9b%bd%e5%a4%96%e4%bc%9a%e8%ae%a1%e6%96%87%e6%9c%ac%e4%bf%a1%e6%81%af%e5%ae%9e%e8%af%81%e7%a0%94%e7%a9%b6%e8%bf%b0%e8%af%84%e4%b8%8e%e5%b1%95%e6%9c%9b_%e8%82%96%e6%b5%a9-17.png" alt=""  />

<img loading="lazy" src="img/%e5%9b%bd%e5%a4%96%e4%bc%9a%e8%ae%a1%e6%96%87%e6%9c%ac%e4%bf%a1%e6%81%af%e5%ae%9e%e8%af%81%e7%a0%94%e7%a9%b6%e8%bf%b0%e8%af%84%e4%b8%8e%e5%b1%95%e6%9c%9b_%e8%82%96%e6%b5%a9-18.png" alt=""  />
</p>
<br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>金融研究 | 央行货币政策文本相似度计算与可视化</title>
      <link>https://textdata.cn/blog/2023-01-10-similarity_of_cental_bank_monetary_policy/</link>
      <pubDate>Tue, 10 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-01-10-similarity_of_cental_bank_monetary_policy/</guid>
      <description>本文利用金融情感词典和文本分析技术,分析中国人民银行货币政策执行报告的**文本情绪、文本相似度和文本可读性**等多维文本信息,刻画央行货币政策执行报告的文本特征,探究货币政策报告的文本信息与宏观经济和股票市场的关系。**实证研究发现,货币政策报告的文本情绪的改善会引起显著为正的股票市场价格反应, 报告文本相似度的增加会引起股票市场波动性的显著降低, 报告可读性对公布后股票市场的波动性影响不显著**。货币政策报告文本情绪还与诸多宏观经济指标显著相关。进一步研究发现,引起股票市场显著反应的是报告文本情绪中反映货币政策指引的部分,而反映宏观经济历史状态的部分对股票市场的影响不显著。本文从文本大数据分析角度证明了我国央行沟通的有效性,对国内央行沟通相关研究形成了有益补充。This paper uses text analysis techniques to analyze 71 Monetary Policy Implementation Ｒeports （ hereinafter referred to as“the reports”） of PBOC，calculates the text sentiment （ tone） ，the similarity and readability and other text indicators of the reports，and explores the relationship between these text indicators and the macro economy and the stock market． Based on the Chinese financial sentiment dictionary developed by Jiang et al． （ 2020） ，this paper uses the sentiment unit method to calculate the tone of the reports． In addition，this paper uses TF － IDF weighted cosine similarity to characterize the similarity of the reports，and uses average sentence length to characterize the readability of the reports． The paper then uses correlation analysis to examine the relationship between the tone of the reports and macroeconomic indicators such as economic growth，inflation， and interest rates． With reference to Ehrmann and Fratzscher （ 2009） ，Zhang and Hu （ 2014） ，this paper adds tone，similarity and readability to the EGAＲCH model to explore whether textual indicators of the reports affect stock market returns and the volatility on the trading day after the release． Furthermore，this paper decomposes the content of the reports into two parts： economic and financial fundamentals and central bank policy guidelines，calculates the tone of the two parts and examines their impacts on the stock market respectively．</description>
      <content:encoded><![CDATA[<p>姜富伟,胡逸驰,黄楠.<strong><a href="%E5%A4%AE%E8%A1%8C%E8%B4%A7%E5%B8%81%E6%94%BF%E7%AD%96%E6%8A%A5%E5%91%8A%E6%96%87%E6%9C%AC%E4%BF%A1%E6%81%AF%E3%80%81%E5%AE%8F%E8%A7%82%E7%BB%8F%E6%B5%8E%E4%B8%8E%E8%82%A1%E7%A5%A8%E5%B8%82%E5%9C%BA_%E5%A7%9C%E5%AF%8C%E4%BC%9F.pdf">央行货币政策报告文本信息、宏观经济与股票市场</a></strong>[J].金融研究,2021,(06):95-113.</p>
<br>
<p>摘要:本文利用金融情感词典和文本分析技术,分析中国人民银行货币政策执行报告的<strong>文本情绪、文本相似度和文本可读性</strong>等多维文本信息,刻画央行货币政策执行报告的文本特征,探究货币政策报告的文本信息与宏观经济和股票市场的关系。<strong>实证研究发现,货币政策报告的文本情绪的改善会引起显著为正的股票市场价格反应, 报告文本相似度的增加会引起股票市场波动性的显著降低, 报告可读性对公布后股票市场的波动性影响不显著</strong>。货币政策报告文本情绪还与诸多宏观经济指标显著相关。进一步研究发现,引起股票市场显著反应的是报告文本情绪中反映货币政策指引的部分,而反映宏观经济历史状态的部分对股票市场的影响不显著。本文从文本大数据分析角度证明了我国央行沟通的有效性,对国内央行沟通相关研究形成了有益补充。</p>
<br>
<p>文文相似度很好用，下图是该论文中绘制的2001-2018年间的货币政策报告<strong>文本相似度</strong>。 <strong>前后相邻两个季度的货币政策文本相似度越高，说明政策相似性高，政策连贯性强(变化小)。如果相似度较低，则政策变动的风险较大，政策连贯性差(变化大)</strong>。</p>
<p><img loading="lazy" src="img/%e8%ae%ba%e6%96%87-%e6%8a%a5%e5%91%8a%e6%96%87%e6%9c%ac%e7%9b%b8%e4%bc%bc%e5%ba%a6.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="复现相似度">复现相似度</h2>
<p>本文只实现文本相似度的度量、文本相似度趋势的可视化。</p>
<ol>
<li>准备数据</li>
<li>相似度计算</li>
<li>可视化</li>
</ol>
<p><br><br></p>
<h2 id="1-准备数据">1. 准备数据</h2>
<p>首先先手动从 <strong>中国人民银行</strong> 下载货币政策报告。</p>
<p><img loading="lazy" src="img/pbc.png" alt=""  />
</p>
<p>下图是我下载好的报告</p>
<p><img loading="lazy" src="img/pdfs.png" alt=""  />
</p>
<p>之后将其整理到csv中</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">csv</span>
<span class="kn">from</span> <span class="nn">pdfdocx</span> <span class="kn">import</span> <span class="n">read_pdf</span>


<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;pbc_reports.csv&#39;</span><span class="p">,</span> <span class="s1">&#39;a+&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">,</span> <span class="n">newline</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">csvf</span><span class="p">:</span>
    <span class="c1">#年份、季度、报告文本</span>
    <span class="n">fieldnames</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;year&#39;</span><span class="p">,</span> <span class="s1">&#39;q&#39;</span><span class="p">,</span> <span class="s1">&#39;text&#39;</span><span class="p">]</span>
    <span class="n">writer</span> <span class="o">=</span> <span class="n">csv</span><span class="o">.</span><span class="n">DictWriter</span><span class="p">(</span><span class="n">csvf</span><span class="p">,</span> <span class="n">fieldnames</span><span class="o">=</span><span class="n">fieldnames</span><span class="p">)</span>
    <span class="n">writer</span><span class="o">.</span><span class="n">writeheader</span><span class="p">()</span>

    <span class="n">pdfs</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;data/</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">f</span><span class="p">)</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="s1">&#39;data&#39;</span><span class="p">)]</span>
    <span class="k">for</span> <span class="n">pf</span> <span class="ow">in</span> <span class="n">pdfs</span><span class="p">:</span>
        <span class="n">data</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s1">&#39;year&#39;</span><span class="p">:</span>  <span class="n">pf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;/&#39;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">][:</span><span class="mi">4</span><span class="p">],</span>
            <span class="s1">&#39;q&#39;</span><span class="p">:</span>  <span class="n">pf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;/&#39;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="mi">5</span><span class="p">],</span>
            <span class="s1">&#39;text&#39;</span><span class="p">:</span> <span class="n">read_pdf</span><span class="p">(</span><span class="s1">&#39;data/2013-3.pdf&#39;</span><span class="p">),</span>
        <span class="p">}</span>
        <span class="n">writer</span><span class="o">.</span><span class="n">writerow</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</code></pre></div><p><br><br></p>
<h2 id="2-读取数据">2. 读取数据</h2>
<p>下载pdf时，遗漏了货币政策报告日期数据，将 pbc_reports.csv 修改为 pbc_reports.xlsx ，增加了 date 字段。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_excel</span><span class="p">(</span><span class="s1">&#39;pbc_reports.xlsx&#39;</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<p><img loading="lazy" src="img/df1.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#让每一行含有前后两个季度的报告文本</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;text2&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shift</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<p><img loading="lazy" src="img/df2.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="3-计算相似度">3. 计算相似度</h2>
<p>水平(行)方向，计算每一行中的 text 与 text2 两者的文本相似度。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>

<span class="k">def</span> <span class="nf">cosine_similarity</span><span class="p">(</span><span class="n">row</span><span class="p">):</span>
    <span class="c1">#row 为 pd.Series 类型数据，类似于字段</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">sim</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">cosine_sim</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">],</span> <span class="n">row</span><span class="p">[</span><span class="s1">&#39;text2&#39;</span><span class="p">])</span>
        <span class="k">return</span> <span class="nb">float</span><span class="p">(</span><span class="n">sim</span><span class="p">)</span>
    <span class="k">except</span><span class="p">:</span>
        <span class="c1">#异常标记为1</span>
        <span class="k">return</span> <span class="mi">1</span>

<span class="c1">#计算结果存储到 similarity 字段中</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;similarity&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">row</span><span class="p">:</span> <span class="n">cosine_similarity</span><span class="p">(</span><span class="n">row</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<p><img loading="lazy" src="img/df3.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="4-绘制折线图">4. 绘制折线图</h2>
<p>这里为了方便，使用 pandas_bokeh 库。 注意: 绘图不限于Python，各位也可以用excel、R。</p>
<p>参数:</p>
<ul>
<li>kind 图表类型，折线图line</li>
<li>x 横轴字段</li>
<li>y 纵轴字段</li>
<li>xlabel 横轴标签</li>
<li>ylabel 纵轴标签</li>
<li>title 图标题</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas_bokeh</span>

<span class="n">pandas_bokeh</span><span class="o">.</span><span class="n">output_notebook</span><span class="p">()</span>

<span class="c1">#选择折线图line</span>
<span class="c1">#</span>
<span class="n">df</span><span class="o">.</span><span class="n">plot_bokeh</span><span class="p">(</span><span class="n">kind</span> <span class="o">=</span> <span class="s1">&#39;line&#39;</span><span class="p">,</span>
              <span class="n">x</span> <span class="o">=</span> <span class="s1">&#39;date&#39;</span><span class="p">,</span>
              <span class="n">y</span> <span class="o">=</span> <span class="s1">&#39;similarity&#39;</span><span class="p">,</span>
              <span class="n">title</span> <span class="o">=</span> <span class="s1">&#39;2001~2022央行货币政策相似度趋势&#39;</span><span class="p">,</span>
              <span class="n">xlabel</span> <span class="o">=</span> <span class="s1">&#39;报告发布日期&#39;</span><span class="p">,</span>
              <span class="n">ylabel</span> <span class="o">=</span> <span class="s1">&#39;相似度&#39;</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<p><img loading="lazy" src="img/%e5%9b%be1.png" alt=""  />
</p>
<br>
<p>刚刚生成的图没有经过移动平滑处理，所以锯齿比较多。论文中使用三季度移动平均线处理了 similarity ，我在此将其命名为 ma3_similarity</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas_bokeh</span>

<span class="n">pandas_bokeh</span><span class="o">.</span><span class="n">output_notebook</span><span class="p">()</span>

<span class="c1">#三季度移动平均线</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;ma3_similarity&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;similarity&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">rolling</span><span class="p">(</span><span class="n">window</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">center</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">min_periods</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

<span class="n">df</span><span class="o">.</span><span class="n">plot_bokeh</span><span class="p">(</span><span class="n">kind</span> <span class="o">=</span> <span class="s1">&#39;line&#39;</span><span class="p">,</span>
              <span class="n">x</span> <span class="o">=</span> <span class="s1">&#39;date&#39;</span><span class="p">,</span>
              <span class="n">y</span> <span class="o">=</span> <span class="s1">&#39;ma3_similarity&#39;</span><span class="p">,</span>
              <span class="n">title</span> <span class="o">=</span> <span class="s1">&#39;2001~2022央行货币政策相似度趋势&#39;</span><span class="p">,</span>
              <span class="n">xlabel</span> <span class="o">=</span> <span class="s1">&#39;报告发布日期&#39;</span><span class="p">,</span>
              <span class="n">ylabel</span> <span class="o">=</span> <span class="s1">&#39;相似度&#39;</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<p><img loading="lazy" src="img/%e5%9b%be2.png" alt=""  />
</p>
<p><br>基本复刻论文原图相似度的变化趋势</p>
<p><img loading="lazy" src="img/%e8%ae%ba%e6%96%87-%e6%8a%a5%e5%91%8a%e6%96%87%e6%9c%ac%e7%9b%b8%e4%bc%bc%e5%ba%a6.png" alt=""  />
</p>
<br>
<p>有了相似度变化序列数据， 可以使用 ruptures库， 找到政策变化的时间点， 参考 <a href="https://textdata.cn/blog/2023-11-26-using-ruptures-to-detect-change-point/">使用 Ruptures 识别时间序列数据中的变化点</a></p>
<p><br><br></p>
<h2 id="代码下载">代码下载</h2>
<ul>
<li>代码及视频讲解已经添加至 <a href="https://textdata.cn/blog/management_python_course/">支持开票 | Python实证指标构建与文本分析</a>  中，感兴趣的同学欢迎订阅该系列课，涵盖Python语法入门、数据采集、文本分析、机器学习等。</li>
<li>未订阅 <a href="https://textdata.cn/blog/management_python_course/">支持开票 | Python实证指标构建与文本分析</a> 的朋友们，可转发本文集赞30+， 加微信 <strong>372335839</strong> ， 备注「<strong>姓名-学校-专业-央行相似度</strong>」，获取本文数据及代码。</li>
</ul>
<p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>转载 | 大数据驱动的「社会经济地位」分析研究综述</title>
      <link>https://textdata.cn/blog/2022-12-30-review-about-socioeconomic-status-analysis/</link>
      <pubDate>Fri, 30 Dec 2022 00:00:00 +0000</pubDate>
      
      <guid>/blog/2022-12-30-review-about-socioeconomic-status-analysis/</guid>
      <description>大数据和机器学习技术的发展极大地促进了社 会经济地位的分析以及相关应用。 本文对应用于推断社会属性的大数据方法进行了全面的回顾,并系统地介绍了相应方法以及得到广泛使用的基准测试程序以及资源。 本文旨在提供 一份简洁、清晰的大数据方法应用于社会经济属性分析的概述,其不仅可以为对该方面感兴趣的读者提供帮助,而且可以为继续在该领域工作的研究人员和工程技术人员提供参考。</description>
      <content:encoded><![CDATA[<br>
<p>么晓明, 丁世昌, 赵涛, 黄宏, 罗家德, and 傅晓明. &ldquo;<strong>大数据驱动的社会经济地位分析研究综述</strong>.&rdquo; <em>计算机科学</em> 49, no. 4 (2022): 80-87.</p>
<br>
<p><img loading="lazy" src="img/%e5%a4%a7%e6%95%b0%e6%8d%ae%e9%a9%b1%e5%8a%a8%e7%9a%84%e7%a4%be%e4%bc%9a%e7%bb%8f%e6%b5%8e%e5%9c%b0%e4%bd%8d%e5%88%86%e6%9e%90%e7%a0%94%e7%a9%b6%e7%bb%bc%e8%bf%b0-2.png" alt=""  />

<img loading="lazy" src="img/%e5%a4%a7%e6%95%b0%e6%8d%ae%e9%a9%b1%e5%8a%a8%e7%9a%84%e7%a4%be%e4%bc%9a%e7%bb%8f%e6%b5%8e%e5%9c%b0%e4%bd%8d%e5%88%86%e6%9e%90%e7%a0%94%e7%a9%b6%e7%bb%bc%e8%bf%b0-3.png" alt=""  />

<img loading="lazy" src="img/%e5%a4%a7%e6%95%b0%e6%8d%ae%e9%a9%b1%e5%8a%a8%e7%9a%84%e7%a4%be%e4%bc%9a%e7%bb%8f%e6%b5%8e%e5%9c%b0%e4%bd%8d%e5%88%86%e6%9e%90%e7%a0%94%e7%a9%b6%e7%bb%bc%e8%bf%b0-4.png" alt=""  />

<img loading="lazy" src="img/%e5%a4%a7%e6%95%b0%e6%8d%ae%e9%a9%b1%e5%8a%a8%e7%9a%84%e7%a4%be%e4%bc%9a%e7%bb%8f%e6%b5%8e%e5%9c%b0%e4%bd%8d%e5%88%86%e6%9e%90%e7%a0%94%e7%a9%b6%e7%bb%bc%e8%bf%b0-5.png" alt=""  />

<img loading="lazy" src="img/%e5%a4%a7%e6%95%b0%e6%8d%ae%e9%a9%b1%e5%8a%a8%e7%9a%84%e7%a4%be%e4%bc%9a%e7%bb%8f%e6%b5%8e%e5%9c%b0%e4%bd%8d%e5%88%86%e6%9e%90%e7%a0%94%e7%a9%b6%e7%bb%bc%e8%bf%b0-6.png" alt=""  />

<img loading="lazy" src="img/%e5%a4%a7%e6%95%b0%e6%8d%ae%e9%a9%b1%e5%8a%a8%e7%9a%84%e7%a4%be%e4%bc%9a%e7%bb%8f%e6%b5%8e%e5%9c%b0%e4%bd%8d%e5%88%86%e6%9e%90%e7%a0%94%e7%a9%b6%e7%bb%bc%e8%bf%b0-7.png" alt=""  />
</p>
<br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>数据集 | 585w企业工商注册信息</title>
      <link>https://textdata.cn/blog/2022-12-07-585w-chinese-enterprise-registration-data/</link>
      <pubDate>Tue, 06 Dec 2022 00:00:00 +0000</pubDate>
      
      <guid>/blog/2022-12-07-585w-chinese-enterprise-registration-data/</guid>
      <description>585w企业工商注册信息</description>
      <content:encoded><![CDATA[<p>1978-2019.4,  585w中国大陆企业注册信息</p>
<p>文末有 enterprise-registration-data-of-chinese-mainland.csv 数据获取方式。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;enterprise-registration-data-of-chinese-mainland.csv&#39;</span><span class="p">,</span> 
                 <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">,</span> 
                 <span class="c1">#忽略有问题的记录</span>
                 <span class="n">on_bad_lines</span><span class="o">=</span><span class="s1">&#39;skip&#39;</span><span class="p">)</span>

<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<p><img loading="lazy" src="img/df1.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#剔除大邓广告</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;企业类型&#39;</span><span class="p">]</span><span class="o">!=</span><span class="s1">&#39;公众号: 大邓和他的Python&#39;</span><span class="p">]</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<p><img loading="lazy" src="img/df2.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#记录</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;记录数: &#39;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">))</span>

<span class="c1">#</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;字段有: &#39;</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">&#39;记录数: 12756270&#39;

&#39;字段有: [&#39;企业名称&#39;, &#39;统一社会信用代码&#39;, &#39;注册日期&#39;, &#39;企业类型&#39;, &#39;法人代表&#39;, &#39;注册资金&#39;, &#39;经营范围&#39;, &#39;所在省份&#39;,
       &#39;地区&#39;, &#39;注册地址&#39;]&#39;
</code></pre></div><br>
<p>但数据可能会有重复，这里以企业名称作为唯一标识，可以查看真实的数据量</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;真实记录数: &#39;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;企业名称&#39;</span><span class="p">])))</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">&#39;真实记录数: 5888382&#39;
</code></pre></div><br>
<br>
<h2 id="二如何将多个csv汇总到一个csv中">二、如何将多个csv汇总到一个csv中？</h2>
<p>那么这个enterprise-registration-data-of-chinese-mainland.csv怎么来的？</p>
<p>原始的数据集结构</p>
<p><img loading="lazy" src="img/screen-1.png" alt=""  />

<img loading="lazy" src="img/screen-2.png" alt=""  />
</p>
<br>
<p>先局部实验成功后，推广到整体。</p>
<ol>
<li>获取路径列表</li>
<li>尝试读取任意一个csv文件</li>
<li>尝试合并两个df</li>
<li>合并所有csv到一个文件内</li>
</ol>
<br>
<h3 id="21-获取路径列表">2.1 获取路径列表</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">os</span>

<span class="c1">#大邓电脑为Mac</span>
<span class="c1">#Mac容易在文件夹中生成奇怪的.DS_Store</span>
<span class="c1">#该操作为获取文件夹列表，同时剔除.DS_Store</span>
<span class="n">y_dirs</span> <span class="o">=</span> <span class="p">[</span><span class="n">di</span> <span class="k">for</span> <span class="n">di</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="s1">&#39;csv&#39;</span><span class="p">)</span> <span class="k">if</span> <span class="s1">&#39;.DS_Store&#39;</span><span class="o">!=</span><span class="n">di</span><span class="p">]</span>
<span class="k">for</span> <span class="n">y_dir</span> <span class="ow">in</span> <span class="n">y_dirs</span><span class="p">:</span>
    <span class="c1">#在年份文件夹内有很多csv文件</span>
    <span class="n">fs</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;csv/</span><span class="si">{}</span><span class="s1">/</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">y_dir</span><span class="p">,</span> <span class="n">fn</span><span class="p">)</span> 
          <span class="k">for</span> <span class="n">fn</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="s1">&#39;csv/</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">y_dir</span><span class="p">))</span>
          <span class="k">if</span> <span class="s1">&#39;.csv&#39;</span> <span class="ow">in</span> <span class="n">fn</span><span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">fs</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">......
......
[&#39;csv/2013/河南.csv&#39;, &#39;csv/2013/青海.csv&#39;, &#39;csv/2013/河北.csv&#39;, &#39;csv/2013/浙江.csv&#39;, &#39;csv/2013/内蒙古.csv&#39;, &#39;csv/2013/辽宁.csv&#39;, &#39;csv/2013/天津.csv&#39;, &#39;csv/2013/福建.csv&#39;, &#39;csv/2013/吉林.csv&#39;, &#39;csv/2013/西藏.csv&#39;, &#39;csv/2013/四川.csv&#39;, &#39;csv/2013/云南.csv&#39;, &#39;csv/2013/宁夏.csv&#39;, &#39;csv/2013/新疆.csv&#39;, &#39;csv/2013/安徽.csv&#39;, &#39;csv/2013/重庆.csv&#39;, &#39;csv/2013/贵州.csv&#39;, &#39;csv/2013/湖南.csv&#39;, &#39;csv/2013/海南.csv&#39;, &#39;csv/2013/湖北.csv&#39;, &#39;csv/2013/江西.csv&#39;, &#39;csv/2013/广东.csv&#39;, &#39;csv/2013/北京.csv&#39;, &#39;csv/2013/山西.csv&#39;, &#39;csv/2013/上海.csv&#39;, &#39;csv/2013/陕西.csv&#39;, &#39;csv/2013/黑龙江.csv&#39;, &#39;csv/2013/甘肃.csv&#39;, &#39;csv/2013/江苏.csv&#39;, &#39;csv/2013/山东.csv&#39;, &#39;csv/2013/广西.csv&#39;]

[&#39;csv/2014/河南.csv&#39;, &#39;csv/2014/青海.csv&#39;, &#39;csv/2014/河北.csv&#39;, &#39;csv/2014/浙江.csv&#39;, &#39;csv/2014/内蒙古.csv&#39;, &#39;csv/2014/辽宁.csv&#39;, &#39;csv/2014/天津.csv&#39;, &#39;csv/2014/福建.csv&#39;, &#39;csv/2014/吉林.csv&#39;, &#39;csv/2014/西藏.csv&#39;, &#39;csv/2014/四川.csv&#39;, &#39;csv/2014/云南.csv&#39;, &#39;csv/2014/宁夏.csv&#39;, &#39;csv/2014/新疆.csv&#39;, &#39;csv/2014/安徽.csv&#39;, &#39;csv/2014/重庆.csv&#39;, &#39;csv/2014/贵州.csv&#39;, &#39;csv/2014/湖南.csv&#39;, &#39;csv/2014/海南.csv&#39;, &#39;csv/2014/湖北.csv&#39;, &#39;csv/2014/江西.csv&#39;, &#39;csv/2014/广东.csv&#39;, &#39;csv/2014/北京.csv&#39;, &#39;csv/2014/山西.csv&#39;, &#39;csv/2014/上海.csv&#39;, &#39;csv/2014/陕西.csv&#39;, &#39;csv/2014/黑龙江.csv&#39;, &#39;csv/2014/甘肃.csv&#39;, &#39;csv/2014/江苏.csv&#39;, &#39;csv/2014/山东.csv&#39;, &#39;csv/2014/广西.csv&#39;]

[&#39;csv/2015/河南.csv&#39;, &#39;csv/2015/青海.csv&#39;, &#39;csv/2015/河北.csv&#39;, &#39;csv/2015/浙江.csv&#39;, &#39;csv/2015/内蒙古.csv&#39;, &#39;csv/2015/辽宁.csv&#39;, &#39;csv/2015/天津.csv&#39;, &#39;csv/2015/福建.csv&#39;, &#39;csv/2015/吉林.csv&#39;, &#39;csv/2015/西藏.csv&#39;, &#39;csv/2015/四川.csv&#39;, &#39;csv/2015/云南.csv&#39;, &#39;csv/2015/宁夏.csv&#39;, &#39;csv/2015/新疆.csv&#39;, &#39;csv/2015/安徽.csv&#39;, &#39;csv/2015/重庆.csv&#39;, &#39;csv/2015/贵州.csv&#39;, &#39;csv/2015/湖南.csv&#39;, &#39;csv/2015/海南.csv&#39;, &#39;csv/2015/湖北.csv&#39;, &#39;csv/2015/江西.csv&#39;, &#39;csv/2015/广东.csv&#39;, &#39;csv/2015/北京.csv&#39;, &#39;csv/2015/山西.csv&#39;, &#39;csv/2015/上海.csv&#39;, &#39;csv/2015/陕西.csv&#39;, &#39;csv/2015/黑龙江.csv&#39;, &#39;csv/2015/甘肃.csv&#39;, &#39;csv/2015/江苏.csv&#39;, &#39;csv/2015/山东.csv&#39;, &#39;csv/2015/广西.csv&#39;]

.....
.....
</code></pre></div><p><br><br></p>
<h3 id="22-尝试读取任意一个csv文件">2.2 尝试读取任意一个csv文件</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">df1</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;csv/2012/辽宁.csv&#39;</span><span class="p">,</span> 
                  <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">,</span> 
                  <span class="n">on_bad_lines</span><span class="o">=</span><span class="s1">&#39;skip&#39;</span><span class="p">)</span>

<span class="n">df1</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<p><img loading="lazy" src="img/df3.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df2</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;csv/2013/青海.csv&#39;</span><span class="p">,</span> 
                  <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">,</span> 
                  <span class="n">on_bad_lines</span><span class="o">=</span><span class="s1">&#39;skip&#39;</span><span class="p">)</span>

<span class="n">df2</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<p><img loading="lazy" src="img/df4.png" alt=""  />
</p>
<br>
<h3 id="23-尝试合并两个df">2.3 尝试合并两个df</h3>
<p>两个df垂直方向堆积，不增加字段种类，所以选择 pd.concat函数。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df12</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">df1</span><span class="p">,</span> <span class="n">df2</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">df12</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<p><img loading="lazy" src="img/df3.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#检查记录数</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">df1</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">df2</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">df12</span><span class="p">))</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">10246
4417
14663
</code></pre></div><br>
<h3 id="24-合并所有csv到一个文件内">2.4 合并所有csv到一个文件内</h3>
<p>将步骤1、2、3代码整理，汇总</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="c1">#存df列表</span>
<span class="n">dfs</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1">#文件路径列表</span>
<span class="n">y_dirs</span> <span class="o">=</span> <span class="p">[</span><span class="n">di</span> <span class="k">for</span> <span class="n">di</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="s1">&#39;csv&#39;</span><span class="p">)</span> <span class="k">if</span> <span class="s1">&#39;.DS_Store&#39;</span><span class="o">!=</span><span class="n">di</span><span class="p">]</span>
<span class="k">for</span> <span class="n">y_dir</span> <span class="ow">in</span> <span class="n">y_dirs</span><span class="p">:</span>
    <span class="n">csvfs</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;csv/</span><span class="si">{}</span><span class="s1">/</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">y_dir</span><span class="p">,</span> <span class="n">fn</span><span class="p">)</span> 
             <span class="k">for</span> <span class="n">fn</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="s1">&#39;csv/</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">y_dir</span><span class="p">))</span>
             <span class="k">if</span> <span class="s1">&#39;.csv&#39;</span> <span class="ow">in</span> <span class="n">fn</span><span class="p">]</span>
    
    <span class="k">for</span> <span class="n">csvf</span> <span class="ow">in</span> <span class="n">csvfs</span><span class="p">:</span>
        
        <span class="c1">#读取csv，得到df</span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">csvf</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">,</span> <span class="n">on_bad_lines</span><span class="o">=</span><span class="s1">&#39;skip&#39;</span><span class="p">)</span>
        <span class="c1">#存入df列表</span>
        <span class="n">dfs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
        
<span class="c1">#合并dfs为alldf</span>
<span class="n">alldf</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">dfs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1">#导出为data.csv</span>
<span class="n">alldf</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;enterprise-registration-data-of-chinese-mainland.csv&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</code></pre></div><p><br><br></p>
<h2 id="三数据获取">三、数据获取</h2>
<p>转发本文至朋友圈集赞50+， 加微信372335839， 备注【姓名-学校-专业-1200w工商】获取本文数据。</p>
<p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>BERTopic | 使用推特数据构建动态主题模型</title>
      <link>https://textdata.cn/blog/2022-12-03-dynamic_topic_model_with_bertopic/</link>
      <pubDate>Sun, 04 Dec 2022 00:00:00 +0000</pubDate>
      
      <guid>/blog/2022-12-03-dynamic_topic_model_with_bertopic/</guid>
      <description>在本文中将使用BERTopic库，对美国前总统Trump推特数据集，构建动态主题模型DTM(Dynamic Topic Modeling)，可视化文档数据集中不同主题随时间的演变(变迁)。</description>
      <content:encoded><![CDATA[<p>在本文中将使用 BERTopic 库，对美国前总统 Trump 推特数据集，构建动态主题模型 DTM(Dynamic Topic Modeling)，可视化文档数据集中不同主题随时间的演变(变迁)。<strong>文末有代码下载方式</strong></p>
<br>
<h2 id="安装">安装</h2>
<p>为保证代码可复现，保证你我电脑中 bertopic 版本一致，先查看大邓电脑的 bertopic 版本</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">bertopic</span>

<span class="c1">#本文bertopic版本</span>
<span class="n">bertopic</span><span class="o">.</span><span class="n">__version__</span>
</code></pre></div><p>Run</p>
<pre><code>'0.12.0'
</code></pre>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#推荐指定版本安装；</span>
<span class="c1">#!pip3 install bertopic==0.12.0</span>

<span class="c1">#不指定版本安装</span>
<span class="err">!</span><span class="n">pip3</span> <span class="n">install</span> <span class="n">bertopic</span>
</code></pre></div><br>
<h2 id="导入数据">导入数据</h2>
<p>这里准备了twitter账号 @realDonalTrump 中 2021年的推特数据，  点击下载 <a href="code.zip"><strong>数据及代码</strong></a>。</p>
<ul>
<li>我们只分析原推特，不分析每条推特的回复。</li>
<li>因为要分析推特随时间的主题变化，需要准备 <strong>推特</strong> 及对应的 <strong>推文时间</strong></li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">re</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">datetime</span>

<span class="c1"># 导入数据</span>
<span class="n">trump_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;trump_twitter_2021.csv&#39;</span><span class="p">)</span>
<span class="n">trump_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-html" data-lang="html"><span class="p">&lt;</span><span class="nt">div</span><span class="p">&gt;</span>
<span class="p">&lt;</span><span class="nt">style</span> <span class="na">scoped</span><span class="p">&gt;</span>
    <span class="p">.</span><span class="nc">dataframe</span> <span class="nt">tbody</span> <span class="nt">tr</span> <span class="nt">th</span><span class="p">:</span><span class="nd">only-of-type</span> <span class="p">{</span>
        <span class="k">vertical-align</span><span class="p">:</span> <span class="kc">middle</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="p">.</span><span class="nc">dataframe</span> <span class="nt">tbody</span> <span class="nt">tr</span> <span class="nt">th</span> <span class="p">{</span>
        <span class="k">vertical-align</span><span class="p">:</span> <span class="kc">top</span><span class="p">;</span>
    <span class="p">}</span>
    
    <span class="p">.</span><span class="nc">dataframe</span> <span class="nt">thead</span> <span class="nt">th</span> <span class="p">{</span>
        <span class="k">text-align</span><span class="p">:</span> <span class="kc">right</span><span class="p">;</span>
    <span class="p">}</span>
<span class="p">&lt;/</span><span class="nt">style</span><span class="p">&gt;</span>
<span class="p">&lt;</span><span class="nt">table</span> <span class="na">border</span><span class="o">=</span><span class="s">&#34;1&#34;</span> <span class="na">class</span><span class="o">=</span><span class="s">&#34;dataframe&#34;</span><span class="p">&gt;</span>
  <span class="p">&lt;</span><span class="nt">thead</span><span class="p">&gt;</span>
    <span class="p">&lt;</span><span class="nt">tr</span> <span class="na">style</span><span class="o">=</span><span class="s">&#34;text-align: right;&#34;</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">th</span><span class="p">&gt;&lt;/</span><span class="nt">th</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">th</span><span class="p">&gt;</span>id<span class="p">&lt;/</span><span class="nt">th</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">th</span><span class="p">&gt;</span>text<span class="p">&lt;/</span><span class="nt">th</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">th</span><span class="p">&gt;</span>isRetweet<span class="p">&lt;/</span><span class="nt">th</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">th</span><span class="p">&gt;</span>isDeleted<span class="p">&lt;/</span><span class="nt">th</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">th</span><span class="p">&gt;</span>device<span class="p">&lt;/</span><span class="nt">th</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">th</span><span class="p">&gt;</span>favorites<span class="p">&lt;/</span><span class="nt">th</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">th</span><span class="p">&gt;</span>retweets<span class="p">&lt;/</span><span class="nt">th</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">th</span><span class="p">&gt;</span>date<span class="p">&lt;/</span><span class="nt">th</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">th</span><span class="p">&gt;</span>isFlagged<span class="p">&lt;/</span><span class="nt">th</span><span class="p">&gt;</span>
    <span class="p">&lt;/</span><span class="nt">tr</span><span class="p">&gt;</span>
  <span class="p">&lt;/</span><span class="nt">thead</span><span class="p">&gt;</span>
  <span class="p">&lt;</span><span class="nt">tbody</span><span class="p">&gt;</span>
    <span class="p">&lt;</span><span class="nt">tr</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">th</span><span class="p">&gt;</span>0<span class="p">&lt;/</span><span class="nt">th</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>98454970654916608<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>Republicans and Democrats have both created ou...<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>f<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>f<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>TweetDeck<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>49<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>255<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>2011-08-02 18:07:48<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>f<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
    <span class="p">&lt;/</span><span class="nt">tr</span><span class="p">&gt;</span>
    <span class="p">&lt;</span><span class="nt">tr</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">th</span><span class="p">&gt;</span>1<span class="p">&lt;/</span><span class="nt">th</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>1234653427789070336<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>I was thrilled to be back in the Great city of...<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>f<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>f<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>Twitter for iPhone<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>73748<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>17404<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>2020-03-03 01:34:50<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>f<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
    <span class="p">&lt;/</span><span class="nt">tr</span><span class="p">&gt;</span>
    <span class="p">&lt;</span><span class="nt">tr</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">th</span><span class="p">&gt;</span>2<span class="p">&lt;/</span><span class="nt">th</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>1218010753434820614<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>RT @CBS_Herridge: READ: Letter to surveillance...<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>t<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>f<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>Twitter for iPhone<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>0<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>7396<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>2020-01-17 03:22:47<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>f<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
    <span class="p">&lt;/</span><span class="nt">tr</span><span class="p">&gt;</span>
    <span class="p">&lt;</span><span class="nt">tr</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">th</span><span class="p">&gt;</span>3<span class="p">&lt;/</span><span class="nt">th</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>1304875170860015617<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>The Unsolicited Mail In Ballot Scam is a major...<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>f<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>f<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>Twitter for iPhone<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>80527<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>23502<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>2020-09-12 20:10:58<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>f<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
    <span class="p">&lt;/</span><span class="nt">tr</span><span class="p">&gt;</span>
    <span class="p">&lt;</span><span class="nt">tr</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">th</span><span class="p">&gt;</span>4<span class="p">&lt;/</span><span class="nt">th</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>1218159531554897920<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>RT @MZHemingway: Very friendly telling of even...<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>t<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>f<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>Twitter for iPhone<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>0<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>9081<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>2020-01-17 13:13:59<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>f<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
    <span class="p">&lt;/</span><span class="nt">tr</span><span class="p">&gt;</span>
  <span class="p">&lt;/</span><span class="nt">tbody</span><span class="p">&gt;</span>
<span class="p">&lt;/</span><span class="nt">table</span><span class="p">&gt;</span>
<span class="p">&lt;/</span><span class="nt">div</span><span class="p">&gt;</span>
</code></pre></div><br>
<h2 id="预处理">预处理</h2>
<ul>
<li>使用正则表达式 清除推文中的http链接</li>
<li>剔除@符</li>
<li>使用正则表达式 剔除 非英文字符</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">re</span>

<span class="c1">#预处理函数clean_text</span>
<span class="k">def</span> <span class="nf">clean_text</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s2">&#34;http\S+&#34;</span><span class="p">,</span> <span class="s2">&#34;&#34;</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
    <span class="n">text</span> <span class="o">=</span> <span class="s2">&#34; &#34;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">w</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">text</span><span class="o">.</span><span class="n">split</span><span class="p">()</span> <span class="k">if</span> <span class="n">w</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">!=</span><span class="s1">&#39;@&#39;</span><span class="p">])</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s2">&#34;[^a-zA-Z]+&#34;</span><span class="p">,</span> <span class="s2">&#34; &#34;</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">text</span>


<span class="n">test_text</span> <span class="o">=</span> <span class="s1">&#39;hello @Apple, https://apple.com 李John&#39;</span>
<span class="c1">#验证函数有效性</span>
<span class="n">clean_text</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="n">test_text</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<pre><code>'hello john'
</code></pre>
<br>
<ul>
<li>对text字段使用预处理函数 clean_text</li>
<li>只保留原推文</li>
<li>准备推特tweets和时间戳 timestamps</li>
</ul>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#清洗字段text</span>
<span class="n">trump_df</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">trump_df</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">clean_text</span><span class="p">)</span>

<span class="c1">#只保留特朗普原推文(剔除特朗普的Retweet)</span>
<span class="c1">#推文内容不能为”“</span>
<span class="n">trump_df</span> <span class="o">=</span> <span class="n">trump_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[(</span><span class="n">trump_df</span><span class="p">[</span><span class="s1">&#39;isRetweet&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&#34;f&#34;</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">trump_df</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">]</span> <span class="o">!=</span> <span class="s2">&#34;&#34;</span><span class="p">),</span> <span class="p">:]</span>

<span class="c1">#准备tweets及对应的timestamps</span>
<span class="n">tweets</span> <span class="o">=</span> <span class="n">trump_df</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">to_list</span><span class="p">()</span>
<span class="n">timestamps</span> <span class="o">=</span> <span class="n">trump_df</span><span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">to_list</span><span class="p">()</span>

<span class="n">tweets</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</code></pre></div><p>Run</p>
<pre><code>'republicans and democrats have both created our economic problems '
</code></pre>
<br>
<h2 id="初始化bertopic">初始化BERTopic</h2>
<p>在模型初始化阶段，使用所有推文数据， 会忽略时间维度。 该步骤会把所有时间段中出现的主题都提前训练识别出来。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">bertopic</span> <span class="kn">import</span> <span class="n">BERTopic</span>

<span class="c1">#大邓这里，运行了不到1小时</span>
<span class="c1">#特朗普比较活跃，什么内容都会参与，所以这里设置一个话题数下限为35，话题数上限不设置</span>
<span class="n">topic_model</span> <span class="o">=</span> <span class="n">BERTopic</span><span class="p">(</span><span class="n">min_topic_size</span><span class="o">=</span><span class="mi">35</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">topics</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">topic_model</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">tweets</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">    Downloading:   0%|          | 0.00/1.18k [00:00&lt;?, ?B/s]
    Downloading:   0%|          | 0.00/190 [00:00&lt;?, ?B/s]
    Downloading:   0%|          | 0.00/10.6k [00:00&lt;?, ?B/s]
    Downloading:   0%|          | 0.00/612 [00:00&lt;?, ?B/s]
    Downloading:   0%|          | 0.00/116 [00:00&lt;?, ?B/s]
    Downloading:   0%|          | 0.00/39.3k [00:00&lt;?, ?B/s]
    Downloading:   0%|          | 0.00/349 [00:00&lt;?, ?B/s]
    Downloading:   0%|          | 0.00/90.9M [00:00&lt;?, ?B/s]
    Downloading:   0%|          | 0.00/53.0 [00:00&lt;?, ?B/s]
    Downloading:   0%|          | 0.00/112 [00:00&lt;?, ?B/s]
    Downloading:   0%|          | 0.00/466k [00:00&lt;?, ?B/s]
    Downloading:   0%|          | 0.00/350 [00:00&lt;?, ?B/s]
    Downloading:   0%|          | 0.00/13.2k [00:00&lt;?, ?B/s]
    Downloading:   0%|          | 0.00/232k [00:00&lt;?, ?B/s]
    Batches:   0%|          | 0/1418 [00:00&lt;?, ?it/s]

    2022-12-04 22:04:02,964 - BERTopic - Transformed documents to Embeddings
    2022-12-04 22:05:13,606 - BERTopic - Reduced dimensionality
    2022-12-04 22:05:17,814 - BERTopic - Clustered reduced embeddings
</code></pre></div><br>
<p>抽取出所有的话题</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">freq</span> <span class="o">=</span> <span class="n">topic_model</span><span class="o">.</span><span class="n">get_topic_info</span><span class="p">()</span>

<span class="c1">#话题总数</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">freq</span><span class="p">))</span>
<span class="n">freq</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">    169
</code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-html" data-lang="html"><span class="p">&lt;</span><span class="nt">div</span><span class="p">&gt;</span>
<span class="p">&lt;</span><span class="nt">style</span> <span class="na">scoped</span><span class="p">&gt;</span>
    <span class="p">.</span><span class="nc">dataframe</span> <span class="nt">tbody</span> <span class="nt">tr</span> <span class="nt">th</span><span class="p">:</span><span class="nd">only-of-type</span> <span class="p">{</span>
        <span class="k">vertical-align</span><span class="p">:</span> <span class="kc">middle</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="p">.</span><span class="nc">dataframe</span> <span class="nt">tbody</span> <span class="nt">tr</span> <span class="nt">th</span> <span class="p">{</span>
        <span class="k">vertical-align</span><span class="p">:</span> <span class="kc">top</span><span class="p">;</span>
    <span class="p">}</span>
    
    <span class="p">.</span><span class="nc">dataframe</span> <span class="nt">thead</span> <span class="nt">th</span> <span class="p">{</span>
        <span class="k">text-align</span><span class="p">:</span> <span class="kc">right</span><span class="p">;</span>
    <span class="p">}</span>
<span class="p">&lt;/</span><span class="nt">style</span><span class="p">&gt;</span>
<span class="p">&lt;</span><span class="nt">table</span> <span class="na">border</span><span class="o">=</span><span class="s">&#34;1&#34;</span> <span class="na">class</span><span class="o">=</span><span class="s">&#34;dataframe&#34;</span><span class="p">&gt;</span>
  <span class="p">&lt;</span><span class="nt">thead</span><span class="p">&gt;</span>
    <span class="p">&lt;</span><span class="nt">tr</span> <span class="na">style</span><span class="o">=</span><span class="s">&#34;text-align: right;&#34;</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">th</span><span class="p">&gt;&lt;/</span><span class="nt">th</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">th</span><span class="p">&gt;</span>Topic<span class="p">&lt;/</span><span class="nt">th</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">th</span><span class="p">&gt;</span>Count<span class="p">&lt;/</span><span class="nt">th</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">th</span><span class="p">&gt;</span>Name<span class="p">&lt;/</span><span class="nt">th</span><span class="p">&gt;</span>
    <span class="p">&lt;/</span><span class="nt">tr</span><span class="p">&gt;</span>
  <span class="p">&lt;/</span><span class="nt">thead</span><span class="p">&gt;</span>
  <span class="p">&lt;</span><span class="nt">tbody</span><span class="p">&gt;</span>
    <span class="p">&lt;</span><span class="nt">tr</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">th</span><span class="p">&gt;</span>0<span class="p">&lt;/</span><span class="nt">th</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>-1<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>15098<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>-1_the_to_is_of<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
    <span class="p">&lt;/</span><span class="nt">tr</span><span class="p">&gt;</span>
    <span class="p">&lt;</span><span class="nt">tr</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">th</span><span class="p">&gt;</span>1<span class="p">&lt;/</span><span class="nt">th</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>0<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>3182<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>0_run_president_trump_donald<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
    <span class="p">&lt;/</span><span class="nt">tr</span><span class="p">&gt;</span>
    <span class="p">&lt;</span><span class="nt">tr</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">th</span><span class="p">&gt;</span>2<span class="p">&lt;/</span><span class="nt">th</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>1<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>1821<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>1_crowd_carolina_join_thank<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
    <span class="p">&lt;/</span><span class="nt">tr</span><span class="p">&gt;</span>
    <span class="p">&lt;</span><span class="nt">tr</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">th</span><span class="p">&gt;</span>3<span class="p">&lt;/</span><span class="nt">th</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>2<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>1084<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>2_golf_course_doral_scotland<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
    <span class="p">&lt;/</span><span class="nt">tr</span><span class="p">&gt;</span>
    <span class="p">&lt;</span><span class="nt">tr</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">th</span><span class="p">&gt;</span>4<span class="p">&lt;/</span><span class="nt">th</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>3<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>1030<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>3_border_wall_immigration_mexico<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
    <span class="p">&lt;/</span><span class="nt">tr</span><span class="p">&gt;</span>
    <span class="p">&lt;</span><span class="nt">tr</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">th</span><span class="p">&gt;</span>5<span class="p">&lt;/</span><span class="nt">th</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>4<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>811<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>4_china_trade_tariffs_chinese<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
    <span class="p">&lt;/</span><span class="nt">tr</span><span class="p">&gt;</span>
    <span class="p">&lt;</span><span class="nt">tr</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">th</span><span class="p">&gt;</span>6<span class="p">&lt;/</span><span class="nt">th</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>5<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>642<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>5_obamacare_healthcare_repeal_website<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
    <span class="p">&lt;/</span><span class="nt">tr</span><span class="p">&gt;</span>
    <span class="p">&lt;</span><span class="nt">tr</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">th</span><span class="p">&gt;</span>7<span class="p">&lt;/</span><span class="nt">th</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>6<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>638<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>6_hillary_clinton_crooked_she<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
    <span class="p">&lt;/</span><span class="nt">tr</span><span class="p">&gt;</span>
    <span class="p">&lt;</span><span class="nt">tr</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">th</span><span class="p">&gt;</span>8<span class="p">&lt;/</span><span class="nt">th</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>7<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>607<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>7_amp_it_you_to<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
    <span class="p">&lt;/</span><span class="nt">tr</span><span class="p">&gt;</span>
    <span class="p">&lt;</span><span class="nt">tr</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">th</span><span class="p">&gt;</span>9<span class="p">&lt;/</span><span class="nt">th</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>8<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>562<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>8_media_fake_news_failing<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
    <span class="p">&lt;/</span><span class="nt">tr</span><span class="p">&gt;</span>
  <span class="p">&lt;/</span><span class="nt">tbody</span><span class="p">&gt;</span>
<span class="p">&lt;/</span><span class="nt">table</span><span class="p">&gt;</span>
<span class="p">&lt;/</span><span class="nt">div</span><span class="p">&gt;</span>
</code></pre></div><br>
<p>-1 意识是所有的离群点(异类)推文，应该被忽略掉。接下来让我们看一下 Topic-4 的特征词及其权重</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#topic-4的特征词及权重</span>
<span class="n">topic_model</span><span class="o">.</span><span class="n">get_topic</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">    [(&#39;china&#39;, 0.05289416225000891),
     (&#39;tariffs&#39;, 0.024471004754487165),
     (&#39;trade&#39;, 0.02437576425026641),
     (&#39;chinese&#39;, 0.013643270667358017),
     (&#39;us&#39;, 0.011206804363719649),
     (&#39;farmers&#39;, 0.01113584970813823),
     (&#39;our&#39;, 0.010197907480148342),
     (&#39;deal&#39;, 0.010014612658730073),
     (&#39;we&#39;, 0.009043537683534882),
     (&#39;countries&#39;, 0.00901653033214627)]
</code></pre></div><br>
<p>在二维空间中使用  Intertopic Distance Map 可视化所有主题。该图可以让我们继续创建 DTM 前，判断主题数设置的是否充分够用。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">fig</span> <span class="o">=</span> <span class="n">topic_model</span><span class="o">.</span><span class="n">visualize_topics</span><span class="p">()</span>
<span class="n">fig</span>
</code></pre></div><p>Run</p>
<p><img loading="lazy" src="img/topics.png" alt=""  />
</p>
<p>渲染的可视化文件太大，这里感兴趣的可以 <a href="topics.html">点击查看动态效果图</a></p>
<br>
<h2 id="构建dtm">构建DTM</h2>
<p>在 构建动态主题模型 前， 不同时间段中出现的主题需要预先都训练好。</p>
<ul>
<li>docs 文档数据，对应于本文的 tweets</li>
<li>timestamps 时间戳，对应于本文的 timestamps</li>
<li>global_tuning 是否将某个主题在 时间t 的主题表示向量 与 其全局主题表示向量 进行平均</li>
<li>evolution_tuning 是否将某个主题在 时间t 的主题表示向量 与 该主题在时间t-1 的主题表示向量 进行平均</li>
<li>nr_bins 时间段内含有的时间戳(点)数量。在数千个不同的时间戳中提取主题在计算上是低效的, 可以合并 20 个时间戳为一个时间段</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">topics_over_time</span> <span class="o">=</span> <span class="n">topic_model</span><span class="o">.</span><span class="n">topics_over_time</span><span class="p">(</span><span class="n">docs</span><span class="o">=</span><span class="n">tweets</span><span class="p">,</span> 
                                                <span class="n">timestamps</span><span class="o">=</span><span class="n">timestamps</span><span class="p">,</span> 
                                                <span class="n">global_tuning</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
                                                <span class="n">evolution_tuning</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
                                                <span class="n">nr_bins</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>

<span class="n">topics_over_time</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-html" data-lang="html"><span class="p">&lt;</span><span class="nt">div</span><span class="p">&gt;</span>
<span class="p">&lt;</span><span class="nt">style</span> <span class="na">scoped</span><span class="p">&gt;</span>
    <span class="p">.</span><span class="nc">dataframe</span> <span class="nt">tbody</span> <span class="nt">tr</span> <span class="nt">th</span><span class="p">:</span><span class="nd">only-of-type</span> <span class="p">{</span>
        <span class="k">vertical-align</span><span class="p">:</span> <span class="kc">middle</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="p">.</span><span class="nc">dataframe</span> <span class="nt">tbody</span> <span class="nt">tr</span> <span class="nt">th</span> <span class="p">{</span>
        <span class="k">vertical-align</span><span class="p">:</span> <span class="kc">top</span><span class="p">;</span>
    <span class="p">}</span>
    
    <span class="p">.</span><span class="nc">dataframe</span> <span class="nt">thead</span> <span class="nt">th</span> <span class="p">{</span>
        <span class="k">text-align</span><span class="p">:</span> <span class="kc">right</span><span class="p">;</span>
    <span class="p">}</span>
<span class="p">&lt;/</span><span class="nt">style</span><span class="p">&gt;</span>
<span class="p">&lt;</span><span class="nt">table</span> <span class="na">border</span><span class="o">=</span><span class="s">&#34;1&#34;</span> <span class="na">class</span><span class="o">=</span><span class="s">&#34;dataframe&#34;</span><span class="p">&gt;</span>
  <span class="p">&lt;</span><span class="nt">thead</span><span class="p">&gt;</span>
    <span class="p">&lt;</span><span class="nt">tr</span> <span class="na">style</span><span class="o">=</span><span class="s">&#34;text-align: right;&#34;</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">th</span><span class="p">&gt;&lt;/</span><span class="nt">th</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">th</span><span class="p">&gt;</span>Topic<span class="p">&lt;/</span><span class="nt">th</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">th</span><span class="p">&gt;</span>Words<span class="p">&lt;/</span><span class="nt">th</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">th</span><span class="p">&gt;</span>Frequency<span class="p">&lt;/</span><span class="nt">th</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">th</span><span class="p">&gt;</span>Timestamp<span class="p">&lt;/</span><span class="nt">th</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">th</span><span class="p">&gt;</span>Name<span class="p">&lt;/</span><span class="nt">th</span><span class="p">&gt;</span>
    <span class="p">&lt;/</span><span class="nt">tr</span><span class="p">&gt;</span>
  <span class="p">&lt;/</span><span class="nt">thead</span><span class="p">&gt;</span>
  <span class="p">&lt;</span><span class="nt">tbody</span><span class="p">&gt;</span>
    <span class="p">&lt;</span><span class="nt">tr</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">th</span><span class="p">&gt;</span>0<span class="p">&lt;/</span><span class="nt">th</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>-1<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>donald, keychain, champion, trump, contest<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>20<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>2009-04-30 12:30:07.596999936<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>-1_the_to_is_of<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
    <span class="p">&lt;/</span><span class="nt">tr</span><span class="p">&gt;</span>
    <span class="p">&lt;</span><span class="nt">tr</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">th</span><span class="p">&gt;</span>1<span class="p">&lt;/</span><span class="nt">th</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>0<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>donald, execute, imagination, step, randal<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>9<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>2009-04-30 12:30:07.596999936<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>0_run_president_trump_donald<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
    <span class="p">&lt;/</span><span class="nt">tr</span><span class="p">&gt;</span>
    <span class="p">&lt;</span><span class="nt">tr</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">th</span><span class="p">&gt;</span>2<span class="p">&lt;/</span><span class="nt">th</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>2<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>begun, schedule, ahead, international, scotland<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>1<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>2009-04-30 12:30:07.596999936<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>2_golf_course_doral_scotland<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
    <span class="p">&lt;/</span><span class="nt">tr</span><span class="p">&gt;</span>
    <span class="p">&lt;</span><span class="nt">tr</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">th</span><span class="p">&gt;</span>3<span class="p">&lt;/</span><span class="nt">th</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>3<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>cling, wallflower, persona, walls, rather<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>1<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>2009-04-30 12:30:07.596999936<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>3_border_wall_immigration_mexico<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
    <span class="p">&lt;/</span><span class="nt">tr</span><span class="p">&gt;</span>
    <span class="p">&lt;</span><span class="nt">tr</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">th</span><span class="p">&gt;</span>4<span class="p">&lt;/</span><span class="nt">th</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>10<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>independence, safe, here, enjoy, happy<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>1<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>2009-04-30 12:30:07.596999936<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>10_veterans_honor_heroes_our<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
    <span class="p">&lt;/</span><span class="nt">tr</span><span class="p">&gt;</span>
    <span class="p">&lt;</span><span class="nt">tr</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">th</span><span class="p">&gt;</span>...<span class="p">&lt;/</span><span class="nt">th</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>...<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>...<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>...<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>...<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>...<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
    <span class="p">&lt;/</span><span class="nt">tr</span><span class="p">&gt;</span>
    <span class="p">&lt;</span><span class="nt">tr</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">th</span><span class="p">&gt;</span>1880<span class="p">&lt;/</span><span class="nt">th</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>162<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>ratings, fredo, frank, bad, based<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>2<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>2020-06-09 07:29:57.849999872<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>162_ratings_machine_show_sided<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
    <span class="p">&lt;/</span><span class="nt">tr</span><span class="p">&gt;</span>
    <span class="p">&lt;</span><span class="nt">tr</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">th</span><span class="p">&gt;</span>1881<span class="p">&lt;/</span><span class="nt">th</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>163<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>yes, no, way, absolutely,<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>2<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>2020-06-09 07:29:57.849999872<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>163_yes_no_absolutely_way<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
    <span class="p">&lt;/</span><span class="nt">tr</span><span class="p">&gt;</span>
    <span class="p">&lt;</span><span class="nt">tr</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">th</span><span class="p">&gt;</span>1882<span class="p">&lt;/</span><span class="nt">th</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>164<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>twitter, trending, section, trends, conservative<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>13<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>2020-06-09 07:29:57.849999872<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>164_twitter_trending_conservative_sectio...<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
    <span class="p">&lt;/</span><span class="nt">tr</span><span class="p">&gt;</span>
    <span class="p">&lt;</span><span class="nt">tr</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">th</span><span class="p">&gt;</span>1883<span class="p">&lt;/</span><span class="nt">th</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>165<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>york, eaten, hell, new, blasio<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>4<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>2020-06-09 07:29:57.849999872<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>165_york_ny_new_wonerful<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
    <span class="p">&lt;/</span><span class="nt">tr</span><span class="p">&gt;</span>
    <span class="p">&lt;</span><span class="nt">tr</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">th</span><span class="p">&gt;</span>1884<span class="p">&lt;/</span><span class="nt">th</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>167<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>mixing, courthouse, mocked, notes, prosecuted<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>3<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>2020-06-09 07:29:57.849999872<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>167_jury_judge_guilty_foreperson<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
    <span class="p">&lt;/</span><span class="nt">tr</span><span class="p">&gt;</span>
  <span class="p">&lt;/</span><span class="nt">tbody</span><span class="p">&gt;</span>
<span class="p">&lt;/</span><span class="nt">table</span><span class="p">&gt;</span>
<span class="p">&lt;</span><span class="nt">p</span><span class="p">&gt;</span>1885 rows × 5 columns<span class="p">&lt;/</span><span class="nt">p</span><span class="p">&gt;</span>
<span class="p">&lt;/</span><span class="nt">div</span><span class="p">&gt;</span>
</code></pre></div><br>
<h2 id="可视化dtm">可视化DTM</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#模型中一共有169个主题，这里显示前Top10的主题的演变</span>
<span class="n">topic_model</span><span class="o">.</span><span class="n">visualize_topics_over_time</span><span class="p">(</span><span class="n">topics_over_time</span><span class="p">,</span> <span class="n">top_n_topics</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<p><img loading="lazy" src="img/dtm.png" alt=""  />

渲染的可视化文件太大，这里感兴趣的可以 <a href="dtm.html">点击查看动态效果图</a></p>
<br>
<h3 id="获取本文代码">获取本文代码</h3>
<p>点击获取 <a href="code.zip"><strong>数据及代码</strong></a></p>
<br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>JM2022综述 | 黄金领域: 为营销研究(新洞察)采集网络数据</title>
      <link>https://textdata.cn/blog/2022-12-03-scraping-web-data-for-marketing-insights/</link>
      <pubDate>Sat, 03 Dec 2022 00:00:00 +0000</pubDate>
      
      <guid>/blog/2022-12-03-scraping-web-data-for-marketing-insights/</guid>
      <description>Journal of Marketing 2022年一篇关于营销领域网络爬虫的文献综述</description>
      <content:encoded><![CDATA[<p>Boegershausen, Johannes, Hannes Datta, Abhishek Borah, and Andrew Stephen. &ldquo;Fields of gold: Scraping web data for marketing insights.&rdquo; <em>Journal of Marketing</em> (2022).</p>
<p>本文是JM中少有的技术流综述文，阅读起来晦涩难懂，我们就大概知道怎么回事， 查看有没有自己感兴趣的研究(方法)即可。该文作者为该综述专门开发了一个 web-scraping.org 的网站,截图如下</p>
<p><img loading="lazy" src="img/01-web-scraping.png" alt=""  />

<img loading="lazy" src="img/02-web-scraping.png" alt=""  />
</p>

<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
  <iframe src="https://www.youtube.com/embed/KiyFyLEkqNk" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video"></iframe>
</div>

<br>
<h2 id="摘要">摘要</h2>
<p>市场营销学者越来越多使用网络爬虫和API接口，从互联网收集数据。尽管网络数据得到广泛使用，但很少有学者关注收集过程中面临的各种挑战。<strong>研究人员如何确保采集的数据集是有效的？</strong> 虽然现有资源强调提取网络数据的技术细节，<strong>但作者提出了一种新的方法框架，重点是提高其有效性</strong>。特别是，该框架强调解决有效性问题， 需要在数据采集的三个阶段(<strong>选择数据源、设计数据收集和提取数据</strong>)联合考虑技术和法律/伦理问题。作者进一步审查了营销Top5期刊上300 篇使用网络数据的论文，并总结提出了如何使用网络数据促进营销研究。本文最后指出了未来研究的方向，高价值的网络数据源和新方法。</p>
<p><strong>Keywords：</strong></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">- web scraping
- application programming interface, API
- crawling
- validity
- user-generated content
- social media
big data
</code></pre></div><br>
<h2 id="一网络数据的魅力">一、网络数据的魅力</h2>
<p>社会和商业生活的加速数字化创造了数量空前的消费者和企业行为数字痕迹。 每分钟，全球用户在 Google 上进行 570 万次搜索，进行 600 万次商业交易，并在 Instagram 上分享6.5万张照片（Statista 2021）。 由此产生的网络数据——规模庞大、形式多样，而且通常可以在互联网上公开访问——对于那些想要量化消费、深入了解企业行为并跟踪难以或昂贵地观察社会活动的营销学者来说，这是一个潜在的金矿 . 网络数据对营销研究的重要性反映在越来越多的有影响力的出版物中，涵盖消费者文化理论、消费者心理学、实证建模和营销策略等。</p>
<p><img loading="lazy" src="img/fig-1-increased-use-of-web-data-in-marketing.png" alt=""  />
</p>
<p>整理了 <strong>营销领域 top 5 期刊( JM、JMR、JCR、JCP、MS) 的 313 篇论文</strong> ，经过整理绘制图-1（Figure1）， 使用网络数据进行研究的量呈现快速上涨的趋势。使用网络数据的论文占比，从2010年的4%提升到2020年的15%。 者313篇论文，数据的获取方式统计</p>
<ul>
<li>**59% 的论文使用了 <strong>网络爬虫</strong> 采集数据</li>
<li>12% 的论文使用API收集数据</li>
<li>9% 的论文同时使用了网络爬虫和API</li>
<li>20% 使用人工从网站手动复制粘贴数据</li>
</ul>
<p><strong>使用 网络数据 的论文，平均被引用次数 7.55， 远高于 非网络数据 的 3.90</strong>。</p>
<br>
<p>使用网络数据做新研究，大致有4种实现路径</p>
<ol>
<li><strong>研究新现象，新场景</strong>
<ul>
<li>网络世界产生的不同于现实世界的情景，可以研究新现象</li>
</ul>
</li>
<li><strong>繁荣生态价值</strong>
<ul>
<li>比如，对亚马逊评论数据进行研究，研究发现可以帮助亚马逊平台进行改善。</li>
</ul>
</li>
<li><strong>促进方法论进步</strong>
<ul>
<li>文本、图片、音频、视频等</li>
</ul>
</li>
<li><strong>提高测量效果(快、准、好、全)</strong>
<ul>
<li>借助一些API，可以对已有的数据集增加新的信息量。</li>
<li>例如，日期数据，结合HolidayAPI，可以查看日期的节假日信息</li>
<li>给定日期和IP地址，使用Weather Underground可以查看天气信息</li>
</ul>
</li>
</ol>
<p><img loading="lazy" src="img/table-1-four-pathway-of-knowledge-creation-using-web-data.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="二数据采集的方法框架">二、数据采集的方法框架</h2>
<p>在使用 **网络爬虫 和 API ** 自动收集网络数据时，研究人员通常会在 **研究有效性、技术可行性和法律/伦理风险 **1 三者间权衡利弊得失，研究人员如何解决这些权衡，通过增强或破坏 <strong>统计结论有效性、内部有效性、结构有效性和外部有效性</strong> 来塑造研究结果的可信度（Shadish、Cook 和 Campbell 2002）。</p>
<p><img loading="lazy" src="img/fig-2-methodological-framework-for-collecting-web-data.png" alt=""  />
</p>
<p>本文开发了一个方法框架，为使用 网络爬虫 和 API 自动收集网络数据提供指导。图 2（Figure 2） 涵盖三个关键阶段</p>
<ul>
<li><strong>数据源选择</strong></li>
<li><strong>设计方案</strong>
<ul>
<li>从网站中抽取哪些信息</li>
<li>采集频率，即 每天(周/月)重复运行一次爬虫，得到面板数据</li>
</ul>
</li>
<li><strong>执行数据采集</strong>
<ul>
<li>如何改善爬虫运行效率</li>
<li>如何处理原始信息，完整的保存为原始格式html、json，还是只抽取存储当前想要的字段</li>
</ul>
</li>
</ul>
<p>研究人员通常从一组广泛的潜在数据源开始，并根据三个关键考虑因素（有效性、技术可行性和法律/道德风险）剔除其中一些数据源。这三个考虑因素出现在倒金字塔的角落，底部的有效性强调其重要性。鉴于在收集最终数据集之前难以预测其确切特征，研究人员在设计、原型化和完善数据收集时经常重新考虑这些因素。未能解决技术或法律/伦理问题可能意味着网络数据无法有意义地告知研究问题。</p>
<h3 id="21-数据源面临的挑战解决办法">2.1 数据源面临的挑战(解决办法)</h3>
<ol>
<li>探索潜在网络数据源
<ul>
<li>由于网络资源在质量、稳定性和可检索性方面存在巨大差异，研究人员可能倾向于只考虑主要或熟悉的平台。 对数据世界的彻底探索允许令人信服的理论检验和识别可能难以以其他方式注意到的新颖的、新兴的营销现象。</li>
</ul>
</li>
<li>考虑网络爬虫的替代方案
<ul>
<li>由于网络抓取是最流行的网络数据提取方法，研究人员可能会忽视其他提取数据的方法。 API 提供了一种记录和授权的方式来获取许多来源的 Web 数据。 一些来源还提供现成的数据集。 使用此类替代方案可以节省时间并最大限度地减少法律风险。</li>
</ul>
</li>
<li>将数据与场景结合对应起来
<ul>
<li>Web 数据通常没有大量的文档。 尽早识别潜在相关的背景信息对于研究的相关性和有效性至关重要。
<img loading="lazy" src="img/table-2-chanllenges-and-solutions-in-selecting-web-data-sources.png" alt=""  />
</li>
</ul>
</li>
</ol>
<br>
<h3 id="22-设计数据采集方案">2.2 设计数据采集方案</h3>
<ol>
<li>从页面抽取什么信息，从有效性、合法、技术可行性 三个方面论证。</li>
<li>如何进行数据抽样？</li>
<li>以什么频率(每天、周、月)进行数据采集</li>
</ol>
<p><img loading="lazy" src="img/table-3-1-chanllenges-and-solutions-in-selecting-web-data-sources.png" alt=""  />

<img loading="lazy" src="img/table-3-2-chanllenges-and-solutions-in-selecting-web-data-sources.png" alt=""  />
</p>
<br>
<h3 id="23-执行数据采集">2.3 执行数据采集</h3>
<ol>
<li>如何改善爬虫运行效率</li>
<li>如何监控数据质量</li>
<li>整理数据文档(记录)
<img loading="lazy" src="img/table-4-chanllenges-and-solutions-in-selecting-web-data-sources.png" alt=""  />
</li>
</ol>
<br>
<h2 id="部分参考文献">部分参考文献</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">[1]Allard, Thomas, Lea H. Dunn, and Katherine White. &#34;Negative reviews, positive impact: Consumer empathetic responding to unfair word of mouth.&#34; Journal of Marketing 84, no. 4 (2020): 86-108.
[2]Gao, Weihe, Li Ji, Yong Liu, and Qi Sun. &#34;Branding cultural products in international markets: a study of hollywood movies in China.&#34; Journal of Marketing 84, no. 3 (2020): 86-105.
[3]Reich, Taly, and Sam J. Maglio. &#34;Featuring mistakes: The persuasive impact of purchase mistakes in online reviews.&#34; Journal of Marketing 84, no. 1 (2020): 52-65.
[4]Lee, Jeffrey K., and Ann Kronrod. &#34;The strength of weak-tie consensus language.&#34; Journal of Marketing Research 57, no. 2 (2020): 353-374.
[5]Matz, Sandra C., Cristina Segalin, David Stillwell, Sandrine R. Müller, and Maarten W. Bos. &#34;Predicting the personal appeal of marketing images using computational methods.&#34; Journal of Consumer Psychology 29, no. 3 (2019): 370-390.
[6]Dai, Hengchen, and Dennis J. Zhang. &#34;Prosocial goal pursuit in crowdfunding: Evidence from kickstarter.&#34; Journal of Marketing Research 56, no. 3 (2019): 498-517.
[7]Luffarelli, Jonathan, Mudra Mukesh, and Ammara Mahmood. &#34;Let the logo do the talking: The influence of logo descriptiveness on brand equity.&#34; Journal of Marketing Research 56, no. 5 (2019): 862-878.
[8]Bond, Samuel D., Stephen X. He, and Wen Wen. &#34;Speaking for “free”: Word of mouth in free-and paid-product settings.&#34; Journal of Marketing Research 56, no. 2 (2019): 276-290.
[9]Han, Kyuhong, Jihye Jung, Vikas Mittal, Jinyong Daniel Zyung, and Hajo Adam. &#34;Political identity and financial risk taking: Insights from social dominance orientation.&#34; Journal of Marketing Research 56, no. 4 (2019): 581-601.
[10]Netzer, Oded, Alain Lemaire, and Michal Herzenstein. &#34;When words sweat: Identifying signals for loan default in the text of loan applications.&#34; Journal of Marketing Research 56, no. 6 (2019): 960-980.
[11]Toubia, Olivier, Garud Iyengar, Renée Bunnell, and Alain Lemaire. &#34;Extracting features of entertainment products: A guided latent dirichlet allocation approach informed by the psychology of media consumption.&#34; Journal of Marketing Research 56, no. 1 (2019): 18-36.
[12]Van Laer, Tom, Jennifer Edson Escalas, Stephan Ludwig, and Ellis A. Van Den Hende. &#34;What happens in Vegas stays on TripAdvisor? A theory and technique to understand narrativity in consumer reviews.&#34; Journal of Consumer Research 46, no. 2 (2019): 267-285.
[13]Zhong, Ning, and David A. Schweidel. &#34;Capturing changes in social media content: A multiple latent changepoint topic model.&#34; Marketing Science 39, no. 4 (2020): 827-846.
[14]Colicev, Anatoli, Ashwin Malshe, Koen Pauwels, and Peter O&#39;Connor. &#34;Improving consumer mindset metrics and shareholder value through social media: The different roles of owned and earned media.&#34; Journal of Marketing 82, no. 1 (2018): 37-56.
[15]Liu, Xuan, Savannah Wei Shi, Thales Teixeira, and Michel Wedel. &#34;Video content marketing: The making of clips.&#34; Journal of Marketing 82, no. 4 (2018): 86-101.
[16]Liu, Jia, and Olivier Toubia. &#34;A semantic approach for estimating consumer content preferences from online search queries.&#34; Marketing Science 37, no. 6 (2018): 930-952.
[17]Nam, Hyoryung, Yogesh V. Joshi, and P. K. Kannan. &#34;Harvesting brand information from social tags.&#34; Journal of Marketing 81, no. 4 (2017): 88-108.
[18]Packard, Grant, and Jonah Berger. &#34;How language shapes word of mouth&#39;s impact.&#34; Journal of Marketing Research 54, no. 4 (2017): 572-588.
</code></pre></div><br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>社会学研究 | 社会计算驱动的社会科学研究方法</title>
      <link>https://textdata.cn/blog/2022-12-03-social-computing-methodology-about-big-data-and-artificial-intelligence/</link>
      <pubDate>Sat, 03 Dec 2022 00:00:00 +0000</pubDate>
      
      <guid>/blog/2022-12-03-social-computing-methodology-about-big-data-and-artificial-intelligence/</guid>
      <description>一篇关于计算社会学方法论的综述性论文</description>
      <content:encoded><![CDATA[<p><strong><a href="%E7%A4%BE%E4%BC%9A%E8%AE%A1%E7%AE%97%E9%A9%B1%E5%8A%A8%E7%9A%84%E7%A4%BE%E4%BC%9A%E7%A7%91%E5%AD%A6%E7%A0%94%E7%A9%B6%E6%96%B9%E6%B3%95_%E5%91%A8%E6%B6%9B.pdf">周涛,高馨,罗家德.社会计算驱动的社会科学研究方法[J].社会学研究,2022,37(05):130-155+228-229.</a></strong></p>
<p><img loading="lazy" src="img/%e5%91%a8%e6%b6%9b-01.png" alt=""  />

<img loading="lazy" src="img/%e5%91%a8%e6%b6%9b-02.png" alt=""  />

<img loading="lazy" src="img/%e5%91%a8%e6%b6%9b-03.png" alt=""  />

<img loading="lazy" src="img/%e5%91%a8%e6%b6%9b-04.png" alt=""  />

<img loading="lazy" src="img/%e5%91%a8%e6%b6%9b-05.png" alt=""  />

<img loading="lazy" src="img/%e5%91%a8%e6%b6%9b-06.png" alt=""  />

<img loading="lazy" src="img/%e5%91%a8%e6%b6%9b-07.png" alt=""  />

<img loading="lazy" src="img/%e5%91%a8%e6%b6%9b-08.png" alt=""  />

<img loading="lazy" src="img/%e5%91%a8%e6%b6%9b-09.png" alt=""  />

<img loading="lazy" src="img/%e5%91%a8%e6%b6%9b-10.png" alt=""  />

<img loading="lazy" src="img/%e5%91%a8%e6%b6%9b-11.png" alt=""  />

<img loading="lazy" src="img/%e5%91%a8%e6%b6%9b-12.png" alt=""  />

<img loading="lazy" src="img/%e5%91%a8%e6%b6%9b-13.png" alt=""  />

<img loading="lazy" src="img/%e5%91%a8%e6%b6%9b-14.png" alt=""  />

<img loading="lazy" src="img/%e5%91%a8%e6%b6%9b-15.png" alt=""  />

<img loading="lazy" src="img/%e5%91%a8%e6%b6%9b-16.png" alt=""  />

<img loading="lazy" src="img/%e5%91%a8%e6%b6%9b-17.png" alt=""  />

<img loading="lazy" src="img/%e5%91%a8%e6%b6%9b-18.png" alt=""  />

<img loading="lazy" src="img/%e5%91%a8%e6%b6%9b-19.png" alt=""  />

<img loading="lazy" src="img/%e5%91%a8%e6%b6%9b-20.png" alt=""  />

<img loading="lazy" src="img/%e5%91%a8%e6%b6%9b-21.png" alt=""  />
</p>
<br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>数据集(付费) | 90w条中国上市公司高管数据</title>
      <link>https://textdata.cn/blog/2022-11-25-senior-manager-resume-dataset/</link>
      <pubDate>Fri, 25 Nov 2022 00:00:00 +0000</pubDate>
      
      <guid>/blog/2022-11-25-senior-manager-resume-dataset/</guid>
      <description>数据集 | 90w条中国上市公司高管数据</description>
      <content:encoded><![CDATA[<p>90w条中国上市公司高管简历，数据源-新浪财经，统计的日期范围1990-2021年。</p>
<p><br><br></p>
<h2 id="相关论文">相关论文</h2>
<p>这里粘贴部分应用高管数据论文</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">- 何瑛,于文蕾,戴逸驰,王砚羽.高管职业经历与企业创新[J].管理世界,2019,35(11):174-192.
- 杨林,和欣,顾红芳.高管团队经验、动态能力与企业战略突变：管理自主权的调节效应[J].管理世界,2020,36(06):168-188+201+252.
- 周楷唐,麻志明,吴联生.高管学术经历与公司债务融资成本[J].经济研究,2017,52(07):169-183.
- 陆瑶,张叶青,黎波,赵浩宇.高管个人特征与公司业绩——基于机器学习的经验证据[J].管理科学学报,2020,23(02):120-140.
- 柳光强,孔高文.高管经管教育背景与企业内部薪酬差距[J].会计研究,2021,(03):110-121.
- 郑建明,孙诗璐,李金甜.高管文化背景与企业债务成本——基于劳模文化的视角[J].会计研究,2021,(03):137-145.
</code></pre></div><p><br><br></p>
<h2 id="一数据集字段">一、数据集字段</h2>
<blockquote>
<p>数据集的字段含，大多是从「个人简历」中计算衍生出来的。</p>
</blockquote>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">- ID
- 姓名
- 证券代码
- 统计截止日期
- 个人简历
- 国籍
- 籍贯
- 籍贯所在地区代码
- 出生地
- 出生地所在地区代码
- 性别
- 年龄
- 毕业院校
- 学历  1=中专及中专以下； 2=大专； 3=本科； 4=硕士研究生； 5=博士研究生； 6=其他（以其他形式公布的学历，如荣誉博士、函授等）； 7=MBA/EMBA
- 专业
- 职称
- 是否领取薪酬
- 报告期报酬总额
- 年末持股数
- 是否高管团队成员
- 是否董事会成员
- 是否独立董事
- 是否兼任董事长和CEO
- 是否监事
- 具体职务
</code></pre></div><p><br><br></p>
<h2 id="二实验代码">二、实验代码</h2>
<h3 id="21-读取数据">2.1 读取数据</h3>
<ul>
<li>数据文件 <code>高管数据.xlsx</code></li>
<li>强制某几个字段的数据类型</li>
<li>将字段 「统计截止日期」 转化为 datetime 类型</li>
</ul>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">import pandas as pd

# 导入数据，
df = pd.read_excel(&#39;高管数据.xlsx&#39;, 
                   #保证这两个字段是字符串格式
                   converters={&#39;证券代码&#39;: str, 
                               &#39;ID&#39;: str})

#将字段「统计截止日期」 整理为datetime格式
df[&#39;统计截止日期&#39;] = pd.to_datetime(df[&#39;统计截止日期&#39;])
#显示前1条记录
df.head(1)
</code></pre></div><p>Run</p>
<p><img loading="lazy" src="img/df.png" alt=""  />
</p>
<br>
<h3 id="22-字段">2.2 字段</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">df.columns
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">    Index([&#39;ID&#39;, &#39;姓名&#39;, &#39;证券代码&#39;, &#39;统计截止日期&#39;, &#39;个人简历&#39;, &#39;国籍&#39;, &#39;籍贯&#39;, &#39;籍贯所在地区代码&#39;, &#39;出生地&#39;,
           &#39;出生地所在地区代码&#39;, &#39;性别&#39;, &#39;年龄&#39;, &#39;毕业院校&#39;, &#39;学历&#39;, &#39;专业&#39;, &#39;职称&#39;, &#39;是否领取薪酬&#39;, &#39;报告期报酬总额&#39;,
           &#39;津贴&#39;, &#39;年末持股数&#39;, &#39;是否高管团队成员&#39;, &#39;是否董事会成员&#39;, &#39;是否独立董事&#39;, &#39;是否兼任董事长和CEO&#39;, &#39;是否监事&#39;,
           &#39;具体职务&#39;],
          dtype=&#39;object&#39;)
</code></pre></div><br>
<h3 id="23-记录数">2.3 记录数</h3>
<p>数据集记录数共</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">len(df)
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">    900887
</code></pre></div><br>
<h3 id="24-覆盖日期">2.4 覆盖日期</h3>
<p>数据统计日期范围自 1990年12月10日 至 2021年7月19日</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">df[&#39;统计截止日期&#39;].sort_values()
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">    900886   1990-12-10
    900884   1990-12-10
    900883   1990-12-10
    900882   1990-12-10
    900881   1990-12-10
                ...    
    59734    2021-07-19
    59733    2021-07-19
    59731    2021-07-19
    59736    2021-07-19
    59742    2021-07-19
    Name: 统计截止日期, Length: 900887, dtype: datetime64[ns]
</code></pre></div><br>
<p>数据集字段 有</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">df.columns
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">    Index([&#39;ID&#39;, &#39;姓名&#39;, &#39;证券代码&#39;, &#39;统计截止日期&#39;, &#39;个人简历&#39;, &#39;国籍&#39;, &#39;籍贯&#39;, &#39;籍贯所在地区代码&#39;, &#39;出生地&#39;,
           &#39;出生地所在地区代码&#39;, &#39;性别&#39;, &#39;年龄&#39;, &#39;毕业院校&#39;, &#39;学历&#39;, &#39;专业&#39;, &#39;职称&#39;, &#39;是否领取薪酬&#39;, &#39;报告期报酬总额&#39;,
           &#39;津贴&#39;, &#39;年末持股数&#39;, &#39;是否高管团队成员&#39;, &#39;是否董事会成员&#39;, &#39;是否独立董事&#39;, &#39;是否兼任董事长和CEO&#39;, &#39;是否监事&#39;,
           &#39;具体职务&#39;],
          dtype=&#39;object&#39;)
</code></pre></div><br>
<h3 id="25-按条件筛选记录">2.5 按条件筛选记录</h3>
<p>截止统计日期时大于90岁的高管 记录有</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">df[df[&#39;年龄&#39;]&gt;90]
</code></pre></div><p><img loading="lazy" src="img/df2.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="三相关内容">三、相关内容</h2>
<p><strong>何瑛,于文蕾,戴逸驰,王砚羽.高管职业经历与企业创新[J].管理世界,2019,35(11):174-192.</strong></p>
<blockquote>
<p>摘要:管理的本质是一种实践,在某些情形下,<strong>阅历比简历更重要,丰富的职业经历有助于企业高管形成多元化的思维结构、广阔的管理视野、丰富的社会资源和过人的胆识,也是塑造复合型人才的重要路径</strong>。本文基于行为金融理论和高层梯队理论,手工搜集整理了2007～2016年中国沪深A股上市公司高管职业经历独特数据集,从<strong>职能部门、企业、行业、组织机构和地域类型</strong>五个维度构建了复合型职业经历的衡量指标——职业经历丰富度指数,对CEO职业经历与企业创新的影响因素和影响机理进行理论解释、数据分析和验证。研究结果表明:CEO职业经历越丰富,企业创新水平越高,<strong>其中跨企业经历对创新水平的影响最为显著</strong>,其次是跨行业经历和跨组织机构经历,跨职能部门经历和跨地域经历对企业创新水平的影响最小;影响因素方面,基于公司内外部治理的视角发现,市场化程度越低、企业融资约束程度越低时,CEO职业经历丰富度对企业创新水平的促进作用越明显,国有企业CEO职业经历丰富度对企业创新水平的促进作用更强,而股权制衡度对CEO职业经历丰富度与企业创新水平的调节作用不明显;影响机理方面,CEO复合型职业经历主要是通过丰富高管的社会网络资源以及增强高管的风险偏好倾向,从而提升企业的创新水平。本文的研究结论拓展了企业创新影响因素及高管职业经历经济后果领域的相关文献,将复合型人才的影响从国家宏观层面拓展到企业微观层面,为企业高层次人才的招聘和选拔提供新的证据支持。 中提到高管的创新</p>
</blockquote>
<p>高管，一般是有多个企业经历的， 如何将高管职业经历转化为可以计算和比较的 <strong>高管职业经历向量</strong> 呢？</p>
<p><a href="https://mp.weixin.qq.com/s/1bs8ZS4upx25C08f2uBjBA"><strong>如何用「图嵌入」将企业、高管职业经历表征为向量数据</strong></a> , 有了向量可以</p>
<ul>
<li>计算高管之间的相似度</li>
<li>企业高管团队异质性，计算高管向量之间的距离</li>
<li>&hellip;</li>
</ul>
<p><br><br></p>
<h2 id="四数据获取">四、数据获取</h2>
<p>数据集 50 元， 加微信 <strong>372335839</strong>, 备注【姓名-学校-专业-高管】获取本数据集。</p>
<br>
<br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>FinBERT | 金融文本BERT模型，可情感分析、识别ESG和FLS类型</title>
      <link>https://textdata.cn/blog/2022-11-17-finbert-finance-bert-model/</link>
      <pubDate>Wed, 16 Nov 2022 00:00:00 +0000</pubDate>
      
      <guid>/blog/2022-11-17-finbert-finance-bert-model/</guid>
      <description>金融语言模型</description>
      <content:encoded><![CDATA[<h2 id="finbert介绍">FinBERT介绍</h2>

<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
  <iframe src="https://www.youtube.com/embed/uj4hm7Lr2Wo" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video"></iframe>
</div>

<br>
<p>FinBERT， 是使用49亿词的英文金融语料库数据，生成的BERT预训练语言模型。语料库上大小为 49亿个词。</p>
<ul>
<li>公司报告 10-K 和 10-Q：25亿个词</li>
<li>电话会议记录：13亿个词</li>
<li>分析师报告：11亿个词</li>
</ul>
<p>FinBERT开发者在多个金融 NLP 任务上对 FinBERT 预训练模型进行了微调，均优于传统机器学习模型、深度学习模型和微调 BERT 模型。 所有经过微调的 FinBERT 模型都公开托管在 Huggingface 🤗。  目前支持包括<strong>情绪分析、ESG 分类、前瞻性陈述 (FLS) 分类</strong>。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">Huang, Allen H., Hui Wang, and Yi Yang. &#34;FinBERT: A large language model for extracting information from financial text.&#34; Contemporary Accounting Research (2022).

摘要（翻译）: 我们开发了 FinBERT，这是一种适用于金融领域的最先进的大型语言模型。我们表明，FinBERT 结合了金融知识，可以更好地总结金融文本中的上下文信息。使用分析报告中研究人员标记的句子样本，我们证明 FinBERT 大大优于 Loughran 和 McDonald 词典以及其他机器学习算法，包括朴素贝叶斯、支持向量机、随机森林、卷积神经网络和长短期记忆，在情感分类中。我们的结果表明，FinBERT 擅长识别其他算法错误标记为中性的句子的正面或负面情绪，这可能是因为它使用了金融文本中的上下文信息。我们发现，FinBERT 优于其他算法，以及 Google 的原始双向编码器表示形式来自 transformers (BERT) 模型，当训练样本量较小且文本中包含一般文本中不常用的金融词时，这种优势尤为突出。 FinBERT 在识别与环境、社会和治理问题相关的讨论方面也优于其他模型。最后，我们表明，与 FinBERT 相比，其他方法低估了收益电话会议的文本信息量至少 18%。我们的结果对学术研究人员、投资专业人士和金融市场监管机构具有重要意义。
</code></pre></div><br>
<h3 id="finbert功能">FinBERT功能</h3>
<p>具体来说，FinBERT有以下内容：</p>
<ul>
<li><a href="https://huggingface.co/yiyanghkust/finbert-pretrain">FinBERT-Pretrained</a>： 针对大规模金融文本的预训练 FinBERT 模型。</li>
<li><a href="https://huggingface.co/yiyanghkust/finbert-tone">FinBERT-Sentiment</a>： 用于情感分类任务。</li>
<li><a href="https://huggingface.co/yiyanghkust/finbert-esg">FinBERT-ESG</a>： 用于 ESG 分类任务。</li>
<li><a href="https://huggingface.co/yiyanghkust/finbert-fls">FinBERT-FLS</a>： 用于前瞻性陈述（FLS）分类任务。</li>
</ul>
<br>
<h3 id="环境配置">环境配置</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">pip install transformers==4.18.0
</code></pre></div><p>本次实验使用的transformers版本为</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">import transformers
transformers.__version__
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">4.18.0
</code></pre></div><br>
<h3 id="代码下载">代码下载</h3>
<p><a href="FinBERT.ipynb">点击下载</a></p>
<p><br><br></p>
<h2 id="一情感分析">一、情感分析</h2>
<p>金融文本情绪可以调动管理者、信息中介和投资者的观点和意见, 因此分析金融文本情感(情绪)是有价值的。 FinBERT-Sentiment 是一个 FinBERT 模型，它根据标准普尔 500 家公司的分析师报告中的 10,000 个手动注释的句子进行了Fine-tune(微调)。</p>
<blockquote>
<p>Fine-Tune微调 是 深度学习的一种语言处理技术，可以在前人（已有）的语言模型文件基础上加入少量新场景的文本数据进行更新训练，生成出新场景的语言模型。</p>
</blockquote>
<ul>
<li><strong>输入</strong>：金融文本。</li>
<li><strong>输出</strong>：Positive, Neutral or Negative.</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">BertTokenizer</span><span class="p">,</span> <span class="n">BertForSequenceClassification</span><span class="p">,</span> <span class="n">pipeline</span>

<span class="c1">#首次运行，因为会下载FinBERT模型，耗时会比较久</span>
<span class="n">senti_finbert</span> <span class="o">=</span> <span class="n">BertForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">&#39;yiyanghkust/finbert-tone&#39;</span><span class="p">,</span><span class="n">num_labels</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">senti_tokenizer</span> <span class="o">=</span> <span class="n">BertTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">&#39;yiyanghkust/finbert-tone&#39;</span><span class="p">)</span>
<span class="n">senti_nlp</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span><span class="s2">&#34;text-classification&#34;</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">senti_finbert</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">=</span><span class="n">senti_tokenizer</span><span class="p">)</span>
</code></pre></div><p><br>使用3条测试文本进行测试</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1"># 待分析的文本数据</span>
<span class="n">senti_results</span> <span class="o">=</span> <span class="n">senti_nlp</span><span class="p">([</span><span class="s1">&#39;growth is strong and we have plenty of liquidity.&#39;</span><span class="p">,</span> 
                           <span class="s1">&#39;there is a shortage of capital, and we need extra financing.&#39;</span><span class="p">,</span>
                           <span class="s1">&#39;formulation patents might protect Vasotec to a limited extent.&#39;</span><span class="p">])</span>
<span class="n">senti_results</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">    [{&#39;label&#39;: &#39;Positive&#39;, &#39;score&#39;: 1.0},
     {&#39;label&#39;: &#39;Negative&#39;, &#39;score&#39;: 0.9952379465103149},
     {&#39;label&#39;: &#39;Neutral&#39;, &#39;score&#39;: 0.9979718327522278}]
</code></pre></div><p><br><br></p>
<h2 id="二esg分类">二、ESG分类</h2>
<p>ESG 分析可以帮助投资者确定企业的长期可持续性并识别相关风险。 FinBERT-ESG 是一个 FinBERT 模型，根据来自公司 ESG 报告和年度报告的 2,000 个手动注释句子进行微调。</p>
<ul>
<li><strong>输入</strong>：金融文本。</li>
<li><strong>输出</strong>：Environmental, Social, Governance or None.</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">BertTokenizer</span><span class="p">,</span> <span class="n">BertForSequenceClassification</span><span class="p">,</span> <span class="n">pipeline</span>

<span class="n">esg_finbert</span> <span class="o">=</span> <span class="n">BertForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">&#39;yiyanghkust/finbert-esg&#39;</span><span class="p">,</span><span class="n">num_labels</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="n">esg_tokenizer</span> <span class="o">=</span> <span class="n">BertTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">&#39;yiyanghkust/finbert-esg&#39;</span><span class="p">)</span>
<span class="n">esg_nlp</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span><span class="s2">&#34;text-classification&#34;</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">esg_finbert</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">=</span><span class="n">esg_tokenizer</span><span class="p">)</span>
</code></pre></div><p><br>使用3条测试文本进行测试</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">esg_results</span> <span class="o">=</span> <span class="n">esg_nlp</span><span class="p">([</span><span class="s1">&#39;Managing and working to mitigate the impact our operations have on the environment is a core element of our business.&#39;</span><span class="p">,</span>
                      <span class="s1">&#39;Rhonda has been volunteering for several years for a variety of charitable community programs.&#39;</span><span class="p">,</span>
                      <span class="s1">&#39;Cabot</span><span class="se">\&#39;</span><span class="s1">s annual statements are audited annually by an independent registered public accounting firm.&#39;</span><span class="p">,</span>
                      <span class="s1">&#39;As of December 31, 2012, the 2011 Term Loan had a principal balance of $492.5 million.&#39;</span><span class="p">])</span>

<span class="n">esg_results</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">    [{&#39;label&#39;: &#39;Environmental&#39;, &#39;score&#39;: 0.9805498719215393},
     {&#39;label&#39;: &#39;Social&#39;, &#39;score&#39;: 0.9906041026115417},
     {&#39;label&#39;: &#39;Governance&#39;, &#39;score&#39;: 0.6738430857658386},
     {&#39;label&#39;: &#39;None&#39;, &#39;score&#39;: 0.9960240125656128}]
</code></pre></div><p><br><br></p>
<h2 id="三fls识别">三、FLS识别</h2>
<p><strong>前瞻性陈述 (FLS)</strong> 告知投资者经理人对公司未来事件或结果的信念和意见。 从公司报告中识别前瞻性陈述可以帮助投资者进行财务分析。 FinBERT-FLS 是一个 FinBERT 模型，它基于罗素 3000 家公司年报的管理讨论和分析部分的 3,500 个手动注释的句子进行了微调。</p>
<ul>
<li><strong>输入</strong>：金融文本。</li>
<li><strong>输出</strong>：Specific-FLS(特定 FLS) , Non-specific FLS(非特定 FLS),  Not-FLS(非 FLS)。</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">BertTokenizer</span><span class="p">,</span> <span class="n">BertForSequenceClassification</span><span class="p">,</span> <span class="n">pipeline</span>

<span class="n">fls_finbert</span> <span class="o">=</span> <span class="n">BertForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">&#39;yiyanghkust/finbert-fls&#39;</span><span class="p">,</span><span class="n">num_labels</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">fls_tokenizer</span> <span class="o">=</span> <span class="n">BertTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">&#39;yiyanghkust/finbert-fls&#39;</span><span class="p">)</span>

<span class="n">fls_nlp</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span><span class="s2">&#34;text-classification&#34;</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">fls_finbert</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">=</span><span class="n">fls_tokenizer</span><span class="p">)</span>
</code></pre></div><p><br> 使用3条测试文本进行测试</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">fls_results</span> <span class="o">=</span> <span class="n">fls_nlp</span><span class="p">([</span><span class="s1">&#39;we expect the age of our fleet to enhance availability and reliability due to reduced downtime for repairs.&#39;</span><span class="p">,</span>
                      <span class="s1">&#39;on an equivalent unit of production basis, general and administrative expenses declined 24 percent from 1994 to $.67 per boe.&#39;</span><span class="p">,</span>
                      <span class="s1">&#39;we will continue to assess the need for a valuation allowance against deferred tax assets considering all available evidence obtained in future reporting periods.&#39;</span><span class="p">])</span>


<span class="n">fls_results</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">    [{&#39;label&#39;: &#39;Specific FLS&#39;, &#39;score&#39;: 0.7727874517440796},
     {&#39;label&#39;: &#39;Not FLS&#39;, &#39;score&#39;: 0.9905241131782532},
     {&#39;label&#39;: &#39;Non-specific FLS&#39;, &#39;score&#39;: 0.975904107093811}]
</code></pre></div><p><br><br></p>
<h2 id="文档及引用说明">文档及引用说明</h2>
<ul>
<li>
<p>文档github地址 <a href="https://github.com/yya518/FinBERT">https://github.com/yya518/FinBERT</a></p>
</li>
<li>
<p>作者博客: <a href="https://yya518.github.io/research">https://yya518.github.io/research</a></p>
</li>
</ul>
<br>
<p>Huang, Allen H., Hui Wang, and Yi Yang. &ldquo;FinBERT: A large language model for extracting information from financial text.&rdquo; <strong>Contemporary Accounting Research (2022)</strong>.</p>
<p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>转载 | 金融学文本大数据挖掘方法与研究进展</title>
      <link>https://textdata.cn/blog/2022-11-16-literature-review-textmining-in-finance-yao2020/</link>
      <pubDate>Wed, 16 Nov 2022 00:00:00 +0000</pubDate>
      
      <guid>/blog/2022-11-16-literature-review-textmining-in-finance-yao2020/</guid>
      <description>description用于SEO优化</description>
      <content:encoded><![CDATA[<blockquote>
<p>姚加权,张锟澎,罗平.金融学文本大数据挖掘方法与研究进展[J].经济学动态,2020(04):143-158.</p>
</blockquote>
<h2 id="摘要">摘要</h2>
<p>在金融学领域的传统实证研究中，所用数据多局限于财务报表和股票市场数据等结构化数据。而在大数据时代，计算机技术的进步使得数据类型不断丰富，研究者开始将非结构化的文本大数据引入到金融学领域的研究中，其主要包括<strong>上市公司披露文本</strong>、<strong>财经媒体报道</strong>、<strong>社交网络文本</strong>、网络搜索指数以及 P2P 网络借贷文本等，并对 <strong>文本可读性</strong>、<strong>语气语调</strong>、<strong>相似性</strong> 以及 <strong>语义特征</strong> 展开研究。本文首先介绍了金融学领域文本大数据挖掘步骤和方法，描述了语料获取、预处理过程、文档表示以及文档的特征抽取；然后根据不同的文本信息来源，梳理了金融学文本大数据的研究进展；最后对未来金融学文本大数据的研究方法和研究内容进行了展望。</p>
<p>关键词：文本大数据 文本分析 机器学习 深度学习 数据挖掘</p>
<p><img loading="lazy" src="img/01.png" alt=""  />

<img loading="lazy" src="img/02.png" alt=""  />

<img loading="lazy" src="img/03.png" alt=""  />

<img loading="lazy" src="img/04.png" alt=""  />

<img loading="lazy" src="img/05.png" alt=""  />

<img loading="lazy" src="img/06.png" alt=""  />

<img loading="lazy" src="img/07.png" alt=""  />

<img loading="lazy" src="img/08.png" alt=""  />

<img loading="lazy" src="img/09.png" alt=""  />

<img loading="lazy" src="img/10.png" alt=""  />

<img loading="lazy" src="img/11.png" alt=""  />

<img loading="lazy" src="img/12.png" alt=""  />
</p>
<br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>PNAS | 使用语义距离测量一个人的创新力(发散思维)得分</title>
      <link>https://textdata.cn/blog/2022-11-14-pnas_naming_unrelated_words_predicts_creativity/</link>
      <pubDate>Mon, 14 Nov 2022 00:00:00 +0000</pubDate>
      
      <guid>/blog/2022-11-14-pnas_naming_unrelated_words_predicts_creativity/</guid>
      <description>使用语义距离测量一个人的创新力(发散思维)得分</description>
      <content:encoded><![CDATA[<br>
<p>传统测量 <strong>被试者创造力</strong> 存在耗费时间、主观性太强、缺乏客观性，且所得到的分值是不稳定的，无法跨时间、文化、群体进行分值比较。该研究分析了创新力的两大理论，即联系理论和执行理论，即创新力是包含思维的广度和深度两方面。</p>
<ul>
<li><strong>联系理论(广度)</strong> 负责搜寻所有可能方案的集合，增加集合的规模，体现思维的广度。</li>
<li><strong>执行理论(深度)</strong> 负责寻找最佳方案，并将方案落实执行，体现思维的深度。</li>
</ul>
<p>结合Glove词嵌入技术，将每个词理解为一个技术或知识，两词语语义越相似，发散性越低。</p>
<p>文中让被试按照一定规则，随意填写10个名词，使用其中7个有效词语测量被试的创新力(发散性)思维。可以简单的把7个词理解为知识或者技术，7个词语会形成21种词语对(组合)。最后求均值可以测量出被试词语对的语义距离体现创新发散性的强度。<strong>文末含案例代码</strong></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">Olson, J.A., Nahas, J., Chmoulevitch, D., Cropper, S.J. and Webb, M.E., 2021. Naming unrelated words predicts creativity. Proceedings of the National Academy of Sciences, 118(25), p.e2022340118.
</code></pre></div><p><br><br></p>
<h2 id="一摘要">一、摘要</h2>
<p><strong>一些理论认为，有 创造力 的人能够产生更多 发散性 的想法。如果这是正确的，简单地让被试写 N 个不相关的单词，然后测量这N个词的语义距离， 作为 #发散思维 的客观衡量标准</strong>。为了验证这一假设，我们要求 8,914 名参与者说出 10 个彼此尽可能不同的单词。</p>
<p>然后计算算法估计单词之间的平均语义距离；<strong>相关词（例如 cat 和 dog）比不相关词（例如 cat 和 thimble）的距离更短。我们预测，产生更大语义距离的人也会在传统的创造力测量中得分更高</strong>。</p>
<p>在研究 1 中，我们发现语义距离与两个广泛使用的创造力测量（替代用途任务和桥接关联差距任务）之间存在中度至强相关性。在研究 2 中，参与者来自 98 个国家，语义距离仅因基本人口变量而略有不同。在一系列已知可预测创造力的问题上，语义距离与表现之间也存在正相关关系。</p>
<p>总体而言， <strong>语义距离</strong> 与已建立的 创造力测量 的相关性至少与这些测量彼此之间的相关性一样强。 因此，在我们所说的发散关联任务中命名不相关的词可以作为发散思维的简短、可靠和客观的衡量标准。</p>
<br>
<h2 id="二创新力理论">二、创新力理论</h2>
<p>想出 3 个尽可能不同的词。根据两种主要的创造力理论 (1, 2)，选择这些词依赖于产生 #远程联想 ，同时抑制 #常见联想 。</p>
<p>#联想理论 (Associative Theory)认为，有创造力的人具有语义记忆结构，可以更容易地链接远程元素 (3-6)。</p>
<p>#执行理论 (Executive Theory) 侧重于自上而下的注意力控制；创造性的解决方案来自于监测和抑制共同的联想 (2, 7)。</p>
<p>基于这些理论，我们假设 <strong>填写n个无关单词的任务</strong> 可以可靠地衡量 #语言创造力 。 <strong>创造力有两个主要的心理成分， 收敛思维和发散思维，它们在产生创意输出时协同工作</strong>。收敛性思维任务衡量评估多种刺激并得出最适当响应的能力，例如问题的最佳解决方案 (3, 8-10)。这些任务往往更容易得分，因为只有一小部分正确答案。<strong>相比之下，发散思维任务通常使用开放式问题来衡量一个人产生各种解决方案的能力</strong> (11-13)。它们通常需要更长的回答(文本)，因此更难客观评分。</p>
<br>
<h2 id="三创新力测量">三、创新力测量</h2>
<h3 id="31--替代用途任务">3.1  替代用途任务</h3>
<p>最常见的发散思维测量是 <strong>替代用途任务</strong> Alternative Uses Task (14, 15)，在该任务中，参与者生成常见物体的用途，例如回形针或鞋子。使用常用的评分方法 (16)，评分者然后根据三个组成部分来判断回答：</p>
<ul>
<li>灵活性，产生的不同用途类别的数量；</li>
<li>独创性，每次使用相对于样本的其余部分的稀有程度，这对创造力特别重要（17、18）；和</li>
<li>流畅度，一共产生了多少次使用。</li>
</ul>
<br>
<h3 id="32-离散联系任务">3.2 离散联系任务</h3>
<p>本研究作者开发了 <strong>离散联系任务</strong> (Divergent Association Task， DAT) 的网站， <strong>填写你想到的10个不相关词语， 创造力越丰富的人，填写的词语语义距离往往会更远</strong>。</p>
<p><a href="https://www.datcreativity.com/">https://www.datcreativity.com/</a></p>
<p><img loading="lazy" src="img/1_pnas_divergent_association_task_mainpage.png" alt=""  />
</p>
<h3 id="被试填写10个单词的规则">被试填写10个单词的规则</h3>
<ol>
<li>只能填写英文单词</li>
<li>只能是名词(如事情、物体、概念)</li>
<li>不能填 专有名词（例如，特定的人或地点）</li>
<li>不能填写 专业词（比如技术词）</li>
<li>自己思考这些词，不要只看周围环境的物体。</li>
</ol>
<h3 id="dat算法实现">DAT算法实现</h3>
<ol>
<li>使用Glove预训练模型</li>
<li>选前7个词(一共10个词)， 存在 21个词对（组合）</li>
<li>对21词对， 分别计算词向量的余弦距离，分别乘以100。最终求均值得到DAT得分。</li>
</ol>
<blockquote>
<p>下图是大邓第二次填写得到的DAT得分，第一次只超过了6%的人，这方法第一次准，再测就知道如何提高DAT得分。</p>
</blockquote>
<p><img loading="lazy" src="img/2_pnas_divergent_association_task_result.png" alt=""  />
</p>
<p>DAT得分范围0-200， 得分为0可能是7个有效词之间语义相同，而得分200可能是有效词之间彼此语义完全不相同。实践中，得分大多处于65~90之间，且很少超过100。</p>
<p><img loading="lazy" src="img/pnas_dat_score_low_median_high.jpg" alt=""  />
</p>
<blockquote>
<p>词嵌入技术可以把每个词转化为等长的向量，而不同词语共处于相同的语义空间中。常见的词嵌入技术有word2vec、Glove、flastText等，因为最近有学者在 <strong>替代用途任务</strong>(Alternative Uses Task）中用过Glove算法，本文采用Glove算法。本研究使用的Glove预训练模型来自Common Crawl Corpus项目，该项目拥有数十亿网页文本数据。</p>
<p>为了提供冗余， 只采用 被试者 填写的前7个词作为有效单词(DAT的被试需要填写10个词)。DAT得分是这些词之间的语义距离的平均值，具体计算方法， 7个词两两相关的组合有 42种组合， 选择其中最有可能的 21 个语义组合。</p>
</blockquote>
<br>
<h2 id="四实验">四、实验</h2>
<p>这种发散思维的操作化是基于创造力的联想和执行控制理论。 更高的分数将显示出更大的能力来利用更远程的关联 (3-5) 或抑制过度相关的关联 (2, 7)。</p>
<p>在研究 1 中，我们通过将 DAT 与其他两种创造力测量方法进行比较来检验这一假设：替代用途任务 (15) 和桥接关联差距任务 (36)。
<img loading="lazy" src="img/pnas_dat_aut_algo_valid_num.jpg" alt=""  />
</p>
<p>在研究 2 中，我们测试了这些分数如何随人口统计而变化，以及它们是否与更大数据集中与发散性思维相关的其他测量值相关 (9, 37)。 这些研究评估了语义距离是否可以作为发散思维的可靠指标。
<img loading="lazy" src="img/pnas_dat_gender_age.jpg" alt=""  />
</p>
<br>
<h2 id="五讨论">五、讨论</h2>
<p>研究结果表面， 让被试简单的填写10个不想管单词的任务可以作为 测量发散思维 的可靠衡量标准。在研究中， 将这项任务的表现与已有的两种创造力量表做了比较，具有很高的相关性。</p>
<p>总体而言支持了语义发散性，尽管这种联系背后的确切机制尚不清楚，但在创新力最主要的两个理论，即联想理论或执行理论 的联系网络中衡量网络的范围或效率。</p>
<p><strong>DAT算法表现稳定，方差不随人口统计特征变化出现显著性变化（研究2），可以在跨年龄、跨性别的情况下应用</strong>。</p>
<br>
<h3 id="51-dat的优点">5.1 DAT的优点</h3>
<ul>
<li>操作简单，快捷，客观，节约了大量的人力时间，又能保证客观性。</li>
<li>得分绝对，可比较，可以用于测量不同群体(种族、文化、性别、年龄)的创造力得分。</li>
<li>对被试友好，一般一两分钟即可完成。</li>
</ul>
<h3 id="52-dat的不足">5.2 DAT的不足</h3>
<ul>
<li>创造力有发散性和执行力，发散性负责搜选所有方案集合的规模，而执行力是从方案集中选出最优方案并将其执行。DAT测量的仅仅是发散性思维。</li>
<li>被试可能通过填写稀奇的词语提高DAT得分。</li>
<li>只有短短几分钟，被试可能很难短时间内了解实验规则。</li>
</ul>
<h3 id="53-未来展望">5.3 未来展望</h3>
<p>DAT得分取决于Glove模型、语料库(数据集), 更新词模型或语料库，被试的DAT得分会发生变化。为简单起见，本研究使用免费的预训练模型， 通过一些努力，未来研究者可以对不同时期，不同国家的语料库来训练Glove模型。随着特定单词关联或多或少的联系， 更新的模型将会自动考虑这些变化，这将允许DAT得分跨越文化跨越时代，进行创新力的比较。</p>
<p><br><br></p>
<h2 id="代码">代码</h2>
<p>代码的文档说明请点击 github仓库地址 <a href="https://github.com/jayolson/divergent-association-task">https://github.com/jayolson/divergent-association-task</a> 查看。这里仅粘贴作者源代码，源代码需要配置好才可运行。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">dat</span>

<span class="c1">## 从 https://nlp.stanford.edu/projects/glove/ 下载Glove模型</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">dat</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="s2">&#34;glove.840B.300d.txt&#34;</span><span class="p">,</span> <span class="s2">&#34;words.txt&#34;</span><span class="p">)</span>

<span class="c1"># 验证词语，如输入的是词组，代码会将其转为连线形式的单词</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">validate</span><span class="p">(</span><span class="s2">&#34;cul de sac&#34;</span><span class="p">))</span> 
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">cul-de-sac
</code></pre></div><br>
<p>计算两个词语之间的语义距离</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">distance</span><span class="p">(</span><span class="s2">&#34;cat&#34;</span><span class="p">,</span> <span class="s2">&#34;dog&#34;</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">distance</span><span class="p">(</span><span class="s2">&#34;cat&#34;</span><span class="p">,</span> <span class="s2">&#34;thimble&#34;</span><span class="p">))</span> 
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">0.1983
0.8787
</code></pre></div><br>
<p>计算词对的DAT得分（语义cosine距离*100）</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">dat</span><span class="p">([</span><span class="s2">&#34;cat&#34;</span><span class="p">,</span> <span class="s2">&#34;dog&#34;</span><span class="p">],</span> <span class="mi">2</span><span class="p">))</span> 
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">dat</span><span class="p">([</span><span class="s2">&#34;cat&#34;</span><span class="p">,</span> <span class="s2">&#34;thimble&#34;</span><span class="p">],</span> <span class="mi">2</span><span class="p">))</span> 
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">19.83
87.87
</code></pre></div><br>
<p>假设有三个人分别都填写10个词，选其前7个词作为有效词。有效词如下，</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">low</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&#34;arm&#34;</span><span class="p">,</span> <span class="s2">&#34;eyes&#34;</span><span class="p">,</span> <span class="s2">&#34;feet&#34;</span><span class="p">,</span> <span class="s2">&#34;hand&#34;</span><span class="p">,</span> <span class="s2">&#34;head&#34;</span><span class="p">,</span> <span class="s2">&#34;leg&#34;</span><span class="p">,</span> <span class="s2">&#34;body&#34;</span><span class="p">]</span>
<span class="n">average</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&#34;bag&#34;</span><span class="p">,</span> <span class="s2">&#34;bee&#34;</span><span class="p">,</span> <span class="s2">&#34;burger&#34;</span><span class="p">,</span> <span class="s2">&#34;feast&#34;</span><span class="p">,</span> <span class="s2">&#34;office&#34;</span><span class="p">,</span> <span class="s2">&#34;shoes&#34;</span><span class="p">,</span> <span class="s2">&#34;tree&#34;</span><span class="p">]</span>
<span class="n">high</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&#34;hippo&#34;</span><span class="p">,</span> <span class="s2">&#34;jumper&#34;</span><span class="p">,</span> <span class="s2">&#34;machinery&#34;</span><span class="p">,</span> <span class="s2">&#34;prickle&#34;</span><span class="p">,</span> <span class="s2">&#34;tickets&#34;</span><span class="p">,</span> <span class="s2">&#34;tomato&#34;</span><span class="p">,</span> <span class="s2">&#34;violin&#34;</span><span class="p">]</span>

<span class="c1"># Compute the DAT score (transformed average cosine distance of first 7 valid words)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">dat</span><span class="p">(</span><span class="n">low</span><span class="p">))</span> <span class="c1"># 50</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">dat</span><span class="p">(</span><span class="n">average</span><span class="p">))</span> <span class="c1"># 78</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">dat</span><span class="p">(</span><span class="n">high</span><span class="p">))</span> <span class="c1"># 95</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">50
78
95
</code></pre></div><p>需要注意pnas作者公开的代码只能用在英文，且无法自己训练Glove模型。如果想基于自有数据集（中文、英文），训练自有Glove模型，需要学习</p>
<ul>
<li>如何训练Glove模型</li>
<li>如何导入训练好的Glove模型</li>
<li>如何计算中英文dat得分</li>
</ul>
<p>相关知识点已更新至我的录播课课程 <a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></p>
<p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>小规模金融并购、投资事件图谱设计概述与数据构成解析</title>
      <link>https://textdata.cn/blog/2022-11-07-financial-invest-merge/</link>
      <pubDate>Mon, 07 Nov 2022 00:00:00 +0000</pubDate>
      
      <guid>/blog/2022-11-07-financial-invest-merge/</guid>
      <description>小规模金融并购、投资事件图谱设计概述与数据构成解析</description>
      <content:encoded><![CDATA[<h2 id="作者">作者</h2>
<p>刘焕勇，NLP开源爱好者与践行者，主页：https://liuhuanyong.github.io。</p>
<p>就职于360人工智能研究院、曾就职于中国科学院软件研究所。</p>
<p>老刘说NLP，将定期发布语言资源、工程实践、技术总结等内容，欢迎关注。</p>
<br>
<p>事件图谱是当前的一个十分有趣的话题，我们在前面的事件图谱系列文章中对事件图谱进行了论述。</p>
<p>例如文章《技术思考：面向落地应用的事件类图谱划分、关键问题及其与知识图谱的对比辨析》、《事件图谱应用：智能金融与情报分析中的七大应用潜在场景概述》、《事件图谱技术：基于触发词的事件句识别方法与关键流程总结》等。</p>
<p>同样本着技术具像化的原则，为了让大家对具体事件图谱有个清晰的直观的认识，本文我们介绍一个自建的金融事件图谱，涵盖并购和投资两大类事件类型，从金融事件图谱设计概述、投资事件图谱数据介绍以及并购事件图谱数据介绍三个角度进行论述，供大家一起参考。</p>
<br>
<h2 id="一金融事件图谱设计概述">一、金融事件图谱设计概述</h2>
<p>事件知识图谱EKG（event knowledge graph）是当前事件类图谱的一种，在这里，我更倾向于认为这个图谱本身更倾向于为一个事件知识库，而非实体知识图谱。</p>
<p><strong>事件知识图谱的工作主要围绕事件知识本身进行展开，关注点在于事件内部信息，如ACE中的8大类事件，将这几类事件中的信息进行抽取和填充就能够得到一个以特定事件类型作为分类标准的事件知识库，如婚姻事件库、爆炸事件库等。</strong></p>
<p>而相对应的，领域事件图谱显得更为重要，金融领域作为一个需求较为明显的领域，其建模能力更具代表性，例如，我们可以对事件图谱进行本体定义：</p>
<table>
<thead>
<tr>
<th style="text-align:left"><strong>事件类型</strong></th>
<th style="text-align:left"><strong>事件要素</strong></th>
<th style="text-align:left"><strong>事件关系</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">投资事件</td>
<td style="text-align:left">融资方、投资方、金额、轮次、融资时间、所属行业</td>
<td style="text-align:left">顺承/时序</td>
</tr>
<tr>
<td style="text-align:left">并购事件</td>
<td style="text-align:left">并购方、被并购方、并购状态、所属行业、涉及股权、并购开始时间、并购结束时间、是否VC/PE支持</td>
<td style="text-align:left">顺承/时序</td>
</tr>
</tbody>
</table>
<p>在这样一个本体框架之下，我们要构建起一个事件图谱，可以有两种方式：</p>
<ul>
<li>
<p><strong>从已经结构化好的数据源中直接获取</strong>。例如，目前针对投融资领域已经出现了许多垂类网站，如投资界、IT橘子中直接获取，并做清洗。这种方式最为快捷，但受制于人，其中的数据有限，并存在字段不全的问题。当我们想建成一个实时动态的金融事件图谱库，在捕捉实时数据时，及时处理时候，就需要采用抽取的思路。</p>
</li>
<li>
<p><strong>基于模型的非结构化文本抽取</strong>。为了避免方法1带来的拿来主义缺陷，我们可以转换为标准的事件抽取任务，针对实时的实时新闻流，进行论元识别、事件要素抽取。</p>
</li>
</ul>
<p>例如，给定文本：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">8日消息，总部位于墨西哥的在线批发平台Miferia获得了700万美元种子轮融资，该轮融资由贝恩资本风险投资公司和Tiger Global共同领投。Miferia批发平台将墨西哥的独立零售店与化妆品、食品和饮料以及家居装饰等类别的品牌联系起来。该平台拥有来自500多个品牌的数千种产品，每周有30多个新品牌上线。（Latamlist）
</code></pre></div><p>我们可以从中检测出融资事件：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">8月8日消息，总部位于墨西哥的在线批发平台Miferia获得了700万美元种子轮融资，该轮融资由贝恩资本风险投资公司和Tiger Global共同领投。
</code></pre></div><p>并识别出一下结构化信息：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">融资方：Miferia
金额：700万美元
轮次：种子轮以及投资方贝恩资本风险投资公司、Tiger Global；
融资时间：8月8日、所属行业：在线批发等信息
</code></pre></div><p>下图展示了一个金融领域的一个典型投资领域事件图谱：</p>
<p>其中包括“君度德瑞、新余凯信投资、深圳市立德富盈投资等投资信濠光电20%股权”、“东莞中科中广基金（领投）、中广创投、紫宸创投等投资信濠光电5%股权”两个投资事件，每个投资事件由投资方、融资方、金额、日期、轮次几个事件要素构成，<strong>而若以一个融资方为中心进行融资历程的刻画，就可以根据日期发展的先后顺序，在两个事件之间形成一条边</strong>。</p>
<p><img loading="lazy" src="img/fin_edge_networks.png" alt=""  />
</p>
<p>需要注意的是，现在的事件抽取任务中，是不包含事件名称的抽取的，但如果要星辰恶搞事件图谱，就必须保证该事件的唯一性和友好性，可以使用md5值来表示，但并不直观，图中给出了一个较好的例子，用一个短句来表示。</p>
<br>
<h2 id="二投资事件图谱数据介绍">二、投资事件图谱数据介绍</h2>
<p>我们以投资界为数据源，通过解析整理，形成了9093条投资事件，包括融资方、投资方、金额、轮次、融资时间、所属行业共5个要素。</p>
<p><img loading="lazy" src="img/fin_extract_data.png" alt=""  />
</p>
<p>数据样例：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="p">{</span>
    <span class="s2">&#34;name&#34;</span><span class="p">:</span><span class="s2">&#34;苏州聚源铸芯创投基金（领投）、创世一期、高捷资本等投资英彼森&#34;</span><span class="p">,</span>
    <span class="s2">&#34;event_type&#34;</span><span class="p">:</span><span class="s2">&#34;投资事件&#34;</span><span class="p">,</span>
    <span class="s2">&#34;融资方&#34;</span><span class="p">:</span><span class="s2">&#34;英彼森半导体（珠海）有限公司&#34;</span><span class="p">,</span>
    <span class="s2">&#34;投资方&#34;</span><span class="p">:[</span>
        <span class="s2">&#34;聚源资本&#34;</span><span class="p">,</span>
        <span class="s2">&#34;高捷资本&#34;</span><span class="p">,</span>
        <span class="s2">&#34;创世伙伴&#34;</span><span class="p">,</span>
        <span class="s2">&#34;绿河投资&#34;</span><span class="p">,</span>
        <span class="s2">&#34;珠海科技创投&#34;</span>
    <span class="p">],</span>
    <span class="s2">&#34;金额&#34;</span><span class="p">:</span><span class="s2">&#34;RMB数亿&#34;</span><span class="p">,</span>
    <span class="s2">&#34;轮次&#34;</span><span class="p">:</span><span class="s2">&#34;A轮&#34;</span><span class="p">,</span>
    <span class="s2">&#34;融资时间&#34;</span><span class="p">:</span><span class="s2">&#34;2021年06月29日&#34;</span><span class="p">,</span>
    <span class="s2">&#34;所属行业&#34;</span><span class="p">:</span><span class="s2">&#34;半导体及电子设备-半导体&#34;</span>
<span class="p">}</span>

<span class="p">{</span>
    <span class="s2">&#34;name&#34;</span><span class="p">:</span><span class="s2">&#34;Esta Investments、DD Asset Holdings、DST China EC XI等投资滴滴集团6.08%股权&#34;</span><span class="p">,</span>
    <span class="s2">&#34;event_type&#34;</span><span class="p">:</span><span class="s2">&#34;投资事件&#34;</span><span class="p">,</span>
    <span class="s2">&#34;融资方&#34;</span><span class="p">:</span><span class="s2">&#34;滴滴&#34;</span><span class="p">,</span>
    <span class="s2">&#34;投资方&#34;</span><span class="p">:[</span>
        <span class="s2">&#34;Esta Investments&#34;</span><span class="p">,</span>
        <span class="s2">&#34;腾讯投资&#34;</span><span class="p">,</span>
        <span class="s2">&#34;THL A11&#34;</span><span class="p">,</span>
        <span class="s2">&#34;纪源资本&#34;</span><span class="p">,</span>
        <span class="s2">&#34;数字天空技术&#34;</span>
    <span class="p">],</span>
    <span class="s2">&#34;金额&#34;</span><span class="p">:</span><span class="s2">&#34;USD7.5亿&#34;</span><span class="p">,</span>
    <span class="s2">&#34;轮次&#34;</span><span class="p">:</span><span class="s2">&#34;B轮&#34;</span><span class="p">,</span>
    <span class="s2">&#34;融资时间&#34;</span><span class="p">:</span><span class="s2">&#34;2014年12月02日&#34;</span><span class="p">,</span>
    <span class="s2">&#34;所属行业&#34;</span><span class="p">:</span><span class="s2">&#34;电信及增值业务-无线互联网服务&#34;</span>
<span class="p">}</span>

</code></pre></div><br>
<h2 id="三并购事件图谱数据介绍">三、并购事件图谱数据介绍</h2>
<p>同样的，我们得到了3865条并购事件数据，包括并购方、被并购方、并购状态、所属行业、涉及股权、并购开始时间、并购结束时间以及是否VC/PE支持等事件要素。</p>
<p><img loading="lazy" src="img/fin_extract_data2.png" alt=""  />
</p>
<p>数据样例：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="p">{</span>
    <span class="s2">&#34;name&#34;</span><span class="p">:</span><span class="s2">&#34;友睦口腔收购友睦三九60%股权&#34;</span><span class="p">,</span>
    <span class="s2">&#34;event_type&#34;</span><span class="p">:</span><span class="s2">&#34;并购事件&#34;</span><span class="p">,</span>
    <span class="s2">&#34;并购方&#34;</span><span class="p">:</span><span class="s2">&#34;深圳市友睦口腔股份有限公司&#34;</span><span class="p">,</span>
    <span class="s2">&#34;被并购方&#34;</span><span class="p">:</span><span class="s2">&#34;深圳友睦三九口腔门诊部有限公司&#34;</span><span class="p">,</span>
    <span class="s2">&#34;并购状态&#34;</span><span class="p">:</span><span class="s2">&#34;已完成&#34;</span><span class="p">,</span>
    <span class="s2">&#34;所属行业&#34;</span><span class="p">:</span><span class="s2">&#34;生物技术/医疗健康-医疗服务&#34;</span><span class="p">,</span>
    <span class="s2">&#34;涉及股权&#34;</span><span class="p">:</span><span class="s2">&#34;60.00 %&#34;</span><span class="p">,</span>
    <span class="s2">&#34;并购开始时间&#34;</span><span class="p">:</span><span class="s2">&#34;2017年03月21日&#34;</span><span class="p">,</span>
    <span class="s2">&#34;并购结束时间&#34;</span><span class="p">:</span><span class="s2">&#34;2017年03月21日&#34;</span><span class="p">,</span>
    <span class="s2">&#34;是否VC/PE支持&#34;</span><span class="p">:</span><span class="s2">&#34;是&#34;</span>
<span class="p">}</span>

<span class="p">{</span>
    <span class="s2">&#34;name&#34;</span><span class="p">:</span><span class="s2">&#34;我享科技收购我享网络&#34;</span><span class="p">,</span>
    <span class="s2">&#34;event_type&#34;</span><span class="p">:</span><span class="s2">&#34;并购事件&#34;</span><span class="p">,</span>
    <span class="s2">&#34;并购方&#34;</span><span class="p">:</span><span class="s2">&#34;上海我享网络信息科技股份有限公司&#34;</span><span class="p">,</span>
    <span class="s2">&#34;被并购方&#34;</span><span class="p">:</span><span class="s2">&#34;上海我享网络科技有限公司&#34;</span><span class="p">,</span>
    <span class="s2">&#34;并购状态&#34;</span><span class="p">:</span><span class="s2">&#34;已完成&#34;</span><span class="p">,</span>
    <span class="s2">&#34;所属行业&#34;</span><span class="p">:</span><span class="s2">&#34;互联网-电子商务-C2C&#34;</span><span class="p">,</span>
    <span class="s2">&#34;涉及股权&#34;</span><span class="p">:</span><span class="s2">&#34;N/A&#34;</span><span class="p">,</span>
    <span class="s2">&#34;并购开始时间&#34;</span><span class="p">:</span><span class="s2">&#34;2017年03月01日&#34;</span><span class="p">,</span>
    <span class="s2">&#34;并购结束时间&#34;</span><span class="p">:</span><span class="s2">&#34;2017年03月24日&#34;</span><span class="p">,</span>
    <span class="s2">&#34;是否VC/PE支持&#34;</span><span class="p">:</span><span class="s2">&#34;是&#34;</span>
<span class="p">}</span>
</code></pre></div><br>
<h2 id="总结">总结</h2>
<p>本文我们介绍l额一个自建的金融事件图谱，涵盖并购和投资两大类事件类型，从金融事件图谱设计概述、投资事件图谱数据介绍以及并购事件图谱数据介绍三个角度进行论述，这对加深我们对事件图谱的具象化认识具有一定的意义。</p>
<p>关于具体的数据，可以关注 <strong>公众号：老刘说NLP</strong>，并加入技术社区，与技术社区的朋友一同分享获取。</p>
<br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>Maigret库 | 查询某用户名在各平台网站的使用情况</title>
      <link>https://textdata.cn/blog/2022-10-08-find-sns-account-information-with-maigret/</link>
      <pubDate>Sat, 08 Oct 2022 00:00:00 +0000</pubDate>
      
      <guid>/blog/2022-10-08-find-sns-account-information-with-maigret/</guid>
      <description>Maigret 能检查各网站(应用) 某 **用户名** 是否注册，并从网页收集所有可用信息,  运行过程不需要 API 密钥。目前支持超过 2500 个站点检索（完整列表），默认针对 500 个热门站点按受欢迎程度降序启动搜索。</description>
      <content:encoded><![CDATA[<p>Maigret 能检查各网站(应用) 某 <strong>用户名</strong> 是否注册，并从网页收集所有可用信息,  运行过程不需要 API 密钥。目前支持超过 2500 个站点检索（完整列表），默认针对 500 个热门站点按受欢迎程度降序启动搜索。</p>
<br>
<h2 id="主要功能">主要功能</h2>
<ul>
<li>个人资料页面解析</li>
<li>个人信息提取</li>
<li>其他个人资料链接等。</li>
<li>通过新用户名和找到的其他 id 进行递归搜索</li>
<li>按标签搜索（网站类别、国家/地区）</li>
</ul>
<br>
<h2 id="安装">安装</h2>
<p>命令行中安装maigret包</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">pip3 install maigret
</code></pre></div><br>
<h2 id="使用">使用</h2>
<p>我自己有个账号名是hidadeng，就用hidadeng试试。</p>
<p>为了解用户名hidadeng使用情况，报告结果存储于html和pdf。 在命令行中执行，</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">maigret hidadeng --html --pdf
</code></pre></div><p>命令行运行过程</p>
<p><img loading="lazy" src="img/hidadeng-cmd.png" alt=""  />
</p>
<br>
<h2 id="报告">报告</h2>
<p>maigret查询用户名hidadeng的使用情况、兴趣等结果可以绘制成报告。</p>
<p><a href="report_hidadeng_plain.html">点击查看hidadeng报告</a></p>
<p><img loading="lazy" src="img/hidadeng-report-1.png" alt=""  />
</p>
<p><img loading="lazy" src="img/hidadeng-report-2.png" alt=""  />
</p>
<p>效果挺准的，对hidadeng这个用户兴趣(coding、shopping)拿捏的也挺不错。</p>
<br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>Google Books Ngram Viewer显示英文词汇历史使用趋势</title>
      <link>https://textdata.cn/blog/2022-09-27-r-ngramr/</link>
      <pubDate>Tue, 27 Sep 2022 00:00:00 +0000</pubDate>
      
      <guid>/blog/2022-09-27-r-ngramr/</guid>
      <description>显示词汇历史使用趋势</description>
      <content:encoded><![CDATA[


<p><a href="https://books.google.com/ngrams/">Google Books Ngram Viewer</a> 可以显示输入短语(你感兴趣的词组)在谷歌书籍中（例如，“British English”、“English Fiction”、“French”）中出现的频率变化趋势 。</p>
<p>网址 <a href="https://books.google.com/ngrams/" class="uri">https://books.google.com/ngrams/</a></p>
<p><img src="ngramr_hacker_programmer.png" /></p>
<p><img src="ngramr_democracy_monarchy.png" /></p>
<p><img src="us_is_us_has.png" /></p>
]]></content:encoded>
    </item>
    
    <item>
      <title>文献汇总 | 量化历史学与经济学研究</title>
      <link>https://textdata.cn/blog/2022-09-19-quantitative-history-economic/</link>
      <pubDate>Mon, 19 Sep 2022 00:00:00 +0000</pubDate>
      
      <guid>/blog/2022-09-19-quantitative-history-economic/</guid>
      <description>通过历史数据挖掘构建有意思的新变量， 量化历史学 可能是个不错的借鉴思路。</description>
      <content:encoded><![CDATA[<p>我对经济史不太懂，标题起的可能不一定恰当，通过历史数据挖掘构建有意思的新变量， <strong>量化历史学</strong> 可能是个不错的借鉴思路。</p>
<p><br><br></p>
<h2 id="历史与经济">历史与经济</h2>
<blockquote>
<p>摘自 <a href="https://mp.weixin.qq.com/s/pnwlwQfO0EWgV8XNHzMuZg">陈志武教授统筹量化历史研究获得创纪录研究经费支持</a></p>
</blockquote>
<p>由<strong>陈志武</strong>教授统筹的跨领域研究项目获得大学教育资助委员会（教资会）辖下的研究资助局（研资局）6,732万港元（即逾850万美元） 的拨款资助，再加上香港大学的支持，此单一研究项目共获得7,480万港元 （即逾950万美元），资助金额创学院自2001年成立以来的新高。项目研究团队由来自五间教资会资助院校的成员及合作方组成，包括香港大学（港大）、香港中文大学 （中大）、香港科技大学 （科大）、岭南大学（岭大）及香港浸会大学（浸大），另外亦有来自牛津大学及中国人民大学的学者。项目成员包括：港大陈志武 （项目统筹人）、Jed O. Kaplan、梁其姿、林晨和马驰骋、白营（中大）、康文林（科大）、林展 （人民大学）、刘光临（岭大）以及马德斌 （牛津）。（按英文字母顺序排列）</p>
<p>题为 “<strong>量化历史研究：追寻现代中国发展的根源</strong>” 的研究项目获得研资局辖下第十轮 “<strong>卓越学科领域计划</strong>” 的资助，旨在透过在香港大学成立 “<strong>量化历史研究中心</strong>” ，作为协调和开展 “<strong>量化中国历史</strong>” 研究的核心学术机构，<strong>致力加深对中国历史发展的认识，挖掘历史新知识，促进历史教学，引导政策制定，改善商界运营模式</strong>。</p>
<p>学院金融学讲座教授及郑裕彤基金教授（金融学）陈志武指出：“我们很荣幸能够获得今年度卓越学科领域计划的拨款，这支持并肯定了我们为多层面中国历史研究所作出的努力。<strong>中国蕴藏丰富的历史档案和考古挖掘，其规模在世界乃独一无二， 内容几乎涵盖中国社会的所有方面：从政治到商业、法律和监管、犯罪和动乱、家庭和宗族、文化和习俗、宗教和社会组织，以及科学。近年，这些档案被数码化，为量化历史学家提供前所未有的机会去全面重新审视中国历史的各方面</strong>。作为中国的一部分，香港具有语言、文化和人力资源的优势去建立整体而全面的中国量化历史，我们深信成立量化历史研究中心，将推动香港成为全球量化历史研究的领导者。”</p>
<p><br><br></p>
<h2 id="更多资料">更多资料</h2>
<ul>
<li><a href="https://academic.oup.com/ej/article/130/631/2030/5819954"><strong>鉴古识今 – 从「科举考试」分析中国经济发展</strong></a><br>Ting Chen, James Kai-sing Kung, Chicheng Ma, Long Live <em>Keju</em>! The Persistent Effects of China’s Civil Examination System, <em><strong>The Economic Journal</strong></em>, Volume 130, Issue 631, October 2020, Pages 2030–2064, <a href="https://doi.org/10.1093/ej/ueaa043">https://doi.org/10.1093/ej/ueaa043</a></li>
</ul>
<br>
<ul>
<li>Zhiwu Chen, Chicheng Ma, Andrew J Sinclair, Banking on the Confucian Clan: Why China Developed Financial Markets so Late, <em><strong>The Economic Journal</strong></em>, Volume 132, Issue 644, May 2022, Pages 1378–1413, <a href="https://doi.org/10.1093/ej/ueab082">https://doi.org/10.1093/ej/ueab082</a></li>
</ul>
<br>
<ul>
<li><a href="https://www.bilibili.com/video/BV19L4y1A7Yn">从权贵到富贵： 中国传世明画产权变动与社会流动性研究，960-1911</a></li>
</ul>
<iframe
    src="//player.bilibili.com/player.html?bvid=BV19L4y1A7Yn&page=1"
    scrolling="no"
    height="500px"
    width="800px"
    frameborder="no"
    framespacing="0"
    allowfullscreen="true"
>
</iframe>

<ul>
<li><a href="https://www.bilibili.com/video/BV1Q34y1J7f5">陈志武 &ndash; 史前文明摇篮的长久影响 &mdash;你的故乡是兴是衰在四千多年前就确定？</a></li>
</ul>
<iframe
    src="//player.bilibili.com/player.html?bvid=BV1Q34y1J7f5&page=1"
    scrolling="no"
    height="500px"
    width="800px"
    frameborder="no"
    framespacing="0"
    allowfullscreen="true"
>
</iframe>

<br>
<ul>
<li><a href="https://mp.weixin.qq.com/s/DJei28L1iZ_7rtkD0dZAQQ">李中清|《大数据与中国社会经济史》</a></li>
</ul>
<br>
<ul>
<li><a href="https://mp.weixin.qq.com/s/wpfz4WbNg-wW5IYxbBWcEQ">陈春声 | 统计分析方法在史学研究中的应用</a></li>
</ul>
<br>
<ul>
<li><a href="https://mp.weixin.qq.com/s/NxcFvQm7msQq9DrRLpMydQ">地理信息系统（GIS）与中国历史研究</a></li>
</ul>
<br>
<ul>
<li><a href="https://mp.weixin.qq.com/s/HqLvrK626bXt984dGtnR_A">周欣平：大数据与社会科学和人文科学研究</a></li>
</ul>
<br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>国庆直播 | Python实证指标与文本分析</title>
      <link>https://textdata.cn/blog/2022-09-19-text-mining-in-ms-workshop/</link>
      <pubDate>Sun, 18 Sep 2022 00:00:00 +0000</pubDate>
      
      <guid>/blog/2022-09-19-text-mining-in-ms-workshop/</guid>
      <description>文本分析在经管研究中的应用</description>
      <content:encoded><![CDATA[<h2 id="报名信息">报名信息</h2>
<ul>
<li>
<p>时间：<strong>2022.10.03 ~ 2022.10.04</strong></p>
</li>
<li>
<p>地点: 小鹅通平台（线上直播）</p>
</li>
<li>
<p>报名咨询:  17816181460（同微信）（汪老师）</p>
</li>
<li>
<p>报名费：<strong>2500元</strong></p>
<ul>
<li>单位：杭州国商智库信息技术服务有限公司</li>
<li>开户银行： 中国银行杭州大学城支行</li>
<li>银行账户：6232636200100260588</li>
</ul>
</li>
</ul>
<br>
<h2 id="简介">简介</h2>
<p>在科学研究中，数据的获取及分析是最重要的也是最棘手的两个环节！</p>
<p>在<strong>前大数据时代</strong>，一般使用实验法、调查问卷、访谈或者二手数据等方式，将数据整理为结构化的表格数据，之后再使用各种计量分析方法，对这些表格数据进行分析。<strong>大数据时代</strong>，大量商业信息、社会信息以文本等非结构化、异构型数据格式存储于海量的网页中。那么对于经管为代表的人文社科类专业科研工作者而言，通过Python可以帮助学者解决使用Web数据进行科研面临的两个问题：</p>
<ol>
<li><strong>网络爬虫</strong> 解决 如何从网络世界中高效地 <strong>采集数据</strong>？</li>
<li><strong>文本分析</strong> 解决 如何从杂乱的文本数据中 <strong>构建指标</strong>？</li>
</ol>
<p>为方便大家感受到文本数据的魅力，按照是否采用某项技术(爬虫、词频、词袋、w2v建词典、w2v认知变迁)，从五个维度标记代表性的7篇论文。</p>
<table>
<thead>
<tr>
<th>文献</th>
<th>爬虫</th>
<th>定性</th>
<th>词频</th>
<th>词袋</th>
<th>W2V建词典</th>
<th>W2V认知变迁</th>
</tr>
</thead>
<tbody>
<tr>
<td>王伟 , 陈伟, 祝效国 and 王洪伟, 2016. 众筹融资成功率与语言风格的说服性&ndash;基于 Kickstarter 的实证研究. <em>管理世界</em>, (5), pp.81-98.</td>
<td>Y</td>
<td>Y</td>
<td>Y</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><strong>语言具体性如何影响顾客满意度</strong><br>Packard, Grant, and Jonah Berger. “How concrete language shapes customer satisfaction.” <em>Journal of Consumer Research</em> 47, no. 5 (2021): 787-806.</td>
<td></td>
<td></td>
<td>Y</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Wang, Quan, Beibei Li, and Param Vir Singh. &ldquo;<strong>Copycats vs. original mobile apps</strong>: A machine learning copycat-detection method and empirical analysis.&rdquo; Information Systems Research 29, no. 2 (2018): 273-291.</td>
<td>Y</td>
<td></td>
<td></td>
<td>Y</td>
<td></td>
<td></td>
</tr>
<tr>
<td><strong>文本相似度</strong><br>Cohen, L., Malloy, C. and Nguyen, Q., 2020. Lazy prices. <em>The Journal of Finance</em>, <em>75</em>(3), pp.1371-1415.</td>
<td></td>
<td></td>
<td></td>
<td>Y</td>
<td></td>
<td></td>
</tr>
<tr>
<td>胡楠, 薛付婧 and 王昊楠, 2021. <strong>管理者短视主义影响企业长期投资吗</strong>———基于文本分析和机器学习. <em>管理世界</em>, <em>37</em>(5), pp.139-156.</td>
<td></td>
<td></td>
<td>Y</td>
<td></td>
<td>Y</td>
<td></td>
</tr>
<tr>
<td>Kai Li, Feng Mai, Rui Shen, Xinyan Yan, <strong>Measuring Corporate Culture Using Machine Learning</strong>, The Review of Financial Studies, 2020</td>
<td></td>
<td></td>
<td></td>
<td>Y</td>
<td>Y</td>
<td></td>
</tr>
<tr>
<td><strong>女性就职高管改变组织内性别偏见</strong><br>Lawson, M. Asher, Ashley E. Martin, Imrul Huda, and Sandra C. Matz. &ldquo;Hiring women into senior leadership positions is associated with a reduction in gender stereotypes in organizational language.&rdquo; <em>Proceedings of the National Academy of Sciences</em> 119, no. 9 (2022): e2026443119.</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>Y</td>
</tr>
</tbody>
</table>
<br>
<h2 id="主讲老师">主讲老师</h2>
<p>大邓，哈尔滨工业大学(HIT)管理学院信息管理系统方向在读博士。在多所大学分享数据采集和文本分析。运营公众号：大邓和他的Python，主要分享Python、爬虫、文本分析、机器学习等内容。</p>
<br>
<h2 id="一入门语法">一、入门语法</h2>
<ul>
<li>Python跟英语一样是一门语言</li>
<li>数据类型之字符串</li>
<li>数据类型之列表元组集合</li>
<li>数据类型之字典</li>
<li>数据类型之布尔值、None</li>
<li>逻辑语句(if&amp;for&amp;tryexcept)</li>
<li>列表推导式</li>
<li>理解函数</li>
<li>常用的内置函数</li>
<li>os路径库</li>
<li>内置库csv文件库</li>
<li>常见错误汇总</li>
</ul>
<h2 id="二数据采集">二、数据采集</h2>
<ul>
<li>网络爬虫原理</li>
<li>寻找网址规律</li>
<li>获取网页-requests库</li>
<li>pyquery库解析html网页</li>
<li><strong>案例:</strong> 豆瓣小说</li>
<li>json库解析json网页</li>
<li><strong>案例:</strong> 豆瓣电影</li>
<li><strong>案例:</strong> 微博</li>
<li><strong>案例:</strong> 文件下载</li>
<li><strong>案例:</strong> 上市公司定期报告pdf批量下载</li>
<li>区分动态网站与静态网站</li>
</ul>
<h2 id="三文本初识">三、文本初识</h2>
<ul>
<li>从信息传播视角重新认识文本</li>
<li>读取各类文件中的数据</li>
<li><strong>案例:</strong>  识别图片中的文本</li>
<li>数据清洗re库</li>
<li><strong>案例:</strong> 将多个数据文件汇总至一个csv文件</li>
<li><strong>案例:</strong> 中文jieba分词、词频统计、制作词云图</li>
<li><strong>案例:</strong> 使用共现(word2vec)法扩展情感词典</li>
<li><strong>案例:</strong> 使用词典做情感分析(无权重)</li>
<li><strong>案例:</strong> 数据分析pandas库快速入门</li>
<li><strong>案例:</strong> 使用pandas对excel中的文本进行情感分析</li>
</ul>
<h2 id="四文本进阶">四、文本进阶</h2>
<ul>
<li>文本分析与机器学习</li>
<li>特征工程-认识词袋法、one-hot、Tf-Idf、word2vec</li>
<li>将文档转为机器可处理的向量</li>
<li><strong>案例:</strong> 使用情感词典和tf-idf做情感分析（有权重）</li>
<li><strong>案例:</strong> 在线评论文本分类</li>
<li><strong>案例:</strong> 使用文本相似性识别变化(政策连续性)</li>
<li><strong>案例:</strong> Kmeans聚类算法、LDA话题模型</li>
<li>文本中的人类记忆(认知)</li>
<li>如何测量人类认知偏见(刻板印象)</li>
<li><strong>案例:</strong> 词向量模型的使用方法-豆瓣影评</li>
<li>文本分析在经管社科领域中的应用概述</li>
</ul>
<br>
<h2 id="参考文献">参考文献</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">[1]沈艳, 陈赟 and 黄卓, 2019. 文本大数据分析在经济学和金融学中的应用: 一个文献综述. *经济学 (季刊)*, *18*(4), pp.1153-1186.
[2]冉雅璇,李志强,刘佳妮,张逸石.大数据时代下社会科学研究方法的拓展——基于词嵌入技术的文本分析的应用[J/OL].南开管理评论:1-27[2022-04-08].http://kns.cnki.net/kcms/detail/12.1288.F.20210905.1337.002.html
[3]王伟,陈伟,祝效国,王洪伟. 众筹融资成功率与语言风格的说服性-基于Kickstarter的实证研究.*管理世界*.2016;5:81-98.
[4]胡楠,薛付婧,王昊楠.管理者短视主义影响企业长期投资吗？——基于文本分析和机器学习[J].管理世界,2021,37(05):139-156+11+19-21.
[5]Kai Li, Feng Mai, Rui Shen, Xinyan Yan, Measuring Corporate Culture Using Machine Learning, *The Review of Financial Studies*,2020
[6]Loughran T, McDonald B. Textual analysis in accounting and finance: A survey[J]. *Journal of Accounting Research*, 2016, 54(4): 1187-1230. Author links open overlay panelComputational socioeconomics
[7]Berger, Jonah, Ashlee Humphreys, Stephan Ludwig, Wendy W. Moe, Oded Netzer, and David A. Schweidel. &#34;Uniting the tribes: Using text for marketing insight.&#34; *Journal of Marketing* 84, no. 1 (2020): 1-25.
[8]Banks, George C., Haley M. Woznyj, Ryan S. Wesslen, and Roxanne L. Ross. &#34;A review of best practice recommendations for text analysis in R (and a user-friendly app).&#34; *Journal of Business and Psychology* 33, no. 4 (2018): 445-459.
[9]Cohen, Lauren, Christopher Malloy, and Quoc Nguyen. &#34;Lazy prices.&#34; *The Journal of Finance* 75, no. 3 (2020): 1371-1415.
[10]孟庆斌, 杨俊华, 鲁冰. 管理层讨论与分析披露的信息含量与股价崩盘风险——基于文本向量化方法的研究[J]. *中国工业经济*, 2017 (12): 132-150.
[11]Wang, Quan, Beibei Li, and Param Vir Singh. &#34;Copycats vs. Original Mobile Apps: A Machine Learning Copycat-Detection Method and Empirical Analysis.&#34; *Information Systems Research* 29.2 (2018): 273-291.
[12]Hoberg, Gerard, and Gordon Phillips. 2016, Text-based network industries and endogenous product differentiation,?*Journal of Political Economy* 124, 1423-1465
[13]Loughran, Tim, and Bill McDonald. &#34;When is a liability not a liability? Textual analysis, dictionaries, and 10‐Ks.&#34; *The Journal of Finance* 66, no. 1 (2011): 35-65.
[14]Fairclough, Norman. 2003. Analysing discourse: Textual analysis for social research (Psychology Press)
[15]Grimmer, Justin, and Brandon M Stewart. 2013, Text as data: The promise and pitfalls of automatic content analysis methods for political texts, *Political analysis*21, 267-297.
[16]Markowitz, D. M., &amp; Shulman, H. C. (2021). The predictive utility of word familiarity for online engagements and funding. Proceedings of the National Academy of Sciences, 118(18).
[17]Packard, Grant, and Jonah Berger. “How concrete language shapes customer satisfaction.” Journal of Consumer Research 47, no. 5 (2021): 787-806.
[18]Chen, H., Yang, C., Zhang, X., Liu, Z., Sun, M. and Jin, J., 2021. From Symbols to Embeddings: A Tale of Two Representations in Computational Social Science. Journal of Social Computing, 2(2), pp.103-156.
[19]Lawson, M. Asher, Ashley E. Martin, Imrul Huda, and Sandra C. Matz. &#34;Hiring women into senior leadership positions is associated with a reduction in gender stereotypes in organizational language.&#34; *Proceedings of the National Academy of Sciences* 119, no. 9 (2022): e2026443119.
</code></pre></div>]]></content:encoded>
    </item>
    
    <item>
      <title>视频2022 | 文本分析在经管研究中的应用</title>
      <link>https://textdata.cn/blog/2022-09-08-dufe-text-mining-in-ms/</link>
      <pubDate>Thu, 08 Sep 2022 00:00:00 +0000</pubDate>
      
      <guid>/blog/2022-09-08-dufe-text-mining-in-ms/</guid>
      <description>报告以文本分析方法为例，围绕着文本产生、作用、算法、编程四个方面展开。报告人结合自己的最新研究对大数据时代文本分析方法在管理领域的应用展开讨论，介绍文本编码常见算法，诸如词典法、文档向量化、词向量等，分享此类研究的过程和要点。东北财经大学管理科学与工程学院。Application of Text Analysis in Economics and Management Research</description>
      <content:encoded><![CDATA[<p><a href="https://smse.dufe.edu.cn/content_69944.html"><img loading="lazy" src="img/cover.png" alt=""  />
</a></p>
<p><br><br></p>
<h2 id="slideshttpstextdatacnblog2022-09-08-dufe-text-mining-in-msslideshtml"><a href="https://textdata.cn/blog/2022-09-08-dufe-text-mining-in-ms/slides.html">Slides</a></h2>
<iframe
    src="//player.bilibili.com/player.html?bvid=BV1se4y1C7MV&page=1"
    scrolling="no"
    height="500px"
    width="800px"
    frameborder="no"
    framespacing="0"
    allowfullscreen="true"
>
</iframe>

<p><br><br></p>
<h2 id="背景">背景</h2>
<p><img loading="lazy" src="img/multitudes-of-content-illustration.jpeg" alt=""  />
</p>
<p>在经管研究中，往往会涉及很多文本数据的编码。但是做研究面临两个问题:</p>
<h3 id="难题1--数据量大">难题1- 数据量大</h3>
<p>量太大，以至于废人力所能及。</p>
<p>时代发展，体现在数据上的特点就是数据大爆炸，过去做经管研究，使用访谈等研究方法，收录的文本内容，规模大多停留在M级。但是现在大数据时代，研究对象相关的文本数据，G级的数据量也是很常见的。</p>
<h3 id="难题2--格式乱">难题2- 格式乱</h3>
<p>信息存储技术发展，有应用不同场景的不同数据存储格式。数据可能是pdf、txt、docx，也可能是音频、视频等转录的文件。如果快捷整理，这也是个难点。</p>
<h3 id="难题3-难编码">难题3-难编码</h3>
<p>数据量少，可以人工阅读对数据进行理解和编码。但是当数据量大到无法处理的级别后，选择何种算法、各种算法技术的优缺点如何把握，对经管学者也是一个需要攻克的的技术难题。</p>
<p><img loading="lazy" src="img/consumer_org_society.png" alt=""  />
</p>
<p>难度大，但因为文本涉及的主体错综复杂，千丝万缕，所以可以研究很多对象。如个人、组织、社会之间的交互。</p>
<p><br><br></p>
<h2 id="编码解码理论">编码解码理论</h2>
<p>斯图亚特·霍尔在《电视话语的编码和解码》提出 『编码-解码理论』。该理论形成于70年代冷战时期，冷战中不两大阵营为了维护各自的社会稳定，为了在意识形态宣传中取胜，都在宣传工作中投入了重金。</p>
<p>当时的宣传工具是单向的广播模式，媒体作为统治阶级的喉舌，要将统治阶级的偏好、价值观等进行加工，生产相应意识形态内容。</p>
<p>而普罗大众，作为内容的接受者， 一成长于该特定意识形态的社会，同时又有一定的自我意识，所以对于一个宣传内容可能会有三种反应，表里都认同、表认同里不认同、表里都不认同。</p>
<p><img loading="lazy" src="img/SenderReceiver.png" alt=""  />
</p>
<h3 id="使用文本想清楚两个问题">使用文本想清楚两个问题</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">- How text reflects its Sender？
- How text impacts its Receiver？
</code></pre></div><h3 id="使用文本明晰三个角度">使用文本明晰三个角度</h3>
<p>我做的研究使用的文本数据，涉及哪些角色、作用力方向、感兴趣的内容。</p>
<ul>
<li>角色: Sender or Receiver</li>
<li>方向: Reflect or Impact</li>
<li>内容: Sender的意识(认知、偏好、&hellip;)   vs  Receiver的意识(认知、偏好、&hellip;)</li>
</ul>
<p>下面是经管领域研究部分汇总，每个学者根据自己学科研究对象，应该能在4*4的矩阵中找到自己对应的位置</p>
<p><img loading="lazy" src="img/%e7%94%9f%e4%ba%a7%e4%b8%8e%e6%b6%88%e8%b4%b9.png" alt=""  />
</p>
<blockquote>
<p>Berger, Jonah, Ashlee Humphreys, Stephan Ludwig, Wendy W. Moe, Oded Netzer, and David A. Schweidel. &ldquo;Uniting the tribes: Using text for marketing insight.&rdquo; Journal of Marketing 84, no. 1 (2020): 1-25.</p>
</blockquote>
<p><br><br></p>
<h2 id="人工编码与机器编码">人工编码与机器编码</h2>
<p><img loading="lazy" src="img/unstructrueddata.png" alt=""  />
</p>
<p>做研究需要有干净的数据做实证分析，最为理想的是表数据，例如excel文件，每一行代表一条记录，每一列代表一个字段。编码的作用就是将非机构化的、脏乱的数据整理为干净整洁的表数据。</p>
<p>要明确编码方法的优点和缺点，在合理的适用范围使用。对于文本数据的编码，需要理解人工和机器两种编码方式的优缺点</p>
<table>
<thead>
<tr>
<th style="text-align:left"></th>
<th>分析方法</th>
<th>优点</th>
<th>缺点</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">人工编码</td>
<td>质性（扎根）</td>
<td>少量数据，深刻洞见。</td>
<td>难以应对大数据；<br>编码标准不统一；</td>
</tr>
<tr>
<td style="text-align:left">机器编码</td>
<td>词频、向量相似度、向量距离</td>
<td>标准如一;<br>适合大规模文本挖掘；</td>
<td>需要破坏文本的结构，<br>丧失了部分信息量</td>
</tr>
</tbody>
</table>
<p><br><br></p>
<h2 id="机器编码-将文本转为数字或向量">机器编码-将文本转为数字或向量</h2>
<ul>
<li>
<p>符号法(每个词对应一个数字)</p>
<ul>
<li>词典(词频)法</li>
<li>词袋法、TF-IDF</li>
</ul>
</li>
<li>
<p>词嵌入(每个词对应一个向量)</p>
</li>
</ul>
<p>符号法算法假设词语彼此是语义不相关的，目的是把 <strong>文本</strong> 转为某个数字或<strong>向量</strong>。</p>
<p>而词嵌入算法假设不同的词语是由n维个语义组成的线性组合，目的是把 <strong>词语</strong> 转为<strong>向量</strong>。</p>
<br>
<h3 id="符号法">符号法</h3>
<p>符号法就是数某个词或某类词的出现次数(或占比)。符合法是计算机NLP领域的专业叫法，在经管社科领域，最常见的文本分析软件<a href="https://textdata.cn/blog/liwc_python_text_mining/">LIWC</a>其实也是符号法。而LIWC全(Linguistic Inquiry and Word Count，即语义查询与词频统计。</p>
<p><img loading="lazy" src="img/symbol-representation-1.png" alt=""  />
</p>
<h3 id="符号法的应用">符号法的应用</h3>
<table>
<thead>
<tr>
<th>概念</th>
<th>测量方法</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>认真(努力)</strong></td>
<td>测量文本中词语的个数</td>
</tr>
<tr>
<td><strong>情感</strong></td>
<td>使用情感词典，统计文本中正面词占比</td>
</tr>
<tr>
<td><strong>可读性</strong></td>
<td>文本中高难度(或专业性)词占比</td>
</tr>
<tr>
<td><strong>客观性</strong></td>
<td>文本中某个值的方差，如情感<br>- A<code>产品不错， 包装破损， 态度很好， 综合还是推荐大家购买!</code> [5, 1, 5, 4]<br>- B<code>产品垃圾，使用垃圾， 包装破损， 差评!!</code> [1,  1,  1,  1]<br>A的方差更大，更客观</td>
</tr>
<tr>
<td><strong>相似性(政策稳定性)</strong></td>
<td>cosine(text_vector1, text_vector2)</td>
</tr>
<tr>
<td>&hellip;</td>
<td>&hellip;</td>
</tr>
</tbody>
</table>
<br>
<h3 id="词嵌入">词嵌入</h3>
<p>词嵌入技术有 Word2Vec、Glove，这类技术是挖掘出每个词的上下文语境，通俗的说法就是让计算机，对同样的文章数据，做千万次、上亿次完形填空。这样每个词语都有独特的上下文语义，并以n维向量形式表示，所以词嵌入也可以称之为词向量。</p>
<p><strong>向量模型有近义词相近、概念类似的平行两个特点</strong>。分别举几个例子，方便大家理解。</p>
<p>语义空间是n维，为了便于理解，将其压缩至二维空间。中学的向量大家都比较熟悉，在二维坐标中空间中，两个点的连线可以组成新的向量，相同的向量是平行的。</p>
<p>而在下图的2维语义空间中，good、best语义更接近，所以空间距离更近。同理bad、worst更近。</p>
<p>而vector(good, best)、vector(bad, worst)这两个向量均表示<code>原形-&gt;最高级</code>, 语义向量会近似平行。</p>
<p>同理， vector(good, bad)、 vector(best, worst)两个向量表示 <code>好-&gt;差</code>，语义向量也会近似平行。</p>
<p><img loading="lazy" src="img/embeddings-based.png" alt=""  />
</p>
<br>
<h3 id="词嵌入与认知">词嵌入与认知</h3>
<p>刚刚词嵌入的语义空间中的几个例子，其实就体现了语言的记忆。语义记录了使用该语言的人的记忆。不同的组织，对于同一种概念，会有不同的偏好。例如， Nature2022使用大规模语料数据训练出的词向量，发现语言中残存着人类的某些认知记忆。</p>
<p>通过构建概念词组对儿，在空间中投影，就可以挖掘出词语的在该概念中的分值。例如，使用</p>
<ul>
<li>SMALL = [small, tiny, little&hellip;]</li>
<li>BIG = [big, mega, large&hellip;]</li>
</ul>
<p>每个词都是一个n维的向量，SMALL或BIG都能计算出一个均值向量。大家记得中学的向量投影不，Nature2022就使用这个朴素的方法测量每个动物名称所蕴含的人类尺寸认知。</p>
<p><img loading="lazy" src="img/Concept_Words_Project.png" alt=""  />
</p>
<blockquote>
<p>Grand, G., Blank, I.A., Pereira, F. and Fedorenko, E., 2022. Semantic projection recovers rich human knowledge of multiple object features from word embeddings. Nature Human Behaviour, pp.1-13.</p>
</blockquote>
<br>
<h3 id="技术对比">技术对比</h3>
<p>这里做个表格对比，大家自己感受下三种技术的异同。</p>
<table>
<thead>
<tr>
<th>技术</th>
<th>技术</th>
<th>维度类比</th>
<th>任务</th>
<th>例子</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>符号法-字典</strong>（词频）</td>
<td>数个数</td>
<td>原子</td>
<td>统计每句话里的名词个数</td>
<td>sent_num1 = 2<br>sent_num2 = 1</td>
</tr>
<tr>
<td><strong>符号法-词袋</strong></td>
<td>bag of words<br>one-hot<br>Tf-idf</td>
<td>分子</td>
<td>转化为词向量, 计算两个句子相似度。</td>
<td>vec1 = [1, 1, 1, 1, 1, 0]<br>vec2 = [0, 1, 0, 1, 0, 1]<br>similarity = cosine(vec1, vec2)</td>
</tr>
<tr>
<td><strong>词嵌入</strong></td>
<td>word2vec、<br>glove等</td>
<td>中子、质子、电子</td>
<td>词语相似度。(语义上大小相近，方向相反; 态度、偏见)</td>
<td>mom = [0.2, 0.7, 0.1]<br/>dad   = [0.3, 0.5, -0.2]</td>
</tr>
</tbody>
</table>
<p><br><br></p>
<h2 id="经管-文本分析-文献">经管-文本分析-文献</h2>
<p>在这里我把技术细分为词频、词袋、w2v建词典、w2v认知变迁四个维度，整理了经管7篇论文。大家可以阅读这7篇论文，掌握文本分析的应用场景。</p>
<table>
<thead>
<tr>
<th>文献</th>
<th>定性</th>
<th>词频</th>
<th>词袋</th>
<th>W2V建词典</th>
<th>W2V认知变迁</th>
</tr>
</thead>
<tbody>
<tr>
<td>王伟, 陈伟, 祝效国 and 王洪伟, 2016. 众筹融资成功率与语言风格的说服性&ndash;基于 Kickstarter 的实证研究. <em>管理世界</em>, (5), pp.81-98.</td>
<td>Y</td>
<td>Y</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><a href="https://textdata.cn/blog/jcr_concreteness_computation/">语言具体性如何影响顾客满意度</a><br>Packard, Grant, and Jonah Berger. “How concrete language shapes customer satisfaction.” <em>Journal of Consumer Research</em> 47, no. 5 (2021): 787-806.</td>
<td></td>
<td>Y</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Wang, Quan, Beibei Li, and Param Vir Singh. &ldquo;Copycats vs. original mobile apps: A machine learning copycat-detection method and empirical analysis.&rdquo; Information Systems Research 29, no. 2 (2018): 273-291.</td>
<td></td>
<td></td>
<td>Y</td>
<td></td>
<td></td>
</tr>
<tr>
<td><a href="https://textdata.cn/blog/2019-12-08-lazy-prices/">文本相似度</a><br>Cohen, L., Malloy, C. and Nguyen, Q., 2020. Lazy prices. <em>The Journal of Finance</em>, <em>75</em>(3), pp.1371-1415.</td>
<td></td>
<td></td>
<td>Y</td>
<td></td>
<td></td>
</tr>
<tr>
<td>胡楠, 薛付婧 and 王昊楠, 2021. <a href="https://textdata.cn/blog/text_mining_in_2021_management_world/">管理者短视主义</a>影响企业长期投资吗———基于文本分析和机器学习. <em>管理世界</em>, <em>37</em>(5), pp.139-156.</td>
<td></td>
<td>Y</td>
<td></td>
<td>Y</td>
<td></td>
</tr>
<tr>
<td>Kai Li, Feng Mai, Rui Shen, Xinyan Yan, <a href="https://github.com/MS20190155/Measuring-Corporate-Culture-Using-Machine-Learning">Measuring Corporate Culture Using Machine Learning</a>, The Review of Financial Studies, 2020</td>
<td></td>
<td></td>
<td>Y</td>
<td>Y</td>
<td></td>
</tr>
<tr>
<td>女性就职高管改变组织内性别偏见<br>Lawson, M. Asher, Ashley E. Martin, Imrul Huda, and Sandra C. Matz. &ldquo;Hiring women into senior leadership positions is associated with a reduction in gender stereotypes in organizational language.&rdquo; <em>Proceedings of the National Academy of Sciences</em> 119, no. 9 (2022): e2026443119.</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>Y</td>
</tr>
<tr>
<td>使用词嵌入技术，量化近百年以来性别和族群的刻板印象<br>Garg, Nikhil, Londa Schiebinger, Dan Jurafsky, and James Zou. &ldquo;Word embeddings quantify 100 years of gender and ethnic stereotypes.&rdquo; Proceedings of the National Academy of Sciences 115, no. 16 (2018): E3635-E3644.</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>Y</td>
</tr>
</tbody>
</table>
<p><br><br></p>
<h2 id="案例">案例</h2>
<h3 id="案例1-众筹语言风格">案例1-众筹语言风格</h3>
<p>王伟, 陈伟, 祝效国 and 王洪伟, 2016. 众筹融资成功率与语言风格的说服性&ndash;基于 Kickstarter 的实证研究. <em>管理世界</em>, (5), pp.81-98.</p>
<blockquote>
<p>众筹融资效果决定着众筹平台的兴衰。 众筹行为很大程度上是由投资者的主观因素决定的，而影响主观判断的一个重要因素就是语言的说服性。 而这又是一种典型的用 户产生内容（UGC），项目发起者可以采用任意类型的语言风格对项目进行描述。 不同的语 言风格会改变投资者对项目前景的感知，进而影响他们的投资意愿。 首先，依据 Aristotle 修 辞三元组以及 Hovland 说服模型，采用扎根理论，将众筹项目的语言说服风格分为 5 类：诉诸可信、诉诸情感、诉诸逻辑、诉诸回报和诉诸夸张。</p>
<p>然后，<strong>借助文本挖掘方法，构建说服风格语料库，并对项目摘要进行分类。</strong></p>
<p>最后，建立语言说服风格对项目筹资影响的计量模型，并对 <strong>Kickstarter 平台上的 128345 个项目进行实证分析</strong>。 总体来说，由于项目性质的差异，不同 的项目类别对应于不同的最佳说服风格。</p>
</blockquote>
<p><img loading="lazy" src="img/%e4%bc%97%e7%ad%b9-%e7%a7%8d%e5%ad%90%e8%af%8d.png" alt=""  />

<img loading="lazy" src="img/%e4%bc%97%e7%ad%b9-%e6%b5%81%e7%a8%8b%e5%9b%be.png" alt=""  />
</p>
<br>
<h3 id="案例2-山寨-vs-原创">案例2 山寨 vs 原创</h3>
<p>Wang, Quan, Beibei Li, and Param Vir Singh. &ldquo;Copycats vs. original mobile apps: A machine learning copycat-detection method and empirical analysis.&rdquo; Information Systems Research 29, no. 2 (2018): 273-291.</p>
<blockquote>
<p><strong>进行此类研究的主要威慑因素是缺乏一种客观的方法来识别应用程序是模仿者还是原创者。通过结合自然语言处理，潜在语义分析，基于网络的聚类和图像分析等机器学习技术，我们提出了一种将应用识别为原创app或模仿app，可检测两种模仿者的方法：欺骗性和非欺骗性。</strong></p>
<p>根据检测结果，我们进行了经济计量分析，以确定五年间在iOS App Store中发布的<strong>5,141个开发人员的10,100个动作游戏应用程序</strong>样本中，模仿app对原创app需求的影响。我们的结果表明，特定模仿者对原始应用需求的影响取决于模仿者的质量和欺骗程度。高质量的非欺骗性复制品会对原件产生负面影响。相比之下，低质量，欺骗性的模仿者正面影响了对原创app的需求。</p>
<p>结果表明，从总体上讲，模仿app对原创app需求的影响在统计上是微不足道的。<strong>我们的研究通过提供一种识别模仿app的方法</strong>，并提供模仿app对原创app需求影响的证据，为越来越多的移动应用消费文献做出了贡献。</p>
</blockquote>
<p><img loading="lazy" src="img/copycat.png" alt=""  />
</p>
<br>
<h3 id="案例3-lazy-prices文本相似性">案例3 Lazy prices文本相似性</h3>
<p>Cohen, L., Malloy, C. and Nguyen, Q., 2020. <a href="https://textdata.cn/blog/2019-12-08-lazy-prices/">Lazy prices</a>. <em>The Journal of Finance</em>, <em>75</em>(3), pp.1371-1415.</p>
<blockquote>
<p>之前的研究认为，尽管投资者一次对包含重大变化的财务报表的发布作出了迅时反应，但随着时间的流逝，这种公告作用是会减弱的(Brown and Tucker, 2011 and Feldman et al., 2010)。这表示10-K报告会随着时间推移，信息价值大打折扣。尽管我们复现了这个事实，即与常规文件的变更没有重大的公告效应，但我们认为，前人的研究忽略了更重要部分(如MD&amp;A)对对资产价格的影响。</p>
</blockquote>
<blockquote>
<p>确切的说，<strong>并不是报告的披露效应的信息价值变低了，而是投资者越来越难以发现报告中微妙的信息变化， 比如因为报告变得越来越冗杂。投资者只有看到某些新闻后，才会逐渐意识到之前公司报告内容变化的的真正价值</strong>。</p>
<p>使用1995年-2014年所有美国公司季度和年度申报的完整历史记录，研究发现当公司对<strong>报告进行积极更改</strong>时，这种行为<strong>蕴含着</strong>公司未来运营的<strong>重要信号</strong>。</p>
<p><strong>财务报告的语言和结构的变化也对公司的未来收益产生重大影响</strong>：做空&quot;变化&quot;的公司（持有的公司，如果其报告发生变化的，做空该公司股票），买入“不变化”的公司，使用这样的投资组合策略，在2006年的每月alpha值高达1.88%的收益（每年超过22％）。报告中涉及执行官（CEO和CFO）团队的话语风格的变化，或者有关诉讼(风险部分)的话语的变化，都对投资的未来收益有重要作用。</p>
</blockquote>
<p><img loading="lazy" src="img/lazy-prices-1.png" alt=""  />

<img loading="lazy" src="img/lazy-prices-2.png" alt=""  />
</p>
<br>
<h3 id="案例3-女性就职高管改变组织内性别刻板印象-pnas2022">案例3-女性就职高管改变组织内性别刻板印象 PNAS2022</h3>
<p>Lawson, M. Asher, Ashley E. Martin, Imrul Huda, and Sandra C. Matz. &ldquo;Hiring women into senior leadership positions is associated with a reduction in gender stereotypes in organizational language.&rdquo; <em>Proceedings of the National Academy of Sciences</em> 119, no. 9 (2022): e2026443119.</p>
<blockquote>
<p>女性在领导职位上的代表性仍然不足。这种代表性不足至少部分是由将男性与成就导向的代理特征（例如，自信和果断）联系起来的性别刻板印象驱动的。这些刻板印象在语言中得到表达和延续，女性被描述的方式比男性少。目前的研究表明，任命女性担任高层管理人员可以减轻这些以语言表达的根深蒂固的刻板印象。我们使用自然语言处理技术分析了超过 <strong>43,000 份包含 12.3 亿字的文档，发现聘用女性首席执行官和董事会成员与组织使用语言的变化有关，因此女性的语义变得更类似于代理的语义</strong>。换句话说，雇用女性担任领导职务有助于将女性与对领导成功至关重要的特征联系起来。重要的是，我们的研究结果表明，通过增加女性代表来改变组织语言可能会为女性提供摆脱双重束缚的途径：当女性领导人被任命担任权力职位时，女性与代理的积极方面（例如，独立和自信）在语言上，不以减少与社区的联系（例如，善良和关怀）为代价。总而言之，我们的研究结果表明，女性代表不仅是目的，而且是系统地改变阴险的性别刻板印象并克服女性被认为是有能力或可爱的权衡的一种手段。</p>
<p>本文使用的词向量， 刻画研究对象的文化认知，是依对象依时间而变化的。</p>
</blockquote>
<p><img loading="lazy" src="img/hiring_women.png" alt=""  />
</p>
<br>
<h3 id="案例4--使用词嵌入技术量化近百年以来性别和族群的刻板印象-pnas2018">案例4- 使用词嵌入技术，量化近百年以来性别和族群的刻板印象 PNAS2018</h3>
<iframe
    src="//player.bilibili.com/player.html?bvid=BV1b4411X7i1&page=1"
    scrolling="no"
    height="500px"
    width="800px"
    frameborder="no"
    framespacing="0"
    allowfullscreen="true"
>
</iframe>

<p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>ManagementScience | 使用网络算法识别创新的颠覆性与否</title>
      <link>https://textdata.cn/blog/2022-09-07-management-science-disrupt-science-and-technology/</link>
      <pubDate>Wed, 07 Sep 2022 00:00:00 +0000</pubDate>
      
      <guid>/blog/2022-09-07-management-science-disrupt-science-and-technology/</guid>
      <description>The CD index is a new approach to finding important points in evolving networks. When applied to large-scale data sets like U.S. patent citations, the index is useful for identifying influential innovations and other features of technological change.</description>
      <content:encoded><![CDATA[


<p>颠覆式创新是一个很火的概念，在创新创业、科学学等研究中，每个专利、论文的正文中都会引用关系，而引用关系会构成一个引用网络。</p>
<p>那么创新如何从网络形态进行区分，如何计算网络节点的创新程度，本文列举两篇与此相关的论文，分别是 Management science 和 Science 。</p>
<p><br><br></p>
<div id="文献摘要" class="section level2">
<h2>文献摘要</h2>
<p><strong>Funk, Russell J., and Jason Owen-Smith. “A dynamic network measure of technological change.” <em>Management science</em> 63, no. 3 (2017): 791-817.</strong></p>
<p>该文使用网络分析方法研究技术变革，论文认为 <strong>颠覆性的新发明，通过将发明者的注意力转移到或远离这些发明所依赖的知识，来重塑相互关联的技术网络。即更广的视野或更久远的视角，往往有利于颠覆性创新的产生</strong>。<strong>基于该思路，本文开发了新发明的颠覆性与否的计算指标cdindex</strong>。我们将这些指标应用于大学研究商业化的分析，并发现 <strong>联邦研究资金推动校园产生颠覆性创新，而商业联系会有利于巩固现状的创新</strong>。通过量化新技术，我们提出的指数允许基于专利的创新研究捕捉概念上重要的现象， 这些现象无法通过既定措施检测到。该测量方法提供了支持创新、创业、技术战略、科学政策和社会网络理论研究的理论发展的经验见解。</p>
<blockquote>
<p>Abstract: This article outlines a network approach to the study of technological change. We propose that new inventions reshape networks of interlinked technologies by shifting inventors’ attention to or away from the knowledge on which those inventions build. Using this approach, we develop novel indexes of the extent to which a new invention consolidates or destabilizes existing technology streams. We apply these indexes in analyses of university research commercialization and ﬁnd that, although federal research funding pushes campuses to create inventions that are more destabilizing, deeper commercial ties lead them to produce technologies that consolidate the status quo. By quantifying the eﬀects that new technologies have on their predecessors, the indexes we propose allow patent-based studies of innovation to capture conceptually important phenomena that are not detectable with established measures. The measurement approach presented here oﬀers empirical insights that support theoretical development in studies of innovation, entrepreneurship, technology strategy, science policy, and social network theory.</p>
</blockquote>
<p><br></p>
<p><strong>Wu, Lingfei, Dashun Wang, and James A. Evans. “Large teams develop and small teams disrupt science and technology.” Nature 566, no. 7744 (2019): 378-382.</strong></p>
<p>当今科学和技术最普遍的趋势之一是各个领域的大型团队的增长，因为孤独的研究人员和小型团队的流行程度正在减少 。团队规模的增加归因于科学活动的专业化、通信技术的改进 或需要跨学科解决方案的现代问题的复杂性。团队规模的这种转变引发了一个问题，即大团队所产生的科技特征是否以及如何不同于小团队。分析了 1954-2014 年期间超过 6500 万篇论文、专利和软件产品，证明在此期间，<strong>较小的团队倾向于将拉长到更大的时间尺度，借鉴过去，用新的想法和机会来颠覆科学和技术；而较大的团队倾向于聚焦于当前流行的，完善当前现有的</strong>。不论团队大小，均对于蓬勃发展的科学技术生态至关重要，并表明，为实现这一目标，科学政策应旨在支持团队规模的多样性。</p>
<blockquote>
<p>Abstract: One of the most universal trends in science and technology today is the growth of large teams in all areas, as solitary researchers and small teams diminish in prevalence. Increases in team size have been attributed to the specialization of scientific activities,
improvements in communication technology, or the complexity
of modern problems that require interdisciplinary solutions.This shift in team size raises the question of whether and how the character of the science and technology produced by large teams differs from that of small teams. Here we analyse more than 65 million papers, patents and software products that span the period 1954–2014, and demonstrate that across this period smaller teams have tended to disrupt science and technology with new ideas and opportunities, whereas larger teams have tended to develop existing ones. Work from larger teams builds on morerecent and popular developments, and attention to their work comes
immediately. By contrast, contributions by smaller teams search more deeply into the past, are viewed as disruptive to science and technology and succeed further into the future—if at all. Observed differences between small and large teams are magnified for higherimpact work, with small teams known for disruptive work and large teams for developing work. Differences in topic and research design
account for a small part of the relationship between team size and disruption; most of the effect occurs at the level of the individual, as people move between smaller and larger teams. These results demonstrate that both small and large teams are essential to a flourishing ecology of science and technology, and suggest that, to achieve this, science policies should aim to support a diversity of team sizes.</p>
</blockquote>
<p><br><br></p>
</div>
<div id="算法对比" class="section level2">
<h2>算法对比</h2>
<p>我没阅读两篇论文，仅就颠覆性与否的计算方法和图例，感觉算法实现差不多。</p>
<div class="figure">
<img src="img/cdindex-managent_science_2017.png" alt="" />
<p class="caption">上图为2017年Management Science的插图</p>
</div>
<p><br></p>
<div class="figure">
<img src="img/disruption_nature_2019.png" alt="" />
<p class="caption">上图为2019年Nature的插图</p>
</div>
<p><br><br></p>
</div>
<div id="代码数据" class="section level2">
<h2>代码数据</h2>
<p>下面分别为Management2017和Nature2019的主页，均含数据和代码。</p>
<p><a href="http://russellfunk.org/cdindex/"><img src="img/cdindex-homepage.png" /></a></p>
<p><br></p>
<p><a href="https://lingfeiwu.github.io/smallTeams/"><img src="img/nature2019-disrupt-homepage.png" /></a></p>
<p><br><br></p>
</div>
<div id="算法实现" class="section level2">
<h2>算法实现</h2>
<p>按照时间优先原则，本文就只分享Management2017论文作者Funk, Russell开源了cdindex库 (开发语言C和Python) ，安装</p>
<p><br></p>
<pre><code>pip3 install cdindex</code></pre>
<p>将Management2017 cdindex算法图 标注为如下图， 下图中左右两个网络节点是相同的，只需构造一套节点，两套边数据即可完成实验。</p>
<p><img src="img/cdindex-managent_science_2017_demo.png" /></p>
<p><br></p>
<p>我们就直接上代码</p>
<pre class="python"><code>import cdindex
import datetime

#节点，理解为专利号或者论文doi号；同时节点有先后时间属性
vertices = [{&quot;name&quot;: &quot;x1&quot;, &quot;time&quot;: datetime.datetime(1990, 1, 1)},
           {&quot;name&quot;: &quot;x2&quot;, &quot;time&quot;: datetime.datetime(1990, 1, 1)},
           {&quot;name&quot;: &quot;x3&quot;, &quot;time&quot;: datetime.datetime(1990, 1, 1)},
           {&quot;name&quot;: &quot;x4&quot;, &quot;time&quot;: datetime.datetime(1990, 1, 1)},
        
           {&quot;name&quot;: &quot;y&quot;, &quot;time&quot;: datetime.datetime(1991, 1, 1)},
          
           {&quot;name&quot;: &quot;z1&quot;, &quot;time&quot;: datetime.datetime(1995, 1, 1)},
           {&quot;name&quot;: &quot;z2&quot;, &quot;time&quot;: datetime.datetime(1995, 1, 1)},
           {&quot;name&quot;: &quot;z3&quot;, &quot;time&quot;: datetime.datetime(1995, 1, 1)},
           {&quot;name&quot;: &quot;z4&quot;, &quot;time&quot;: datetime.datetime(1995, 1, 1)},
           {&quot;name&quot;: &quot;z5&quot;, &quot;time&quot;: datetime.datetime(1995, 1, 1)},
           {&quot;name&quot;: &quot;z6&quot;, &quot;time&quot;: datetime.datetime(1995, 1, 1)}]
           
    
#edges_1边关系
#edges_1中的y为颠覆型
edges_1 = [{&quot;source&quot;: &quot;z1&quot;, &quot;target&quot;: &quot;y&quot;},
           {&quot;source&quot;: &quot;z2&quot;, &quot;target&quot;: &quot;y&quot;},
           {&quot;source&quot;: &quot;z3&quot;, &quot;target&quot;: &quot;y&quot;},
           {&quot;source&quot;: &quot;z4&quot;, &quot;target&quot;: &quot;y&quot;},
           {&quot;source&quot;: &quot;z5&quot;, &quot;target&quot;: &quot;y&quot;},
           {&quot;source&quot;: &quot;z6&quot;, &quot;target&quot;: &quot;y&quot;},
           
           {&quot;source&quot;: &quot;y&quot;, &quot;target&quot;: &quot;x1&quot;},
           {&quot;source&quot;: &quot;y&quot;, &quot;target&quot;: &quot;x2&quot;},
           {&quot;source&quot;: &quot;y&quot;, &quot;target&quot;: &quot;x3&quot;},
           {&quot;source&quot;: &quot;y&quot;, &quot;target&quot;: &quot;x4&quot;}]


#edges_2边关系 
#edges_2中的y为巩固型
edges_2 = [{&quot;source&quot;: &quot;z1&quot;, &quot;target&quot;: &quot;y&quot;},
           {&quot;source&quot;: &quot;z2&quot;, &quot;target&quot;: &quot;y&quot;},
           {&quot;source&quot;: &quot;z3&quot;, &quot;target&quot;: &quot;y&quot;},
           {&quot;source&quot;: &quot;z4&quot;, &quot;target&quot;: &quot;y&quot;},
           {&quot;source&quot;: &quot;z5&quot;, &quot;target&quot;: &quot;y&quot;},
           {&quot;source&quot;: &quot;z6&quot;, &quot;target&quot;: &quot;y&quot;},
           
           {&quot;source&quot;: &quot;y&quot;, &quot;target&quot;: &quot;x1&quot;},
           {&quot;source&quot;: &quot;y&quot;, &quot;target&quot;: &quot;x2&quot;},
           {&quot;source&quot;: &quot;y&quot;, &quot;target&quot;: &quot;x3&quot;},
           {&quot;source&quot;: &quot;y&quot;, &quot;target&quot;: &quot;x4&quot;},
          
          {&quot;source&quot;: &quot;z1&quot;, &quot;target&quot;: &quot;x1&quot;},
          {&quot;source&quot;: &quot;z2&quot;, &quot;target&quot;: &quot;x1&quot;},
          {&quot;source&quot;: &quot;z3&quot;, &quot;target&quot;: &quot;x2&quot;},
           
          {&quot;source&quot;: &quot;z4&quot;, &quot;target&quot;: &quot;x3&quot;},
          {&quot;source&quot;: &quot;z5&quot;, &quot;target&quot;: &quot;x3&quot;},
          {&quot;source&quot;: &quot;z5&quot;, &quot;target&quot;: &quot;x4&quot;},
          {&quot;source&quot;: &quot;z6&quot;, &quot;target&quot;: &quot;x4&quot;}]



# 构建两个网络
graph1 = cdindex.Graph() #颠覆型
graph2 = cdindex.Graph() #发展型

# 添加节点
for vertex in vertices:
    graph1.add_vertex(vertex[&quot;name&quot;], cdindex.timestamp_from_datetime(vertex[&quot;time&quot;]))
    graph2.add_vertex(vertex[&quot;name&quot;], cdindex.timestamp_from_datetime(vertex[&quot;time&quot;]))

# 添加引用关系
for edge in edges_1:
    graph1.add_edge(edge[&quot;source&quot;], edge[&quot;target&quot;])
for edge in edges_2:
    graph2.add_edge(edge[&quot;source&quot;], edge[&quot;target&quot;])
    
    
#y研究发布后1825天内，引用y的论文(专利)列入网络。
t_delta = int(datetime.timedelta(days=1825).total_seconds())

#计算cdindex得分
score1 = graph1.cdindex(&quot;y&quot;, t_delta)
score2 = graph2.cdindex(&quot;y&quot;, t_delta)

print(&#39;左侧-网络中的y节点的cdinex得分: {}, 节点y 为颠覆性创新&#39;.format(score1))</code></pre>
<pre><code>## 左侧-网络中的y节点的cdinex得分: 1.0, 节点y 为颠覆性创新</code></pre>
<p><br></p>
<pre class="python"><code>print(&#39;右侧-网络中的y节点的cdinex得分: {}, 节点y 为发展性创新&#39;.format(score2))</code></pre>
<pre><code>## 右侧-网络中的y节点的cdinex得分: -1.0, 节点y 为发展性创新</code></pre>
<p><br><br></p>
</div>
<div id="cdindex" class="section level2">
<h2>cdindex</h2>
<p>对比Python的结果，与论文计算过程，完全一致。cdindex内部实现我不太熟悉，如果想了解cdindex内部实现，可前往 <a href="https://github.com/russellfunk/cdindex" class="uri">https://github.com/russellfunk/cdindex</a> 阅读cdindex库的源码。
<img src="img/cdindex-managent_science_2017.png" /></p>
</div>
]]></content:encoded>
    </item>
    
    <item>
      <title>实战 | 构建基于客户细分的 K-Means 聚类算法！</title>
      <link>https://textdata.cn/blog/customer_segment_with_kmeans/</link>
      <pubDate>Thu, 09 Jun 2022 18:43:10 +0600</pubDate>
      
      <guid>/blog/customer_segment_with_kmeans/</guid>
      <description>客群细分对于企业了解目标受众非常重要。根据受众群体的不同，我们可以给采取不同的营销策略。目前有许多无监督的机器学习算法可以帮助公司识别他们的用户群并创建消费群体。</description>
      <content:encoded><![CDATA[<p>客群细分对于企业了解目标受众非常重要。根据受众群体的不同，我们可以给采取不同的营销策略。目前有许多无监督的机器学习算法可以帮助公司识别他们的用户群并创建消费群体。</p>
<p>在本文中，我将分享一种目前比较流行的 K-Means 聚类的无监督学习技术。K-Means的目标是将所有可用的数据分组为彼此不同的不重叠的子组。K-Means聚类是数据科学家用来帮助公司进行客户细分的常用技术。</p>
<p>在本文中，你将了解以下内容：</p>
<ul>
<li>K-Means聚类的数据预处理</li>
<li>从头构建K-Means聚类算法</li>
<li>用于评估聚类模型性能的指标</li>
<li>可视化构建簇类</li>
<li>簇类构建的解读与分析</li>
</ul>
<h2 id="代码下载">代码下载</h2>
<p><a href="customer_segment_with_kmeans.zip">点击下载</a></p>
<br>
<h2 id="预备知识">预备知识</h2>
<p>在开始之前安装以下库：pandas、numpy、matplotlib、seaborn、sciket learn、kneed。完成后，我们就可以开始制作模型了！</p>
<p>本文中要的数据集可以文末下载，运行以下代码行以导入必要的库并读取数据集：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;Mall_Customers.csv&#39;</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>CustomerID</th>
      <th>Gender</th>
      <th>Age</th>
      <th>Annual Income (k$)</th>
      <th>Spending Score (1-100)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>Male</td>
      <td>19</td>
      <td>15</td>
      <td>39</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>Male</td>
      <td>21</td>
      <td>15</td>
      <td>81</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>Female</td>
      <td>20</td>
      <td>16</td>
      <td>6</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>Female</td>
      <td>23</td>
      <td>16</td>
      <td>77</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>Female</td>
      <td>31</td>
      <td>17</td>
      <td>40</td>
    </tr>
  </tbody>
</table>
</div>
<p>数据集中有五个变量。CustomerID是数据集中每个客户的唯一标识符，我们可以删除这个变量。它没有为我们提供任何有用的集群信息。由于 gender 是一个分类变量，它需要编码并转换成数字。</p>
<p>在输入模型之前，其他所有变量都将按正态分布进行缩放。我们将标准化这些变量，平均值为0，标准偏差为1。</p>
<br>
<h2 id="标准化变量">标准化变量</h2>
<p>首先，让我们标准化数据集中的所有变量，使它们在相同的范围内。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>

<span class="n">col_names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Annual Income (k$)&#39;</span><span class="p">,</span> <span class="s1">&#39;Age&#39;</span><span class="p">,</span> <span class="s1">&#39;Spending Score (1-100)&#39;</span><span class="p">]</span>
<span class="n">features</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">col_names</span><span class="p">]</span>

<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">features</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
<span class="n">features</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">features</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
<span class="n">scaled_features</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">columns</span> <span class="o">=</span> <span class="n">col_names</span><span class="p">)</span>
<span class="n">scaled_features</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Annual Income (k$)</th>
      <th>Age</th>
      <th>Spending Score (1-100)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>-1.738999</td>
      <td>-1.424569</td>
      <td>-0.434801</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-1.738999</td>
      <td>-1.281035</td>
      <td>1.195704</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-1.700830</td>
      <td>-1.352802</td>
      <td>-1.715913</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-1.700830</td>
      <td>-1.137502</td>
      <td>1.040418</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-1.662660</td>
      <td>-0.563369</td>
      <td>-0.395980</td>
    </tr>
  </tbody>
</table>
</div>
<p>我们可以看到所有的变量都被转换了，现在都以零为中心。</p>
<br>
<h2 id="热编码">热编码</h2>
<p>变量&quot;gender&quot;是分类变量，我们需要把它转换成一个数值变量，可以用pd.get_dummies()来处理。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">gender</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Gender&#39;</span><span class="p">]</span>
<span class="n">newdf</span> <span class="o">=</span> <span class="n">scaled_features</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">gender</span><span class="p">)</span>

<span class="n">newdf</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">newdf</span><span class="p">,</span> <span class="n">prefix</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">prefix_sep</span><span class="o">=</span><span class="s1">&#39;_&#39;</span><span class="p">,</span> <span class="n">dummy_na</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">drop_first</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

<span class="n">newdf</span> <span class="o">=</span> <span class="n">newdf</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s1">&#39;Gender_Male&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">newdf</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Annual Income (k$)</th>
      <th>Age</th>
      <th>Spending Score (1-100)</th>
      <th>Gender_Female</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>-1.738999</td>
      <td>-1.424569</td>
      <td>-0.434801</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-1.738999</td>
      <td>-1.281035</td>
      <td>1.195704</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-1.700830</td>
      <td>-1.352802</td>
      <td>-1.715913</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-1.700830</td>
      <td>-1.137502</td>
      <td>1.040418</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-1.662660</td>
      <td>-0.563369</td>
      <td>-0.395980</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>
<p>可以看到，性别变量已经发生了变化，从数据框中删除了“Gender_Male”。这是因为不需要再保留变量了。</p>
<br>
<h2 id="建立聚类模型">建立聚类模型</h2>
<p>让我们构建一个 K-means 聚类模型，并将其拟合到数据集中的所有变量上，我们用肘部图可视化聚类模型的性能，它会告诉我们在构建模型时使用的「最佳聚类数」。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">SSE</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">cluster</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">10</span><span class="p">):</span>
    <span class="n">kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span> <span class="o">=</span> <span class="n">cluster</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="s1">&#39;k-means++&#39;</span><span class="p">)</span>
    <span class="n">kmeans</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">newdf</span><span class="p">)</span>
    <span class="n">SSE</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">kmeans</span><span class="o">.</span><span class="n">inertia_</span><span class="p">)</span>

<span class="c1"># converting the results into a dataframe and plotting them</span>

<span class="n">frame</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;Cluster&#39;</span><span class="p">:</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">10</span><span class="p">),</span> <span class="s1">&#39;SSE&#39;</span><span class="p">:</span><span class="n">SSE</span><span class="p">})</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">frame</span><span class="p">[</span><span class="s1">&#39;Cluster&#39;</span><span class="p">],</span> <span class="n">frame</span><span class="p">[</span><span class="s1">&#39;SSE&#39;</span><span class="p">],</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Number of clusters&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Inertia&#39;</span><span class="p">)</span>
</code></pre></div><pre><code>Text(0, 0.5, 'Inertia')
</code></pre>
<p>​ <br>
<img loading="lazy" src="output_9_1.png" alt="png"  />

​</p>
<p>根据上面的「肘部图」，我们可以看到最佳聚类数为「4」</p>
<br>
<h2 id="轮廓系数">轮廓系数</h2>
<p>轮廓系数或轮廓分数是用于评估该算法创建的簇的质量的方法。轮廓分数在-1到+1之间。轮廓分数越高，模型越好。轮廓分数度量同一簇中所有数据点之间的距离。这个距离越小，轮廓分数就越好。</p>
<p>让我们计算一下我们刚刚建立的模型的轮廓分数：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">silhouette_score</span>
<span class="c1"># First, build a model with 4 clusters</span>

<span class="n">kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="s1">&#39;k-means++&#39;</span><span class="p">)</span>
<span class="n">kmeans</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">newdf</span><span class="p">)</span>

<span class="c1"># Now, print the silhouette score of this model</span>

<span class="nb">print</span><span class="p">(</span><span class="n">silhouette_score</span><span class="p">(</span><span class="n">newdf</span><span class="p">,</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">labels_</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s1">&#39;euclidean&#39;</span><span class="p">))</span>
</code></pre></div><pre><code>0.35027020434653977
</code></pre>
<p>轮廓线得分约为「0.35」。这是一个不错的模型，但我们可以做得更好，并尝试获得更高的簇群分离。</p>
<p>在我们尝试这样做之前，让我们将刚刚构建的聚类可视化，以了解模型的运行情况：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">clusters</span> <span class="o">=</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">newdf</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">1</span><span class="p">:])</span>

<span class="n">newdf</span><span class="p">[</span><span class="s2">&#34;label&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="n">clusters</span>
 
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">21</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">,</span> <span class="n">projection</span><span class="o">=</span><span class="s1">&#39;3d&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">newdf</span><span class="p">[</span><span class="s1">&#39;Age&#39;</span><span class="p">][</span><span class="n">newdf</span><span class="o">.</span><span class="n">label</span> <span class="o">==</span> <span class="mi">0</span><span class="p">],</span> 
           <span class="n">newdf</span><span class="p">[</span><span class="s2">&#34;Annual Income (k$)&#34;</span><span class="p">][</span><span class="n">newdf</span><span class="o">.</span><span class="n">label</span> <span class="o">==</span> <span class="mi">0</span><span class="p">],</span> 
           <span class="n">df</span><span class="p">[</span><span class="s2">&#34;Spending Score (1-100)&#34;</span><span class="p">][</span><span class="n">newdf</span><span class="o">.</span><span class="n">label</span> <span class="o">==</span> <span class="mi">0</span><span class="p">],</span> 
           <span class="n">c</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">60</span><span class="p">)</span>

<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">newdf</span><span class="p">[</span><span class="s1">&#39;Age&#39;</span><span class="p">][</span><span class="n">newdf</span><span class="o">.</span><span class="n">label</span> <span class="o">==</span> <span class="mi">1</span><span class="p">],</span> 
           <span class="n">newdf</span><span class="p">[</span><span class="s2">&#34;Annual Income (k$)&#34;</span><span class="p">][</span><span class="n">newdf</span><span class="o">.</span><span class="n">label</span> <span class="o">==</span> <span class="mi">1</span><span class="p">],</span> 
           <span class="n">newdf</span><span class="p">[</span><span class="s2">&#34;Spending Score (1-100)&#34;</span><span class="p">][</span><span class="n">newdf</span><span class="o">.</span><span class="n">label</span> <span class="o">==</span> <span class="mi">1</span><span class="p">],</span> 
           <span class="n">c</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">60</span><span class="p">)</span>

<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">newdf</span><span class="p">[</span><span class="s1">&#39;Age&#39;</span><span class="p">][</span><span class="n">newdf</span><span class="o">.</span><span class="n">label</span> <span class="o">==</span> <span class="mi">2</span><span class="p">],</span> 
           <span class="n">newdf</span><span class="p">[</span><span class="s2">&#34;Annual Income (k$)&#34;</span><span class="p">][</span><span class="n">newdf</span><span class="o">.</span><span class="n">label</span> <span class="o">==</span> <span class="mi">2</span><span class="p">],</span> 
           <span class="n">df</span><span class="p">[</span><span class="s2">&#34;Spending Score (1-100)&#34;</span><span class="p">][</span><span class="n">newdf</span><span class="o">.</span><span class="n">label</span> <span class="o">==</span> <span class="mi">2</span><span class="p">],</span> 
           <span class="n">c</span><span class="o">=</span><span class="s1">&#39;green&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">60</span><span class="p">)</span>

<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">newdf</span><span class="p">[</span><span class="s1">&#39;Age&#39;</span><span class="p">][</span><span class="n">newdf</span><span class="o">.</span><span class="n">label</span> <span class="o">==</span> <span class="mi">3</span><span class="p">],</span> 
           <span class="n">newdf</span><span class="p">[</span><span class="s2">&#34;Annual Income (k$)&#34;</span><span class="p">][</span><span class="n">newdf</span><span class="o">.</span><span class="n">label</span> <span class="o">==</span> <span class="mi">3</span><span class="p">],</span> 
           <span class="n">newdf</span><span class="p">[</span><span class="s2">&#34;Spending Score (1-100)&#34;</span><span class="p">][</span><span class="n">newdf</span><span class="o">.</span><span class="n">label</span> <span class="o">==</span> <span class="mi">3</span><span class="p">],</span> 
           <span class="n">c</span><span class="o">=</span><span class="s1">&#39;orange&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">60</span><span class="p">)</span>

<span class="n">ax</span><span class="o">.</span><span class="n">view_init</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span> <span class="mi">185</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div><p>​ <br>
<img loading="lazy" src="output_13_0.png" alt="png"  />

​</p>
<p>从上图可以看出，簇类分离度不是很大。红点与蓝色混合，绿色与黄色重叠，这与轮廓分数一起向我们表明该模型表现不佳。现在，让我们创建一个比这个模型具有更好集群可分离性的新模型。</p>
<br>
<h2 id="建立聚类模型2">建立聚类模型2</h2>
<p>对于这个模型，让我们做一些特征选择。我们可以使用一种叫做主成分分析（PCA）的技术。</p>
<p>PCA 是一种帮助我们降低数据集维数的技术。现在，让我们在数据集上运行PCA：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>

<span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="n">principalComponents</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">newdf</span><span class="p">)</span>

<span class="n">features</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="n">pca</span><span class="o">.</span><span class="n">n_components_</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">pca</span><span class="o">.</span><span class="n">explained_variance_ratio_</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;PCA features&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;variance %&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>

<span class="n">PCA_components</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">principalComponents</span><span class="p">)</span>
</code></pre></div><p>​ <br>
<img loading="lazy" src="output_15_0.png" alt="png"  />

​</p>
<p>这张图表显示了每个主成分分析的组成，以及它的方差。我们可以看到前两个主成分解释了大约70%的数据集方差。我们可以将这两个组件输入到模型中再次构建模型，并选择要使用的簇的数量</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">ks</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">inertias</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">ks</span><span class="p">:</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="n">k</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">PCA_components</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,:</span><span class="mi">2</span><span class="p">])</span>
    <span class="n">inertias</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">inertia_</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ks</span><span class="p">,</span> <span class="n">inertias</span><span class="p">,</span> <span class="s1">&#39;-o&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;number of clusters, k&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;inertia&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">ks</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="output_17_0.png" alt="png"  />

​</p>
<p>同样，看起来「最佳簇数是4」。我们可以用4个簇来计算此模型的轮廓分数：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">model</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">PCA_components</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,:</span><span class="mi">2</span><span class="p">])</span>

<span class="c1"># silhouette score</span>
<span class="nb">print</span><span class="p">(</span><span class="n">silhouette_score</span><span class="p">(</span><span class="n">PCA_components</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,:</span><span class="mi">2</span><span class="p">],</span> <span class="n">model</span><span class="o">.</span><span class="n">labels_</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s1">&#39;euclidean&#39;</span><span class="p">))</span>
</code></pre></div><pre><code>0.6025604455573874
</code></pre>
<p>这个模型的轮廓分数是「0.42」，这比我们之前创建的模型要好。我们可以像前面一样可视化此模型：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">model</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>

<span class="n">clusters</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">PCA_components</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,:</span><span class="mi">2</span><span class="p">])</span>
<span class="n">newdf</span><span class="p">[</span><span class="s2">&#34;label&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="n">clusters</span>
 
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">21</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">,</span> <span class="n">projection</span><span class="o">=</span><span class="s1">&#39;3d&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">newdf</span><span class="o">.</span><span class="n">Age</span><span class="p">[</span><span class="n">newdf</span><span class="o">.</span><span class="n">label</span> <span class="o">==</span> <span class="mi">0</span><span class="p">],</span> <span class="n">newdf</span><span class="p">[</span><span class="s2">&#34;Annual Income (k$)&#34;</span><span class="p">][</span><span class="n">newdf</span><span class="o">.</span><span class="n">label</span> <span class="o">==</span> <span class="mi">0</span><span class="p">],</span> <span class="n">newdf</span><span class="p">[</span><span class="s2">&#34;Spending Score (1-100)&#34;</span><span class="p">][</span><span class="n">newdf</span><span class="o">.</span><span class="n">label</span> <span class="o">==</span> <span class="mi">0</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">60</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">newdf</span><span class="o">.</span><span class="n">Age</span><span class="p">[</span><span class="n">newdf</span><span class="o">.</span><span class="n">label</span> <span class="o">==</span> <span class="mi">1</span><span class="p">],</span> <span class="n">newdf</span><span class="p">[</span><span class="s2">&#34;Annual Income (k$)&#34;</span><span class="p">][</span><span class="n">newdf</span><span class="o">.</span><span class="n">label</span> <span class="o">==</span> <span class="mi">1</span><span class="p">],</span> <span class="n">newdf</span><span class="p">[</span><span class="s2">&#34;Spending Score (1-100)&#34;</span><span class="p">][</span><span class="n">newdf</span><span class="o">.</span><span class="n">label</span> <span class="o">==</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">60</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">newdf</span><span class="o">.</span><span class="n">Age</span><span class="p">[</span><span class="n">newdf</span><span class="o">.</span><span class="n">label</span> <span class="o">==</span> <span class="mi">2</span><span class="p">],</span> <span class="n">newdf</span><span class="p">[</span><span class="s2">&#34;Annual Income (k$)&#34;</span><span class="p">][</span><span class="n">newdf</span><span class="o">.</span><span class="n">label</span> <span class="o">==</span> <span class="mi">2</span><span class="p">],</span> <span class="n">newdf</span><span class="p">[</span><span class="s2">&#34;Spending Score (1-100)&#34;</span><span class="p">][</span><span class="n">newdf</span><span class="o">.</span><span class="n">label</span> <span class="o">==</span> <span class="mi">2</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;green&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">60</span><span class="p">)</span>

<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">newdf</span><span class="o">.</span><span class="n">Age</span><span class="p">[</span><span class="n">newdf</span><span class="o">.</span><span class="n">label</span> <span class="o">==</span> <span class="mi">3</span><span class="p">],</span> <span class="n">newdf</span><span class="p">[</span><span class="s2">&#34;Annual Income (k$)&#34;</span><span class="p">][</span><span class="n">newdf</span><span class="o">.</span><span class="n">label</span> <span class="o">==</span> <span class="mi">3</span><span class="p">],</span> <span class="n">newdf</span><span class="p">[</span><span class="s2">&#34;Spending Score (1-100)&#34;</span><span class="p">][</span><span class="n">newdf</span><span class="o">.</span><span class="n">label</span> <span class="o">==</span> <span class="mi">3</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;orange&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">60</span><span class="p">)</span>

<span class="n">ax</span><span class="o">.</span><span class="n">view_init</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span> <span class="mi">185</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div><p>​ <br>
<img loading="lazy" src="output_21_0.png" alt="png"  />

​</p>
<br> 
<h2 id="模型1与模型2">模型1与模型2</h2>
<p>让我们比较一下这个模型和第一个模型的聚类可分性：</p>
<p>第二个模型中的簇比第一个模型中的簇分离得好得多。此外，第二个模型的轮廓分数要高得多。基于这些原因，我们可以选择第二个模型进行分析。</p>
<br>
<h2 id="聚类分析">聚类分析</h2>
<p>首先，让我们将簇类映射回数据集，并查看数据帧。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;Mall_Customers.csv&#39;</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s1">&#39;CustomerID&#39;</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># map back clusters to dataframe</span>

<span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">PCA_components</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,:</span><span class="mi">2</span><span class="p">])</span>
<span class="n">frame</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
<span class="n">frame</span><span class="p">[</span><span class="s1">&#39;cluster&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pred</span>
<span class="n">frame</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Gender</th>
      <th>Age</th>
      <th>Annual Income (k$)</th>
      <th>Spending Score (1-100)</th>
      <th>cluster</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Male</td>
      <td>19</td>
      <td>15</td>
      <td>39</td>
      <td>3</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Male</td>
      <td>21</td>
      <td>15</td>
      <td>81</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Female</td>
      <td>20</td>
      <td>16</td>
      <td>6</td>
      <td>3</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Female</td>
      <td>23</td>
      <td>16</td>
      <td>77</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Female</td>
      <td>31</td>
      <td>17</td>
      <td>40</td>
      <td>3</td>
    </tr>
  </tbody>
</table>
</div>
<p>数据帧中的每一行现在都分配给一个集群。要比较不同群集的属性，请查找每个群集上所有变量的平均值：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">avg_df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">([</span><span class="s1">&#39;cluster&#39;</span><span class="p">],</span> <span class="n">as_index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

<span class="n">avg_df</span>
</code></pre></div><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>cluster</th>
      <th>Age</th>
      <th>Annual Income (k$)</th>
      <th>Spending Score (1-100)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>25.521739</td>
      <td>26.304348</td>
      <td>78.565217</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>51.681818</td>
      <td>62.125000</td>
      <td>33.750000</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2</td>
      <td>32.904762</td>
      <td>84.380952</td>
      <td>80.500000</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3</td>
      <td>26.659574</td>
      <td>53.106383</td>
      <td>40.042553</td>
    </tr>
  </tbody>
</table>
</div>
<p>如果我们将这些簇可视化，我们可以更容易地解释它们。运行以下代码以获得每个变量的不同可视化效果：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="n">sns</span><span class="o">.</span><span class="n">barplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s1">&#39;cluster&#39;</span><span class="p">,</span><span class="n">y</span><span class="o">=</span><span class="s1">&#39;Age&#39;</span><span class="p">,</span><span class="n">data</span><span class="o">=</span><span class="n">avg_df</span><span class="p">)</span>
</code></pre></div><pre><code>&lt;AxesSubplot:xlabel='cluster', ylabel='Age'&gt;
</code></pre>
<p>​ <br>
<img loading="lazy" src="output_27_1.png" alt="png"  />

​</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">sns</span><span class="o">.</span><span class="n">barplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s1">&#39;cluster&#39;</span><span class="p">,</span><span class="n">y</span><span class="o">=</span><span class="s1">&#39;Spending Score (1-100)&#39;</span><span class="p">,</span><span class="n">data</span><span class="o">=</span><span class="n">avg_df</span><span class="p">)</span>
</code></pre></div><pre><code>&lt;AxesSubplot:xlabel='cluster', ylabel='Spending Score (1-100)'&gt;
</code></pre>
<p>​ <br>
<img loading="lazy" src="output_28_1.png" alt="png"  />

​</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">sns</span><span class="o">.</span><span class="n">barplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s1">&#39;cluster&#39;</span><span class="p">,</span><span class="n">y</span><span class="o">=</span><span class="s1">&#39;Annual Income (k$)&#39;</span><span class="p">,</span><span class="n">data</span><span class="o">=</span><span class="n">avg_df</span><span class="p">)</span>
</code></pre></div><pre><code>&lt;AxesSubplot:xlabel='cluster', ylabel='Annual Income (k$)'&gt;
</code></pre>
<p>​ <br>
<img loading="lazy" src="output_29_1.png" alt="png"  />

​</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df2</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">([</span><span class="s1">&#39;cluster&#39;</span><span class="p">,</span><span class="s1">&#39;Gender&#39;</span><span class="p">])[</span><span class="s1">&#39;Gender&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">count</span><span class="p">())</span>
<span class="n">df2</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th></th>
      <th>Gender</th>
    </tr>
    <tr>
      <th>cluster</th>
      <th>Gender</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="2" valign="top">0</th>
      <th>Female</th>
      <td>14</td>
    </tr>
    <tr>
      <th>Male</th>
      <td>9</td>
    </tr>
    <tr>
      <th rowspan="2" valign="top">1</th>
      <th>Female</th>
      <td>47</td>
    </tr>
    <tr>
      <th>Male</th>
      <td>41</td>
    </tr>
    <tr>
      <th>2</th>
      <th>Female</th>
      <td>23</td>
    </tr>
  </tbody>
</table>
</div>
<p>各细分市场的主要特点</p>
<p><strong>簇类0</strong>:</p>
<ul>
<li>年平均收入高，支出低。</li>
<li>平均年龄在40岁左右，性别以男性为主。</li>
</ul>
<p><strong>簇类1</strong>：</p>
<ul>
<li>中低收入，平均消费能力。</li>
<li>平均年龄在50岁左右，性别以女性为主。</li>
</ul>
<p><strong>簇类2</strong>：</p>
<ul>
<li>平均收入低，消费分数高。</li>
<li>平均年龄在25岁左右，性别以女性为主。</li>
</ul>
<p><strong>簇类3</strong>：</p>
<ul>
<li>平均收入高，消费分数高。</li>
<li>平均年龄在30岁左右，性别以女性为主。</li>
</ul>
<p>值得注意的是，计算年龄中位数将有助于更好地了解每个集群内的年龄分布。</p>
<p>而且，女性在整个数据集中的代表性更高，这就是为什么大多数集群中女性的数量比男性多。我们可以找到每个性别相对于整个数据集中的数字的百分比，以便更好地了解性别分布。</p>
<br>
<h2 id="为每个簇类构建角色">为每个簇类构建角色</h2>
<p>作为一名数据科学家，能够用你的分析讲述一个故事是一项重要的技能，这将帮助你的客户或利益相关者更容易理解你的发现。下面是一个基于创建的簇类构建消费者角色的示例：</p>
<p><strong>簇类0</strong></p>
<p>这个角色由对金钱非常谨慎的中年人组成。尽管与所有其他群体中的个人相比，他们的平均收入最高，但花费最少。这可能是因为他们有经济责任——比如为孩子的高等教育存钱。</p>
<p>建议：促销、优惠券和折扣代码将吸引这一领域的个人，因为他们倾向于少花钱。</p>
<p><strong>簇类1</strong></p>
<p>这部分人包括一个年龄较大的群体。他们挣的少，花的少，而且可能正在为退休储蓄。</p>
<p>建议：针对这些人的营销可以向这一领域的人推广医疗保健相关产品。</p>
<p><strong>簇类2</strong></p>
<p>这一部分由较年轻的年龄组组成。这部分人最有可能是第一批求职者。与其他人相比，他们赚的钱最少。然而，这些人都是热情的年轻人，他们喜欢过上好的生活方式，而且往往超支消费。</p>
<p>建议：由于这些年轻人花费很多，给他们提供旅游优惠券或酒店折扣可能是个好主意。为他们提供折扣的顶级服装和化妆品品牌也将很好地为这一部分。</p>
<p><strong>簇类3</strong></p>
<p>这部分人是由中年人组成的。这些人努力工作，积累了大量财富。他们也花大量的钱来过好的生活。</p>
<p>建议：由于他们的消费能力和人口结构，这些人很可能会寻找房产购买或投资。</p>
<br>
<h2 id="结论">结论</h2>
<p>在本文中，我已经详细的建立了一个用于客户细分的 K-Means 聚类模型。我们还探讨了聚类分析，并分析了每个聚类中个体的行为。最后，我们看了一些可以根据集群中每个人的属性提供的业务建议。</p>
<br>
<br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>转载 | 从符号到嵌入：计算社会科学的两种文本表示</title>
      <link>https://textdata.cn/blog/from_sysbol_to_embeddings_in_computational_social_science/</link>
      <pubDate>Mon, 25 Apr 2022 10:40:10 +0600</pubDate>
      
      <guid>/blog/from_sysbol_to_embeddings_in_computational_social_science/</guid>
      <description>如何有效地表示数据以挖掘我们想要的计算社会科学的含义？为了探索答案，我们对 CSS 中文本和网络的数据表示进行了彻底的回顾，我们将现有的表示总结为两个方案，即基于符号的表示和基于嵌入的表示。How to efficiently represent data to mine the implications we want for computational social science? To explore the answer, we conduct a thorough review of data representations for text and the web in CSS, and we summarize existing representations into two schemes, symbol-based and embedding-based</description>
      <content:encoded><![CDATA[<p>B站看到大牛刘知远关于文本分析在计算社会科学领域应用的分享，解答了我对文本表示的疑惑，看完了能对文本的特征工程加深理解，同时也能更清晰未来如何借助计算机科学技术开展社会科学研究。</p>
<blockquote>
<p><strong>全文摘抄自</strong></p>
<p>Chen, H., Yang, C., Zhang, X., Liu, Z., Sun, M. and Jin, J., 2021. From Symbols to Embeddings: A Tale of Two Representations in Computational Social Science. Journal of Social Computing, 2(2), pp.103-156.</p>
</blockquote>
<iframe
    src="//player.bilibili.com/player.html?bvid=BV1qi4y1Q7qj&page=1"
    scrolling="no"
    height="500px"
    width="800px"
    frameborder="no"
    framespacing="0"
    allowfullscreen="true"
>
</iframe>

<br>
<h2 id="摘要">摘要</h2>
<p><strong>计算社会科学</strong>（CSS），旨在利用计算方法来解决社会科学问题，是一个新兴和快速发展的领域。 CSS 的研究是数据驱动的，并且显着受益于在线用户生成内容和社交网络的可用性，其中包含用于调查的富文本和网络数据。然而，这些大规模、多模态的数据也给研究人员带来了很大的挑战：<strong>如何有效地表示数据以挖掘我们想要的 CSS 含义</strong>？为了探索答案，<strong>我们对 CSS 中文本和网络的数据表示进行了彻底的回顾，我们将现有的表示总结为两个方案，即基于符号的表示和基于嵌入的表示</strong>，并为每个方案介绍了一系列典型的方法。随后，我们基于对来自 6 个涉及 CSS 的顶级场所的 400 多篇研究文章的调查，展示了上述表示的应用。从这些应用程序的统计数据中，<strong>我们挖掘出每种表示的强度，并发现基于嵌入的表示在过去十年中出现并获得越来越多的关注的趋势</strong>。最后，我们讨论了几个关键挑战和未来方向的开放性问题。本调查旨在为 CSS 研究人员提供对数据表示的更深入理解和更明智的应用。</p>
<p><strong>关键词</strong>：计算社会科学；基于符号的表示；基于嵌入的表示；社交网络</p>
<br>
<h2 id="一计算社会学数据分析流程">一、计算社会学数据分析流程</h2>
<p>其中第二步，数据表示目前有两大类表示(特征工程)方法</p>
<ul>
<li><strong>基于符号的文本表示</strong>；符号可以是单词(或词组)，也可以是概念(如正面情感、负面情感)</li>
<li><strong>基于嵌入(分布式)的文本表示</strong>；相比于符号法，将词(词组)看做一个点。嵌入表示认为词是存在更多浅藏含义，存在亲疏远近，是可以比较的词向量。词向量可以有v(king)-v(queen)约等于v(man)-v(woman)</li>
</ul>
<p><img loading="lazy" src="img/fig1.png" alt=""  />
</p>
<br>
<h2 id="二基于符号的文本表示">二、基于符号的文本表示</h2>
<p>基于符号的文本表示一般来说默认词语是不可分的符号，每个词能根据词频统计出现次数的多与少，或是否存在。</p>
<h3 id="21-词语层面">2.1 词语层面</h3>
<ul>
<li>
<p>基于词频表示</p>
<ul>
<li>是否出现，出现标位1，反之标位0。</li>
<li>出现多少，词语出现几次，标为几个。</li>
</ul>
</li>
<li>
<p>基于特征表示，如每个词带有权重(得分)</p>
</li>
<li>
<p>基于网络表示，如词语共现网络(矩阵)</p>
</li>
</ul>
<h3 id="22-句子层面">2.2 句子层面</h3>
<ul>
<li>
<p>基于词频的表示</p>
<ul>
<li>one-hot 将文本转为向量，向量中每个数，词语出现标位1，反之标位0</li>
<li>bag-of-words，将文本转为向量，向量中每个数，词语出现n次标记为n</li>
<li>n-grams，对词组的处理，将词组看做一个单词(整体)。</li>
<li>Tf-Idf ,该算法分为tf和idf两部分。其中tf与bag-of-words类似，考虑词语出现次数。而idf还考虑词语在语料中出现场景的稀缺性程度。</li>
</ul>
</li>
<li>
<p>基于语法特征，如句法依存关系，类似于英语语法，将句子分为主谓宾、动词、名词等。</p>
</li>
<li>
<p>词典法，如使用正、负情感词典，对文本数据进行情感分析，可以得到pos和neg的各自得分</p>
</li>
</ul>
<p><img loading="lazy" src="img/fig2.png" alt=""  />
</p>
<br>
<h2 id="三基于嵌入的文本表示">三、基于嵌入的文本表示</h2>
<h3 id="31词语层面">3.1词语层面</h3>
<p>嵌入表示认为词是存在更多浅藏含义，存在亲疏远近，是可以比较的词向量。词向量可以有v(best)-v(good)约等于v(worst)-v(bad)</p>
<h3 id="32-句子层面">3.2 句子层面</h3>
<p>词语是向量，那么由词语组成的句子也会加权得到一个向量。含有相似话题或含义相近的句子在多维向量空间中会比较接近。</p>
<p><img loading="lazy" src="img/fig7.png" alt=""  />
</p>
<br>
<h2 id="四任务分类文本的用法">四、任务分类：文本的用法</h2>
<p><img loading="lazy" src="img/fig16.png" alt=""  />
</p>
<p>有了文本数据，刚刚解决了如何表示文本。接下来，需要明确，我们使用文本目的是为了做哪类分析，得到哪些信息。有8种常见的文本分析图式</p>
<ul>
<li>描述性。如随时间推移，词频的发展趋势是变大的</li>
<li>相关性。</li>
<li>聚类。如lda话题分析、k-means聚类</li>
<li>相似度。两个文档转为向量后，可以通过cosine计算相似度</li>
<li>分类。机器学习分类，判断某文本隶属于哪个类别</li>
<li>回归。例如根据文本，判断某件事发生的概率</li>
<li>语言模型。</li>
<li>排序。</li>
</ul>
<br>
<h2 id="五发文趋势-符号vs嵌入">五、发文趋势-符号vs嵌入</h2>
<p>基于上一节中对应用程序的介绍，可以观察到基于符号和基于嵌入的表示在 <strong>计算社会科学</strong>中都得到了相当大的采用。为了明确研究它们的覆盖范围，我们计算了每年使用两种表示中的一种或两种的作品数量，如图 17 所示。通过比较nature、science、pnas三大顶级期刊，我们可以发现使用<strong>基于嵌入表示</strong>的文章比例在过去几年中逐渐。这表明越来越多的 计算社会科学文章 已经考虑并受益于基于嵌入表示。</p>
<p>图 18 显示了在 计算机领域ACL、WWW 和 KDD 的会议上中，发现使用基于嵌入的表示的文章数量已大大超过使用基于符号的表示的文章数量。然而，与图 17 相比，计算机科学会议中基于嵌入的表示的数量与三个多学科期刊之间存在很大差距。</p>
<p><img loading="lazy" src="img/3_top_journals.png" alt=""  />
</p>
<p><img loading="lazy" src="img/nlp.png" alt=""  />
</p>
<p>总而言之，在过去十年中，基于嵌入的表示已经出现并在 计算社会科学 中发挥着越来越重要的作用。</p>
<br>
<h2 id="六趋势解读">六、趋势解读</h2>
<p>基于它们的内部机制和现有应用，对趋势解读，我们总结出以下三个关键点。</p>
<p>基于符号的表示因其明确性和可解释性而擅长描述和关系的任务。</p>
<p>基于符号的表示中的每个值都表示一定的人类可读的含义，因此我们可以直接使用它来观察数据的分布，以及提取对象之间的关系。例如，基于频率的词表示用于观察文化变化并捕捉新闻中提及次数与公司股票交易量之间的关系。虽然基于主题模型的表示和一些基于神经的表示在一定程度上具有实际意义，但它们对于社会科学研究人员来说仍然是模糊的并且不那么引人注目。</p>
<p>由于神经网络具有强大的拟合数据和提取深度语义的能力，基于嵌入的表示在预测（例如分类和回归）和相似性任务中表现更好。一方面，神经网络通过大规模神经元的连接实现高效的输入输出映射功能。另一方面，通过多层网络的构建，实现深层语义和抽象概念的提取。现有研究表明，深层捕获相对于浅层更抽象的特征。诸如社会偏见和道德化之类的抽象概念都可以通过基于嵌入的表示来很好地衡量。虽然我们提到基于符号的表示可以通过一些定义的符号来代表抽象概念，但这种表示仍然是部分和肤浅的，很难捕捉到它们的全貌。</p>
<p>基于嵌入的表示需要更少的人力。基于符号的表示通常需要大量的专家知识来定义研究对象的特征，这是劳动密集型的。此外，对于一些没有充分特征的抽象概念或对象，它们的表现将受到限制。与它们不同的是，基于嵌入的表示是从数据中自动提取的，几乎不需要人工干预，甚至可以补充人类知识。例如，可以使用神经网络来自动恢复丢失的巴比伦文本，这即使对专家来说也是具有挑战性的。此外，基于嵌入的表示可以在没有手动定义的情况下描述语言的复杂性和歧义性。</p>
<br> 
<h2 id="七未来展望">七、未来展望</h2>
<p>尽管在过去十年中出现了从符号到嵌入的趋势，但仍有许多挑战和悬而未决的问题有待探索。展望未来，我们列出了一些与计算社会科学 中的数据表示相关的基本和潜在的未来方向。</p>
<p>预训练的语言模型。近年来，预训练的语言模型受到了相当大的关注，并在处理文本数据方面取得了巨大的成功 [100, 240]。这些模型从百科全书和书籍等海量文本数据中学习丰富的语义信息，仅在下游任务中进行微调以实现有效的基于嵌入的表示。因此，对于 计算社会科学，我们可以借助预训练的语言模型获得更通用、更健壮的文本表示。与从传统神经网络模型中学习的表示相比，这些表示不仅可以更广泛、更准确地从文本中分析社会现象，而且还可以减少那些需要大量标记数据的任务的人工注释。</p>
<p>图神经网络。通过消息传递机制，图神经网络 [461] 可以同时有效地对网络拓扑和节点/边缘特征（例如文本信息）进行建模，从而提供一个统一的框架来利用来自异构来源的信息。 计算社会科学 中的许多场景需要处理社交网络以及个人特征。因此，图神经网络技术在 计算社会科学 研究中具有很大的应用潜力，可以学习融合文本和网络信息的表示。事实上，计算机科学中的各种应用，例如自然语言处理 [418] 和推荐系统 [439]，已经采用图神经网络进行建模。</p>
<p>设计为预测和相似性。基于嵌入的表示以丰富和深层次的语义而闻名，而基于符号的表示通常保留在部分和浅层语义中。同时，基于嵌入的表示擅长预测和相似性的任务。因此，为了充分利用嵌入中的强语义，鼓励 计算社会科学 研究人员尽可能将研究问题设计为预测或相似性任务。例如，我们可以将社会偏见问题设计为性别词和中性词嵌入之间的相似性度量 [59, 133]。此外，人类语言的复杂性可以设计为一项预测任务，它以语言模型为指标查看单词或句子的预测概率[155]。</p>
<p>可解释性。诚然，基于嵌入的方法的一个缺点是缺乏可解释性。这个问题会损害与道德、安全或隐私相关的决策关键系统的应用。尽管嵌入模型，尤其是神经网络模型的可解释性尚未完全解决，但计算机科学领域的研究人员已经做出了一些努力，以提高基于神经模型的可解释性 [16]。因此，利用基于嵌入的模型和可解释性分析方法进行有效和（部分）可解释的预测将是一个有趣的方向。</p>
<br>
<h2 id="结论">结论</h2>
<p>计算社会科学作为一个新兴且有前途的跨学科领域，近年来吸引了相当多的研究兴趣。 计算社会科学 研究中广泛使用两种主要类型的数据，即文本数据和网络数据。在本次调查中，我们首先将数据表示总结为基于符号和基于嵌入的表示，并在构建这些表示时进一步介绍典型的方法。之后，我们基于来自 6 个经典期刊和会议的 400 多篇高被引文献，对这两类表示的应用进行了全面回顾。根据对这些应用的统计，发现了 计算社会科学 中基于嵌入的文本和网络表示正在出现和增长的趋势，我们进一步讨论了其中的原因。最后，我们提出了 计算社会科学 中的四个挑战和未解决的问题，它们是需要探索的基本和潜在方向。</p>
<br>
<br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>营销科技 | 今天出门穿什么？时尚电商Stitch Fix</title>
      <link>https://textdata.cn/blog/stitchfix/</link>
      <pubDate>Sun, 27 Mar 2022 10:43:10 +0600</pubDate>
      
      <guid>/blog/stitchfix/</guid>
      <description>“穿衣服是大学问”，不相信可以问问很多女生，每天出门前会不会为了今天要穿什麽衣服而伤脑筋？现在如果有一家公司帮您聘请一个专属的“穿衣顾问”，只在一开始收费120多元（二十块美金）的造型费，然后定期寄来已经帮您量身打造的时尚服饰，您愿意买单吗？不瞒您说，目前全世球已有三百五十万人接受美国一家叫做“Stitch Fix”的穿衣时尚订阅公司的服务。</description>
      <content:encoded><![CDATA[<blockquote>
<ul>
<li>作者：蘇宇暉（台科大管研所博士候選人）、羅凱揚（台科大企管系博士）</li>
<li>日期: 2020-12-14</li>
<li>绘图：彭煖蘋</li>
<li>出处: <a href="https://medium.com/marketingdatascience/%E6%99%82%E5%B0%9A%E9%9B%BB%E5%95%86stitch-fix-6aed7636b2c9">medium</a></li>
</ul>
</blockquote>
<br>
<p>“穿衣服是大学问”，不相信可以问问很多女生，每天出门前会不会为了今天要穿什麽衣服而伤脑筋？现在如果有一家公司帮您聘请一个专属的“穿衣顾问”，只在一开始收费120多元（二十块美金）的造型费，然后定期寄来已经帮您量身打造的时尚服饰，您愿意买单吗？不瞒您说，目前全世球已有三百五十万人接受美国一家叫做“Stitch Fix”的穿衣时尚订阅公司的服务。</p>
<div style="text-align: center;">
<figure >
    <a href="https://www.stitchfix.com/">
        <img src="img/StitchFix.png" width="100%" />
    </a>
    <figcaption><small><i>点击浏览Stitch Fix网站</i></small></figcaption>
</figure>
</div>
<p>2011年6月，刚从哈佛大学商学院毕业的美日混血儿<strong>卡翠娜‧雷克</strong>（Katrina Lake），在美国旧金山成立时尚电商公司Stitch Fix。满脑子有趣想法的雷克，透过募集到的五十万美金，开始了她的创业之旅。短短不到七年的时间，到了2017年11月，Stitch Fix在美国Nasdaq上市。而卡翠娜‧雷克本人也成为2019年《福布斯》全美白手起家女富豪排行榜中的55名。</p>
<p><strong>Stitch Fix的背后，其实是一家充分利用营销研究和营销数据科学，同时提供“穿衣时尚订阅”服务的新创公司。现在让我们来看看，Stitch Fix如何运作</strong>，如图-1所示。</p>
<div style="text-align: center;">
<figure >
    <a href="https://www.stitchfix.com/">
        <img src="img/StitchFix%e8%bf%90%e4%bd%9c.png" width="100%" />
    </a>
    <figcaption><small><i>图-1 StitchFix运作</i></small></figcaption>
</figure>
</div>
<p>消费者在登录Stitch Fix的网站首页时，不会看到像其他购物网站会有太多的商品展示，反而是<strong>介绍穿衣风格才是重点</strong>。而<strong>网站会有造型师来塑造消费者的风格，并且透过这种新的购物方式力邀消费者加入会员</strong>。因此，当消费者在Stitch Fix的网站注册时，Stitch Fix会请会员填答一份详细的问卷，包括顾客的<strong>基本资料、身高、尺码、喜欢的颜色、风格、经常出席的场合、甚至是预算</strong>等。</p>
<p>接著，Stitch Fix每个月就会透过一个称为“<strong>订购盒子</strong>（Subscription Box）”的包裹，一次将五件服饰寄送给顾客。等到消费者收到包裹时，可以留下觉得满意的服饰，看不上眼或者不满意的服饰就再寄回给Stitch Fix。如果消费者将服饰全部留下，就会享受到折扣，反之，如果一件都不想买，就负担二十美元的包裹服务费。</p>
<p>在美国，消费者要买衣服，往往得开车到购物中心或百货公司，买个两三件衣服总要花上半天时间。Stitch Fix一次寄来五件衣服（连同一张纸本问卷），其实也经过精算，因为如果一次寄太多件，消费者心理和预算上都难以承受。而Stitch Fix透过消费者所填答的电脑和纸本问卷，以及购买与退换货记录，利用机器学习算法对消费者喜好与需求进行预测，并结合设计师的搭配，给消费者定制化的建议。因为喜欢的衣服被留下，不喜欢的退回，Stitch Fix就很容易利用这些大量数据建立起消费者穿衣风格的“模型”。</p>
<p>而为了进一步收集到更精准的数据，2017年，Stitch Fix推出了一款Style Shuffle的小游戏，让顾客针对不同的服饰或配件，简单回应喜爱或是不喜爱。借此更进一步收集消费者的偏好，并增加消费者的粘性。Stitch Fix后来并将触角伸向男性服饰以及儿童服饰。而大尺码的女性服饰更是其服务重点。</p>
<p>通过收集大量消费者用户数据，以及不断优化的模型算法，并结合个人造型师和机器学习（AI）进行个性化推荐，让Stitch Fix的时尚订阅制服务，能够更精准地预测与满足消费者偏好的服饰及配件。据了解，截至2019年，该公司拥有8,000名员工，其中包括5,100名造型师和100多名数据科学家。</p>
<p>从以上Stitch Fix的故事中，我们看到了营销研究与数据科学的完美搭配。</p>
<br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>文本相似 | Lazy Prices公司年报内容变动预示重大风险</title>
      <link>https://textdata.cn/blog/2019-12-08-lazy-prices/</link>
      <pubDate>Tue, 31 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/2019-12-08-lazy-prices/</guid>
      <description>一个公司报告文件会有不同部分，我们需要将不同的部分分别识别出来。这里用到正则表达式，可以进行快速的数据清洗和数据抽取。文本转为向量后就可以进行相似度计算,</description>
      <content:encoded><![CDATA[<h2 id="文献">文献</h2>
<p>Cohen, L., Malloy, C. and Nguyen, Q., 2020. Lazy prices. <em>The Journal of Finance</em>, <em>75</em>(3), pp.1371-1415.</p>
<br>
<h2 id="摘要">摘要</h2>
<p>使用1995年-2014年所有美国公司季度和年度申报的完整历史记录，研究发现当公司对<strong>报告进行积极更改</strong>时，这种行为<strong>蕴含着</strong>公司未来运营的<strong>重要信号</strong>。</p>
<p><strong>财务报告的语言和结构的变化也对公司的未来收益产生重大影响</strong>：做空&quot;变化&quot;的公司（持有的公司，如果其报告发生变化的，做空该公司股票），买入“不变化”的公司，使用这样的投资组合策略，在2006年的每月alpha值高达1.88%的收益（每年超过22％）。报告中涉及执行官（CEO和CFO）团队的话语风格的变化，或者有关诉讼(风险部分)的话语的变化，都对投资的未来收益有重要作用。</p>
<p>研究发现，对10-K的变化可以预测未来的收益、获利能力、未来的新闻公告，甚至未来的公司破产。同时，不做任何变化的公司将获得显著的异常收益。与资产价格典型的反应不足研究不同，我们发现没有任何与这些变化相关的公告效应–仅在后来通过新闻，事件或收益披露信息时才产生回报–暗示投资者并未注意到整个公众领域的这些变化。</p>
<br>
<h2 id="研究背景">研究背景</h2>
<p>之前的研究认为，尽管投资者一次对包含重大变化的财务报表的发布作出了迅时反应，但随着时间的流逝，这种公告作用是会减弱的(Brown and Tucker, 2011 and Feldman et al., 2010)。这表示10-K报告会随着时间推移，信息价值大打折扣。尽管我们复现了这个事实，即与常规文件的变更没有重大的公告效应，但我们认为，前人的研究忽略了更重要部分(如MD&amp;A)对对资产价格的影响。</p>
<p>确切的说，<strong>并不是报告的披露效应的信息价值变低了，而是投资者越来越难以发现报告中微妙的信息变化， 比如因为报告变得越来越冗杂。投资者只有看到某些新闻后，才会逐渐意识到之前公司报告内容变化的的真正价值</strong>。</p>
<p>例如Baxter公司</p>
<ul>
<li>纽约时报在 <strong>2010年4月23日</strong> 发了一条FDA将有对输液泵(infusion pumps)更严格对审批管理规定的新闻，<strong>新闻中提到了Baxter公司</strong>。新闻公布当天，<strong>Baxter股价大跌</strong>。</li>
<li><strong>10天</strong>后的（2010年5月4日），Baxter宣布<strong>召回问题的输液泵产品</strong>，股价当天再次大跌。</li>
</ul>
<p><img loading="lazy" src="img/lazy-prices-1.png" alt=""  />
</p>
<p>两次负面新闻导致Baxter股价大跌超过20%，最有意思的是Baxter公司一个多月前（<strong>2010年2月23日</strong>）10-k报告中 <strong>提到</strong> 了与这两条新闻类似的 <strong>线索</strong>。</p>
<p><img loading="lazy" src="img/clues_from_report.png" alt=""  />
</p>
<p>截图中写着 <strong>Baxter的产品COLLEGUE未来可能面脸额外的处罚，而且相关销售面临着FDA、OIG、DOI和FTC越来越严格的审批，面临的执法强度也越来越大</strong>。</p>
<p>因纽约时报发布的消息，股价大跌。但是大跌之前Baxter的10-k报告中似乎提示未来公司可能面临的风险，但是投资者怎么没有注意到这个重要线索呢？</p>
<br>
<h2 id="数据获取与分析方法">数据获取与分析方法</h2>
<p>这篇文章用到了很多 文本数据挖掘 方法，如</p>
<ul>
<li>数据采集(报告下载和信息监测)</li>
<li>正则表达式（数据分割与抽取）</li>
<li>文本相似度(计算报告变化程度)</li>
</ul>
<p>我大致说下这几部分技术在这篇论文中的应用。</p>
<h3 id="1-数据采集">1. 数据采集</h3>
<p>这篇论文研究者认为，只有投资者意识到本期报告和上一期报告做对比，才能发现报告变化，进而对股价有影响。所以当有新公告公布后，投资者是否下载本期报告的同时顺带着下载上一期报告，下载量又是多少。</p>
<p>下载量可以从Freedom of Information Act下载，</p>
<p><img loading="lazy" src="img/download_data.png" alt=""  />
</p>
<p>可以拿到的信息包括:</p>
<ul>
<li>报告文件</li>
<li>报告下载时间</li>
<li>报告下载的IP地址(可以通过这个ip来当作投资者的id)</li>
</ul>
<br>
<h3 id="2-正则表达式">2. 正则表达式</h3>
<p>一个公司报告文件会有不同部分，我们需要将不同的部分分别识别出来。这里用到正则表达式，可以进行快速的数据清洗和数据抽取。</p>
<p><img loading="lazy" src="img/regular_expression.png" alt=""  />
</p>
<br>
<h3 id="3-文本相似度">3. 文本相似度</h3>
<p>文本转为向量后就可以进行相似度计算,</p>
<p><img loading="lazy" src="img/similar-1.png" alt=""  />

<img loading="lazy" src="img/similar-2.png" alt=""  />

<img loading="lazy" src="img/similar-3.png" alt=""  />
</p>
<p>这里使用我开发的cntext包，可以实现cosine和jaccard相似度的计算。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>

<span class="n">A</span> <span class="o">=</span> <span class="s1">&#39;We expect demand to increase.&#39;</span>
<span class="n">B</span> <span class="o">=</span> <span class="s1">&#39;We expect worldwide demand to increase.&#39;</span>
<span class="n">C</span> <span class="o">=</span> <span class="s1">&#39;We expect weakness in sales&#39;</span>

<span class="nb">print</span><span class="p">(</span><span class="n">ct</span><span class="o">.</span><span class="n">cosine_sim</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">C</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">ct</span><span class="o">.</span><span class="n">jaccard_sim</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">))</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">0.40
0.83
</code></pre></div><p>如果对Baxter公司多个年度对报告进行相似度计算，绘制成图就会发现2010年与前后变化很大。相似度越低，说明公司报告前后变化很大，应该引起投资者注意，如果能注意到就会避免纽约时报导致到股价暴跌。如下图</p>
<p><img loading="lazy" src="img/lazy-prices-2.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="案例实现">案例实现</h2>
<p>由于没有完全一样的数据，这里使用政府工作报告数据类比，使用cosine相似度画出趋势线条。</p>
<p>使用相似性识别变化的时间点</p>
<h3 id="准备数据">准备数据</h3>
<p>政府工作报告 <a href="http://www.gov.cn/guowuyuan/zfgzbg.htm">http://www.gov.cn/guowuyuan/zfgzbg.htm</a></p>
<p>prc_reports.xlsx 链接:https://pan.baidu.com/s/1sVU3mkEcP7Z3_hbG5AVNUA 密码:zjrq</p>
<p>将下载好后的 prc_reports.xlsx 文件放置于 .ipynb文件 所在的文件夹内。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_excel</span><span class="p">(</span><span class="s1">&#39;prc_reports.xlsx&#39;</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">dropna</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<p><img loading="lazy" src="img/df.png" alt=""  />
</p>
<h3 id="计算相似度">计算相似度</h3>
<p>运行时间大概30s， 运算结果是列表数据 cosines</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>

<span class="n">cosines</span> <span class="o">=</span> <span class="p">[]</span>
<span class="c1">#row  Series</span>
<span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">iterrows</span><span class="p">():</span>
    <span class="n">text1</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="s1">&#39;report&#39;</span><span class="p">]</span>
    <span class="n">text2</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="s1">&#39;report2&#39;</span><span class="p">]</span>
    <span class="n">simi</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">cosine_sim</span><span class="p">(</span><span class="n">text1</span><span class="p">,</span> <span class="n">text2</span><span class="p">)</span>
    <span class="n">cosines</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">simi</span><span class="p">)</span>
    
<span class="n">cosines</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">[0.44&#39;, &#39;0.39&#39;, &#39;0.35&#39;, ... &#39;0.62&#39;, &#39;0.61&#39;, &#39;0.60&#39;]
</code></pre></div><h3 id="绘制柱状图">绘制柱状图</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">pyecharts.charts</span> <span class="kn">import</span> <span class="n">Bar</span>
<span class="kn">from</span> <span class="nn">pyecharts</span> <span class="kn">import</span> <span class="n">options</span> <span class="k">as</span> <span class="n">opts</span>
<span class="kn">from</span> <span class="nn">pyecharts.globals</span> <span class="kn">import</span> <span class="n">CurrentConfig</span><span class="p">,</span> <span class="n">NotebookType</span>
<span class="n">CurrentConfig</span><span class="o">.</span><span class="n">NOTEBOOK_TYPE</span> <span class="o">=</span> <span class="n">NotebookType</span><span class="o">.</span><span class="n">JUPYTER_NOTEBOOK</span>

<span class="n">bar</span> <span class="o">=</span> <span class="n">Bar</span><span class="p">()</span>

<span class="n">bar</span><span class="o">.</span><span class="n">add_xaxis</span><span class="p">(</span><span class="n">xaxis_data</span><span class="o">=</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;year&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">])</span>
<span class="n">bar</span><span class="o">.</span><span class="n">add_yaxis</span><span class="p">(</span><span class="s2">&#34;相似度&#34;</span><span class="p">,</span> 
               <span class="n">cosines</span><span class="p">,</span> 
               <span class="n">label_opts</span><span class="o">=</span><span class="n">opts</span><span class="o">.</span><span class="n">LabelOpts</span><span class="p">(</span><span class="n">is_show</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>

<span class="n">bar</span><span class="o">.</span><span class="n">set_global_opts</span><span class="p">(</span><span class="n">title_opts</span><span class="o">=</span><span class="n">opts</span><span class="o">.</span><span class="n">TitleOpts</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s2">&#34;政府工作报告相似度可视化&#34;</span><span class="p">))</span>
<span class="n">bar</span><span class="o">.</span><span class="n">load_javascript</span><span class="p">()</span>

<span class="n">bar</span><span class="o">.</span><span class="n">render</span><span class="p">(</span><span class="s1">&#39;政府工作报告相似度可视化1.html&#39;</span><span class="p">)</span>
<span class="n">bar</span><span class="o">.</span><span class="n">render_notebook</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<p><img loading="lazy" src="img/vis_res.png" alt=""  />
</p>
<h3 id="解读">解读</h3>
<p>从图中可以看到除1959年异常外，其他方面能挖掘出很多信息。从相似度整体趋势，</p>
<p>1959-1992 第一阶段，
1992-至今 第二阶段</p>
<p>1992年附近，第一次确立社会主义市场经济制度。之后的岁月里一直围绕着经济建设高速发展。</p>
<p>同时也可以看出在第一阶段前期相似度异常的低，可以理解为新中国初建，百废待兴，对于建设者而言，组着和管理这个国家的政府也在学习如何建设新中国。而90年代后，相似度越来越高，体现了政府越来越熟悉如何治理国家，如何搞经济建设。</p>
<p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
  </channel>
</rss>
