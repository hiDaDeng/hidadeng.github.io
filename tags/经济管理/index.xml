<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>经济管理 on 大邓和他的PYTHON</title>
    <link>/tags/%E7%BB%8F%E6%B5%8E%E7%AE%A1%E7%90%86/</link>
    <description>Recent content in 经济管理 on 大邓和他的PYTHON</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh</language>
    <lastBuildDate>Wed, 26 Apr 2023 00:00:00 +0000</lastBuildDate><atom:link href="/tags/%E7%BB%8F%E6%B5%8E%E7%AE%A1%E7%90%86/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>从3571w条专利数据集「匹配」上市公司的专利信息</title>
      <link>https://textdata.cn/blog/2023-04-26-matching-listed-corporate-with-patent-dataset/</link>
      <pubDate>Wed, 26 Apr 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-04-26-matching-listed-corporate-with-patent-dataset/</guid>
      <description>3571万专利申请全量数据(1985-2022年)数据</description>
      <content:encoded><![CDATA[<h2 id="一问题">一、问题</h2>
<p>之前分享过 <a href="https://textdata.cn/blog/2023-04-13-3571w-patent-dataset-in-china-mainland/">数据集(付费) | 3571万条专利申请数据集(1985-2022年)</a> ， 没有涉及匹配数据的问题。 <strong>有学员反映，该数据集是否支持匹配上市公司。或者上市公司的专利数量等信息能否从该数据集中抽取， 答案是可以的</strong>。 如果对数据集了解，可以直接看第二部分，不熟悉的建议看下数据集大致信息。</p>
<br>
<h3 id="11-专利申请数据集">1.1 专利申请数据集</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">- 数据集名称：省份版知识产权局专利
- 时间跨度：1985-2022，专利申请总量3571万
- 数据来源：『国家知识产权局』
- 数据整理: 『公众号:大邓和他的Python』
</code></pre></div><br>
<h3 id="12-字段">1.2 字段</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"> -  专利公开号
 -  专利名称
 -  专利类型
 -  专利摘要
 -  【申请人】
 -  专利申请号
 -  申请日
 -  申请公布日
 -  授权公布号
 -  授权公布日
 -  申请地址
 -  主权项
 -  发明人
 -  分类号
 -  主分类号
 -  代理机构
 -  分案原申请号
 -  优先权
 -  国际申请
 -  国际公布
 -  代理人
 -  省份或国家代码
 -  法律状态
 -  专利领域
 -  专利学科
 -  多次公布
</code></pre></div><br>
<h3 id="13-数据集大小">1.3 数据集大小</h3>
<p>整体解压后大概70G，</p>
<p><img loading="lazy" src="img/screen-datasets.png" alt=""  />
</p>
<br>
<h3 id="13-分省统计">1.3 分省统计</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">| 省份(区域)       |  专利数  |
| :---------------| :------ |
| 广东省           | 5728705 |
| 江苏省           | 4879171 |
| 浙江省           | 3706820 |
| 山东省           | 2064446 |
| 北京市           | 2069913 |
| 四川省           | 1159551 |
| 天津市           | 712932  |
| 上海市           | 1548278 |
| 贵州省           | 265512  |
| 陕西省           | 655837  |
| 吉林省           | 232264  |
| 辽宁省           | 637853  |
| 湖北省           | 966384  |
| 山西省           | 233418  |
| 宁夏回族自治区    | 66919   |
| 西藏自治区        | 9911    |
| 广西壮族自治区    | 377658  |
| 江西省           | 519584  |
| 湖南省           | 743828  |
| 黑龙江省         | 357881  |
| 海南省           | 59202   |
| 福建省           | 1046473 |
| 安徽省           | 1342364 |
| 河北省           | 645420  |
| 重庆市           | 592382  |
| 内蒙古自治区      | 133277  |
| 云南省           | 252407  |
| 甘肃省           | 164274  |
| 新疆维吾尔自治区   | 124734  |
| 河南省           | 966477  |
| 青海省           | 34127   |
| 台湾省           | 401555  |
| 香港特别行政区    | 61636   |
| 澳门特别行政区    | 2010    |
| 其他国家         | 2948557 |
</code></pre></div><p><br><br></p>
<h2 id="二读取数据">二、读取数据</h2>
<p>数据集中的个别csv文件较大，例如广东省.csv体积10G。 我们就以建议分析的时候， 电脑内存大于等于16G的， 每次分析时不要开其他软件。</p>
<p>为了演示， 我选择用较小的 黑龙江省.csv 为例。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;黑龙江省.csv&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">,</span> <span class="n">low_memory</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<p><img loading="lazy" src="img/df.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;黑龙江省专利数量: &#39;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">))</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">河北省: 357881
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#数据集中的字段含</span>
<span class="n">df</span><span class="o">.</span><span class="n">columns</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">Index([&#39;专利公开号&#39;, &#39;专利名称&#39;, &#39;专利类型&#39;, &#39;专利摘要&#39;, 
&#39;申请人&#39;, &#39;专利申请号&#39;, &#39;申请日&#39;, &#39;申请公布日&#39;, 
&#39;授权公布号&#39;, &#39;授权公布日&#39;, &#39;申请地址&#39;, &#39;主权项&#39;, &#39;发明人&#39;,
&#39;分类号&#39;, &#39;主分类号&#39;, &#39;代理机构&#39;, &#39;分案原申请号&#39;, &#39;优先权&#39;, 
&#39;国际申请&#39;, &#39;国际公布&#39;, &#39;代理人&#39;, &#39;省份或国家代码&#39;,
&#39;法律状态&#39;, &#39;专利领域&#39;, &#39;专利学科&#39;, &#39;多次公布&#39;],
dtype=&#39;object&#39;)
</code></pre></div><p><br><br></p>
<p>大邓现在在大东北，知道黑龙江的上市公司有哈药集团和北大荒。 我们就查一下 「黑龙江省.csv」 专利申请的数据中是否有北大荒和哈药集团。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;北大荒专利数: &#39;</span><span class="p">,</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;申请人&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="s1">&#39;北大荒集团&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;哈药集团专利数: &#39;</span><span class="p">,</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;申请人&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="s1">&#39;哈药集团&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">北大荒专利数:  4
哈药集团专利数:  712
</code></pre></div><p>还真有!!! so， 这个  <a href="">数据集 | 3571万条专利申请数据集(1985-2022年)</a> 是真的可以匹配上市公司，做一些有价值的变量。 感叹完毕， 继续写点没营养的代码。</p>
<br>
<h2 id="三匹配公司">三、匹配公司</h2>
<p>从上面可以看出哈药集团专利数很多，咱们继续检查哈药集团的专利数据。那么如何筛选出某公司的所有专利申请记录数据呢？这里会用到DataFrame的布尔条件筛选，把值为True的筛选出来。</p>
<ol>
<li>宽松条件  <code>「申请人」含「哈药集团」字眼的</code></li>
<li>严格条件 <code>「申请人」所含字眼就是「哈药集团」四个字</code></li>
</ol>
<br>
<h3 id="31-宽松条件">3.1 宽松条件</h3>
<p>把「申请人」含「哈药集团」字眼的记录筛选出来</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df2</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;申请人&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="s1">&#39;哈药集团&#39;</span><span class="p">)</span><span class="o">==</span><span class="kc">True</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">df2</span><span class="p">))</span>
<span class="n">df2</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/df2.png" alt=""  />
</p>
<p>返回结果可以看到，申请人主体是有很多个不同的主体，都是「哈药集团」附属的子公司或分厂。</p>
<br>
<h3 id="31-严格条件">3.1 严格条件</h3>
<p>「申请人」所含字眼就是「哈药集团」四个字</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df3</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;申请人&#39;</span><span class="p">]</span><span class="o">==</span><span class="s1">&#39;哈药集团&#39;</span><span class="p">]</span>

<span class="n">df3</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/df3.png" alt=""  />
</p>
<p>严格条件筛选后，符合的记录数量为0 。 「哈药集团」这四个字是上市公司名称的缩写简写，所以直接这样做筛选，一般得到的结果都是0。  实际上，一个完整的公司名一般是 「属地+公司名+股份有限公司」。例如，</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df4</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;申请人&#39;</span><span class="p">]</span><span class="o">==</span><span class="s1">&#39;哈药集团三精制药四厂有限公司&#39;</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">df4</span><span class="p">))</span>
<span class="n">df4</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">28
</code></pre></div><p><img loading="lazy" src="img/df4.png" alt=""  />
</p>
<br>
<br>
<h2 id="四其他操作">四、其他操作</h2>
<h3 id="41-类型字段">4.1 类型字段</h3>
<p>想了解「哈药集团」相关公司「专利领域」的分布情况</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df3</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;申请人&#39;</span><span class="p">]</span><span class="o">==</span><span class="s1">&#39;哈药集团&#39;</span><span class="p">]</span>

<span class="n">df3</span><span class="p">[</span><span class="s1">&#39;专利领域&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">工程科技Ⅱ辑            265
医药卫生科技            250
工程科技Ⅰ辑            157
基础科学               34
农业科技                5
工程科技Ⅰ辑; 工程科技Ⅱ辑      1
Name: 专利领域, dtype: int64
</code></pre></div><p>可以看到 「哈药集团」 在医药相关的领域布局较多，农业科技只有5个，从中可以看出 「哈药集团」还是一个技术很专注的企业。</p>
<br>
<h3 id="42-如何剔除nan">4.2 如何剔除Nan</h3>
<p>如果对某个字段感兴趣， 比如「国际申请」</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df</span><span class="p">[</span><span class="s1">&#39;国际申请&#39;</span><span class="p">]</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">0         NaN
1         NaN
2         NaN
3         NaN
4         NaN
         ... 
357876    NaN
357877    NaN
357878    NaN
357879    NaN
357880    NaN
Name: 国际申请, Length: 357881, dtype: object
</code></pre></div><p>但肉眼所见全是Nan， <strong>如何剔除掉Nan， 显露出非Nan的记录呢？</strong></p>
<p>解决办法依然是使用DataFrame的逻辑布尔筛选数据。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df</span><span class="p">[</span><span class="o">~</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;国际申请&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">isna</span><span class="p">()]</span>
</code></pre></div><p><img loading="lazy" src="img/df5.png" alt=""  />

<br></p>
<br>
<h2 id="五获取3751w专利数据集">五、获取3751w专利数据集</h2>
<p>该数据集为付费数据集， 如需数据，点击该链接 <a href="https://textdata.cn/blog/2023-04-13-3571w-patent-dataset-in-china-mainland/">数据集(付费) | 3571万条专利申请数据集(1985-2022年)</a> 进行购买。</p>
<p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>实验 | 互联网黑话与MD&amp;A</title>
      <link>https://textdata.cn/blog/2023-04-26-chinese-it-industry-slangs-words/</link>
      <pubDate>Wed, 26 Apr 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-04-26-chinese-it-industry-slangs-words/</guid>
      <description>&lt;p&gt;最近大邓意外发现，使用mda预训练语言模型扩展互联网黑近义词，模型返回的有鼻子有眼的，这意味着上市公司高管在md&amp;amp;a中可能频繁使用了互联网黑话。&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;一互联网黑话&#34;&gt;一、互联网黑话&lt;/h2&gt;
&lt;h3 id=&#34;二字动词&#34;&gt;二字动词&lt;/h3&gt;
&lt;p&gt;复盘，赋能，沉淀，倒逼，落地，串联，协同，反晡，兼容，包装，重组，履约，晌应，量化，发力，布局，联动，细分，梳理，输出，加速，共建，支撑，融合，聚合，集成，对齐，对标，对焦，拆解，拉通，抽象，摸索，提炼，打通，打透，吃透，迁移，分发，分层，分装，穿梭，辐射，围绕，复用，渗透，扩展，开拓。&lt;/p&gt;
&lt;h3 id=&#34;二字名词&#34;&gt;二字名词&lt;/h3&gt;
&lt;p&gt;漏斗，中台，闭环，打法，拉通，纽带，矩阵，刺激，规模，场景，聚焦，维度，格局，形态，生态，话术，体系，抓手，赛道，认知，玩法，体感，感知，调性，心智，战役，合力，心力。&lt;/p&gt;
&lt;h3 id=&#34;三字名词&#34;&gt;三字名词&lt;/h3&gt;
&lt;p&gt;颗粒度，感知度，方法论，组合拳，引爆点，点线面，精细化，差异化，平台化，结构化，影响力，耦合性，易用性，一致性，端到端，短平快。&lt;/p&gt;
&lt;h3 id=&#34;四字名词&#34;&gt;四字名词&lt;/h3&gt;
&lt;p&gt;生命周期，价值转化，强化认知，资源倾斜，完善逻辑，抽离透传，复用打法，商业模式，快速响应，定性定量，关键路径，去中心化，结果导向，垂直领域，如何收口，归因分析，体验度量，信息屏障。&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;二模型近义词&#34;&gt;二、模型近义词&lt;/h2&gt;
&lt;p&gt;之前分享过一个中文金融领域的word2vec预训练语言模型，这里就不详细介绍模型参数。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://textdata.cn/blog/2023-03-24-load-w2v-and-expand-your-concpet-dicitonary/&#34;&gt;使用中文MD&amp;amp;A数据集训练word2vec预训练模型， 可扩展或新建会计金融等领域的情感词典&lt;/a&gt;&lt;/p&gt;
&lt;br&gt;
&lt;p&gt;文本分析最常用的方法是词典法(例如，LIWC)，而词向量模型可以帮助我们扩展或者构建概念情感词典。&lt;/p&gt;
&lt;p&gt;现在给大家演示只给一个词，返回topn个语义最相关的词。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 与 seedwords 最相关的前topn个词&lt;/span&gt;
&lt;span class=&#34;c1&#34;&gt;# wv是预训练语言模型&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;expand_dictionary&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
                  &lt;span class=&#34;n&#34;&gt;seedwords&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;复盘&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;
                  &lt;span class=&#34;n&#34;&gt;topn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;[&amp;#39;复盘&amp;#39;,
 &amp;#39;检视&amp;#39;,
 &amp;#39;检讨&amp;#39;,
 &amp;#39;KPI&amp;#39;,
 &amp;#39;考核评估&amp;#39;,
 &amp;#39;量化考核&amp;#39;,
 &amp;#39;跟踪考核&amp;#39;,
 &amp;#39;纠偏&amp;#39;,
 &amp;#39;过程跟踪&amp;#39;,
 &amp;#39;分析总结&amp;#39;,
 &amp;#39;KPI指标&amp;#39;]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;expand_dictionary&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
                  &lt;span class=&#34;n&#34;&gt;seedwords&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;赋能&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;
                  &lt;span class=&#34;n&#34;&gt;topn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;[&amp;#39;赋能&amp;#39;,
 &amp;#39;技术赋能&amp;#39;,
 &amp;#39;全面赋能&amp;#39;,
 &amp;#39;平台赋能&amp;#39;,
 &amp;#39;科技赋能&amp;#39;,
 &amp;#39;助力&amp;#39;,
 &amp;#39;数字化赋能&amp;#39;,
 &amp;#39;数据赋能&amp;#39;,
 &amp;#39;数智化&amp;#39;,
 &amp;#39;数据驱动&amp;#39;,
 &amp;#39;生态构建&amp;#39;]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;expand_dictionary&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
                  &lt;span class=&#34;n&#34;&gt;seedwords&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;感知度&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;
                  &lt;span class=&#34;n&#34;&gt;topn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;[&amp;#39;感知度&amp;#39;,
 &amp;#39;体验度&amp;#39;,
 &amp;#39;产品认知度&amp;#39;,
 &amp;#39;知晓度&amp;#39;,
 &amp;#39;购买率&amp;#39;,
 &amp;#39;品牌黏性&amp;#39;,
 &amp;#39;满意度忠诚度&amp;#39;,
 &amp;#39;忠诚度美誉度&amp;#39;,
 &amp;#39;消费者满意度&amp;#39;,
 &amp;#39;体验满意度&amp;#39;,
 &amp;#39;好感度&amp;#39;]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;expand_dictionary&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
                  &lt;span class=&#34;n&#34;&gt;seedwords&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;倒逼&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;
                  &lt;span class=&#34;n&#34;&gt;topn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;[&amp;#39;倒逼&amp;#39;, 
&amp;#39;倒逼企业&amp;#39;, 
&amp;#39;势在必行&amp;#39;, 
&amp;#39;迫使&amp;#39;, 
&amp;#39;大势所趋&amp;#39;, 
&amp;#39;促使&amp;#39;, 
&amp;#39;优胜劣汰&amp;#39;, 
&amp;#39;加速淘汰&amp;#39;, 
&amp;#39;势必&amp;#39;, 
&amp;#39;趋严&amp;#39;, 
&amp;#39;成为常态&amp;#39;]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;expand_dictionary&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
                  &lt;span class=&#34;n&#34;&gt;seedwords&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;闭环&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;
                  &lt;span class=&#34;n&#34;&gt;topn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;[&amp;#39;闭环&amp;#39;,
&amp;#39;完整闭环&amp;#39;, 
&amp;#39;全链路&amp;#39;, 
&amp;#39;全链条&amp;#39;, 
&amp;#39;全流程&amp;#39;, 
&amp;#39;闭环式&amp;#39;, 
&amp;#39;端端&amp;#39;, 
&amp;#39;端到端&amp;#39;, 
&amp;#39;服务闭环&amp;#39;, 
&amp;#39;全周期&amp;#39;, 
&amp;#39;闭环管理&amp;#39;]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;expand_dictionary&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
                  &lt;span class=&#34;n&#34;&gt;seedwords&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;端到端&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;
                  &lt;span class=&#34;n&#34;&gt;topn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;[&amp;#39;端到端&amp;#39;,
 &amp;#39;端端&amp;#39;,
 &amp;#39;端到端的&amp;#39;,
 &amp;#39;全链路&amp;#39;,
 &amp;#39;端端的&amp;#39;,
 &amp;#39;数字化运营&amp;#39;,
 &amp;#39;全业务流程&amp;#39;,
 &amp;#39;场景全&amp;#39;,
 &amp;#39;全链条&amp;#39;,
 &amp;#39;敏捷&amp;#39;,
 &amp;#39;全价值链&amp;#39;]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;可以看到， 返回的近义词都是挺互联网范儿的。 只有较为频繁使用， 语言模型才有可能捕捉到这种语义关系。这从侧面反映了近年来互联网高级黑话影响力之大。&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;三获取模型&#34;&gt;三、获取模型&lt;/h2&gt;
&lt;p&gt;模型训练不易， 为付费资源，如需使用请 &lt;a href=&#34;https://mp.weixin.qq.com/s/zle9-BR-ei1V8Nmul19_7w&#34;&gt;&lt;strong&gt;点击进入跳转购买链接&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;期待合作&#34;&gt;期待合作&lt;/h2&gt;
&lt;p&gt;cntext目前仍在技术迭代，版本2.0.0综合了训练语言模型&amp;amp;多语言模型对齐， 有较大的应用价值，期待有独特文本数据集交流合作。&lt;/p&gt;
&lt;p&gt;通过cntext2.0.0，理论上可以对文本所涉社会主体进行计算，适合企业文化、品牌印象、旅游目的地形象、国家形象等&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;同主体不同时间段， 文本中蕴含的文化态度认知变迁，&lt;/li&gt;
&lt;li&gt;或同时间段，不同主体的大样本文本蕴含的差异性&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;广而告之&#34;&gt;广而告之&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/call_for_paper/&#34;&gt;长期征稿&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/we_need_you/&#34;&gt;长期招募小伙伴&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/management_python_course/&#34;&gt;付费视频课 | Python实证指标构建与文本分析&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
      <content:encoded><![CDATA[<p>最近大邓意外发现，使用mda预训练语言模型扩展互联网黑近义词，模型返回的有鼻子有眼的，这意味着上市公司高管在md&amp;a中可能频繁使用了互联网黑话。</p>
<p><br><br></p>
<h2 id="一互联网黑话">一、互联网黑话</h2>
<h3 id="二字动词">二字动词</h3>
<p>复盘，赋能，沉淀，倒逼，落地，串联，协同，反晡，兼容，包装，重组，履约，晌应，量化，发力，布局，联动，细分，梳理，输出，加速，共建，支撑，融合，聚合，集成，对齐，对标，对焦，拆解，拉通，抽象，摸索，提炼，打通，打透，吃透，迁移，分发，分层，分装，穿梭，辐射，围绕，复用，渗透，扩展，开拓。</p>
<h3 id="二字名词">二字名词</h3>
<p>漏斗，中台，闭环，打法，拉通，纽带，矩阵，刺激，规模，场景，聚焦，维度，格局，形态，生态，话术，体系，抓手，赛道，认知，玩法，体感，感知，调性，心智，战役，合力，心力。</p>
<h3 id="三字名词">三字名词</h3>
<p>颗粒度，感知度，方法论，组合拳，引爆点，点线面，精细化，差异化，平台化，结构化，影响力，耦合性，易用性，一致性，端到端，短平快。</p>
<h3 id="四字名词">四字名词</h3>
<p>生命周期，价值转化，强化认知，资源倾斜，完善逻辑，抽离透传，复用打法，商业模式，快速响应，定性定量，关键路径，去中心化，结果导向，垂直领域，如何收口，归因分析，体验度量，信息屏障。</p>
<p><br><br></p>
<h2 id="二模型近义词">二、模型近义词</h2>
<p>之前分享过一个中文金融领域的word2vec预训练语言模型，这里就不详细介绍模型参数。</p>
<p><a href="https://textdata.cn/blog/2023-03-24-load-w2v-and-expand-your-concpet-dicitonary/">使用中文MD&amp;A数据集训练word2vec预训练模型， 可扩展或新建会计金融等领域的情感词典</a></p>
<br>
<p>文本分析最常用的方法是词典法(例如，LIWC)，而词向量模型可以帮助我们扩展或者构建概念情感词典。</p>
<p>现在给大家演示只给一个词，返回topn个语义最相关的词。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1"># 与 seedwords 最相关的前topn个词</span>
<span class="c1"># wv是预训练语言模型</span>
<span class="n">expand_dictionary</span><span class="p">(</span><span class="n">wv</span><span class="o">=</span><span class="n">wv</span><span class="p">,</span> 
                  <span class="n">seedwords</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;复盘&#39;</span><span class="p">],</span>
                  <span class="n">topn</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">[&#39;复盘&#39;,
 &#39;检视&#39;,
 &#39;检讨&#39;,
 &#39;KPI&#39;,
 &#39;考核评估&#39;,
 &#39;量化考核&#39;,
 &#39;跟踪考核&#39;,
 &#39;纠偏&#39;,
 &#39;过程跟踪&#39;,
 &#39;分析总结&#39;,
 &#39;KPI指标&#39;]
</code></pre></div> <br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">expand_dictionary</span><span class="p">(</span><span class="n">wv</span><span class="o">=</span><span class="n">wv</span><span class="p">,</span> 
                  <span class="n">seedwords</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;赋能&#39;</span><span class="p">],</span>
                  <span class="n">topn</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">[&#39;赋能&#39;,
 &#39;技术赋能&#39;,
 &#39;全面赋能&#39;,
 &#39;平台赋能&#39;,
 &#39;科技赋能&#39;,
 &#39;助力&#39;,
 &#39;数字化赋能&#39;,
 &#39;数据赋能&#39;,
 &#39;数智化&#39;,
 &#39;数据驱动&#39;,
 &#39;生态构建&#39;]
</code></pre></div> <br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">expand_dictionary</span><span class="p">(</span><span class="n">wv</span><span class="o">=</span><span class="n">wv</span><span class="p">,</span> 
                  <span class="n">seedwords</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;感知度&#39;</span><span class="p">],</span>
                  <span class="n">topn</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">[&#39;感知度&#39;,
 &#39;体验度&#39;,
 &#39;产品认知度&#39;,
 &#39;知晓度&#39;,
 &#39;购买率&#39;,
 &#39;品牌黏性&#39;,
 &#39;满意度忠诚度&#39;,
 &#39;忠诚度美誉度&#39;,
 &#39;消费者满意度&#39;,
 &#39;体验满意度&#39;,
 &#39;好感度&#39;]
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">expand_dictionary</span><span class="p">(</span><span class="n">wv</span><span class="o">=</span><span class="n">wv</span><span class="p">,</span> 
                  <span class="n">seedwords</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;倒逼&#39;</span><span class="p">],</span>
                  <span class="n">topn</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">[&#39;倒逼&#39;, 
&#39;倒逼企业&#39;, 
&#39;势在必行&#39;, 
&#39;迫使&#39;, 
&#39;大势所趋&#39;, 
&#39;促使&#39;, 
&#39;优胜劣汰&#39;, 
&#39;加速淘汰&#39;, 
&#39;势必&#39;, 
&#39;趋严&#39;, 
&#39;成为常态&#39;]
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">expand_dictionary</span><span class="p">(</span><span class="n">wv</span><span class="o">=</span><span class="n">wv</span><span class="p">,</span> 
                  <span class="n">seedwords</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;闭环&#39;</span><span class="p">],</span>
                  <span class="n">topn</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">[&#39;闭环&#39;,
&#39;完整闭环&#39;, 
&#39;全链路&#39;, 
&#39;全链条&#39;, 
&#39;全流程&#39;, 
&#39;闭环式&#39;, 
&#39;端端&#39;, 
&#39;端到端&#39;, 
&#39;服务闭环&#39;, 
&#39;全周期&#39;, 
&#39;闭环管理&#39;]
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">expand_dictionary</span><span class="p">(</span><span class="n">wv</span><span class="o">=</span><span class="n">wv</span><span class="p">,</span> 
                  <span class="n">seedwords</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;端到端&#39;</span><span class="p">],</span>
                  <span class="n">topn</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">[&#39;端到端&#39;,
 &#39;端端&#39;,
 &#39;端到端的&#39;,
 &#39;全链路&#39;,
 &#39;端端的&#39;,
 &#39;数字化运营&#39;,
 &#39;全业务流程&#39;,
 &#39;场景全&#39;,
 &#39;全链条&#39;,
 &#39;敏捷&#39;,
 &#39;全价值链&#39;]
</code></pre></div><p>可以看到， 返回的近义词都是挺互联网范儿的。 只有较为频繁使用， 语言模型才有可能捕捉到这种语义关系。这从侧面反映了近年来互联网高级黑话影响力之大。</p>
<p><br><br></p>
<h2 id="三获取模型">三、获取模型</h2>
<p>模型训练不易， 为付费资源，如需使用请 <a href="https://mp.weixin.qq.com/s/zle9-BR-ei1V8Nmul19_7w"><strong>点击进入跳转购买链接</strong></a></p>
<p><br><br></p>
<h2 id="期待合作">期待合作</h2>
<p>cntext目前仍在技术迭代，版本2.0.0综合了训练语言模型&amp;多语言模型对齐， 有较大的应用价值，期待有独特文本数据集交流合作。</p>
<p>通过cntext2.0.0，理论上可以对文本所涉社会主体进行计算，适合企业文化、品牌印象、旅游目的地形象、国家形象等</p>
<ul>
<li>同主体不同时间段， 文本中蕴含的文化态度认知变迁，</li>
<li>或同时间段，不同主体的大样本文本蕴含的差异性</li>
</ul>
<p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>「问询函」数据集</title>
      <link>https://textdata.cn/blog/2023-04-17-china-a-market-inquiry-letter-datasets/</link>
      <pubDate>Mon, 17 Apr 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-04-17-china-a-market-inquiry-letter-datasets/</guid>
      <description>数据量不大，只有400多M， 但依然做很多分析。本文只是分享Python代码，大家可以结合之前公众号内的分享，做情感分析、词频统计、情感分析等。</description>
      <content:encoded><![CDATA[<p><strong>问询函</strong>，是指上海证券交易所和深圳证券交易所在审核上市公司相关公告过程中如果发现未达到“直接监管标准”(一般表现为信息披露不准确或内容不全)的问题时，会针对财务报告、并购重组、关联交易、股票异常波动和媒体报道的社会热点等事件发出问询函，要求上市公司在规定时间内书面回函并公开披露。倘若上市公司仍存在信息披露不准确或不全的问题，交易所会再次问询。</p>
<br>
<h2 id="一数据集详情">一、数据集详情</h2>
<p><strong>问询数据集</strong>，有 <strong>11714</strong> 条问询记录， 时间范围  <strong>2014.12~2021.12</strong> 。</p>
<table>
<thead>
<tr>
<th>字段</th>
<th>含义</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>code</strong></td>
<td>股票代码</td>
</tr>
<tr>
<td><strong>corp_name</strong></td>
<td>上市公司简称</td>
</tr>
<tr>
<td><strong>let_cat</strong></td>
<td><strong>监管机构</strong>发出的问询函所属类别</td>
</tr>
<tr>
<td><strong>inq_title</strong></td>
<td>问询函的标题</td>
</tr>
<tr>
<td><strong>inq_content</strong></td>
<td>问询函中询问的具体内容</td>
</tr>
<tr>
<td><strong>reply_content</strong></td>
<td>上市公司回复的详细内容</td>
</tr>
<tr>
<td><strong>inq_date</strong></td>
<td>监管机构发函日期</td>
</tr>
<tr>
<td><strong>ddl_date</strong></td>
<td>规定限期回复日期</td>
</tr>
<tr>
<td><strong>reply_date</strong></td>
<td>公司实际回复日期</td>
</tr>
</tbody>
</table>
<p>数据量不大，只有400多M， 但依然做很多分析。本文只是分享Python代码，大家可以结合之前公众号内的分享，做情感分析、词频统计、情感分析等。</p>
<p><br><br></p>
<h2 id="二导入数据">二、导入数据</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>


<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;监管问询.csv&#39;</span><span class="p">,</span> 
                 <span class="n">converters</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;code&#39;</span><span class="p">:</span> <span class="nb">str</span><span class="p">},</span>  <span class="c1">#防止股票代码被识别为数字</span>
                 <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span>  
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/df.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#字段含</span>
<span class="n">df</span><span class="o">.</span><span class="n">columns</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">Index([&#39;code&#39;, &#39;corp_name&#39;, &#39;let_cat&#39;, &#39;inq_title&#39;, &#39;inq_content&#39;,
       &#39;reply_content&#39;, &#39;inq_date&#39;, &#39;ddl_date&#39;, &#39;reply_date&#39;],
          dtype=&#39;object&#39;)
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#数据量</span>
<span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">11714
</code></pre></div><p><br><br></p>
<h2 id="三数据分析">三、数据分析</h2>
<h3 id="31-更改日期格式">3.1 更改日期格式</h3>
<p>将日期字符串数据改为datetime类型数据，即可做日期间隔的计算。这里只演示公司回复日期与监管机构发函日期时间间隔。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df</span><span class="p">[</span><span class="s1">&#39;inq_date&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;inq_date&#39;</span><span class="p">])</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;ddl_date&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;ddl_date&#39;</span><span class="p">])</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;reply_date&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;reply_date&#39;</span><span class="p">])</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;duration1&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;reply_date&#39;</span><span class="p">]</span> <span class="o">-</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;inq_date&#39;</span><span class="p">]</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/df2.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#数据集的时间跨度</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;inq_date&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;inq_date&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">2014-12-04 00:00:00
2021-12-31 00:00:00
</code></pre></div><br>
<h3 id="32-问询量年度变化">3.2 问询量年度变化</h3>
<p>随着我国金融市场发展，监管越来越到位，再加上上市公司会越来越多， 问询量年度变化应该是越来越多。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">matplotlib</span>
<span class="kn">import</span> <span class="nn">matplotlib_inline</span>
<span class="n">matplotlib_inline</span><span class="o">.</span><span class="n">backend_inline</span><span class="o">.</span><span class="n">set_matplotlib_formats</span><span class="p">(</span><span class="s1">&#39;png&#39;</span><span class="p">,</span> <span class="s1">&#39;svg&#39;</span><span class="p">)</span>
<span class="kn">import</span> <span class="nn">scienceplots</span>
<span class="kn">import</span> <span class="nn">platform</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">([</span><span class="s1">&#39;science&#39;</span><span class="p">,</span> <span class="s1">&#39;no-latex&#39;</span><span class="p">,</span> <span class="s1">&#39;cjk-sc-font&#39;</span><span class="p">])</span>
<span class="n">system</span> <span class="o">=</span> <span class="n">platform</span><span class="o">.</span><span class="n">system</span><span class="p">()</span>  <span class="c1"># 获取操作系统类型</span>

<span class="k">if</span> <span class="n">system</span> <span class="o">==</span> <span class="s1">&#39;Windows&#39;</span><span class="p">:</span>
    <span class="n">font</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;family&#39;</span><span class="p">:</span> <span class="s1">&#39;SimHei&#39;</span><span class="p">}</span>
<span class="k">elif</span> <span class="n">system</span> <span class="o">==</span> <span class="s1">&#39;Darwin&#39;</span><span class="p">:</span>
    <span class="n">font</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;family&#39;</span><span class="p">:</span> <span class="s1">&#39;Arial Unicode MS&#39;</span><span class="p">}</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">font</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;family&#39;</span><span class="p">:</span> <span class="s1">&#39;sans-serif&#39;</span><span class="p">}</span>
<span class="n">matplotlib</span><span class="o">.</span><span class="n">rc</span><span class="p">(</span><span class="s1">&#39;font&#39;</span><span class="p">,</span> <span class="o">**</span><span class="n">font</span><span class="p">)</span>  <span class="c1"># 设置全局字体</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>


<span class="n">df</span><span class="p">[</span><span class="s1">&#39;inq_date&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">dt</span><span class="o">.</span><span class="n">year</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span><span class="o">.</span><span class="n">sort_index</span><span class="p">()</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s1">&#39;bar&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;监管机构发起问询量年度变化&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;问询量&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">13</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;年份&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">13</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</code></pre></div><p><img loading="lazy" src="img/output_8_1.svg" alt="svg"  />
</p>
<br>
<h3 id="33-问询回复间隔">3.3 问询回复间隔</h3>
<p>从监管机构发起问询与公司回复之间的时间差， 按道理</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df</span><span class="p">[</span><span class="s1">&#39;duration1&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;duration1&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">dt</span><span class="o">.</span><span class="n">days</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/df3.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">sz_mean</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;code&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;0&#39;</span><span class="p">)]</span><span class="o">.</span><span class="n">duration1</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="n">sh_mean</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;code&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;6&#39;</span><span class="p">)]</span><span class="o">.</span><span class="n">duration1</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;深市平均回复时间&#39;</span><span class="p">,</span> <span class="n">sz_mean</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;沪市平均回复时间&#39;</span><span class="p">,</span> <span class="n">sh_mean</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">深市平均回复时间 13.90656874745002
沪市平均回复时间 25.54510661563696
</code></pre></div><p>似乎沪市的上市公司回复的更慢</p>
<br>
<h3 id="34-公司回复问询函速度">3.4 公司回复问询函速度</h3>
<p>公司回复问询函的速度是越来越快还是越来越久？</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;inq_date&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">dt</span><span class="o">.</span><span class="n">year</span><span class="p">)[</span><span class="s1">&#39;duration1&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s1">&#39;line&#39;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;公司为回复监管机构问询函所需准备的时间(单位: 天)&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;准备天数&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">13</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;年份&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">13</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</code></pre></div><p><img loading="lazy" src="img/output_13_1.svg" alt="svg"  />

​</p>
<br>
<h3 id="34-文本长度静态对比">3.4 文本长度静态对比</h3>
<p>不考虑时间，比较沪深问询函内容及回复内容文本长度</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df</span><span class="p">[</span><span class="s1">&#39;inq_len&#39;</span><span class="p">]</span> <span class="o">=</span>  <span class="n">df</span><span class="p">[</span><span class="s1">&#39;inq_content&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">len</span><span class="p">()</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;reply_len&#39;</span><span class="p">]</span> <span class="o">=</span>  <span class="n">df</span><span class="p">[</span><span class="s1">&#39;reply_content&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">len</span><span class="p">()</span>


<span class="n">sz_inq_len_mean</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;code&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;0&#39;</span><span class="p">)]</span><span class="o">.</span><span class="n">inq_len</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="n">sh_inq_len_mean</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;code&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;6&#39;</span><span class="p">)]</span><span class="o">.</span><span class="n">inq_len</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;深市-监管机构平均问询函内容长度&#39;</span><span class="p">,</span> <span class="n">sz_inq_len_mean</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;沪市-监管机构平均问询函内容长度&#39;</span><span class="p">,</span> <span class="n">sh_inq_len_mean</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;-&#39;</span><span class="o">*</span><span class="mi">40</span><span class="p">,</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>


<span class="n">sz_reply_len_mean</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;code&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;0&#39;</span><span class="p">)]</span><span class="o">.</span><span class="n">reply_len</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="n">sh_reply_len_mean</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;code&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;6&#39;</span><span class="p">)]</span><span class="o">.</span><span class="n">reply_len</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;深市公司平均回复长度&#39;</span><span class="p">,</span> <span class="n">sz_reply_len_mean</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;沪市公司平均回复时间&#39;</span><span class="p">,</span> <span class="n">sh_reply_len_mean</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">
深市-监管机构平均问询函内容长度 1909.5531135531135
沪市-监管机构平均问询函内容长度 2084.0572959604287
----------------------------------------  
    
深市公司平均回复长度 13776.946043165468
沪市公司平均回复时间 17136.937894736842
</code></pre></div><p>似乎监管机构对沪市公司发起的问询内容更长， 而沪市的上市公司对应回应问询的内容也更长。</p>
<br>
<h3 id="35-随时间文本长度变化">3.5 随时间文本长度变化</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;inq_date&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">dt</span><span class="o">.</span><span class="n">year</span><span class="p">)[</span><span class="s1">&#39;inq_len&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s1">&#39;line&#39;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;监管机构问询函内容长度随时间的变化趋势&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;问询函长度&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;年份&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</code></pre></div><p><img loading="lazy" src="img/output_17_1.svg" alt="svg"  />

​</p>
<br>
<h2 id="代码及数据集获取">代码及数据集获取</h2>
<p>数据&amp;代码整理不易，需要的话， <a href="https://mp.weixin.qq.com/s/TicAXv6moHA2joYctE3fYQ">点击链接进入购买页面</a>， 有疑问，加微信372335839， 备注「姓名-学校-专业」</p>
 <br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>数据集 | 3571万条专利申请数据集(1985-2022年)</title>
      <link>https://textdata.cn/blog/2023-04-13-3571w-patent-dataset-in-china-mainland/</link>
      <pubDate>Thu, 13 Apr 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-04-13-3571w-patent-dataset-in-china-mainland/</guid>
      <description>3571万专利申请全量数据(1985-2022年)数据</description>
      <content:encoded><![CDATA[<h2 id="相关推文">相关推文</h2>
<p><a href="https://textdata.cn/blog/2023-04-26-matching-listed-corporate-with-patent-dataset/">从3571w条专利数据集「匹配」上市公司的专利信息</a></p>
<p><br><br></p>
<p>3571万专利申请全量数据(1985-2022年)数据，解压后整个文件夹70多G。</p>
<p><img loading="lazy" src="img/screen-datasets.png" alt=""  />
</p>
<h2 id="一数据介绍">一、数据介绍</h2>
<h3 id="11-数据集概况">1.1 数据集概况</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">- 数据集名称：省份版知识产权局专利
- 时间跨度：1985-2022，专利申请总量3571万
- 数据来源：『国家知识产权局』
- 数据整理: 『公众号:大邓和他的Python』
</code></pre></div><br>
<h3 id="12-分省统计">1.2 分省统计</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">| 省份(区域)       |  专利数  |
| :---------------| :------ |
| 广东省           | 5728705 |
| 江苏省           | 4879171 |
| 浙江省           | 3706820 |
| 山东省           | 2064446 |
| 北京市           | 2069913 |
| 四川省           | 1159551 |
| 天津市           | 712932  |
| 上海市           | 1548278 |
| 贵州省           | 265512  |
| 陕西省           | 655837  |
| 吉林省           | 232264  |
| 辽宁省           | 637853  |
| 湖北省           | 966384  |
| 山西省           | 233418  |
| 宁夏回族自治区    | 66919   |
| 西藏自治区        | 9911    |
| 广西壮族自治区    | 377658  |
| 江西省           | 519584  |
| 湖南省           | 743828  |
| 黑龙江省         | 357881  |
| 海南省           | 59202   |
| 福建省           | 1046473 |
| 安徽省           | 1342364 |
| 河北省           | 645420  |
| 重庆市           | 592382  |
| 内蒙古自治区      | 133277  |
| 云南省           | 252407  |
| 甘肃省           | 164274  |
| 新疆维吾尔自治区   | 124734  |
| 河南省           | 966477  |
| 青海省           | 34127   |
| 台湾省           | 401555  |
| 香港特别行政区    | 61636   |
| 澳门特别行政区    | 2010    |
| 其他国家         | 2948557 |
</code></pre></div><br>
<h3 id="13-字段">1.3 字段</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"> -  专利公开号
 -  专利名称
 -  专利类型
 -  专利摘要
 -  申请人
 -  专利申请号
 -  申请日
 -  申请公布日
 -  授权公布号
 -  授权公布日
 -  申请地址
 -  主权项
 -  发明人
 -  分类号
 -  主分类号
 -  代理机构
 -  分案原申请号
 -  优先权
 -  国际申请
 -  国际公布
 -  代理人
 -  省份或国家代码
 -  法律状态
 -  专利领域
 -  专利学科
 -  多次公布
</code></pre></div><p><br><br></p>
<h2 id="二读取数据">二、读取数据</h2>
<p>数据集中的个别csv文件较大，例如广东省.csv体积10G。建议分析的时候， 电脑内存大于等于16G的， 每次分析时不要开其他软件。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;河北省.csv&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">,</span> <span class="n">low_memory</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p>Run
<img loading="lazy" src="img/df.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;河北省: &#39;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">))</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">河北省: 645420
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df</span><span class="o">.</span><span class="n">columns</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">Index([&#39;专利公开号&#39;, &#39;专利名称&#39;, &#39;专利类型&#39;, &#39;专利摘要&#39;, 
&#39;申请人&#39;, &#39;专利申请号&#39;, &#39;申请日&#39;, &#39;申请公布日&#39;, 
&#39;授权公布号&#39;, &#39;授权公布日&#39;, &#39;申请地址&#39;, &#39;主权项&#39;, &#39;发明人&#39;,
&#39;分类号&#39;, &#39;主分类号&#39;, &#39;代理机构&#39;, &#39;分案原申请号&#39;, &#39;优先权&#39;, 
&#39;国际申请&#39;, &#39;国际公布&#39;, &#39;代理人&#39;, &#39;省份或国家代码&#39;,
&#39;法律状态&#39;, &#39;专利领域&#39;, &#39;专利学科&#39;, &#39;多次公布&#39;],
dtype=&#39;object&#39;)
</code></pre></div><p><br><br></p>
<h2 id="三可视化">三、可视化</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="c1">#为减轻内存压力，可以选择需要的字段读取</span>
<span class="n">cols</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;申请日&#39;</span><span class="p">,</span> <span class="s1">&#39;授权公布日&#39;</span><span class="p">]</span>

<span class="c1">#读取数据</span>
<span class="n">guangdong_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;广东省.csv&#39;</span><span class="p">,</span> <span class="n">usecols</span><span class="o">=</span><span class="n">cols</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">,</span> <span class="n">low_memory</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">jiangsu_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;江苏省.csv&#39;</span><span class="p">,</span> <span class="n">usecols</span><span class="o">=</span><span class="n">cols</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">,</span> <span class="n">low_memory</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">shandong_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;山东省.csv&#39;</span><span class="p">,</span> <span class="n">usecols</span><span class="o">=</span><span class="n">cols</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">,</span> <span class="n">low_memory</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">zhejiang_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;浙江省.csv&#39;</span><span class="p">,</span> <span class="n">usecols</span><span class="o">=</span><span class="n">cols</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">,</span> <span class="n">low_memory</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">beijing_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;北京市.csv&#39;</span><span class="p">,</span> <span class="n">usecols</span><span class="o">=</span><span class="n">cols</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">,</span> <span class="n">low_memory</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">shanghai_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;上海市.csv&#39;</span><span class="p">,</span> <span class="n">usecols</span><span class="o">=</span><span class="n">cols</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">,</span> <span class="n">low_memory</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1">#显示前5行</span>
<span class="n">shanghai_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/df2.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">matplotlib</span>
<span class="kn">import</span> <span class="nn">matplotlib_inline</span>
<span class="n">matplotlib_inline</span><span class="o">.</span><span class="n">backend_inline</span><span class="o">.</span><span class="n">set_matplotlib_formats</span><span class="p">(</span><span class="s1">&#39;png&#39;</span><span class="p">,</span> <span class="s1">&#39;svg&#39;</span><span class="p">)</span>
<span class="kn">import</span> <span class="nn">scienceplots</span>
<span class="kn">import</span> <span class="nn">platform</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">([</span><span class="s1">&#39;science&#39;</span><span class="p">,</span> <span class="s1">&#39;no-latex&#39;</span><span class="p">,</span> <span class="s1">&#39;cjk-sc-font&#39;</span><span class="p">])</span>
<span class="n">system</span> <span class="o">=</span> <span class="n">platform</span><span class="o">.</span><span class="n">system</span><span class="p">()</span>  <span class="c1"># 获取操作系统类型</span>

<span class="k">if</span> <span class="n">system</span> <span class="o">==</span> <span class="s1">&#39;Windows&#39;</span><span class="p">:</span>
    <span class="n">font</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;family&#39;</span><span class="p">:</span> <span class="s1">&#39;SimHei&#39;</span><span class="p">}</span>
<span class="k">elif</span> <span class="n">system</span> <span class="o">==</span> <span class="s1">&#39;Darwin&#39;</span><span class="p">:</span>
    <span class="n">font</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;family&#39;</span><span class="p">:</span> <span class="s1">&#39;Arial Unicode MS&#39;</span><span class="p">}</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">font</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;family&#39;</span><span class="p">:</span> <span class="s1">&#39;sans-serif&#39;</span><span class="p">}</span>
<span class="n">matplotlib</span><span class="o">.</span><span class="n">rc</span><span class="p">(</span><span class="s1">&#39;font&#39;</span><span class="p">,</span> <span class="o">**</span><span class="n">font</span><span class="p">)</span>  <span class="c1"># 设置全局字体</span>
    
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">years</span> <span class="o">=</span> <span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2000</span><span class="p">,</span> <span class="mi">2020</span><span class="p">)]</span>


<span class="n">guangdong_df</span><span class="p">[</span><span class="s1">&#39;申请日&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">slice</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="n">years</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;广东&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">jiangsu_df</span><span class="p">[</span><span class="s1">&#39;申请日&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">slice</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="n">years</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;江苏&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">zhejiang_df</span><span class="p">[</span><span class="s1">&#39;申请日&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">slice</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="n">years</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;浙江&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">shandong_df</span><span class="p">[</span><span class="s1">&#39;申请日&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">slice</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="n">years</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;山东&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">beijing_df</span><span class="p">[</span><span class="s1">&#39;申请日&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">slice</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="n">years</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;北京&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">shanghai_df</span><span class="p">[</span><span class="s1">&#39;申请日&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">slice</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="n">years</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;上海&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">hebei_df</span><span class="p">[</span><span class="s1">&#39;申请日&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">slice</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="n">years</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;河北&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>



<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;七省市专利申请量(2000年-2019年)&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;年份(按申请日统计)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;申请量&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper right&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>    
</code></pre></div><p><img loading="lazy" src="img/output_7_0.png" alt=""  />
</p>
<ul>
<li>
<p>2012年， 申请量开始下降， 直至2014年，触底反弹。这个时期国内外宏观经济发生了什么？</p>
</li>
<li>
<p>不考虑人口规模， 在专利申请量可以看出广东、江苏、浙江体量还是比北京、上海、河北要高的。</p>
</li>
<li>
<p>2015年开始， 广东触底反弹后， 拉开了与江苏、浙江的体量。</p>
</li>
</ul>
<p><br><br></p>
<h2 id="数据集获取">数据集获取</h2>
<p>数据整理不易，需要的话， <a href="https://mp.weixin.qq.com/s/WdHMYXHPAVIzXBR5g2Hymw">点击链接进入购买页面</a>， 有疑问，加微信372335839， 备注「姓名-学校-专业」</p>
<p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>数据集 | 2亿条中国大陆工商企业注册信息</title>
      <link>https://textdata.cn/blog/2023-04-12-china-mainland-corporate-registration-information/</link>
      <pubDate>Wed, 12 Apr 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-04-12-china-mainland-corporate-registration-information/</guid>
      <description>341个地市， 2亿条工商注册信息， 网盘压缩文件夹体积17.6G</description>
      <content:encoded><![CDATA[<h2 id="2亿条工商注册信息">2亿条工商注册信息</h2>
<p>341个地市， 2亿条工商注册信息， 网盘压缩文件夹体积17.6G</p>
<p><img loading="lazy" src="img/size.png" alt=""  />
</p>
<p>解压后截图如下</p>
<p><img loading="lazy" src="img/files.png" alt=""  />
</p>
<p>任意csv文件的字段包括</p>
<ul>
<li>企业组织机构代码</li>
<li>企业名称</li>
<li>注册资本</li>
<li>实缴资本</li>
<li>纳税人识别号</li>
<li>法定代表人</li>
<li>企业状态</li>
<li>所属行业</li>
<li>统一社会信用代码</li>
<li>工商注册号</li>
<li>组织机构代码</li>
<li>登记机关</li>
<li>注册日期</li>
<li>核准日期</li>
<li>企业类型</li>
<li>经营期限</li>
<li>注册所在地</li>
<li>地区编码</li>
<li>详细地址</li>
<li>经营范围</li>
<li>参保人数</li>
<li>企业电话(脱敏)</li>
<li>企业座机(脱敏)</li>
<li>企业邮箱(脱敏)</li>
</ul>
<p>数据集已经脱敏处理， 避免分享过程出现违规(法)问题。</p>
<br>
<h2 id="地市">地市</h2>
<p>341个地市</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">os</span>

<span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"> [
 &#39;北京市.csv&#39;,
 &#39;上海市.csv&#39;,
 &#39;南京市.csv&#39;,
 ...
 &#39;重庆市.csv&#39;,
  ]
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#341个地级市工商信息</span>
<span class="nb">len</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">())</span>
</code></pre></div><p>Run</p>
<pre><code>341
</code></pre>
<br>
<br>
<h2 id="读取">读取</h2>
<p>读取 石家庄市、长沙市、杭州市</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">sjz_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;石家庄市.csv&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">,</span> <span class="n">low_memory</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">cs_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;长沙市.csv&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">,</span> <span class="n">low_memory</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">hz_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;杭州市.csv&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">,</span> <span class="n">low_memory</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">sjz_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/df.png" alt=""  />
</p>
<br>
<p>石家庄市.csv 企业记录数</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="nb">len</span><span class="p">(</span><span class="n">sjz_df</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">1131028
</code></pre></div><br>
<p>含有的字段有</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">sjz_df</span><span class="o">.</span><span class="n">columns</span>
</code></pre></div><pre><code>Index(['企业组织机构代码', '企业名称', '注册资本', '实缴资本', '纳税人识别号', '法定代表人', '企业状态', '所属行业',
       '统一社会信用代码', '工商注册号', '组织机构代码', '登记机关', '注册日期', '核准日期', '企业类型', '经营期限',
       '注册所在地', '地区编码', '详细地址', '经营范围', '参保人数', '企业电话', '企业座机', '企业邮箱'],
      dtype='object')
</code></pre>
<br>
<h2 id="可视化">可视化</h2>
<p>绘制一个1992-2019年的注册量折线图</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">matplotlib</span>
<span class="kn">import</span> <span class="nn">matplotlib_inline</span>
<span class="n">matplotlib_inline</span><span class="o">.</span><span class="n">backend_inline</span><span class="o">.</span><span class="n">set_matplotlib_formats</span><span class="p">(</span><span class="s1">&#39;png&#39;</span><span class="p">,</span> <span class="s1">&#39;svg&#39;</span><span class="p">)</span>
<span class="kn">import</span> <span class="nn">scienceplots</span>
<span class="kn">import</span> <span class="nn">platform</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">([</span><span class="s1">&#39;science&#39;</span><span class="p">,</span> <span class="s1">&#39;no-latex&#39;</span><span class="p">,</span> <span class="s1">&#39;cjk-sc-font&#39;</span><span class="p">])</span>
<span class="n">system</span> <span class="o">=</span> <span class="n">platform</span><span class="o">.</span><span class="n">system</span><span class="p">()</span>  <span class="c1"># 获取操作系统类型</span>

<span class="k">if</span> <span class="n">system</span> <span class="o">==</span> <span class="s1">&#39;Windows&#39;</span><span class="p">:</span>
    <span class="n">font</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;family&#39;</span><span class="p">:</span> <span class="s1">&#39;SimHei&#39;</span><span class="p">}</span>
<span class="k">elif</span> <span class="n">system</span> <span class="o">==</span> <span class="s1">&#39;Darwin&#39;</span><span class="p">:</span>
    <span class="n">font</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;family&#39;</span><span class="p">:</span> <span class="s1">&#39;Arial Unicode MS&#39;</span><span class="p">}</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">font</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;family&#39;</span><span class="p">:</span> <span class="s1">&#39;sans-serif&#39;</span><span class="p">}</span>
<span class="n">matplotlib</span><span class="o">.</span><span class="n">rc</span><span class="p">(</span><span class="s1">&#39;font&#39;</span><span class="p">,</span> <span class="o">**</span><span class="n">font</span><span class="p">)</span>  <span class="c1"># 设置全局字体</span>
    
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">years</span> <span class="o">=</span> <span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1992</span><span class="p">,</span> <span class="mi">2020</span><span class="p">)]</span>

<span class="n">sjz_df</span><span class="p">[</span><span class="s1">&#39;注册日期&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">slice</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="n">years</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;石家庄&#39;</span><span class="p">)</span>
<span class="n">cs_df</span><span class="p">[</span><span class="s1">&#39;注册日期&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">slice</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="n">years</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;长沙&#39;</span><span class="p">)</span>
<span class="n">hz_df</span><span class="p">[</span><span class="s1">&#39;注册日期&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">slice</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="n">years</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;杭州&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;工商企业注册量1992-2019年&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;年份&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;注册量&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper right&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>    
</code></pre></div><p><img loading="lazy" src="img/output_8_0.svg" alt="svg"  />
</p>
<p>在2016年之前，长沙和石家庄注册量相当。但是自2016年后，长沙甩开石家庄， 不愧是新一线城市。</p>
<br>
<h2 id="数据集获取">数据集获取</h2>
<p><a href="https://mp.weixin.qq.com/s/csaVlaHysSzWUbxkgK_ONw">付费内容， 点击链接进入跳转页面</a>， 有疑问，加微信372335839， 备注「姓名-学校-专业」</p>
<br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>预训练模型 | 金融会计类word2vec， 可扩展或构建领域内概念情感词典</title>
      <link>https://textdata.cn/blog/2023-03-24-load-w2v-and-expand-your-concpet-dicitonary/</link>
      <pubDate>Fri, 24 Mar 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-03-24-load-w2v-and-expand-your-concpet-dicitonary/</guid>
      <description>&lt;h2 id=&#34;相关内容&#34;&gt;相关内容&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/2023-04-26-chinese-it-industry-slangs-words/&#34;&gt;&lt;strong&gt;实验 | 互联网黑话与MD&amp;amp;A&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;一介绍&#34;&gt;一、介绍&lt;/h2&gt;
&lt;p&gt;使用2001-2021年的&lt;strong&gt;管理层讨论与分析mda&lt;/strong&gt;数据(1.45G)，训练出的中国A股市场词向量模型，词汇量789539， 模型文件650M。可广泛用于经济管理等领域概念(情感)词典的构建或扩展。&lt;/p&gt;
&lt;p&gt;训练环境为内存256G的windows服务器(日常办公电脑内存16G居多)， 2.0.0版本cntext库(该版本暂不开源，最新可获取的版本为1.8.4)。在该环境下，我也尝试使用14G的年报数据，训练了两天，跑不出结果，256G的内存基本用光了。所以cntext训练模型，适合的数据规模是1G左右。模型文件&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;mda01-21.200.6.bin&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;mda01-21.200.6.bin.vectors.npy&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;pretained-screen.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;参数解读&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;mda01-21 使用2001-2021年度的mda数据训练&lt;/li&gt;
&lt;li&gt;200 嵌入的维度数，即每个词的向量长度是200&lt;/li&gt;
&lt;li&gt;6 词语上下文的窗口是6&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;为什么这样确定200和6，可以看这篇 &lt;a href=&#34;https://textdata.cn/blog/2023-03-15-39faq-about-word-embeddings-for-social-science&#34;&gt;词嵌入技术在社会科学领域进行数据挖掘常见39个FAQ汇总&lt;/a&gt;&lt;/p&gt;
&lt;br&gt;
&lt;br&gt;
&lt;h2 id=&#34;二导入模型&#34;&gt;二、导入模型&lt;/h2&gt;
&lt;p&gt;需要用到两个自定义函数load_w2v、expand_dictionary，源代码太长，为了提高阅读体验， 放在文末。大家记得用这两个函数前一定要先导入。&lt;a href=&#34;mda_pretained_model_code.ipynb&#34;&gt;&lt;strong&gt;点击下载本文&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;c1&#34;&gt;#先导入load_w2v、expand_dictionary函数源代码&lt;/span&gt;


&lt;span class=&#34;c1&#34;&gt;#读取模型文件&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;load_w2v&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;w2v_path&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;model/mda01-21.200.6.bin&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Loading word2vec model...
&amp;lt;gensim.models.keyedvectors.KeyedVectors at 0x7fcc91900a90&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;三wv的使用&#34;&gt;三、wv的使用&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;查看词汇量&lt;/li&gt;
&lt;li&gt;查询某词向量&lt;/li&gt;
&lt;li&gt;查看多个词的均值向量&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;更多内容，建议查看下gensim库的文档&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;c1&#34;&gt;#词汇量&lt;/span&gt;
&lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;index_to_key&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;789539
&lt;/code&gt;&lt;/pre&gt;
&lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;c1&#34;&gt;#查询某词的词向量&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;get_vector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;创新&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;array([ 4.34389877e+00, -4.93447453e-01,  2.17293240e-02,  1.90846980e+00,
        8.75901580e-01, -7.95542181e-01, -1.12950909e+00,  7.44228721e-01,
        7.38122821e-01,  6.42377853e-01,  3.99175316e-01,  2.17924786e+00,
        9.30410504e-01, -3.23538423e+00, -2.91860670e-01,  1.04046893e+00,
       -1.73857129e+00, -1.12141383e+00,  3.51870751e+00, -8.69141936e-01,
        4.95228887e-01,  4.80194688e-01, -3.35257435e+00,  7.16054797e-01,
        2.29016230e-01,  2.40962386e+00, -7.40825295e-01,  2.18998361e+00,
       -3.37587762e+00, -1.30376315e+00,  5.08445930e+00, -1.68504322e+00,
       -1.60081315e+00, -8.33779454e-01, -7.58818448e-01, -1.78838921e+00,
        2.44672084e+00,  2.27579999e+00, -2.52457595e+00,  1.36214256e-01,
       -3.09675723e-01, -6.98232710e-01,  1.73018420e+00, -8.05342972e-01,
       -1.70148358e-01, -2.43612671e+00, -1.23085886e-01,  2.83124876e+00,
        3.89446110e-01, -3.16048344e-03, -2.09607935e+00, -1.49788404e+00,
        8.58029604e-01, -1.26923633e+00,  1.86084434e-01,  9.13471103e-01,
        1.53111053e+00, -2.57916182e-01,  1.83742964e+00,  1.50475979e+00,
        6.84375539e-02,  2.76320624e+00,  1.02619076e+00,  9.41017449e-01,
        1.66149962e+00, -2.49254084e+00, -7.78038025e-01, -6.52620196e-01,
       -1.59455287e+00, -4.13568115e+00,  2.78383470e+00, -5.71591198e-01,
       -8.45031738e-01,  4.54110718e+00,  1.67990357e-01,  2.12474012e+00,
       -2.25404716e+00, -8.35567772e-01,  9.91619170e-01, -2.55307484e+00,
        2.39850569e+00,  7.65280128e-01,  2.64600372e+00,  2.58998632e-01,
       -6.56729996e-01, -1.55601549e+00,  1.49751770e+00,  8.47311080e-01,
       -2.05665565e+00, -1.14815748e+00,  1.97350585e+00,  1.02964830e+00,
       -3.87644440e-01, -9.38048363e-01, -2.55545706e-01, -7.02206418e-03,
       -2.94358826e+00, -7.96167493e-01,  1.59571424e-01,  1.25497723e+00,
        7.12080002e-01, -1.34656525e+00,  1.54059935e+00, -1.12930894e+00,
       -3.66737366e+00, -7.17270374e-01, -2.69604278e+00,  1.90242791e+00,
        9.33268607e-01, -4.67624277e-01,  3.51641893e+00,  5.66355512e-02,
       -1.31763351e+00,  1.53379011e+00,  2.32190108e+00, -5.21186776e-02,
        4.06406015e-01,  4.48809415e-01, -3.68958092e+00, -1.01650321e+00,
       -1.08470261e+00, -1.93710685e+00,  2.27287245e+00, -6.63952589e-01,
        1.88207674e+00, -1.20226216e+00,  1.08953261e+00,  1.32847381e+00,
        1.38213491e+00,  1.47196710e+00, -2.06643629e+00,  1.99588931e+00,
       -1.64155555e+00, -2.24964902e-01, -2.74115324e+00, -3.16747665e+00,
        1.24095821e+00, -4.10616726e-01, -3.48466903e-01,  1.38452172e+00,
       -1.45676279e+00, -3.54911834e-02, -4.73554075e-01, -4.23114252e+00,
        1.52749741e+00,  7.25808144e-01, -4.50003862e-01, -3.16014004e+00,
        2.60309219e+00, -2.11320925e+00,  3.61347020e-01,  1.73625088e+00,
        1.57609022e+00, -2.08762145e+00,  2.18810892e+00,  1.20706499e+00,
       -1.82370770e+00,  1.22358835e+00, -8.91464829e-01, -3.30527711e+00,
       -3.72515142e-01, -6.23329699e-01,  8.11975658e-01, -8.52464736e-01,
       -9.35325995e-02, -4.06904364e+00,  1.57146180e+00,  7.85030201e-02,
        1.94540334e+00,  2.13809991e+00, -1.58913553e+00, -3.81727874e-01,
       -2.08527303e+00,  5.89691937e-01,  2.55564898e-01,  2.38364622e-01,
        3.64680409e+00,  4.18930590e-01,  1.62034535e+00, -4.63252217e-02,
        5.80206394e-01,  5.55441022e-01,  1.91946900e+00, -1.89253080e+00,
        1.77489519e+00, -3.15311766e+00,  6.48138940e-01,  1.15823770e+00,
       -2.54519200e+00, -1.03516951e-01,  1.15724599e+00, -1.83681571e+00,
       -9.87860620e-01, -1.99984312e+00,  2.76547909e-01,  8.02748859e-01,
        1.99196494e+00, -1.43310416e+00, -2.03039408e+00, -7.19777197e-02],
      dtype=float32)
&lt;/code&gt;&lt;/pre&gt;
&lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;c1&#34;&gt;#查询多个词的词向量&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;get_mean_vector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;([&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;创新&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;研发&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Ruj&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;array([ 0.17623448, -0.02220692, -0.01040847,  0.03616136,  0.04931263,
       -0.06220303, -0.02846557, -0.00156435,  0.04524047,  0.03185674,
        0.01104859,  0.06962118, -0.01969986, -0.10831943, -0.0524368 ,
        0.00623383, -0.04149605, -0.004912  ,  0.13154642, -0.04317038,
       -0.00407438,  0.00923527, -0.13339072,  0.01446994, -0.00153984,
        0.12378754, -0.06064663,  0.09322313, -0.07711462, -0.05880795,
        0.13697049,  0.0133168 ,  0.02769322,  0.02677607,  0.02549294,
       -0.04504526,  0.06267191,  0.02421109, -0.13401456,  0.01423616,
        0.01860182,  0.00344108,  0.04811918,  0.02748652,  0.0190251 ,
       -0.03800797,  0.01517046,  0.06439836,  0.01320594,  0.04748138,
       -0.08914943, -0.00642068,  0.01786153, -0.02472607, -0.04597819,
        0.05832303,  0.11275461, -0.0387079 ,  0.06912261,  0.05287468,
       -0.04447906,  0.10994074, -0.04371417,  0.01227543,  0.07498093,
       -0.11285575, -0.03113984, -0.01122221, -0.03913497, -0.12117577,
        0.08593786, -0.04319173, -0.01860389,  0.15636683,  0.02267851,
        0.0922839 , -0.12106322, -0.07572737,  0.0191772 , -0.00977821,
        0.00455545,  0.01378978,  0.04774487, -0.02080727,  0.01015578,
       -0.04695337,  0.0848957 , -0.01112909, -0.03210922,  0.01151857,
        0.02214565,  0.03220333, -0.02468888, -0.07493623, -0.03724978,
       -0.00716823, -0.12043905, -0.0560291 , -0.00666756,  0.03659805,
        0.0532646 , -0.05371486,  0.06905847,  0.00660356, -0.10362111,
       -0.0015829 , -0.13282564,  0.08241726,  0.00993685,  0.04208402,
        0.03087696,  0.04765649, -0.00834742,  0.07236902,  0.04473683,
       -0.02643864, -0.0050621 ,  0.04462356, -0.0832998 , -0.05533891,
        0.00664944, -0.13001585,  0.07607447, -0.00764748,  0.01410657,
       -0.03057465,  0.0250505 ,  0.09252612, -0.00784517,  0.0386237 ,
       -0.059011  ,  0.05357389, -0.04604931,  0.04388874, -0.0971131 ,
       -0.09777305,  0.02943253, -0.04103448, -0.03944859,  0.09638489,
       -0.02226706,  0.02822194, -0.0093646 , -0.11203568,  0.06142627,
        0.04761236,  0.02720375, -0.09777595,  0.04048391, -0.06758034,
       -0.01500905,  0.02439078,  0.07150253, -0.02562411,  0.02533657,
        0.00799897, -0.06416934,  0.03153701, -0.03944302, -0.04653639,
       -0.04123383, -0.01590026,  0.03051148, -0.02014856, -0.01448381,
       -0.10517117, -0.00649814,  0.02478252,  0.02855514,  0.09052269,
       -0.03505059, -0.03173327, -0.06641324,  0.06284194,  0.01993516,
        0.01349441,  0.1410133 , -0.05283241,  0.03687092, -0.02535007,
        0.00415636,  0.05841105,  0.07389537, -0.13176979,  0.06759793,
       -0.092868  ,  0.01370211,  0.06616284, -0.09137756, -0.01640504,
        0.06095972, -0.05725639, -0.04122292,  0.00598698,  0.02904861,
        0.0442962 ,  0.07399555, -0.04657119, -0.07636161,  0.03204561],
      dtype=float32)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;有了每个词或者概念的向量，可以结合cntext旧版本单语言模型内的态度偏见的度量。&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;四扩展词典&#34;&gt;四、扩展词典&lt;/h2&gt;
&lt;p&gt;做词典法的文本分析，最重要的是有自己的领域词典。之前受限于技术难度，文科生的我也一直在用形容词的通用情感词典。现在依托word2vec技术， 可以加速人工构建的准确率和效率。&lt;/p&gt;
&lt;p&gt;下面是在 mda01-21.200.6.bin 上做的词典扩展测试，函数expand_dictionary会根据种子词选取最准确的topn个词。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;c1&#34;&gt;#短视主义词  实验&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;expand_dictionary&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
                  &lt;span class=&#34;n&#34;&gt;seedwords&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;抓紧&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;立刻&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;月底&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;年底&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;年终&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;争取&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;力争&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;
                  &lt;span class=&#34;n&#34;&gt;topn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;30&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[&#39;抓紧&#39;,
 &#39;立刻&#39;,
 &#39;月底&#39;,
 &#39;年底&#39;,
 &#39;年终&#39;,
 &#39;争取&#39;,
 &#39;力争&#39;,
 &#39;争取&#39;,
 &#39;力争&#39;,
 &#39;年内&#39;,
 &#39;月底&#39;,
 &#39;年底&#39;,
 &#39;尽早&#39;,
 &#39;3月底&#39;,
 &#39;尽快&#39;,
 &#39;抓紧&#39;,
 &#39;6月份&#39;,
 &#39;4月份&#39;,
 &#39;月份&#39;,
 &#39;工作力争&#39;,
 &#39;努力争取&#39;,
 &#39;工作争取&#39;,
 &#39;10月底&#39;,
 &#39;年内实现&#39;,
 &#39;年底完成&#39;,
 &#39;中旬&#39;,
 &#39;7月份&#39;,
 &#39;9月底&#39;,
 &#39;有望&#39;,
 &#39;月底前&#39;,
 &#39;早日&#39;,
 &#39;全力&#39;,
 &#39;继续&#39;,
 &#39;月初&#39;,
 &#39;努力&#39;,
 &#39;确保&#39;,
 &#39;8月份&#39;]
&lt;/code&gt;&lt;/pre&gt;
&lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;expand_dictionary&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
                  &lt;span class=&#34;n&#34;&gt;seedwords&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;团结&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;拼搏&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;  &lt;span class=&#34;s1&#34;&gt;&amp;#39;克服&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;  &lt;span class=&#34;s1&#34;&gt;&amp;#39;勇攀高峰&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;  &lt;span class=&#34;s1&#34;&gt;&amp;#39;友善&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;  &lt;span class=&#34;s1&#34;&gt;&amp;#39;进取&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;
                  &lt;span class=&#34;n&#34;&gt;topn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;30&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[&#39;团结&#39;,
 &#39;拼搏&#39;,
 &#39;克服&#39;,
 &#39;勇攀高峰&#39;,
 &#39;友善&#39;,
 &#39;进取&#39;,
 &#39;拼搏&#39;,
 &#39;艰苦奋斗&#39;,
 &#39;坚定信念&#39;,
 &#39;团结拼搏&#39;,
 &#39;上下同心&#39;,
 &#39;团结&#39;,
 &#39;顽强拼搏&#39;,
 &#39;勇于担当&#39;,
 &#39;团结一致&#39;,
 &#39;团结奋进&#39;,
 &#39;精诚团结&#39;,
 &#39;齐心协力&#39;,
 &#39;开拓进取&#39;,
 &#39;奋进&#39;,
 &#39;团结一心&#39;,
 &#39;实干&#39;,
 &#39;同心协力&#39;,
 &#39;团结协作&#39;,
 &#39;锐意进取&#39;,
 &#39;积极进取&#39;,
 &#39;奋力拼搏&#39;,
 &#39;拼搏精神&#39;,
 &#39;努力拼搏&#39;,
 &#39;进取&#39;,
 &#39;奋发有为&#39;,
 &#39;扎实工作&#39;,
 &#39;同心同德&#39;,
 &#39;拼搏进取&#39;,
 &#39;脚踏实地&#39;,
 &#39;励精图治&#39;]
&lt;/code&gt;&lt;/pre&gt;
&lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;expand_dictionary&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
                  &lt;span class=&#34;n&#34;&gt;seedwords&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;创新&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;科技&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;  &lt;span class=&#34;s1&#34;&gt;&amp;#39;研发&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;  &lt;span class=&#34;s1&#34;&gt;&amp;#39;技术&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;  &lt;span class=&#34;s1&#34;&gt;&amp;#39;标准&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;
                  &lt;span class=&#34;n&#34;&gt;topn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;30&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[&#39;创新&#39;,
 &#39;科技&#39;,
 &#39;研发&#39;,
 &#39;技术&#39;,
 &#39;标准&#39;,
 &#39;创新&#39;,
 &#39;技术创新&#39;,
 &#39;技术研发&#39;,
 &#39;科技创新&#39;,
 &#39;先进技术&#39;,
 &#39;自主创新&#39;,
 &#39;前沿技术&#39;,
 &#39;关键技术&#39;,
 &#39;科研&#39;,
 &#39;新技术&#39;,
 &#39;创新性&#39;,
 &#39;研发创新&#39;,
 &#39;产品研发&#39;,
 &#39;基础研究&#39;,
 &#39;产品开发&#39;,
 &#39;集成创新&#39;,
 &#39;核心技术&#39;,
 &#39;自主研发&#39;,
 &#39;技术应用&#39;,
 &#39;技术集成&#39;,
 &#39;前沿科技&#39;,
 &#39;技术标准&#39;,
 &#39;工艺技术&#39;,
 &#39;科技成果&#39;,
 &#39;技术开发&#39;,
 &#39;尖端技术&#39;,
 &#39;工程技术&#39;,
 &#39;技术相结合&#39;,
 &#39;科学技术&#39;,
 &#39;工艺&#39;]
&lt;/code&gt;&lt;/pre&gt;
&lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;expand_dictionary&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
                  &lt;span class=&#34;n&#34;&gt;seedwords&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;竞争&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;竞争力&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;
                  &lt;span class=&#34;n&#34;&gt;topn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;30&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[&#39;竞争&#39;,
 &#39;竞争力&#39;,
 &#39;竞争能力&#39;,
 &#39;竞争优势&#39;,
 &#39;市场竞争&#39;,
 &#39;竞&#39;,
 &#39;市场竞争力&#39;,
 &#39;竞争实力&#39;,
 &#39;参与市场竞争&#39;,
 &#39;国际竞争&#39;,
 &#39;市场竞争能力&#39;,
 &#39;核心竞争力&#39;,
 &#39;激烈竞争&#39;,
 &#39;市场竞争优势&#39;,
 &#39;竞争态势&#39;,
 &#39;参与竞争&#39;,
 &#39;竞争力重要&#39;,
 &#39;竞争对手&#39;,
 &#39;创新能力&#39;,
 &#39;综合竞争力&#39;,
 &#39;价格竞争&#39;,
 &#39;之间竞争&#39;,
 &#39;核心竞争能力&#39;,
 &#39;未来市场竞争&#39;,
 &#39;国际竞争力&#39;,
 &#39;影响力竞争力&#39;,
 &#39;国际化竞争&#39;,
 &#39;行业竞争&#39;,
 &#39;综合竞争能力&#39;,
 &#39;竞争日趋激烈&#39;,
 &#39;产品竞争力&#39;,
 &#39;竞争力影响力&#39;]
&lt;/code&gt;&lt;/pre&gt;
&lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;expand_dictionary&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
                  &lt;span class=&#34;n&#34;&gt;seedwords&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;疫情&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;扩散&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;防控&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;反复&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;冲击&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;
                  &lt;span class=&#34;n&#34;&gt;topn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;30&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[&#39;疫情&#39;,
 &#39;扩散&#39;,
 &#39;防控&#39;,
 &#39;反复&#39;,
 &#39;冲击&#39;,
 &#39;蔓延&#39;,
 &#39;疫情冲击&#39;,
 &#39;疫情爆发&#39;,
 &#39;新冠疫情&#39;,
 &#39;新冠肺炎&#39;,
 &#39;疫情蔓延&#39;,
 &#39;疫情暴发&#39;,
 &#39;肆虐&#39;,
 &#39;本次疫情&#39;,
 &#39;冲击疫情&#39;,
 &#39;新冠病毒&#39;,
 &#39;疫情扩散&#39;,
 &#39;全球蔓延&#39;,
 &#39;疫情影响&#39;,
 &#39;病毒疫情&#39;,
 &#39;肺炎疫情&#39;,
 &#39;击&#39;,
 &#39;持续蔓延&#39;,
 &#39;疫情持续&#39;,
 &#39;各地疫情&#39;,
 &#39;疫情突然&#39;,
 &#39;疫情全球&#39;,
 &#39;疫情传播&#39;,
 &#39;疫情反复&#39;,
 &#39;散发&#39;,
 &#39;变异毒株&#39;,
 &#39;疫情导致&#39;,
 &#39;疫情肆虐&#39;,
 &#39;全球疫情&#39;,
 &#39;全球新冠&#39;]
&lt;/code&gt;&lt;/pre&gt;
&lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;expand_dictionary&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
                  &lt;span class=&#34;n&#34;&gt;seedwords&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;旧&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;老&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;后&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;落后&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;
                  &lt;span class=&#34;n&#34;&gt;topn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;30&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[&#39;旧&#39;,
 &#39;老&#39;,
 &#39;后&#39;,
 &#39;落后&#39;,
 &#39;旧&#39;,
 &#39;老&#39;,
 &#39;陈旧&#39;,
 &#39;老旧&#39;,
 &#39;淘汰&#39;,
 &#39;高能耗&#39;,
 &#39;低效率&#39;,
 &#39;设备陈旧&#39;,
 &#39;能耗高&#39;,
 &#39;老旧设备&#39;,
 &#39;落后工艺&#39;,
 &#39;进行改造&#39;,
 &#39;工艺落后&#39;,
 &#39;技术落后&#39;,
 &#39;翻新&#39;,
 &#39;更新改造&#39;,
 &#39;改造&#39;,
 &#39;更新&#39;,
 &#39;替换&#39;,
 &#39;改造更新&#39;,
 &#39;旧设备&#39;,
 &#39;污染重&#39;,
 &#39;淘汰一批&#39;,
 &#39;拆除&#39;,
 &#39;污染严重&#39;,
 &#39;简陋&#39;,
 &#39;产能落后&#39;,
 &#39;相对落后&#39;,
 &#39;产能淘汰&#39;,
 &#39;效率低下&#39;]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;五源代码&#34;&gt;五、源代码&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;gensim.models&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;KeyedVectors&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pathlib&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Path&lt;/span&gt;


&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;load_w2v&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;w2v_path&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
    &lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&amp;#34;
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;    Load word2vec model
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;    Args:
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;        w2v_path (str): path of word2vec model
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;    Returns:
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;        model: word2vec model
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;    &amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;
    &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;Loading word2vec model...&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;model&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;KeyedVectors&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;load&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;w2v_path&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
    &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;model&lt;/span&gt;


&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;expand_dictionary&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;seedwords&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;topn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;100&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
    &lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&amp;#34;
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;    According to the seed word file, select the top n words with the most similar semantics and save them in the directory save_dir.
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;    
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;    Args:
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;        wv (Word2VecKeyedVectors): the word embedding model
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;        seedwords (list): 种子词
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;        topn (int, optional): Set the number of most similar words to retrieve to topn. Defaults to 100.
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;        save_dir (str, optional): the directory to save the candidate words. Defaults to &amp;#39;Word2Vec&amp;#39;.
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;    
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;    Returns:
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;    &amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;simidx_scores&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt;

    &lt;span class=&#34;n&#34;&gt;similars_candidate_idxs&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;#the candidate words of seedwords&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;dictionary&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;key_to_index&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;seedidxs&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;#transform word to index&lt;/span&gt;
    &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;seed&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;seedwords&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
        &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;seed&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;dictionary&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
            &lt;span class=&#34;n&#34;&gt;seedidx&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;dictionary&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;seed&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
            &lt;span class=&#34;n&#34;&gt;seedidxs&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;append&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;seedidx&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
    &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;seedidx&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;seedidxs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
        &lt;span class=&#34;c1&#34;&gt;# sims_words such as [(&amp;#39;by&amp;#39;, 0.99984), (&amp;#39;or&amp;#39;, 0.99982), (&amp;#39;an&amp;#39;, 0.99981), (&amp;#39;up&amp;#39;, 0.99980)]&lt;/span&gt;
        &lt;span class=&#34;n&#34;&gt;sims_words&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;similar_by_word&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;seedidx&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;topn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;topn&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
        &lt;span class=&#34;c1&#34;&gt;#Convert words to index and store them&lt;/span&gt;
        &lt;span class=&#34;n&#34;&gt;similars_candidate_idxs&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;extend&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;([&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dictionary&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sim&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]]&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sim&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sims_words&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;similars_candidate_idxs&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;set&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;similars_candidate_idxs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
    
    &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;idx&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;similars_candidate_idxs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
        &lt;span class=&#34;n&#34;&gt;score&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;n_similarity&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;([&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;idx&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;seedidxs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
        &lt;span class=&#34;n&#34;&gt;simidx_scores&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;append&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;((&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;idx&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;score&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;simidxs&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;w&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;w&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;sorted&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;simidx_scores&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;key&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;lambda&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;k&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;k&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;reverse&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)]&lt;/span&gt;

    &lt;span class=&#34;n&#34;&gt;simwords&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;str&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;index_to_key&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;idx&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;idx&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;simidxs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;][:&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;topn&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;

    &lt;span class=&#34;n&#34;&gt;resultwords&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;resultwords&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;extend&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;seedwords&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;resultwords&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;extend&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;simwords&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
    
    &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;resultwords&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;获取模型&#34;&gt;获取模型&lt;/h2&gt;
&lt;p&gt;模型训练不易， 为付费资源，如需使用请 &lt;a href=&#34;https://mp.weixin.qq.com/s/zle9-BR-ei1V8Nmul19_7w&#34;&gt;&lt;strong&gt;点击进入跳转购买链接&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;期待合作&#34;&gt;期待合作&lt;/h2&gt;
&lt;p&gt;cntext目前仍在技术迭代，版本2.0.0综合了训练语言模型&amp;amp;多语言模型对齐， 有较大的应用价值，期待有独特文本数据集交流合作。&lt;/p&gt;
&lt;p&gt;通过cntext2.0.0，理论上可以对文本所涉社会主体进行计算，适合企业文化、品牌印象、旅游目的地形象、国家形象等&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;同主体不同时间段， 文本中蕴含的文化态度认知变迁，&lt;/li&gt;
&lt;li&gt;或同时间段，不同主体的大样本文本蕴含的差异性&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;广而告之&#34;&gt;广而告之&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/call_for_paper/&#34;&gt;长期征稿&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/we_need_you/&#34;&gt;长期招募小伙伴&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/management_python_course/&#34;&gt;付费视频课 | Python实证指标构建与文本分析&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
      <content:encoded><![CDATA[<h2 id="相关内容">相关内容</h2>
<ul>
<li><a href="https://textdata.cn/blog/2023-04-26-chinese-it-industry-slangs-words/"><strong>实验 | 互联网黑话与MD&amp;A</strong></a></li>
</ul>
<p><br><br></p>
<h2 id="一介绍">一、介绍</h2>
<p>使用2001-2021年的<strong>管理层讨论与分析mda</strong>数据(1.45G)，训练出的中国A股市场词向量模型，词汇量789539， 模型文件650M。可广泛用于经济管理等领域概念(情感)词典的构建或扩展。</p>
<p>训练环境为内存256G的windows服务器(日常办公电脑内存16G居多)， 2.0.0版本cntext库(该版本暂不开源，最新可获取的版本为1.8.4)。在该环境下，我也尝试使用14G的年报数据，训练了两天，跑不出结果，256G的内存基本用光了。所以cntext训练模型，适合的数据规模是1G左右。模型文件</p>
<ul>
<li><strong>mda01-21.200.6.bin</strong></li>
<li><strong>mda01-21.200.6.bin.vectors.npy</strong></li>
</ul>
<p><img loading="lazy" src="pretained-screen.png" alt=""  />
</p>
<p>参数解读</p>
<ul>
<li>mda01-21 使用2001-2021年度的mda数据训练</li>
<li>200 嵌入的维度数，即每个词的向量长度是200</li>
<li>6 词语上下文的窗口是6</li>
</ul>
<p>为什么这样确定200和6，可以看这篇 <a href="https://textdata.cn/blog/2023-03-15-39faq-about-word-embeddings-for-social-science">词嵌入技术在社会科学领域进行数据挖掘常见39个FAQ汇总</a></p>
<br>
<br>
<h2 id="二导入模型">二、导入模型</h2>
<p>需要用到两个自定义函数load_w2v、expand_dictionary，源代码太长，为了提高阅读体验， 放在文末。大家记得用这两个函数前一定要先导入。<a href="mda_pretained_model_code.ipynb"><strong>点击下载本文</strong></a></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#先导入load_w2v、expand_dictionary函数源代码</span>


<span class="c1">#读取模型文件</span>
<span class="n">wv</span> <span class="o">=</span> <span class="n">load_w2v</span><span class="p">(</span><span class="n">w2v_path</span><span class="o">=</span><span class="s1">&#39;model/mda01-21.200.6.bin&#39;</span><span class="p">)</span>
<span class="n">wv</span>
</code></pre></div><pre><code>Loading word2vec model...
&lt;gensim.models.keyedvectors.KeyedVectors at 0x7fcc91900a90&gt;
</code></pre>
<h3 id="三wv的使用">三、wv的使用</h3>
<ul>
<li>查看词汇量</li>
<li>查询某词向量</li>
<li>查看多个词的均值向量</li>
</ul>
<p>更多内容，建议查看下gensim库的文档</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#词汇量</span>
<span class="nb">len</span><span class="p">(</span><span class="n">wv</span><span class="o">.</span><span class="n">index_to_key</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<pre><code>789539
</code></pre>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#查询某词的词向量</span>
<span class="n">wv</span><span class="o">.</span><span class="n">get_vector</span><span class="p">(</span><span class="s1">&#39;创新&#39;</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<pre><code>array([ 4.34389877e+00, -4.93447453e-01,  2.17293240e-02,  1.90846980e+00,
        8.75901580e-01, -7.95542181e-01, -1.12950909e+00,  7.44228721e-01,
        7.38122821e-01,  6.42377853e-01,  3.99175316e-01,  2.17924786e+00,
        9.30410504e-01, -3.23538423e+00, -2.91860670e-01,  1.04046893e+00,
       -1.73857129e+00, -1.12141383e+00,  3.51870751e+00, -8.69141936e-01,
        4.95228887e-01,  4.80194688e-01, -3.35257435e+00,  7.16054797e-01,
        2.29016230e-01,  2.40962386e+00, -7.40825295e-01,  2.18998361e+00,
       -3.37587762e+00, -1.30376315e+00,  5.08445930e+00, -1.68504322e+00,
       -1.60081315e+00, -8.33779454e-01, -7.58818448e-01, -1.78838921e+00,
        2.44672084e+00,  2.27579999e+00, -2.52457595e+00,  1.36214256e-01,
       -3.09675723e-01, -6.98232710e-01,  1.73018420e+00, -8.05342972e-01,
       -1.70148358e-01, -2.43612671e+00, -1.23085886e-01,  2.83124876e+00,
        3.89446110e-01, -3.16048344e-03, -2.09607935e+00, -1.49788404e+00,
        8.58029604e-01, -1.26923633e+00,  1.86084434e-01,  9.13471103e-01,
        1.53111053e+00, -2.57916182e-01,  1.83742964e+00,  1.50475979e+00,
        6.84375539e-02,  2.76320624e+00,  1.02619076e+00,  9.41017449e-01,
        1.66149962e+00, -2.49254084e+00, -7.78038025e-01, -6.52620196e-01,
       -1.59455287e+00, -4.13568115e+00,  2.78383470e+00, -5.71591198e-01,
       -8.45031738e-01,  4.54110718e+00,  1.67990357e-01,  2.12474012e+00,
       -2.25404716e+00, -8.35567772e-01,  9.91619170e-01, -2.55307484e+00,
        2.39850569e+00,  7.65280128e-01,  2.64600372e+00,  2.58998632e-01,
       -6.56729996e-01, -1.55601549e+00,  1.49751770e+00,  8.47311080e-01,
       -2.05665565e+00, -1.14815748e+00,  1.97350585e+00,  1.02964830e+00,
       -3.87644440e-01, -9.38048363e-01, -2.55545706e-01, -7.02206418e-03,
       -2.94358826e+00, -7.96167493e-01,  1.59571424e-01,  1.25497723e+00,
        7.12080002e-01, -1.34656525e+00,  1.54059935e+00, -1.12930894e+00,
       -3.66737366e+00, -7.17270374e-01, -2.69604278e+00,  1.90242791e+00,
        9.33268607e-01, -4.67624277e-01,  3.51641893e+00,  5.66355512e-02,
       -1.31763351e+00,  1.53379011e+00,  2.32190108e+00, -5.21186776e-02,
        4.06406015e-01,  4.48809415e-01, -3.68958092e+00, -1.01650321e+00,
       -1.08470261e+00, -1.93710685e+00,  2.27287245e+00, -6.63952589e-01,
        1.88207674e+00, -1.20226216e+00,  1.08953261e+00,  1.32847381e+00,
        1.38213491e+00,  1.47196710e+00, -2.06643629e+00,  1.99588931e+00,
       -1.64155555e+00, -2.24964902e-01, -2.74115324e+00, -3.16747665e+00,
        1.24095821e+00, -4.10616726e-01, -3.48466903e-01,  1.38452172e+00,
       -1.45676279e+00, -3.54911834e-02, -4.73554075e-01, -4.23114252e+00,
        1.52749741e+00,  7.25808144e-01, -4.50003862e-01, -3.16014004e+00,
        2.60309219e+00, -2.11320925e+00,  3.61347020e-01,  1.73625088e+00,
        1.57609022e+00, -2.08762145e+00,  2.18810892e+00,  1.20706499e+00,
       -1.82370770e+00,  1.22358835e+00, -8.91464829e-01, -3.30527711e+00,
       -3.72515142e-01, -6.23329699e-01,  8.11975658e-01, -8.52464736e-01,
       -9.35325995e-02, -4.06904364e+00,  1.57146180e+00,  7.85030201e-02,
        1.94540334e+00,  2.13809991e+00, -1.58913553e+00, -3.81727874e-01,
       -2.08527303e+00,  5.89691937e-01,  2.55564898e-01,  2.38364622e-01,
        3.64680409e+00,  4.18930590e-01,  1.62034535e+00, -4.63252217e-02,
        5.80206394e-01,  5.55441022e-01,  1.91946900e+00, -1.89253080e+00,
        1.77489519e+00, -3.15311766e+00,  6.48138940e-01,  1.15823770e+00,
       -2.54519200e+00, -1.03516951e-01,  1.15724599e+00, -1.83681571e+00,
       -9.87860620e-01, -1.99984312e+00,  2.76547909e-01,  8.02748859e-01,
        1.99196494e+00, -1.43310416e+00, -2.03039408e+00, -7.19777197e-02],
      dtype=float32)
</code></pre>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#查询多个词的词向量</span>
<span class="n">wv</span><span class="o">.</span><span class="n">get_mean_vector</span><span class="p">([</span><span class="s1">&#39;创新&#39;</span><span class="p">,</span> <span class="s1">&#39;研发&#39;</span><span class="p">])</span>
</code></pre></div><p>Ruj</p>
<pre><code>array([ 0.17623448, -0.02220692, -0.01040847,  0.03616136,  0.04931263,
       -0.06220303, -0.02846557, -0.00156435,  0.04524047,  0.03185674,
        0.01104859,  0.06962118, -0.01969986, -0.10831943, -0.0524368 ,
        0.00623383, -0.04149605, -0.004912  ,  0.13154642, -0.04317038,
       -0.00407438,  0.00923527, -0.13339072,  0.01446994, -0.00153984,
        0.12378754, -0.06064663,  0.09322313, -0.07711462, -0.05880795,
        0.13697049,  0.0133168 ,  0.02769322,  0.02677607,  0.02549294,
       -0.04504526,  0.06267191,  0.02421109, -0.13401456,  0.01423616,
        0.01860182,  0.00344108,  0.04811918,  0.02748652,  0.0190251 ,
       -0.03800797,  0.01517046,  0.06439836,  0.01320594,  0.04748138,
       -0.08914943, -0.00642068,  0.01786153, -0.02472607, -0.04597819,
        0.05832303,  0.11275461, -0.0387079 ,  0.06912261,  0.05287468,
       -0.04447906,  0.10994074, -0.04371417,  0.01227543,  0.07498093,
       -0.11285575, -0.03113984, -0.01122221, -0.03913497, -0.12117577,
        0.08593786, -0.04319173, -0.01860389,  0.15636683,  0.02267851,
        0.0922839 , -0.12106322, -0.07572737,  0.0191772 , -0.00977821,
        0.00455545,  0.01378978,  0.04774487, -0.02080727,  0.01015578,
       -0.04695337,  0.0848957 , -0.01112909, -0.03210922,  0.01151857,
        0.02214565,  0.03220333, -0.02468888, -0.07493623, -0.03724978,
       -0.00716823, -0.12043905, -0.0560291 , -0.00666756,  0.03659805,
        0.0532646 , -0.05371486,  0.06905847,  0.00660356, -0.10362111,
       -0.0015829 , -0.13282564,  0.08241726,  0.00993685,  0.04208402,
        0.03087696,  0.04765649, -0.00834742,  0.07236902,  0.04473683,
       -0.02643864, -0.0050621 ,  0.04462356, -0.0832998 , -0.05533891,
        0.00664944, -0.13001585,  0.07607447, -0.00764748,  0.01410657,
       -0.03057465,  0.0250505 ,  0.09252612, -0.00784517,  0.0386237 ,
       -0.059011  ,  0.05357389, -0.04604931,  0.04388874, -0.0971131 ,
       -0.09777305,  0.02943253, -0.04103448, -0.03944859,  0.09638489,
       -0.02226706,  0.02822194, -0.0093646 , -0.11203568,  0.06142627,
        0.04761236,  0.02720375, -0.09777595,  0.04048391, -0.06758034,
       -0.01500905,  0.02439078,  0.07150253, -0.02562411,  0.02533657,
        0.00799897, -0.06416934,  0.03153701, -0.03944302, -0.04653639,
       -0.04123383, -0.01590026,  0.03051148, -0.02014856, -0.01448381,
       -0.10517117, -0.00649814,  0.02478252,  0.02855514,  0.09052269,
       -0.03505059, -0.03173327, -0.06641324,  0.06284194,  0.01993516,
        0.01349441,  0.1410133 , -0.05283241,  0.03687092, -0.02535007,
        0.00415636,  0.05841105,  0.07389537, -0.13176979,  0.06759793,
       -0.092868  ,  0.01370211,  0.06616284, -0.09137756, -0.01640504,
        0.06095972, -0.05725639, -0.04122292,  0.00598698,  0.02904861,
        0.0442962 ,  0.07399555, -0.04657119, -0.07636161,  0.03204561],
      dtype=float32)
</code></pre>
<p>有了每个词或者概念的向量，可以结合cntext旧版本单语言模型内的态度偏见的度量。</p>
<p><br><br></p>
<h2 id="四扩展词典">四、扩展词典</h2>
<p>做词典法的文本分析，最重要的是有自己的领域词典。之前受限于技术难度，文科生的我也一直在用形容词的通用情感词典。现在依托word2vec技术， 可以加速人工构建的准确率和效率。</p>
<p>下面是在 mda01-21.200.6.bin 上做的词典扩展测试，函数expand_dictionary会根据种子词选取最准确的topn个词。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#短视主义词  实验</span>
<span class="n">expand_dictionary</span><span class="p">(</span><span class="n">wv</span><span class="o">=</span><span class="n">wv</span><span class="p">,</span> 
                  <span class="n">seedwords</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;抓紧&#39;</span><span class="p">,</span> <span class="s1">&#39;立刻&#39;</span><span class="p">,</span> <span class="s1">&#39;月底&#39;</span><span class="p">,</span> <span class="s1">&#39;年底&#39;</span><span class="p">,</span> <span class="s1">&#39;年终&#39;</span><span class="p">,</span> <span class="s1">&#39;争取&#39;</span><span class="p">,</span> <span class="s1">&#39;力争&#39;</span><span class="p">],</span>
                  <span class="n">topn</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<pre><code>['抓紧',
 '立刻',
 '月底',
 '年底',
 '年终',
 '争取',
 '力争',
 '争取',
 '力争',
 '年内',
 '月底',
 '年底',
 '尽早',
 '3月底',
 '尽快',
 '抓紧',
 '6月份',
 '4月份',
 '月份',
 '工作力争',
 '努力争取',
 '工作争取',
 '10月底',
 '年内实现',
 '年底完成',
 '中旬',
 '7月份',
 '9月底',
 '有望',
 '月底前',
 '早日',
 '全力',
 '继续',
 '月初',
 '努力',
 '确保',
 '8月份']
</code></pre>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">expand_dictionary</span><span class="p">(</span><span class="n">wv</span><span class="o">=</span><span class="n">wv</span><span class="p">,</span> 
                  <span class="n">seedwords</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;团结&#39;</span><span class="p">,</span> <span class="s1">&#39;拼搏&#39;</span><span class="p">,</span>  <span class="s1">&#39;克服&#39;</span><span class="p">,</span>  <span class="s1">&#39;勇攀高峰&#39;</span><span class="p">,</span>  <span class="s1">&#39;友善&#39;</span><span class="p">,</span>  <span class="s1">&#39;进取&#39;</span><span class="p">],</span>
                  <span class="n">topn</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<pre><code>['团结',
 '拼搏',
 '克服',
 '勇攀高峰',
 '友善',
 '进取',
 '拼搏',
 '艰苦奋斗',
 '坚定信念',
 '团结拼搏',
 '上下同心',
 '团结',
 '顽强拼搏',
 '勇于担当',
 '团结一致',
 '团结奋进',
 '精诚团结',
 '齐心协力',
 '开拓进取',
 '奋进',
 '团结一心',
 '实干',
 '同心协力',
 '团结协作',
 '锐意进取',
 '积极进取',
 '奋力拼搏',
 '拼搏精神',
 '努力拼搏',
 '进取',
 '奋发有为',
 '扎实工作',
 '同心同德',
 '拼搏进取',
 '脚踏实地',
 '励精图治']
</code></pre>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">expand_dictionary</span><span class="p">(</span><span class="n">wv</span><span class="o">=</span><span class="n">wv</span><span class="p">,</span> 
                  <span class="n">seedwords</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;创新&#39;</span><span class="p">,</span> <span class="s1">&#39;科技&#39;</span><span class="p">,</span>  <span class="s1">&#39;研发&#39;</span><span class="p">,</span>  <span class="s1">&#39;技术&#39;</span><span class="p">,</span>  <span class="s1">&#39;标准&#39;</span><span class="p">],</span>
                  <span class="n">topn</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<pre><code>['创新',
 '科技',
 '研发',
 '技术',
 '标准',
 '创新',
 '技术创新',
 '技术研发',
 '科技创新',
 '先进技术',
 '自主创新',
 '前沿技术',
 '关键技术',
 '科研',
 '新技术',
 '创新性',
 '研发创新',
 '产品研发',
 '基础研究',
 '产品开发',
 '集成创新',
 '核心技术',
 '自主研发',
 '技术应用',
 '技术集成',
 '前沿科技',
 '技术标准',
 '工艺技术',
 '科技成果',
 '技术开发',
 '尖端技术',
 '工程技术',
 '技术相结合',
 '科学技术',
 '工艺']
</code></pre>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">expand_dictionary</span><span class="p">(</span><span class="n">wv</span><span class="o">=</span><span class="n">wv</span><span class="p">,</span> 
                  <span class="n">seedwords</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;竞争&#39;</span><span class="p">,</span> <span class="s1">&#39;竞争力&#39;</span><span class="p">],</span>
                  <span class="n">topn</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<pre><code>['竞争',
 '竞争力',
 '竞争能力',
 '竞争优势',
 '市场竞争',
 '竞',
 '市场竞争力',
 '竞争实力',
 '参与市场竞争',
 '国际竞争',
 '市场竞争能力',
 '核心竞争力',
 '激烈竞争',
 '市场竞争优势',
 '竞争态势',
 '参与竞争',
 '竞争力重要',
 '竞争对手',
 '创新能力',
 '综合竞争力',
 '价格竞争',
 '之间竞争',
 '核心竞争能力',
 '未来市场竞争',
 '国际竞争力',
 '影响力竞争力',
 '国际化竞争',
 '行业竞争',
 '综合竞争能力',
 '竞争日趋激烈',
 '产品竞争力',
 '竞争力影响力']
</code></pre>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">expand_dictionary</span><span class="p">(</span><span class="n">wv</span><span class="o">=</span><span class="n">wv</span><span class="p">,</span> 
                  <span class="n">seedwords</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;疫情&#39;</span><span class="p">,</span> <span class="s1">&#39;扩散&#39;</span><span class="p">,</span> <span class="s1">&#39;防控&#39;</span><span class="p">,</span> <span class="s1">&#39;反复&#39;</span><span class="p">,</span> <span class="s1">&#39;冲击&#39;</span><span class="p">],</span>
                  <span class="n">topn</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<pre><code>['疫情',
 '扩散',
 '防控',
 '反复',
 '冲击',
 '蔓延',
 '疫情冲击',
 '疫情爆发',
 '新冠疫情',
 '新冠肺炎',
 '疫情蔓延',
 '疫情暴发',
 '肆虐',
 '本次疫情',
 '冲击疫情',
 '新冠病毒',
 '疫情扩散',
 '全球蔓延',
 '疫情影响',
 '病毒疫情',
 '肺炎疫情',
 '击',
 '持续蔓延',
 '疫情持续',
 '各地疫情',
 '疫情突然',
 '疫情全球',
 '疫情传播',
 '疫情反复',
 '散发',
 '变异毒株',
 '疫情导致',
 '疫情肆虐',
 '全球疫情',
 '全球新冠']
</code></pre>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">expand_dictionary</span><span class="p">(</span><span class="n">wv</span><span class="o">=</span><span class="n">wv</span><span class="p">,</span> 
                  <span class="n">seedwords</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;旧&#39;</span><span class="p">,</span> <span class="s1">&#39;老&#39;</span><span class="p">,</span> <span class="s1">&#39;后&#39;</span><span class="p">,</span> <span class="s1">&#39;落后&#39;</span><span class="p">],</span>
                  <span class="n">topn</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<pre><code>['旧',
 '老',
 '后',
 '落后',
 '旧',
 '老',
 '陈旧',
 '老旧',
 '淘汰',
 '高能耗',
 '低效率',
 '设备陈旧',
 '能耗高',
 '老旧设备',
 '落后工艺',
 '进行改造',
 '工艺落后',
 '技术落后',
 '翻新',
 '更新改造',
 '改造',
 '更新',
 '替换',
 '改造更新',
 '旧设备',
 '污染重',
 '淘汰一批',
 '拆除',
 '污染严重',
 '简陋',
 '产能落后',
 '相对落后',
 '产能淘汰',
 '效率低下']
</code></pre>
<p><br><br></p>
<h2 id="五源代码">五、源代码</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">gensim.models</span> <span class="kn">import</span> <span class="n">KeyedVectors</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>


<span class="k">def</span> <span class="nf">load_w2v</span><span class="p">(</span><span class="n">w2v_path</span><span class="p">):</span>
    <span class="s2">&#34;&#34;&#34;
</span><span class="s2">    Load word2vec model
</span><span class="s2">
</span><span class="s2">    Args:
</span><span class="s2">        w2v_path (str): path of word2vec model
</span><span class="s2">
</span><span class="s2">    Returns:
</span><span class="s2">        model: word2vec model
</span><span class="s2">    &#34;&#34;&#34;</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Loading word2vec model...&#39;</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">KeyedVectors</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">w2v_path</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">model</span>


<span class="k">def</span> <span class="nf">expand_dictionary</span><span class="p">(</span><span class="n">wv</span><span class="p">,</span> <span class="n">seedwords</span><span class="p">,</span> <span class="n">topn</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
    <span class="s2">&#34;&#34;&#34;
</span><span class="s2">    According to the seed word file, select the top n words with the most similar semantics and save them in the directory save_dir.
</span><span class="s2">    
</span><span class="s2">    Args:
</span><span class="s2">        wv (Word2VecKeyedVectors): the word embedding model
</span><span class="s2">        seedwords (list): 种子词
</span><span class="s2">        topn (int, optional): Set the number of most similar words to retrieve to topn. Defaults to 100.
</span><span class="s2">        save_dir (str, optional): the directory to save the candidate words. Defaults to &#39;Word2Vec&#39;.
</span><span class="s2">    
</span><span class="s2">    Returns:
</span><span class="s2">    &#34;&#34;&#34;</span>
    <span class="n">simidx_scores</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="n">similars_candidate_idxs</span> <span class="o">=</span> <span class="p">[]</span> <span class="c1">#the candidate words of seedwords</span>
    <span class="n">dictionary</span> <span class="o">=</span> <span class="n">wv</span><span class="o">.</span><span class="n">key_to_index</span>
    <span class="n">seedidxs</span> <span class="o">=</span> <span class="p">[]</span> <span class="c1">#transform word to index</span>
    <span class="k">for</span> <span class="n">seed</span> <span class="ow">in</span> <span class="n">seedwords</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">seed</span> <span class="ow">in</span> <span class="n">dictionary</span><span class="p">:</span>
            <span class="n">seedidx</span> <span class="o">=</span> <span class="n">dictionary</span><span class="p">[</span><span class="n">seed</span><span class="p">]</span>
            <span class="n">seedidxs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">seedidx</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">seedidx</span> <span class="ow">in</span> <span class="n">seedidxs</span><span class="p">:</span>
        <span class="c1"># sims_words such as [(&#39;by&#39;, 0.99984), (&#39;or&#39;, 0.99982), (&#39;an&#39;, 0.99981), (&#39;up&#39;, 0.99980)]</span>
        <span class="n">sims_words</span> <span class="o">=</span> <span class="n">wv</span><span class="o">.</span><span class="n">similar_by_word</span><span class="p">(</span><span class="n">seedidx</span><span class="p">,</span> <span class="n">topn</span><span class="o">=</span><span class="n">topn</span><span class="p">)</span>
        <span class="c1">#Convert words to index and store them</span>
        <span class="n">similars_candidate_idxs</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="n">dictionary</span><span class="p">[</span><span class="n">sim</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span> <span class="k">for</span> <span class="n">sim</span> <span class="ow">in</span> <span class="n">sims_words</span><span class="p">])</span>
    <span class="n">similars_candidate_idxs</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">similars_candidate_idxs</span><span class="p">)</span>
    
    <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">similars_candidate_idxs</span><span class="p">:</span>
        <span class="n">score</span> <span class="o">=</span> <span class="n">wv</span><span class="o">.</span><span class="n">n_similarity</span><span class="p">([</span><span class="n">idx</span><span class="p">],</span> <span class="n">seedidxs</span><span class="p">)</span>
        <span class="n">simidx_scores</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">idx</span><span class="p">,</span> <span class="n">score</span><span class="p">))</span>
    <span class="n">simidxs</span> <span class="o">=</span> <span class="p">[</span><span class="n">w</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">simidx_scores</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">k</span><span class="p">:</span><span class="n">k</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)]</span>

    <span class="n">simwords</span> <span class="o">=</span> <span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">wv</span><span class="o">.</span><span class="n">index_to_key</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">simidxs</span><span class="p">][:</span><span class="n">topn</span><span class="p">]</span>

    <span class="n">resultwords</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">resultwords</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">seedwords</span><span class="p">)</span>
    <span class="n">resultwords</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">simwords</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">resultwords</span>
</code></pre></div><p><br><br></p>
<h2 id="获取模型">获取模型</h2>
<p>模型训练不易， 为付费资源，如需使用请 <a href="https://mp.weixin.qq.com/s/zle9-BR-ei1V8Nmul19_7w"><strong>点击进入跳转购买链接</strong></a></p>
<p><br><br></p>
<h2 id="期待合作">期待合作</h2>
<p>cntext目前仍在技术迭代，版本2.0.0综合了训练语言模型&amp;多语言模型对齐， 有较大的应用价值，期待有独特文本数据集交流合作。</p>
<p>通过cntext2.0.0，理论上可以对文本所涉社会主体进行计算，适合企业文化、品牌印象、旅游目的地形象、国家形象等</p>
<ul>
<li>同主体不同时间段， 文本中蕴含的文化态度认知变迁，</li>
<li>或同时间段，不同主体的大样本文本蕴含的差异性</li>
</ul>
<p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>数据集 | 2001-2021年A股上市公司年报&amp;管理层讨论与分析</title>
      <link>https://textdata.cn/blog/2023-03-23-china-a-share-market-dataset-mda-from-01-to-21/</link>
      <pubDate>Thu, 16 Mar 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-03-23-china-a-share-market-dataset-mda-from-01-to-21/</guid>
      <description>&lt;p&gt;2001-2021年A股年报数据集，含4个文件，共17G&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;年报01年-21年.csv&lt;/li&gt;
&lt;li&gt;MDA01年-21年.csv&lt;/li&gt;
&lt;li&gt;公司基本情况文件.xlsx&lt;/li&gt;
&lt;li&gt;特殊变动处理.xlsx&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/dataset.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;数据获取&#34;&gt;数据获取&lt;/h2&gt;
&lt;p&gt;数据整理不易， 如需数据，&lt;a href=&#34;https://mp.weixin.qq.com/s/sgv5icnUZUFlP2JKvovEhA&#34;&gt;点击进入购买页面&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;一年报数据&#34;&gt;一、年报数据&lt;/h2&gt;
&lt;p&gt;01-21年年报数据&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pandas&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pd&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read_csv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;年报01年-21年.csv&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;converters&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;code&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;str&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;})&lt;/span&gt;
&lt;span class=&#34;c1&#34;&gt;#剔除第一行广告的办法&lt;/span&gt;
&lt;span class=&#34;c1&#34;&gt;#df = df[df.code!=&amp;#39;公众号:大邓和他的Python&amp;#39;]&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;head&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/df1.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;二mda数据&#34;&gt;二、MD&amp;amp;A数据&lt;/h2&gt;
&lt;p&gt;01-21年MD&amp;amp;A数据&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pandas&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pd&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;mda_df&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read_csv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;MDA01年-21年.csv&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;converters&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;code&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;str&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;})&lt;/span&gt;
&lt;span class=&#34;c1&#34;&gt;#剔除第一行广告的办法&lt;/span&gt;
&lt;span class=&#34;c1&#34;&gt;#mda_df = mda_df[mda_df.code!=&amp;#39;公众号:大邓和他的Python&amp;#39;]&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;mda_df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;head&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/df2.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mda_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;50302
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;三公司基本情况文件xlsx&#34;&gt;三、公司基本情况文件.xlsx&lt;/h2&gt;
&lt;p&gt;公司基本情况文件.xlsx&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Stkcd: 证券代码&lt;/li&gt;
&lt;li&gt;Stknme: 证券中文简称&lt;/li&gt;
&lt;li&gt;Stktype: 股票类型&lt;/li&gt;
&lt;li&gt;Crcd: A/B/H股交叉码&lt;/li&gt;
&lt;li&gt;Conme: 公司名称&lt;/li&gt;
&lt;li&gt;Cochsnm: 公司中文简称&lt;/li&gt;
&lt;li&gt;Conmee: 公司英文名称&lt;/li&gt;
&lt;li&gt;Nnindnme: 行业名称C&lt;/li&gt;
&lt;li&gt;Nnindcd: 行业代码C&lt;/li&gt;
&lt;li&gt;Nindnme: 行业名称B&lt;/li&gt;
&lt;li&gt;Nindcd: 行业代码B&lt;/li&gt;
&lt;li&gt;Indnme: 行业名称A&lt;/li&gt;
&lt;li&gt;Indcd: 行业代码A&lt;/li&gt;
&lt;li&gt;Busscope: 经营范围&lt;/li&gt;
&lt;li&gt;Cohisty: 公司沿革&lt;/li&gt;
&lt;li&gt;Regcap: 注册资本&lt;/li&gt;
&lt;li&gt;EstablishDate: 成立日期&lt;/li&gt;
&lt;li&gt;ListedDate: 上市日期&lt;/li&gt;
&lt;li&gt;DelistedDate: 退市日期&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pandas&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pd&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;ind_df&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read_excel&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;公司基本情况文件.xlsx&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;ind_df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;head&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/df3.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;四特殊变动处理xlsx&#34;&gt;四、特殊变动处理.xlsx&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Symbol: 证券代码&lt;/li&gt;
&lt;li&gt;ShortNamebc: 变动前的证券简称&lt;/li&gt;
&lt;li&gt;ShortNameac: 变动后的证券简称&lt;/li&gt;
&lt;li&gt;Chgtype: 变动类型&lt;/li&gt;
&lt;li&gt;Annoudt: 变动发布日期&lt;/li&gt;
&lt;li&gt;Execudt: 执行日期&lt;/li&gt;
&lt;li&gt;Chgreas: 变动原因编码&lt;/li&gt;
&lt;li&gt;Chgrsdis: 变动原因&lt;/li&gt;
&lt;li&gt;Content: 变动公告内容&lt;/li&gt;
&lt;li&gt;TypeAuditOpinbc: 变动前一年审计意见类型&lt;/li&gt;
&lt;li&gt;ISSustManaNonStandExpl: 是否发布可持续经营非标意见&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;st_pt_df&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read_excel&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;特殊变动处理.xlsx&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;st_pt_df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;head&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/df4.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;广而告之&#34;&gt;广而告之&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/call_for_paper/&#34;&gt;长期征稿&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/we_need_you/&#34;&gt;长期招募小伙伴&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/management_python_course/&#34;&gt;付费视频课 | Python实证指标构建与文本分析&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
      <content:encoded><![CDATA[<p>2001-2021年A股年报数据集，含4个文件，共17G</p>
<ul>
<li>年报01年-21年.csv</li>
<li>MDA01年-21年.csv</li>
<li>公司基本情况文件.xlsx</li>
<li>特殊变动处理.xlsx</li>
</ul>
<p><img loading="lazy" src="img/dataset.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="数据获取">数据获取</h2>
<p>数据整理不易， 如需数据，<a href="https://mp.weixin.qq.com/s/sgv5icnUZUFlP2JKvovEhA">点击进入购买页面</a></p>
<p><br><br></p>
<h2 id="一年报数据">一、年报数据</h2>
<p>01-21年年报数据</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;年报01年-21年.csv&#39;</span><span class="p">,</span> <span class="n">converters</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;code&#39;</span><span class="p">:</span> <span class="nb">str</span><span class="p">})</span>
<span class="c1">#剔除第一行广告的办法</span>
<span class="c1">#df = df[df.code!=&#39;公众号:大邓和他的Python&#39;]</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<p><img loading="lazy" src="img/df1.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="二mda数据">二、MD&amp;A数据</h2>
<p>01-21年MD&amp;A数据</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">mda_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;MDA01年-21年.csv&#39;</span><span class="p">,</span> <span class="n">converters</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;code&#39;</span><span class="p">:</span> <span class="nb">str</span><span class="p">})</span>
<span class="c1">#剔除第一行广告的办法</span>
<span class="c1">#mda_df = mda_df[mda_df.code!=&#39;公众号:大邓和他的Python&#39;]</span>
<span class="n">mda_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<p><img loading="lazy" src="img/df2.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="nb">len</span><span class="p">(</span><span class="n">mda_df</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">50302
</code></pre></div><p><br><br></p>
<h2 id="三公司基本情况文件xlsx">三、公司基本情况文件.xlsx</h2>
<p>公司基本情况文件.xlsx</p>
<ul>
<li>Stkcd: 证券代码</li>
<li>Stknme: 证券中文简称</li>
<li>Stktype: 股票类型</li>
<li>Crcd: A/B/H股交叉码</li>
<li>Conme: 公司名称</li>
<li>Cochsnm: 公司中文简称</li>
<li>Conmee: 公司英文名称</li>
<li>Nnindnme: 行业名称C</li>
<li>Nnindcd: 行业代码C</li>
<li>Nindnme: 行业名称B</li>
<li>Nindcd: 行业代码B</li>
<li>Indnme: 行业名称A</li>
<li>Indcd: 行业代码A</li>
<li>Busscope: 经营范围</li>
<li>Cohisty: 公司沿革</li>
<li>Regcap: 注册资本</li>
<li>EstablishDate: 成立日期</li>
<li>ListedDate: 上市日期</li>
<li>DelistedDate: 退市日期</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">ind_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_excel</span><span class="p">(</span><span class="s1">&#39;公司基本情况文件.xlsx&#39;</span><span class="p">)</span>
<span class="n">ind_df</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<p><img loading="lazy" src="img/df3.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="四特殊变动处理xlsx">四、特殊变动处理.xlsx</h2>
<ul>
<li>Symbol: 证券代码</li>
<li>ShortNamebc: 变动前的证券简称</li>
<li>ShortNameac: 变动后的证券简称</li>
<li>Chgtype: 变动类型</li>
<li>Annoudt: 变动发布日期</li>
<li>Execudt: 执行日期</li>
<li>Chgreas: 变动原因编码</li>
<li>Chgrsdis: 变动原因</li>
<li>Content: 变动公告内容</li>
<li>TypeAuditOpinbc: 变动前一年审计意见类型</li>
<li>ISSustManaNonStandExpl: 是否发布可持续经营非标意见</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">st_pt_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_excel</span><span class="p">(</span><span class="s1">&#39;特殊变动处理.xlsx&#39;</span><span class="p">)</span>
<span class="n">st_pt_df</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</code></pre></div><p><img loading="lazy" src="img/df4.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>借助chatGPT更高效地学习「Python实证指标构建与文本分析」</title>
      <link>https://textdata.cn/blog/2023-03-15-how-to-learn-python-data-mining-with-chatgpt/</link>
      <pubDate>Wed, 15 Mar 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-03-15-how-to-learn-python-data-mining-with-chatgpt/</guid>
      <description>借助chatGPT更高效地学习「Python实证指标构建与文本分析」学一门含有Python语法、代码技术、科研应用三类内容的课程，如【Python实证指标构建文本分析】，掌握并内化最少必要知识量。明白原理，会把需求转化成问题，向chatGPT提问。如果把社科数据分析需求比作城堡， 我们需要掌握拆解成多个小积木的能力，之后每个小积木让chatGPT帮我实现。我们要做的是</description>
      <content:encoded><![CDATA[<p>对编程0基础的人而言，三个痛点及解决办法</p>
<table>
<thead>
<tr>
<th>学习痛点</th>
<th>解决办法</th>
</tr>
</thead>
<tbody>
<tr>
<td>软件安装配置环境</td>
<td>淘宝搜【python环境配置】，30min，30元左右搞定</td>
</tr>
<tr>
<td>敲代码遇到问题，缺乏及时的答疑解惑</td>
<td>会正确上网，向chatGPT(实时应答的编程教练)提问</td>
</tr>
<tr>
<td>如何使用编程语言解决社科类科研数据挖掘问题</td>
<td>学一门含有Python语法、代码技术、科研应用三类内容的课程，如【Python实证指标构建文本分析】，掌握并内化 <strong>最少必要知识量</strong>。明白原理，会把需求转化成问题，向chatGPT提问。</td>
</tr>
</tbody>
</table>
<p>三种痛点及解决办法，可以将Python文本分析开展社科类科研数据挖掘的门槛大大降低。</p>
<br>
<h2 id="用术语提问">用术语提问</h2>
<p>如果把社科数据分析需求比作城堡， 我们需要掌握拆解成多个小积木的能力，之后每个小积木让chatGPT帮我实现。我们要做的是</p>
<ul>
<li>心中有施工蓝图，把大城堡拆解成多个小积木</li>
<li>每个小积木，要尽量用术语向chatGPT提问</li>
<li>对chatGPT回答进行检查和实验</li>
<li>最后，按施工蓝图把多个小积木搭成城堡。</li>
</ul>
<p>这需要我们掌握最少必要知识， Python语法，如数据类型、逻辑语句、常用库、常用函数、科研应用案例。</p>
<br>
<h2 id="提问案例">提问案例</h2>
<p>多观察代码，学会基本提问， 例如</p>
<ol>
<li>我是Python初学者，正在学Python。希望你当做我的Python解释器，我输入代码，你帮我运行并返回中文解释。</li>
<li>如何用Python写for循环</li>
<li>我想用Python统计某个词语列表中某些关键词的词频</li>
<li>如何用Python读取csv</li>
<li>我的代码出现UnicodeDecode错误， 这是源代码xxxx,这是报错提示，请解释问题，告诉我解决办法。</li>
<li>&hellip;&hellip;</li>
</ol>
<p>借助chatGPT写代码应用案例</p>
<ul>
<li><a href="https://textdata.cn/blog/2023-02-15-write-web-scraper-with-chatgpt/">使用 chatGPT 写 Python 网络爬虫</a></li>
<li><a href="https://textdata.cn/blog/2023-02-12-regex-expression-generated-by-chatgpt/">数据清洗 | 借助 chatGPT 设计正则表达式</a></li>
<li><a href="https://textdata.cn/blog/2023-02-11-chatgpt-plus-for-text-mining/">使用 chatGPT 做词频统计&amp;词云图</a></li>
</ul>
<br>
<h2 id="注册chatgpt">注册chatGPT</h2>
<p>科学上网、使用chatGPT都不难的，相关操作，可以参考大邓这篇博文</p>
<p><a href="https://textdata.cn/blog/2023-02-15-how-to-sign-up-the-chatgpt-accout-and-upgrade-to-plus/">https://textdata.cn/blog/2023-02-15-how-to-sign-up-the-chatgpt-accout-and-upgrade-to-plus/</a></p>
<br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>近年《经济研究》中「文本分析」相关论文</title>
      <link>https://textdata.cn/blog/2023-01-16-papers-using-text-mining-tech-in-journal-of-economic-research/</link>
      <pubDate>Mon, 16 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-01-16-papers-using-text-mining-tech-in-journal-of-economic-research/</guid>
      <description>使用机器学习、文本分析方法，发表在《经济研究》的相关论文</description>
      <content:encoded><![CDATA[<p>张叶青, 陆瑶, 李乐芸. <strong>大数据应用对中国企业市场价值的影响——来自中国上市公司年报文本分析的证据</strong>[J]. 经济研究, 2021, 56(12):18.</p>
<p>摘要：推进大数据与实体经济的深度融合成为中国新一轮的经济增长点.本文通过对A股上市公司的年报进行<strong>文本分析</strong>, <strong>构建了衡量公司层面&quot;大数据&quot;应用程度的指标</strong>,探讨了企业大数据应用的发展状况及决定因素,检验了大数据应用对公司市场价值的影响.研究发现:第一,规模较大,有形资产比例较低,盈利能力较强,以及所在地区市场化程度较高的公司更可能在生产经营过程中应用大数据;第二,大数据的应用可以显著提高公司的市场价值;第三,主要的影响机制在于大数据的应用显著提高了公司的生产效率和研发投入,而相关技术和人才供给的不足可能会阻碍大数据对市场价值的积极影响.本文结论对中国未来大数据相关的政策设计具有参考价值,为推动实体企业生产经营与大数据的高效融合提供了经验证据和指导建议.</p>
 <br> 
<p>李晓溪,杨国超,饶品贵.<strong>交易所问询函有监管作用吗?——基于并购重组报告书的文本分析</strong>[J].经济研究,2019,54(05):181-198.</p>
<p>摘要:在国务院大力强调优化兼并重组市场环境的形势下,2014年以来交易所广泛使用的并购问询函制度能否发挥监管作用,成为并购重组服务实体经济能力的重要影响因素。为此,本文研究交易所问询函是否降低并购重组信息不对称进而提升并购绩效。研究结果表明,交易所问询函能够识别并购重组中的潜在风险,表现为信息不对称程度较高、报告书信息披露质量较差的并购重组交易更可能收到问询函。进一步地,被问询样本在收到问询函之后的买卖价差、分析师盈余预测误差以及分析师乐观程度较低。 <strong>针对具体作用机制,本文采用文本分析法比较修订前后的并购重组报告书,发现新修订报告书中标的方历史信息和前瞻信息的内容均更多,且更详细,表明问询函制度通过改善信息披露缓解了并购交易的信息不对称问题</strong>。经济后果方面,本文发现信息披露改善较多的被问询样本重组成功的可能性更大,未来市场业绩也更好。本文研究不仅丰富了问询函经济后果的相关研究,也为问询监管政策缓解并购重组信息不对称提供了理论参考。</p>
 <br> 
<p>张成思, 孙宇辰, 阮睿. <strong>宏观经济感知,货币政策与微观企业投融资行为</strong>[J]. 经济研究, 2021, 56(10):17.</p>
<p>摘要：<strong>本文基于中国上市公司年报文本信息,首次构建了中国微观企业宏观经济感知指数</strong>,并通过一个三期理论模型阐释货币政策在不同宏观经济感知情形下如何影响微观企业投融资行为.实证分析表明,当央行实施积极货币政策时,对宏观经济感知更乐观的企业更积极地响应政策刺激,表现为投融资行为增加.进一步将宏观经济感知指数分解为预期指数和回顾指数,分析结果表明:宏观经济感知指数的影响主要由反映企业未来预期的宏观经济预期指数引致,而反映历史信息的宏观经济回顾指数则没有显著影响.区分企业所有制的结果还表明,持有积极宏观经济感知的民营企业仅在积极货币政策状态下增加投资和提高杠杆率,而宏观经济感知对国有企业投融资行为的作用则未受货币政策状态影响.</p>
<br> 
<p>林建浩, 陈良源, 罗子豪,等. <strong>央行沟通有助于改善宏观经济预测吗?——基于文本数据的高维稀疏建模</strong>[J]. 经济研究, 2021,56(03).</p>
<p>摘要： 宏观经济预测是宏观调控精准施策的重要前提,一直以来是方法论研究的前沿议题.随着央行沟通在预期管理中的频繁使用,其传达的信息受到普遍关注,<strong>本文致力于利用央行沟通文本进行宏观经济预测.首先生成符合央行沟通表达习惯的专用词典用于构建完整语料库,继而利用栅栏分布式多项回归模型从高维和稀疏的语料库中提取有效信息</strong>,得到央行沟通测度.基于152个指标构建基准动态因子模型,进一步引入央行沟通测度作为新的预测因子,结果显示央行沟通测度有助于提升模型样本内拟合效果.考察样本外预测效果,在不包括预测变量历史信息时,央行沟通测度能够使得不同期限的预测精度提高6.80％-16.65％;包含预测变量历史信息时则出现分化,在期限较短时,央行沟通未能提升预测精度,这是因为主要沟通信息与预测变量历史信息重叠;当期限较长时,预测精度有所提升,表明沟通中少量的前瞻性指引具有持续的预测能力.本文研究从预测角度验证了中国央行沟通在预期管理中的作用,并为进一步利用非结构化的文本大数据提升中国宏观经济实时预测能力提供了新思路.</p>
 <br> 
<p>曹廷求, 张光利. <strong>自愿性信息披露与股价崩盘风险:基于电话会议的研究</strong>[J]. 经济研究, 2020, 55(11):17.</p>
<p>摘要：<strong>电话会议已经成为中国上市企业自愿性信息披露的重要渠道</strong>,本文从股价崩盘风险的视角探讨了电话会议的信息披露效果.实证结果表明,电话会议能够显著降低企业股价崩盘风险,在控制反向因果和遗漏变量导致的内生性问题之后,该结论依然成立.电话会议影响股价崩盘风险的程度受到企业异质性和外部信息环境的影响,具体而言,我们发现当企业的信息披露质量越高,机构投资者持股比例越高,被分析师关注程度越高,投资者对企业信息的需求越强时,电话会议对企业股价崩盘风险的影响越强.另外,我们分别从<strong>电话会议信息含量</strong>,投资者反应周期,<strong>高管语言特征</strong>,会议主题的视角讨论了电话会议影响股价崩盘风险的机制.本文的研究对于全面认识电话会议在资本市场中的信息披露效果以及如何降低股价崩盘风险具有重要的理论和现实意义。</p>
<br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>金融研究 | 使用Python构建「关键审计事项信息含量」</title>
      <link>https://textdata.cn/blog/2023-01-13-information-content-of-critical-audit/</link>
      <pubDate>Fri, 13 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-01-13-information-content-of-critical-audit/</guid>
      <description>关键审计事项是来自审计师视角的信息， 其蕴含的特质性信息对实现沟通价值至关重要。本文采用文本 分析方法计算的文本相似度衡量关键审计事项特质性信息含量，考察其对公司债券发行定价的影响。 结果发现， 以较低文本相似度代表的较高关键审计事项信息含量能够降低公司债券发行定价。 较高的审计师专业胜任能力 和独立性能够增强关键审计事项信息含量对公司债券发行定价的降低作用。 信息不对称的缓解是关键审计事项 信息含量降低公司债券发行定价的具体影响渠道。考虑关键审计事项类型后发现， 关联交易类关键审计事项信 息含量对公司债券发行定价的降低作用更强。本文研究结论有助于未来改进关键审计事项的披露要求。</description>
      <content:encoded><![CDATA[<p>宋建波,冯晓晴.关键审计事项信息含量与公司债券发行定价——基于文本相似度视角[J].会计研究,2022,(03):174-191.
<img loading="lazy" src="img/%e5%85%b3%e9%94%ae%e5%ae%a1%e8%ae%a1%e4%ba%8b%e9%a1%b9%e4%bf%a1%e6%81%af%e5%90%ab%e9%87%8f%e4%b8%8e%e5%85%ac%e5%8f%b8%e5%80%ba%e5%88%b8%e5%8f%91%e8%a1%8c%e5%ae%9a%e4%bb%b7_cover.png" alt=""  />
</p>
<h2 id="摘要">摘要</h2>
<p>关键审计事项是来自审计师视角的信息， 其蕴含的特质性信息对实现沟通价值至关重要。<strong>本文采用文本分析方法计算的文本相似度衡量关键审计事项特质性信息含量，考察其对公司债券发行定价的影响。 结果发现， 以较低文本相似度代表的较高关键审计事项信息含量能够降低公司债券发行定价</strong>。 较高的审计师专业胜任能力 和独立性能够增强关键审计事项信息含量对公司债券发行定价的降低作用。 信息不对称的缓解是关键审计事项 信息含量降低公司债券发行定价的具体影响渠道。考虑关键审计事项类型后发现， 关联交易类关键审计事项信 息含量对公司债券发行定价的降低作用更强。本文研究结论有助于未来改进关键审计事项的披露要求。</p>
<p>关键词: 关键审计事项; 公司债券; 发行定价; 信息含量; 文本相似度</p>
<p><br><br></p>
<h2 id="一信息含量算法">一、信息含量算法</h2>
<p>文中关键审计事项信息含量算法</p>
<p><img loading="lazy" src="img/%e5%85%b3%e9%94%ae%e5%ae%a1%e8%ae%a1%e4%ba%8b%e9%a1%b9%e4%bf%a1%e6%81%af%e5%90%ab%e9%87%8f-%e5%ae%9e%e7%8e%b0%e7%ae%97%e6%b3%95.png" alt=""  />
</p>
<p>本文不仅限于关键审计事项，在别的应用场景中也可以使用相似度计算得到信息含量。这里将算法再简化为文本向量化，依次计算得到该企业的<strong>企业向量</strong>、该企业所在行业的<strong>行业向量</strong>、<strong>信息含量(特质性)</strong>。大致的算法思路如下</p>
<ol>
<li>使用sklearn，将该企业文本(审计报告文本)转为TF-IDF的<strong>企业向量</strong>。</li>
<li>当年同行业所有企业(排除该公司)向量求均值，得到<strong>行业向量</strong>。</li>
<li>计算企业向量与行业向量余弦值，乘以(-1)，得到该企业的特质性的<strong>信息含量</strong></li>
</ol>
<p><br><br></p>
<h2 id="二信息含量算法实现">二、信息含量算法实现</h2>
<p>计算关键审计事项信息含量，需要有审计报告、行业。这里参考论文，使用md&amp;a文本 和 md&amp;a数据,用于计算 <strong>企业信息含量(特质性)</strong> 。</p>
<p>为了减少计算工作量，这里只准备了 2020 年的数据。</p>
<h3 id="21-读入数据">2.1 读入数据</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="c1"># converters 强制声明该列为字符串，  防止股票代码 被程序识别为数字，</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_excel</span><span class="p">(</span><span class="s1">&#39;mda2020.xlsx&#39;</span><span class="p">,</span> <span class="n">converters</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;股票代码&#39;</span><span class="p">:</span> <span class="nb">str</span><span class="p">})</span>

<span class="c1">#显示前5行</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/df1.png" alt=""  />
</p>
<br>
<h3 id="22-数据筛选">2.2 数据筛选</h3>
<p>行业内企业数量过少，会导致行业向量与某个或某几个企业向量相关性增大，极端情况下，一个企业就是一个行业。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df</span><span class="p">[</span><span class="s1">&#39;行业代码&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</code></pre></div><pre><code>C39    419
C26    272
C35    256
C38    254
I65    250
      ... 
M75      1
R88      1
O80      1
B10      1
E49      1
Name: 行业代码, Length: 81, dtype: int64
</code></pre>
<p>剔除掉企业数较少的行业，这里只保留大于20的行业。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">ind_codes</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;行业代码&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
<span class="n">ind_codes</span> <span class="o">=</span> <span class="n">ind_codes</span><span class="p">[</span><span class="n">ind_codes</span><span class="o">&gt;</span><span class="mi">20</span><span class="p">]</span><span class="o">.</span><span class="n">index</span>
<span class="n">ind_codes</span>
</code></pre></div><pre><code>Index(['C39', 'C26', 'C35', 'C38', 'I65', 'C27', 'C34', 'C36', 'K70', 'C30',
       'F52', 'C29', 'F51', 'C32', 'C33', 'D44', 'I64', 'E48', 'C40', 'C14',
       'C37', 'N77', 'J67', 'L72', 'C13', 'M74', 'C15', 'C17', 'C18', 'J66',
       'G54', 'C22', 'C31', 'G55', 'E50', 'C28', 'D45', 'R86', 'R85', 'C21',
       'B06', 'C41', 'B09', 'J69'],
      dtype='object')
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">filter_industry</span><span class="p">(</span><span class="n">ind_code</span><span class="p">):</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">ind_code</span> <span class="ow">in</span> <span class="n">ind_codes</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">True</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">False</span>
    <span class="k">except</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">False</span>


<span class="n">df2</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;行业代码&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">filter_industry</span><span class="p">)]</span>
<span class="n">df2</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/df2.png" alt=""  />
</p>
<br>
<h3 id="23-文本向量化">2.3 文本向量化</h3>
<p>使用sklearn，将该企业文本(审计报告文本)转为TF-IDF的企业向量。步骤</p>
<ol>
<li>分词整理</li>
<li>tfidff文本向量化</li>
<li>合并多个字段为新的df</li>
</ol>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>
<span class="kn">import</span> <span class="nn">jieba</span>
<span class="kn">import</span> <span class="nn">re</span>

<span class="n">stopwords</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">load_pkl_dict</span><span class="p">(</span><span class="s1">&#39;STOPWORDS.pkl&#39;</span><span class="p">)[</span><span class="s1">&#39;STOPWORDS&#39;</span><span class="p">][</span><span class="s1">&#39;chinese&#39;</span><span class="p">]</span>


<span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="c1">#只保留md&amp;a中的中文内容</span>
    <span class="n">text</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">re</span><span class="o">.</span><span class="n">findall</span><span class="p">(</span><span class="s1">&#39;[</span><span class="se">\u4e00</span><span class="s1">-</span><span class="se">\u9fa5</span><span class="s1">]+&#39;</span><span class="p">,</span> <span class="n">text</span><span class="p">))</span>
    <span class="c1">#剔除停用词</span>
    <span class="n">words</span> <span class="o">=</span> <span class="p">[</span><span class="n">w</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">jieba</span><span class="o">.</span><span class="n">cut</span><span class="p">(</span><span class="n">text</span><span class="p">)</span> <span class="k">if</span> <span class="n">w</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">stopwords</span><span class="p">]</span>
    <span class="c1">#整理为用空格间隔的字符串(类西方语言文本格式)</span>
    <span class="k">return</span> <span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">words</span><span class="p">)</span>

<span class="n">df2</span><span class="p">[</span><span class="s1">&#39;clean_text&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df2</span><span class="p">[</span><span class="s1">&#39;经营讨论与分析内容&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">transform</span><span class="p">)</span>
<span class="n">df2</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/df3.png" alt=""  />
</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">TfidfVectorizer</span>

<span class="n">cv</span> <span class="o">=</span> <span class="n">TfidfVectorizer</span><span class="p">(</span><span class="n">min_df</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span> <span class="n">max_df</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span> 
<span class="c1"># 生成稀疏bow矩阵</span>
<span class="c1">#dtm 文档-词频-矩阵</span>
<span class="n">dtm2020</span> <span class="o">=</span> <span class="n">cv</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df2</span><span class="p">[</span><span class="s1">&#39;clean_text&#39;</span><span class="p">])</span> 
<span class="n">dtm2020</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">dtm2020</span><span class="o">.</span><span class="n">toarray</span><span class="p">())</span>
<span class="n">dtm2020</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/df4.png" alt=""  />
</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#合并多个字段为新的df</span>
<span class="n">dtm2020_</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">df2</span><span class="p">[[</span><span class="s1">&#39;股票代码&#39;</span><span class="p">,</span> <span class="s1">&#39;会计年度&#39;</span><span class="p">,</span> <span class="s1">&#39;行业代码&#39;</span><span class="p">]],</span> <span class="n">dtm2020</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">dtm2020_</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/df5.png" alt=""  />
</p>
<br>
<h3 id="24-计算2020年信息含量">2.4 计算2020年信息含量</h3>
<ol>
<li>使用sklearn，将该企业文本(审计报告文本)转为TF-IDF的<strong>企业向量</strong>。</li>
<li>当年同行业所有企业(排除该公司)向量求均值，得到<strong>行业向量</strong>。</li>
<li>计算企业向量与行业向量余弦值，乘以(-1)，得到该企业的特质性的<strong>信息含量</strong></li>
</ol>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics.pairwise</span> <span class="kn">import</span> <span class="n">cosine_similarity</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">csv</span>

<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;信息含量2020.csv&#39;</span><span class="p">,</span> <span class="s1">&#39;a+&#39;</span><span class="p">,</span> <span class="n">newline</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">csvf</span><span class="p">:</span>
    <span class="n">fieldnames</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;股票代码&#39;</span><span class="p">,</span> <span class="s1">&#39;会计年度&#39;</span><span class="p">,</span> <span class="s1">&#39;行业代码&#39;</span><span class="p">,</span> <span class="s1">&#39;信息含量&#39;</span><span class="p">]</span>
    <span class="n">writer</span> <span class="o">=</span> <span class="n">csv</span><span class="o">.</span><span class="n">DictWriter</span><span class="p">(</span><span class="n">csvf</span><span class="p">,</span> <span class="n">fieldnames</span><span class="o">=</span><span class="n">fieldnames</span><span class="p">)</span>
    <span class="n">writer</span><span class="o">.</span><span class="n">writeheader</span><span class="p">()</span>
    
    <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dtm2020_</span><span class="p">)):</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">code</span> <span class="o">=</span> <span class="n">dtm2020_</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="s1">&#39;股票代码&#39;</span><span class="p">]</span>
            <span class="n">ind</span> <span class="o">=</span> <span class="n">dtm2020_</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="s1">&#39;行业代码&#39;</span><span class="p">]</span>
            <span class="n">year</span> <span class="o">=</span> <span class="n">dtm2020_</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="s1">&#39;会计年度&#39;</span><span class="p">]</span>
            <span class="c1">#企业向量</span>
            <span class="n">corp_vec</span> <span class="o">=</span> <span class="p">[</span><span class="n">dtm2020_</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="mi">3</span><span class="p">:]</span><span class="o">.</span><span class="n">values</span><span class="p">]</span>
            <span class="n">corp_arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">corp_vec</span><span class="p">)</span>
            <span class="c1">#行业向量</span>
            <span class="n">ind_vec</span> <span class="o">=</span> <span class="p">[</span><span class="n">dtm2020_</span><span class="p">[</span><span class="n">dtm2020_</span><span class="p">[</span><span class="s1">&#39;行业代码&#39;</span><span class="p">]</span><span class="o">==</span><span class="n">ind</span><span class="p">][</span><span class="n">dtm2020_</span><span class="p">[</span><span class="s1">&#39;股票代码&#39;</span><span class="p">]</span><span class="o">!=</span><span class="n">code</span><span class="p">]</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">3</span><span class="p">:]</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">values</span><span class="p">]</span>
            <span class="n">ind_arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">ind_vec</span><span class="p">)</span>
            <span class="c1">#信息含量</span>
            <span class="n">special_info</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span> <span class="o">*</span> <span class="n">cosine_similarity</span><span class="p">(</span><span class="n">corp_arr</span><span class="p">,</span> <span class="n">ind_arr</span><span class="p">)[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>

            <span class="n">data</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
            <span class="n">data</span><span class="p">[</span><span class="s1">&#39;股票代码&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">code</span>
            <span class="n">data</span><span class="p">[</span><span class="s1">&#39;行业代码&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">ind</span>
            <span class="n">data</span><span class="p">[</span><span class="s1">&#39;会计年度&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">year</span>
            <span class="n">data</span><span class="p">[</span><span class="s1">&#39;信息含量&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">special_info</span>

            <span class="n">writer</span><span class="o">.</span><span class="n">writerow</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="k">except</span><span class="p">:</span>
            <span class="k">pass</span>
</code></pre></div><p>欣赏一下结果</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">idf</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;信息含量2020.csv&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">idf</span><span class="p">))</span>
<span class="n">idf</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/df6.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="三讨论">三、讨论</h2>
<p>最近陆续分享了几篇<strong>文本相似度</strong>、<strong>信息含量</strong>的论文</p>
<ul>
<li>[1]姜富伟,胡逸驰,黄楠.央行货币政策报告文本信息、宏观经济与股票市场[J].金融研究,2021,(06):95-113.</li>
<li>[2]宋建波,冯晓晴.关键审计事项信息含量与公司债券发行定价——基于文本相似度视角[J].会计研究,2022,(03):174-191.</li>
<li>[3]孟庆斌,杨俊华,鲁冰.管理层讨论与分析披露的信息含量与股价崩盘风险——基于文本向量化方法的研究[J].中国工业经济,2017,(12):132-150.</li>
</ul>
<p>比较一下,三者均先使用了文本向量化，将本文数据转为向量。每篇论文的算法</p>
<br>
<table>
<thead>
<tr>
<th>论文</th>
<th>指标</th>
<th>算法</th>
</tr>
</thead>
<tbody>
<tr>
<td>[1]</td>
<td>文本相似度</td>
<td>将央行货币政策报告向量化， 临近的两个报告文本向量计算相似度，相似度越高，金融市场波动性越小。</td>
</tr>
<tr>
<td>[2]</td>
<td>信息含量</td>
<td>将同行业内所有企业向量Corp求均值得到行业向量Ind，求Corp与Ind的余弦相似度，并将结果乘以(-1),所得结果定义为信息向量。</td>
</tr>
<tr>
<td>[3]</td>
<td>信息含量</td>
<td>文本向量化+计量建模，认为md&amp;a中的信息向量Norm可以由市场Norm_Market、行业Norm_Industry、企业异质性μ三种信息向量组成，通过计算 <br><code>Norm = a0 + a1*Norm_Industry +  a2*Norm_Market + μ</code> <br>，将μ 向量的绝对值和作为信息含量，而a1+a2看标准信息。</td>
</tr>
</tbody>
</table>
<br>
<p>从中可以看到两个向量的余弦相似度，在不同场景，解读含义是不同的，亦正亦邪。在货币政策中，相似度越高，表示越政策稳定，金融市场波动星越小。而在关键审计场景中，特质性信息是缓解公司与投资者信息不对称的关键，公司向量Corp与行业向量Ind相似度越高，表示公司审计报告文本特质性信息越少。</p>
<br>
<br>
<h2 id="代码获取">代码获取</h2>
<ul>
<li>代码及视频讲解已经添加至 <a href="https://textdata.cn/blog/management_python_course/">支持开票 | Python实证指标构建与文本分析</a> 中，感兴趣的同学欢迎订阅该系列课，涵盖Python语法入门、数据采集、文本分析、机器学习等。</li>
<li>数据&amp;代码创作不易， 如果需要源代码和数据， <a href="https://mp.weixin.qq.com/s/wkETqR-e0pgN8QLar-GUmw">点击进入购买链接</a></li>
</ul>
<br>
<br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>转载 | 国外会计文本信息实证研究述评与展望</title>
      <link>https://textdata.cn/blog/2023-01-12-review_about_accounting_text_mining/</link>
      <pubDate>Thu, 12 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-01-12-review_about_accounting_text_mining/</guid>
      <description>近年来，文本信息逐渐成为国外会计实证研究的热点，许多学者开始致力于 运用文本分析方法来解决会计与财务问题，并取得了众多有价值的研究成果。与之相比，国 内的此类研究却相当缺乏。为了弥补国内研究的不足，本文对国外近十年来取得的研究成果 进行了系统的梳理和述评。首先，系统阐述了会计文本信息的定义、特征及其测量方法；其 次，从不同层面出发，总结并分析了会计文本信息的影响因素及其作用结果；再次，指出了 现今国外研究中存在的不足。在此基础上，本文提出了一个未来研究的框架，分别从基础、 引入、拓展三个方向来展望国内研究，具体包括如何构建适合中文会计语言的文本分析方 法、国外现有理论与问题在我国的本土化检验以及在中国情境下可以拓展的独创性研究。In recent years, text information has gradually become a hot spot in foreign accounting empirical research. Many scholars have begun to use text analysis methods to solve accounting and financial problems, and have achieved many valuable research results. In contrast, such research in China is quite lacking. In order to make up for the lack of domestic research, this paper systematically sorts out and reviews the research achievements abroad in the past ten years. Firstly, it systematically expounds the definition, characteristics and measurement methods of accounting textual information; secondly, it summarizes and analyzes the influencing factors and results of accounting textual information from different levels; thirdly, it points out the deficiencies in current foreign research . On this basis, this paper proposes a framework for future research, looking forward to domestic research from the three directions of foundation, introduction, and expansion, including how to construct a text analysis method suitable for Chinese accounting language, and the existing foreign theories and problems in my country. Indigenous testing and original research that can be extended in the Chinese context.</description>
      <content:encoded><![CDATA[<br>
<p>肖浩,詹雷,王征.国外会计文本信息实证研究述评与展望[J].外国经济与管理,2016,38(09):93-112.</p>
<br>
<p><img loading="lazy" src="img/%e5%9b%bd%e5%a4%96%e4%bc%9a%e8%ae%a1%e6%96%87%e6%9c%ac%e4%bf%a1%e6%81%af%e5%ae%9e%e8%af%81%e7%a0%94%e7%a9%b6%e8%bf%b0%e8%af%84%e4%b8%8e%e5%b1%95%e6%9c%9b_%e8%82%96%e6%b5%a9-01.png" alt=""  />

<img loading="lazy" src="img/%e5%9b%bd%e5%a4%96%e4%bc%9a%e8%ae%a1%e6%96%87%e6%9c%ac%e4%bf%a1%e6%81%af%e5%ae%9e%e8%af%81%e7%a0%94%e7%a9%b6%e8%bf%b0%e8%af%84%e4%b8%8e%e5%b1%95%e6%9c%9b_%e8%82%96%e6%b5%a9-02.png" alt=""  />

<img loading="lazy" src="img/%e5%9b%bd%e5%a4%96%e4%bc%9a%e8%ae%a1%e6%96%87%e6%9c%ac%e4%bf%a1%e6%81%af%e5%ae%9e%e8%af%81%e7%a0%94%e7%a9%b6%e8%bf%b0%e8%af%84%e4%b8%8e%e5%b1%95%e6%9c%9b_%e8%82%96%e6%b5%a9-03.png" alt=""  />

<img loading="lazy" src="img/%e5%9b%bd%e5%a4%96%e4%bc%9a%e8%ae%a1%e6%96%87%e6%9c%ac%e4%bf%a1%e6%81%af%e5%ae%9e%e8%af%81%e7%a0%94%e7%a9%b6%e8%bf%b0%e8%af%84%e4%b8%8e%e5%b1%95%e6%9c%9b_%e8%82%96%e6%b5%a9-04.png" alt=""  />

<img loading="lazy" src="img/%e5%9b%bd%e5%a4%96%e4%bc%9a%e8%ae%a1%e6%96%87%e6%9c%ac%e4%bf%a1%e6%81%af%e5%ae%9e%e8%af%81%e7%a0%94%e7%a9%b6%e8%bf%b0%e8%af%84%e4%b8%8e%e5%b1%95%e6%9c%9b_%e8%82%96%e6%b5%a9-05.png" alt=""  />

<img loading="lazy" src="img/%e5%9b%bd%e5%a4%96%e4%bc%9a%e8%ae%a1%e6%96%87%e6%9c%ac%e4%bf%a1%e6%81%af%e5%ae%9e%e8%af%81%e7%a0%94%e7%a9%b6%e8%bf%b0%e8%af%84%e4%b8%8e%e5%b1%95%e6%9c%9b_%e8%82%96%e6%b5%a9-06.png" alt=""  />

<img loading="lazy" src="img/%e5%9b%bd%e5%a4%96%e4%bc%9a%e8%ae%a1%e6%96%87%e6%9c%ac%e4%bf%a1%e6%81%af%e5%ae%9e%e8%af%81%e7%a0%94%e7%a9%b6%e8%bf%b0%e8%af%84%e4%b8%8e%e5%b1%95%e6%9c%9b_%e8%82%96%e6%b5%a9-07.png" alt=""  />

<img loading="lazy" src="img/%e5%9b%bd%e5%a4%96%e4%bc%9a%e8%ae%a1%e6%96%87%e6%9c%ac%e4%bf%a1%e6%81%af%e5%ae%9e%e8%af%81%e7%a0%94%e7%a9%b6%e8%bf%b0%e8%af%84%e4%b8%8e%e5%b1%95%e6%9c%9b_%e8%82%96%e6%b5%a9-08.png" alt=""  />

<img loading="lazy" src="img/%e5%9b%bd%e5%a4%96%e4%bc%9a%e8%ae%a1%e6%96%87%e6%9c%ac%e4%bf%a1%e6%81%af%e5%ae%9e%e8%af%81%e7%a0%94%e7%a9%b6%e8%bf%b0%e8%af%84%e4%b8%8e%e5%b1%95%e6%9c%9b_%e8%82%96%e6%b5%a9-09.png" alt=""  />

<img loading="lazy" src="img/%e5%9b%bd%e5%a4%96%e4%bc%9a%e8%ae%a1%e6%96%87%e6%9c%ac%e4%bf%a1%e6%81%af%e5%ae%9e%e8%af%81%e7%a0%94%e7%a9%b6%e8%bf%b0%e8%af%84%e4%b8%8e%e5%b1%95%e6%9c%9b_%e8%82%96%e6%b5%a9-10.png" alt=""  />

<img loading="lazy" src="img/%e5%9b%bd%e5%a4%96%e4%bc%9a%e8%ae%a1%e6%96%87%e6%9c%ac%e4%bf%a1%e6%81%af%e5%ae%9e%e8%af%81%e7%a0%94%e7%a9%b6%e8%bf%b0%e8%af%84%e4%b8%8e%e5%b1%95%e6%9c%9b_%e8%82%96%e6%b5%a9-11.png" alt=""  />

<img loading="lazy" src="img/%e5%9b%bd%e5%a4%96%e4%bc%9a%e8%ae%a1%e6%96%87%e6%9c%ac%e4%bf%a1%e6%81%af%e5%ae%9e%e8%af%81%e7%a0%94%e7%a9%b6%e8%bf%b0%e8%af%84%e4%b8%8e%e5%b1%95%e6%9c%9b_%e8%82%96%e6%b5%a9-12.png" alt=""  />

<img loading="lazy" src="img/%e5%9b%bd%e5%a4%96%e4%bc%9a%e8%ae%a1%e6%96%87%e6%9c%ac%e4%bf%a1%e6%81%af%e5%ae%9e%e8%af%81%e7%a0%94%e7%a9%b6%e8%bf%b0%e8%af%84%e4%b8%8e%e5%b1%95%e6%9c%9b_%e8%82%96%e6%b5%a9-13.png" alt=""  />

<img loading="lazy" src="img/%e5%9b%bd%e5%a4%96%e4%bc%9a%e8%ae%a1%e6%96%87%e6%9c%ac%e4%bf%a1%e6%81%af%e5%ae%9e%e8%af%81%e7%a0%94%e7%a9%b6%e8%bf%b0%e8%af%84%e4%b8%8e%e5%b1%95%e6%9c%9b_%e8%82%96%e6%b5%a9-14.png" alt=""  />

<img loading="lazy" src="img/%e5%9b%bd%e5%a4%96%e4%bc%9a%e8%ae%a1%e6%96%87%e6%9c%ac%e4%bf%a1%e6%81%af%e5%ae%9e%e8%af%81%e7%a0%94%e7%a9%b6%e8%bf%b0%e8%af%84%e4%b8%8e%e5%b1%95%e6%9c%9b_%e8%82%96%e6%b5%a9-15.png" alt=""  />

<img loading="lazy" src="img/%e5%9b%bd%e5%a4%96%e4%bc%9a%e8%ae%a1%e6%96%87%e6%9c%ac%e4%bf%a1%e6%81%af%e5%ae%9e%e8%af%81%e7%a0%94%e7%a9%b6%e8%bf%b0%e8%af%84%e4%b8%8e%e5%b1%95%e6%9c%9b_%e8%82%96%e6%b5%a9-16.png" alt=""  />

<img loading="lazy" src="img/%e5%9b%bd%e5%a4%96%e4%bc%9a%e8%ae%a1%e6%96%87%e6%9c%ac%e4%bf%a1%e6%81%af%e5%ae%9e%e8%af%81%e7%a0%94%e7%a9%b6%e8%bf%b0%e8%af%84%e4%b8%8e%e5%b1%95%e6%9c%9b_%e8%82%96%e6%b5%a9-17.png" alt=""  />

<img loading="lazy" src="img/%e5%9b%bd%e5%a4%96%e4%bc%9a%e8%ae%a1%e6%96%87%e6%9c%ac%e4%bf%a1%e6%81%af%e5%ae%9e%e8%af%81%e7%a0%94%e7%a9%b6%e8%bf%b0%e8%af%84%e4%b8%8e%e5%b1%95%e6%9c%9b_%e8%82%96%e6%b5%a9-18.png" alt=""  />
</p>
<br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>金融研究 | 央行货币政策文本相似度计算与可视化</title>
      <link>https://textdata.cn/blog/2023-01-10-similarity_of_cental_bank_monetary_policy/</link>
      <pubDate>Tue, 10 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-01-10-similarity_of_cental_bank_monetary_policy/</guid>
      <description>本文利用金融情感词典和文本分析技术,分析中国人民银行货币政策执行报告的**文本情绪、文本相似度和文本可读性**等多维文本信息,刻画央行货币政策执行报告的文本特征,探究货币政策报告的文本信息与宏观经济和股票市场的关系。**实证研究发现,货币政策报告的文本情绪的改善会引起显著为正的股票市场价格反应, 报告文本相似度的增加会引起股票市场波动性的显著降低, 报告可读性对公布后股票市场的波动性影响不显著**。货币政策报告文本情绪还与诸多宏观经济指标显著相关。进一步研究发现,引起股票市场显著反应的是报告文本情绪中反映货币政策指引的部分,而反映宏观经济历史状态的部分对股票市场的影响不显著。本文从文本大数据分析角度证明了我国央行沟通的有效性,对国内央行沟通相关研究形成了有益补充。This paper uses text analysis techniques to analyze 71 Monetary Policy Implementation Ｒeports （ hereinafter referred to as“the reports”） of PBOC，calculates the text sentiment （ tone） ，the similarity and readability and other text indicators of the reports，and explores the relationship between these text indicators and the macro economy and the stock market． Based on the Chinese financial sentiment dictionary developed by Jiang et al． （ 2020） ，this paper uses the sentiment unit method to calculate the tone of the reports． In addition，this paper uses TF － IDF weighted cosine similarity to characterize the similarity of the reports，and uses average sentence length to characterize the readability of the reports． The paper then uses correlation analysis to examine the relationship between the tone of the reports and macroeconomic indicators such as economic growth，inflation， and interest rates． With reference to Ehrmann and Fratzscher （ 2009） ，Zhang and Hu （ 2014） ，this paper adds tone，similarity and readability to the EGAＲCH model to explore whether textual indicators of the reports affect stock market returns and the volatility on the trading day after the release． Furthermore，this paper decomposes the content of the reports into two parts： economic and financial fundamentals and central bank policy guidelines，calculates the tone of the two parts and examines their impacts on the stock market respectively．</description>
      <content:encoded><![CDATA[<p>姜富伟,胡逸驰,黄楠.<strong><a href="%E5%A4%AE%E8%A1%8C%E8%B4%A7%E5%B8%81%E6%94%BF%E7%AD%96%E6%8A%A5%E5%91%8A%E6%96%87%E6%9C%AC%E4%BF%A1%E6%81%AF%E3%80%81%E5%AE%8F%E8%A7%82%E7%BB%8F%E6%B5%8E%E4%B8%8E%E8%82%A1%E7%A5%A8%E5%B8%82%E5%9C%BA_%E5%A7%9C%E5%AF%8C%E4%BC%9F.pdf">央行货币政策报告文本信息、宏观经济与股票市场</a></strong>[J].金融研究,2021,(06):95-113.</p>
<br>
<p>摘要:本文利用金融情感词典和文本分析技术,分析中国人民银行货币政策执行报告的<strong>文本情绪、文本相似度和文本可读性</strong>等多维文本信息,刻画央行货币政策执行报告的文本特征,探究货币政策报告的文本信息与宏观经济和股票市场的关系。<strong>实证研究发现,货币政策报告的文本情绪的改善会引起显著为正的股票市场价格反应, 报告文本相似度的增加会引起股票市场波动性的显著降低, 报告可读性对公布后股票市场的波动性影响不显著</strong>。货币政策报告文本情绪还与诸多宏观经济指标显著相关。进一步研究发现,引起股票市场显著反应的是报告文本情绪中反映货币政策指引的部分,而反映宏观经济历史状态的部分对股票市场的影响不显著。本文从文本大数据分析角度证明了我国央行沟通的有效性,对国内央行沟通相关研究形成了有益补充。</p>
<br>
<p>文文相似度很好用，下图是该论文中绘制的2001-2018年间的货币政策报告<strong>文本相似度</strong>。 <strong>前后相邻两个季度的货币政策文本相似度越高，说明政策相似性高，政策连贯性强(变化小)。如果相似度较低，则政策变动的风险较大，政策连贯性差(变化大)</strong>。</p>
<p><img loading="lazy" src="img/%e8%ae%ba%e6%96%87-%e6%8a%a5%e5%91%8a%e6%96%87%e6%9c%ac%e7%9b%b8%e4%bc%bc%e5%ba%a6.png" alt=""  />
</p>
<br>
<h2 id="复现相似度">复现相似度</h2>
<p>本文只实现文本相似度的度量、文本相似度趋势的可视化。</p>
<ol>
<li>准备数据</li>
<li>相似度计算</li>
<li>可视化</li>
</ol>
<br>
<h2 id="1-准备数据">1. 准备数据</h2>
<p>首先先手动从 <strong>中国人民银行</strong> 下载货币政策报告。</p>
<p><img loading="lazy" src="img/pbc.png" alt=""  />
</p>
<p>下图是我下载好的报告</p>
<p><img loading="lazy" src="img/pdfs.png" alt=""  />
</p>
<p>之后将其整理到csv中</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">csv</span>
<span class="kn">from</span> <span class="nn">pdfdocx</span> <span class="kn">import</span> <span class="n">read_pdf</span>


<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;pbc_reports.csv&#39;</span><span class="p">,</span> <span class="s1">&#39;a+&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">,</span> <span class="n">newline</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">csvf</span><span class="p">:</span>
    <span class="c1">#年份、季度、报告文本</span>
    <span class="n">fieldnames</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;year&#39;</span><span class="p">,</span> <span class="s1">&#39;q&#39;</span><span class="p">,</span> <span class="s1">&#39;text&#39;</span><span class="p">]</span>
    <span class="n">writer</span> <span class="o">=</span> <span class="n">csv</span><span class="o">.</span><span class="n">DictWriter</span><span class="p">(</span><span class="n">csvf</span><span class="p">,</span> <span class="n">fieldnames</span><span class="o">=</span><span class="n">fieldnames</span><span class="p">)</span>
    <span class="n">writer</span><span class="o">.</span><span class="n">writeheader</span><span class="p">()</span>

    <span class="n">pdfs</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;data/</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">f</span><span class="p">)</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="s1">&#39;data&#39;</span><span class="p">)]</span>
    <span class="k">for</span> <span class="n">pf</span> <span class="ow">in</span> <span class="n">pdfs</span><span class="p">:</span>
        <span class="n">data</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s1">&#39;year&#39;</span><span class="p">:</span>  <span class="n">pf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;/&#39;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">][:</span><span class="mi">4</span><span class="p">],</span>
            <span class="s1">&#39;q&#39;</span><span class="p">:</span>  <span class="n">pf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;/&#39;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="mi">5</span><span class="p">],</span>
            <span class="s1">&#39;text&#39;</span><span class="p">:</span> <span class="n">read_pdf</span><span class="p">(</span><span class="s1">&#39;data/2013-3.pdf&#39;</span><span class="p">),</span>
        <span class="p">}</span>
        <span class="n">writer</span><span class="o">.</span><span class="n">writerow</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</code></pre></div><br>
<h2 id="2-读取数据">2. 读取数据</h2>
<p>下载pdf时，遗漏了货币政策报告日期数据，将 pbc_reports.csv 修改为 pbc_reports.xlsx ，增加了 date 字段。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_excel</span><span class="p">(</span><span class="s1">&#39;pbc_reports.xlsx&#39;</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<p><img loading="lazy" src="img/df1.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#让每一行含有前后两个季度的报告文本</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;text2&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shift</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<p><img loading="lazy" src="img/df2.png" alt=""  />
</p>
<br>
<h2 id="3-计算相似度">3. 计算相似度</h2>
<p>水平(行)方向，计算每一行中的 text 与 text2 两者的文本相似度。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>

<span class="k">def</span> <span class="nf">cosine_similarity</span><span class="p">(</span><span class="n">row</span><span class="p">):</span>
    <span class="c1">#row 为 pd.Series 类型数据，类似于字段</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">sim</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">cosine_sim</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">],</span> <span class="n">row</span><span class="p">[</span><span class="s1">&#39;text2&#39;</span><span class="p">])</span>
        <span class="k">return</span> <span class="nb">float</span><span class="p">(</span><span class="n">sim</span><span class="p">)</span>
    <span class="k">except</span><span class="p">:</span>
        <span class="c1">#异常标记为1</span>
        <span class="k">return</span> <span class="mi">1</span>

<span class="c1">#计算结果存储到 similarity 字段中</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;similarity&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">row</span><span class="p">:</span> <span class="n">cosine_similarity</span><span class="p">(</span><span class="n">row</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<p><img loading="lazy" src="img/df3.png" alt=""  />
</p>
<h2 id="4-绘制折线图">4. 绘制折线图</h2>
<p>这里为了方便，使用 pandas_bokeh 库。 注意: 绘图不限于Python，各位也可以用excel、R。</p>
<p>参数:</p>
<ul>
<li>kind 图表类型，折线图line</li>
<li>x 横轴字段</li>
<li>y 纵轴字段</li>
<li>xlabel 横轴标签</li>
<li>ylabel 纵轴标签</li>
<li>title 图标题</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas_bokeh</span>

<span class="n">pandas_bokeh</span><span class="o">.</span><span class="n">output_notebook</span><span class="p">()</span>

<span class="c1">#选择折线图line</span>
<span class="c1">#</span>
<span class="n">df</span><span class="o">.</span><span class="n">plot_bokeh</span><span class="p">(</span><span class="n">kind</span> <span class="o">=</span> <span class="s1">&#39;line&#39;</span><span class="p">,</span>
              <span class="n">x</span> <span class="o">=</span> <span class="s1">&#39;date&#39;</span><span class="p">,</span>
              <span class="n">y</span> <span class="o">=</span> <span class="s1">&#39;similarity&#39;</span><span class="p">,</span>
              <span class="n">title</span> <span class="o">=</span> <span class="s1">&#39;2001~2022央行货币政策相似度趋势&#39;</span><span class="p">,</span>
              <span class="n">xlabel</span> <span class="o">=</span> <span class="s1">&#39;报告发布日期&#39;</span><span class="p">,</span>
              <span class="n">ylabel</span> <span class="o">=</span> <span class="s1">&#39;相似度&#39;</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<p><img loading="lazy" src="img/%e5%9b%be1.png" alt=""  />
</p>
<p>刚刚生成的图没有经过移动平滑处理，所以锯齿比较多。论文中使用三季度移动平均线处理了 similarity ，我在此将其命名为 ma3_similarity</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas_bokeh</span>

<span class="n">pandas_bokeh</span><span class="o">.</span><span class="n">output_notebook</span><span class="p">()</span>

<span class="c1">#三季度移动平均线</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;ma3_similarity&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;similarity&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">rolling</span><span class="p">(</span><span class="n">window</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">center</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">min_periods</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

<span class="n">df</span><span class="o">.</span><span class="n">plot_bokeh</span><span class="p">(</span><span class="n">kind</span> <span class="o">=</span> <span class="s1">&#39;line&#39;</span><span class="p">,</span>
              <span class="n">x</span> <span class="o">=</span> <span class="s1">&#39;date&#39;</span><span class="p">,</span>
              <span class="n">y</span> <span class="o">=</span> <span class="s1">&#39;ma3_similarity&#39;</span><span class="p">,</span>
              <span class="n">title</span> <span class="o">=</span> <span class="s1">&#39;2001~2022央行货币政策相似度趋势&#39;</span><span class="p">,</span>
              <span class="n">xlabel</span> <span class="o">=</span> <span class="s1">&#39;报告发布日期&#39;</span><span class="p">,</span>
              <span class="n">ylabel</span> <span class="o">=</span> <span class="s1">&#39;相似度&#39;</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<p><img loading="lazy" src="img/%e5%9b%be2.png" alt=""  />
</p>
<p>基本复刻论文原图相似度的变化趋势</p>
<p><img loading="lazy" src="img/%e8%ae%ba%e6%96%87-%e6%8a%a5%e5%91%8a%e6%96%87%e6%9c%ac%e7%9b%b8%e4%bc%bc%e5%ba%a6.png" alt=""  />
</p>
<br>
<h2 id="代码下载">代码下载</h2>
<ul>
<li>代码及视频讲解已经添加至 <a href="https://textdata.cn/blog/management_python_course/">支持开票 | Python实证指标构建与文本分析</a>  中，感兴趣的同学欢迎订阅该系列课，涵盖Python语法入门、数据采集、文本分析、机器学习等。</li>
<li>未订阅 <a href="https://textdata.cn/blog/management_python_course/">支持开票 | Python实证指标构建与文本分析</a> 的朋友们，可转发本文集赞30+， 加微信 <strong>372335839</strong> ， 备注「<strong>姓名-学校-专业-央行相似度</strong>」，获取本文数据及代码。</li>
</ul>
<br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>中国工业经济 | MD&amp;A信息含量指标构建代码实现</title>
      <link>https://textdata.cn/blog/2023-01-06-mda_informative_content/</link>
      <pubDate>Fri, 06 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-01-06-mda_informative_content/</guid>
      <description>每个上市公司 MD&amp;amp;A 信息不可避免地在某种程度上与同行业其他上市公司以及市场其他行业上市公司存在一定的相似性， 甚至某些公司可能直接参考其他公司 MD&amp;amp;A 的表述。 可以将与行业其他公司或其他行业的公司重复或相似的信息定义为不具有信息含量的内容，同时将不同的信息定义为真正具有信息含量的内容，简称为信息含量。In this paper ， we discuss the impact of informative content of Management Discussion and Analysis （ MD&amp;amp;A ） on stock price crash risk using the method of text vectorization. Using the MD&amp;amp;A in annual reports of China A -share listed firms from 2007 to 2015 ， we find that the informative content of MD&amp;amp;A can reduce future stock price crash risk ， and the informative content of preview section has significant effects on stock price crash risk ， while that of review section does not. After controlling endogeneity ， the conclusions still stand. Further ， we study the influence of informative content of preview section on crash risk from the aspects of readability and information opaqueness. The results show that the higher readability and higher information opaqueness ， the greater impact of informative content has on stock price crash risk. Finally ， after changing the calculation of crash risk ， and controlling the impact of stock price synchronicity ， the informative content of preview section still reduces stock price crash risk. This paper enriches the influencing factors of stock price crash risk and improves the study of the usefulness of MD&amp;amp;A from the perspective of incremental information ， which has important theoretical and practical significance.</description>
      <content:encoded><![CDATA[<h2 id="信息含量">信息含量</h2>
<p>由于每个公司的 MD&amp;A 中不仅包括公司经营状况等历史信息， 也包括与其他公司相似的信息， 如外部环境、市场格局、风险因素等内容。 因此， 本文参考 Hanley and Hoberg （ 2010 ）， 从行业和市场两个维度来考察和定义公司 MD&amp;A 中的信息含量。</p>
<ul>
<li><strong>市场因素</strong>， 所有上市公司都处于相同的宏观经济环境、风险因素和政治、政策背景之下；</li>
<li><strong>行业因素</strong>， 同一行业中的各上市公司又面临着相似的产业政策、竞争环境和市场特征。</li>
</ul>
<p>由此可见， 每个上市公司 MD&amp;A 信息不可避免地在某种程度上与同行业其他上市公司以及市场其他行业上市公司存在一定的相似性， 甚至某些公司可能直接参考其他公司 MD&amp;A 的表述。 <strong>可以将与行业其他公司或其他行业的公司重复或相似的信息定义为不具有信息含量的内容，同时将不同的信息定义为真正具有信息含量的内容，简称为信息含量</strong>。</p>
<br>
<blockquote>
<p>孟庆斌, 杨俊华, and 鲁冰. &ldquo;管理层讨论与分析披露的信息含量与股价崩盘风险——基于文本向量化方法的研究.&rdquo; 中国工业经济 12 (2017): 132-150.</p>
</blockquote>
<br>
<h3 id="摘要">摘要</h3>
<p>本文采用文本向量化的方法， 对 2007—2015 年中国 A 股上市公司年报的管理层讨论与分析（MD&amp;A）所披露的信息含量加以度量， 研究其对股价崩盘风险的影响。 研究发现， MD&amp;A 的信息含量越高，未来股价崩盘风险越低。 将 MD&amp;A 进一步划分为回顾部分和展望部分后发现，仅有展望部分中的信息含量能够显著降低未来股价崩盘风险。 在控制内生性问题之后，本文的结论依然成立。 本文还分别从文本可读性和信息不对称的角度出发，研究它们对二者关系的影响。 结果表明，信息的可读性越高，信息不对称程度越高，展望部分的信息含量对股价崩盘风险的降低作用越大。 在重新定义股价崩盘风险的计算区间以及控制股价同步性之后， MD&amp;A 展望部分的信息含量依然能够显著降低股价崩盘风险， 表明本文的结论是稳健的。 本文从文本信息的角度丰富了股价崩盘风险影响因素的研究， 同时也从增量信息的角度完善了 MD&amp;A 信息有用性的研究，具有重要的理论和现实意义。</p>
<br>
<h3 id="样本选择和处理">样本选择和处理</h3>
<p>本文选取 2007 — 2015 年中国上市公司年报中的 MD&amp;A 信息作为研究样本。 之所以选取 2007 年作为样本的起点， 是因为从 2007 年开始， MD&amp;A 在企业定期报告中的披露要求已经较为完善， 而且 2007 年是中国会计准则国际趋同的重要时点， 新制定的《企业会计准则》已经开始实施， 为避免前后会计准则差异而产生的影响， 因此选取 2007 年作为样本区间的起点。</p>
<p>本文所使用的上市公司年度报告均来自于巨潮资讯网。 数据处理过程如下：</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">（ 1 ）剔除金融行业、 ST 和 *ST 类企业， 以及上市时间不足一年的企业。

（ 2 ）从 MD&amp;A 的内容中分别提取回顾和展望部分， 保存为回顾信息文件和展望信息文件， 部分无法抓取出的年报通过手工收集处理。

（ 3 ）文本处理-文本向量化。 借鉴 Hanley and Hoberg （ 2010 ）的研究思路， 将每个 MD&amp;A 文本通过向量的 形式表示出来， 其每个元素为文本中的每个词语出现的频率。 例如， 假设某 MD&amp;A 文本中包含 10000 个词， 则该文本对应一个 10000×1 维的向量。 举一个简单的例子来描述文本向量化的过程： 在两个简化的 MD&amp;A 文本中， 一个包含“我们生产土豆和生产玉米”， 另一个包含“我们生产家具”， 剔除连词“和”、代词“我们”之后， 只剩下“生产”、“土豆”、“玉米”、“家具”这 4 个词。 那么， 在第一个 MD&amp;A 文本中， “生产”、“土豆”和“玉米”分别出现了 2 次、 1 次和 1 次， 而“家具”出现 0 次， 所以该 文本的向量为 {2 ， 1 ， 1 ， 0} ， 同样得到第二个文本的向量为 {1 ， 0 ， 0 ， 1} 。

（ 4 ）向量标准化。 对于向量化的文本， 仍需解决文本长度不同导致的结果不可比问题。 一般来说， 某一个词在长文本中重复出现的次数较多， 在短文本中重复出现的次数较少， 但并不能因此说 长文本比短文本的信息量大。 为此， 本文进一步将这些向量进行标准化处理， 即将该向量除以文本 中单词的总数， 得到标准化后的向量。 在上面的例子中， 两个公司的标准化之后的向量就成为了 {0.50 ， 0.25 ， 0.25 ， 0} 和 {0.50 ， 0 ， 0 ， 0.50} 。
</code></pre></div><br>
<h3 id="文件目录">文件目录</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">管理层讨论信息含量/
├── 信息含量计算代码.ipynb
├── data/
│   ├── 行业代码.xlsx
│   └── mda10-20.xlsx
├── mda_infor.csv
├── output/
│   └── 2020/
│       ├── 000002.csv
│       ├── 000004.csv
│       ├── 000005.csv
│       ├── 000006.csv
│       ├── ...
│   └── 2019/
│       ├── 000002.csv
│       ├── 000004.csv
│       ├── 000005.csv
│       ├── 000006.csv
│       ├── ...
│   └── 2018/
│       ├── 000002.csv
│       ├── 000004.csv
│       ├── 000005.csv
│       ├── 000006.csv
│       ├── 000006.csv
│       ├── ...
│   └── ...
</code></pre></div><p><br><br></p>
<h2 id="一导入数据">一、导入数据</h2>
<p>这里准备了2010-2020年A股经营讨论与分析内容和行业代码数据。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="c1"># converters 强制声明该列为字符串，  防止股票代码 被程序识别为数字，</span>
<span class="c1"># 完整数据370+M </span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_excel</span><span class="p">(</span><span class="s1">&#39;data/mda10-20.xlsx&#39;</span><span class="p">,</span> <span class="n">converters</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;股票代码&#39;</span><span class="p">:</span> <span class="nb">str</span><span class="p">})</span>

<span class="c1">#上市公司行业信息</span>
<span class="n">ind_info_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_excel</span><span class="p">(</span><span class="s1">&#39;data/行业代码.xlsx&#39;</span><span class="p">,</span> <span class="n">converters</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;股票代码&#39;</span><span class="p">:</span> <span class="nb">str</span><span class="p">})</span>


<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">ind_info_df</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;股票代码&#39;</span><span class="p">,</span> <span class="s1">&#39;会计年度&#39;</span><span class="p">],</span> <span class="n">how</span><span class="o">=</span><span class="s1">&#39;inner&#39;</span><span class="p">)</span>

<span class="c1">#显示前5行</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<p><img loading="lazy" src="img/df1.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1"># 剔除金融行业处理</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="o">~</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;行业代码&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="s2">&#34;J&#34;</span><span class="p">)]</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="o">~</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;公司简称&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="s2">&#34;ST&#34;</span><span class="p">)]</span>

<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<p><img loading="lazy" src="img/df2.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="二以2020年为例">二、以2020年为例</h2>
<p>写代码先局部后整体，以2020年为例，如果2020年可以成功计算出信息含量，则可以for循环推广到所有股票所有年份。本章节需要做</p>
<ol>
<li>选定某年份，以2020年为例</li>
<li>定义transform函数，用于处理「经营讨论与分析内容」字段内的内容。</li>
<li>文本向量化，向量标准化。</li>
</ol>
<br>
<h3 id="21-选定2020年">2.1 选定2020年</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df_per_year</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;会计年度&#39;</span><span class="p">]</span><span class="o">==</span><span class="mi">2020</span><span class="p">]</span>
<span class="n">df_per_year</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">df_per_year</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<p><img loading="lazy" src="img/df3.png" alt=""  />
</p>
<br>
<h3 id="22-定义transform函数">2.2 定义transform函数</h3>
<p>定义transform函数，该函数可以处理「经营讨论与分析内容」字段内容，使其:</p>
<ol>
<li>只保留中文内容</li>
<li>剔除停用词</li>
<li>整理为用空格间隔的字符串(类西方语言文本格式)</li>
</ol>
<p>之后应用 <strong>transform函数</strong>， 使用<strong>apply方法</strong>， 处理 <strong>df_per_year[&lsquo;经营讨论与分析内容&rsquo;]</strong> 。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>
<span class="kn">import</span> <span class="nn">jieba</span>
<span class="kn">import</span> <span class="nn">re</span>

<span class="n">stopwords</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">load_pkl_dict</span><span class="p">(</span><span class="s1">&#39;STOPWORDS.pkl&#39;</span><span class="p">)[</span><span class="s1">&#39;STOPWORDS&#39;</span><span class="p">][</span><span class="s1">&#39;chinese&#39;</span><span class="p">]</span>

<span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="c1">#只保留md&amp;a中的中文内容</span>
    <span class="n">text</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">re</span><span class="o">.</span><span class="n">findall</span><span class="p">(</span><span class="s1">&#39;[</span><span class="se">\u4e00</span><span class="s1">-</span><span class="se">\u9fa5</span><span class="s1">]+&#39;</span><span class="p">,</span> <span class="n">text</span><span class="p">))</span>
    <span class="c1">#剔除停用词</span>
    <span class="n">words</span> <span class="o">=</span> <span class="p">[</span><span class="n">w</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">jieba</span><span class="o">.</span><span class="n">cut</span><span class="p">(</span><span class="n">text</span><span class="p">)</span> <span class="k">if</span> <span class="n">w</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">stopwords</span><span class="p">]</span>
    <span class="c1">#整理为用空格间隔的字符串(类西方语言文本格式)</span>
    <span class="k">return</span> <span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">words</span><span class="p">)</span>


<span class="n">df_per_year</span><span class="p">[</span><span class="s1">&#39;clean_text&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_per_year</span><span class="p">[</span><span class="s1">&#39;经营讨论与分析内容&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">transform</span><span class="p">)</span>
</code></pre></div><pre><code>Building prefix dict from the default dictionary ...
Loading model from cache /var/folders/sc/3mnt5tgs419_hk7s16gq61p80000gn/T/jieba.cache
Loading model cost 0.556 seconds.
Prefix dict has been built successfully.
</code></pre>
<br>
<h3 id="23-文本向量化">2.3 文本向量化</h3>
<p>本小节要做:</p>
<ol>
<li>文本向量化</li>
<li>向量标准化</li>
<li>合并多个字段为新的df</li>
</ol>
<p>先将df_per_year[&lsquo;clean_text&rsquo;] 向量化，代码如下</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">CountVectorizer</span>

<span class="n">cv</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">(</span><span class="n">min_df</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span> <span class="n">max_df</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span> 
<span class="c1"># 生成稀疏bow矩阵</span>
<span class="n">dtm_per_year</span> <span class="o">=</span> <span class="n">cv</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df_per_year</span><span class="p">[</span><span class="s1">&#39;clean_text&#39;</span><span class="p">])</span> 
<span class="n">dtm_per_year</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">dtm_per_year</span><span class="o">.</span><span class="n">toarray</span><span class="p">())</span>
<span class="n">dtm_per_year</span>
</code></pre></div><p>Run</p>
<p><img loading="lazy" src="img/df4.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="c1">#向量标准化</span>
<span class="n">dtm_per_year</span> <span class="o">=</span> <span class="n">dtm_per_year</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">row</span><span class="p">:</span> <span class="n">row</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">row</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">dtm_per_year</span>
</code></pre></div><p>Run</p>
<p><img loading="lazy" src="img/df5.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#合并多个字段为新的df</span>
<span class="n">dtm_per_year</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">df_per_year</span><span class="p">[[</span><span class="s1">&#39;股票代码&#39;</span><span class="p">,</span> <span class="s1">&#39;会计年度&#39;</span><span class="p">,</span> <span class="s1">&#39;行业代码&#39;</span><span class="p">]],</span> <span class="n">dtm_per_year</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">dtm_per_year</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<p><img loading="lazy" src="img/df6.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="三计算2020年行业向量市场向量">三、计算2020年行业向量、市场向量</h2>
<p>计算2020年所有公司的市场向量、行业向量。这里</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dtm_per_year</span><span class="p">)):</span>
    <span class="n">code</span> <span class="o">=</span> <span class="n">dtm_per_year</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="s1">&#39;股票代码&#39;</span><span class="p">]</span>
    <span class="n">ind</span> <span class="o">=</span> <span class="n">dtm_per_year</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="s1">&#39;行业代码&#39;</span><span class="p">]</span>
    <span class="n">year</span> <span class="o">=</span> <span class="n">dtm_per_year</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="s1">&#39;会计年度&#39;</span><span class="p">]</span>
    
    <span class="n">ind_freq</span> <span class="o">=</span> <span class="n">dtm_per_year</span><span class="p">[</span><span class="n">dtm_per_year</span><span class="p">[</span><span class="s1">&#39;行业代码&#39;</span><span class="p">]</span><span class="o">==</span><span class="n">ind</span><span class="p">][</span><span class="n">dtm_per_year</span><span class="p">[</span><span class="s1">&#39;股票代码&#39;</span><span class="p">]</span><span class="o">!=</span><span class="n">code</span><span class="p">]</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">3</span><span class="p">:]</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">market_freq</span> <span class="o">=</span> <span class="n">dtm_per_year</span><span class="p">[</span><span class="n">dtm_per_year</span><span class="p">[</span><span class="s1">&#39;行业代码&#39;</span><span class="p">]</span><span class="o">!=</span><span class="n">ind</span><span class="p">]</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">3</span><span class="p">:]</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    
    <span class="n">dtm_per_year_melted</span> <span class="o">=</span> <span class="n">dtm_per_year</span><span class="o">.</span><span class="n">melt</span><span class="p">(</span><span class="n">id_vars</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;股票代码&#39;</span><span class="p">,</span> <span class="s1">&#39;会计年度&#39;</span><span class="p">,</span> <span class="s1">&#39;行业代码&#39;</span><span class="p">],</span>
                                            <span class="n">var_name</span><span class="o">=</span><span class="s1">&#39;word_id&#39;</span><span class="p">,</span> 
                                            <span class="n">value_name</span><span class="o">=</span><span class="s1">&#39;word_freq&#39;</span><span class="p">)</span>
    <span class="n">corporate_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;word_id&#39;</span><span class="p">:</span> <span class="n">dtm_per_year_melted</span><span class="p">[</span><span class="n">dtm_per_year_melted</span><span class="p">[</span><span class="s1">&#39;股票代码&#39;</span><span class="p">]</span><span class="o">==</span><span class="n">code</span><span class="p">][</span><span class="s1">&#39;word_id&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span>
                                 <span class="s1">&#39;word_freq&#39;</span><span class="p">:</span> <span class="n">dtm_per_year_melted</span><span class="p">[</span><span class="n">dtm_per_year_melted</span><span class="p">[</span><span class="s1">&#39;股票代码&#39;</span><span class="p">]</span><span class="o">==</span><span class="n">code</span><span class="p">][</span><span class="s1">&#39;word_freq&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span>
                                 <span class="s1">&#39;ind_freq&#39;</span><span class="p">:</span> <span class="n">ind_freq</span><span class="p">,</span>
                                 <span class="s1">&#39;market_freq&#39;</span><span class="p">:</span><span class="n">market_freq</span><span class="p">})</span>
    <span class="n">corporate_df</span><span class="p">[</span><span class="s1">&#39;股票代码&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">code</span>
    <span class="n">corporate_df</span><span class="p">[</span><span class="s1">&#39;行业代码&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">ind</span>
    <span class="n">corporate_df</span><span class="p">[</span><span class="s1">&#39;会计年度&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">year</span>
    <span class="n">corporate_df</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">corporate_df</span> <span class="o">=</span> <span class="n">corporate_df</span><span class="p">[[</span><span class="s1">&#39;股票代码&#39;</span><span class="p">,</span> <span class="s1">&#39;行业代码&#39;</span><span class="p">,</span> <span class="s1">&#39;会计年度&#39;</span><span class="p">,</span> <span class="s1">&#39;word_id&#39;</span><span class="p">,</span> <span class="s1">&#39;word_freq&#39;</span><span class="p">,</span> <span class="s1">&#39;ind_freq&#39;</span><span class="p">,</span> <span class="s1">&#39;market_freq&#39;</span><span class="p">]]</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="s1">&#39;output/</span><span class="si">{year}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">year</span><span class="o">=</span><span class="n">year</span><span class="p">)):</span>
        <span class="n">os</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="s1">&#39;output/</span><span class="si">{year}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">year</span><span class="o">=</span><span class="n">year</span><span class="p">))</span>
    <span class="n">corporate_df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;output/</span><span class="si">{year}</span><span class="s1">/</span><span class="si">{code}</span><span class="s1">.csv&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">year</span><span class="o">=</span><span class="n">year</span><span class="p">,</span> <span class="n">code</span><span class="o">=</span><span class="n">code</span><span class="p">),</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</code></pre></div><p><br><br></p>
<h2 id="四计算2010-2020年所有公司行业向量市场向量">四、计算2010-2020年所有公司行业向量、市场向量</h2>
<p>信息含量的定义。 由于每个公司的 MD&amp;A 中不仅包括公司经营状况等历史信息， 也包括与其他公司相似的信息， 如外部环境、市场格局、风险因素等内容。 因此， 本文参考 Hanley and Hoberg （ 2010 ）， 从行业和市场两个维度来考察和定义公司 MD&amp;A 中的信息含量。</p>
<ul>
<li><strong>市场因素</strong>， 所有上市公司都处于相同的宏观经济环境、风险因素和政治、政策背景之下；</li>
<li><strong>行业因素</strong>， 同一行业中的各上市公司又面临着相似的产业政策、竞争环境和市场特征。</li>
</ul>
<p>由此可见， 每个上市公司 MD&amp;A 信息不可避免地在某种程度上与同行业其他上市公司以及市场其他行业上市公司存在一定的相似性， 甚至某些公司可能直接参考其他公司 MD&amp;A 的表述。</p>
<p><img loading="lazy" src="img/norm_ind_market.png" alt=""  />
</p>
<p>参考文中截图行业向量、市场向量计算方法，有如下代码。<strong>该部分代码运行较慢，全部运行下来大约10小时。</strong></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">CountVectorizer</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>
<span class="kn">import</span> <span class="nn">jieba</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">re</span>

<span class="n">stopwords</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">load_pkl_dict</span><span class="p">(</span><span class="s1">&#39;STOPWORDS.pkl&#39;</span><span class="p">)[</span><span class="s1">&#39;STOPWORDS&#39;</span><span class="p">][</span><span class="s1">&#39;chinese&#39;</span><span class="p">]</span>

<span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="c1">#只保留md&amp;a中的中文内容</span>
    <span class="n">text</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">re</span><span class="o">.</span><span class="n">findall</span><span class="p">(</span><span class="s1">&#39;[</span><span class="se">\u4e00</span><span class="s1">-</span><span class="se">\u9fa5</span><span class="s1">]+&#39;</span><span class="p">,</span> <span class="n">text</span><span class="p">))</span>
    <span class="c1">#剔除停用词</span>
    <span class="n">words</span> <span class="o">=</span> <span class="p">[</span><span class="n">w</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">jieba</span><span class="o">.</span><span class="n">cut</span><span class="p">(</span><span class="n">text</span><span class="p">)</span> <span class="k">if</span> <span class="n">w</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">stopwords</span><span class="p">]</span>
    <span class="c1">#整理为用空格间隔的字符串(类西方语言文本格式)</span>
    <span class="k">return</span> <span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">words</span><span class="p">)</span>


<span class="c1"># converters 强制声明该列为字符串，  防止股票代码 被程序识别为数字，</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_excel</span><span class="p">(</span><span class="s1">&#39;data/mda10-20.xlsx&#39;</span><span class="p">,</span> <span class="n">converters</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;股票代码&#39;</span><span class="p">:</span> <span class="nb">str</span><span class="p">})</span>
<span class="c1">#上市公司行业信息</span>
<span class="n">ind_info_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_excel</span><span class="p">(</span><span class="s1">&#39;data/行业代码.xlsx&#39;</span><span class="p">,</span> <span class="n">converters</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;股票代码&#39;</span><span class="p">:</span> <span class="nb">str</span><span class="p">})</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">ind_info_df</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;股票代码&#39;</span><span class="p">,</span> <span class="s1">&#39;会计年度&#39;</span><span class="p">],</span> <span class="n">how</span><span class="o">=</span><span class="s1">&#39;inner&#39;</span><span class="p">)</span>

<span class="c1"># 剔除金融行业处理</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="o">~</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;行业代码&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="s2">&#34;J&#34;</span><span class="p">)]</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="o">~</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;公司简称&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="s2">&#34;ST&#34;</span><span class="p">)]</span>

<span class="k">for</span> <span class="n">year</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">2010</span><span class="p">,</span> <span class="mi">2011</span><span class="p">,</span> <span class="mi">2012</span><span class="p">,</span> <span class="mi">2013</span><span class="p">]:</span>
<span class="c1">#for year in set(df[&#39;会计年度&#39;].values):</span>
    <span class="n">df_per_year</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;会计年度&#39;</span><span class="p">]</span><span class="o">==</span><span class="n">year</span><span class="p">]</span>
    <span class="n">df_per_year</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">df_per_year</span><span class="p">[</span><span class="s1">&#39;clean_text&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_per_year</span><span class="p">[</span><span class="s1">&#39;经营讨论与分析内容&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">transform</span><span class="p">)</span>
    

    <span class="n">cv</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">(</span><span class="n">min_df</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span> <span class="n">max_df</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span> 
    <span class="c1"># 生成稀疏bow矩阵</span>
    <span class="n">dtm_per_year</span> <span class="o">=</span> <span class="n">cv</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df_per_year</span><span class="p">[</span><span class="s1">&#39;clean_text&#39;</span><span class="p">])</span> 
    <span class="n">dtm_per_year</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">dtm_per_year</span><span class="o">.</span><span class="n">toarray</span><span class="p">())</span>
    <span class="n">dtm_per_year</span> <span class="o">=</span> <span class="n">dtm_per_year</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">row</span><span class="p">:</span> <span class="n">row</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">row</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    
    <span class="n">dtm_per_year</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">df_per_year</span><span class="p">[[</span><span class="s1">&#39;股票代码&#39;</span><span class="p">,</span> <span class="s1">&#39;会计年度&#39;</span><span class="p">,</span> <span class="s1">&#39;行业代码&#39;</span><span class="p">]],</span> <span class="n">dtm_per_year</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    
    <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dtm_per_year</span><span class="p">)):</span>
        <span class="n">code</span> <span class="o">=</span> <span class="n">dtm_per_year</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="s1">&#39;股票代码&#39;</span><span class="p">]</span>
        <span class="n">ind</span> <span class="o">=</span> <span class="n">dtm_per_year</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="s1">&#39;行业代码&#39;</span><span class="p">]</span>
        <span class="n">year</span> <span class="o">=</span> <span class="n">dtm_per_year</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="s1">&#39;会计年度&#39;</span><span class="p">]</span>



        <span class="n">ind_freq</span> <span class="o">=</span> <span class="n">dtm_per_year</span><span class="p">[</span><span class="n">dtm_per_year</span><span class="p">[</span><span class="s1">&#39;行业代码&#39;</span><span class="p">]</span><span class="o">==</span><span class="n">ind</span><span class="p">][</span><span class="n">dtm_per_year</span><span class="p">[</span><span class="s1">&#39;股票代码&#39;</span><span class="p">]</span><span class="o">!=</span><span class="n">code</span><span class="p">]</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">3</span><span class="p">:]</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">market_freq</span> <span class="o">=</span> <span class="n">dtm_per_year</span><span class="p">[</span><span class="n">dtm_per_year</span><span class="p">[</span><span class="s1">&#39;行业代码&#39;</span><span class="p">]</span><span class="o">!=</span><span class="n">ind</span><span class="p">]</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">3</span><span class="p">:]</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        
        <span class="n">dtm_per_year_melted</span> <span class="o">=</span> <span class="n">dtm_per_year</span><span class="o">.</span><span class="n">melt</span><span class="p">(</span><span class="n">id_vars</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;股票代码&#39;</span><span class="p">,</span> <span class="s1">&#39;会计年度&#39;</span><span class="p">,</span> <span class="s1">&#39;行业代码&#39;</span><span class="p">],</span>
                                                <span class="n">var_name</span><span class="o">=</span><span class="s1">&#39;word_id&#39;</span><span class="p">,</span> 
                                                <span class="n">value_name</span><span class="o">=</span><span class="s1">&#39;word_freq&#39;</span><span class="p">)</span>
        <span class="n">corporate_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span> <span class="s1">&#39;word_id&#39;</span><span class="p">:</span> <span class="n">dtm_per_year_melted</span><span class="p">[</span><span class="n">dtm_per_year_melted</span><span class="p">[</span><span class="s1">&#39;股票代码&#39;</span><span class="p">]</span><span class="o">==</span><span class="n">code</span><span class="p">][</span><span class="s1">&#39;word_id&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span>
                                       <span class="s1">&#39;word_freq&#39;</span><span class="p">:</span> <span class="n">dtm_per_year_melted</span><span class="p">[</span><span class="n">dtm_per_year_melted</span><span class="p">[</span><span class="s1">&#39;股票代码&#39;</span><span class="p">]</span><span class="o">==</span><span class="n">code</span><span class="p">][</span><span class="s1">&#39;word_freq&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span>
                                       <span class="s1">&#39;ind_freq&#39;</span><span class="p">:</span> <span class="n">ind_freq</span><span class="p">,</span>
                                       <span class="s1">&#39;market_freq&#39;</span><span class="p">:</span><span class="n">market_freq</span><span class="p">})</span>
        <span class="n">corporate_df</span><span class="p">[</span><span class="s1">&#39;股票代码&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">code</span>
        <span class="n">corporate_df</span><span class="p">[</span><span class="s1">&#39;行业代码&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">ind</span>
        <span class="n">corporate_df</span><span class="p">[</span><span class="s1">&#39;会计年度&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">year</span>
        <span class="n">corporate_df</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">corporate_df</span> <span class="o">=</span> <span class="n">corporate_df</span><span class="p">[[</span><span class="s1">&#39;股票代码&#39;</span><span class="p">,</span> <span class="s1">&#39;行业代码&#39;</span><span class="p">,</span> <span class="s1">&#39;会计年度&#39;</span><span class="p">,</span> <span class="s1">&#39;word_id&#39;</span><span class="p">,</span> <span class="s1">&#39;word_freq&#39;</span><span class="p">,</span> <span class="s1">&#39;ind_freq&#39;</span><span class="p">,</span> <span class="s1">&#39;market_freq&#39;</span><span class="p">]]</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="s1">&#39;output/</span><span class="si">{year}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">year</span><span class="o">=</span><span class="n">year</span><span class="p">)):</span>
            <span class="n">os</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="s1">&#39;output/</span><span class="si">{year}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">year</span><span class="o">=</span><span class="n">year</span><span class="p">))</span>
        <span class="n">corporate_df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;output/</span><span class="si">{year}</span><span class="s1">/</span><span class="si">{code}</span><span class="s1">.csv&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">year</span><span class="o">=</span><span class="n">year</span><span class="p">,</span> <span class="n">code</span><span class="o">=</span><span class="n">code</span><span class="p">),</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</code></pre></div><p><br><br></p>
<h2 id="五标准信息信息含量">五、标准信息、信息含量</h2>
<p>以2020年000002为例，计算其标准信息、信息含量。计算成功后，再计算所有年份所有上市公司 md&amp;a的标准信息、信息含量。</p>
<p><strong>原文除了计算md&amp;a，还将md&amp;a区分为回顾过去、展望未来两部分，并分别计算了对应的标准信息、信息含量。这里只计算md&amp;a的标准信息、信息含量。</strong></p>
<p><img loading="lazy" src="img/infor_pre.png" alt=""  />
</p>
<p>这里使用Python的统计模型statsmodels库OLS来计算标准信息和信息含量。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">csv_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;output/2020/000002.csv&#39;</span><span class="p">,</span>  <span class="n">converters</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;股票代码&#39;</span><span class="p">:</span> <span class="nb">str</span><span class="p">})</span>
<span class="n">csv_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<p><img loading="lazy" src="img/df7.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#更改字段名</span>
<span class="n">csv_df</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;股票代码&#39;</span><span class="p">,</span> <span class="s1">&#39;行业代码&#39;</span><span class="p">,</span> <span class="s1">&#39;会计年度&#39;</span><span class="p">,</span> <span class="s1">&#39;word_id&#39;</span><span class="p">,</span> <span class="s1">&#39;Norm&#39;</span><span class="p">,</span> <span class="s1">&#39;Norm_Ind&#39;</span><span class="p">,</span> <span class="s1">&#39;Norm_Market&#39;</span><span class="p">]</span>
<span class="n">csv_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p>Run
<img loading="lazy" src="img/df8.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">statsmodels.formula.api</span> <span class="k">as</span> <span class="nn">smf</span>

<span class="c1">#因变量Norm</span>
<span class="c1">#解释变量Norm_Ind、 Norm_Market</span>
<span class="n">formula</span> <span class="o">=</span> <span class="s1">&#39;Norm ~ Norm_Ind + Norm_Market&#39;</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="n">formula</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">csv_df</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">
                                OLS Regression Results                            
    ==============================================================================
    Dep. Variable:                   Norm   R-squared:                       0.319
    Model:                            OLS   Adj. R-squared:                  0.318
    Method:                 Least Squares   F-statistic:                     763.9
    Date:                Fri, 06 Jan 2023   Prob (F-statistic):          6.88e-273
    Time:                        06:37:27   Log-Likelihood:                 17334.
    No. Observations:                3269   AIC:                        -3.466e+04
    Df Residuals:                    3266   BIC:                        -3.464e+04
    Df Model:                           2                                         
    Covariance Type:            nonrobust                                         
    ===============================================================================
                      coef    std err          t      P&gt;|t|      [0.025      0.975]
    -------------------------------------------------------------------------------
    Intercept    1.164e-05   2.86e-05      0.407      0.684   -4.44e-05    6.77e-05
    Norm_Ind        0.7486      0.020     37.460      0.000       0.709       0.788
    Norm_Market     0.2133      0.064      3.327      0.001       0.088       0.339
    ==============================================================================
    Omnibus:                     4804.262   Durbin-Watson:                   2.026
    Prob(Omnibus):                  0.000   Jarque-Bera (JB):          4165802.983
    Skew:                           8.425   Prob(JB):                         0.00
    Kurtosis:                     177.069   Cond. No.                     3.05e+03
    ==============================================================================
    
    Notes:
    [1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
    [2] The condition number is large, 3.05e+03. This might indicate that there are
    strong multicollinearity or other numerical problems.
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#标准信息</span>
<span class="n">standard_info</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">Norm_Ind</span> <span class="o">+</span> <span class="n">result</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">Norm_Market</span>


<span class="c1">#信息含量</span>
<span class="n">informative_content</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="nb">abs</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">resid</span><span class="p">))</span>


<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;000002标准信息: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">standard_info</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;000002信息含量: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">informative_content</span><span class="p">))</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">    000002标准信息: 0.9619640977801796
    000002信息含量: 1.2750713760886476
</code></pre></div><br>
<p>既然能成功计算某年某公司的标准信息、信息含量，现在推广到所有年份所有公司，计算结果存储为一个csv文件。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">csv</span>
<span class="kn">import</span> <span class="nn">statsmodels.formula.api</span> <span class="k">as</span> <span class="nn">smf</span>
<span class="kn">import</span> <span class="nn">re</span>

<span class="c1">#结果存储到mda_infor.csv</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;mda_infor.csv&#39;</span><span class="p">,</span> <span class="s1">&#39;a+&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">,</span> <span class="n">newline</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">csvf</span><span class="p">:</span>
    <span class="n">fieldnames</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;股票代码&#39;</span><span class="p">,</span> <span class="s1">&#39;会计年度&#39;</span><span class="p">,</span> <span class="s1">&#39;标准信息&#39;</span><span class="p">,</span> <span class="s1">&#39;信息含量&#39;</span><span class="p">]</span>
    <span class="n">writer</span> <span class="o">=</span> <span class="n">csv</span><span class="o">.</span><span class="n">DictWriter</span><span class="p">(</span><span class="n">csvf</span><span class="p">,</span> <span class="n">fieldnames</span><span class="o">=</span><span class="n">fieldnames</span><span class="p">)</span>
    <span class="n">writer</span><span class="o">.</span><span class="n">writeheader</span><span class="p">()</span>
    
    <span class="n">year_dirs</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="s1">&#39;output&#39;</span><span class="p">)</span>
    <span class="n">year_dirs</span> <span class="o">=</span> <span class="p">[</span><span class="n">y</span> <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">year_dirs</span> <span class="k">if</span> <span class="s1">&#39;DS&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">y</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">year_dir</span> <span class="ow">in</span> <span class="n">year_dirs</span><span class="p">:</span>
        <span class="n">code_csvfs</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;output/</span><span class="si">{year}</span><span class="s1">/</span><span class="si">{csvf}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">year</span><span class="o">=</span><span class="n">year_dir</span><span class="p">,</span> <span class="n">csvf</span><span class="o">=</span><span class="n">f</span><span class="p">)</span> 
                      <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="s1">&#39;output/</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">year_dir</span><span class="p">))]</span>
        <span class="n">code_csvfs</span> <span class="o">=</span> <span class="p">[</span><span class="n">f</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">code_csvfs</span> <span class="k">if</span> <span class="s1">&#39;DS&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">f</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">csvf</span> <span class="ow">in</span> <span class="n">code_csvfs</span><span class="p">:</span> 
            <span class="k">try</span><span class="p">:</span>
                <span class="n">csv_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">csvf</span><span class="p">,</span>  <span class="n">converters</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;股票代码&#39;</span><span class="p">:</span> <span class="nb">str</span><span class="p">})</span>
                <span class="n">csv_df</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;股票代码&#39;</span><span class="p">,</span> <span class="s1">&#39;行业代码&#39;</span><span class="p">,</span> <span class="s1">&#39;会计年度&#39;</span><span class="p">,</span> <span class="s1">&#39;word_id&#39;</span><span class="p">,</span> <span class="s1">&#39;Norm&#39;</span><span class="p">,</span> <span class="s1">&#39;Norm_Ind&#39;</span><span class="p">,</span> <span class="s1">&#39;Norm_Market&#39;</span><span class="p">]</span>
                <span class="n">formula</span> <span class="o">=</span> <span class="s1">&#39;Norm ~ Norm_Ind + Norm_Market&#39;</span>
                <span class="n">model</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="n">formula</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">csv_df</span><span class="p">)</span>
                <span class="n">result</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>

                <span class="c1">#标准信息</span>
                <span class="n">standard_info</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">Norm_Ind</span> <span class="o">+</span> <span class="n">result</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">Norm_Market</span>
                <span class="c1">#信息含量</span>
                <span class="n">informative_content</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="nb">abs</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">resid</span><span class="p">))</span>

                <span class="n">data</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;股票代码&#39;</span><span class="p">:</span> <span class="n">re</span><span class="o">.</span><span class="n">findall</span><span class="p">(</span><span class="s1">&#39;\d</span><span class="si">{6}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">csvf</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span> 
                        <span class="s1">&#39;会计年度&#39;</span><span class="p">:</span> <span class="n">re</span><span class="o">.</span><span class="n">findall</span><span class="p">(</span><span class="s1">&#39;\d</span><span class="si">{4}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">csvf</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span> 
                        <span class="s1">&#39;标准信息&#39;</span><span class="p">:</span> <span class="n">standard_info</span><span class="p">,</span> 
                        <span class="s1">&#39;信息含量&#39;</span><span class="p">:</span> <span class="n">informative_content</span><span class="p">}</span>
                <span class="n">writer</span><span class="o">.</span><span class="n">writerow</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
            <span class="k">except</span><span class="p">:</span>
                <span class="k">pass</span>
</code></pre></div><p><br><br></p>
<h2 id="最后">最后</h2>
<p>读取生成的 &lsquo;mda_infor.csv&rsquo; 文件，欣赏一下 <code>标准信息、信息含量</code></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;mda_infor.csv&#39;</span><span class="p">,</span> <span class="n">converters</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;股票代码&#39;</span><span class="p">:</span> <span class="nb">str</span><span class="p">})</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<p><img loading="lazy" src="img/df9.png" alt=""  />
</p>
<br>
<p>需要注意，原文选取 2007 — 2015 年中国上市公司年报中的 MD&amp;A 信息作为研究样本。 之所以选取 2007 年作为样本的起点， 是因为从 2007 年开始， MD&amp;A 在企业定期报告中的披露要求已经较为完善， 而且 2007 年是中国会计准则国际趋同的重要时点， 新制定的《企业会计准则》已经开始实施， 为避免前后会计准则差异而产生的影响， 因此选取 2007 年作为样本区间的起点。</p>
<p><strong>mda_infor.csv含有2010-2020年的数据，如要复现原文，需要注意筛选数据。</strong></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;mda_infor.csv记录数:&#39;</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">))</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">    mda_infor.csv记录数: 30173
</code></pre></div><p><br><br></p>
<h2 id="数据代码获取">数据代码获取</h2>
<ul>
<li>数据&amp;代码创作不易， 如果需要源代码和数据， <a href="https://mp.weixin.qq.com/s/Rf3B0GJ_Tml-DVH-A6gV_g">点击进入购买链接</a>。</li>
<li>已购买 <a href="https://textdata.cn/blog/management_python_course/"><strong>支持开票 | Python实证指标构建与文本分析</strong></a> 课程学员，可私信大邓，直接获取本文数据、代码。</li>
</ul>
<p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>转载 | 大数据驱动的「社会经济地位」分析研究综述</title>
      <link>https://textdata.cn/blog/2022-12-30-review-about-socioeconomic-status-analysis/</link>
      <pubDate>Fri, 30 Dec 2022 00:00:00 +0000</pubDate>
      
      <guid>/blog/2022-12-30-review-about-socioeconomic-status-analysis/</guid>
      <description>大数据和机器学习技术的发展极大地促进了社 会经济地位的分析以及相关应用。 本文对应用于推断社会属性的大数据方法进行了全面的回顾,并系统地介绍了相应方法以及得到广泛使用的基准测试程序以及资源。 本文旨在提供 一份简洁、清晰的大数据方法应用于社会经济属性分析的概述,其不仅可以为对该方面感兴趣的读者提供帮助,而且可以为继续在该领域工作的研究人员和工程技术人员提供参考。</description>
      <content:encoded><![CDATA[<br>
<p>么晓明, 丁世昌, 赵涛, 黄宏, 罗家德, and 傅晓明. &ldquo;<strong>大数据驱动的社会经济地位分析研究综述</strong>.&rdquo; <em>计算机科学</em> 49, no. 4 (2022): 80-87.</p>
<br>
<p><img loading="lazy" src="img/%e5%a4%a7%e6%95%b0%e6%8d%ae%e9%a9%b1%e5%8a%a8%e7%9a%84%e7%a4%be%e4%bc%9a%e7%bb%8f%e6%b5%8e%e5%9c%b0%e4%bd%8d%e5%88%86%e6%9e%90%e7%a0%94%e7%a9%b6%e7%bb%bc%e8%bf%b0-2.png" alt=""  />

<img loading="lazy" src="img/%e5%a4%a7%e6%95%b0%e6%8d%ae%e9%a9%b1%e5%8a%a8%e7%9a%84%e7%a4%be%e4%bc%9a%e7%bb%8f%e6%b5%8e%e5%9c%b0%e4%bd%8d%e5%88%86%e6%9e%90%e7%a0%94%e7%a9%b6%e7%bb%bc%e8%bf%b0-3.png" alt=""  />

<img loading="lazy" src="img/%e5%a4%a7%e6%95%b0%e6%8d%ae%e9%a9%b1%e5%8a%a8%e7%9a%84%e7%a4%be%e4%bc%9a%e7%bb%8f%e6%b5%8e%e5%9c%b0%e4%bd%8d%e5%88%86%e6%9e%90%e7%a0%94%e7%a9%b6%e7%bb%bc%e8%bf%b0-4.png" alt=""  />

<img loading="lazy" src="img/%e5%a4%a7%e6%95%b0%e6%8d%ae%e9%a9%b1%e5%8a%a8%e7%9a%84%e7%a4%be%e4%bc%9a%e7%bb%8f%e6%b5%8e%e5%9c%b0%e4%bd%8d%e5%88%86%e6%9e%90%e7%a0%94%e7%a9%b6%e7%bb%bc%e8%bf%b0-5.png" alt=""  />

<img loading="lazy" src="img/%e5%a4%a7%e6%95%b0%e6%8d%ae%e9%a9%b1%e5%8a%a8%e7%9a%84%e7%a4%be%e4%bc%9a%e7%bb%8f%e6%b5%8e%e5%9c%b0%e4%bd%8d%e5%88%86%e6%9e%90%e7%a0%94%e7%a9%b6%e7%bb%bc%e8%bf%b0-6.png" alt=""  />

<img loading="lazy" src="img/%e5%a4%a7%e6%95%b0%e6%8d%ae%e9%a9%b1%e5%8a%a8%e7%9a%84%e7%a4%be%e4%bc%9a%e7%bb%8f%e6%b5%8e%e5%9c%b0%e4%bd%8d%e5%88%86%e6%9e%90%e7%a0%94%e7%a9%b6%e7%bb%bc%e8%bf%b0-7.png" alt=""  />
</p>
<br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>数据集 | 585w企业工商注册信息</title>
      <link>https://textdata.cn/blog/2022-12-07-585w-chinese-enterprise-registration-data/</link>
      <pubDate>Tue, 06 Dec 2022 00:00:00 +0000</pubDate>
      
      <guid>/blog/2022-12-07-585w-chinese-enterprise-registration-data/</guid>
      <description>585w企业工商注册信息</description>
      <content:encoded><![CDATA[<p>1978-2019.4,  585w中国大陆企业注册信息</p>
<p>文末有 enterprise-registration-data-of-chinese-mainland.csv 数据获取方式。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;enterprise-registration-data-of-chinese-mainland.csv&#39;</span><span class="p">,</span> 
                 <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">,</span> 
                 <span class="c1">#忽略有问题的记录</span>
                 <span class="n">on_bad_lines</span><span class="o">=</span><span class="s1">&#39;skip&#39;</span><span class="p">)</span>

<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<p><img loading="lazy" src="img/df1.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#剔除大邓广告</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;企业类型&#39;</span><span class="p">]</span><span class="o">!=</span><span class="s1">&#39;公众号: 大邓和他的Python&#39;</span><span class="p">]</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<p><img loading="lazy" src="img/df2.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#记录</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;记录数: &#39;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">))</span>

<span class="c1">#</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;字段有: &#39;</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">&#39;记录数: 12756270&#39;

&#39;字段有: [&#39;企业名称&#39;, &#39;统一社会信用代码&#39;, &#39;注册日期&#39;, &#39;企业类型&#39;, &#39;法人代表&#39;, &#39;注册资金&#39;, &#39;经营范围&#39;, &#39;所在省份&#39;,
       &#39;地区&#39;, &#39;注册地址&#39;]&#39;
</code></pre></div><br>
<p>但数据可能会有重复，这里以企业名称作为唯一标识，可以查看真实的数据量</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;真实记录数: &#39;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;企业名称&#39;</span><span class="p">])))</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">&#39;真实记录数: 5888382&#39;
</code></pre></div><br>
<br>
<h2 id="二如何将多个csv汇总到一个csv中">二、如何将多个csv汇总到一个csv中？</h2>
<p>那么这个enterprise-registration-data-of-chinese-mainland.csv怎么来的？</p>
<p>原始的数据集结构</p>
<p><img loading="lazy" src="img/screen-1.png" alt=""  />

<img loading="lazy" src="img/screen-2.png" alt=""  />
</p>
<br>
<p>先局部实验成功后，推广到整体。</p>
<ol>
<li>获取路径列表</li>
<li>尝试读取任意一个csv文件</li>
<li>尝试合并两个df</li>
<li>合并所有csv到一个文件内</li>
</ol>
<br>
<h3 id="21-获取路径列表">2.1 获取路径列表</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">os</span>

<span class="c1">#大邓电脑为Mac</span>
<span class="c1">#Mac容易在文件夹中生成奇怪的.DS_Store</span>
<span class="c1">#该操作为获取文件夹列表，同时剔除.DS_Store</span>
<span class="n">y_dirs</span> <span class="o">=</span> <span class="p">[</span><span class="n">di</span> <span class="k">for</span> <span class="n">di</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="s1">&#39;csv&#39;</span><span class="p">)</span> <span class="k">if</span> <span class="s1">&#39;.DS_Store&#39;</span><span class="o">!=</span><span class="n">di</span><span class="p">]</span>
<span class="k">for</span> <span class="n">y_dir</span> <span class="ow">in</span> <span class="n">y_dirs</span><span class="p">:</span>
    <span class="c1">#在年份文件夹内有很多csv文件</span>
    <span class="n">fs</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;csv/</span><span class="si">{}</span><span class="s1">/</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">y_dir</span><span class="p">,</span> <span class="n">fn</span><span class="p">)</span> 
          <span class="k">for</span> <span class="n">fn</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="s1">&#39;csv/</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">y_dir</span><span class="p">))</span>
          <span class="k">if</span> <span class="s1">&#39;.csv&#39;</span> <span class="ow">in</span> <span class="n">fn</span><span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">fs</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">......
......
[&#39;csv/2013/河南.csv&#39;, &#39;csv/2013/青海.csv&#39;, &#39;csv/2013/河北.csv&#39;, &#39;csv/2013/浙江.csv&#39;, &#39;csv/2013/内蒙古.csv&#39;, &#39;csv/2013/辽宁.csv&#39;, &#39;csv/2013/天津.csv&#39;, &#39;csv/2013/福建.csv&#39;, &#39;csv/2013/吉林.csv&#39;, &#39;csv/2013/西藏.csv&#39;, &#39;csv/2013/四川.csv&#39;, &#39;csv/2013/云南.csv&#39;, &#39;csv/2013/宁夏.csv&#39;, &#39;csv/2013/新疆.csv&#39;, &#39;csv/2013/安徽.csv&#39;, &#39;csv/2013/重庆.csv&#39;, &#39;csv/2013/贵州.csv&#39;, &#39;csv/2013/湖南.csv&#39;, &#39;csv/2013/海南.csv&#39;, &#39;csv/2013/湖北.csv&#39;, &#39;csv/2013/江西.csv&#39;, &#39;csv/2013/广东.csv&#39;, &#39;csv/2013/北京.csv&#39;, &#39;csv/2013/山西.csv&#39;, &#39;csv/2013/上海.csv&#39;, &#39;csv/2013/陕西.csv&#39;, &#39;csv/2013/黑龙江.csv&#39;, &#39;csv/2013/甘肃.csv&#39;, &#39;csv/2013/江苏.csv&#39;, &#39;csv/2013/山东.csv&#39;, &#39;csv/2013/广西.csv&#39;]

[&#39;csv/2014/河南.csv&#39;, &#39;csv/2014/青海.csv&#39;, &#39;csv/2014/河北.csv&#39;, &#39;csv/2014/浙江.csv&#39;, &#39;csv/2014/内蒙古.csv&#39;, &#39;csv/2014/辽宁.csv&#39;, &#39;csv/2014/天津.csv&#39;, &#39;csv/2014/福建.csv&#39;, &#39;csv/2014/吉林.csv&#39;, &#39;csv/2014/西藏.csv&#39;, &#39;csv/2014/四川.csv&#39;, &#39;csv/2014/云南.csv&#39;, &#39;csv/2014/宁夏.csv&#39;, &#39;csv/2014/新疆.csv&#39;, &#39;csv/2014/安徽.csv&#39;, &#39;csv/2014/重庆.csv&#39;, &#39;csv/2014/贵州.csv&#39;, &#39;csv/2014/湖南.csv&#39;, &#39;csv/2014/海南.csv&#39;, &#39;csv/2014/湖北.csv&#39;, &#39;csv/2014/江西.csv&#39;, &#39;csv/2014/广东.csv&#39;, &#39;csv/2014/北京.csv&#39;, &#39;csv/2014/山西.csv&#39;, &#39;csv/2014/上海.csv&#39;, &#39;csv/2014/陕西.csv&#39;, &#39;csv/2014/黑龙江.csv&#39;, &#39;csv/2014/甘肃.csv&#39;, &#39;csv/2014/江苏.csv&#39;, &#39;csv/2014/山东.csv&#39;, &#39;csv/2014/广西.csv&#39;]

[&#39;csv/2015/河南.csv&#39;, &#39;csv/2015/青海.csv&#39;, &#39;csv/2015/河北.csv&#39;, &#39;csv/2015/浙江.csv&#39;, &#39;csv/2015/内蒙古.csv&#39;, &#39;csv/2015/辽宁.csv&#39;, &#39;csv/2015/天津.csv&#39;, &#39;csv/2015/福建.csv&#39;, &#39;csv/2015/吉林.csv&#39;, &#39;csv/2015/西藏.csv&#39;, &#39;csv/2015/四川.csv&#39;, &#39;csv/2015/云南.csv&#39;, &#39;csv/2015/宁夏.csv&#39;, &#39;csv/2015/新疆.csv&#39;, &#39;csv/2015/安徽.csv&#39;, &#39;csv/2015/重庆.csv&#39;, &#39;csv/2015/贵州.csv&#39;, &#39;csv/2015/湖南.csv&#39;, &#39;csv/2015/海南.csv&#39;, &#39;csv/2015/湖北.csv&#39;, &#39;csv/2015/江西.csv&#39;, &#39;csv/2015/广东.csv&#39;, &#39;csv/2015/北京.csv&#39;, &#39;csv/2015/山西.csv&#39;, &#39;csv/2015/上海.csv&#39;, &#39;csv/2015/陕西.csv&#39;, &#39;csv/2015/黑龙江.csv&#39;, &#39;csv/2015/甘肃.csv&#39;, &#39;csv/2015/江苏.csv&#39;, &#39;csv/2015/山东.csv&#39;, &#39;csv/2015/广西.csv&#39;]

.....
.....
</code></pre></div><p><br><br></p>
<h3 id="22-尝试读取任意一个csv文件">2.2 尝试读取任意一个csv文件</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">df1</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;csv/2012/辽宁.csv&#39;</span><span class="p">,</span> 
                  <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">,</span> 
                  <span class="n">on_bad_lines</span><span class="o">=</span><span class="s1">&#39;skip&#39;</span><span class="p">)</span>

<span class="n">df1</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<p><img loading="lazy" src="img/df3.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df2</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;csv/2013/青海.csv&#39;</span><span class="p">,</span> 
                  <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">,</span> 
                  <span class="n">on_bad_lines</span><span class="o">=</span><span class="s1">&#39;skip&#39;</span><span class="p">)</span>

<span class="n">df2</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<p><img loading="lazy" src="img/df4.png" alt=""  />
</p>
<br>
<h3 id="23-尝试合并两个df">2.3 尝试合并两个df</h3>
<p>两个df垂直方向堆积，不增加字段种类，所以选择 pd.concat函数。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df12</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">df1</span><span class="p">,</span> <span class="n">df2</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">df12</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<p><img loading="lazy" src="img/df3.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#检查记录数</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">df1</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">df2</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">df12</span><span class="p">))</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">10246
4417
14663
</code></pre></div><br>
<h3 id="24-合并所有csv到一个文件内">2.4 合并所有csv到一个文件内</h3>
<p>将步骤1、2、3代码整理，汇总</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="c1">#存df列表</span>
<span class="n">dfs</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1">#文件路径列表</span>
<span class="n">y_dirs</span> <span class="o">=</span> <span class="p">[</span><span class="n">di</span> <span class="k">for</span> <span class="n">di</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="s1">&#39;csv&#39;</span><span class="p">)</span> <span class="k">if</span> <span class="s1">&#39;.DS_Store&#39;</span><span class="o">!=</span><span class="n">di</span><span class="p">]</span>
<span class="k">for</span> <span class="n">y_dir</span> <span class="ow">in</span> <span class="n">y_dirs</span><span class="p">:</span>
    <span class="n">csvfs</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;csv/</span><span class="si">{}</span><span class="s1">/</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">y_dir</span><span class="p">,</span> <span class="n">fn</span><span class="p">)</span> 
             <span class="k">for</span> <span class="n">fn</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="s1">&#39;csv/</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">y_dir</span><span class="p">))</span>
             <span class="k">if</span> <span class="s1">&#39;.csv&#39;</span> <span class="ow">in</span> <span class="n">fn</span><span class="p">]</span>
    
    <span class="k">for</span> <span class="n">csvf</span> <span class="ow">in</span> <span class="n">csvfs</span><span class="p">:</span>
        
        <span class="c1">#读取csv，得到df</span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">csvf</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">,</span> <span class="n">on_bad_lines</span><span class="o">=</span><span class="s1">&#39;skip&#39;</span><span class="p">)</span>
        <span class="c1">#存入df列表</span>
        <span class="n">dfs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
        
<span class="c1">#合并dfs为alldf</span>
<span class="n">alldf</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">dfs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1">#导出为data.csv</span>
<span class="n">alldf</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;enterprise-registration-data-of-chinese-mainland.csv&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</code></pre></div><p><br><br></p>
<h2 id="三数据获取">三、数据获取</h2>
<p>转发本文至朋友圈集赞50+， 加微信372335839， 备注【姓名-学校-专业-1200w工商】获取本文数据。</p>
<p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>BERTopic | 使用推特数据构建动态主题模型</title>
      <link>https://textdata.cn/blog/2022-12-03-dynamic_topic_model_with_bertopic/</link>
      <pubDate>Sun, 04 Dec 2022 00:00:00 +0000</pubDate>
      
      <guid>/blog/2022-12-03-dynamic_topic_model_with_bertopic/</guid>
      <description>在本文中将使用BERTopic库，对美国前总统Trump推特数据集，构建动态主题模型DTM(Dynamic Topic Modeling)，可视化文档数据集中不同主题随时间的演变(变迁)。</description>
      <content:encoded><![CDATA[<p>在本文中将使用 BERTopic 库，对美国前总统 Trump 推特数据集，构建动态主题模型 DTM(Dynamic Topic Modeling)，可视化文档数据集中不同主题随时间的演变(变迁)。<strong>文末有代码下载方式</strong></p>
<br>
<h2 id="安装">安装</h2>
<p>为保证代码可复现，保证你我电脑中 bertopic 版本一致，先查看大邓电脑的 bertopic 版本</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">bertopic</span>

<span class="c1">#本文bertopic版本</span>
<span class="n">bertopic</span><span class="o">.</span><span class="n">__version__</span>
</code></pre></div><p>Run</p>
<pre><code>'0.12.0'
</code></pre>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#推荐指定版本安装；</span>
<span class="c1">#!pip3 install bertopic==0.12.0</span>

<span class="c1">#不指定版本安装</span>
<span class="err">!</span><span class="n">pip3</span> <span class="n">install</span> <span class="n">bertopic</span>
</code></pre></div><br>
<h2 id="导入数据">导入数据</h2>
<p>这里准备了twitter账号 @realDonalTrump 中 2021年的推特数据，  点击下载 <a href="code.zip"><strong>数据及代码</strong></a>。</p>
<ul>
<li>我们只分析原推特，不分析每条推特的回复。</li>
<li>因为要分析推特随时间的主题变化，需要准备 <strong>推特</strong> 及对应的 <strong>推文时间</strong></li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">re</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">datetime</span>

<span class="c1"># 导入数据</span>
<span class="n">trump_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;trump_twitter_2021.csv&#39;</span><span class="p">)</span>
<span class="n">trump_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-html" data-lang="html"><span class="p">&lt;</span><span class="nt">div</span><span class="p">&gt;</span>
<span class="p">&lt;</span><span class="nt">style</span> <span class="na">scoped</span><span class="p">&gt;</span>
    <span class="p">.</span><span class="nc">dataframe</span> <span class="nt">tbody</span> <span class="nt">tr</span> <span class="nt">th</span><span class="p">:</span><span class="nd">only-of-type</span> <span class="p">{</span>
        <span class="k">vertical-align</span><span class="p">:</span> <span class="kc">middle</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="p">.</span><span class="nc">dataframe</span> <span class="nt">tbody</span> <span class="nt">tr</span> <span class="nt">th</span> <span class="p">{</span>
        <span class="k">vertical-align</span><span class="p">:</span> <span class="kc">top</span><span class="p">;</span>
    <span class="p">}</span>
    
    <span class="p">.</span><span class="nc">dataframe</span> <span class="nt">thead</span> <span class="nt">th</span> <span class="p">{</span>
        <span class="k">text-align</span><span class="p">:</span> <span class="kc">right</span><span class="p">;</span>
    <span class="p">}</span>
<span class="p">&lt;/</span><span class="nt">style</span><span class="p">&gt;</span>
<span class="p">&lt;</span><span class="nt">table</span> <span class="na">border</span><span class="o">=</span><span class="s">&#34;1&#34;</span> <span class="na">class</span><span class="o">=</span><span class="s">&#34;dataframe&#34;</span><span class="p">&gt;</span>
  <span class="p">&lt;</span><span class="nt">thead</span><span class="p">&gt;</span>
    <span class="p">&lt;</span><span class="nt">tr</span> <span class="na">style</span><span class="o">=</span><span class="s">&#34;text-align: right;&#34;</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">th</span><span class="p">&gt;&lt;/</span><span class="nt">th</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">th</span><span class="p">&gt;</span>id<span class="p">&lt;/</span><span class="nt">th</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">th</span><span class="p">&gt;</span>text<span class="p">&lt;/</span><span class="nt">th</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">th</span><span class="p">&gt;</span>isRetweet<span class="p">&lt;/</span><span class="nt">th</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">th</span><span class="p">&gt;</span>isDeleted<span class="p">&lt;/</span><span class="nt">th</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">th</span><span class="p">&gt;</span>device<span class="p">&lt;/</span><span class="nt">th</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">th</span><span class="p">&gt;</span>favorites<span class="p">&lt;/</span><span class="nt">th</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">th</span><span class="p">&gt;</span>retweets<span class="p">&lt;/</span><span class="nt">th</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">th</span><span class="p">&gt;</span>date<span class="p">&lt;/</span><span class="nt">th</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">th</span><span class="p">&gt;</span>isFlagged<span class="p">&lt;/</span><span class="nt">th</span><span class="p">&gt;</span>
    <span class="p">&lt;/</span><span class="nt">tr</span><span class="p">&gt;</span>
  <span class="p">&lt;/</span><span class="nt">thead</span><span class="p">&gt;</span>
  <span class="p">&lt;</span><span class="nt">tbody</span><span class="p">&gt;</span>
    <span class="p">&lt;</span><span class="nt">tr</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">th</span><span class="p">&gt;</span>0<span class="p">&lt;/</span><span class="nt">th</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>98454970654916608<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>Republicans and Democrats have both created ou...<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>f<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>f<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>TweetDeck<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>49<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>255<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>2011-08-02 18:07:48<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>f<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
    <span class="p">&lt;/</span><span class="nt">tr</span><span class="p">&gt;</span>
    <span class="p">&lt;</span><span class="nt">tr</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">th</span><span class="p">&gt;</span>1<span class="p">&lt;/</span><span class="nt">th</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>1234653427789070336<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>I was thrilled to be back in the Great city of...<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>f<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>f<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>Twitter for iPhone<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>73748<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>17404<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>2020-03-03 01:34:50<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>f<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
    <span class="p">&lt;/</span><span class="nt">tr</span><span class="p">&gt;</span>
    <span class="p">&lt;</span><span class="nt">tr</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">th</span><span class="p">&gt;</span>2<span class="p">&lt;/</span><span class="nt">th</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>1218010753434820614<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>RT @CBS_Herridge: READ: Letter to surveillance...<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>t<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>f<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>Twitter for iPhone<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>0<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>7396<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>2020-01-17 03:22:47<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>f<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
    <span class="p">&lt;/</span><span class="nt">tr</span><span class="p">&gt;</span>
    <span class="p">&lt;</span><span class="nt">tr</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">th</span><span class="p">&gt;</span>3<span class="p">&lt;/</span><span class="nt">th</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>1304875170860015617<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>The Unsolicited Mail In Ballot Scam is a major...<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>f<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>f<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>Twitter for iPhone<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>80527<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>23502<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>2020-09-12 20:10:58<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>f<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
    <span class="p">&lt;/</span><span class="nt">tr</span><span class="p">&gt;</span>
    <span class="p">&lt;</span><span class="nt">tr</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">th</span><span class="p">&gt;</span>4<span class="p">&lt;/</span><span class="nt">th</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>1218159531554897920<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>RT @MZHemingway: Very friendly telling of even...<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>t<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>f<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>Twitter for iPhone<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>0<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>9081<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>2020-01-17 13:13:59<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>f<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
    <span class="p">&lt;/</span><span class="nt">tr</span><span class="p">&gt;</span>
  <span class="p">&lt;/</span><span class="nt">tbody</span><span class="p">&gt;</span>
<span class="p">&lt;/</span><span class="nt">table</span><span class="p">&gt;</span>
<span class="p">&lt;/</span><span class="nt">div</span><span class="p">&gt;</span>
</code></pre></div><br>
<h2 id="预处理">预处理</h2>
<ul>
<li>使用正则表达式 清除推文中的http链接</li>
<li>剔除@符</li>
<li>使用正则表达式 剔除 非英文字符</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">re</span>

<span class="c1">#预处理函数clean_text</span>
<span class="k">def</span> <span class="nf">clean_text</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s2">&#34;http\S+&#34;</span><span class="p">,</span> <span class="s2">&#34;&#34;</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
    <span class="n">text</span> <span class="o">=</span> <span class="s2">&#34; &#34;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">w</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">text</span><span class="o">.</span><span class="n">split</span><span class="p">()</span> <span class="k">if</span> <span class="n">w</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">!=</span><span class="s1">&#39;@&#39;</span><span class="p">])</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s2">&#34;[^a-zA-Z]+&#34;</span><span class="p">,</span> <span class="s2">&#34; &#34;</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">text</span>


<span class="n">test_text</span> <span class="o">=</span> <span class="s1">&#39;hello @Apple, https://apple.com 李John&#39;</span>
<span class="c1">#验证函数有效性</span>
<span class="n">clean_text</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="n">test_text</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<pre><code>'hello john'
</code></pre>
<br>
<ul>
<li>对text字段使用预处理函数 clean_text</li>
<li>只保留原推文</li>
<li>准备推特tweets和时间戳 timestamps</li>
</ul>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#清洗字段text</span>
<span class="n">trump_df</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">trump_df</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">clean_text</span><span class="p">)</span>

<span class="c1">#只保留特朗普原推文(剔除特朗普的Retweet)</span>
<span class="c1">#推文内容不能为”“</span>
<span class="n">trump_df</span> <span class="o">=</span> <span class="n">trump_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[(</span><span class="n">trump_df</span><span class="p">[</span><span class="s1">&#39;isRetweet&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&#34;f&#34;</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">trump_df</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">]</span> <span class="o">!=</span> <span class="s2">&#34;&#34;</span><span class="p">),</span> <span class="p">:]</span>

<span class="c1">#准备tweets及对应的timestamps</span>
<span class="n">tweets</span> <span class="o">=</span> <span class="n">trump_df</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">to_list</span><span class="p">()</span>
<span class="n">timestamps</span> <span class="o">=</span> <span class="n">trump_df</span><span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">to_list</span><span class="p">()</span>

<span class="n">tweets</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</code></pre></div><p>Run</p>
<pre><code>'republicans and democrats have both created our economic problems '
</code></pre>
<br>
<h2 id="初始化bertopic">初始化BERTopic</h2>
<p>在模型初始化阶段，使用所有推文数据， 会忽略时间维度。 该步骤会把所有时间段中出现的主题都提前训练识别出来。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">bertopic</span> <span class="kn">import</span> <span class="n">BERTopic</span>

<span class="c1">#大邓这里，运行了不到1小时</span>
<span class="c1">#特朗普比较活跃，什么内容都会参与，所以这里设置一个话题数下限为35，话题数上限不设置</span>
<span class="n">topic_model</span> <span class="o">=</span> <span class="n">BERTopic</span><span class="p">(</span><span class="n">min_topic_size</span><span class="o">=</span><span class="mi">35</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">topics</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">topic_model</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">tweets</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">    Downloading:   0%|          | 0.00/1.18k [00:00&lt;?, ?B/s]
    Downloading:   0%|          | 0.00/190 [00:00&lt;?, ?B/s]
    Downloading:   0%|          | 0.00/10.6k [00:00&lt;?, ?B/s]
    Downloading:   0%|          | 0.00/612 [00:00&lt;?, ?B/s]
    Downloading:   0%|          | 0.00/116 [00:00&lt;?, ?B/s]
    Downloading:   0%|          | 0.00/39.3k [00:00&lt;?, ?B/s]
    Downloading:   0%|          | 0.00/349 [00:00&lt;?, ?B/s]
    Downloading:   0%|          | 0.00/90.9M [00:00&lt;?, ?B/s]
    Downloading:   0%|          | 0.00/53.0 [00:00&lt;?, ?B/s]
    Downloading:   0%|          | 0.00/112 [00:00&lt;?, ?B/s]
    Downloading:   0%|          | 0.00/466k [00:00&lt;?, ?B/s]
    Downloading:   0%|          | 0.00/350 [00:00&lt;?, ?B/s]
    Downloading:   0%|          | 0.00/13.2k [00:00&lt;?, ?B/s]
    Downloading:   0%|          | 0.00/232k [00:00&lt;?, ?B/s]
    Batches:   0%|          | 0/1418 [00:00&lt;?, ?it/s]

    2022-12-04 22:04:02,964 - BERTopic - Transformed documents to Embeddings
    2022-12-04 22:05:13,606 - BERTopic - Reduced dimensionality
    2022-12-04 22:05:17,814 - BERTopic - Clustered reduced embeddings
</code></pre></div><br>
<p>抽取出所有的话题</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">freq</span> <span class="o">=</span> <span class="n">topic_model</span><span class="o">.</span><span class="n">get_topic_info</span><span class="p">()</span>

<span class="c1">#话题总数</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">freq</span><span class="p">))</span>
<span class="n">freq</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">    169
</code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-html" data-lang="html"><span class="p">&lt;</span><span class="nt">div</span><span class="p">&gt;</span>
<span class="p">&lt;</span><span class="nt">style</span> <span class="na">scoped</span><span class="p">&gt;</span>
    <span class="p">.</span><span class="nc">dataframe</span> <span class="nt">tbody</span> <span class="nt">tr</span> <span class="nt">th</span><span class="p">:</span><span class="nd">only-of-type</span> <span class="p">{</span>
        <span class="k">vertical-align</span><span class="p">:</span> <span class="kc">middle</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="p">.</span><span class="nc">dataframe</span> <span class="nt">tbody</span> <span class="nt">tr</span> <span class="nt">th</span> <span class="p">{</span>
        <span class="k">vertical-align</span><span class="p">:</span> <span class="kc">top</span><span class="p">;</span>
    <span class="p">}</span>
    
    <span class="p">.</span><span class="nc">dataframe</span> <span class="nt">thead</span> <span class="nt">th</span> <span class="p">{</span>
        <span class="k">text-align</span><span class="p">:</span> <span class="kc">right</span><span class="p">;</span>
    <span class="p">}</span>
<span class="p">&lt;/</span><span class="nt">style</span><span class="p">&gt;</span>
<span class="p">&lt;</span><span class="nt">table</span> <span class="na">border</span><span class="o">=</span><span class="s">&#34;1&#34;</span> <span class="na">class</span><span class="o">=</span><span class="s">&#34;dataframe&#34;</span><span class="p">&gt;</span>
  <span class="p">&lt;</span><span class="nt">thead</span><span class="p">&gt;</span>
    <span class="p">&lt;</span><span class="nt">tr</span> <span class="na">style</span><span class="o">=</span><span class="s">&#34;text-align: right;&#34;</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">th</span><span class="p">&gt;&lt;/</span><span class="nt">th</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">th</span><span class="p">&gt;</span>Topic<span class="p">&lt;/</span><span class="nt">th</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">th</span><span class="p">&gt;</span>Count<span class="p">&lt;/</span><span class="nt">th</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">th</span><span class="p">&gt;</span>Name<span class="p">&lt;/</span><span class="nt">th</span><span class="p">&gt;</span>
    <span class="p">&lt;/</span><span class="nt">tr</span><span class="p">&gt;</span>
  <span class="p">&lt;/</span><span class="nt">thead</span><span class="p">&gt;</span>
  <span class="p">&lt;</span><span class="nt">tbody</span><span class="p">&gt;</span>
    <span class="p">&lt;</span><span class="nt">tr</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">th</span><span class="p">&gt;</span>0<span class="p">&lt;/</span><span class="nt">th</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>-1<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>15098<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>-1_the_to_is_of<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
    <span class="p">&lt;/</span><span class="nt">tr</span><span class="p">&gt;</span>
    <span class="p">&lt;</span><span class="nt">tr</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">th</span><span class="p">&gt;</span>1<span class="p">&lt;/</span><span class="nt">th</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>0<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>3182<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>0_run_president_trump_donald<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
    <span class="p">&lt;/</span><span class="nt">tr</span><span class="p">&gt;</span>
    <span class="p">&lt;</span><span class="nt">tr</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">th</span><span class="p">&gt;</span>2<span class="p">&lt;/</span><span class="nt">th</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>1<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>1821<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>1_crowd_carolina_join_thank<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
    <span class="p">&lt;/</span><span class="nt">tr</span><span class="p">&gt;</span>
    <span class="p">&lt;</span><span class="nt">tr</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">th</span><span class="p">&gt;</span>3<span class="p">&lt;/</span><span class="nt">th</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>2<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>1084<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>2_golf_course_doral_scotland<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
    <span class="p">&lt;/</span><span class="nt">tr</span><span class="p">&gt;</span>
    <span class="p">&lt;</span><span class="nt">tr</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">th</span><span class="p">&gt;</span>4<span class="p">&lt;/</span><span class="nt">th</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>3<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>1030<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>3_border_wall_immigration_mexico<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
    <span class="p">&lt;/</span><span class="nt">tr</span><span class="p">&gt;</span>
    <span class="p">&lt;</span><span class="nt">tr</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">th</span><span class="p">&gt;</span>5<span class="p">&lt;/</span><span class="nt">th</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>4<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>811<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>4_china_trade_tariffs_chinese<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
    <span class="p">&lt;/</span><span class="nt">tr</span><span class="p">&gt;</span>
    <span class="p">&lt;</span><span class="nt">tr</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">th</span><span class="p">&gt;</span>6<span class="p">&lt;/</span><span class="nt">th</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>5<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>642<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>5_obamacare_healthcare_repeal_website<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
    <span class="p">&lt;/</span><span class="nt">tr</span><span class="p">&gt;</span>
    <span class="p">&lt;</span><span class="nt">tr</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">th</span><span class="p">&gt;</span>7<span class="p">&lt;/</span><span class="nt">th</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>6<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>638<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>6_hillary_clinton_crooked_she<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
    <span class="p">&lt;/</span><span class="nt">tr</span><span class="p">&gt;</span>
    <span class="p">&lt;</span><span class="nt">tr</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">th</span><span class="p">&gt;</span>8<span class="p">&lt;/</span><span class="nt">th</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>7<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>607<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>7_amp_it_you_to<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
    <span class="p">&lt;/</span><span class="nt">tr</span><span class="p">&gt;</span>
    <span class="p">&lt;</span><span class="nt">tr</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">th</span><span class="p">&gt;</span>9<span class="p">&lt;/</span><span class="nt">th</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>8<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>562<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>8_media_fake_news_failing<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
    <span class="p">&lt;/</span><span class="nt">tr</span><span class="p">&gt;</span>
  <span class="p">&lt;/</span><span class="nt">tbody</span><span class="p">&gt;</span>
<span class="p">&lt;/</span><span class="nt">table</span><span class="p">&gt;</span>
<span class="p">&lt;/</span><span class="nt">div</span><span class="p">&gt;</span>
</code></pre></div><br>
<p>-1 意识是所有的离群点(异类)推文，应该被忽略掉。接下来让我们看一下 Topic-4 的特征词及其权重</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#topic-4的特征词及权重</span>
<span class="n">topic_model</span><span class="o">.</span><span class="n">get_topic</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">    [(&#39;china&#39;, 0.05289416225000891),
     (&#39;tariffs&#39;, 0.024471004754487165),
     (&#39;trade&#39;, 0.02437576425026641),
     (&#39;chinese&#39;, 0.013643270667358017),
     (&#39;us&#39;, 0.011206804363719649),
     (&#39;farmers&#39;, 0.01113584970813823),
     (&#39;our&#39;, 0.010197907480148342),
     (&#39;deal&#39;, 0.010014612658730073),
     (&#39;we&#39;, 0.009043537683534882),
     (&#39;countries&#39;, 0.00901653033214627)]
</code></pre></div><br>
<p>在二维空间中使用  Intertopic Distance Map 可视化所有主题。该图可以让我们继续创建 DTM 前，判断主题数设置的是否充分够用。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">fig</span> <span class="o">=</span> <span class="n">topic_model</span><span class="o">.</span><span class="n">visualize_topics</span><span class="p">()</span>
<span class="n">fig</span>
</code></pre></div><p>Run</p>
<p><img loading="lazy" src="img/topics.png" alt=""  />
</p>
<p>渲染的可视化文件太大，这里感兴趣的可以 <a href="topics.html">点击查看动态效果图</a></p>
<br>
<h2 id="构建dtm">构建DTM</h2>
<p>在 构建动态主题模型 前， 不同时间段中出现的主题需要预先都训练好。</p>
<ul>
<li>docs 文档数据，对应于本文的 tweets</li>
<li>timestamps 时间戳，对应于本文的 timestamps</li>
<li>global_tuning 是否将某个主题在 时间t 的主题表示向量 与 其全局主题表示向量 进行平均</li>
<li>evolution_tuning 是否将某个主题在 时间t 的主题表示向量 与 该主题在时间t-1 的主题表示向量 进行平均</li>
<li>nr_bins 时间段内含有的时间戳(点)数量。在数千个不同的时间戳中提取主题在计算上是低效的, 可以合并 20 个时间戳为一个时间段</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">topics_over_time</span> <span class="o">=</span> <span class="n">topic_model</span><span class="o">.</span><span class="n">topics_over_time</span><span class="p">(</span><span class="n">docs</span><span class="o">=</span><span class="n">tweets</span><span class="p">,</span> 
                                                <span class="n">timestamps</span><span class="o">=</span><span class="n">timestamps</span><span class="p">,</span> 
                                                <span class="n">global_tuning</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
                                                <span class="n">evolution_tuning</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
                                                <span class="n">nr_bins</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>

<span class="n">topics_over_time</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-html" data-lang="html"><span class="p">&lt;</span><span class="nt">div</span><span class="p">&gt;</span>
<span class="p">&lt;</span><span class="nt">style</span> <span class="na">scoped</span><span class="p">&gt;</span>
    <span class="p">.</span><span class="nc">dataframe</span> <span class="nt">tbody</span> <span class="nt">tr</span> <span class="nt">th</span><span class="p">:</span><span class="nd">only-of-type</span> <span class="p">{</span>
        <span class="k">vertical-align</span><span class="p">:</span> <span class="kc">middle</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="p">.</span><span class="nc">dataframe</span> <span class="nt">tbody</span> <span class="nt">tr</span> <span class="nt">th</span> <span class="p">{</span>
        <span class="k">vertical-align</span><span class="p">:</span> <span class="kc">top</span><span class="p">;</span>
    <span class="p">}</span>
    
    <span class="p">.</span><span class="nc">dataframe</span> <span class="nt">thead</span> <span class="nt">th</span> <span class="p">{</span>
        <span class="k">text-align</span><span class="p">:</span> <span class="kc">right</span><span class="p">;</span>
    <span class="p">}</span>
<span class="p">&lt;/</span><span class="nt">style</span><span class="p">&gt;</span>
<span class="p">&lt;</span><span class="nt">table</span> <span class="na">border</span><span class="o">=</span><span class="s">&#34;1&#34;</span> <span class="na">class</span><span class="o">=</span><span class="s">&#34;dataframe&#34;</span><span class="p">&gt;</span>
  <span class="p">&lt;</span><span class="nt">thead</span><span class="p">&gt;</span>
    <span class="p">&lt;</span><span class="nt">tr</span> <span class="na">style</span><span class="o">=</span><span class="s">&#34;text-align: right;&#34;</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">th</span><span class="p">&gt;&lt;/</span><span class="nt">th</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">th</span><span class="p">&gt;</span>Topic<span class="p">&lt;/</span><span class="nt">th</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">th</span><span class="p">&gt;</span>Words<span class="p">&lt;/</span><span class="nt">th</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">th</span><span class="p">&gt;</span>Frequency<span class="p">&lt;/</span><span class="nt">th</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">th</span><span class="p">&gt;</span>Timestamp<span class="p">&lt;/</span><span class="nt">th</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">th</span><span class="p">&gt;</span>Name<span class="p">&lt;/</span><span class="nt">th</span><span class="p">&gt;</span>
    <span class="p">&lt;/</span><span class="nt">tr</span><span class="p">&gt;</span>
  <span class="p">&lt;/</span><span class="nt">thead</span><span class="p">&gt;</span>
  <span class="p">&lt;</span><span class="nt">tbody</span><span class="p">&gt;</span>
    <span class="p">&lt;</span><span class="nt">tr</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">th</span><span class="p">&gt;</span>0<span class="p">&lt;/</span><span class="nt">th</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>-1<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>donald, keychain, champion, trump, contest<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>20<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>2009-04-30 12:30:07.596999936<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>-1_the_to_is_of<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
    <span class="p">&lt;/</span><span class="nt">tr</span><span class="p">&gt;</span>
    <span class="p">&lt;</span><span class="nt">tr</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">th</span><span class="p">&gt;</span>1<span class="p">&lt;/</span><span class="nt">th</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>0<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>donald, execute, imagination, step, randal<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>9<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>2009-04-30 12:30:07.596999936<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>0_run_president_trump_donald<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
    <span class="p">&lt;/</span><span class="nt">tr</span><span class="p">&gt;</span>
    <span class="p">&lt;</span><span class="nt">tr</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">th</span><span class="p">&gt;</span>2<span class="p">&lt;/</span><span class="nt">th</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>2<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>begun, schedule, ahead, international, scotland<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>1<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>2009-04-30 12:30:07.596999936<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>2_golf_course_doral_scotland<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
    <span class="p">&lt;/</span><span class="nt">tr</span><span class="p">&gt;</span>
    <span class="p">&lt;</span><span class="nt">tr</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">th</span><span class="p">&gt;</span>3<span class="p">&lt;/</span><span class="nt">th</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>3<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>cling, wallflower, persona, walls, rather<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>1<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>2009-04-30 12:30:07.596999936<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>3_border_wall_immigration_mexico<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
    <span class="p">&lt;/</span><span class="nt">tr</span><span class="p">&gt;</span>
    <span class="p">&lt;</span><span class="nt">tr</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">th</span><span class="p">&gt;</span>4<span class="p">&lt;/</span><span class="nt">th</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>10<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>independence, safe, here, enjoy, happy<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>1<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>2009-04-30 12:30:07.596999936<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>10_veterans_honor_heroes_our<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
    <span class="p">&lt;/</span><span class="nt">tr</span><span class="p">&gt;</span>
    <span class="p">&lt;</span><span class="nt">tr</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">th</span><span class="p">&gt;</span>...<span class="p">&lt;/</span><span class="nt">th</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>...<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>...<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>...<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>...<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>...<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
    <span class="p">&lt;/</span><span class="nt">tr</span><span class="p">&gt;</span>
    <span class="p">&lt;</span><span class="nt">tr</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">th</span><span class="p">&gt;</span>1880<span class="p">&lt;/</span><span class="nt">th</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>162<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>ratings, fredo, frank, bad, based<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>2<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>2020-06-09 07:29:57.849999872<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>162_ratings_machine_show_sided<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
    <span class="p">&lt;/</span><span class="nt">tr</span><span class="p">&gt;</span>
    <span class="p">&lt;</span><span class="nt">tr</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">th</span><span class="p">&gt;</span>1881<span class="p">&lt;/</span><span class="nt">th</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>163<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>yes, no, way, absolutely,<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>2<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>2020-06-09 07:29:57.849999872<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>163_yes_no_absolutely_way<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
    <span class="p">&lt;/</span><span class="nt">tr</span><span class="p">&gt;</span>
    <span class="p">&lt;</span><span class="nt">tr</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">th</span><span class="p">&gt;</span>1882<span class="p">&lt;/</span><span class="nt">th</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>164<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>twitter, trending, section, trends, conservative<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>13<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>2020-06-09 07:29:57.849999872<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>164_twitter_trending_conservative_sectio...<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
    <span class="p">&lt;/</span><span class="nt">tr</span><span class="p">&gt;</span>
    <span class="p">&lt;</span><span class="nt">tr</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">th</span><span class="p">&gt;</span>1883<span class="p">&lt;/</span><span class="nt">th</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>165<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>york, eaten, hell, new, blasio<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>4<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>2020-06-09 07:29:57.849999872<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>165_york_ny_new_wonerful<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
    <span class="p">&lt;/</span><span class="nt">tr</span><span class="p">&gt;</span>
    <span class="p">&lt;</span><span class="nt">tr</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">th</span><span class="p">&gt;</span>1884<span class="p">&lt;/</span><span class="nt">th</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>167<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>mixing, courthouse, mocked, notes, prosecuted<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>3<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>2020-06-09 07:29:57.849999872<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">td</span><span class="p">&gt;</span>167_jury_judge_guilty_foreperson<span class="p">&lt;/</span><span class="nt">td</span><span class="p">&gt;</span>
    <span class="p">&lt;/</span><span class="nt">tr</span><span class="p">&gt;</span>
  <span class="p">&lt;/</span><span class="nt">tbody</span><span class="p">&gt;</span>
<span class="p">&lt;/</span><span class="nt">table</span><span class="p">&gt;</span>
<span class="p">&lt;</span><span class="nt">p</span><span class="p">&gt;</span>1885 rows × 5 columns<span class="p">&lt;/</span><span class="nt">p</span><span class="p">&gt;</span>
<span class="p">&lt;/</span><span class="nt">div</span><span class="p">&gt;</span>
</code></pre></div><br>
<h2 id="可视化dtm">可视化DTM</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#模型中一共有169个主题，这里显示前Top10的主题的演变</span>
<span class="n">topic_model</span><span class="o">.</span><span class="n">visualize_topics_over_time</span><span class="p">(</span><span class="n">topics_over_time</span><span class="p">,</span> <span class="n">top_n_topics</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<p><img loading="lazy" src="img/dtm.png" alt=""  />

渲染的可视化文件太大，这里感兴趣的可以 <a href="dtm.html">点击查看动态效果图</a></p>
<br>
<h3 id="获取本文代码">获取本文代码</h3>
<p>点击获取 <a href="code.zip"><strong>数据及代码</strong></a></p>
<br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>JM2022综述 | 黄金领域: 为营销研究(新洞察)采集网络数据</title>
      <link>https://textdata.cn/blog/2022-12-03-scraping-web-data-for-marketing-insights/</link>
      <pubDate>Sat, 03 Dec 2022 00:00:00 +0000</pubDate>
      
      <guid>/blog/2022-12-03-scraping-web-data-for-marketing-insights/</guid>
      <description>Journal of Marketing 2022年一篇关于营销领域网络爬虫的文献综述</description>
      <content:encoded><![CDATA[<p>Boegershausen, Johannes, Hannes Datta, Abhishek Borah, and Andrew Stephen. &ldquo;Fields of gold: Scraping web data for marketing insights.&rdquo; <em>Journal of Marketing</em> (2022).</p>
<p>本文是JM中少有的技术流综述文，阅读起来晦涩难懂，我们就大概知道怎么回事， 查看有没有自己感兴趣的研究(方法)即可。该文作者为该综述专门开发了一个 web-scraping.org 的网站,截图如下</p>
<p><img loading="lazy" src="img/01-web-scraping.png" alt=""  />

<img loading="lazy" src="img/02-web-scraping.png" alt=""  />
</p>

<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
  <iframe src="https://www.youtube.com/embed/KiyFyLEkqNk" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video"></iframe>
</div>

<br>
<h2 id="摘要">摘要</h2>
<p>市场营销学者越来越多使用网络爬虫和API接口，从互联网收集数据。尽管网络数据得到广泛使用，但很少有学者关注收集过程中面临的各种挑战。<strong>研究人员如何确保采集的数据集是有效的？</strong> 虽然现有资源强调提取网络数据的技术细节，<strong>但作者提出了一种新的方法框架，重点是提高其有效性</strong>。特别是，该框架强调解决有效性问题， 需要在数据采集的三个阶段(<strong>选择数据源、设计数据收集和提取数据</strong>)联合考虑技术和法律/伦理问题。作者进一步审查了营销Top5期刊上300 篇使用网络数据的论文，并总结提出了如何使用网络数据促进营销研究。本文最后指出了未来研究的方向，高价值的网络数据源和新方法。</p>
<p><strong>Keywords：</strong></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">- web scraping
- application programming interface, API
- crawling
- validity
- user-generated content
- social media
big data
</code></pre></div><br>
<h2 id="一网络数据的魅力">一、网络数据的魅力</h2>
<p>社会和商业生活的加速数字化创造了数量空前的消费者和企业行为数字痕迹。 每分钟，全球用户在 Google 上进行 570 万次搜索，进行 600 万次商业交易，并在 Instagram 上分享6.5万张照片（Statista 2021）。 由此产生的网络数据——规模庞大、形式多样，而且通常可以在互联网上公开访问——对于那些想要量化消费、深入了解企业行为并跟踪难以或昂贵地观察社会活动的营销学者来说，这是一个潜在的金矿 . 网络数据对营销研究的重要性反映在越来越多的有影响力的出版物中，涵盖消费者文化理论、消费者心理学、实证建模和营销策略等。</p>
<p><img loading="lazy" src="img/fig-1-increased-use-of-web-data-in-marketing.png" alt=""  />
</p>
<p>整理了 <strong>营销领域 top 5 期刊( JM、JMR、JCR、JCP、MS) 的 313 篇论文</strong> ，经过整理绘制图-1（Figure1）， 使用网络数据进行研究的量呈现快速上涨的趋势。使用网络数据的论文占比，从2010年的4%提升到2020年的15%。 者313篇论文，数据的获取方式统计</p>
<ul>
<li>**59% 的论文使用了 <strong>网络爬虫</strong> 采集数据</li>
<li>12% 的论文使用API收集数据</li>
<li>9% 的论文同时使用了网络爬虫和API</li>
<li>20% 使用人工从网站手动复制粘贴数据</li>
</ul>
<p><strong>使用 网络数据 的论文，平均被引用次数 7.55， 远高于 非网络数据 的 3.90</strong>。</p>
<br>
<p>使用网络数据做新研究，大致有4种实现路径</p>
<ol>
<li><strong>研究新现象，新场景</strong>
<ul>
<li>网络世界产生的不同于现实世界的情景，可以研究新现象</li>
</ul>
</li>
<li><strong>繁荣生态价值</strong>
<ul>
<li>比如，对亚马逊评论数据进行研究，研究发现可以帮助亚马逊平台进行改善。</li>
</ul>
</li>
<li><strong>促进方法论进步</strong>
<ul>
<li>文本、图片、音频、视频等</li>
</ul>
</li>
<li><strong>提高测量效果(快、准、好、全)</strong>
<ul>
<li>借助一些API，可以对已有的数据集增加新的信息量。</li>
<li>例如，日期数据，结合HolidayAPI，可以查看日期的节假日信息</li>
<li>给定日期和IP地址，使用Weather Underground可以查看天气信息</li>
</ul>
</li>
</ol>
<p><img loading="lazy" src="img/table-1-four-pathway-of-knowledge-creation-using-web-data.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="二数据采集的方法框架">二、数据采集的方法框架</h2>
<p>在使用 **网络爬虫 和 API ** 自动收集网络数据时，研究人员通常会在 **研究有效性、技术可行性和法律/伦理风险 **1 三者间权衡利弊得失，研究人员如何解决这些权衡，通过增强或破坏 <strong>统计结论有效性、内部有效性、结构有效性和外部有效性</strong> 来塑造研究结果的可信度（Shadish、Cook 和 Campbell 2002）。</p>
<p><img loading="lazy" src="img/fig-2-methodological-framework-for-collecting-web-data.png" alt=""  />
</p>
<p>本文开发了一个方法框架，为使用 网络爬虫 和 API 自动收集网络数据提供指导。图 2（Figure 2） 涵盖三个关键阶段</p>
<ul>
<li><strong>数据源选择</strong></li>
<li><strong>设计方案</strong>
<ul>
<li>从网站中抽取哪些信息</li>
<li>采集频率，即 每天(周/月)重复运行一次爬虫，得到面板数据</li>
</ul>
</li>
<li><strong>执行数据采集</strong>
<ul>
<li>如何改善爬虫运行效率</li>
<li>如何处理原始信息，完整的保存为原始格式html、json，还是只抽取存储当前想要的字段</li>
</ul>
</li>
</ul>
<p>研究人员通常从一组广泛的潜在数据源开始，并根据三个关键考虑因素（有效性、技术可行性和法律/道德风险）剔除其中一些数据源。这三个考虑因素出现在倒金字塔的角落，底部的有效性强调其重要性。鉴于在收集最终数据集之前难以预测其确切特征，研究人员在设计、原型化和完善数据收集时经常重新考虑这些因素。未能解决技术或法律/伦理问题可能意味着网络数据无法有意义地告知研究问题。</p>
<h3 id="21-数据源面临的挑战解决办法">2.1 数据源面临的挑战(解决办法)</h3>
<ol>
<li>探索潜在网络数据源
<ul>
<li>由于网络资源在质量、稳定性和可检索性方面存在巨大差异，研究人员可能倾向于只考虑主要或熟悉的平台。 对数据世界的彻底探索允许令人信服的理论检验和识别可能难以以其他方式注意到的新颖的、新兴的营销现象。</li>
</ul>
</li>
<li>考虑网络爬虫的替代方案
<ul>
<li>由于网络抓取是最流行的网络数据提取方法，研究人员可能会忽视其他提取数据的方法。 API 提供了一种记录和授权的方式来获取许多来源的 Web 数据。 一些来源还提供现成的数据集。 使用此类替代方案可以节省时间并最大限度地减少法律风险。</li>
</ul>
</li>
<li>将数据与场景结合对应起来
<ul>
<li>Web 数据通常没有大量的文档。 尽早识别潜在相关的背景信息对于研究的相关性和有效性至关重要。
<img loading="lazy" src="img/table-2-chanllenges-and-solutions-in-selecting-web-data-sources.png" alt=""  />
</li>
</ul>
</li>
</ol>
<br>
<h3 id="22-设计数据采集方案">2.2 设计数据采集方案</h3>
<ol>
<li>从页面抽取什么信息，从有效性、合法、技术可行性 三个方面论证。</li>
<li>如何进行数据抽样？</li>
<li>以什么频率(每天、周、月)进行数据采集</li>
</ol>
<p><img loading="lazy" src="img/table-3-1-chanllenges-and-solutions-in-selecting-web-data-sources.png" alt=""  />

<img loading="lazy" src="img/table-3-2-chanllenges-and-solutions-in-selecting-web-data-sources.png" alt=""  />
</p>
<br>
<h3 id="23-执行数据采集">2.3 执行数据采集</h3>
<ol>
<li>如何改善爬虫运行效率</li>
<li>如何监控数据质量</li>
<li>整理数据文档(记录)
<img loading="lazy" src="img/table-4-chanllenges-and-solutions-in-selecting-web-data-sources.png" alt=""  />
</li>
</ol>
<br>
<h2 id="部分参考文献">部分参考文献</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">[1]Allard, Thomas, Lea H. Dunn, and Katherine White. &#34;Negative reviews, positive impact: Consumer empathetic responding to unfair word of mouth.&#34; Journal of Marketing 84, no. 4 (2020): 86-108.
[2]Gao, Weihe, Li Ji, Yong Liu, and Qi Sun. &#34;Branding cultural products in international markets: a study of hollywood movies in China.&#34; Journal of Marketing 84, no. 3 (2020): 86-105.
[3]Reich, Taly, and Sam J. Maglio. &#34;Featuring mistakes: The persuasive impact of purchase mistakes in online reviews.&#34; Journal of Marketing 84, no. 1 (2020): 52-65.
[4]Lee, Jeffrey K., and Ann Kronrod. &#34;The strength of weak-tie consensus language.&#34; Journal of Marketing Research 57, no. 2 (2020): 353-374.
[5]Matz, Sandra C., Cristina Segalin, David Stillwell, Sandrine R. Müller, and Maarten W. Bos. &#34;Predicting the personal appeal of marketing images using computational methods.&#34; Journal of Consumer Psychology 29, no. 3 (2019): 370-390.
[6]Dai, Hengchen, and Dennis J. Zhang. &#34;Prosocial goal pursuit in crowdfunding: Evidence from kickstarter.&#34; Journal of Marketing Research 56, no. 3 (2019): 498-517.
[7]Luffarelli, Jonathan, Mudra Mukesh, and Ammara Mahmood. &#34;Let the logo do the talking: The influence of logo descriptiveness on brand equity.&#34; Journal of Marketing Research 56, no. 5 (2019): 862-878.
[8]Bond, Samuel D., Stephen X. He, and Wen Wen. &#34;Speaking for “free”: Word of mouth in free-and paid-product settings.&#34; Journal of Marketing Research 56, no. 2 (2019): 276-290.
[9]Han, Kyuhong, Jihye Jung, Vikas Mittal, Jinyong Daniel Zyung, and Hajo Adam. &#34;Political identity and financial risk taking: Insights from social dominance orientation.&#34; Journal of Marketing Research 56, no. 4 (2019): 581-601.
[10]Netzer, Oded, Alain Lemaire, and Michal Herzenstein. &#34;When words sweat: Identifying signals for loan default in the text of loan applications.&#34; Journal of Marketing Research 56, no. 6 (2019): 960-980.
[11]Toubia, Olivier, Garud Iyengar, Renée Bunnell, and Alain Lemaire. &#34;Extracting features of entertainment products: A guided latent dirichlet allocation approach informed by the psychology of media consumption.&#34; Journal of Marketing Research 56, no. 1 (2019): 18-36.
[12]Van Laer, Tom, Jennifer Edson Escalas, Stephan Ludwig, and Ellis A. Van Den Hende. &#34;What happens in Vegas stays on TripAdvisor? A theory and technique to understand narrativity in consumer reviews.&#34; Journal of Consumer Research 46, no. 2 (2019): 267-285.
[13]Zhong, Ning, and David A. Schweidel. &#34;Capturing changes in social media content: A multiple latent changepoint topic model.&#34; Marketing Science 39, no. 4 (2020): 827-846.
[14]Colicev, Anatoli, Ashwin Malshe, Koen Pauwels, and Peter O&#39;Connor. &#34;Improving consumer mindset metrics and shareholder value through social media: The different roles of owned and earned media.&#34; Journal of Marketing 82, no. 1 (2018): 37-56.
[15]Liu, Xuan, Savannah Wei Shi, Thales Teixeira, and Michel Wedel. &#34;Video content marketing: The making of clips.&#34; Journal of Marketing 82, no. 4 (2018): 86-101.
[16]Liu, Jia, and Olivier Toubia. &#34;A semantic approach for estimating consumer content preferences from online search queries.&#34; Marketing Science 37, no. 6 (2018): 930-952.
[17]Nam, Hyoryung, Yogesh V. Joshi, and P. K. Kannan. &#34;Harvesting brand information from social tags.&#34; Journal of Marketing 81, no. 4 (2017): 88-108.
[18]Packard, Grant, and Jonah Berger. &#34;How language shapes word of mouth&#39;s impact.&#34; Journal of Marketing Research 54, no. 4 (2017): 572-588.
</code></pre></div><br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>社会学研究 | 社会计算驱动的社会科学研究方法</title>
      <link>https://textdata.cn/blog/2022-12-03-social-computing-methodology-about-big-data-and-artificial-intelligence/</link>
      <pubDate>Sat, 03 Dec 2022 00:00:00 +0000</pubDate>
      
      <guid>/blog/2022-12-03-social-computing-methodology-about-big-data-and-artificial-intelligence/</guid>
      <description>一篇关于计算社会学方法论的综述性论文</description>
      <content:encoded><![CDATA[<p><strong><a href="%E7%A4%BE%E4%BC%9A%E8%AE%A1%E7%AE%97%E9%A9%B1%E5%8A%A8%E7%9A%84%E7%A4%BE%E4%BC%9A%E7%A7%91%E5%AD%A6%E7%A0%94%E7%A9%B6%E6%96%B9%E6%B3%95_%E5%91%A8%E6%B6%9B.pdf">周涛,高馨,罗家德.社会计算驱动的社会科学研究方法[J].社会学研究,2022,37(05):130-155+228-229.</a></strong></p>
<p><img loading="lazy" src="img/%e5%91%a8%e6%b6%9b-01.png" alt=""  />

<img loading="lazy" src="img/%e5%91%a8%e6%b6%9b-02.png" alt=""  />

<img loading="lazy" src="img/%e5%91%a8%e6%b6%9b-03.png" alt=""  />

<img loading="lazy" src="img/%e5%91%a8%e6%b6%9b-04.png" alt=""  />

<img loading="lazy" src="img/%e5%91%a8%e6%b6%9b-05.png" alt=""  />

<img loading="lazy" src="img/%e5%91%a8%e6%b6%9b-06.png" alt=""  />

<img loading="lazy" src="img/%e5%91%a8%e6%b6%9b-07.png" alt=""  />

<img loading="lazy" src="img/%e5%91%a8%e6%b6%9b-08.png" alt=""  />

<img loading="lazy" src="img/%e5%91%a8%e6%b6%9b-09.png" alt=""  />

<img loading="lazy" src="img/%e5%91%a8%e6%b6%9b-10.png" alt=""  />

<img loading="lazy" src="img/%e5%91%a8%e6%b6%9b-11.png" alt=""  />

<img loading="lazy" src="img/%e5%91%a8%e6%b6%9b-12.png" alt=""  />

<img loading="lazy" src="img/%e5%91%a8%e6%b6%9b-13.png" alt=""  />

<img loading="lazy" src="img/%e5%91%a8%e6%b6%9b-14.png" alt=""  />

<img loading="lazy" src="img/%e5%91%a8%e6%b6%9b-15.png" alt=""  />

<img loading="lazy" src="img/%e5%91%a8%e6%b6%9b-16.png" alt=""  />

<img loading="lazy" src="img/%e5%91%a8%e6%b6%9b-17.png" alt=""  />

<img loading="lazy" src="img/%e5%91%a8%e6%b6%9b-18.png" alt=""  />

<img loading="lazy" src="img/%e5%91%a8%e6%b6%9b-19.png" alt=""  />

<img loading="lazy" src="img/%e5%91%a8%e6%b6%9b-20.png" alt=""  />

<img loading="lazy" src="img/%e5%91%a8%e6%b6%9b-21.png" alt=""  />
</p>
<br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>数据集 | 90w条中国上市公司高管数据</title>
      <link>https://textdata.cn/blog/2022-11-25-senior-manager-resume-dataset/</link>
      <pubDate>Fri, 25 Nov 2022 00:00:00 +0000</pubDate>
      
      <guid>/blog/2022-11-25-senior-manager-resume-dataset/</guid>
      <description>数据集 | 90w条中国上市公司高管数据</description>
      <content:encoded><![CDATA[<p>90w条中国上市公司高管简历，数据源-新浪财经，统计的日期范围1990-2021年。</p>
<p><br><br></p>
<h2 id="相关论文">相关论文</h2>
<p>这里粘贴部分应用高管数据论文</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">- 何瑛,于文蕾,戴逸驰,王砚羽.高管职业经历与企业创新[J].管理世界,2019,35(11):174-192.
- 杨林,和欣,顾红芳.高管团队经验、动态能力与企业战略突变：管理自主权的调节效应[J].管理世界,2020,36(06):168-188+201+252.
- 周楷唐,麻志明,吴联生.高管学术经历与公司债务融资成本[J].经济研究,2017,52(07):169-183.
- 陆瑶,张叶青,黎波,赵浩宇.高管个人特征与公司业绩——基于机器学习的经验证据[J].管理科学学报,2020,23(02):120-140.
- 柳光强,孔高文.高管经管教育背景与企业内部薪酬差距[J].会计研究,2021,(03):110-121.
- 郑建明,孙诗璐,李金甜.高管文化背景与企业债务成本——基于劳模文化的视角[J].会计研究,2021,(03):137-145.
</code></pre></div><p><br><br></p>
<h2 id="数据集字段">数据集字段</h2>
<blockquote>
<p>数据集的字段含，大多是从「个人简历」中计算衍生出来的。</p>
</blockquote>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">- ID
- 姓名
- 证券代码
- 统计截止日期
- 个人简历
- 国籍
- 籍贯
- 籍贯所在地区代码
- 出生地
- 出生地所在地区代码
- 性别
- 年龄
- 毕业院校
- 学历  1=中专及中专以下； 2=大专； 3=本科； 4=硕士研究生； 5=博士研究生； 6=其他（以其他形式公布的学历，如荣誉博士、函授等）； 7=MBA/EMBA
- 专业
- 职称
- 是否领取薪酬
- 报告期报酬总额
- 年末持股数
- 是否高管团队成员
- 是否董事会成员
- 是否独立董事
- 是否兼任董事长和CEO
- 是否监事
- 具体职务
</code></pre></div><p><br><br></p>
<h2 id="读取数据">读取数据</h2>
<ul>
<li>数据文件 <code>高管数据.xlsx</code></li>
<li>强制某几个字段的数据类型</li>
<li>将字段 「统计截止日期」 转化为 datetime 类型</li>
</ul>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">import pandas as pd

# 导入数据，
df = pd.read_excel(&#39;高管数据.xlsx&#39;, 
                   #保证这两个字段是字符串格式
                   converters={&#39;证券代码&#39;: str, 
                               &#39;ID&#39;: str})

#将字段「统计截止日期」 整理为datetime格式
df[&#39;统计截止日期&#39;] = pd.to_datetime(df[&#39;统计截止日期&#39;])
#显示前1条记录
df.head(1)
</code></pre></div><p>Run</p>
<p><img loading="lazy" src="img/df.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">df.columns
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">    Index([&#39;ID&#39;, &#39;姓名&#39;, &#39;证券代码&#39;, &#39;统计截止日期&#39;, &#39;个人简历&#39;, &#39;国籍&#39;, &#39;籍贯&#39;, &#39;籍贯所在地区代码&#39;, &#39;出生地&#39;,
           &#39;出生地所在地区代码&#39;, &#39;性别&#39;, &#39;年龄&#39;, &#39;毕业院校&#39;, &#39;学历&#39;, &#39;专业&#39;, &#39;职称&#39;, &#39;是否领取薪酬&#39;, &#39;报告期报酬总额&#39;,
           &#39;津贴&#39;, &#39;年末持股数&#39;, &#39;是否高管团队成员&#39;, &#39;是否董事会成员&#39;, &#39;是否独立董事&#39;, &#39;是否兼任董事长和CEO&#39;, &#39;是否监事&#39;,
           &#39;具体职务&#39;],
          dtype=&#39;object&#39;)
</code></pre></div><br>
<p>数据集记录数共</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">len(df)
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">    900887
</code></pre></div><br>
<p>数据统计日期范围自 1990年12月10日 至 2021年7月19日</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">df[&#39;统计截止日期&#39;].sort_values()
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">    900886   1990-12-10
    900884   1990-12-10
    900883   1990-12-10
    900882   1990-12-10
    900881   1990-12-10
                ...    
    59734    2021-07-19
    59733    2021-07-19
    59731    2021-07-19
    59736    2021-07-19
    59742    2021-07-19
    Name: 统计截止日期, Length: 900887, dtype: datetime64[ns]
</code></pre></div><br>
<p>数据集字段 有</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">df.columns
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">    Index([&#39;ID&#39;, &#39;姓名&#39;, &#39;证券代码&#39;, &#39;统计截止日期&#39;, &#39;个人简历&#39;, &#39;国籍&#39;, &#39;籍贯&#39;, &#39;籍贯所在地区代码&#39;, &#39;出生地&#39;,
           &#39;出生地所在地区代码&#39;, &#39;性别&#39;, &#39;年龄&#39;, &#39;毕业院校&#39;, &#39;学历&#39;, &#39;专业&#39;, &#39;职称&#39;, &#39;是否领取薪酬&#39;, &#39;报告期报酬总额&#39;,
           &#39;津贴&#39;, &#39;年末持股数&#39;, &#39;是否高管团队成员&#39;, &#39;是否董事会成员&#39;, &#39;是否独立董事&#39;, &#39;是否兼任董事长和CEO&#39;, &#39;是否监事&#39;,
           &#39;具体职务&#39;],
          dtype=&#39;object&#39;)
</code></pre></div><br>
<p>截止统计日期时大于90岁的高管 记录有</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">df[df[&#39;年龄&#39;]&gt;90]
</code></pre></div><p><img loading="lazy" src="img/df2.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="相关内容">相关内容</h2>
<p><strong>何瑛,于文蕾,戴逸驰,王砚羽.高管职业经历与企业创新[J].管理世界,2019,35(11):174-192.</strong></p>
<blockquote>
<p>摘要:管理的本质是一种实践,在某些情形下,<strong>阅历比简历更重要,丰富的职业经历有助于企业高管形成多元化的思维结构、广阔的管理视野、丰富的社会资源和过人的胆识,也是塑造复合型人才的重要路径</strong>。本文基于行为金融理论和高层梯队理论,手工搜集整理了2007～2016年中国沪深A股上市公司高管职业经历独特数据集,从<strong>职能部门、企业、行业、组织机构和地域类型</strong>五个维度构建了复合型职业经历的衡量指标——职业经历丰富度指数,对CEO职业经历与企业创新的影响因素和影响机理进行理论解释、数据分析和验证。研究结果表明:CEO职业经历越丰富,企业创新水平越高,<strong>其中跨企业经历对创新水平的影响最为显著</strong>,其次是跨行业经历和跨组织机构经历,跨职能部门经历和跨地域经历对企业创新水平的影响最小;影响因素方面,基于公司内外部治理的视角发现,市场化程度越低、企业融资约束程度越低时,CEO职业经历丰富度对企业创新水平的促进作用越明显,国有企业CEO职业经历丰富度对企业创新水平的促进作用更强,而股权制衡度对CEO职业经历丰富度与企业创新水平的调节作用不明显;影响机理方面,CEO复合型职业经历主要是通过丰富高管的社会网络资源以及增强高管的风险偏好倾向,从而提升企业的创新水平。本文的研究结论拓展了企业创新影响因素及高管职业经历经济后果领域的相关文献,将复合型人才的影响从国家宏观层面拓展到企业微观层面,为企业高层次人才的招聘和选拔提供新的证据支持。 中提到高管的创新</p>
</blockquote>
<p>高管，一般是有多个企业经历的， 如何将高管职业经历转化为可以计算和比较的 <strong>高管职业经历向量</strong> 呢？</p>
<p><a href="https://mp.weixin.qq.com/s/1bs8ZS4upx25C08f2uBjBA"><strong>如何用「图嵌入」将企业、高管职业经历表征为向量数据</strong></a> , 有了向量可以</p>
<ul>
<li>计算高管之间的相似度</li>
<li>企业高管团队异质性，计算高管向量之间的距离</li>
<li>&hellip;</li>
</ul>
<p><br><br></p>
<h2 id="数据获取">数据获取</h2>
<p>转发集赞 30+ ， 加微信 372335839, 备注【姓名-学校-专业-高管数据集】获取本数据集。</p>
<br>
<br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>FinBERT | 金融文本BERT模型，可情感分析、识别ESG和FLS类型</title>
      <link>https://textdata.cn/blog/2022-11-17-finbert-finance-bert-model/</link>
      <pubDate>Wed, 16 Nov 2022 00:00:00 +0000</pubDate>
      
      <guid>/blog/2022-11-17-finbert-finance-bert-model/</guid>
      <description>金融语言模型</description>
      <content:encoded><![CDATA[<h2 id="finbert介绍">FinBERT介绍</h2>

<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
  <iframe src="https://www.youtube.com/embed/uj4hm7Lr2Wo" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video"></iframe>
</div>

<br>
<p>FinBERT， 是使用49亿词的英文金融语料库数据，生成的BERT预训练语言模型。语料库上大小为 49亿个词。</p>
<ul>
<li>公司报告 10-K 和 10-Q：25亿个词</li>
<li>电话会议记录：13亿个词</li>
<li>分析师报告：11亿个词</li>
</ul>
<p>FinBERT开发者在多个金融 NLP 任务上对 FinBERT 预训练模型进行了微调，均优于传统机器学习模型、深度学习模型和微调 BERT 模型。 所有经过微调的 FinBERT 模型都公开托管在 Huggingface 🤗。  目前支持包括<strong>情绪分析、ESG 分类、前瞻性陈述 (FLS) 分类</strong>。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">Huang, Allen H., Hui Wang, and Yi Yang. &#34;FinBERT: A large language model for extracting information from financial text.&#34; Contemporary Accounting Research (2022).

摘要（翻译）: 我们开发了 FinBERT，这是一种适用于金融领域的最先进的大型语言模型。我们表明，FinBERT 结合了金融知识，可以更好地总结金融文本中的上下文信息。使用分析报告中研究人员标记的句子样本，我们证明 FinBERT 大大优于 Loughran 和 McDonald 词典以及其他机器学习算法，包括朴素贝叶斯、支持向量机、随机森林、卷积神经网络和长短期记忆，在情感分类中。我们的结果表明，FinBERT 擅长识别其他算法错误标记为中性的句子的正面或负面情绪，这可能是因为它使用了金融文本中的上下文信息。我们发现，FinBERT 优于其他算法，以及 Google 的原始双向编码器表示形式来自 transformers (BERT) 模型，当训练样本量较小且文本中包含一般文本中不常用的金融词时，这种优势尤为突出。 FinBERT 在识别与环境、社会和治理问题相关的讨论方面也优于其他模型。最后，我们表明，与 FinBERT 相比，其他方法低估了收益电话会议的文本信息量至少 18%。我们的结果对学术研究人员、投资专业人士和金融市场监管机构具有重要意义。
</code></pre></div><br>
<h3 id="finbert功能">FinBERT功能</h3>
<p>具体来说，FinBERT有以下内容：</p>
<ul>
<li><a href="https://huggingface.co/yiyanghkust/finbert-pretrain">FinBERT-Pretrained</a>： 针对大规模金融文本的预训练 FinBERT 模型。</li>
<li><a href="https://huggingface.co/yiyanghkust/finbert-tone">FinBERT-Sentiment</a>： 用于情感分类任务。</li>
<li><a href="https://huggingface.co/yiyanghkust/finbert-esg">FinBERT-ESG</a>： 用于 ESG 分类任务。</li>
<li><a href="https://huggingface.co/yiyanghkust/finbert-fls">FinBERT-FLS</a>： 用于前瞻性陈述（FLS）分类任务。</li>
</ul>
<br>
<h3 id="环境配置">环境配置</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">pip install transformers==4.18.0
</code></pre></div><p>本次实验使用的transformers版本为</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">import transformers
transformers.__version__
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">4.18.0
</code></pre></div><br>
<h3 id="代码下载">代码下载</h3>
<p><a href="FinBERT.ipynb">点击下载</a></p>
<p><br><br></p>
<h2 id="一情感分析">一、情感分析</h2>
<p>金融文本情绪可以调动管理者、信息中介和投资者的观点和意见, 因此分析金融文本情感(情绪)是有价值的。 FinBERT-Sentiment 是一个 FinBERT 模型，它根据标准普尔 500 家公司的分析师报告中的 10,000 个手动注释的句子进行了Fine-tune(微调)。</p>
<blockquote>
<p>Fine-Tune微调 是 深度学习的一种语言处理技术，可以在前人（已有）的语言模型文件基础上加入少量新场景的文本数据进行更新训练，生成出新场景的语言模型。</p>
</blockquote>
<ul>
<li><strong>输入</strong>：金融文本。</li>
<li><strong>输出</strong>：Positive, Neutral or Negative.</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">BertTokenizer</span><span class="p">,</span> <span class="n">BertForSequenceClassification</span><span class="p">,</span> <span class="n">pipeline</span>

<span class="c1">#首次运行，因为会下载FinBERT模型，耗时会比较久</span>
<span class="n">senti_finbert</span> <span class="o">=</span> <span class="n">BertForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">&#39;yiyanghkust/finbert-tone&#39;</span><span class="p">,</span><span class="n">num_labels</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">senti_tokenizer</span> <span class="o">=</span> <span class="n">BertTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">&#39;yiyanghkust/finbert-tone&#39;</span><span class="p">)</span>
<span class="n">senti_nlp</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span><span class="s2">&#34;text-classification&#34;</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">senti_finbert</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">=</span><span class="n">senti_tokenizer</span><span class="p">)</span>
</code></pre></div><p><br>使用3条测试文本进行测试</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1"># 待分析的文本数据</span>
<span class="n">senti_results</span> <span class="o">=</span> <span class="n">senti_nlp</span><span class="p">([</span><span class="s1">&#39;growth is strong and we have plenty of liquidity.&#39;</span><span class="p">,</span> 
                           <span class="s1">&#39;there is a shortage of capital, and we need extra financing.&#39;</span><span class="p">,</span>
                           <span class="s1">&#39;formulation patents might protect Vasotec to a limited extent.&#39;</span><span class="p">])</span>
<span class="n">senti_results</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">    [{&#39;label&#39;: &#39;Positive&#39;, &#39;score&#39;: 1.0},
     {&#39;label&#39;: &#39;Negative&#39;, &#39;score&#39;: 0.9952379465103149},
     {&#39;label&#39;: &#39;Neutral&#39;, &#39;score&#39;: 0.9979718327522278}]
</code></pre></div><p><br><br></p>
<h2 id="二esg分类">二、ESG分类</h2>
<p>ESG 分析可以帮助投资者确定企业的长期可持续性并识别相关风险。 FinBERT-ESG 是一个 FinBERT 模型，根据来自公司 ESG 报告和年度报告的 2,000 个手动注释句子进行微调。</p>
<ul>
<li><strong>输入</strong>：金融文本。</li>
<li><strong>输出</strong>：Environmental, Social, Governance or None.</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">BertTokenizer</span><span class="p">,</span> <span class="n">BertForSequenceClassification</span><span class="p">,</span> <span class="n">pipeline</span>

<span class="n">esg_finbert</span> <span class="o">=</span> <span class="n">BertForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">&#39;yiyanghkust/finbert-esg&#39;</span><span class="p">,</span><span class="n">num_labels</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="n">esg_tokenizer</span> <span class="o">=</span> <span class="n">BertTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">&#39;yiyanghkust/finbert-esg&#39;</span><span class="p">)</span>
<span class="n">esg_nlp</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span><span class="s2">&#34;text-classification&#34;</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">esg_finbert</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">=</span><span class="n">esg_tokenizer</span><span class="p">)</span>
</code></pre></div><p><br>使用3条测试文本进行测试</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">esg_results</span> <span class="o">=</span> <span class="n">esg_nlp</span><span class="p">([</span><span class="s1">&#39;Managing and working to mitigate the impact our operations have on the environment is a core element of our business.&#39;</span><span class="p">,</span>
                      <span class="s1">&#39;Rhonda has been volunteering for several years for a variety of charitable community programs.&#39;</span><span class="p">,</span>
                      <span class="s1">&#39;Cabot</span><span class="se">\&#39;</span><span class="s1">s annual statements are audited annually by an independent registered public accounting firm.&#39;</span><span class="p">,</span>
                      <span class="s1">&#39;As of December 31, 2012, the 2011 Term Loan had a principal balance of $492.5 million.&#39;</span><span class="p">])</span>

<span class="n">esg_results</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">    [{&#39;label&#39;: &#39;Environmental&#39;, &#39;score&#39;: 0.9805498719215393},
     {&#39;label&#39;: &#39;Social&#39;, &#39;score&#39;: 0.9906041026115417},
     {&#39;label&#39;: &#39;Governance&#39;, &#39;score&#39;: 0.6738430857658386},
     {&#39;label&#39;: &#39;None&#39;, &#39;score&#39;: 0.9960240125656128}]
</code></pre></div><p><br><br></p>
<h2 id="三fls识别">三、FLS识别</h2>
<p><strong>前瞻性陈述 (FLS)</strong> 告知投资者经理人对公司未来事件或结果的信念和意见。 从公司报告中识别前瞻性陈述可以帮助投资者进行财务分析。 FinBERT-FLS 是一个 FinBERT 模型，它基于罗素 3000 家公司年报的管理讨论和分析部分的 3,500 个手动注释的句子进行了微调。</p>
<ul>
<li><strong>输入</strong>：金融文本。</li>
<li><strong>输出</strong>：Specific-FLS(特定 FLS) , Non-specific FLS(非特定 FLS),  Not-FLS(非 FLS)。</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">BertTokenizer</span><span class="p">,</span> <span class="n">BertForSequenceClassification</span><span class="p">,</span> <span class="n">pipeline</span>

<span class="n">fls_finbert</span> <span class="o">=</span> <span class="n">BertForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">&#39;yiyanghkust/finbert-fls&#39;</span><span class="p">,</span><span class="n">num_labels</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">fls_tokenizer</span> <span class="o">=</span> <span class="n">BertTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">&#39;yiyanghkust/finbert-fls&#39;</span><span class="p">)</span>

<span class="n">fls_nlp</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span><span class="s2">&#34;text-classification&#34;</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">fls_finbert</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">=</span><span class="n">fls_tokenizer</span><span class="p">)</span>
</code></pre></div><p><br> 使用3条测试文本进行测试</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">fls_results</span> <span class="o">=</span> <span class="n">fls_nlp</span><span class="p">([</span><span class="s1">&#39;we expect the age of our fleet to enhance availability and reliability due to reduced downtime for repairs.&#39;</span><span class="p">,</span>
                      <span class="s1">&#39;on an equivalent unit of production basis, general and administrative expenses declined 24 percent from 1994 to $.67 per boe.&#39;</span><span class="p">,</span>
                      <span class="s1">&#39;we will continue to assess the need for a valuation allowance against deferred tax assets considering all available evidence obtained in future reporting periods.&#39;</span><span class="p">])</span>


<span class="n">fls_results</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">    [{&#39;label&#39;: &#39;Specific FLS&#39;, &#39;score&#39;: 0.7727874517440796},
     {&#39;label&#39;: &#39;Not FLS&#39;, &#39;score&#39;: 0.9905241131782532},
     {&#39;label&#39;: &#39;Non-specific FLS&#39;, &#39;score&#39;: 0.975904107093811}]
</code></pre></div><p><br><br></p>
<h2 id="文档及引用说明">文档及引用说明</h2>
<ul>
<li>
<p>文档github地址 <a href="https://github.com/yya518/FinBERT">https://github.com/yya518/FinBERT</a></p>
</li>
<li>
<p>作者博客: <a href="https://yya518.github.io/research">https://yya518.github.io/research</a></p>
</li>
</ul>
<br>
<p>Huang, Allen H., Hui Wang, and Yi Yang. &ldquo;FinBERT: A large language model for extracting information from financial text.&rdquo; <strong>Contemporary Accounting Research (2022)</strong>.</p>
<p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>转载 | 金融学文本大数据挖掘方法与研究进展</title>
      <link>https://textdata.cn/blog/2022-11-16-literature-review-textmining-in-finance-yao2020/</link>
      <pubDate>Wed, 16 Nov 2022 00:00:00 +0000</pubDate>
      
      <guid>/blog/2022-11-16-literature-review-textmining-in-finance-yao2020/</guid>
      <description>description用于SEO优化</description>
      <content:encoded><![CDATA[<blockquote>
<p>姚加权,张锟澎,罗平.金融学文本大数据挖掘方法与研究进展[J].经济学动态,2020(04):143-158.</p>
</blockquote>
<h2 id="摘要">摘要</h2>
<p>在金融学领域的传统实证研究中，所用数据多局限于财务报表和股票市场数据等结构化数据。而在大数据时代，计算机技术的进步使得数据类型不断丰富，研究者开始将非结构化的文本大数据引入到金融学领域的研究中，其主要包括<strong>上市公司披露文本</strong>、<strong>财经媒体报道</strong>、<strong>社交网络文本</strong>、网络搜索指数以及 P2P 网络借贷文本等，并对 <strong>文本可读性</strong>、<strong>语气语调</strong>、<strong>相似性</strong> 以及 <strong>语义特征</strong> 展开研究。本文首先介绍了金融学领域文本大数据挖掘步骤和方法，描述了语料获取、预处理过程、文档表示以及文档的特征抽取；然后根据不同的文本信息来源，梳理了金融学文本大数据的研究进展；最后对未来金融学文本大数据的研究方法和研究内容进行了展望。</p>
<p>关键词：文本大数据 文本分析 机器学习 深度学习 数据挖掘</p>
<p><img loading="lazy" src="img/01.png" alt=""  />

<img loading="lazy" src="img/02.png" alt=""  />

<img loading="lazy" src="img/03.png" alt=""  />

<img loading="lazy" src="img/04.png" alt=""  />

<img loading="lazy" src="img/05.png" alt=""  />

<img loading="lazy" src="img/06.png" alt=""  />

<img loading="lazy" src="img/07.png" alt=""  />

<img loading="lazy" src="img/08.png" alt=""  />

<img loading="lazy" src="img/09.png" alt=""  />

<img loading="lazy" src="img/10.png" alt=""  />

<img loading="lazy" src="img/11.png" alt=""  />

<img loading="lazy" src="img/12.png" alt=""  />
</p>
<br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>PNAS | 使用语义距离测量一个人的创新力(发散思维)得分</title>
      <link>https://textdata.cn/blog/2022-11-14-pnas_naming_unrelated_words_predicts_creativity/</link>
      <pubDate>Mon, 14 Nov 2022 00:00:00 +0000</pubDate>
      
      <guid>/blog/2022-11-14-pnas_naming_unrelated_words_predicts_creativity/</guid>
      <description>使用语义距离测量一个人的创新力(发散思维)得分</description>
      <content:encoded><![CDATA[<br>
<p>传统测量 <strong>被试者创造力</strong> 存在耗费时间、主观性太强、缺乏客观性，且所得到的分值是不稳定的，无法跨时间、文化、群体进行分值比较。该研究分析了创新力的两大理论，即联系理论和执行理论，即创新力是包含思维的广度和深度两方面。</p>
<ul>
<li><strong>联系理论(广度)</strong> 负责搜寻所有可能方案的集合，增加集合的规模，体现思维的广度。</li>
<li><strong>执行理论(深度)</strong> 负责寻找最佳方案，并将方案落实执行，体现思维的深度。</li>
</ul>
<p>结合Glove词嵌入技术，将每个词理解为一个技术或知识，两词语语义越相似，发散性越低。</p>
<p>文中让被试按照一定规则，随意填写10个名词，使用其中7个有效词语测量被试的创新力(发散性)思维。可以简单的把7个词理解为知识或者技术，7个词语会形成21种词语对(组合)。最后求均值可以测量出被试词语对的语义距离体现创新发散性的强度。<strong>文末含案例代码</strong></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">Olson, J.A., Nahas, J., Chmoulevitch, D., Cropper, S.J. and Webb, M.E., 2021. Naming unrelated words predicts creativity. Proceedings of the National Academy of Sciences, 118(25), p.e2022340118.
</code></pre></div><p><br><br></p>
<h2 id="一摘要">一、摘要</h2>
<p><strong>一些理论认为，有 创造力 的人能够产生更多 发散性 的想法。如果这是正确的，简单地让被试写 N 个不相关的单词，然后测量这N个词的语义距离， 作为 #发散思维 的客观衡量标准</strong>。为了验证这一假设，我们要求 8,914 名参与者说出 10 个彼此尽可能不同的单词。</p>
<p>然后计算算法估计单词之间的平均语义距离；<strong>相关词（例如 cat 和 dog）比不相关词（例如 cat 和 thimble）的距离更短。我们预测，产生更大语义距离的人也会在传统的创造力测量中得分更高</strong>。</p>
<p>在研究 1 中，我们发现语义距离与两个广泛使用的创造力测量（替代用途任务和桥接关联差距任务）之间存在中度至强相关性。在研究 2 中，参与者来自 98 个国家，语义距离仅因基本人口变量而略有不同。在一系列已知可预测创造力的问题上，语义距离与表现之间也存在正相关关系。</p>
<p>总体而言， <strong>语义距离</strong> 与已建立的 创造力测量 的相关性至少与这些测量彼此之间的相关性一样强。 因此，在我们所说的发散关联任务中命名不相关的词可以作为发散思维的简短、可靠和客观的衡量标准。</p>
<br>
<h2 id="二创新力理论">二、创新力理论</h2>
<p>想出 3 个尽可能不同的词。根据两种主要的创造力理论 (1, 2)，选择这些词依赖于产生 #远程联想 ，同时抑制 #常见联想 。</p>
<p>#联想理论 (Associative Theory)认为，有创造力的人具有语义记忆结构，可以更容易地链接远程元素 (3-6)。</p>
<p>#执行理论 (Executive Theory) 侧重于自上而下的注意力控制；创造性的解决方案来自于监测和抑制共同的联想 (2, 7)。</p>
<p>基于这些理论，我们假设 <strong>填写n个无关单词的任务</strong> 可以可靠地衡量 #语言创造力 。 <strong>创造力有两个主要的心理成分， 收敛思维和发散思维，它们在产生创意输出时协同工作</strong>。收敛性思维任务衡量评估多种刺激并得出最适当响应的能力，例如问题的最佳解决方案 (3, 8-10)。这些任务往往更容易得分，因为只有一小部分正确答案。<strong>相比之下，发散思维任务通常使用开放式问题来衡量一个人产生各种解决方案的能力</strong> (11-13)。它们通常需要更长的回答(文本)，因此更难客观评分。</p>
<br>
<h2 id="三创新力测量">三、创新力测量</h2>
<h3 id="31--替代用途任务">3.1  替代用途任务</h3>
<p>最常见的发散思维测量是 <strong>替代用途任务</strong> Alternative Uses Task (14, 15)，在该任务中，参与者生成常见物体的用途，例如回形针或鞋子。使用常用的评分方法 (16)，评分者然后根据三个组成部分来判断回答：</p>
<ul>
<li>灵活性，产生的不同用途类别的数量；</li>
<li>独创性，每次使用相对于样本的其余部分的稀有程度，这对创造力特别重要（17、18）；和</li>
<li>流畅度，一共产生了多少次使用。</li>
</ul>
<br>
<h3 id="32-离散联系任务">3.2 离散联系任务</h3>
<p>本研究作者开发了 <strong>离散联系任务</strong> (Divergent Association Task， DAT) 的网站， <strong>填写你想到的10个不相关词语， 创造力越丰富的人，填写的词语语义距离往往会更远</strong>。</p>
<p><a href="https://www.datcreativity.com/">https://www.datcreativity.com/</a></p>
<p><img loading="lazy" src="img/1_pnas_divergent_association_task_mainpage.png" alt=""  />
</p>
<h3 id="被试填写10个单词的规则">被试填写10个单词的规则</h3>
<ol>
<li>只能填写英文单词</li>
<li>只能是名词(如事情、物体、概念)</li>
<li>不能填 专有名词（例如，特定的人或地点）</li>
<li>不能填写 专业词（比如技术词）</li>
<li>自己思考这些词，不要只看周围环境的物体。</li>
</ol>
<h3 id="dat算法实现">DAT算法实现</h3>
<ol>
<li>使用Glove预训练模型</li>
<li>选前7个词(一共10个词)， 存在 21个词对（组合）</li>
<li>对21词对， 分别计算词向量的余弦距离，分别乘以100。最终求均值得到DAT得分。</li>
</ol>
<blockquote>
<p>下图是大邓第二次填写得到的DAT得分，第一次只超过了6%的人，这方法第一次准，再测就知道如何提高DAT得分。</p>
</blockquote>
<p><img loading="lazy" src="img/2_pnas_divergent_association_task_result.png" alt=""  />
</p>
<p>DAT得分范围0-200， 得分为0可能是7个有效词之间语义相同，而得分200可能是有效词之间彼此语义完全不相同。实践中，得分大多处于65~90之间，且很少超过100。</p>
<p><img loading="lazy" src="img/pnas_dat_score_low_median_high.jpg" alt=""  />
</p>
<blockquote>
<p>词嵌入技术可以把每个词转化为等长的向量，而不同词语共处于相同的语义空间中。常见的词嵌入技术有word2vec、Glove、flastText等，因为最近有学者在 <strong>替代用途任务</strong>(Alternative Uses Task）中用过Glove算法，本文采用Glove算法。本研究使用的Glove预训练模型来自Common Crawl Corpus项目，该项目拥有数十亿网页文本数据。</p>
<p>为了提供冗余， 只采用 被试者 填写的前7个词作为有效单词(DAT的被试需要填写10个词)。DAT得分是这些词之间的语义距离的平均值，具体计算方法， 7个词两两相关的组合有 42种组合， 选择其中最有可能的 21 个语义组合。</p>
</blockquote>
<br>
<h2 id="四实验">四、实验</h2>
<p>这种发散思维的操作化是基于创造力的联想和执行控制理论。 更高的分数将显示出更大的能力来利用更远程的关联 (3-5) 或抑制过度相关的关联 (2, 7)。</p>
<p>在研究 1 中，我们通过将 DAT 与其他两种创造力测量方法进行比较来检验这一假设：替代用途任务 (15) 和桥接关联差距任务 (36)。
<img loading="lazy" src="img/pnas_dat_aut_algo_valid_num.jpg" alt=""  />
</p>
<p>在研究 2 中，我们测试了这些分数如何随人口统计而变化，以及它们是否与更大数据集中与发散性思维相关的其他测量值相关 (9, 37)。 这些研究评估了语义距离是否可以作为发散思维的可靠指标。
<img loading="lazy" src="img/pnas_dat_gender_age.jpg" alt=""  />
</p>
<br>
<h2 id="五讨论">五、讨论</h2>
<p>研究结果表面， 让被试简单的填写10个不想管单词的任务可以作为 测量发散思维 的可靠衡量标准。在研究中， 将这项任务的表现与已有的两种创造力量表做了比较，具有很高的相关性。</p>
<p>总体而言支持了语义发散性，尽管这种联系背后的确切机制尚不清楚，但在创新力最主要的两个理论，即联想理论或执行理论 的联系网络中衡量网络的范围或效率。</p>
<p><strong>DAT算法表现稳定，方差不随人口统计特征变化出现显著性变化（研究2），可以在跨年龄、跨性别的情况下应用</strong>。</p>
<br>
<h3 id="51-dat的优点">5.1 DAT的优点</h3>
<ul>
<li>操作简单，快捷，客观，节约了大量的人力时间，又能保证客观性。</li>
<li>得分绝对，可比较，可以用于测量不同群体(种族、文化、性别、年龄)的创造力得分。</li>
<li>对被试友好，一般一两分钟即可完成。</li>
</ul>
<h3 id="52-dat的不足">5.2 DAT的不足</h3>
<ul>
<li>创造力有发散性和执行力，发散性负责搜选所有方案集合的规模，而执行力是从方案集中选出最优方案并将其执行。DAT测量的仅仅是发散性思维。</li>
<li>被试可能通过填写稀奇的词语提高DAT得分。</li>
<li>只有短短几分钟，被试可能很难短时间内了解实验规则。</li>
</ul>
<h3 id="53-未来展望">5.3 未来展望</h3>
<p>DAT得分取决于Glove模型、语料库(数据集), 更新词模型或语料库，被试的DAT得分会发生变化。为简单起见，本研究使用免费的预训练模型， 通过一些努力，未来研究者可以对不同时期，不同国家的语料库来训练Glove模型。随着特定单词关联或多或少的联系， 更新的模型将会自动考虑这些变化，这将允许DAT得分跨越文化跨越时代，进行创新力的比较。</p>
<p><br><br></p>
<h2 id="代码">代码</h2>
<p>代码的文档说明请点击 github仓库地址 <a href="https://github.com/jayolson/divergent-association-task">https://github.com/jayolson/divergent-association-task</a> 查看。这里仅粘贴作者源代码，源代码需要配置好才可运行。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">dat</span>

<span class="c1">## 从 https://nlp.stanford.edu/projects/glove/ 下载Glove模型</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">dat</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="s2">&#34;glove.840B.300d.txt&#34;</span><span class="p">,</span> <span class="s2">&#34;words.txt&#34;</span><span class="p">)</span>

<span class="c1"># 验证词语，如输入的是词组，代码会将其转为连线形式的单词</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">validate</span><span class="p">(</span><span class="s2">&#34;cul de sac&#34;</span><span class="p">))</span> 
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">cul-de-sac
</code></pre></div><br>
<p>计算两个词语之间的语义距离</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">distance</span><span class="p">(</span><span class="s2">&#34;cat&#34;</span><span class="p">,</span> <span class="s2">&#34;dog&#34;</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">distance</span><span class="p">(</span><span class="s2">&#34;cat&#34;</span><span class="p">,</span> <span class="s2">&#34;thimble&#34;</span><span class="p">))</span> 
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">0.1983
0.8787
</code></pre></div><br>
<p>计算词对的DAT得分（语义cosine距离*100）</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">dat</span><span class="p">([</span><span class="s2">&#34;cat&#34;</span><span class="p">,</span> <span class="s2">&#34;dog&#34;</span><span class="p">],</span> <span class="mi">2</span><span class="p">))</span> 
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">dat</span><span class="p">([</span><span class="s2">&#34;cat&#34;</span><span class="p">,</span> <span class="s2">&#34;thimble&#34;</span><span class="p">],</span> <span class="mi">2</span><span class="p">))</span> 
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">19.83
87.87
</code></pre></div><br>
<p>假设有三个人分别都填写10个词，选其前7个词作为有效词。有效词如下，</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">low</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&#34;arm&#34;</span><span class="p">,</span> <span class="s2">&#34;eyes&#34;</span><span class="p">,</span> <span class="s2">&#34;feet&#34;</span><span class="p">,</span> <span class="s2">&#34;hand&#34;</span><span class="p">,</span> <span class="s2">&#34;head&#34;</span><span class="p">,</span> <span class="s2">&#34;leg&#34;</span><span class="p">,</span> <span class="s2">&#34;body&#34;</span><span class="p">]</span>
<span class="n">average</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&#34;bag&#34;</span><span class="p">,</span> <span class="s2">&#34;bee&#34;</span><span class="p">,</span> <span class="s2">&#34;burger&#34;</span><span class="p">,</span> <span class="s2">&#34;feast&#34;</span><span class="p">,</span> <span class="s2">&#34;office&#34;</span><span class="p">,</span> <span class="s2">&#34;shoes&#34;</span><span class="p">,</span> <span class="s2">&#34;tree&#34;</span><span class="p">]</span>
<span class="n">high</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&#34;hippo&#34;</span><span class="p">,</span> <span class="s2">&#34;jumper&#34;</span><span class="p">,</span> <span class="s2">&#34;machinery&#34;</span><span class="p">,</span> <span class="s2">&#34;prickle&#34;</span><span class="p">,</span> <span class="s2">&#34;tickets&#34;</span><span class="p">,</span> <span class="s2">&#34;tomato&#34;</span><span class="p">,</span> <span class="s2">&#34;violin&#34;</span><span class="p">]</span>

<span class="c1"># Compute the DAT score (transformed average cosine distance of first 7 valid words)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">dat</span><span class="p">(</span><span class="n">low</span><span class="p">))</span> <span class="c1"># 50</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">dat</span><span class="p">(</span><span class="n">average</span><span class="p">))</span> <span class="c1"># 78</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">dat</span><span class="p">(</span><span class="n">high</span><span class="p">))</span> <span class="c1"># 95</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">50
78
95
</code></pre></div><p>需要注意pnas作者公开的代码只能用在英文，且无法自己训练Glove模型。如果想基于自有数据集（中文、英文），训练自有Glove模型，需要学习</p>
<ul>
<li>如何训练Glove模型</li>
<li>如何导入训练好的Glove模型</li>
<li>如何计算中英文dat得分</li>
</ul>
<p>相关知识点已更新至我的录播课课程 <a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></p>
<p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>小规模金融并购、投资事件图谱设计概述与数据构成解析</title>
      <link>https://textdata.cn/blog/2022-11-07-financial-invest-merge/</link>
      <pubDate>Mon, 07 Nov 2022 00:00:00 +0000</pubDate>
      
      <guid>/blog/2022-11-07-financial-invest-merge/</guid>
      <description>小规模金融并购、投资事件图谱设计概述与数据构成解析</description>
      <content:encoded><![CDATA[<h2 id="作者">作者</h2>
<p>刘焕勇，NLP开源爱好者与践行者，主页：https://liuhuanyong.github.io。</p>
<p>就职于360人工智能研究院、曾就职于中国科学院软件研究所。</p>
<p>老刘说NLP，将定期发布语言资源、工程实践、技术总结等内容，欢迎关注。</p>
<br>
<p>事件图谱是当前的一个十分有趣的话题，我们在前面的事件图谱系列文章中对事件图谱进行了论述。</p>
<p>例如文章《技术思考：面向落地应用的事件类图谱划分、关键问题及其与知识图谱的对比辨析》、《事件图谱应用：智能金融与情报分析中的七大应用潜在场景概述》、《事件图谱技术：基于触发词的事件句识别方法与关键流程总结》等。</p>
<p>同样本着技术具像化的原则，为了让大家对具体事件图谱有个清晰的直观的认识，本文我们介绍一个自建的金融事件图谱，涵盖并购和投资两大类事件类型，从金融事件图谱设计概述、投资事件图谱数据介绍以及并购事件图谱数据介绍三个角度进行论述，供大家一起参考。</p>
<br>
<h2 id="一金融事件图谱设计概述">一、金融事件图谱设计概述</h2>
<p>事件知识图谱EKG（event knowledge graph）是当前事件类图谱的一种，在这里，我更倾向于认为这个图谱本身更倾向于为一个事件知识库，而非实体知识图谱。</p>
<p><strong>事件知识图谱的工作主要围绕事件知识本身进行展开，关注点在于事件内部信息，如ACE中的8大类事件，将这几类事件中的信息进行抽取和填充就能够得到一个以特定事件类型作为分类标准的事件知识库，如婚姻事件库、爆炸事件库等。</strong></p>
<p>而相对应的，领域事件图谱显得更为重要，金融领域作为一个需求较为明显的领域，其建模能力更具代表性，例如，我们可以对事件图谱进行本体定义：</p>
<table>
<thead>
<tr>
<th style="text-align:left"><strong>事件类型</strong></th>
<th style="text-align:left"><strong>事件要素</strong></th>
<th style="text-align:left"><strong>事件关系</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">投资事件</td>
<td style="text-align:left">融资方、投资方、金额、轮次、融资时间、所属行业</td>
<td style="text-align:left">顺承/时序</td>
</tr>
<tr>
<td style="text-align:left">并购事件</td>
<td style="text-align:left">并购方、被并购方、并购状态、所属行业、涉及股权、并购开始时间、并购结束时间、是否VC/PE支持</td>
<td style="text-align:left">顺承/时序</td>
</tr>
</tbody>
</table>
<p>在这样一个本体框架之下，我们要构建起一个事件图谱，可以有两种方式：</p>
<ul>
<li>
<p><strong>从已经结构化好的数据源中直接获取</strong>。例如，目前针对投融资领域已经出现了许多垂类网站，如投资界、IT橘子中直接获取，并做清洗。这种方式最为快捷，但受制于人，其中的数据有限，并存在字段不全的问题。当我们想建成一个实时动态的金融事件图谱库，在捕捉实时数据时，及时处理时候，就需要采用抽取的思路。</p>
</li>
<li>
<p><strong>基于模型的非结构化文本抽取</strong>。为了避免方法1带来的拿来主义缺陷，我们可以转换为标准的事件抽取任务，针对实时的实时新闻流，进行论元识别、事件要素抽取。</p>
</li>
</ul>
<p>例如，给定文本：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">8日消息，总部位于墨西哥的在线批发平台Miferia获得了700万美元种子轮融资，该轮融资由贝恩资本风险投资公司和Tiger Global共同领投。Miferia批发平台将墨西哥的独立零售店与化妆品、食品和饮料以及家居装饰等类别的品牌联系起来。该平台拥有来自500多个品牌的数千种产品，每周有30多个新品牌上线。（Latamlist）
</code></pre></div><p>我们可以从中检测出融资事件：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">8月8日消息，总部位于墨西哥的在线批发平台Miferia获得了700万美元种子轮融资，该轮融资由贝恩资本风险投资公司和Tiger Global共同领投。
</code></pre></div><p>并识别出一下结构化信息：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">融资方：Miferia
金额：700万美元
轮次：种子轮以及投资方贝恩资本风险投资公司、Tiger Global；
融资时间：8月8日、所属行业：在线批发等信息
</code></pre></div><p>下图展示了一个金融领域的一个典型投资领域事件图谱：</p>
<p>其中包括“君度德瑞、新余凯信投资、深圳市立德富盈投资等投资信濠光电20%股权”、“东莞中科中广基金（领投）、中广创投、紫宸创投等投资信濠光电5%股权”两个投资事件，每个投资事件由投资方、融资方、金额、日期、轮次几个事件要素构成，<strong>而若以一个融资方为中心进行融资历程的刻画，就可以根据日期发展的先后顺序，在两个事件之间形成一条边</strong>。</p>
<p><img loading="lazy" src="img/fin_edge_networks.png" alt=""  />
</p>
<p>需要注意的是，现在的事件抽取任务中，是不包含事件名称的抽取的，但如果要星辰恶搞事件图谱，就必须保证该事件的唯一性和友好性，可以使用md5值来表示，但并不直观，图中给出了一个较好的例子，用一个短句来表示。</p>
<br>
<h2 id="二投资事件图谱数据介绍">二、投资事件图谱数据介绍</h2>
<p>我们以投资界为数据源，通过解析整理，形成了9093条投资事件，包括融资方、投资方、金额、轮次、融资时间、所属行业共5个要素。</p>
<p><img loading="lazy" src="img/fin_extract_data.png" alt=""  />
</p>
<p>数据样例：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="p">{</span>
    <span class="s2">&#34;name&#34;</span><span class="p">:</span><span class="s2">&#34;苏州聚源铸芯创投基金（领投）、创世一期、高捷资本等投资英彼森&#34;</span><span class="p">,</span>
    <span class="s2">&#34;event_type&#34;</span><span class="p">:</span><span class="s2">&#34;投资事件&#34;</span><span class="p">,</span>
    <span class="s2">&#34;融资方&#34;</span><span class="p">:</span><span class="s2">&#34;英彼森半导体（珠海）有限公司&#34;</span><span class="p">,</span>
    <span class="s2">&#34;投资方&#34;</span><span class="p">:[</span>
        <span class="s2">&#34;聚源资本&#34;</span><span class="p">,</span>
        <span class="s2">&#34;高捷资本&#34;</span><span class="p">,</span>
        <span class="s2">&#34;创世伙伴&#34;</span><span class="p">,</span>
        <span class="s2">&#34;绿河投资&#34;</span><span class="p">,</span>
        <span class="s2">&#34;珠海科技创投&#34;</span>
    <span class="p">],</span>
    <span class="s2">&#34;金额&#34;</span><span class="p">:</span><span class="s2">&#34;RMB数亿&#34;</span><span class="p">,</span>
    <span class="s2">&#34;轮次&#34;</span><span class="p">:</span><span class="s2">&#34;A轮&#34;</span><span class="p">,</span>
    <span class="s2">&#34;融资时间&#34;</span><span class="p">:</span><span class="s2">&#34;2021年06月29日&#34;</span><span class="p">,</span>
    <span class="s2">&#34;所属行业&#34;</span><span class="p">:</span><span class="s2">&#34;半导体及电子设备-半导体&#34;</span>
<span class="p">}</span>

<span class="p">{</span>
    <span class="s2">&#34;name&#34;</span><span class="p">:</span><span class="s2">&#34;Esta Investments、DD Asset Holdings、DST China EC XI等投资滴滴集团6.08%股权&#34;</span><span class="p">,</span>
    <span class="s2">&#34;event_type&#34;</span><span class="p">:</span><span class="s2">&#34;投资事件&#34;</span><span class="p">,</span>
    <span class="s2">&#34;融资方&#34;</span><span class="p">:</span><span class="s2">&#34;滴滴&#34;</span><span class="p">,</span>
    <span class="s2">&#34;投资方&#34;</span><span class="p">:[</span>
        <span class="s2">&#34;Esta Investments&#34;</span><span class="p">,</span>
        <span class="s2">&#34;腾讯投资&#34;</span><span class="p">,</span>
        <span class="s2">&#34;THL A11&#34;</span><span class="p">,</span>
        <span class="s2">&#34;纪源资本&#34;</span><span class="p">,</span>
        <span class="s2">&#34;数字天空技术&#34;</span>
    <span class="p">],</span>
    <span class="s2">&#34;金额&#34;</span><span class="p">:</span><span class="s2">&#34;USD7.5亿&#34;</span><span class="p">,</span>
    <span class="s2">&#34;轮次&#34;</span><span class="p">:</span><span class="s2">&#34;B轮&#34;</span><span class="p">,</span>
    <span class="s2">&#34;融资时间&#34;</span><span class="p">:</span><span class="s2">&#34;2014年12月02日&#34;</span><span class="p">,</span>
    <span class="s2">&#34;所属行业&#34;</span><span class="p">:</span><span class="s2">&#34;电信及增值业务-无线互联网服务&#34;</span>
<span class="p">}</span>

</code></pre></div><br>
<h2 id="三并购事件图谱数据介绍">三、并购事件图谱数据介绍</h2>
<p>同样的，我们得到了3865条并购事件数据，包括并购方、被并购方、并购状态、所属行业、涉及股权、并购开始时间、并购结束时间以及是否VC/PE支持等事件要素。</p>
<p><img loading="lazy" src="img/fin_extract_data2.png" alt=""  />
</p>
<p>数据样例：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="p">{</span>
    <span class="s2">&#34;name&#34;</span><span class="p">:</span><span class="s2">&#34;友睦口腔收购友睦三九60%股权&#34;</span><span class="p">,</span>
    <span class="s2">&#34;event_type&#34;</span><span class="p">:</span><span class="s2">&#34;并购事件&#34;</span><span class="p">,</span>
    <span class="s2">&#34;并购方&#34;</span><span class="p">:</span><span class="s2">&#34;深圳市友睦口腔股份有限公司&#34;</span><span class="p">,</span>
    <span class="s2">&#34;被并购方&#34;</span><span class="p">:</span><span class="s2">&#34;深圳友睦三九口腔门诊部有限公司&#34;</span><span class="p">,</span>
    <span class="s2">&#34;并购状态&#34;</span><span class="p">:</span><span class="s2">&#34;已完成&#34;</span><span class="p">,</span>
    <span class="s2">&#34;所属行业&#34;</span><span class="p">:</span><span class="s2">&#34;生物技术/医疗健康-医疗服务&#34;</span><span class="p">,</span>
    <span class="s2">&#34;涉及股权&#34;</span><span class="p">:</span><span class="s2">&#34;60.00 %&#34;</span><span class="p">,</span>
    <span class="s2">&#34;并购开始时间&#34;</span><span class="p">:</span><span class="s2">&#34;2017年03月21日&#34;</span><span class="p">,</span>
    <span class="s2">&#34;并购结束时间&#34;</span><span class="p">:</span><span class="s2">&#34;2017年03月21日&#34;</span><span class="p">,</span>
    <span class="s2">&#34;是否VC/PE支持&#34;</span><span class="p">:</span><span class="s2">&#34;是&#34;</span>
<span class="p">}</span>

<span class="p">{</span>
    <span class="s2">&#34;name&#34;</span><span class="p">:</span><span class="s2">&#34;我享科技收购我享网络&#34;</span><span class="p">,</span>
    <span class="s2">&#34;event_type&#34;</span><span class="p">:</span><span class="s2">&#34;并购事件&#34;</span><span class="p">,</span>
    <span class="s2">&#34;并购方&#34;</span><span class="p">:</span><span class="s2">&#34;上海我享网络信息科技股份有限公司&#34;</span><span class="p">,</span>
    <span class="s2">&#34;被并购方&#34;</span><span class="p">:</span><span class="s2">&#34;上海我享网络科技有限公司&#34;</span><span class="p">,</span>
    <span class="s2">&#34;并购状态&#34;</span><span class="p">:</span><span class="s2">&#34;已完成&#34;</span><span class="p">,</span>
    <span class="s2">&#34;所属行业&#34;</span><span class="p">:</span><span class="s2">&#34;互联网-电子商务-C2C&#34;</span><span class="p">,</span>
    <span class="s2">&#34;涉及股权&#34;</span><span class="p">:</span><span class="s2">&#34;N/A&#34;</span><span class="p">,</span>
    <span class="s2">&#34;并购开始时间&#34;</span><span class="p">:</span><span class="s2">&#34;2017年03月01日&#34;</span><span class="p">,</span>
    <span class="s2">&#34;并购结束时间&#34;</span><span class="p">:</span><span class="s2">&#34;2017年03月24日&#34;</span><span class="p">,</span>
    <span class="s2">&#34;是否VC/PE支持&#34;</span><span class="p">:</span><span class="s2">&#34;是&#34;</span>
<span class="p">}</span>
</code></pre></div><br>
<h2 id="总结">总结</h2>
<p>本文我们介绍l额一个自建的金融事件图谱，涵盖并购和投资两大类事件类型，从金融事件图谱设计概述、投资事件图谱数据介绍以及并购事件图谱数据介绍三个角度进行论述，这对加深我们对事件图谱的具象化认识具有一定的意义。</p>
<p>关于具体的数据，可以关注 <strong>公众号：老刘说NLP</strong>，并加入技术社区，与技术社区的朋友一同分享获取。</p>
<br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>Maigret库 | 查询某用户名在各平台网站的使用情况</title>
      <link>https://textdata.cn/blog/2022-10-08-find-sns-account-information-with-maigret/</link>
      <pubDate>Sat, 08 Oct 2022 00:00:00 +0000</pubDate>
      
      <guid>/blog/2022-10-08-find-sns-account-information-with-maigret/</guid>
      <description>Maigret 能检查各网站(应用) 某 **用户名** 是否注册，并从网页收集所有可用信息,  运行过程不需要 API 密钥。目前支持超过 2500 个站点检索（完整列表），默认针对 500 个热门站点按受欢迎程度降序启动搜索。</description>
      <content:encoded><![CDATA[<p>Maigret 能检查各网站(应用) 某 <strong>用户名</strong> 是否注册，并从网页收集所有可用信息,  运行过程不需要 API 密钥。目前支持超过 2500 个站点检索（完整列表），默认针对 500 个热门站点按受欢迎程度降序启动搜索。</p>
<br>
<h2 id="主要功能">主要功能</h2>
<ul>
<li>个人资料页面解析</li>
<li>个人信息提取</li>
<li>其他个人资料链接等。</li>
<li>通过新用户名和找到的其他 id 进行递归搜索</li>
<li>按标签搜索（网站类别、国家/地区）</li>
</ul>
<br>
<h2 id="安装">安装</h2>
<p>命令行中安装maigret包</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">pip3 install maigret
</code></pre></div><br>
<h2 id="使用">使用</h2>
<p>我自己有个账号名是hidadeng，就用hidadeng试试。</p>
<p>为了解用户名hidadeng使用情况，报告结果存储于html和pdf。 在命令行中执行，</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">maigret hidadeng --html --pdf
</code></pre></div><p>命令行运行过程</p>
<p><img loading="lazy" src="img/hidadeng-cmd.png" alt=""  />
</p>
<br>
<h2 id="报告">报告</h2>
<p>maigret查询用户名hidadeng的使用情况、兴趣等结果可以绘制成报告。</p>
<p><a href="report_hidadeng_plain.html">点击查看hidadeng报告</a></p>
<p><img loading="lazy" src="img/hidadeng-report-1.png" alt=""  />
</p>
<p><img loading="lazy" src="img/hidadeng-report-2.png" alt=""  />
</p>
<p>效果挺准的，对hidadeng这个用户兴趣(coding、shopping)拿捏的也挺不错。</p>
<br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>Google Books Ngram Viewer显示英文词汇历史使用趋势</title>
      <link>https://textdata.cn/blog/2022-09-27-r-ngramr/</link>
      <pubDate>Tue, 27 Sep 2022 00:00:00 +0000</pubDate>
      
      <guid>/blog/2022-09-27-r-ngramr/</guid>
      <description>显示词汇历史使用趋势</description>
      <content:encoded><![CDATA[


<p><a href="https://books.google.com/ngrams/">Google Books Ngram Viewer</a> 可以显示输入短语(你感兴趣的词组)在谷歌书籍中（例如，“British English”、“English Fiction”、“French”）中出现的频率变化趋势 。</p>
<p>网址 <a href="https://books.google.com/ngrams/" class="uri">https://books.google.com/ngrams/</a></p>
<p><img src="ngramr_hacker_programmer.png" /></p>
<p><img src="ngramr_democracy_monarchy.png" /></p>
<p><img src="us_is_us_has.png" /></p>
]]></content:encoded>
    </item>
    
    <item>
      <title>文献汇总 | 量化历史学与经济学研究</title>
      <link>https://textdata.cn/blog/2022-09-19-quantitative-history-economic/</link>
      <pubDate>Mon, 19 Sep 2022 00:00:00 +0000</pubDate>
      
      <guid>/blog/2022-09-19-quantitative-history-economic/</guid>
      <description>通过历史数据挖掘构建有意思的新变量， 量化历史学 可能是个不错的借鉴思路。</description>
      <content:encoded><![CDATA[<p>我对经济史不太懂，标题起的可能不一定恰当，通过历史数据挖掘构建有意思的新变量， <strong>量化历史学</strong> 可能是个不错的借鉴思路。</p>
<p><br><br></p>
<h2 id="历史与经济">历史与经济</h2>
<blockquote>
<p>摘自 <a href="https://mp.weixin.qq.com/s/pnwlwQfO0EWgV8XNHzMuZg">陈志武教授统筹量化历史研究获得创纪录研究经费支持</a></p>
</blockquote>
<p>由<strong>陈志武</strong>教授统筹的跨领域研究项目获得大学教育资助委员会（教资会）辖下的研究资助局（研资局）6,732万港元（即逾850万美元） 的拨款资助，再加上香港大学的支持，此单一研究项目共获得7,480万港元 （即逾950万美元），资助金额创学院自2001年成立以来的新高。项目研究团队由来自五间教资会资助院校的成员及合作方组成，包括香港大学（港大）、香港中文大学 （中大）、香港科技大学 （科大）、岭南大学（岭大）及香港浸会大学（浸大），另外亦有来自牛津大学及中国人民大学的学者。项目成员包括：港大陈志武 （项目统筹人）、Jed O. Kaplan、梁其姿、林晨和马驰骋、白营（中大）、康文林（科大）、林展 （人民大学）、刘光临（岭大）以及马德斌 （牛津）。（按英文字母顺序排列）</p>
<p>题为 “<strong>量化历史研究：追寻现代中国发展的根源</strong>” 的研究项目获得研资局辖下第十轮 “<strong>卓越学科领域计划</strong>” 的资助，旨在透过在香港大学成立 “<strong>量化历史研究中心</strong>” ，作为协调和开展 “<strong>量化中国历史</strong>” 研究的核心学术机构，<strong>致力加深对中国历史发展的认识，挖掘历史新知识，促进历史教学，引导政策制定，改善商界运营模式</strong>。</p>
<p>学院金融学讲座教授及郑裕彤基金教授（金融学）陈志武指出：“我们很荣幸能够获得今年度卓越学科领域计划的拨款，这支持并肯定了我们为多层面中国历史研究所作出的努力。<strong>中国蕴藏丰富的历史档案和考古挖掘，其规模在世界乃独一无二， 内容几乎涵盖中国社会的所有方面：从政治到商业、法律和监管、犯罪和动乱、家庭和宗族、文化和习俗、宗教和社会组织，以及科学。近年，这些档案被数码化，为量化历史学家提供前所未有的机会去全面重新审视中国历史的各方面</strong>。作为中国的一部分，香港具有语言、文化和人力资源的优势去建立整体而全面的中国量化历史，我们深信成立量化历史研究中心，将推动香港成为全球量化历史研究的领导者。”</p>
<p><br><br></p>
<h2 id="更多资料">更多资料</h2>
<ul>
<li><a href="https://academic.oup.com/ej/article/130/631/2030/5819954"><strong>鉴古识今 – 从「科举考试」分析中国经济发展</strong></a><br>Ting Chen, James Kai-sing Kung, Chicheng Ma, Long Live <em>Keju</em>! The Persistent Effects of China’s Civil Examination System, <em><strong>The Economic Journal</strong></em>, Volume 130, Issue 631, October 2020, Pages 2030–2064, <a href="https://doi.org/10.1093/ej/ueaa043">https://doi.org/10.1093/ej/ueaa043</a></li>
</ul>
<br>
<ul>
<li>Zhiwu Chen, Chicheng Ma, Andrew J Sinclair, Banking on the Confucian Clan: Why China Developed Financial Markets so Late, <em><strong>The Economic Journal</strong></em>, Volume 132, Issue 644, May 2022, Pages 1378–1413, <a href="https://doi.org/10.1093/ej/ueab082">https://doi.org/10.1093/ej/ueab082</a></li>
</ul>
<br>
<ul>
<li><a href="https://www.bilibili.com/video/BV19L4y1A7Yn">从权贵到富贵： 中国传世明画产权变动与社会流动性研究，960-1911</a></li>
</ul>
<iframe
    src="//player.bilibili.com/player.html?bvid=BV19L4y1A7Yn&page=1"
    scrolling="no"
    height="500px"
    width="800px"
    frameborder="no"
    framespacing="0"
    allowfullscreen="true"
>
</iframe>

<ul>
<li><a href="https://www.bilibili.com/video/BV1Q34y1J7f5">陈志武 &ndash; 史前文明摇篮的长久影响 &mdash;你的故乡是兴是衰在四千多年前就确定？</a></li>
</ul>
<iframe
    src="//player.bilibili.com/player.html?bvid=BV1Q34y1J7f5&page=1"
    scrolling="no"
    height="500px"
    width="800px"
    frameborder="no"
    framespacing="0"
    allowfullscreen="true"
>
</iframe>

<br>
<ul>
<li><a href="https://mp.weixin.qq.com/s/DJei28L1iZ_7rtkD0dZAQQ">李中清|《大数据与中国社会经济史》</a></li>
</ul>
<br>
<ul>
<li><a href="https://mp.weixin.qq.com/s/wpfz4WbNg-wW5IYxbBWcEQ">陈春声 | 统计分析方法在史学研究中的应用</a></li>
</ul>
<br>
<ul>
<li><a href="https://mp.weixin.qq.com/s/NxcFvQm7msQq9DrRLpMydQ">地理信息系统（GIS）与中国历史研究</a></li>
</ul>
<br>
<ul>
<li><a href="https://mp.weixin.qq.com/s/HqLvrK626bXt984dGtnR_A">周欣平：大数据与社会科学和人文科学研究</a></li>
</ul>
<br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>国庆直播 | Python实证指标与文本分析</title>
      <link>https://textdata.cn/blog/2022-09-19-text-mining-in-ms-workshop/</link>
      <pubDate>Sun, 18 Sep 2022 00:00:00 +0000</pubDate>
      
      <guid>/blog/2022-09-19-text-mining-in-ms-workshop/</guid>
      <description>文本分析在经管研究中的应用</description>
      <content:encoded><![CDATA[<h2 id="报名信息">报名信息</h2>
<ul>
<li>
<p>时间：<strong>2022.10.03 ~ 2022.10.04</strong></p>
</li>
<li>
<p>地点: 小鹅通平台（线上直播）</p>
</li>
<li>
<p>报名咨询:  17816181460（同微信）（汪老师）</p>
</li>
<li>
<p>报名费：<strong>2500元</strong></p>
<ul>
<li>单位：杭州国商智库信息技术服务有限公司</li>
<li>开户银行： 中国银行杭州大学城支行</li>
<li>银行账户：6232636200100260588</li>
</ul>
</li>
</ul>
<br>
<h2 id="简介">简介</h2>
<p>在科学研究中，数据的获取及分析是最重要的也是最棘手的两个环节！</p>
<p>在<strong>前大数据时代</strong>，一般使用实验法、调查问卷、访谈或者二手数据等方式，将数据整理为结构化的表格数据，之后再使用各种计量分析方法，对这些表格数据进行分析。<strong>大数据时代</strong>，大量商业信息、社会信息以文本等非结构化、异构型数据格式存储于海量的网页中。那么对于经管为代表的人文社科类专业科研工作者而言，通过Python可以帮助学者解决使用Web数据进行科研面临的两个问题：</p>
<ol>
<li><strong>网络爬虫</strong> 解决 如何从网络世界中高效地 <strong>采集数据</strong>？</li>
<li><strong>文本分析</strong> 解决 如何从杂乱的文本数据中 <strong>构建指标</strong>？</li>
</ol>
<p>为方便大家感受到文本数据的魅力，按照是否采用某项技术(爬虫、词频、词袋、w2v建词典、w2v认知变迁)，从五个维度标记代表性的7篇论文。</p>
<table>
<thead>
<tr>
<th>文献</th>
<th>爬虫</th>
<th>定性</th>
<th>词频</th>
<th>词袋</th>
<th>W2V建词典</th>
<th>W2V认知变迁</th>
</tr>
</thead>
<tbody>
<tr>
<td>王伟 , 陈伟, 祝效国 and 王洪伟, 2016. 众筹融资成功率与语言风格的说服性&ndash;基于 Kickstarter 的实证研究. <em>管理世界</em>, (5), pp.81-98.</td>
<td>Y</td>
<td>Y</td>
<td>Y</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><strong>语言具体性如何影响顾客满意度</strong><br>Packard, Grant, and Jonah Berger. “How concrete language shapes customer satisfaction.” <em>Journal of Consumer Research</em> 47, no. 5 (2021): 787-806.</td>
<td></td>
<td></td>
<td>Y</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Wang, Quan, Beibei Li, and Param Vir Singh. &ldquo;<strong>Copycats vs. original mobile apps</strong>: A machine learning copycat-detection method and empirical analysis.&rdquo; Information Systems Research 29, no. 2 (2018): 273-291.</td>
<td>Y</td>
<td></td>
<td></td>
<td>Y</td>
<td></td>
<td></td>
</tr>
<tr>
<td><strong>文本相似度</strong><br>Cohen, L., Malloy, C. and Nguyen, Q., 2020. Lazy prices. <em>The Journal of Finance</em>, <em>75</em>(3), pp.1371-1415.</td>
<td></td>
<td></td>
<td></td>
<td>Y</td>
<td></td>
<td></td>
</tr>
<tr>
<td>胡楠, 薛付婧 and 王昊楠, 2021. <strong>管理者短视主义影响企业长期投资吗</strong>———基于文本分析和机器学习. <em>管理世界</em>, <em>37</em>(5), pp.139-156.</td>
<td></td>
<td></td>
<td>Y</td>
<td></td>
<td>Y</td>
<td></td>
</tr>
<tr>
<td>Kai Li, Feng Mai, Rui Shen, Xinyan Yan, <strong>Measuring Corporate Culture Using Machine Learning</strong>, The Review of Financial Studies, 2020</td>
<td></td>
<td></td>
<td></td>
<td>Y</td>
<td>Y</td>
<td></td>
</tr>
<tr>
<td><strong>女性就职高管改变组织内性别偏见</strong><br>Lawson, M. Asher, Ashley E. Martin, Imrul Huda, and Sandra C. Matz. &ldquo;Hiring women into senior leadership positions is associated with a reduction in gender stereotypes in organizational language.&rdquo; <em>Proceedings of the National Academy of Sciences</em> 119, no. 9 (2022): e2026443119.</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>Y</td>
</tr>
</tbody>
</table>
<br>
<h2 id="主讲老师">主讲老师</h2>
<p>大邓，哈尔滨工业大学(HIT)管理学院信息管理系统方向在读博士。在多所大学分享数据采集和文本分析。运营公众号：大邓和他的Python，主要分享Python、爬虫、文本分析、机器学习等内容。</p>
<br>
<h2 id="一入门语法">一、入门语法</h2>
<ul>
<li>Python跟英语一样是一门语言</li>
<li>数据类型之字符串</li>
<li>数据类型之列表元组集合</li>
<li>数据类型之字典</li>
<li>数据类型之布尔值、None</li>
<li>逻辑语句(if&amp;for&amp;tryexcept)</li>
<li>列表推导式</li>
<li>理解函数</li>
<li>常用的内置函数</li>
<li>os路径库</li>
<li>内置库csv文件库</li>
<li>常见错误汇总</li>
</ul>
<h2 id="二数据采集">二、数据采集</h2>
<ul>
<li>网络爬虫原理</li>
<li>寻找网址规律</li>
<li>获取网页-requests库</li>
<li>pyquery库解析html网页</li>
<li><strong>案例:</strong> 豆瓣小说</li>
<li>json库解析json网页</li>
<li><strong>案例:</strong> 豆瓣电影</li>
<li><strong>案例:</strong> 微博</li>
<li><strong>案例:</strong> 文件下载</li>
<li><strong>案例:</strong> 上市公司定期报告pdf批量下载</li>
<li>区分动态网站与静态网站</li>
</ul>
<h2 id="三文本初识">三、文本初识</h2>
<ul>
<li>从信息传播视角重新认识文本</li>
<li>读取各类文件中的数据</li>
<li><strong>案例:</strong>  识别图片中的文本</li>
<li>数据清洗re库</li>
<li><strong>案例:</strong> 将多个数据文件汇总至一个csv文件</li>
<li><strong>案例:</strong> 中文jieba分词、词频统计、制作词云图</li>
<li><strong>案例:</strong> 使用共现(word2vec)法扩展情感词典</li>
<li><strong>案例:</strong> 使用词典做情感分析(无权重)</li>
<li><strong>案例:</strong> 数据分析pandas库快速入门</li>
<li><strong>案例:</strong> 使用pandas对excel中的文本进行情感分析</li>
</ul>
<h2 id="四文本进阶">四、文本进阶</h2>
<ul>
<li>文本分析与机器学习</li>
<li>特征工程-认识词袋法、one-hot、Tf-Idf、word2vec</li>
<li>将文档转为机器可处理的向量</li>
<li><strong>案例:</strong> 使用情感词典和tf-idf做情感分析（有权重）</li>
<li><strong>案例:</strong> 在线评论文本分类</li>
<li><strong>案例:</strong> 使用文本相似性识别变化(政策连续性)</li>
<li><strong>案例:</strong> Kmeans聚类算法、LDA话题模型</li>
<li>文本中的人类记忆(认知)</li>
<li>如何测量人类认知偏见(刻板印象)</li>
<li><strong>案例:</strong> 词向量模型的使用方法-豆瓣影评</li>
<li>文本分析在经管社科领域中的应用概述</li>
</ul>
<br>
<h2 id="参考文献">参考文献</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">[1]沈艳, 陈赟 and 黄卓, 2019. 文本大数据分析在经济学和金融学中的应用: 一个文献综述. *经济学 (季刊)*, *18*(4), pp.1153-1186.
[2]冉雅璇,李志强,刘佳妮,张逸石.大数据时代下社会科学研究方法的拓展——基于词嵌入技术的文本分析的应用[J/OL].南开管理评论:1-27[2022-04-08].http://kns.cnki.net/kcms/detail/12.1288.F.20210905.1337.002.html
[3]王伟,陈伟,祝效国,王洪伟. 众筹融资成功率与语言风格的说服性-基于Kickstarter的实证研究.*管理世界*.2016;5:81-98.
[4]胡楠,薛付婧,王昊楠.管理者短视主义影响企业长期投资吗？——基于文本分析和机器学习[J].管理世界,2021,37(05):139-156+11+19-21.
[5]Kai Li, Feng Mai, Rui Shen, Xinyan Yan, Measuring Corporate Culture Using Machine Learning, *The Review of Financial Studies*,2020
[6]Loughran T, McDonald B. Textual analysis in accounting and finance: A survey[J]. *Journal of Accounting Research*, 2016, 54(4): 1187-1230. Author links open overlay panelComputational socioeconomics
[7]Berger, Jonah, Ashlee Humphreys, Stephan Ludwig, Wendy W. Moe, Oded Netzer, and David A. Schweidel. &#34;Uniting the tribes: Using text for marketing insight.&#34; *Journal of Marketing* 84, no. 1 (2020): 1-25.
[8]Banks, George C., Haley M. Woznyj, Ryan S. Wesslen, and Roxanne L. Ross. &#34;A review of best practice recommendations for text analysis in R (and a user-friendly app).&#34; *Journal of Business and Psychology* 33, no. 4 (2018): 445-459.
[9]Cohen, Lauren, Christopher Malloy, and Quoc Nguyen. &#34;Lazy prices.&#34; *The Journal of Finance* 75, no. 3 (2020): 1371-1415.
[10]孟庆斌, 杨俊华, 鲁冰. 管理层讨论与分析披露的信息含量与股价崩盘风险——基于文本向量化方法的研究[J]. *中国工业经济*, 2017 (12): 132-150.
[11]Wang, Quan, Beibei Li, and Param Vir Singh. &#34;Copycats vs. Original Mobile Apps: A Machine Learning Copycat-Detection Method and Empirical Analysis.&#34; *Information Systems Research* 29.2 (2018): 273-291.
[12]Hoberg, Gerard, and Gordon Phillips. 2016, Text-based network industries and endogenous product differentiation,?*Journal of Political Economy* 124, 1423-1465
[13]Loughran, Tim, and Bill McDonald. &#34;When is a liability not a liability? Textual analysis, dictionaries, and 10‐Ks.&#34; *The Journal of Finance* 66, no. 1 (2011): 35-65.
[14]Fairclough, Norman. 2003. Analysing discourse: Textual analysis for social research (Psychology Press)
[15]Grimmer, Justin, and Brandon M Stewart. 2013, Text as data: The promise and pitfalls of automatic content analysis methods for political texts, *Political analysis*21, 267-297.
[16]Markowitz, D. M., &amp; Shulman, H. C. (2021). The predictive utility of word familiarity for online engagements and funding. Proceedings of the National Academy of Sciences, 118(18).
[17]Packard, Grant, and Jonah Berger. “How concrete language shapes customer satisfaction.” Journal of Consumer Research 47, no. 5 (2021): 787-806.
[18]Chen, H., Yang, C., Zhang, X., Liu, Z., Sun, M. and Jin, J., 2021. From Symbols to Embeddings: A Tale of Two Representations in Computational Social Science. Journal of Social Computing, 2(2), pp.103-156.
[19]Lawson, M. Asher, Ashley E. Martin, Imrul Huda, and Sandra C. Matz. &#34;Hiring women into senior leadership positions is associated with a reduction in gender stereotypes in organizational language.&#34; *Proceedings of the National Academy of Sciences* 119, no. 9 (2022): e2026443119.
</code></pre></div>]]></content:encoded>
    </item>
    
    <item>
      <title>视频分享 | 文本分析在经管研究中的应用</title>
      <link>https://textdata.cn/blog/2022-09-08-dufe-text-mining-in-ms/</link>
      <pubDate>Thu, 08 Sep 2022 00:00:00 +0000</pubDate>
      
      <guid>/blog/2022-09-08-dufe-text-mining-in-ms/</guid>
      <description>文本分析在经管研究中的应用。Application of Text Analysis in Economics and Management Research</description>
      <content:encoded><![CDATA[<h2 id="slideshttpstextdatacnblog2022-09-08-dufe-text-mining-in-msslideshtml"><a href="https://textdata.cn/blog/2022-09-08-dufe-text-mining-in-ms/slides.html">Slides</a></h2>
<iframe
    src="//player.bilibili.com/player.html?bvid=BV1se4y1C7MV&page=1"
    scrolling="no"
    height="500px"
    width="800px"
    frameborder="no"
    framespacing="0"
    allowfullscreen="true"
>
</iframe>

<p><br><br></p>
<h2 id="背景">背景</h2>
<p><img loading="lazy" src="img/multitudes-of-content-illustration.jpeg" alt=""  />
</p>
<p>在经管研究中，往往会涉及很多文本数据的编码。但是做研究面临两个问题:</p>
<h3 id="难题1--数据量大">难题1- 数据量大</h3>
<p>量太大，以至于废人力所能及。</p>
<p>时代发展，体现在数据上的特点就是数据大爆炸，过去做经管研究，使用访谈等研究方法，收录的文本内容，规模大多停留在M级。但是现在大数据时代，研究对象相关的文本数据，G级的数据量也是很常见的。</p>
<h3 id="难题2--格式乱">难题2- 格式乱</h3>
<p>信息存储技术发展，有应用不同场景的不同数据存储格式。数据可能是pdf、txt、docx，也可能是音频、视频等转录的文件。如果快捷整理，这也是个难点。</p>
<h3 id="难题3-难编码">难题3-难编码</h3>
<p>数据量少，可以人工阅读对数据进行理解和编码。但是当数据量大到无法处理的级别后，选择何种算法、各种算法技术的优缺点如何把握，对经管学者也是一个需要攻克的的技术难题。</p>
<p><img loading="lazy" src="img/consumer_org_society.png" alt=""  />
</p>
<p>难度大，但因为文本涉及的主体错综复杂，千丝万缕，所以可以研究很多对象。如个人、组织、社会之间的交互。</p>
<p><br><br></p>
<h2 id="编码解码理论">编码解码理论</h2>
<p>斯图亚特·霍尔在《电视话语的编码和解码》提出 『编码-解码理论』。该理论形成于70年代冷战时期，冷战中不两大阵营为了维护各自的社会稳定，为了在意识形态宣传中取胜，都在宣传工作中投入了重金。</p>
<p>当时的宣传工具是单向的广播模式，媒体作为统治阶级的喉舌，要将统治阶级的偏好、价值观等进行加工，生产相应意识形态内容。</p>
<p>而普罗大众，作为内容的接受者， 一成长于该特定意识形态的社会，同时又有一定的自我意识，所以对于一个宣传内容可能会有三种反应，表里都认同、表认同里不认同、表里都不认同。</p>
<p><img loading="lazy" src="img/SenderReceiver.png" alt=""  />
</p>
<h3 id="使用文本想清楚两个问题">使用文本想清楚两个问题</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">- How text reflects its Sender？
- How text impacts its Receiver？
</code></pre></div><h3 id="使用文本明晰三个角度">使用文本明晰三个角度</h3>
<p>我做的研究使用的文本数据，涉及哪些角色、作用力方向、感兴趣的内容。</p>
<ul>
<li>角色: Sender or Receiver</li>
<li>方向: Reflect or Impact</li>
<li>内容: Sender的意识(认知、偏好、&hellip;)   vs  Receiver的意识(认知、偏好、&hellip;)</li>
</ul>
<p>下面是经管领域研究部分汇总，每个学者根据自己学科研究对象，应该能在4*4的矩阵中找到自己对应的位置</p>
<p><img loading="lazy" src="img/%e7%94%9f%e4%ba%a7%e4%b8%8e%e6%b6%88%e8%b4%b9.png" alt=""  />
</p>
<blockquote>
<p>Berger, Jonah, Ashlee Humphreys, Stephan Ludwig, Wendy W. Moe, Oded Netzer, and David A. Schweidel. &ldquo;Uniting the tribes: Using text for marketing insight.&rdquo; Journal of Marketing 84, no. 1 (2020): 1-25.</p>
</blockquote>
<p><br><br></p>
<h2 id="人工编码与机器编码">人工编码与机器编码</h2>
<p><img loading="lazy" src="img/unstructrueddata.png" alt=""  />
</p>
<p>做研究需要有干净的数据做实证分析，最为理想的是表数据，例如excel文件，每一行代表一条记录，每一列代表一个字段。编码的作用就是将非机构化的、脏乱的数据整理为干净整洁的表数据。</p>
<p>要明确编码方法的优点和缺点，在合理的适用范围使用。对于文本数据的编码，需要理解人工和机器两种编码方式的优缺点</p>
<table>
<thead>
<tr>
<th style="text-align:left"></th>
<th>分析方法</th>
<th>优点</th>
<th>缺点</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">人工编码</td>
<td>质性（扎根）</td>
<td>少量数据，深刻洞见。</td>
<td>难以应对大数据；<br>编码标准不统一；</td>
</tr>
<tr>
<td style="text-align:left">机器编码</td>
<td>词频、向量相似度、向量距离</td>
<td>标准如一;<br>适合大规模文本挖掘；</td>
<td>需要破坏文本的结构，<br>丧失了部分信息量</td>
</tr>
</tbody>
</table>
<p><br><br></p>
<h2 id="机器编码-将文本转为数字或向量">机器编码-将文本转为数字或向量</h2>
<ul>
<li>
<p>符号法(每个词对应一个数字)</p>
<ul>
<li>词典(词频)法</li>
<li>词袋法、TF-IDF</li>
</ul>
</li>
<li>
<p>词嵌入(每个词对应一个向量)</p>
</li>
</ul>
<p>符号法算法假设词语彼此是语义不相关的，目的是把 <strong>文本</strong> 转为某个数字或<strong>向量</strong>。</p>
<p>而词嵌入算法假设不同的词语是由n维个语义组成的线性组合，目的是把 <strong>词语</strong> 转为<strong>向量</strong>。</p>
<br>
<h3 id="符号法">符号法</h3>
<p>符号法就是数某个词或某类词的出现次数(或占比)。符合法是计算机NLP领域的专业叫法，在经管社科领域，最常见的文本分析软件<a href="https://textdata.cn/blog/liwc_python_text_mining/">LIWC</a>其实也是符号法。而LIWC全(Linguistic Inquiry and Word Count，即语义查询与词频统计。</p>
<p><img loading="lazy" src="img/symbol-representation-1.png" alt=""  />
</p>
<h3 id="符号法的应用">符号法的应用</h3>
<table>
<thead>
<tr>
<th>概念</th>
<th>测量方法</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>认真(努力)</strong></td>
<td>测量文本中词语的个数</td>
</tr>
<tr>
<td><strong>情感</strong></td>
<td>使用情感词典，统计文本中正面词占比</td>
</tr>
<tr>
<td><strong>可读性</strong></td>
<td>文本中高难度(或专业性)词占比</td>
</tr>
<tr>
<td><strong>客观性</strong></td>
<td>文本中某个值的方差，如情感<br>- A<code>产品不错， 包装破损， 态度很好， 综合还是推荐大家购买!</code> [5, 1, 5, 4]<br>- B<code>产品垃圾，使用垃圾， 包装破损， 差评!!</code> [1,  1,  1,  1]<br>A的方差更大，更客观</td>
</tr>
<tr>
<td><strong>相似性(政策稳定性)</strong></td>
<td>cosine(text_vector1, text_vector2)</td>
</tr>
<tr>
<td>&hellip;</td>
<td>&hellip;</td>
</tr>
</tbody>
</table>
<br>
<h3 id="词嵌入">词嵌入</h3>
<p>词嵌入技术有 Word2Vec、Glove，这类技术是挖掘出每个词的上下文语境，通俗的说法就是让计算机，对同样的文章数据，做千万次、上亿次完形填空。这样每个词语都有独特的上下文语义，并以n维向量形式表示，所以词嵌入也可以称之为词向量。</p>
<p><strong>向量模型有近义词相近、概念类似的平行两个特点</strong>。分别举几个例子，方便大家理解。</p>
<p>语义空间是n维，为了便于理解，将其压缩至二维空间。中学的向量大家都比较熟悉，在二维坐标中空间中，两个点的连线可以组成新的向量，相同的向量是平行的。</p>
<p>而在下图的2维语义空间中，good、best语义更接近，所以空间距离更近。同理bad、worst更近。</p>
<p>而vector(good, best)、vector(bad, worst)这两个向量均表示<code>原形-&gt;最高级</code>, 语义向量会近似平行。</p>
<p>同理， vector(good, bad)、 vector(best, worst)两个向量表示 <code>好-&gt;差</code>，语义向量也会近似平行。</p>
<p><img loading="lazy" src="img/embeddings-based.png" alt=""  />
</p>
<br>
<h3 id="词嵌入与认知">词嵌入与认知</h3>
<p>刚刚词嵌入的语义空间中的几个例子，其实就体现了语言的记忆。语义记录了使用该语言的人的记忆。不同的组织，对于同一种概念，会有不同的偏好。例如， Nature2022使用大规模语料数据训练出的词向量，发现语言中残存着人类的某些认知记忆。</p>
<p>通过构建概念词组对儿，在空间中投影，就可以挖掘出词语的在该概念中的分值。例如，使用</p>
<ul>
<li>SMALL = [small, tiny, little&hellip;]</li>
<li>BIG = [big, mega, large&hellip;]</li>
</ul>
<p>每个词都是一个n维的向量，SMALL或BIG都能计算出一个均值向量。大家记得中学的向量投影不，Nature2022就使用这个朴素的方法测量每个动物名称所蕴含的人类尺寸认知。</p>
<p><img loading="lazy" src="img/Concept_Words_Project.png" alt=""  />
</p>
<blockquote>
<p>Grand, G., Blank, I.A., Pereira, F. and Fedorenko, E., 2022. Semantic projection recovers rich human knowledge of multiple object features from word embeddings. Nature Human Behaviour, pp.1-13.</p>
</blockquote>
<br>
<h3 id="技术对比">技术对比</h3>
<p>这里做个表格对比，大家自己感受下三种技术的异同。</p>
<table>
<thead>
<tr>
<th>技术</th>
<th>技术</th>
<th>维度类比</th>
<th>任务</th>
<th>例子</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>符号法-字典</strong>（词频）</td>
<td>数个数</td>
<td>原子</td>
<td>统计每句话里的名词个数</td>
<td>sent_num1 = 2<br>sent_num2 = 1</td>
</tr>
<tr>
<td><strong>符号法-词袋</strong></td>
<td>bag of words<br>one-hot<br>Tf-idf</td>
<td>分子</td>
<td>转化为词向量, 计算两个句子相似度。</td>
<td>vec1 = [1, 1, 1, 1, 1, 0]<br>vec2 = [0, 1, 0, 1, 0, 1]<br>similarity = cosine(vec1, vec2)</td>
</tr>
<tr>
<td><strong>词嵌入</strong></td>
<td>word2vec、<br>glove等</td>
<td>中子、质子、电子</td>
<td>词语相似度。(语义上大小相近，方向相反; 态度、偏见)</td>
<td>mom = [0.2, 0.7, 0.1]<br/>dad   = [0.3, 0.5, -0.2]</td>
</tr>
</tbody>
</table>
<p><br><br></p>
<h2 id="经管-文本分析-文献">经管-文本分析-文献</h2>
<p>在这里我把技术细分为词频、词袋、w2v建词典、w2v认知变迁四个维度，整理了经管7篇论文。大家可以阅读这7篇论文，掌握文本分析的应用场景。</p>
<table>
<thead>
<tr>
<th>文献</th>
<th>定性</th>
<th>词频</th>
<th>词袋</th>
<th>W2V建词典</th>
<th>W2V认知变迁</th>
</tr>
</thead>
<tbody>
<tr>
<td>王伟, 陈伟, 祝效国 and 王洪伟, 2016. 众筹融资成功率与语言风格的说服性&ndash;基于 Kickstarter 的实证研究. <em>管理世界</em>, (5), pp.81-98.</td>
<td>Y</td>
<td>Y</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><a href="https://textdata.cn/blog/jcr_concreteness_computation/">语言具体性如何影响顾客满意度</a><br>Packard, Grant, and Jonah Berger. “How concrete language shapes customer satisfaction.” <em>Journal of Consumer Research</em> 47, no. 5 (2021): 787-806.</td>
<td></td>
<td>Y</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Wang, Quan, Beibei Li, and Param Vir Singh. &ldquo;Copycats vs. original mobile apps: A machine learning copycat-detection method and empirical analysis.&rdquo; Information Systems Research 29, no. 2 (2018): 273-291.</td>
<td></td>
<td></td>
<td>Y</td>
<td></td>
<td></td>
</tr>
<tr>
<td><a href="https://textdata.cn/blog/2019-12-08-lazy-prices/">文本相似度</a><br>Cohen, L., Malloy, C. and Nguyen, Q., 2020. Lazy prices. <em>The Journal of Finance</em>, <em>75</em>(3), pp.1371-1415.</td>
<td></td>
<td></td>
<td>Y</td>
<td></td>
<td></td>
</tr>
<tr>
<td>胡楠, 薛付婧 and 王昊楠, 2021. <a href="https://textdata.cn/blog/text_mining_in_2021_management_world/">管理者短视主义</a>影响企业长期投资吗———基于文本分析和机器学习. <em>管理世界</em>, <em>37</em>(5), pp.139-156.</td>
<td></td>
<td>Y</td>
<td></td>
<td>Y</td>
<td></td>
</tr>
<tr>
<td>Kai Li, Feng Mai, Rui Shen, Xinyan Yan, <a href="https://github.com/MS20190155/Measuring-Corporate-Culture-Using-Machine-Learning">Measuring Corporate Culture Using Machine Learning</a>, The Review of Financial Studies, 2020</td>
<td></td>
<td></td>
<td>Y</td>
<td>Y</td>
<td></td>
</tr>
<tr>
<td>女性就职高管改变组织内性别偏见<br>Lawson, M. Asher, Ashley E. Martin, Imrul Huda, and Sandra C. Matz. &ldquo;Hiring women into senior leadership positions is associated with a reduction in gender stereotypes in organizational language.&rdquo; <em>Proceedings of the National Academy of Sciences</em> 119, no. 9 (2022): e2026443119.</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>Y</td>
</tr>
<tr>
<td>使用词嵌入技术，量化近百年以来性别和族群的刻板印象<br>Garg, Nikhil, Londa Schiebinger, Dan Jurafsky, and James Zou. &ldquo;Word embeddings quantify 100 years of gender and ethnic stereotypes.&rdquo; Proceedings of the National Academy of Sciences 115, no. 16 (2018): E3635-E3644.</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>Y</td>
</tr>
</tbody>
</table>
<p><br><br></p>
<h2 id="案例">案例</h2>
<h3 id="案例1-众筹语言风格">案例1-众筹语言风格</h3>
<p>王伟, 陈伟, 祝效国 and 王洪伟, 2016. 众筹融资成功率与语言风格的说服性&ndash;基于 Kickstarter 的实证研究. <em>管理世界</em>, (5), pp.81-98.</p>
<blockquote>
<p>众筹融资效果决定着众筹平台的兴衰。 众筹行为很大程度上是由投资者的主观因素决定的，而影响主观判断的一个重要因素就是语言的说服性。 而这又是一种典型的用 户产生内容（UGC），项目发起者可以采用任意类型的语言风格对项目进行描述。 不同的语 言风格会改变投资者对项目前景的感知，进而影响他们的投资意愿。 首先，依据 Aristotle 修 辞三元组以及 Hovland 说服模型，采用扎根理论，将众筹项目的语言说服风格分为 5 类：诉诸可信、诉诸情感、诉诸逻辑、诉诸回报和诉诸夸张。</p>
<p>然后，<strong>借助文本挖掘方法，构建说服风格语料库，并对项目摘要进行分类。</strong></p>
<p>最后，建立语言说服风格对项目筹资影响的计量模型，并对 <strong>Kickstarter 平台上的 128345 个项目进行实证分析</strong>。 总体来说，由于项目性质的差异，不同 的项目类别对应于不同的最佳说服风格。</p>
</blockquote>
<p><img loading="lazy" src="img/%e4%bc%97%e7%ad%b9-%e7%a7%8d%e5%ad%90%e8%af%8d.png" alt=""  />

<img loading="lazy" src="img/%e4%bc%97%e7%ad%b9-%e6%b5%81%e7%a8%8b%e5%9b%be.png" alt=""  />
</p>
<br>
<h3 id="案例2-山寨-vs-原创">案例2 山寨 vs 原创</h3>
<p>Wang, Quan, Beibei Li, and Param Vir Singh. &ldquo;Copycats vs. original mobile apps: A machine learning copycat-detection method and empirical analysis.&rdquo; Information Systems Research 29, no. 2 (2018): 273-291.</p>
<blockquote>
<p><strong>进行此类研究的主要威慑因素是缺乏一种客观的方法来识别应用程序是模仿者还是原创者。通过结合自然语言处理，潜在语义分析，基于网络的聚类和图像分析等机器学习技术，我们提出了一种将应用识别为原创app或模仿app，可检测两种模仿者的方法：欺骗性和非欺骗性。</strong></p>
<p>根据检测结果，我们进行了经济计量分析，以确定五年间在iOS App Store中发布的<strong>5,141个开发人员的10,100个动作游戏应用程序</strong>样本中，模仿app对原创app需求的影响。我们的结果表明，特定模仿者对原始应用需求的影响取决于模仿者的质量和欺骗程度。高质量的非欺骗性复制品会对原件产生负面影响。相比之下，低质量，欺骗性的模仿者正面影响了对原创app的需求。</p>
<p>结果表明，从总体上讲，模仿app对原创app需求的影响在统计上是微不足道的。<strong>我们的研究通过提供一种识别模仿app的方法</strong>，并提供模仿app对原创app需求影响的证据，为越来越多的移动应用消费文献做出了贡献。</p>
</blockquote>
<p><img loading="lazy" src="img/copycat.png" alt=""  />
</p>
<br>
<h3 id="案例3-lazy-prices文本相似性">案例3 Lazy prices文本相似性</h3>
<p>Cohen, L., Malloy, C. and Nguyen, Q., 2020. <a href="https://textdata.cn/blog/2019-12-08-lazy-prices/">Lazy prices</a>. <em>The Journal of Finance</em>, <em>75</em>(3), pp.1371-1415.</p>
<blockquote>
<p>之前的研究认为，尽管投资者一次对包含重大变化的财务报表的发布作出了迅时反应，但随着时间的流逝，这种公告作用是会减弱的(Brown and Tucker, 2011 and Feldman et al., 2010)。这表示10-K报告会随着时间推移，信息价值大打折扣。尽管我们复现了这个事实，即与常规文件的变更没有重大的公告效应，但我们认为，前人的研究忽略了更重要部分(如MD&amp;A)对对资产价格的影响。</p>
</blockquote>
<blockquote>
<p>确切的说，<strong>并不是报告的披露效应的信息价值变低了，而是投资者越来越难以发现报告中微妙的信息变化， 比如因为报告变得越来越冗杂。投资者只有看到某些新闻后，才会逐渐意识到之前公司报告内容变化的的真正价值</strong>。</p>
<p>使用1995年-2014年所有美国公司季度和年度申报的完整历史记录，研究发现当公司对<strong>报告进行积极更改</strong>时，这种行为<strong>蕴含着</strong>公司未来运营的<strong>重要信号</strong>。</p>
<p><strong>财务报告的语言和结构的变化也对公司的未来收益产生重大影响</strong>：做空&quot;变化&quot;的公司（持有的公司，如果其报告发生变化的，做空该公司股票），买入“不变化”的公司，使用这样的投资组合策略，在2006年的每月alpha值高达1.88%的收益（每年超过22％）。报告中涉及执行官（CEO和CFO）团队的话语风格的变化，或者有关诉讼(风险部分)的话语的变化，都对投资的未来收益有重要作用。</p>
</blockquote>
<p><img loading="lazy" src="img/lazy-prices-1.png" alt=""  />

<img loading="lazy" src="img/lazy-prices-2.png" alt=""  />
</p>
<br>
<h3 id="案例3-女性就职高管改变组织内性别刻板印象-pnas2022">案例3-女性就职高管改变组织内性别刻板印象 PNAS2022</h3>
<p>Lawson, M. Asher, Ashley E. Martin, Imrul Huda, and Sandra C. Matz. &ldquo;Hiring women into senior leadership positions is associated with a reduction in gender stereotypes in organizational language.&rdquo; <em>Proceedings of the National Academy of Sciences</em> 119, no. 9 (2022): e2026443119.</p>
<blockquote>
<p>女性在领导职位上的代表性仍然不足。这种代表性不足至少部分是由将男性与成就导向的代理特征（例如，自信和果断）联系起来的性别刻板印象驱动的。这些刻板印象在语言中得到表达和延续，女性被描述的方式比男性少。目前的研究表明，任命女性担任高层管理人员可以减轻这些以语言表达的根深蒂固的刻板印象。我们使用自然语言处理技术分析了超过 <strong>43,000 份包含 12.3 亿字的文档，发现聘用女性首席执行官和董事会成员与组织使用语言的变化有关，因此女性的语义变得更类似于代理的语义</strong>。换句话说，雇用女性担任领导职务有助于将女性与对领导成功至关重要的特征联系起来。重要的是，我们的研究结果表明，通过增加女性代表来改变组织语言可能会为女性提供摆脱双重束缚的途径：当女性领导人被任命担任权力职位时，女性与代理的积极方面（例如，独立和自信）在语言上，不以减少与社区的联系（例如，善良和关怀）为代价。总而言之，我们的研究结果表明，女性代表不仅是目的，而且是系统地改变阴险的性别刻板印象并克服女性被认为是有能力或可爱的权衡的一种手段。</p>
<p>本文使用的词向量， 刻画研究对象的文化认知，是依对象依时间而变化的。</p>
</blockquote>
<p><img loading="lazy" src="img/hiring_women.png" alt=""  />
</p>
<br>
<h3 id="案例4--使用词嵌入技术量化近百年以来性别和族群的刻板印象-pnas2018">案例4- 使用词嵌入技术，量化近百年以来性别和族群的刻板印象 PNAS2018</h3>
<p>{{ &lt; bilibili BV1b4411X7i1 &gt;}}</p>
<br>
<h2 id="关于合作与交流">关于合作与交流</h2>
<p>如果正在推进的项目，需要用到文本分析，欢迎交流与合作 ~</p>
<p>可加微信372335839， 备注【姓名-学校-专业】, 说明来意。如果想系统获取技术细节，课程 <a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a> 内都有的技术代码和讲解，欢迎了解。</p>
<p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>ManagementScience | 使用网络算法识别创新的颠覆性与否</title>
      <link>https://textdata.cn/blog/2022-09-07-management-science-disrupt-science-and-technology/</link>
      <pubDate>Wed, 07 Sep 2022 00:00:00 +0000</pubDate>
      
      <guid>/blog/2022-09-07-management-science-disrupt-science-and-technology/</guid>
      <description>The CD index is a new approach to finding important points in evolving networks. When applied to large-scale data sets like U.S. patent citations, the index is useful for identifying influential innovations and other features of technological change.</description>
      <content:encoded><![CDATA[


<p>颠覆式创新是一个很火的概念，在创新创业、科学学等研究中，每个专利、论文的正文中都会引用关系，而引用关系会构成一个引用网络。</p>
<p>那么创新如何从网络形态进行区分，如何计算网络节点的创新程度，本文列举两篇与此相关的论文，分别是 Management science 和 Science 。</p>
<p><br><br></p>
<div id="文献摘要" class="section level2">
<h2>文献摘要</h2>
<p><strong>Funk, Russell J., and Jason Owen-Smith. “A dynamic network measure of technological change.” <em>Management science</em> 63, no. 3 (2017): 791-817.</strong></p>
<p>该文使用网络分析方法研究技术变革，论文认为 <strong>颠覆性的新发明，通过将发明者的注意力转移到或远离这些发明所依赖的知识，来重塑相互关联的技术网络。即更广的视野或更久远的视角，往往有利于颠覆性创新的产生</strong>。<strong>基于该思路，本文开发了新发明的颠覆性与否的计算指标cdindex</strong>。我们将这些指标应用于大学研究商业化的分析，并发现 <strong>联邦研究资金推动校园产生颠覆性创新，而商业联系会有利于巩固现状的创新</strong>。通过量化新技术，我们提出的指数允许基于专利的创新研究捕捉概念上重要的现象， 这些现象无法通过既定措施检测到。该测量方法提供了支持创新、创业、技术战略、科学政策和社会网络理论研究的理论发展的经验见解。</p>
<blockquote>
<p>Abstract: This article outlines a network approach to the study of technological change. We propose that new inventions reshape networks of interlinked technologies by shifting inventors’ attention to or away from the knowledge on which those inventions build. Using this approach, we develop novel indexes of the extent to which a new invention consolidates or destabilizes existing technology streams. We apply these indexes in analyses of university research commercialization and ﬁnd that, although federal research funding pushes campuses to create inventions that are more destabilizing, deeper commercial ties lead them to produce technologies that consolidate the status quo. By quantifying the eﬀects that new technologies have on their predecessors, the indexes we propose allow patent-based studies of innovation to capture conceptually important phenomena that are not detectable with established measures. The measurement approach presented here oﬀers empirical insights that support theoretical development in studies of innovation, entrepreneurship, technology strategy, science policy, and social network theory.</p>
</blockquote>
<p><br></p>
<p><strong>Wu, Lingfei, Dashun Wang, and James A. Evans. “Large teams develop and small teams disrupt science and technology.” Nature 566, no. 7744 (2019): 378-382.</strong></p>
<p>当今科学和技术最普遍的趋势之一是各个领域的大型团队的增长，因为孤独的研究人员和小型团队的流行程度正在减少 。团队规模的增加归因于科学活动的专业化、通信技术的改进 或需要跨学科解决方案的现代问题的复杂性。团队规模的这种转变引发了一个问题，即大团队所产生的科技特征是否以及如何不同于小团队。分析了 1954-2014 年期间超过 6500 万篇论文、专利和软件产品，证明在此期间，<strong>较小的团队倾向于将拉长到更大的时间尺度，借鉴过去，用新的想法和机会来颠覆科学和技术；而较大的团队倾向于聚焦于当前流行的，完善当前现有的</strong>。不论团队大小，均对于蓬勃发展的科学技术生态至关重要，并表明，为实现这一目标，科学政策应旨在支持团队规模的多样性。</p>
<blockquote>
<p>Abstract: One of the most universal trends in science and technology today is the growth of large teams in all areas, as solitary researchers and small teams diminish in prevalence. Increases in team size have been attributed to the specialization of scientific activities,
improvements in communication technology, or the complexity
of modern problems that require interdisciplinary solutions.This shift in team size raises the question of whether and how the character of the science and technology produced by large teams differs from that of small teams. Here we analyse more than 65 million papers, patents and software products that span the period 1954–2014, and demonstrate that across this period smaller teams have tended to disrupt science and technology with new ideas and opportunities, whereas larger teams have tended to develop existing ones. Work from larger teams builds on morerecent and popular developments, and attention to their work comes
immediately. By contrast, contributions by smaller teams search more deeply into the past, are viewed as disruptive to science and technology and succeed further into the future—if at all. Observed differences between small and large teams are magnified for higherimpact work, with small teams known for disruptive work and large teams for developing work. Differences in topic and research design
account for a small part of the relationship between team size and disruption; most of the effect occurs at the level of the individual, as people move between smaller and larger teams. These results demonstrate that both small and large teams are essential to a flourishing ecology of science and technology, and suggest that, to achieve this, science policies should aim to support a diversity of team sizes.</p>
</blockquote>
<p><br><br></p>
</div>
<div id="算法对比" class="section level2">
<h2>算法对比</h2>
<p>我没阅读两篇论文，仅就颠覆性与否的计算方法和图例，感觉算法实现差不多。</p>
<div class="figure">
<img src="img/cdindex-managent_science_2017.png" alt="" />
<p class="caption">上图为2017年Management Science的插图</p>
</div>
<p><br></p>
<div class="figure">
<img src="img/disruption_nature_2019.png" alt="" />
<p class="caption">上图为2019年Nature的插图</p>
</div>
<p><br><br></p>
</div>
<div id="代码数据" class="section level2">
<h2>代码数据</h2>
<p>下面分别为Management2017和Nature2019的主页，均含数据和代码。</p>
<p><a href="http://russellfunk.org/cdindex/"><img src="img/cdindex-homepage.png" /></a></p>
<p><br></p>
<p><a href="https://lingfeiwu.github.io/smallTeams/"><img src="img/nature2019-disrupt-homepage.png" /></a></p>
<p><br><br></p>
</div>
<div id="算法实现" class="section level2">
<h2>算法实现</h2>
<p>按照时间优先原则，本文就只分享Management2017论文作者Funk, Russell开源了cdindex库 (开发语言C和Python) ，安装</p>
<p><br></p>
<pre><code>pip3 install cdindex</code></pre>
<p>将Management2017 cdindex算法图 标注为如下图， 下图中左右两个网络节点是相同的，只需构造一套节点，两套边数据即可完成实验。</p>
<p><img src="img/cdindex-managent_science_2017_demo.png" /></p>
<p><br></p>
<p>我们就直接上代码</p>
<pre class="python"><code>import cdindex
import datetime

#节点，理解为专利号或者论文doi号；同时节点有先后时间属性
vertices = [{&quot;name&quot;: &quot;x1&quot;, &quot;time&quot;: datetime.datetime(1990, 1, 1)},
           {&quot;name&quot;: &quot;x2&quot;, &quot;time&quot;: datetime.datetime(1990, 1, 1)},
           {&quot;name&quot;: &quot;x3&quot;, &quot;time&quot;: datetime.datetime(1990, 1, 1)},
           {&quot;name&quot;: &quot;x4&quot;, &quot;time&quot;: datetime.datetime(1990, 1, 1)},
        
           {&quot;name&quot;: &quot;y&quot;, &quot;time&quot;: datetime.datetime(1991, 1, 1)},
          
           {&quot;name&quot;: &quot;z1&quot;, &quot;time&quot;: datetime.datetime(1995, 1, 1)},
           {&quot;name&quot;: &quot;z2&quot;, &quot;time&quot;: datetime.datetime(1995, 1, 1)},
           {&quot;name&quot;: &quot;z3&quot;, &quot;time&quot;: datetime.datetime(1995, 1, 1)},
           {&quot;name&quot;: &quot;z4&quot;, &quot;time&quot;: datetime.datetime(1995, 1, 1)},
           {&quot;name&quot;: &quot;z5&quot;, &quot;time&quot;: datetime.datetime(1995, 1, 1)},
           {&quot;name&quot;: &quot;z6&quot;, &quot;time&quot;: datetime.datetime(1995, 1, 1)}]
           
    
#edges_1边关系
#edges_1中的y为颠覆型
edges_1 = [{&quot;source&quot;: &quot;z1&quot;, &quot;target&quot;: &quot;y&quot;},
           {&quot;source&quot;: &quot;z2&quot;, &quot;target&quot;: &quot;y&quot;},
           {&quot;source&quot;: &quot;z3&quot;, &quot;target&quot;: &quot;y&quot;},
           {&quot;source&quot;: &quot;z4&quot;, &quot;target&quot;: &quot;y&quot;},
           {&quot;source&quot;: &quot;z5&quot;, &quot;target&quot;: &quot;y&quot;},
           {&quot;source&quot;: &quot;z6&quot;, &quot;target&quot;: &quot;y&quot;},
           
           {&quot;source&quot;: &quot;y&quot;, &quot;target&quot;: &quot;x1&quot;},
           {&quot;source&quot;: &quot;y&quot;, &quot;target&quot;: &quot;x2&quot;},
           {&quot;source&quot;: &quot;y&quot;, &quot;target&quot;: &quot;x3&quot;},
           {&quot;source&quot;: &quot;y&quot;, &quot;target&quot;: &quot;x4&quot;}]


#edges_2边关系 
#edges_2中的y为巩固型
edges_2 = [{&quot;source&quot;: &quot;z1&quot;, &quot;target&quot;: &quot;y&quot;},
           {&quot;source&quot;: &quot;z2&quot;, &quot;target&quot;: &quot;y&quot;},
           {&quot;source&quot;: &quot;z3&quot;, &quot;target&quot;: &quot;y&quot;},
           {&quot;source&quot;: &quot;z4&quot;, &quot;target&quot;: &quot;y&quot;},
           {&quot;source&quot;: &quot;z5&quot;, &quot;target&quot;: &quot;y&quot;},
           {&quot;source&quot;: &quot;z6&quot;, &quot;target&quot;: &quot;y&quot;},
           
           {&quot;source&quot;: &quot;y&quot;, &quot;target&quot;: &quot;x1&quot;},
           {&quot;source&quot;: &quot;y&quot;, &quot;target&quot;: &quot;x2&quot;},
           {&quot;source&quot;: &quot;y&quot;, &quot;target&quot;: &quot;x3&quot;},
           {&quot;source&quot;: &quot;y&quot;, &quot;target&quot;: &quot;x4&quot;},
          
          {&quot;source&quot;: &quot;z1&quot;, &quot;target&quot;: &quot;x1&quot;},
          {&quot;source&quot;: &quot;z2&quot;, &quot;target&quot;: &quot;x1&quot;},
          {&quot;source&quot;: &quot;z3&quot;, &quot;target&quot;: &quot;x2&quot;},
           
          {&quot;source&quot;: &quot;z4&quot;, &quot;target&quot;: &quot;x3&quot;},
          {&quot;source&quot;: &quot;z5&quot;, &quot;target&quot;: &quot;x3&quot;},
          {&quot;source&quot;: &quot;z5&quot;, &quot;target&quot;: &quot;x4&quot;},
          {&quot;source&quot;: &quot;z6&quot;, &quot;target&quot;: &quot;x4&quot;}]



# 构建两个网络
graph1 = cdindex.Graph() #颠覆型
graph2 = cdindex.Graph() #发展型

# 添加节点
for vertex in vertices:
    graph1.add_vertex(vertex[&quot;name&quot;], cdindex.timestamp_from_datetime(vertex[&quot;time&quot;]))
    graph2.add_vertex(vertex[&quot;name&quot;], cdindex.timestamp_from_datetime(vertex[&quot;time&quot;]))

# 添加引用关系
for edge in edges_1:
    graph1.add_edge(edge[&quot;source&quot;], edge[&quot;target&quot;])
for edge in edges_2:
    graph2.add_edge(edge[&quot;source&quot;], edge[&quot;target&quot;])
    
    
#y研究发布后1825天内，引用y的论文(专利)列入网络。
t_delta = int(datetime.timedelta(days=1825).total_seconds())

#计算cdindex得分
score1 = graph1.cdindex(&quot;y&quot;, t_delta)
score2 = graph2.cdindex(&quot;y&quot;, t_delta)

print(&#39;左侧-网络中的y节点的cdinex得分: {}, 节点y 为颠覆性创新&#39;.format(score1))</code></pre>
<pre><code>## 左侧-网络中的y节点的cdinex得分: 1.0, 节点y 为颠覆性创新</code></pre>
<p><br></p>
<pre class="python"><code>print(&#39;右侧-网络中的y节点的cdinex得分: {}, 节点y 为发展性创新&#39;.format(score2))</code></pre>
<pre><code>## 右侧-网络中的y节点的cdinex得分: -1.0, 节点y 为发展性创新</code></pre>
<p><br><br></p>
</div>
<div id="cdindex" class="section level2">
<h2>cdindex</h2>
<p>对比Python的结果，与论文计算过程，完全一致。cdindex内部实现我不太熟悉，如果想了解cdindex内部实现，可前往 <a href="https://github.com/russellfunk/cdindex" class="uri">https://github.com/russellfunk/cdindex</a> 阅读cdindex库的源码。
<img src="img/cdindex-managent_science_2017.png" /></p>
</div>
]]></content:encoded>
    </item>
    
    <item>
      <title>实战 | 构建基于客户细分的 K-Means 聚类算法！</title>
      <link>https://textdata.cn/blog/customer_segment_with_kmeans/</link>
      <pubDate>Thu, 09 Jun 2022 18:43:10 +0600</pubDate>
      
      <guid>/blog/customer_segment_with_kmeans/</guid>
      <description>客群细分对于企业了解目标受众非常重要。根据受众群体的不同，我们可以给采取不同的营销策略。目前有许多无监督的机器学习算法可以帮助公司识别他们的用户群并创建消费群体。</description>
      <content:encoded><![CDATA[<p>客群细分对于企业了解目标受众非常重要。根据受众群体的不同，我们可以给采取不同的营销策略。目前有许多无监督的机器学习算法可以帮助公司识别他们的用户群并创建消费群体。</p>
<p>在本文中，我将分享一种目前比较流行的 K-Means 聚类的无监督学习技术。K-Means的目标是将所有可用的数据分组为彼此不同的不重叠的子组。K-Means聚类是数据科学家用来帮助公司进行客户细分的常用技术。</p>
<p>在本文中，你将了解以下内容：</p>
<ul>
<li>K-Means聚类的数据预处理</li>
<li>从头构建K-Means聚类算法</li>
<li>用于评估聚类模型性能的指标</li>
<li>可视化构建簇类</li>
<li>簇类构建的解读与分析</li>
</ul>
<h2 id="代码下载">代码下载</h2>
<p><a href="customer_segment_with_kmeans.zip">点击下载</a></p>
<br>
<h2 id="预备知识">预备知识</h2>
<p>在开始之前安装以下库：pandas、numpy、matplotlib、seaborn、sciket learn、kneed。完成后，我们就可以开始制作模型了！</p>
<p>本文中要的数据集可以文末下载，运行以下代码行以导入必要的库并读取数据集：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;Mall_Customers.csv&#39;</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>CustomerID</th>
      <th>Gender</th>
      <th>Age</th>
      <th>Annual Income (k$)</th>
      <th>Spending Score (1-100)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>Male</td>
      <td>19</td>
      <td>15</td>
      <td>39</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>Male</td>
      <td>21</td>
      <td>15</td>
      <td>81</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>Female</td>
      <td>20</td>
      <td>16</td>
      <td>6</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>Female</td>
      <td>23</td>
      <td>16</td>
      <td>77</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>Female</td>
      <td>31</td>
      <td>17</td>
      <td>40</td>
    </tr>
  </tbody>
</table>
</div>
<p>数据集中有五个变量。CustomerID是数据集中每个客户的唯一标识符，我们可以删除这个变量。它没有为我们提供任何有用的集群信息。由于 gender 是一个分类变量，它需要编码并转换成数字。</p>
<p>在输入模型之前，其他所有变量都将按正态分布进行缩放。我们将标准化这些变量，平均值为0，标准偏差为1。</p>
<br>
<h2 id="标准化变量">标准化变量</h2>
<p>首先，让我们标准化数据集中的所有变量，使它们在相同的范围内。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>

<span class="n">col_names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Annual Income (k$)&#39;</span><span class="p">,</span> <span class="s1">&#39;Age&#39;</span><span class="p">,</span> <span class="s1">&#39;Spending Score (1-100)&#39;</span><span class="p">]</span>
<span class="n">features</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">col_names</span><span class="p">]</span>

<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">features</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
<span class="n">features</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">features</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
<span class="n">scaled_features</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">columns</span> <span class="o">=</span> <span class="n">col_names</span><span class="p">)</span>
<span class="n">scaled_features</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Annual Income (k$)</th>
      <th>Age</th>
      <th>Spending Score (1-100)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>-1.738999</td>
      <td>-1.424569</td>
      <td>-0.434801</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-1.738999</td>
      <td>-1.281035</td>
      <td>1.195704</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-1.700830</td>
      <td>-1.352802</td>
      <td>-1.715913</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-1.700830</td>
      <td>-1.137502</td>
      <td>1.040418</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-1.662660</td>
      <td>-0.563369</td>
      <td>-0.395980</td>
    </tr>
  </tbody>
</table>
</div>
<p>我们可以看到所有的变量都被转换了，现在都以零为中心。</p>
<br>
<h2 id="热编码">热编码</h2>
<p>变量&quot;gender&quot;是分类变量，我们需要把它转换成一个数值变量，可以用pd.get_dummies()来处理。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">gender</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Gender&#39;</span><span class="p">]</span>
<span class="n">newdf</span> <span class="o">=</span> <span class="n">scaled_features</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">gender</span><span class="p">)</span>

<span class="n">newdf</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">newdf</span><span class="p">,</span> <span class="n">prefix</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">prefix_sep</span><span class="o">=</span><span class="s1">&#39;_&#39;</span><span class="p">,</span> <span class="n">dummy_na</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">drop_first</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

<span class="n">newdf</span> <span class="o">=</span> <span class="n">newdf</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s1">&#39;Gender_Male&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">newdf</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Annual Income (k$)</th>
      <th>Age</th>
      <th>Spending Score (1-100)</th>
      <th>Gender_Female</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>-1.738999</td>
      <td>-1.424569</td>
      <td>-0.434801</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-1.738999</td>
      <td>-1.281035</td>
      <td>1.195704</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-1.700830</td>
      <td>-1.352802</td>
      <td>-1.715913</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-1.700830</td>
      <td>-1.137502</td>
      <td>1.040418</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-1.662660</td>
      <td>-0.563369</td>
      <td>-0.395980</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>
<p>可以看到，性别变量已经发生了变化，从数据框中删除了“Gender_Male”。这是因为不需要再保留变量了。</p>
<br>
<h2 id="建立聚类模型">建立聚类模型</h2>
<p>让我们构建一个 K-means 聚类模型，并将其拟合到数据集中的所有变量上，我们用肘部图可视化聚类模型的性能，它会告诉我们在构建模型时使用的「最佳聚类数」。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">SSE</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">cluster</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">10</span><span class="p">):</span>
    <span class="n">kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span> <span class="o">=</span> <span class="n">cluster</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="s1">&#39;k-means++&#39;</span><span class="p">)</span>
    <span class="n">kmeans</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">newdf</span><span class="p">)</span>
    <span class="n">SSE</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">kmeans</span><span class="o">.</span><span class="n">inertia_</span><span class="p">)</span>

<span class="c1"># converting the results into a dataframe and plotting them</span>

<span class="n">frame</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;Cluster&#39;</span><span class="p">:</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">10</span><span class="p">),</span> <span class="s1">&#39;SSE&#39;</span><span class="p">:</span><span class="n">SSE</span><span class="p">})</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">frame</span><span class="p">[</span><span class="s1">&#39;Cluster&#39;</span><span class="p">],</span> <span class="n">frame</span><span class="p">[</span><span class="s1">&#39;SSE&#39;</span><span class="p">],</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Number of clusters&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Inertia&#39;</span><span class="p">)</span>
</code></pre></div><pre><code>Text(0, 0.5, 'Inertia')
</code></pre>
<p>​ <br>
<img loading="lazy" src="output_9_1.png" alt="png"  />

​</p>
<p>根据上面的「肘部图」，我们可以看到最佳聚类数为「4」</p>
<br>
<h2 id="轮廓系数">轮廓系数</h2>
<p>轮廓系数或轮廓分数是用于评估该算法创建的簇的质量的方法。轮廓分数在-1到+1之间。轮廓分数越高，模型越好。轮廓分数度量同一簇中所有数据点之间的距离。这个距离越小，轮廓分数就越好。</p>
<p>让我们计算一下我们刚刚建立的模型的轮廓分数：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">silhouette_score</span>
<span class="c1"># First, build a model with 4 clusters</span>

<span class="n">kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="s1">&#39;k-means++&#39;</span><span class="p">)</span>
<span class="n">kmeans</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">newdf</span><span class="p">)</span>

<span class="c1"># Now, print the silhouette score of this model</span>

<span class="nb">print</span><span class="p">(</span><span class="n">silhouette_score</span><span class="p">(</span><span class="n">newdf</span><span class="p">,</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">labels_</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s1">&#39;euclidean&#39;</span><span class="p">))</span>
</code></pre></div><pre><code>0.35027020434653977
</code></pre>
<p>轮廓线得分约为「0.35」。这是一个不错的模型，但我们可以做得更好，并尝试获得更高的簇群分离。</p>
<p>在我们尝试这样做之前，让我们将刚刚构建的聚类可视化，以了解模型的运行情况：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">clusters</span> <span class="o">=</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">newdf</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">1</span><span class="p">:])</span>

<span class="n">newdf</span><span class="p">[</span><span class="s2">&#34;label&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="n">clusters</span>
 
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">21</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">,</span> <span class="n">projection</span><span class="o">=</span><span class="s1">&#39;3d&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">newdf</span><span class="p">[</span><span class="s1">&#39;Age&#39;</span><span class="p">][</span><span class="n">newdf</span><span class="o">.</span><span class="n">label</span> <span class="o">==</span> <span class="mi">0</span><span class="p">],</span> 
           <span class="n">newdf</span><span class="p">[</span><span class="s2">&#34;Annual Income (k$)&#34;</span><span class="p">][</span><span class="n">newdf</span><span class="o">.</span><span class="n">label</span> <span class="o">==</span> <span class="mi">0</span><span class="p">],</span> 
           <span class="n">df</span><span class="p">[</span><span class="s2">&#34;Spending Score (1-100)&#34;</span><span class="p">][</span><span class="n">newdf</span><span class="o">.</span><span class="n">label</span> <span class="o">==</span> <span class="mi">0</span><span class="p">],</span> 
           <span class="n">c</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">60</span><span class="p">)</span>

<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">newdf</span><span class="p">[</span><span class="s1">&#39;Age&#39;</span><span class="p">][</span><span class="n">newdf</span><span class="o">.</span><span class="n">label</span> <span class="o">==</span> <span class="mi">1</span><span class="p">],</span> 
           <span class="n">newdf</span><span class="p">[</span><span class="s2">&#34;Annual Income (k$)&#34;</span><span class="p">][</span><span class="n">newdf</span><span class="o">.</span><span class="n">label</span> <span class="o">==</span> <span class="mi">1</span><span class="p">],</span> 
           <span class="n">newdf</span><span class="p">[</span><span class="s2">&#34;Spending Score (1-100)&#34;</span><span class="p">][</span><span class="n">newdf</span><span class="o">.</span><span class="n">label</span> <span class="o">==</span> <span class="mi">1</span><span class="p">],</span> 
           <span class="n">c</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">60</span><span class="p">)</span>

<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">newdf</span><span class="p">[</span><span class="s1">&#39;Age&#39;</span><span class="p">][</span><span class="n">newdf</span><span class="o">.</span><span class="n">label</span> <span class="o">==</span> <span class="mi">2</span><span class="p">],</span> 
           <span class="n">newdf</span><span class="p">[</span><span class="s2">&#34;Annual Income (k$)&#34;</span><span class="p">][</span><span class="n">newdf</span><span class="o">.</span><span class="n">label</span> <span class="o">==</span> <span class="mi">2</span><span class="p">],</span> 
           <span class="n">df</span><span class="p">[</span><span class="s2">&#34;Spending Score (1-100)&#34;</span><span class="p">][</span><span class="n">newdf</span><span class="o">.</span><span class="n">label</span> <span class="o">==</span> <span class="mi">2</span><span class="p">],</span> 
           <span class="n">c</span><span class="o">=</span><span class="s1">&#39;green&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">60</span><span class="p">)</span>

<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">newdf</span><span class="p">[</span><span class="s1">&#39;Age&#39;</span><span class="p">][</span><span class="n">newdf</span><span class="o">.</span><span class="n">label</span> <span class="o">==</span> <span class="mi">3</span><span class="p">],</span> 
           <span class="n">newdf</span><span class="p">[</span><span class="s2">&#34;Annual Income (k$)&#34;</span><span class="p">][</span><span class="n">newdf</span><span class="o">.</span><span class="n">label</span> <span class="o">==</span> <span class="mi">3</span><span class="p">],</span> 
           <span class="n">newdf</span><span class="p">[</span><span class="s2">&#34;Spending Score (1-100)&#34;</span><span class="p">][</span><span class="n">newdf</span><span class="o">.</span><span class="n">label</span> <span class="o">==</span> <span class="mi">3</span><span class="p">],</span> 
           <span class="n">c</span><span class="o">=</span><span class="s1">&#39;orange&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">60</span><span class="p">)</span>

<span class="n">ax</span><span class="o">.</span><span class="n">view_init</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span> <span class="mi">185</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div><p>​ <br>
<img loading="lazy" src="output_13_0.png" alt="png"  />

​</p>
<p>从上图可以看出，簇类分离度不是很大。红点与蓝色混合，绿色与黄色重叠，这与轮廓分数一起向我们表明该模型表现不佳。现在，让我们创建一个比这个模型具有更好集群可分离性的新模型。</p>
<br>
<h2 id="建立聚类模型2">建立聚类模型2</h2>
<p>对于这个模型，让我们做一些特征选择。我们可以使用一种叫做主成分分析（PCA）的技术。</p>
<p>PCA 是一种帮助我们降低数据集维数的技术。现在，让我们在数据集上运行PCA：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>

<span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="n">principalComponents</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">newdf</span><span class="p">)</span>

<span class="n">features</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="n">pca</span><span class="o">.</span><span class="n">n_components_</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">pca</span><span class="o">.</span><span class="n">explained_variance_ratio_</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;PCA features&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;variance %&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>

<span class="n">PCA_components</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">principalComponents</span><span class="p">)</span>
</code></pre></div><p>​ <br>
<img loading="lazy" src="output_15_0.png" alt="png"  />

​</p>
<p>这张图表显示了每个主成分分析的组成，以及它的方差。我们可以看到前两个主成分解释了大约70%的数据集方差。我们可以将这两个组件输入到模型中再次构建模型，并选择要使用的簇的数量</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">ks</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">inertias</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">ks</span><span class="p">:</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="n">k</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">PCA_components</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,:</span><span class="mi">2</span><span class="p">])</span>
    <span class="n">inertias</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">inertia_</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ks</span><span class="p">,</span> <span class="n">inertias</span><span class="p">,</span> <span class="s1">&#39;-o&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;number of clusters, k&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;inertia&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">ks</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="output_17_0.png" alt="png"  />

​</p>
<p>同样，看起来「最佳簇数是4」。我们可以用4个簇来计算此模型的轮廓分数：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">model</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">PCA_components</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,:</span><span class="mi">2</span><span class="p">])</span>

<span class="c1"># silhouette score</span>
<span class="nb">print</span><span class="p">(</span><span class="n">silhouette_score</span><span class="p">(</span><span class="n">PCA_components</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,:</span><span class="mi">2</span><span class="p">],</span> <span class="n">model</span><span class="o">.</span><span class="n">labels_</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s1">&#39;euclidean&#39;</span><span class="p">))</span>
</code></pre></div><pre><code>0.6025604455573874
</code></pre>
<p>这个模型的轮廓分数是「0.42」，这比我们之前创建的模型要好。我们可以像前面一样可视化此模型：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">model</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>

<span class="n">clusters</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">PCA_components</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,:</span><span class="mi">2</span><span class="p">])</span>
<span class="n">newdf</span><span class="p">[</span><span class="s2">&#34;label&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="n">clusters</span>
 
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">21</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">,</span> <span class="n">projection</span><span class="o">=</span><span class="s1">&#39;3d&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">newdf</span><span class="o">.</span><span class="n">Age</span><span class="p">[</span><span class="n">newdf</span><span class="o">.</span><span class="n">label</span> <span class="o">==</span> <span class="mi">0</span><span class="p">],</span> <span class="n">newdf</span><span class="p">[</span><span class="s2">&#34;Annual Income (k$)&#34;</span><span class="p">][</span><span class="n">newdf</span><span class="o">.</span><span class="n">label</span> <span class="o">==</span> <span class="mi">0</span><span class="p">],</span> <span class="n">newdf</span><span class="p">[</span><span class="s2">&#34;Spending Score (1-100)&#34;</span><span class="p">][</span><span class="n">newdf</span><span class="o">.</span><span class="n">label</span> <span class="o">==</span> <span class="mi">0</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">60</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">newdf</span><span class="o">.</span><span class="n">Age</span><span class="p">[</span><span class="n">newdf</span><span class="o">.</span><span class="n">label</span> <span class="o">==</span> <span class="mi">1</span><span class="p">],</span> <span class="n">newdf</span><span class="p">[</span><span class="s2">&#34;Annual Income (k$)&#34;</span><span class="p">][</span><span class="n">newdf</span><span class="o">.</span><span class="n">label</span> <span class="o">==</span> <span class="mi">1</span><span class="p">],</span> <span class="n">newdf</span><span class="p">[</span><span class="s2">&#34;Spending Score (1-100)&#34;</span><span class="p">][</span><span class="n">newdf</span><span class="o">.</span><span class="n">label</span> <span class="o">==</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">60</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">newdf</span><span class="o">.</span><span class="n">Age</span><span class="p">[</span><span class="n">newdf</span><span class="o">.</span><span class="n">label</span> <span class="o">==</span> <span class="mi">2</span><span class="p">],</span> <span class="n">newdf</span><span class="p">[</span><span class="s2">&#34;Annual Income (k$)&#34;</span><span class="p">][</span><span class="n">newdf</span><span class="o">.</span><span class="n">label</span> <span class="o">==</span> <span class="mi">2</span><span class="p">],</span> <span class="n">newdf</span><span class="p">[</span><span class="s2">&#34;Spending Score (1-100)&#34;</span><span class="p">][</span><span class="n">newdf</span><span class="o">.</span><span class="n">label</span> <span class="o">==</span> <span class="mi">2</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;green&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">60</span><span class="p">)</span>

<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">newdf</span><span class="o">.</span><span class="n">Age</span><span class="p">[</span><span class="n">newdf</span><span class="o">.</span><span class="n">label</span> <span class="o">==</span> <span class="mi">3</span><span class="p">],</span> <span class="n">newdf</span><span class="p">[</span><span class="s2">&#34;Annual Income (k$)&#34;</span><span class="p">][</span><span class="n">newdf</span><span class="o">.</span><span class="n">label</span> <span class="o">==</span> <span class="mi">3</span><span class="p">],</span> <span class="n">newdf</span><span class="p">[</span><span class="s2">&#34;Spending Score (1-100)&#34;</span><span class="p">][</span><span class="n">newdf</span><span class="o">.</span><span class="n">label</span> <span class="o">==</span> <span class="mi">3</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;orange&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">60</span><span class="p">)</span>

<span class="n">ax</span><span class="o">.</span><span class="n">view_init</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span> <span class="mi">185</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div><p>​ <br>
<img loading="lazy" src="output_21_0.png" alt="png"  />

​</p>
<br> 
<h2 id="模型1与模型2">模型1与模型2</h2>
<p>让我们比较一下这个模型和第一个模型的聚类可分性：</p>
<p>第二个模型中的簇比第一个模型中的簇分离得好得多。此外，第二个模型的轮廓分数要高得多。基于这些原因，我们可以选择第二个模型进行分析。</p>
<br>
<h2 id="聚类分析">聚类分析</h2>
<p>首先，让我们将簇类映射回数据集，并查看数据帧。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;Mall_Customers.csv&#39;</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s1">&#39;CustomerID&#39;</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># map back clusters to dataframe</span>

<span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">PCA_components</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,:</span><span class="mi">2</span><span class="p">])</span>
<span class="n">frame</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
<span class="n">frame</span><span class="p">[</span><span class="s1">&#39;cluster&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pred</span>
<span class="n">frame</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Gender</th>
      <th>Age</th>
      <th>Annual Income (k$)</th>
      <th>Spending Score (1-100)</th>
      <th>cluster</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Male</td>
      <td>19</td>
      <td>15</td>
      <td>39</td>
      <td>3</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Male</td>
      <td>21</td>
      <td>15</td>
      <td>81</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Female</td>
      <td>20</td>
      <td>16</td>
      <td>6</td>
      <td>3</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Female</td>
      <td>23</td>
      <td>16</td>
      <td>77</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Female</td>
      <td>31</td>
      <td>17</td>
      <td>40</td>
      <td>3</td>
    </tr>
  </tbody>
</table>
</div>
<p>数据帧中的每一行现在都分配给一个集群。要比较不同群集的属性，请查找每个群集上所有变量的平均值：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">avg_df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">([</span><span class="s1">&#39;cluster&#39;</span><span class="p">],</span> <span class="n">as_index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

<span class="n">avg_df</span>
</code></pre></div><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>cluster</th>
      <th>Age</th>
      <th>Annual Income (k$)</th>
      <th>Spending Score (1-100)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>25.521739</td>
      <td>26.304348</td>
      <td>78.565217</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>51.681818</td>
      <td>62.125000</td>
      <td>33.750000</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2</td>
      <td>32.904762</td>
      <td>84.380952</td>
      <td>80.500000</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3</td>
      <td>26.659574</td>
      <td>53.106383</td>
      <td>40.042553</td>
    </tr>
  </tbody>
</table>
</div>
<p>如果我们将这些簇可视化，我们可以更容易地解释它们。运行以下代码以获得每个变量的不同可视化效果：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="n">sns</span><span class="o">.</span><span class="n">barplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s1">&#39;cluster&#39;</span><span class="p">,</span><span class="n">y</span><span class="o">=</span><span class="s1">&#39;Age&#39;</span><span class="p">,</span><span class="n">data</span><span class="o">=</span><span class="n">avg_df</span><span class="p">)</span>
</code></pre></div><pre><code>&lt;AxesSubplot:xlabel='cluster', ylabel='Age'&gt;
</code></pre>
<p>​ <br>
<img loading="lazy" src="output_27_1.png" alt="png"  />

​</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">sns</span><span class="o">.</span><span class="n">barplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s1">&#39;cluster&#39;</span><span class="p">,</span><span class="n">y</span><span class="o">=</span><span class="s1">&#39;Spending Score (1-100)&#39;</span><span class="p">,</span><span class="n">data</span><span class="o">=</span><span class="n">avg_df</span><span class="p">)</span>
</code></pre></div><pre><code>&lt;AxesSubplot:xlabel='cluster', ylabel='Spending Score (1-100)'&gt;
</code></pre>
<p>​ <br>
<img loading="lazy" src="output_28_1.png" alt="png"  />

​</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">sns</span><span class="o">.</span><span class="n">barplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s1">&#39;cluster&#39;</span><span class="p">,</span><span class="n">y</span><span class="o">=</span><span class="s1">&#39;Annual Income (k$)&#39;</span><span class="p">,</span><span class="n">data</span><span class="o">=</span><span class="n">avg_df</span><span class="p">)</span>
</code></pre></div><pre><code>&lt;AxesSubplot:xlabel='cluster', ylabel='Annual Income (k$)'&gt;
</code></pre>
<p>​ <br>
<img loading="lazy" src="output_29_1.png" alt="png"  />

​</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df2</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">([</span><span class="s1">&#39;cluster&#39;</span><span class="p">,</span><span class="s1">&#39;Gender&#39;</span><span class="p">])[</span><span class="s1">&#39;Gender&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">count</span><span class="p">())</span>
<span class="n">df2</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th></th>
      <th>Gender</th>
    </tr>
    <tr>
      <th>cluster</th>
      <th>Gender</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="2" valign="top">0</th>
      <th>Female</th>
      <td>14</td>
    </tr>
    <tr>
      <th>Male</th>
      <td>9</td>
    </tr>
    <tr>
      <th rowspan="2" valign="top">1</th>
      <th>Female</th>
      <td>47</td>
    </tr>
    <tr>
      <th>Male</th>
      <td>41</td>
    </tr>
    <tr>
      <th>2</th>
      <th>Female</th>
      <td>23</td>
    </tr>
  </tbody>
</table>
</div>
<p>各细分市场的主要特点</p>
<p><strong>簇类0</strong>:</p>
<ul>
<li>年平均收入高，支出低。</li>
<li>平均年龄在40岁左右，性别以男性为主。</li>
</ul>
<p><strong>簇类1</strong>：</p>
<ul>
<li>中低收入，平均消费能力。</li>
<li>平均年龄在50岁左右，性别以女性为主。</li>
</ul>
<p><strong>簇类2</strong>：</p>
<ul>
<li>平均收入低，消费分数高。</li>
<li>平均年龄在25岁左右，性别以女性为主。</li>
</ul>
<p><strong>簇类3</strong>：</p>
<ul>
<li>平均收入高，消费分数高。</li>
<li>平均年龄在30岁左右，性别以女性为主。</li>
</ul>
<p>值得注意的是，计算年龄中位数将有助于更好地了解每个集群内的年龄分布。</p>
<p>而且，女性在整个数据集中的代表性更高，这就是为什么大多数集群中女性的数量比男性多。我们可以找到每个性别相对于整个数据集中的数字的百分比，以便更好地了解性别分布。</p>
<br>
<h2 id="为每个簇类构建角色">为每个簇类构建角色</h2>
<p>作为一名数据科学家，能够用你的分析讲述一个故事是一项重要的技能，这将帮助你的客户或利益相关者更容易理解你的发现。下面是一个基于创建的簇类构建消费者角色的示例：</p>
<p><strong>簇类0</strong></p>
<p>这个角色由对金钱非常谨慎的中年人组成。尽管与所有其他群体中的个人相比，他们的平均收入最高，但花费最少。这可能是因为他们有经济责任——比如为孩子的高等教育存钱。</p>
<p>建议：促销、优惠券和折扣代码将吸引这一领域的个人，因为他们倾向于少花钱。</p>
<p><strong>簇类1</strong></p>
<p>这部分人包括一个年龄较大的群体。他们挣的少，花的少，而且可能正在为退休储蓄。</p>
<p>建议：针对这些人的营销可以向这一领域的人推广医疗保健相关产品。</p>
<p><strong>簇类2</strong></p>
<p>这一部分由较年轻的年龄组组成。这部分人最有可能是第一批求职者。与其他人相比，他们赚的钱最少。然而，这些人都是热情的年轻人，他们喜欢过上好的生活方式，而且往往超支消费。</p>
<p>建议：由于这些年轻人花费很多，给他们提供旅游优惠券或酒店折扣可能是个好主意。为他们提供折扣的顶级服装和化妆品品牌也将很好地为这一部分。</p>
<p><strong>簇类3</strong></p>
<p>这部分人是由中年人组成的。这些人努力工作，积累了大量财富。他们也花大量的钱来过好的生活。</p>
<p>建议：由于他们的消费能力和人口结构，这些人很可能会寻找房产购买或投资。</p>
<br>
<h2 id="结论">结论</h2>
<p>在本文中，我已经详细的建立了一个用于客户细分的 K-Means 聚类模型。我们还探讨了聚类分析，并分析了每个聚类中个体的行为。最后，我们看了一些可以根据集群中每个人的属性提供的业务建议。</p>
<br>
<br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>转载 | 从符号到嵌入：计算社会科学的两种文本表示</title>
      <link>https://textdata.cn/blog/from_sysbol_to_embeddings_in_computational_social_science/</link>
      <pubDate>Mon, 25 Apr 2022 10:40:10 +0600</pubDate>
      
      <guid>/blog/from_sysbol_to_embeddings_in_computational_social_science/</guid>
      <description>如何有效地表示数据以挖掘我们想要的计算社会科学的含义？为了探索答案，我们对 CSS 中文本和网络的数据表示进行了彻底的回顾，我们将现有的表示总结为两个方案，即基于符号的表示和基于嵌入的表示。How to efficiently represent data to mine the implications we want for computational social science? To explore the answer, we conduct a thorough review of data representations for text and the web in CSS, and we summarize existing representations into two schemes, symbol-based and embedding-based</description>
      <content:encoded><![CDATA[<p>B站看到大牛刘知远关于文本分析在计算社会科学领域应用的分享，解答了我对文本表示的疑惑，看完了能对文本的特征工程加深理解，同时也能更清晰未来如何借助计算机科学技术开展社会科学研究。</p>
<blockquote>
<p><strong>全文摘抄自</strong></p>
<p>Chen, H., Yang, C., Zhang, X., Liu, Z., Sun, M. and Jin, J., 2021. From Symbols to Embeddings: A Tale of Two Representations in Computational Social Science. Journal of Social Computing, 2(2), pp.103-156.</p>
</blockquote>
<iframe
    src="//player.bilibili.com/player.html?bvid=BV1qi4y1Q7qj&page=1"
    scrolling="no"
    height="500px"
    width="800px"
    frameborder="no"
    framespacing="0"
    allowfullscreen="true"
>
</iframe>

<br>
<h2 id="摘要">摘要</h2>
<p><strong>计算社会科学</strong>（CSS），旨在利用计算方法来解决社会科学问题，是一个新兴和快速发展的领域。 CSS 的研究是数据驱动的，并且显着受益于在线用户生成内容和社交网络的可用性，其中包含用于调查的富文本和网络数据。然而，这些大规模、多模态的数据也给研究人员带来了很大的挑战：<strong>如何有效地表示数据以挖掘我们想要的 CSS 含义</strong>？为了探索答案，<strong>我们对 CSS 中文本和网络的数据表示进行了彻底的回顾，我们将现有的表示总结为两个方案，即基于符号的表示和基于嵌入的表示</strong>，并为每个方案介绍了一系列典型的方法。随后，我们基于对来自 6 个涉及 CSS 的顶级场所的 400 多篇研究文章的调查，展示了上述表示的应用。从这些应用程序的统计数据中，<strong>我们挖掘出每种表示的强度，并发现基于嵌入的表示在过去十年中出现并获得越来越多的关注的趋势</strong>。最后，我们讨论了几个关键挑战和未来方向的开放性问题。本调查旨在为 CSS 研究人员提供对数据表示的更深入理解和更明智的应用。</p>
<p><strong>关键词</strong>：计算社会科学；基于符号的表示；基于嵌入的表示；社交网络</p>
<br>
<h2 id="一计算社会学数据分析流程">一、计算社会学数据分析流程</h2>
<p>其中第二步，数据表示目前有两大类表示(特征工程)方法</p>
<ul>
<li><strong>基于符号的文本表示</strong>；符号可以是单词(或词组)，也可以是概念(如正面情感、负面情感)</li>
<li><strong>基于嵌入(分布式)的文本表示</strong>；相比于符号法，将词(词组)看做一个点。嵌入表示认为词是存在更多浅藏含义，存在亲疏远近，是可以比较的词向量。词向量可以有v(king)-v(queen)约等于v(man)-v(woman)</li>
</ul>
<p><img loading="lazy" src="img/fig1.png" alt=""  />
</p>
<br>
<h2 id="二基于符号的文本表示">二、基于符号的文本表示</h2>
<p>基于符号的文本表示一般来说默认词语是不可分的符号，每个词能根据词频统计出现次数的多与少，或是否存在。</p>
<h3 id="21-词语层面">2.1 词语层面</h3>
<ul>
<li>
<p>基于词频表示</p>
<ul>
<li>是否出现，出现标位1，反之标位0。</li>
<li>出现多少，词语出现几次，标为几个。</li>
</ul>
</li>
<li>
<p>基于特征表示，如每个词带有权重(得分)</p>
</li>
<li>
<p>基于网络表示，如词语共现网络(矩阵)</p>
</li>
</ul>
<h3 id="22-句子层面">2.2 句子层面</h3>
<ul>
<li>
<p>基于词频的表示</p>
<ul>
<li>one-hot 将文本转为向量，向量中每个数，词语出现标位1，反之标位0</li>
<li>bag-of-words，将文本转为向量，向量中每个数，词语出现n次标记为n</li>
<li>n-grams，对词组的处理，将词组看做一个单词(整体)。</li>
<li>Tf-Idf ,该算法分为tf和idf两部分。其中tf与bag-of-words类似，考虑词语出现次数。而idf还考虑词语在语料中出现场景的稀缺性程度。</li>
</ul>
</li>
<li>
<p>基于语法特征，如句法依存关系，类似于英语语法，将句子分为主谓宾、动词、名词等。</p>
</li>
<li>
<p>词典法，如使用正、负情感词典，对文本数据进行情感分析，可以得到pos和neg的各自得分</p>
</li>
</ul>
<p><img loading="lazy" src="img/fig2.png" alt=""  />
</p>
<br>
<h2 id="三基于嵌入的文本表示">三、基于嵌入的文本表示</h2>
<h3 id="31词语层面">3.1词语层面</h3>
<p>嵌入表示认为词是存在更多浅藏含义，存在亲疏远近，是可以比较的词向量。词向量可以有v(best)-v(good)约等于v(worst)-v(bad)</p>
<h3 id="32-句子层面">3.2 句子层面</h3>
<p>词语是向量，那么由词语组成的句子也会加权得到一个向量。含有相似话题或含义相近的句子在多维向量空间中会比较接近。</p>
<p><img loading="lazy" src="img/fig7.png" alt=""  />
</p>
<br>
<h2 id="四任务分类文本的用法">四、任务分类：文本的用法</h2>
<p><img loading="lazy" src="img/fig16.png" alt=""  />
</p>
<p>有了文本数据，刚刚解决了如何表示文本。接下来，需要明确，我们使用文本目的是为了做哪类分析，得到哪些信息。有8种常见的文本分析图式</p>
<ul>
<li>描述性。如随时间推移，词频的发展趋势是变大的</li>
<li>相关性。</li>
<li>聚类。如lda话题分析、k-means聚类</li>
<li>相似度。两个文档转为向量后，可以通过cosine计算相似度</li>
<li>分类。机器学习分类，判断某文本隶属于哪个类别</li>
<li>回归。例如根据文本，判断某件事发生的概率</li>
<li>语言模型。</li>
<li>排序。</li>
</ul>
<br>
<h2 id="五发文趋势-符号vs嵌入">五、发文趋势-符号vs嵌入</h2>
<p>基于上一节中对应用程序的介绍，可以观察到基于符号和基于嵌入的表示在 <strong>计算社会科学</strong>中都得到了相当大的采用。为了明确研究它们的覆盖范围，我们计算了每年使用两种表示中的一种或两种的作品数量，如图 17 所示。通过比较nature、science、pnas三大顶级期刊，我们可以发现使用<strong>基于嵌入表示</strong>的文章比例在过去几年中逐渐。这表明越来越多的 计算社会科学文章 已经考虑并受益于基于嵌入表示。</p>
<p>图 18 显示了在 计算机领域ACL、WWW 和 KDD 的会议上中，发现使用基于嵌入的表示的文章数量已大大超过使用基于符号的表示的文章数量。然而，与图 17 相比，计算机科学会议中基于嵌入的表示的数量与三个多学科期刊之间存在很大差距。</p>
<p><img loading="lazy" src="img/3_top_journals.png" alt=""  />
</p>
<p><img loading="lazy" src="img/nlp.png" alt=""  />
</p>
<p>总而言之，在过去十年中，基于嵌入的表示已经出现并在 计算社会科学 中发挥着越来越重要的作用。</p>
<br>
<h2 id="六趋势解读">六、趋势解读</h2>
<p>基于它们的内部机制和现有应用，对趋势解读，我们总结出以下三个关键点。</p>
<p>基于符号的表示因其明确性和可解释性而擅长描述和关系的任务。</p>
<p>基于符号的表示中的每个值都表示一定的人类可读的含义，因此我们可以直接使用它来观察数据的分布，以及提取对象之间的关系。例如，基于频率的词表示用于观察文化变化并捕捉新闻中提及次数与公司股票交易量之间的关系。虽然基于主题模型的表示和一些基于神经的表示在一定程度上具有实际意义，但它们对于社会科学研究人员来说仍然是模糊的并且不那么引人注目。</p>
<p>由于神经网络具有强大的拟合数据和提取深度语义的能力，基于嵌入的表示在预测（例如分类和回归）和相似性任务中表现更好。一方面，神经网络通过大规模神经元的连接实现高效的输入输出映射功能。另一方面，通过多层网络的构建，实现深层语义和抽象概念的提取。现有研究表明，深层捕获相对于浅层更抽象的特征。诸如社会偏见和道德化之类的抽象概念都可以通过基于嵌入的表示来很好地衡量。虽然我们提到基于符号的表示可以通过一些定义的符号来代表抽象概念，但这种表示仍然是部分和肤浅的，很难捕捉到它们的全貌。</p>
<p>基于嵌入的表示需要更少的人力。基于符号的表示通常需要大量的专家知识来定义研究对象的特征，这是劳动密集型的。此外，对于一些没有充分特征的抽象概念或对象，它们的表现将受到限制。与它们不同的是，基于嵌入的表示是从数据中自动提取的，几乎不需要人工干预，甚至可以补充人类知识。例如，可以使用神经网络来自动恢复丢失的巴比伦文本，这即使对专家来说也是具有挑战性的。此外，基于嵌入的表示可以在没有手动定义的情况下描述语言的复杂性和歧义性。</p>
<br> 
<h2 id="七未来展望">七、未来展望</h2>
<p>尽管在过去十年中出现了从符号到嵌入的趋势，但仍有许多挑战和悬而未决的问题有待探索。展望未来，我们列出了一些与计算社会科学 中的数据表示相关的基本和潜在的未来方向。</p>
<p>预训练的语言模型。近年来，预训练的语言模型受到了相当大的关注，并在处理文本数据方面取得了巨大的成功 [100, 240]。这些模型从百科全书和书籍等海量文本数据中学习丰富的语义信息，仅在下游任务中进行微调以实现有效的基于嵌入的表示。因此，对于 计算社会科学，我们可以借助预训练的语言模型获得更通用、更健壮的文本表示。与从传统神经网络模型中学习的表示相比，这些表示不仅可以更广泛、更准确地从文本中分析社会现象，而且还可以减少那些需要大量标记数据的任务的人工注释。</p>
<p>图神经网络。通过消息传递机制，图神经网络 [461] 可以同时有效地对网络拓扑和节点/边缘特征（例如文本信息）进行建模，从而提供一个统一的框架来利用来自异构来源的信息。 计算社会科学 中的许多场景需要处理社交网络以及个人特征。因此，图神经网络技术在 计算社会科学 研究中具有很大的应用潜力，可以学习融合文本和网络信息的表示。事实上，计算机科学中的各种应用，例如自然语言处理 [418] 和推荐系统 [439]，已经采用图神经网络进行建模。</p>
<p>设计为预测和相似性。基于嵌入的表示以丰富和深层次的语义而闻名，而基于符号的表示通常保留在部分和浅层语义中。同时，基于嵌入的表示擅长预测和相似性的任务。因此，为了充分利用嵌入中的强语义，鼓励 计算社会科学 研究人员尽可能将研究问题设计为预测或相似性任务。例如，我们可以将社会偏见问题设计为性别词和中性词嵌入之间的相似性度量 [59, 133]。此外，人类语言的复杂性可以设计为一项预测任务，它以语言模型为指标查看单词或句子的预测概率[155]。</p>
<p>可解释性。诚然，基于嵌入的方法的一个缺点是缺乏可解释性。这个问题会损害与道德、安全或隐私相关的决策关键系统的应用。尽管嵌入模型，尤其是神经网络模型的可解释性尚未完全解决，但计算机科学领域的研究人员已经做出了一些努力，以提高基于神经模型的可解释性 [16]。因此，利用基于嵌入的模型和可解释性分析方法进行有效和（部分）可解释的预测将是一个有趣的方向。</p>
<br>
<h2 id="结论">结论</h2>
<p>计算社会科学作为一个新兴且有前途的跨学科领域，近年来吸引了相当多的研究兴趣。 计算社会科学 研究中广泛使用两种主要类型的数据，即文本数据和网络数据。在本次调查中，我们首先将数据表示总结为基于符号和基于嵌入的表示，并在构建这些表示时进一步介绍典型的方法。之后，我们基于来自 6 个经典期刊和会议的 400 多篇高被引文献，对这两类表示的应用进行了全面回顾。根据对这些应用的统计，发现了 计算社会科学 中基于嵌入的文本和网络表示正在出现和增长的趋势，我们进一步讨论了其中的原因。最后，我们提出了 计算社会科学 中的四个挑战和未解决的问题，它们是需要探索的基本和潜在方向。</p>
<br>
<br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>营销科技 | 今天出门穿什么？时尚电商Stitch Fix</title>
      <link>https://textdata.cn/blog/stitchfix/</link>
      <pubDate>Sun, 27 Mar 2022 10:43:10 +0600</pubDate>
      
      <guid>/blog/stitchfix/</guid>
      <description>“穿衣服是大学问”，不相信可以问问很多女生，每天出门前会不会为了今天要穿什麽衣服而伤脑筋？现在如果有一家公司帮您聘请一个专属的“穿衣顾问”，只在一开始收费120多元（二十块美金）的造型费，然后定期寄来已经帮您量身打造的时尚服饰，您愿意买单吗？不瞒您说，目前全世球已有三百五十万人接受美国一家叫做“Stitch Fix”的穿衣时尚订阅公司的服务。</description>
      <content:encoded><![CDATA[<blockquote>
<ul>
<li>作者：蘇宇暉（台科大管研所博士候選人）、羅凱揚（台科大企管系博士）</li>
<li>日期: 2020-12-14</li>
<li>绘图：彭煖蘋</li>
<li>出处: <a href="https://medium.com/marketingdatascience/%E6%99%82%E5%B0%9A%E9%9B%BB%E5%95%86stitch-fix-6aed7636b2c9">medium</a></li>
</ul>
</blockquote>
<br>
<p>“穿衣服是大学问”，不相信可以问问很多女生，每天出门前会不会为了今天要穿什麽衣服而伤脑筋？现在如果有一家公司帮您聘请一个专属的“穿衣顾问”，只在一开始收费120多元（二十块美金）的造型费，然后定期寄来已经帮您量身打造的时尚服饰，您愿意买单吗？不瞒您说，目前全世球已有三百五十万人接受美国一家叫做“Stitch Fix”的穿衣时尚订阅公司的服务。</p>
<div style="text-align: center;">
<figure >
    <a href="https://www.stitchfix.com/">
        <img src="img/StitchFix.png" width="100%" />
    </a>
    <figcaption><small><i>点击浏览Stitch Fix网站</i></small></figcaption>
</figure>
</div>
<p>2011年6月，刚从哈佛大学商学院毕业的美日混血儿<strong>卡翠娜‧雷克</strong>（Katrina Lake），在美国旧金山成立时尚电商公司Stitch Fix。满脑子有趣想法的雷克，透过募集到的五十万美金，开始了她的创业之旅。短短不到七年的时间，到了2017年11月，Stitch Fix在美国Nasdaq上市。而卡翠娜‧雷克本人也成为2019年《福布斯》全美白手起家女富豪排行榜中的55名。</p>
<p><strong>Stitch Fix的背后，其实是一家充分利用营销研究和营销数据科学，同时提供“穿衣时尚订阅”服务的新创公司。现在让我们来看看，Stitch Fix如何运作</strong>，如图-1所示。</p>
<div style="text-align: center;">
<figure >
    <a href="https://www.stitchfix.com/">
        <img src="img/StitchFix%e8%bf%90%e4%bd%9c.png" width="100%" />
    </a>
    <figcaption><small><i>图-1 StitchFix运作</i></small></figcaption>
</figure>
</div>
<p>消费者在登录Stitch Fix的网站首页时，不会看到像其他购物网站会有太多的商品展示，反而是<strong>介绍穿衣风格才是重点</strong>。而<strong>网站会有造型师来塑造消费者的风格，并且透过这种新的购物方式力邀消费者加入会员</strong>。因此，当消费者在Stitch Fix的网站注册时，Stitch Fix会请会员填答一份详细的问卷，包括顾客的<strong>基本资料、身高、尺码、喜欢的颜色、风格、经常出席的场合、甚至是预算</strong>等。</p>
<p>接著，Stitch Fix每个月就会透过一个称为“<strong>订购盒子</strong>（Subscription Box）”的包裹，一次将五件服饰寄送给顾客。等到消费者收到包裹时，可以留下觉得满意的服饰，看不上眼或者不满意的服饰就再寄回给Stitch Fix。如果消费者将服饰全部留下，就会享受到折扣，反之，如果一件都不想买，就负担二十美元的包裹服务费。</p>
<p>在美国，消费者要买衣服，往往得开车到购物中心或百货公司，买个两三件衣服总要花上半天时间。Stitch Fix一次寄来五件衣服（连同一张纸本问卷），其实也经过精算，因为如果一次寄太多件，消费者心理和预算上都难以承受。而Stitch Fix透过消费者所填答的电脑和纸本问卷，以及购买与退换货记录，利用机器学习算法对消费者喜好与需求进行预测，并结合设计师的搭配，给消费者定制化的建议。因为喜欢的衣服被留下，不喜欢的退回，Stitch Fix就很容易利用这些大量数据建立起消费者穿衣风格的“模型”。</p>
<p>而为了进一步收集到更精准的数据，2017年，Stitch Fix推出了一款Style Shuffle的小游戏，让顾客针对不同的服饰或配件，简单回应喜爱或是不喜爱。借此更进一步收集消费者的偏好，并增加消费者的粘性。Stitch Fix后来并将触角伸向男性服饰以及儿童服饰。而大尺码的女性服饰更是其服务重点。</p>
<p>通过收集大量消费者用户数据，以及不断优化的模型算法，并结合个人造型师和机器学习（AI）进行个性化推荐，让Stitch Fix的时尚订阅制服务，能够更精准地预测与满足消费者偏好的服饰及配件。据了解，截至2019年，该公司拥有8,000名员工，其中包括5,100名造型师和100多名数据科学家。</p>
<p>从以上Stitch Fix的故事中，我们看到了营销研究与数据科学的完美搭配。</p>
<br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>文本相似 | Lazy Prices公司年报内容变动预示重大风险</title>
      <link>https://textdata.cn/blog/2019-12-08-lazy-prices/</link>
      <pubDate>Tue, 31 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/2019-12-08-lazy-prices/</guid>
      <description>一个公司报告文件会有不同部分，我们需要将不同的部分分别识别出来。这里用到正则表达式，可以进行快速的数据清洗和数据抽取。文本转为向量后就可以进行相似度计算,</description>
      <content:encoded><![CDATA[<h2 id="文献">文献</h2>
<p>Cohen, L., Malloy, C. and Nguyen, Q., 2020. Lazy prices. <em>The Journal of Finance</em>, <em>75</em>(3), pp.1371-1415.</p>
<br>
<h2 id="摘要">摘要</h2>
<p>使用1995年-2014年所有美国公司季度和年度申报的完整历史记录，研究发现当公司对<strong>报告进行积极更改</strong>时，这种行为<strong>蕴含着</strong>公司未来运营的<strong>重要信号</strong>。</p>
<p><strong>财务报告的语言和结构的变化也对公司的未来收益产生重大影响</strong>：做空&quot;变化&quot;的公司（持有的公司，如果其报告发生变化的，做空该公司股票），买入“不变化”的公司，使用这样的投资组合策略，在2006年的每月alpha值高达1.88%的收益（每年超过22％）。报告中涉及执行官（CEO和CFO）团队的话语风格的变化，或者有关诉讼(风险部分)的话语的变化，都对投资的未来收益有重要作用。</p>
<p>研究发现，对10-K的变化可以预测未来的收益、获利能力、未来的新闻公告，甚至未来的公司破产。同时，不做任何变化的公司将获得显著的异常收益。与资产价格典型的反应不足研究不同，我们发现没有任何与这些变化相关的公告效应–仅在后来通过新闻，事件或收益披露信息时才产生回报–暗示投资者并未注意到整个公众领域的这些变化。</p>
<br>
<h2 id="研究背景">研究背景</h2>
<p>之前的研究认为，尽管投资者一次对包含重大变化的财务报表的发布作出了迅时反应，但随着时间的流逝，这种公告作用是会减弱的(Brown and Tucker, 2011 and Feldman et al., 2010)。这表示10-K报告会随着时间推移，信息价值大打折扣。尽管我们复现了这个事实，即与常规文件的变更没有重大的公告效应，但我们认为，前人的研究忽略了更重要部分(如MD&amp;A)对对资产价格的影响。</p>
<p>确切的说，<strong>并不是报告的披露效应的信息价值变低了，而是投资者越来越难以发现报告中微妙的信息变化， 比如因为报告变得越来越冗杂。投资者只有看到某些新闻后，才会逐渐意识到之前公司报告内容变化的的真正价值</strong>。</p>
<p>例如Baxter公司</p>
<ul>
<li>纽约时报在 <strong>2010年4月23日</strong> 发了一条FDA将有对输液泵(infusion pumps)更严格对审批管理规定的新闻，<strong>新闻中提到了Baxter公司</strong>。新闻公布当天，<strong>Baxter股价大跌</strong>。</li>
<li><strong>10天</strong>后的（2010年5月4日），Baxter宣布<strong>召回问题的输液泵产品</strong>，股价当天再次大跌。</li>
</ul>
<p><img loading="lazy" src="img/lazy-prices-1.png" alt=""  />
</p>
<p>两次负面新闻导致Baxter股价大跌超过20%，最有意思的是Baxter公司一个多月前（<strong>2010年2月23日</strong>）10-k报告中 <strong>提到</strong> 了与这两条新闻类似的 <strong>线索</strong>。</p>
<p><img loading="lazy" src="img/clues_from_report.png" alt=""  />
</p>
<p>截图中写着 <strong>Baxter的产品COLLEGUE未来可能面脸额外的处罚，而且相关销售面临着FDA、OIG、DOI和FTC越来越严格的审批，面临的执法强度也越来越大</strong>。</p>
<p>因纽约时报发布的消息，股价大跌。但是大跌之前Baxter的10-k报告中似乎提示未来公司可能面临的风险，但是投资者怎么没有注意到这个重要线索呢？</p>
<br>
<h2 id="数据获取与分析方法">数据获取与分析方法</h2>
<p>这篇文章用到了很多 文本数据挖掘 方法，如</p>
<ul>
<li>数据采集(报告下载和信息监测)</li>
<li>正则表达式（数据分割与抽取）</li>
<li>文本相似度(计算报告变化程度)</li>
</ul>
<p>我大致说下这几部分技术在这篇论文中的应用。</p>
<h3 id="1-数据采集">1. 数据采集</h3>
<p>这篇论文研究者认为，只有投资者意识到本期报告和上一期报告做对比，才能发现报告变化，进而对股价有影响。所以当有新公告公布后，投资者是否下载本期报告的同时顺带着下载上一期报告，下载量又是多少。</p>
<p>下载量可以从Freedom of Information Act下载，</p>
<p><img loading="lazy" src="img/download_data.png" alt=""  />
</p>
<p>可以拿到的信息包括:</p>
<ul>
<li>报告文件</li>
<li>报告下载时间</li>
<li>报告下载的IP地址(可以通过这个ip来当作投资者的id)</li>
</ul>
<br>
<h3 id="2-正则表达式">2. 正则表达式</h3>
<p>一个公司报告文件会有不同部分，我们需要将不同的部分分别识别出来。这里用到正则表达式，可以进行快速的数据清洗和数据抽取。</p>
<p><img loading="lazy" src="img/regular_expression.png" alt=""  />
</p>
<br>
<h3 id="3-文本相似度">3. 文本相似度</h3>
<p>文本转为向量后就可以进行相似度计算,</p>
<p><img loading="lazy" src="img/similar-1.png" alt=""  />

<img loading="lazy" src="img/similar-2.png" alt=""  />

<img loading="lazy" src="img/similar-3.png" alt=""  />
</p>
<p>这里使用我开发的cntext包，可以实现cosine和jaccard相似度的计算。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>

<span class="n">A</span> <span class="o">=</span> <span class="s1">&#39;We expect demand to increase.&#39;</span>
<span class="n">B</span> <span class="o">=</span> <span class="s1">&#39;We expect worldwide demand to increase.&#39;</span>
<span class="n">C</span> <span class="o">=</span> <span class="s1">&#39;We expect weakness in sales&#39;</span>

<span class="nb">print</span><span class="p">(</span><span class="n">ct</span><span class="o">.</span><span class="n">cosine_sim</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">C</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">ct</span><span class="o">.</span><span class="n">jaccard_sim</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">))</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">0.40
0.83
</code></pre></div><p>如果对Baxter公司多个年度对报告进行相似度计算，绘制成图就会发现2010年与前后变化很大。相似度越低，说明公司报告前后变化很大，应该引起投资者注意，如果能注意到就会避免纽约时报导致到股价暴跌。如下图</p>
<p><img loading="lazy" src="img/lazy-prices-2.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="案例实现">案例实现</h2>
<p>由于没有完全一样的数据，这里使用政府工作报告数据类比，使用cosine相似度画出趋势线条。</p>
<p>使用相似性识别变化的时间点</p>
<h3 id="准备数据">准备数据</h3>
<p>政府工作报告 <a href="http://www.gov.cn/guowuyuan/zfgzbg.htm">http://www.gov.cn/guowuyuan/zfgzbg.htm</a></p>
<p>prc_reports.xlsx 链接:https://pan.baidu.com/s/1sVU3mkEcP7Z3_hbG5AVNUA 密码:zjrq</p>
<p>将下载好后的 prc_reports.xlsx 文件放置于 .ipynb文件 所在的文件夹内。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_excel</span><span class="p">(</span><span class="s1">&#39;prc_reports.xlsx&#39;</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">dropna</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<p><img loading="lazy" src="img/df.png" alt=""  />
</p>
<h3 id="计算相似度">计算相似度</h3>
<p>运行时间大概30s， 运算结果是列表数据 cosines</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>

<span class="n">cosines</span> <span class="o">=</span> <span class="p">[]</span>
<span class="c1">#row  Series</span>
<span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">iterrows</span><span class="p">():</span>
    <span class="n">text1</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="s1">&#39;report&#39;</span><span class="p">]</span>
    <span class="n">text2</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="s1">&#39;report2&#39;</span><span class="p">]</span>
    <span class="n">simi</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">cosine_sim</span><span class="p">(</span><span class="n">text1</span><span class="p">,</span> <span class="n">text2</span><span class="p">)</span>
    <span class="n">cosines</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">simi</span><span class="p">)</span>
    
<span class="n">cosines</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">[0.44&#39;, &#39;0.39&#39;, &#39;0.35&#39;, ... &#39;0.62&#39;, &#39;0.61&#39;, &#39;0.60&#39;]
</code></pre></div><h3 id="绘制柱状图">绘制柱状图</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">pyecharts.charts</span> <span class="kn">import</span> <span class="n">Bar</span>
<span class="kn">from</span> <span class="nn">pyecharts</span> <span class="kn">import</span> <span class="n">options</span> <span class="k">as</span> <span class="n">opts</span>
<span class="kn">from</span> <span class="nn">pyecharts.globals</span> <span class="kn">import</span> <span class="n">CurrentConfig</span><span class="p">,</span> <span class="n">NotebookType</span>
<span class="n">CurrentConfig</span><span class="o">.</span><span class="n">NOTEBOOK_TYPE</span> <span class="o">=</span> <span class="n">NotebookType</span><span class="o">.</span><span class="n">JUPYTER_NOTEBOOK</span>

<span class="n">bar</span> <span class="o">=</span> <span class="n">Bar</span><span class="p">()</span>

<span class="n">bar</span><span class="o">.</span><span class="n">add_xaxis</span><span class="p">(</span><span class="n">xaxis_data</span><span class="o">=</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;year&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">])</span>
<span class="n">bar</span><span class="o">.</span><span class="n">add_yaxis</span><span class="p">(</span><span class="s2">&#34;相似度&#34;</span><span class="p">,</span> 
               <span class="n">cosines</span><span class="p">,</span> 
               <span class="n">label_opts</span><span class="o">=</span><span class="n">opts</span><span class="o">.</span><span class="n">LabelOpts</span><span class="p">(</span><span class="n">is_show</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>

<span class="n">bar</span><span class="o">.</span><span class="n">set_global_opts</span><span class="p">(</span><span class="n">title_opts</span><span class="o">=</span><span class="n">opts</span><span class="o">.</span><span class="n">TitleOpts</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s2">&#34;政府工作报告相似度可视化&#34;</span><span class="p">))</span>
<span class="n">bar</span><span class="o">.</span><span class="n">load_javascript</span><span class="p">()</span>

<span class="n">bar</span><span class="o">.</span><span class="n">render</span><span class="p">(</span><span class="s1">&#39;政府工作报告相似度可视化1.html&#39;</span><span class="p">)</span>
<span class="n">bar</span><span class="o">.</span><span class="n">render_notebook</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<p><img loading="lazy" src="img/vis_res.png" alt=""  />
</p>
<h3 id="解读">解读</h3>
<p>从图中可以看到除1959年异常外，其他方面能挖掘出很多信息。从相似度整体趋势，</p>
<p>1959-1992 第一阶段，
1992-至今 第二阶段</p>
<p>1992年附近，第一次确立社会主义市场经济制度。之后的岁月里一直围绕着经济建设高速发展。</p>
<p>同时也可以看出在第一阶段前期相似度异常的低，可以理解为新中国初建，百废待兴，对于建设者而言，组着和管理这个国家的政府也在学习如何建设新中国。而90年代后，相似度越来越高，体现了政府越来越熟悉如何治理国家，如何搞经济建设。</p>
<p><br><br></p>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://textdata.cn/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://textdata.cn/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
  </channel>
</rss>
