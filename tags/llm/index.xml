<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>LLM on 大邓和他的PYTHON</title>
    <link>/tags/llm/</link>
    <description>Recent content in LLM on 大邓和他的PYTHON</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Tue, 09 Sep 2025 00:00:00 +0000</lastBuildDate><atom:link href="/tags/llm/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>教程 | 使用大模型将文本数据转化为结构化数据(LMstudio篇)</title>
      <link>https://textdata.cn/blog/2025-09-09-transform-text-data-into-structured-data-with-lmstudio-and-cntext/</link>
      <pubDate>Tue, 09 Sep 2025 00:00:00 +0000</pubDate>
      
      <guid>/blog/2025-09-09-transform-text-data-into-structured-data-with-lmstudio-and-cntext/</guid>
      <description>实验数据为外卖评论， 今天咱们做个有难度的文本分析任务，从不同维度(味道、速度、服务)对外卖评论进行打分(-1.0~1.0)文本分析（也称为文本挖掘或自然语言处理，NLP）是指使用计算机算法和技术从大量文本数据中提取有价值信息的过程。文本分析的目标是从非结构化的文本数据中识别模式、提取关键信息、理解语义，并将其转化为结构化数据以便进一步分析和应用。</description>
      <content:encoded><![CDATA[<h2 id="一任务">一、任务</h2>
<p>之前分享 <a href="https://textdata.cn/blog/2025-02-14-using-online-large-model-api-to-transform-text-data-into-structured-data/">教程 | 使用大模型将文本编码为结构化数据(Ollma偏)</a> 是基于Ollma的使用的大模型标注教程。 今天咱们换个新工具-<a href="https://lmstudio.ai/">LM Studio</a></p>
<p>使用 LM Studio 和 cntext2x 进行文本分析。</p>
<p><br><br></p>
<h2 id="二配置环境">二、配置环境</h2>
<h3 id="21-安装cntext2x">2.1 安装cntext2x</h3>
<p>将 cntext2的 <em><strong>.whl</strong></em> 文件放置于桌面， 以版本为 <em><strong>cntext-2.1.7-py3-none-any.whl</strong></em> 为例，打开命令行cmd(Mac打开terminal)，依次执行命令</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">cd desktop
pip install cntext-2.1.7-py3-none-any.whl
</code></pre></div><br>
<h3 id="22-安装lm-studio">2.2 安装LM Studio</h3>
<p>在官网 <a href="https://lmstudio.ai/">LM Studio</a> 点击下载， 该软件支持Win、Mac。</p>
<p><img loading="lazy" src="img/01-cover.png" alt=""  />
</p>
<br>
<h3 id="23-配置lms命令行工具">2.3 配置lms命令行工具</h3>
<p>为方便调试，需要配置lms命令行工具。</p>
<ul>
<li>window打开cmd， 执行命令
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">/c %USERPROFILE%/.lmstudio/bin/lms.exe bootstrap
</code></pre></div></li>
<li>mac打开terminal， 执行命令
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">~/.lmstudio/bin/lms bootstrap
</code></pre></div></li>
</ul>
<br>
<h3 id="24-安装模型">2.4 安装模型</h3>
<p>模型可以选择点击操作安装，也可通过命令行安装。</p>
<p><img loading="lazy" src="img/02-model-install.png" alt=""  />
</p>
<p>打开<a href="https://lmstudio.ai/models/">LM Studio模型列表</a>， 选择个小的模型进行安装。 可以找到 <strong>qwen3-4b</strong>。打开命令行cmd (Mac打开terminal)， 执行安装命令</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">lms get qwen/qwen3-4b
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">
   🡇 To download: model qwen/qwen3-4b - 170.89 KB
   └─ 🡇 To download: Qwen3 4B 4BIT [MLX] - 2.28 GB

About to download 2.28 GB.
Continue? (Y/N): Y
⠦ [▏                     ] 0.00% |  707 B / 2.28 GB | 837.6777251184834 B/s | ETA 755:46:24        ⠦ [▏                     ] 0.00% |  707 B / 2.28 GB |                 0 B/s | ETA Infinity:NaN:NaN ⠦ [▏                     ] 0.00% |  707 B / 2.28 GB |                 0 B/s | ETA Infinity:NaN:NaN 
⠇ [██████████████████████] 99.87% |   2.28 GB / 2.28 GB |             7.31 MB/s | ETA 00:00        ⠏ [██████████████████████] 99.87% |   2.28 GB / 2.28 GB |             7.31 MB/s | ETA 00:00        Finalizing download...
Download completed.
</code></pre></div><p>大概 10 分钟安装完成， 模型体积约 2.2GB。</p>
<br>
<p>当然了也可选择图形化安装，如图</p>
<p><img loading="lazy" src="img/03-ui-install.png" alt=""  />
</p>
<br>
<h3 id="25-查看已安装模型">2.5 查看已安装模型</h3>
<p>查看电脑内已安装的模型，打开cmd(Mac打开terminal)， 执行安装命令</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">lms ls
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">You have 5 models, taking up 26.42 GB of disk space.

LLM               PARAMS    ARCH     SIZE                 
qwen/qwen3-4b               qwen3    2.28 GB              
qwen3-1.7b-mlx              qwen3    984.01 MB            
qwen3-32b-mlx               qwen3    18.45 GB             
qwen3-8b-mlx                qwen3    4.62 GB      ✓ LOADED

EMBEDDING                               PARAMS    ARCH          SIZE        
text-embedding-nomic-embed-text-v1.5              Nomic BERT    84.11 MB  
</code></pre></div><p>图形化查看已经安装的模型</p>
<p><img loading="lazy" src="img/04-model-ls.png" alt=""  />
</p>
<br>
<br>
<h2 id="三使用lm-studio">三、使用LM Studio</h2>
<h3 id="31-ui界面尝试">3.1 UI界面尝试</h3>
<p><img loading="lazy" src="img/05-ui-chat.png" alt=""  />

<img loading="lazy" src="img/06ui-chat.png" alt=""  />
</p>
<br>
<h3 id="32-启动lm-studio服务">3.2 启动LM Studio服务</h3>
<p>启动服务，方便Python调用LM Studio。 打开cmd(Mac打开terminal)， 启动服务</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">lms server start
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">Success! Server is now running on port 1234
</code></pre></div><p>注意: 后续如果想关闭服务， 执行命令 <code>lms server stop</code></p>
<br>
<h3 id="33-初次尝试">3.3 初次尝试</h3>
<p>使用cntext内置的sentiment提示词模板,启用lmstudio服务，调用qwen/qwen3-4b模型。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="o">%%</span><span class="n">time</span>
<span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>

<span class="n">texts</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&#34;服务很棒！&#34;</span><span class="p">,</span> <span class="s2">&#34;服务一般！&#34;</span><span class="p">,</span> <span class="s2">&#34;服务很差！&#34;</span><span class="p">]</span>
<span class="k">for</span> <span class="n">text</span> <span class="ow">in</span> <span class="n">texts</span><span class="p">:</span>
    <span class="n">score</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">llm</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> 
                   <span class="n">task</span><span class="o">=</span><span class="s2">&#34;sentiment&#34;</span><span class="p">,</span> 
                   <span class="n">backend</span><span class="o">=</span><span class="s2">&#34;lmstudio&#34;</span><span class="p">,</span>  
                   <span class="n">model_name</span><span class="o">=</span><span class="s2">&#34;qwen/qwen3-4b&#34;</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">score</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">[cntext2x] ✅ 连接模型服务: http://localhost:1234/v1

服务很棒！ {&#39;label&#39;: &#39;pos&#39;, &#39;score&#39;: 0.9}
服务一般！ {&#39;label&#39;: &#39;neutral&#39;, &#39;score&#39;: 0.0}
服务很差！ {&#39;label&#39;: &#39;neg&#39;, &#39;score&#39;: -0.95}

CPU times: user 110 ms, sys: 8.3 ms, total: 119 ms
Wall time: 9.14 s
</code></pre></div><br>
<h3 id="34-内置提示词模板">3.4 内置提示词模板</h3>
<p>cntext2x 内置提示词模板不止支持sentiment，还有其他任务，如分类、实体识别等。具体如下</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">ct</span><span class="o">.</span><span class="n">llm</span><span class="o">.</span><span class="n">tasks_list</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">[&#39;sentiment&#39;,
 &#39;emotion&#39;,
 &#39;classify&#39;,
 &#39;intent&#39;,
 &#39;keywords&#39;,
 &#39;entities&#39;,
 &#39;summarize&#39;,
 &#39;rewrite&#39;,
 &#39;quality&#39;,
 &#39;similarity&#39;]
</code></pre></div><br>
<p>查看模板内容</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">ct</span><span class="o">.</span><span class="n">llm</span><span class="o">.</span><span class="n">tasks_get</span><span class="p">(</span><span class="s1">&#39;emotion&#39;</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">{&#39;prompt&#39;: &#39;识别文本中的主要情绪类型：从 [开心, 愤怒, 悲伤, 惊讶, 厌恶, 恐惧, 中性] 中选择最匹配的一项，返回情绪类型 emotion 和置信度 confidence（0~1）&#39;,
 &#39;output_format&#39;: {&#39;emotion&#39;: &#39;str&#39;, &#39;confidence&#39;: &#39;float&#39;}}
</code></pre></div><br>
<h3 id="35-自定义提示词模板">3.5 自定义提示词模板</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="o">%%</span><span class="n">time</span>
<span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>
<span class="n">PROMPT</span> <span class="o">=</span> <span class="s1">&#39;从口味taste、速度speed、服务service三个维度， 对外卖评论内容进行文本分析， 分别返回不同维度的分值(分值范围-1.0 ~ 1.0)&#39;</span>
<span class="n">OUTPUT</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;taste&#39;</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="s1">&#39;speed&#39;</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="s1">&#39;service&#39;</span><span class="p">:</span> <span class="nb">float</span><span class="p">}</span>

<span class="n">texts</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&#34;服务很棒！&#34;</span><span class="p">,</span> <span class="s2">&#34;服务一般！&#34;</span><span class="p">,</span> <span class="s2">&#34;服务很差！&#34;</span><span class="p">]</span>
<span class="k">for</span> <span class="n">text</span> <span class="ow">in</span> <span class="n">texts</span><span class="p">:</span>
    <span class="n">score</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">llm</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="s2">&#34;服务很棒&#34;</span><span class="p">,</span>
           <span class="n">prompt</span><span class="o">=</span><span class="n">PROMPT</span> <span class="p">,</span>
           <span class="n">output_format</span><span class="o">=</span><span class="n">OUTPUT</span><span class="p">,</span>
           <span class="n">backend</span><span class="o">=</span><span class="s2">&#34;lmstudio&#34;</span><span class="p">,</span>  
           <span class="n">model_name</span><span class="o">=</span><span class="s2">&#34;qwen/qwen3-4b&#34;</span><span class="p">)</span>
    <span class="n">score</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">text</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">score</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">{&#39;taste&#39;: 0.0, &#39;speed&#39;: 0.0, &#39;service&#39;: 1.0, &#39;text&#39;: &#39;服务很棒！&#39;}
{&#39;taste&#39;: 0.0, &#39;speed&#39;: 0.0, &#39;service&#39;: 1.0, &#39;text&#39;: &#39;服务一般！&#39;}
{&#39;taste&#39;: 0.0, &#39;speed&#39;: 0.0, &#39;service&#39;: 1.0, &#39;text&#39;: &#39;服务很差！&#39;}
CPU times: user 114 ms, sys: 8.12 ms, total: 122 ms
Wall time: 8.79 s
</code></pre></div><p>速度有点慢， 如果想加速， 可以考虑使用qwen3-1.7b模型(b的数字越小，模型运行速度越快，但是质量越差)。</p>
<br>
<br>
<h2 id="五获取-cntext2x">五、获取 cntext2.x</h2>
<p>安装包<strong>cntext-2.1.7-py3-none-any.whl</strong> 是付费内容(<strong><em>100 元</em></strong>)， 如需使用<strong>加微信: 372335839</strong>，备注「<strong>姓名-学校-专业-cntext</strong>」</p>
<p><br><br></p>
<h2 id="相关内容">相关内容</h2>
<ul>
<li><a href="https://textdata.cn/blog/2025-02-17-gpt-is-an-effective-tool-for-multilingual-psychological-text-analysis/"><strong>PNAS | GPT 是多语言心理文本分析的有效工具</strong></a></li>
<li><a href="https://textdata.cn/blog/2024-06-14-how-to-download-large-language-model-with-ollama/"><strong>教程 | 如何使用 Ollama 下载 &amp; 使用本地大语言模型</strong></a></li>
<li><a href="https://textdata.cn/blog/2024-08-06-using-the-ollama-local-large-model-to-predict-the-sentiment-category-of-online-comments/"><strong>实验 | 使用本地大模型预测在线评论情感类别和分值</strong></a></li>
<li><a href="https://textdata.cn/blog/2024-08-07-structured-outputs-with-ollama/"><strong>实验 | 如何使 Ollama 结构化输出 JSON 样式的结果</strong></a></li>
<li><a href="https://textdata.cn/blog/2024-04-27-cntext2x-usage-tutorial/"><strong>推荐 | 文本分析库 cntext2.x 使用手册</strong></a></li>
<li><a href="https://textdata.cn/blog/2024-06-14-using-large-language-model-to-extract-structure-data-from-raw-text/"><strong>实验 | 使用本地大模型从文本中提取结构化信息</strong></a></li>
<li><a href="https://textdata.cn/blog/2024-07-10-using-large-language-model-to-build-diy-dictionary/">实验 | 使用 Ollama 本地大模型 DIY 制作单词书教案 PDF</a></li>
<li><a href="https://textdata.cn/blog/2024-08-05-create-a-blog-writer-multi-agent-system-using-crewai-and-ollama/">实验 | 使用 Crewai 和 Ollama 构建智能体(AI Agent)帮我撰写博客文章</a></li>
</ul>
<p><br><br></p>
<h2 id="精选内容">精选内容</h2>
<ul>
<li><a href="https://textdata.cn/blog/datasets_available_for_management_science/">LIST | 可供社科(经管)领域使用的数据集汇总</a></li>
<li><a href="https://textdata.cn/blog/the_text_analysis_list_about_ms/">LIST | 社科(经管)数据挖掘文献资料汇总</a></li>
<li><a href="https://textdata.cn/blog/2024-06-16-scrapegraph-ai/">网络爬虫 | 使用 scrapegraph-ai(大模型方案)自动采集网页数据</a></li>
<li><a href="https://textdata.cn/blog/2024-04-27-cntext2x-usage-tutorial/">推荐 | 文本分析库 cntext2.x 使用手册</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python 实证指标构建与文本分析</a></li>
<li><a href="https://textdata.cn/blog/2024-06-14-using-large-language-model-to-extract-structure-data-from-raw-text/">实验 | 使用本地大模型从文本中提取结构化信息</a>
<br>
<br></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>实验 | 使用大模型从图片中提取结构化数据</title>
      <link>https://textdata.cn/blog/2025-02-22-extracting-structured-data-from-images-with-ollama-and-large-language-models/</link>
      <pubDate>Sat, 22 Feb 2025 00:00:00 +0000</pubDate>
      
      <guid>/blog/2025-02-22-extracting-structured-data-from-images-with-ollama-and-large-language-models/</guid>
      <description>在快速发展的人工智能领域，将视觉功能集成到大型语言模型中，**可以用于解读图片语义， 从图片中提取出结构化数据**。</description>
      <content:encoded><![CDATA[<p>在快速发展的人工智能领域，将视觉功能集成到大型语言模型中，<strong>可以用于解读图片语义， 从图片中提取出结构化数据</strong>。</p>
<p><br><br></p>
<h2 id="一环境配置">一、环境配置</h2>
<p>在Python中调用大模型，  先要配置好相应的环境。</p>
<h3 id="11-安装python包">1.1 安装python包</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">pip3 install ollama
pip3 install pydantic
pip3 install instructor
</code></pre></div><h3 id="12-安装ollama">1.2 安装Ollama</h3>
<p><a href="https://ollama.ai/"><strong>Ollama</strong></a>是一款开源应用程序，可让您使用 MacOS、Linux 和 Windows 上的命令行界面在本地运行、创建和共享大型语言模型。</p>
<p>Ollama 可以直接从其库中访问各种 LLM，只需一个命令即可下载。下载后，只需执行一个命令即可开始使用。这对于工作量围绕终端窗口的用户非常有帮助。Ollama的安装、配置、使用的详细教程可阅读  <a href="https://textdata.cn/blog/2024-06-14-how-to-download-large-language-model-with-ollama/"><strong>教程 | 如何使用 Ollama 下载 &amp; 使用本地大语言模型</strong></a></p>
<p><img loading="lazy" src="img/01-ollama-gui.png" alt=""  />
</p>
<br>
<h3 id="13-安装大模型">1.3 安装大模型</h3>
<p>截止2025.2.22， 在 <a href="https://ollama.ai/"><strong>Ollama</strong></a> 网站中公开的 <em><strong>视觉类大模型</strong></em> 有7个， 这里简单介绍其中的两个</p>
<ul>
<li><em><strong>llama3.2-vision</strong></em> 更擅长识别图片中的英文信息</li>
<li><em><strong>minicpm-v</strong></em>  模型基于qwen， 更擅长识别图片中的中文信息</li>
</ul>
<p><img loading="lazy" src="img/02-vision-llm.png" alt=""  />
</p>
<p>打开命令行 <em><strong>cmd</strong></em> (在mac中对应terminal) ， 执行安装命令</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">ollama pull llama3.2-vision:11b
ollama pull minicpm-v:8b
</code></pre></div><br>
<h3 id="14-启动ollama服务">1.4 启动Ollama服务</h3>
<p>打开命令行 <em><strong>cmd</strong></em> (在mac中对应terminal) ， 执行启动服务命令</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">ollama serve
</code></pre></div><br>
<br>
<h2 id="二实验代码">二、实验代码</h2>
<h3 id="21-非结构化输出">2.1 非结构化输出</h3>
<p>截图的文件名 <em><strong>test_screen.png</strong></em></p>
<p><img loading="lazy" src="img/03-test.png" alt=""  />
</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">ollama</span>


<span class="c1">#论文的截图文件 test_screen.png</span>
<span class="c1">#注意，代码文件与截图文件同处于一个文件夹内</span>

<span class="n">response</span> <span class="o">=</span> <span class="n">ollama</span><span class="o">.</span><span class="n">chat</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="s1">&#39;minicpm-v&#39;</span><span class="p">,</span>  
    <span class="n">messages</span><span class="o">=</span><span class="p">[{</span>
        <span class="s1">&#39;role&#39;</span><span class="p">:</span> <span class="s1">&#39;user&#39;</span><span class="p">,</span>
        <span class="s1">&#39;content&#39;</span><span class="p">:</span> <span class="s1">&#39;这是一篇什么领域的论文？&#39;</span><span class="p">,</span>
        <span class="s1">&#39;images&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;test_screen.png&#39;</span><span class="p">]</span>
    <span class="p">}]</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">ChatResponse(model=&#39;minicpm-v&#39;, created_at=&#39;2025-02-22T13:11:25.766017Z&#39;, done=True, done_reason=&#39;stop&#39;, total_duration=12956488125, load_duration=819433041, prompt_eval_count=461, prompt_eval_duration=9630000000, eval_count=147, eval_duration=2499000000, message=Message(role=&#39;assistant&#39;, content=&#39;这张图片是关于一篇题为“开或关在轨：如何（破碎）的线索影响消费者决策”的文章标题页。该文章由杰基·西尔弗曼和亚历山德拉·巴拉斯奇撰写，探讨了消费者行为的新技术追踪的后果。研究发现，在七项研究中，持续的行为轨迹会引发高消费后的强化，并且如果打破了这些轨迹，则会产生相反的效果，从而影响消费者的决策。所用的研究方法包括跟踪、行为分析以及追踪和监测等工具和技术，以了解线索对不同领域（如体育、学习）的影响。关键词列出了文章的焦点领域：断路器、行为追踪和记录、消费者动机、参与度。&#39;, images=None, tool_calls=None))
</code></pre></div><br>
<h3 id="22-结构化输出">2.2 结构化输出</h3>
<p>设计更详细的提示prompt， 通过使用<em><strong>typing</strong></em> 和<em><strong>pydantic</strong></em> 设计数据结构，输出为字典类数据。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">instructor</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">List</span>
<span class="kn">from</span> <span class="nn">pydantic</span> <span class="kn">import</span> <span class="n">BaseModel</span>
<span class="kn">from</span> <span class="nn">openai</span> <span class="kn">import</span> <span class="n">OpenAI</span>

<span class="n">PROMPT</span> <span class="o">=</span> <span class="s2">&#34;&#34;&#34;请分析提供的图片，并从中提取以下信息：
</span><span class="s2">- 标题(title)
</span><span class="s2">- 学科(subject)
</span><span class="s2">- 领域(field)
</span><span class="s2">
</span><span class="s2">
</span><span class="s2">请以如下格式返回结果：
</span><span class="s2">{
</span><span class="s2">    &#34;title&#34;: &#34;论文的标题&#34;,
</span><span class="s2">    &#34;subject&#34;: &#34;论文所属学科&#34;,
</span><span class="s2">    &#34;field&#34;: &#34;论文的研究领域&#34;,
</span><span class="s2">}&#34;&#34;&#34;</span>


<span class="c1">#本地已安装大模型minicpm-v</span>
<span class="n">model_name</span> <span class="o">=</span> <span class="s1">&#39;minicpm-v&#39;</span>
<span class="n">base_url</span> <span class="o">=</span> <span class="s1">&#39;http://127.0.0.1:11434/v1&#39;</span>
<span class="n">api_key</span> <span class="o">=</span> <span class="s1">&#39;NA&#39;</span>


<span class="c1">#论文的截图文件test_screen.png</span>
<span class="c1">#注意，代码文件与截图文件同处于一个文件夹内</span>
<span class="n">image</span> <span class="o">=</span> <span class="n">instructor</span><span class="o">.</span><span class="n">Image</span><span class="o">.</span><span class="n">from_path</span><span class="p">(</span><span class="s2">&#34;test_screen.png&#34;</span><span class="p">)</span>




<span class="n">client</span> <span class="o">=</span> <span class="n">instructor</span><span class="o">.</span><span class="n">from_openai</span><span class="p">(</span>
        <span class="n">OpenAI</span><span class="p">(</span>
            <span class="n">base_url</span><span class="o">=</span><span class="n">base_url</span><span class="p">,</span>
            <span class="n">api_key</span><span class="o">=</span><span class="n">api_key</span><span class="p">,</span>  <span class="c1"># required, but unused</span>
        <span class="p">),</span>
        <span class="n">mode</span><span class="o">=</span><span class="n">instructor</span><span class="o">.</span><span class="n">Mode</span><span class="o">.</span><span class="n">MD_JSON</span><span class="p">,</span>
<span class="p">)</span>


<span class="k">class</span> <span class="nc">Paper</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>
    <span class="n">title</span><span class="p">:</span> <span class="nb">str</span>
    <span class="n">subject</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span>
    <span class="n">field</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span>




<span class="c1"># Create structured output</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">chat</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="n">model_name</span><span class="p">,</span>
    <span class="n">messages</span><span class="o">=</span><span class="p">[</span>
        <span class="p">{</span><span class="s2">&#34;role&#34;</span><span class="p">:</span> <span class="s2">&#34;asistant&#34;</span><span class="p">,</span> <span class="s2">&#34;content&#34;</span><span class="p">:</span> <span class="n">PROMPT</span><span class="p">},</span>
        <span class="p">{</span><span class="s2">&#34;role&#34;</span><span class="p">:</span> <span class="s2">&#34;user&#34;</span><span class="p">,</span> <span class="s2">&#34;content&#34;</span><span class="p">:</span> <span class="n">image</span><span class="p">},</span>
    <span class="p">],</span>
    <span class="n">response_model</span> <span class="o">=</span> <span class="n">Paper</span><span class="p">,</span>
    <span class="n">temperature</span><span class="o">=</span><span class="mf">0.0</span>
<span class="p">)</span>


<span class="n">result</span><span class="o">.</span><span class="n">model_dump</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">{&#39;title&#39;: &#39;On or Off Track: How (Broken) Streaks Affect Consumer Decisions&#39;,
 &#39;subject&#39;: [&#39;streaks, behavioral tracking and logging, technology, goals and motivation&#39;],
 &#39;field&#39;: [&#39;consumer behavior&#39;, &#39;marketing research&#39;, &#39;engagement strategies&#39;]}
</code></pre></div><br>
<p><br><br></p>
<h2 id="三讨论">三、讨论</h2>
<p>大邓测试发现 <em><strong>结构化输出</strong></em> 很容易出错， 相比之下 <em><strong>非结构化输出</strong></em> 更稳定一些。</p>
<p><br><br></p>
<h2 id="相关内容">相关内容</h2>
<ul>
<li><a href="https://textdata.cn/blog/2025-02-17-gpt-is-an-effective-tool-for-multilingual-psychological-text-analysis/"><strong>PNAS | GPT 是多语言心理文本分析的有效工具</strong></a></li>
<li><a href="https://textdata.cn/blog/2024-06-14-how-to-download-large-language-model-with-ollama/"><strong>教程 | 如何使用 Ollama 下载 &amp; 使用本地大语言模型</strong></a></li>
<li><a href="https://textdata.cn/blog/2024-08-06-using-the-ollama-local-large-model-to-predict-the-sentiment-category-of-online-comments/"><strong>实验 | 使用本地大模型预测在线评论情感类别和分值</strong></a></li>
<li><a href="https://textdata.cn/blog/2024-08-07-structured-outputs-with-ollama/"><strong>实验 | 如何使 Ollama 结构化输出 JSON 样式的结果</strong></a></li>
<li><a href="https://textdata.cn/blog/2024-04-27-cntext2x-usage-tutorial/"><strong>推荐 | 文本分析库cntext2.x使用手册</strong></a></li>
<li><a href="https://textdata.cn/blog/2024-06-14-using-large-language-model-to-extract-structure-data-from-raw-text/"><strong>实验 | 使用本地大模型从文本中提取结构化信息</strong></a></li>
<li><a href="https://textdata.cn/blog/2024-07-10-using-large-language-model-to-build-diy-dictionary/">实验 | 使用Ollama本地大模型DIY制作单词书教案PDF</a></li>
<li><a href="https://textdata.cn/blog/2024-08-05-create-a-blog-writer-multi-agent-system-using-crewai-and-ollama/">实验 | 使用 Crewai 和 Ollama 构建智能体(AI Agent)帮我撰写博客文章</a></li>
</ul>
<p><br><br></p>
<h2 id="精选内容">精选内容</h2>
<ul>
<li><a href="https://textdata.cn/blog/datasets_available_for_management_science/">LIST | 可供社科(经管)领域使用的数据集汇总</a></li>
<li><a href="https://textdata.cn/blog/the_text_analysis_list_about_ms/">LIST | 社科(经管)数据挖掘文献资料汇总</a></li>
<li><a href="https://textdata.cn/blog/2024-06-16-scrapegraph-ai/">网络爬虫 | 使用scrapegraph-ai(大模型方案)自动采集网页数据</a></li>
<li><a href="https://textdata.cn/blog/2024-04-27-cntext2x-usage-tutorial/">推荐 | 文本分析库cntext2.x使用手册</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
<li><a href="https://textdata.cn/blog/2024-06-14-using-large-language-model-to-extract-structure-data-from-raw-text/">实验 | 使用本地大模型从文本中提取结构化信息</a>
<br>
<br></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>PNAS | GPT 是多语言心理文本分析的有效工具</title>
      <link>https://textdata.cn/blog/2025-02-17-gpt-is-an-effective-tool-for-multilingual-psychological-text-analysis/</link>
      <pubDate>Mon, 17 Feb 2025 00:00:00 +0000</pubDate>
      
      <guid>/blog/2025-02-17-gpt-is-an-effective-tool-for-multilingual-psychological-text-analysis/</guid>
      <description>许多领域（包括心理学、社会学、通信、政治学和计算机科学）都使用计算方法来分析文本数据。但是，现有的文本分析方法存在许多缺点。字典方法虽然易于使用，但与最近的方法相比通常不是很准确。机器学习模型虽然更准确，但可能难以训练和使用。我们证明，大型语言模型 GPT 能够使用简单的提示准确检测 12 种语言文本中的各种心理结构（由手动注释者判断），无需额外的训练数据。因此，GPT 克服了现有方法中存在的局限性。GPT 在几种较少使用的语言中也很有效，这可以促进来自研究不足的环境中的文本分析研究。</description>
      <content:encoded><![CDATA[<p>许多领域（包括心理学、社会学、通信、政治学和计算机科学）都使用量化文本分析来构建研究中的概念指标。但现有的文本分析方法存在许多缺点。</p>
<ul>
<li>字典方法易于使用，但与最近的方法相比通常不是很准确。</li>
<li>机器学习模型虽然更准确，但可能难以训练和使用。</li>
</ul>
<p><strong>该研究证明，大型语言模型 GPT 能够使用简单的提示准确检测 12 种语言文本中的各种心理结构(情感、情绪、冒犯性和道德基础)，无需额外的训练数据</strong>。因此，GPT 克服了现有方法中存在的局限性。</p>
<br>
<h2 id="一资料">一、资料</h2>
<h3 id="11-文献">1.1 文献</h3>
<p>S. Rathje, D. Mirea, I. Sucholutsky, R. Marjieh, C.E. Robertson, &amp; J.J. Van Bavel, GPT is an effective tool for multilingual psychological text analysis, Proc. Natl. Acad. Sci. U.S.A. 121 (34) e2308950121, <a href="https://doi.org/10.1073/pnas.2308950121">https://doi.org/10.1073/pnas.2308950121</a> (2024).</p>
<h3 id="12-代码">1.2 代码</h3>
<p>该研究的作者使用的R语言进行的数据分析， 实验数据&amp;代码 <a href="https://osf.io/6pnb2/">https://osf.io/6pnb2/</a></p>
<p>演示视频</p>
<ul>
<li><a href="https://www.youtube.com/watch?v=Mm3uoK4Fogc&amp;t=344s">https://www.youtube.com/watch?v=Mm3uoK4Fogc&amp;t=344s</a></li>
<li><a href="https://www.bilibili.com/video/BV1KQwdeYE74/">https://www.bilibili.com/video/BV1KQwdeYE74/</a></li>
</ul>
<p><img loading="lazy" src="img/03.png" alt=""  />
</p>
<br>
<br>
<h2 id="二内容速览">二、内容速览</h2>
<h3 id="21-研究背景">2.1 研究背景</h3>
<ol>
<li><strong>研究问题</strong>：这篇文章探讨了大型语言模型（LLM）GPT是否可以作为自动化心理文本分析的工具，用于在多种语言中检测心理构念（如情感、离散情绪、冒犯性和道德基础）。</li>
<li><strong>研究难点</strong>：现有的文本分析方法存在准确性和适用性不足的问题。词典方法虽然易于使用，但在检测心理构念时准确性较低。机器学习方法虽然更准确，但需要大量的标注数据和高级编程技能。此外，现有方法在多语言数据分析方面也存在局限性。</li>
<li><strong>相关工作</strong>：计算社会科学领域已经使用自动化文本分析来研究社会趋势、社交媒体病毒式传播、心理健康状况与意识形态、个性等。然而，大多数现有方法依赖于西方人群和英语数据集，缺乏对少数语言和文化的研究。</li>
</ol>
<br>
<h3 id="22-研究方法">2.2 研究方法</h3>
<p>这篇论文提出了使用GPT进行自动化心理文本分析的方法。具体来说，</p>
<ol>
<li><strong>GPT模型</strong>：GPT是基于Transformer架构的大型语言模型，训练数据来自互联网文本（如Common Crawl或Wikipedia），能够在无需额外训练的情况下完成跨语言的文本分析任务（即“零样本学习”）。</li>
<li><strong>提示使用</strong>：GPT通过“提示”的方式工作，即根据用户提出的问题生成输出。例如，对于情感分析任务，提示可以是 <strong>”请根据以下文本的情感打分：1表示非常负面，7表示非常正面”</strong>。</li>
<li><strong>性能评估</strong>：使用准确率和平均F1值来衡量GPT的性能。准确率计算正确评分的数量占总评分数量的比例，而平均F1值则考虑了GPT在不同类型错误（如假阳性和假阴性）上的表现。</li>
</ol>
<br>
<h3 id="23-实验设计">2.3 实验设计</h3>
<ol>
<li><strong>数据集</strong>：使用了15个数据集，共包含47,925条手动标注的推文和新闻标题，涵盖12种语言。数据集涵盖了四种心理构念：<strong>情感、离散情绪、冒犯性和道德基础</strong>。</li>
<li><strong>实验设置</strong>：使用GPT API进行多次提示，提示格式简洁明了。例如，情感分析的提示为：<strong>“请根据以下文本的情感打分：1表示非常负面，7表示非常正面。这里是我们的文本：[文本内容]”</strong>。</li>
<li><strong>对比方法</strong>：将GPT的性能与其他常见的文本分析方法（如词典方法）以及顶级调优的机器学习模型进行对比。</li>
</ol>
<br>
<h3 id="24-结果与分析">2.4 结果与分析</h3>
<p><img loading="lazy" src="img/01.png" alt=""  />
</p>
<p><img loading="lazy" src="img/02.png" alt=""  />
</p>
<ol>
<li><strong>情感分析</strong>：在英语和阿拉伯语数据集上，GPT-3.5 Turbo的准确率为0.673和0.700，F1值分别为0.685和0.720。<strong>GPT-4和GPT-4 Turbo在情感分析任务上也表现出色，且随着模型版本的更新，性能有所提升</strong>。</li>
<li><strong>离散情绪检测</strong>：在英语和印度尼西亚语数据集上，GPT-3.5 Turbo的F1值分别为0.714和0.686，GPT-4 Turbo的F1值分别为0.782和0.785。<strong>GPT-4 Turbo在所有测试的语言中都表现出色，接近或超过了顶级调优的机器学习模型</strong>。</li>
<li><strong>冒犯性检测</strong>：在英语和土耳其语数据集上，GPT-3.5 Turbo的F1值分别为0.721和0.752，GPT-4 Turbo的F1值分别为0.762和0.762。<strong>GPT-4 Turbo在所有测试的语言中都表现出色，显著优于现有的词典方法</strong>。</li>
<li><strong>道德基础检测</strong>：在Reddit评论数据集上，GPT-4的F1值为0.653，GPT-4 Turbo的F1值为0.677。<strong>尽管在某些复杂心理构念（如比例性）上表现较差，但总体上仍接近顶级调优的BERT模型</strong>。</li>
</ol>
<br>
<h3 id="25-总体结论">2.5 总体结论</h3>
<p><strong>这篇论文展示了GPT作为自动化心理文本分析工具的潜力，具有高精度和广泛的应用范围</strong>。GPT在多种语言和不同类型的文本数据上表现出色，且无需额外的训练数据。<strong>尽管在某些复杂心理构念上表现不如最新的调优模型，但其灵活性和易用性使其成为现有自动化文本分析方法的有效替代方案</strong>。未来研究应继续探索GPT和其他LLM在不同语言和文化背景下的表现，以验证其普适性。</p>
<br>
<h2 id="三论文评价">三、论文评价</h2>
<h3 id="31-优点与创新">3.1 优点与创新</h3>
<ol>
<li><strong>多语言支持</strong>：GPT在多种语言（包括12种语言）中表现出色，特别是在较少使用的语言中，如斯瓦希里语、豪萨语、阿姆哈拉语等。</li>
<li><strong>无需训练数据</strong>：GPT能够在零样本学习的情况下进行文本分析，不需要额外的训练数据。</li>
<li><strong>简单易用</strong>：GPT使用简单的提示（如“这篇文章是消极的吗？”）即可进行分析，且不需要大量的编码经验。</li>
<li><strong>高准确性</strong>：<strong>GPT在检测情感、离散情绪、冒犯性和道德基础等心理构念方面，表现优于现有的英语词典分析方法，并且在某些情况下接近或超过了顶级调优的机器学习模型</strong>。</li>
<li><strong>跨语言一致性</strong>：不同版本的GPT在输出上具有高度一致性，表明其结果具有较高的可重复性。</li>
<li><strong>广泛的适用性</strong>：GPT适用于各种文本类型（如推文、新闻标题和Reddit评论），并且能够处理不同类型的评分（如Likert量表）。</li>
<li><strong>测试-重测可靠性</strong>：GPT在多次运行中具有极高的可靠性，Cohen&rsquo;s Kappa值在0.93到0.99之间。</li>
</ol>
<br>
<h3 id="32-不足应对">3.2 不足&amp;应对</h3>
<table>
<thead>
<tr>
<th>问题</th>
<th>反思</th>
<th>应对</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>版本差异</strong></td>
<td>chatGPT模型每时每刻都在训练&amp;更新，不同时刻的GPT可以看做是不同版本；</td>
<td>使用开源LLM， 可明确指定使用的版本，方便其他学者复现。</td>
</tr>
<tr>
<td><strong>心里构念</strong></td>
<td>只能处理较为简单的心理构念， 太复杂的心里构念因为难以描述和界定，无法设计提示。</td>
<td>未来可微调LLM</td>
</tr>
<tr>
<td><strong>成本问题</strong></td>
<td>GPT API的使用成本较高，尤其是GPT-4</td>
<td>使用开源LLM，如Qwen、llama、deepseek；</td>
</tr>
<tr>
<td><strong>隐私问题</strong></td>
<td>使用GPT API可能会导致研究中的隐私数据泄露</td>
<td>本地(离线)部署LLM， 所有数据都不会泄露</td>
</tr>
<tr>
<td><strong>模型选择</strong></td>
<td>本研究仅使用了GPT，未测试其他模型</td>
<td>使用其他LLM，如Qwen、llama、deepseek等</td>
</tr>
<tr>
<td><strong>文化偏见</strong></td>
<td>GPT可能会反映人类偏见，如内群体偏好和对WEIRD人群任务的认知偏差，这可能会影响其结果的普遍性。</td>
<td>对大多数研究来说不是问题， 比如每个研究者都是有偏见的。把GPT这类LLM看做一个有偏见的人看待即可。</td>
</tr>
</tbody>
</table>
<blockquote>
<p>&ldquo;WEIRD&rdquo; 是一个缩写词，代表 &ldquo;Western, Educated, Industrialized, Rich, and Democratic&rdquo;（西方的、受过教育的、工业化的、富裕的和民主的）</p>
</blockquote>
<p><br><br></p>
<h2 id="相关内容">相关内容</h2>
<ul>
<li><a href="https://textdata.cn/blog/2025-02-14-using-online-large-model-api-to-transform-text-data-into-structured-data/"><strong>教程 | 使用大模型将文本数据转化为结构化数据</strong></a></li>
<li><a href="https://textdata.cn/blog/2024-06-14-how-to-download-large-language-model-with-ollama/"><strong>教程 | 如何使用 Ollama 下载 &amp; 使用本地大语言模型</strong></a></li>
<li><a href="https://textdata.cn/blog/2024-08-07-structured-outputs-with-ollama/"><strong>实验 | 如何使 Ollama 结构化输出 JSON 样式的结果</strong></a></li>
<li><a href="https://textdata.cn/blog/2024-04-27-cntext2x-usage-tutorial/"><strong>推荐 | 文本分析库cntext2.x使用手册</strong></a></li>
<li><a href="https://textdata.cn/blog/2024-06-14-using-large-language-model-to-extract-structure-data-from-raw-text/"><strong>实验 | 使用本地大模型从文本中提取结构化信息</strong></a></li>
</ul>
<p><br><br></p>
<h2 id="精选内容">精选内容</h2>
<ul>
<li><a href="https://textdata.cn/blog/datasets_available_for_management_science/">LIST | 可供社科(经管)领域使用的数据集汇总</a></li>
<li><a href="https://textdata.cn/blog/the_text_analysis_list_about_ms/">LIST | 社科(经管)数据挖掘文献资料汇总</a></li>
<li><a href="https://textdata.cn/blog/2024-06-16-scrapegraph-ai/">网络爬虫 | 使用scrapegraph-ai(大模型方案)自动采集网页数据</a></li>
<li><a href="https://textdata.cn/blog/2024-04-27-cntext2x-usage-tutorial/">推荐 | 文本分析库cntext2.x使用手册</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
<li><a href="https://textdata.cn/blog/2024-06-14-using-large-language-model-to-extract-structure-data-from-raw-text/">实验 | 使用本地大模型从文本中提取结构化信息</a>
<br>
<br></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>教程 | 使用大模型将文本编码为结构化数据(Ollama篇)</title>
      <link>https://textdata.cn/blog/2025-02-14-using-online-large-model-api-to-transform-text-data-into-structured-data/</link>
      <pubDate>Fri, 14 Feb 2025 00:00:00 +0000</pubDate>
      
      <guid>/blog/2025-02-14-using-online-large-model-api-to-transform-text-data-into-structured-data/</guid>
      <description>实验数据为外卖评论， 今天咱们做个有难度的文本分析任务，从不同维度(味道、速度、服务)对外卖评论进行打分(-1.0~1.0)文本分析（也称为文本挖掘或自然语言处理，NLP）是指使用计算机算法和技术从大量文本数据中提取有价值信息的过程。文本分析的目标是从非结构化的文本数据中识别模式、提取关键信息、理解语义，并将其转化为结构化数据以便进一步分析和应用。</description>
      <content:encoded><![CDATA[<p>实验数据为外卖评论， 今天咱们做个有难度的文本分析任务，从不同维度(味道、速度、服务)对外卖评论进行打分(-1.0~1.0)。</p>
<p><img loading="lazy" src="img/06-df.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="一文本分析">一、文本分析</h2>
<p><strong>文本分析</strong>（也称为<strong>文本挖掘</strong>或<strong>自然语言处理</strong>，NLP）是指使用计算机算法和技术从大量文本数据中提取有价值信息的过程。文本分析的目标是从非结构化的文本数据中识别模式、提取关键信息、理解语义，并将其转化为结构化数据以便进一步分析和应用。 常用的文本分析方法有:</p>
<ul>
<li>词频统计</li>
<li>情感分析</li>
<li>文本分类</li>
<li>话题分析</li>
<li>&hellip;</li>
</ul>
<p><img loading="lazy" src="img/text-2-structured-data.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="二大模型云服务商">二、大模型云服务商</h2>
<p>随着 chatGPT、deepseek、通义千问这类大语言模型(<strong><em>LLM</em></strong>, large language model)的出现， 它们增强了文本理解能力，能够更精准的把握文本中的语义和情绪等信息，使得文本分析任务实现难度大大降低。</p>
<p>一般大模型服务提供商，有免费开源和封闭付费两种服务。</p>
<ul>
<li>免费模型， 可通过 <strong>Ollama</strong> 本地部署。部署教程可参考 <a href="https://textdata.cn/blog/2024-06-14-how-to-download-large-language-model-with-ollama/"><strong>教程 | 如何使用 Ollama 下载 &amp; 使用本地大语言模型</strong></a></li>
<li>付费模型， 账户有钱的情况下， 通过联网调用大模型厂商的 API 接口。</li>
</ul>
<p>使用 Python 代码， 联网调用大模型的 API，我们首先需要确定三个</p>
<ul>
<li><strong><em>BASE_URL</em></strong> 服务提供商运行大模型的网址。 如果是本地离线， BASE_URL = ''</li>
<li><strong><em>API_KEY</em></strong> 调用服务所需密钥，类似于钥匙</li>
<li><strong><em>MODEL_NAME</em></strong> 调用哪种模型(名字)</li>
</ul>
<p>阿里云不需要注册，支付宝扫码登录，即可调用市面上常见的大模型，如 <strong>通义千问qwen</strong>、<strong>Llama</strong>、<strong>deepseek</strong>、<strong>chatGLM</strong>等。现在我们以阿里云服务商为例， 依次获取<strong>BASE_URL</strong>、<strong>API_KEY</strong>、<strong>MODEL_NAME</strong>。</p>
<br>
<h3 id="21-充钱">2.1 充钱</h3>
<p><a href="https://billing-cost.console.aliyun.com/home">阿里云</a>替咱们在云服务商运行大模型，肯定不能是免费的。 所以先检查下账号里是否有钱，没钱了记得充值哦。 点击链接 <a href="https://billing-cost.console.aliyun.com/home">https://billing-cost.console.aliyun.com/home</a></p>
<p><img loading="lazy" src="img/02-charge.png" alt=""  />
</p>
<br>
<h3 id="22-base_url">2.2 BASE_URL</h3>
<p>阿里云运行大模型的网址 <strong><em>BASE_URL</em></strong> 为 <code>https://dashscope.aliyuncs.com/compatible-mode/v1</code></p>
<br>
<h3 id="23-api_key">2.3 API_KEY</h3>
<p>点击 <a href="https://bailian.console.aliyun.com/">阿里云百炼 https://bailian.console.aliyun.com/</a>，打开后点击右上角<img loading="lazy" src="https://help-static-aliyun-doc.aliyuncs.com/assets/img/zh-CN/0278981271/p824758.png" alt="image"  />
图标，在下拉菜单中单击<strong>API-KEY</strong>。</p>
<p><img loading="lazy" src="img/01-bai-lian.png" alt=""  />
</p>
<br>
<p>在左侧导航栏，选择 <strong>全部 API-KEY</strong> 或 <strong>我的 API-KEY</strong> ，然后<strong>创建</strong>（图中位置 ①）或<strong>查看</strong>（图中位置 ②）<strong><em>API Key</em></strong>。</p>
<p><img loading="lazy" src="img/02-api-key.png" alt=""  />
</p>
<br>
<p><strong>注意:</strong> 请不要将 <strong><em>API Key</em></strong> 以任何方式公开，避免因未经授权的使用造成安全风险或资金损失。</p>
<br>
<h3 id="24-model_name">2.4 MODEL_NAME</h3>
<p><a href="https://help.aliyun.com/zh/model-studio/getting-started/models">通义千问的模型列表 https://help.aliyun.com/zh/model-studio/getting-started/models</a>， 根据任务需要，选择适合的模型。</p>
<p><img loading="lazy" src="img/03-model-name.png" alt=""  />
</p>
<p>上图仅展示了阿里云服务提供的部分大模型， 以通义千问旗舰模型为例， <strong>MODEL_NAME</strong>模型名分别为**<em>qwen-max</em><strong>、</strong><em>qwen-plus</em><strong>、</strong><em>qwen-turbo</em><strong>、</strong><em>qwen-long</em>**。</p>
<br>
<h2 id="三环境配置">三、环境配置</h2>
<p>在 Python 中调用大模型， 不论是本地离线 API 还是云服务 API， 先要配置好相应的环境。 cntext2x支持Ollama和LMstudio结构化输出， 本文使用<strong>Ollama+cntext2.x</strong> 组合。</p>
<h3 id="31-安装软件-ollama">3.1 安装软件 Ollama</h3>
<p><a href="https://ollama.ai/"><strong>Ollama</strong></a>是一款开源应用程序，可让您使用 MacOS、Linux 和 Windows 上的命令行界面在本地运行、创建和共享大型语言模型。</p>
<p>Ollama 可以直接从其库中访问各种 LLM，只需一个命令即可下载。下载后，只需执行一个命令即可开始使用。这对于工作量围绕终端窗口的用户非常有帮助。Ollama 的安装、配置、使用的详细教程可阅读 <a href="https://textdata.cn/blog/2024-06-14-how-to-download-large-language-model-with-ollama/"><strong>教程 | 如何使用 Ollama 下载 &amp; 使用本地大语言模型</strong></a></p>
<p><img loading="lazy" src="img/04-ollama-gui.png" alt=""  />
</p>
<br>
<h3 id="32-安装-cntext2x">3.2 安装 cntext2.x</h3>
<p><a href="https://textdata.cn/blog/2024-04-27-cntext2x-usage-tutorial/">cntext2.x</a>是大邓开发的文本分析库， 内置了丰富的文本分析函数， 如词频统计、词典法情感分析、经济政策不确定性 epu 等， 大大降低了文本分析难度。 以本文大模型文本分析为例， Python 源代码需要 <strong>80+</strong> 行， 经过大邓封装， 使用 cntext2.x 内置函数 <strong><em>text_analysis_by_llm</em></strong> 仅需要不到 <strong>5</strong> 行代码。</p>
<p><strong><em>安装包 cntext-2.1.7-py3-none-any.whl</em></strong> 是付费内容(100 元)， 如需使用<strong>加微信: 372335839</strong>，备注「<strong>姓名-学校-专业-cntext</strong>」</p>
<p>所有 <strong><em>cntext2.x</em></strong> 安装方法类似， 以目前 <strong><em>cntext2.1.7</em></strong> 为例，将 <strong><em>cntext-2.1.7-py3-none-any.whl</em></strong> 放置于桌面，打开 <strong><em>cmd</em></strong> (苹果电脑打开 terminal)， 输入 <strong><em>cd desktop</em></strong></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">cd desktop
</code></pre></div><p>之后在 <strong><em>cmd</em></strong> (苹果电脑打开 terminal) 中使用 <strong><em>pip3</em></strong> 安装</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">pip3 install cntext-2.1.7-py3-none-any.whl
</code></pre></div><p>需要注意， <strong>cntext2.x 使用环境为 Python3.8 及以上版本</strong>； 文章开头和文章末都有 <strong><em>cntext-2.1.7-py3-none-any.whl</em></strong> 获取方式说明。</p>
<p><br><br></p>
<h2 id="四实验代码">四、实验代码</h2>
<h4 id="41-启动本地服务ollama">4.1 启动本地服务(Ollama)</h4>
<p>使用 <strong>cntext2.x</strong> 调用本地电脑安装的大模型进行文本分析，不需要设置<strong>BASE_URL</strong>、<strong>API_KEY</strong> 这两个参数。</p>
<p>本节使用本地安装的模型， 先在命令行<strong>cmd</strong> (mac 对应 terminal) 中检查本地已安装的模型。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">ollama list
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">NAME                       ID              SIZE      MODIFIED
qwen2.5:7b                 845dbda0ea48    4.7 GB    7 days ago
qwen2.5:3b                 357c53fb659c    1.9 GB    7 days ago
qwen2.5:0.5b               a8b0c5157701    397 MB    7 days ago
qwen2.5:1.5b               65ec06548149    986 MB    7 days ago
deepseek-r1:1.5b           a42b25d8c10a    1.1 GB    7 days ago
deepseek-r1:7b             0a8c26691023    4.7 GB    7 days ago
nomic-embed-text:latest    0a109f422b47    274 MB    9 months ago
</code></pre></div><br>
<p>在 <strong><em>cmd</em></strong> 中使用命令 <strong><em>ollama serve</em></strong> 启动本地服务。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">ollama</span> <span class="n">serve</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">2025/02/14 16:00:18 routes.go:1259: INFO server config env=&#34;map[HTTPS_PROXY: HTTP_PROXY: NO_PROXY: OLLAMA_DEBUG:false OLLAMA_FLASH_ATTENTION:false OLLAMA_GPU_OVERHEAD:0 OLLAMA_HOST:http://127.0.0.1:11434 OLLAMA_KEEP_ALIVE:5m0s OLLAMA_KV_CACHE_TYPE: OLLAMA_LLM_LIBRARY: OLLAMA_LOAD_TIMEOUT:5m0s OLLAMA_MAX_LOADED_MODELS:0 OLLAMA_MAX_QUEUE:512 OLLAMA_MODELS:/Users/deng/.ollama/models OLLAMA_MULTIUSER_CACHE:false OLLAMA_NOHISTORY:false OLLAMA_NOPRUNE:false OLLAMA_NUM_PARALLEL:0 OLLAMA_ORIGINS:[http://localhost https://localhost http://localhost:* https://localhost:* http://127.0.0.1 https://127.0.0.1 http://127.0.0.1:* https://127.0.0.1:* http://0.0.0.0 https://0.0.0.0 http://0.0.0.0:* https://0.0.0.0:* app://* file://* tauri://* vscode-webview://*] OLLAMA_SCHED_SPREAD:false http_proxy: https_proxy: no_proxy:]&#34;
time=2025-02-07T16:00:18.551+08:00 level=INFO source=images.go:757 msg=&#34;total blobs: 11&#34;
time=2025-02-07T16:00:18.551+08:00 level=INFO source=images.go:764 msg=&#34;total unused blobs removed: 0&#34;
[GIN-debug] [WARNING] Creating an Engine instance with the Logger and Recovery middleware already attached.

[GIN-debug] [WARNING] Running in &#34;debug&#34; mode. Switch to &#34;release&#34; mode in production.
 - using env:	export GIN_MODE=release
 - using code:	gin.SetMode(gin.ReleaseMode)
er.(*Server).GenerateRoutes.func1 (5 handlers)
......
time=2025-02-14T16:00:18.553+08:00 level=INFO source=routes.go:1339 msg=&#34;Dynamic LLM libraries&#34; runners=[metal]
time=2025-02-14T16:00:18.577+08:00 level=INFO source=types.go:131 msg=&#34;inference compute&#34; id=0 library=metal variant=&#34;&#34; compute=&#34;&#34; driver=0.0 name=&#34;&#34; total=&#34;72.0 GiB&#34; available=&#34;72.0 GiB&#34;

</code></pre></div><p><strong><em>cmd</em></strong> 之中出现上方信息，证明服务已经启动。 如果之前已经启动服务， 会看到信息</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">Error: listen tcp 127.0.0.1:11434: bind: address already in use
</code></pre></div><p>接下来，我们在 Python 中调用模型 <strong><em>qwen2.5:7b</em></strong></p>
<br>
<h3 id="42-读取数据">4.2 读取数据</h3>
<p><strong>实验数据为外卖评论， 今天咱们做个有难度的任务，从不同维度(味道、速度、服务)对外卖评论进行打分(-1.0~1.0)</strong>。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="c1">#构造实验数据</span>
<span class="n">data</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;速度非常快，口味非常好， 服务非常棒！&#39;</span><span class="p">,</span>
        <span class="s1">&#39;送餐时间还是比较久&#39;</span><span class="p">,</span>
        <span class="s1">&#39;送单很快，菜也不错赞&#39;</span><span class="p">,</span>
        <span class="s1">&#39;太难吃了&#39;</span><span class="p">]</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;comment&#39;</span><span class="p">])</span>

<span class="c1">#假设有外卖评论数据集data.csv， 文件内有字段comment， 直接读取数据。</span>
<span class="c1">#df = pd.read_csv(&#39;data.csv&#39;)</span>
<span class="n">df</span>
</code></pre></div><p><img loading="lazy" src="img/05-df.png" alt=""  />
</p>
<br>
<h3 id="43-小实验ctllm">4.3 小实验ct.llm</h3>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>

<span class="n">PROMPT</span> <span class="o">=</span> <span class="s1">&#39;从口味taste、速度speed、服务service三个维度， 对外卖评论内容进行文本分析， 分别返回不同维度的分值(分值范围-1.0 ~ 1.0)&#39;</span>
<span class="n">MODEL_NAME</span> <span class="o">=</span> <span class="s1">&#39;qwen2.5:7b&#39;</span>

<span class="c1">#味道、速度、服务</span>
<span class="n">OUTPUT_FORMAT</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;taste&#39;</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="s1">&#39;speed&#39;</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="s1">&#39;service&#39;</span><span class="p">:</span> <span class="nb">float</span><span class="p">}</span>

<span class="n">COMMENT_CONTENT</span> <span class="o">=</span> <span class="s1">&#39;太难吃了&#39;</span>

<span class="c1">#使用</span>
<span class="c1">#result = ct.llm(text=COMMENT_CONTENT,</span>
<span class="c1">#或</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">llm</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="n">COMMENT_CONTENT</span><span class="p">,</span>
                                 <span class="n">prompt</span><span class="o">=</span><span class="n">PROMPT</span><span class="p">,</span>
                                 <span class="n">model_name</span><span class="o">=</span><span class="n">MODEL_NAME</span><span class="p">,</span>
                                 <span class="n">output_format</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;taste&#39;</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
                                                <span class="s1">&#39;speed&#39;</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
                                                <span class="s1">&#39;service&#39;</span><span class="p">:</span> <span class="nb">float</span><span class="p">},</span>
                                 <span class="n">max_retries</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
                                 <span class="n">return_df</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">result</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">{&#39;taste&#39;: -1.0, &#39;speed&#39;: 0.0, &#39;service&#39;: 0.0}
</code></pre></div><br>
<h3 id="44-内置prompt">4.4 内置Prompt</h3>
<p>cntext2x内置了常用的10种中文文本分析任务， 每个任务都有一个默认的 prompt 模板，用户可以直接使用默认模板或者参考模板进行自定义。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#查看有哪些任务</span>
<span class="n">ct</span><span class="o">.</span><span class="n">llm</span><span class="o">.</span><span class="n">tasks_list</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">[&#39;sentiment&#39;,
 &#39;emotion&#39;,
 &#39;classify&#39;,
 &#39;intent&#39;,
 &#39;keywords&#39;,
 &#39;entities&#39;,
 &#39;summarize&#39;,
 &#39;rewrite&#39;,
 &#39;quality&#39;,
 &#39;similarity&#39;]
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#获取sentiment模板</span>
<span class="n">ct</span><span class="o">.</span><span class="n">llm</span><span class="o">.</span><span class="n">tasks_get</span><span class="p">(</span><span class="s1">&#39;sentiment&#39;</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">{&#39;prompt&#39;: &#39;分析评论的情感倾向：返回情感类别 label（pos 表示正面，neg 表示负面，neutral 表示中性）和情感分值 score（取值范围 -1~1，负数为负面）&#39;,
 &#39;output_format&#39;: {&#39;label&#39;: &#39;str&#39;, &#39;score&#39;: &#39;float&#39;}}
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">#使用sentiment提示词模板。
#启用Ollama服务，调用qwen2.5:7b模型
ct.llm(&#34;服务很棒！&#34;, task=&#34;sentiment&#34;, backend=&#34;ollama&#34;,  model_name=&#34;qwen2.5:7b&#34;)
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">[cntext2x] ✅ 连接模型服务: http://127.0.0.1:11434/v1
{&#39;label&#39;: &#39;pos&#39;, &#39;score&#39;: 0.8}
</code></pre></div><br>
<h3 id="45-云服务商-api">4.5 云服务商 API</h3>
<p>使用 <strong>cntext2.x</strong> 调用云服务商大模型进行文本分析，需要设置<strong>BASE_URL</strong>、<strong>API_KEY</strong>等参数。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>

<span class="n">PROMPT</span> <span class="o">=</span> <span class="s1">&#39;从口味taste、速度speed、服务service三个维度， 对外卖评论内容进行文本分析， 分别返回不同维度的分值(分值范围-1.0 ~ 1.0)&#39;</span>
<span class="n">BASE_URL</span> <span class="o">=</span> <span class="s1">&#39;https://dashscope.aliyuncs.com/compatible-mode/v1&#39;</span>
<span class="n">API_KEY</span> <span class="o">=</span> <span class="s1">&#39;你的API-KEY&#39;</span>
<span class="n">MODEL_NAME</span> <span class="o">=</span> <span class="s1">&#39;qwen-max&#39;</span>

<span class="c1">#味道、速度、服务</span>
<span class="n">OUTPUT_FORMAT</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;taste&#39;</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="s1">&#39;speed&#39;</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="s1">&#39;service&#39;</span><span class="p">:</span> <span class="nb">float</span><span class="p">}</span>

<span class="n">COMMENT_CONTENT</span> <span class="o">=</span> <span class="s1">&#39;太难吃了&#39;</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">llm</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="n">COMMENT_CONTENT</span><span class="p">,</span>
                <span class="n">prompt</span><span class="o">=</span><span class="n">PROMPT</span><span class="p">,</span>
                <span class="n">base_url</span><span class="o">=</span><span class="n">BASE_URL</span><span class="p">,</span>
                <span class="n">api_key</span><span class="o">=</span><span class="n">API_KEY</span><span class="p">,</span>
                <span class="n">model_name</span><span class="o">=</span><span class="n">MODEL_NAME</span><span class="p">,</span>
                <span class="n">output_format</span><span class="o">=</span><span class="n">OUTPUT_FORMAT</span><span class="p">,</span>
                <span class="n">max_retries</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
                <span class="n">return_df</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">result</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">{&#39;taste&#39;: -1.0, &#39;speed&#39;: 0.0, &#39;service&#39;: 0.0}
</code></pre></div><p>小实验成功，现在设计分析函数， 对所有的评论进行分析，输出 dataframe 格式，保存到 csv 中。</p>
<br>
<br>
<h3 id="46-设计分析函数">4.6 设计分析函数</h3>
<p>使用 <strong>cntext2.x</strong> 中的大模型文本分析函数 <strong>ct.llm(text, prompt, base_url, api_key, model_name, temperature, output_format, max_retries, return_df)_</strong></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">- text (str): 待分析的文本内容
- task (str): 预设任务名称，默认为 &#39;sentiment&#39;。可用任务见 TASKS.keys()
- backend (str, optional): 快捷后端别名：
     - &#39;ollama&#39; → http://127.0.0.1:11434/v1
     - &#39;lmstudio&#39; 或 &#39;lms&#39; → http://localhost:1234/v1
     - None → 需配合 base_url 使用
- base_url (str, optional): 自定义模型服务地址，优先级高于 backend。 示例：
     - 远程：https://dashscope.aliyuncs.com/compatible-mode/v1
     - 内网：http://192.168.1.10:11434/v1
     - 本地：http://localhost:1234/v1
- api_key (str): API 密钥，远程服务必填，本地通常为 &#34;EMPTY&#34;
- model_name (str): 模型名称（需服务端已加载）
- temperature (float): 生成温度，0 表示确定性输出
- max_retries (int): 失败重试次数
- return_df (bool): 是否返回 DataFrame
- verbose (bool): 是否输出连接信息
- prompt (str, optional): 自定义系统提示语
- output_format (dict, optional): 自定义输出结构，如 {&#39;label&#39;: str, &#39;score&#39;: float}
</code></pre></div><p>以调用云服务商大模型为例， 设计<strong>ct.llm</strong></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="c1">#分析函数</span>
<span class="k">def</span> <span class="nf">llm_analysis</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">llm</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="n">text</span><span class="p">,</span>
                                <span class="n">prompt</span><span class="o">=</span> <span class="s1">&#39;从口味taste、速度speed、服务service三个维度， 对外卖评论内容进行文本分析， 分别返回不同维度的分值(分值范围-1.0 ~ 1.0)&#39;</span><span class="p">,</span>
                                <span class="n">base_url</span><span class="o">=</span><span class="s1">&#39;https://dashscope.aliyuncs.com/compatible-mode/v1&#39;</span><span class="p">,</span>
                                <span class="n">api_key</span><span class="o">=</span><span class="s1">&#39;你的API-KEY&#39;</span><span class="p">,</span>
                                <span class="n">model_name</span><span class="o">=</span><span class="s1">&#39;qwen-max&#39;</span><span class="p">,</span>
                                <span class="n">temperature</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                                <span class="n">output_format</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;taste&#39;</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="s1">&#39;speed&#39;</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="s1">&#39;service&#39;</span><span class="p">:</span> <span class="nb">float</span><span class="p">}</span>
                               <span class="p">)</span>
    <span class="k">return</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>


<span class="c1">#批量运算</span>
<span class="n">df2</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;comment&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">llm_analysis</span><span class="p">)</span>
<span class="n">res_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">df</span><span class="p">,</span> <span class="n">df2</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="c1">#保存分析结果</span>
<span class="n">res_df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;result.csv&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">res_df</span>
</code></pre></div><p><img loading="lazy" src="img/06-df.png" alt=""  />
</p>
<br>
<br>
<h2 id="五获取-cntext2x">五、获取 cntext2.x</h2>
<p>安装包<strong>cntext-2.1.7-py3-none-any.whl</strong> 是付费内容(<strong><em>100 元</em></strong>)， 如需使用<strong>加微信: 372335839</strong>，备注「<strong>姓名-学校-专业-cntext</strong>」</p>
<p><br><br></p>
<h2 id="相关内容">相关内容</h2>
<ul>
<li><a href="https://textdata.cn/2025-09-09-transform-text-data-into-structured-data-with-lmstudio-and-cntext/"><strong>教程 | 使用大模型将文本数据转化为结构化数据(LMstudio篇)</strong></a></li>
<li><a href="https://textdata.cn/blog/2025-02-17-gpt-is-an-effective-tool-for-multilingual-psychological-text-analysis/"><strong>PNAS | GPT 是多语言心理文本分析的有效工具</strong></a></li>
<li><a href="https://textdata.cn/blog/2024-06-14-how-to-download-large-language-model-with-ollama/"><strong>教程 | 如何使用 Ollama 下载 &amp; 使用本地大语言模型</strong></a></li>
<li><a href="https://textdata.cn/blog/2024-08-06-using-the-ollama-local-large-model-to-predict-the-sentiment-category-of-online-comments/"><strong>实验 | 使用本地大模型预测在线评论情感类别和分值</strong></a></li>
<li><a href="https://textdata.cn/blog/2024-08-07-structured-outputs-with-ollama/"><strong>实验 | 如何使 Ollama 结构化输出 JSON 样式的结果</strong></a></li>
<li><a href="https://textdata.cn/blog/2024-04-27-cntext2x-usage-tutorial/"><strong>推荐 | 文本分析库 cntext2.x 使用手册</strong></a></li>
<li><a href="https://textdata.cn/blog/2024-06-14-using-large-language-model-to-extract-structure-data-from-raw-text/"><strong>实验 | 使用本地大模型从文本中提取结构化信息</strong></a></li>
<li><a href="https://textdata.cn/blog/2024-07-10-using-large-language-model-to-build-diy-dictionary/">实验 | 使用 Ollama 本地大模型 DIY 制作单词书教案 PDF</a></li>
<li><a href="https://textdata.cn/blog/2024-08-05-create-a-blog-writer-multi-agent-system-using-crewai-and-ollama/">实验 | 使用 Crewai 和 Ollama 构建智能体(AI Agent)帮我撰写博客文章</a></li>
</ul>
<p><br><br></p>
<h2 id="精选内容">精选内容</h2>
<ul>
<li><a href="https://textdata.cn/blog/datasets_available_for_management_science/">LIST | 可供社科(经管)领域使用的数据集汇总</a></li>
<li><a href="https://textdata.cn/blog/the_text_analysis_list_about_ms/">LIST | 社科(经管)数据挖掘文献资料汇总</a></li>
<li><a href="https://textdata.cn/blog/2024-06-16-scrapegraph-ai/">网络爬虫 | 使用 scrapegraph-ai(大模型方案)自动采集网页数据</a></li>
<li><a href="https://textdata.cn/blog/2024-04-27-cntext2x-usage-tutorial/">推荐 | 文本分析库 cntext2.x 使用手册</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python 实证指标构建与文本分析</a></li>
<li><a href="https://textdata.cn/blog/2024-06-14-using-large-language-model-to-extract-structure-data-from-raw-text/">实验 | 使用本地大模型从文本中提取结构化信息</a>
<br>
<br></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>实验 | 使用本地大模型预测在线评论情感类别和分值</title>
      <link>https://textdata.cn/blog/2024-08-06-using-the-ollama-local-large-model-to-predict-the-sentiment-category-of-online-comments/</link>
      <pubDate>Fri, 07 Feb 2025 00:00:00 +0000</pubDate>
      
      <guid>/blog/2024-08-06-using-the-ollama-local-large-model-to-predict-the-sentiment-category-of-online-comments/</guid>
      <description>情感分析是分析文本以确定消息的情绪基调是积极、消极还是中性的过程。通过情感分析，我们可以了解文本是否表现出快乐、悲伤、愤怒等情绪。主要的计算方法有语义词典法、机器学习法、混合方法、其他方法。 随着chatGPT这类大语言模型的出现， 它们增强了文本理解能力，使我们能够更精准的把握文本中的语义和情绪，也因此大型语言模型 (LLM) 一出场就有实现情感分析功能。Sentiment analysis is the process of analyzing text to determine whether the emotional tone of a message is positive, negative, or neutral. Through sentiment analysis, we can understand whether the text expresses emotions such as happiness, sadness, anger, etc. The main computational methods are semantic dictionary method, machine learning method, hybrid method, and other methods. With the emergence of large language models such as chatGPT, they enhance text understanding capabilities, allowing us to more accurately grasp the semantics and emotions in the text. Therefore, large language models (LLMs) have implemented sentiment analysis functions as soon as they appeared.</description>
      <content:encoded><![CDATA[<p>情感分析是分析文本以确定消息的情绪基调是积极、消极还是中性的过程。通过情感分析，我们可以了解文本是否表现出快乐、悲伤、愤怒等情绪。主要的计算方法有语义词典法、机器学习法、混合方法、其他方法。 随着chatGPT这类大语言模型的出现， 它们增强了文本理解能力，使我们能够更精准的把握文本中的语义和情绪，也因此大型语言模型 (LLM) 一出场就有实现情感分析功能。</p>
<p><img loading="lazy" src="img/Sentiment-Analysis-methods.png" alt=""  />
</p>
<h2 id="一任务描述">一、任务描述</h2>
<p>大邓准备了200条外卖评论数据(下图蓝色框)， 已进行标注, 其中负面110条，正面90条。</p>
<p>现在想设计一个Prompt， 使用中文大模型对 <em><strong>review</strong></em> 文本进行情感类别(pos/neg)的预测(红色框)， 最终会计算大模型预测的准确率。</p>
<p><img loading="lazy" src="img/00-purpose.png" alt=""  />
</p>
<p>先提前剧透一下， 模型预测的准确率87.5%。这种准确率，用到经管社科研究中， 应该没啥问题。</p>
<p><br><br></p>
<h2 id="二传统模式-vs-大语言模型">二、传统模式 VS 大语言模型</h2>
<p>大语言模型 (LLM) 因其在理解和生成人类语言方面的熟练程度而在情绪分析方面表现出色。通过对各种数据和算法进行训练，LLM 可以检测文本中的细微差别，从而增强其在社交媒体、新闻文章和客户评论等平台上掌握人们情绪和观点的能力。它们捕捉上下文和情感线索的能力提高了情绪分析的准确性和深度。</p>
<p>情感分析领域，传统模式与大语言模型 (LLM) 的比较</p>
<ul>
<li>传统的内容分析方法可能难以准确捕捉细微的情绪。</li>
<li>LLM 使用深度学习和迁移学习等先进技术，擅长理解不同的语言表达。</li>
<li>LLM 在跨文本源（包括社交媒体帖子和新闻文章）的情感分析方面具有卓越的准确性和效率。</li>
</ul>
<p><br><br></p>
<h2 id="三ollama">三、Ollama</h2>
<p><a href="https://ollama.ai/"><strong>Ollama</strong></a>是一款开源应用程序，可让您使用 MacOS、Linux 和 Windows 上的命令行界面在本地运行、创建和共享大型语言模型。</p>
<p>Ollama 可以直接从其库中访问各种 LLM，只需一个命令即可下载。下载后，只需执行一个命令即可开始使用。这对于工作量围绕终端窗口的用户非常有帮助。Ollama的安装、配置、使用的详细教程可阅读  <a href="https://textdata.cn/blog/2024-06-14-how-to-download-large-language-model-with-ollama/"><strong>教程 | 如何使用 Ollama 下载 &amp; 使用本地大语言模型</strong></a></p>
<br>
<h3 id="31-安装模型">3.1 安装模型</h3>
<p>假设电脑中已安装了Ollama软件，</p>
<ul>
<li><em><strong>qwen</strong></em>： 阿里的通义千问大模型， 主要适用于中文场景， 英文也可。</li>
<li><em><strong>llama</strong></em>：Meta发布的LLama大模型，主要适用于英文场景， 中文也可。</li>
<li><em><strong>deepseek</strong></em>： 幻方量化的DeepSeek模型，适用于中英文场景。</li>
</ul>
<p><img loading="lazy" src="img/00-qwen.png" alt=""  />
</p>
<p>本文实验对象为中文内容(中文外卖在线评论）， 之前我尝试过deepseek感觉运行速度较慢， 本文选择 <em><strong>qwen</strong></em> (最新的模型是qwen2.5), <em><strong>我们尝试一次性安装多个模型， 测试运行速度和任务完成的准确率</strong></em>。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">ollama</span> <span class="n">run</span> <span class="n">qwen2</span><span class="mf">.5</span><span class="p">:</span><span class="mf">0.5</span><span class="n">b</span>
<span class="n">ollama</span> <span class="n">run</span> <span class="n">qwen2</span><span class="mf">.5</span><span class="p">:</span><span class="mf">1.5</span><span class="n">b</span>
<span class="n">ollama</span> <span class="n">run</span> <span class="n">qwen2</span><span class="mf">.5</span><span class="p">:</span><span class="mi">3</span><span class="n">b</span>
<span class="n">ollama</span> <span class="n">run</span> <span class="n">qwen2</span><span class="mf">.5</span><span class="p">:</span><span class="mi">7</span><span class="n">b</span>
</code></pre></div><br>
<h3 id="32-安装python包">3.2 安装python包</h3>
<p>打开电脑命令行cmd(mac是terminal),  网络是连网状态，执行安装命令</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">pip3 install ollama
pip3 install instructor
</code></pre></div><p>查看当前版本ollama(0.2.1)和instructor(1.11.2)</p>
<br>
<h3 id="33-启动ollama服务">3.3 启动ollama服务</h3>
<p>在电脑中找到软件 Ollama， 双击打开，即可开启Ollama服务。</p>
<p><br><br></p>
<h2 id="四实验">四、实验</h2>
<h3 id="41-代码结构">4.1 代码结构</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">project
  - code.ipynb                   #代码
  - data.csv                     #在线评论数据
  - qwen2.5-0.5b-result.csv      #qwen2.5:0.5b预测结果
  - qwen2.5-1.5b-result.csv      #qwen2.5:1.5预测结果
  - qwen2.5-3b-result.csv        #qwen2.5:3b预测结果
  - qwen2.5-7b-result.csv        #qwen2.5:7b预测结果
  - async-qwen2.5-7b-result.csv  #qwen2.5:7b异步代码预测结果
</code></pre></div><br>
<h3 id="42-读取数据">4.2 读取数据</h3>
<p><em><strong>data.csv</strong></em> 内存储着200条外卖评论，均已标注(label字段，其中1为正面， 0为负面)</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;data.csv&#39;</span><span class="p">)</span>
<span class="n">df</span>
</code></pre></div><p><img loading="lazy" src="img/06-df.png" alt=""  />
</p>
<br>
<p>字段的数据类型</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df</span><span class="o">.</span><span class="n">dtypes</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">label</span>         <span class="n">int64</span>
<span class="n">review</span>       <span class="nb">object</span>
<span class="n">dtype</span><span class="p">:</span> <span class="nb">object</span>
</code></pre></div><br>
<p>label数值的分布</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">df</span><span class="o">.</span><span class="n">label</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">label
0    110
1     90
Name: count, dtype: int64
</code></pre></div><br>
<h3 id="43-设计提示promp">4.3 设计提示Promp</h3>
<p>需要根据单词，生成单词、音标、语义、例句、历史文化、相关单词等信息， 提示如下，</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">PROMPT_TEXT = &#34;根据评论内容，返回文本的情感类别(pos、neg、neo)和对应的情感得分(取值范围0~1)&#34;&#34;
</code></pre></div><p><strong>注意: PROMPT_TEXT会影响模型表现， 大邓设计的非常粗糙， 建议大家可以设计DIY自己PROMPT_TEXT</strong>。</p>
<br>
<h3 id="44-小实验">4.4 小实验</h3>
<p>使用参考推文 <a href="https://textdata.cn/blog/2024-08-07-structured-outputs-with-ollama/">实验 | 如何使 Ollama 结构化输出 JSON 样式的结果</a> ，可确保情感分析的结果为指定格式。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="o">%%</span><span class="n">time</span>
<span class="kn">from</span> <span class="nn">openai</span> <span class="kn">import</span> <span class="n">OpenAI</span>
<span class="kn">from</span> <span class="nn">pydantic</span> <span class="kn">import</span> <span class="n">BaseModel</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">List</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">instructor</span>

<span class="c1">#结构化输出</span>
<span class="k">class</span> <span class="nc">Sentiment</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>
    <span class="n">senti_label</span><span class="p">:</span> <span class="nb">str</span>
    <span class="n">senti_score</span><span class="p">:</span> <span class="nb">float</span>


<span class="c1">#Prompt提示</span>
<span class="n">PROMPT_TEXT</span> <span class="o">=</span> <span class="s2">&#34;根据评论内容，返回文本的情感类别(pos、neg、neo)和对应的情感得分(取值范围0~1)&#34;</span>

<span class="c1">#实验数据</span>
<span class="n">COMMENT_CONTENT</span> <span class="o">=</span> <span class="s1">&#39;11点14订餐，13点20饭才到，2个小时才把我的午饭送到，而且还是打了2次客服电话，1次投诉电话才给送来，要是不打电话都不知道几点能吃上午饭？&#39;</span>


<span class="n">client</span> <span class="o">=</span> <span class="n">instructor</span><span class="o">.</span><span class="n">from_openai</span><span class="p">(</span>
    <span class="n">OpenAI</span><span class="p">(</span>
        <span class="n">base_url</span><span class="o">=</span><span class="s2">&#34;http://localhost:11434/v1&#34;</span><span class="p">,</span>
        <span class="n">api_key</span><span class="o">=</span><span class="s2">&#34;NA&#34;</span><span class="p">,</span>  <span class="c1"># required, but unused</span>
    <span class="p">),</span>
    <span class="n">mode</span> <span class="o">=</span> <span class="n">instructor</span><span class="o">.</span><span class="n">Mode</span><span class="o">.</span><span class="n">JSON</span><span class="p">,</span>
<span class="p">)</span>


<span class="n">resp</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">chat</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
    <span class="n">model</span> <span class="o">=</span> <span class="s2">&#34;qwen2.5:7b&#34;</span><span class="p">,</span>
    <span class="n">messages</span><span class="o">=</span><span class="p">[</span>
        <span class="p">{</span><span class="s2">&#34;role&#34;</span><span class="p">:</span> <span class="s2">&#34;system&#34;</span><span class="p">,</span> <span class="s2">&#34;content&#34;</span><span class="p">:</span> <span class="n">PROMPT_TEXT</span><span class="p">},</span> <span class="c1">#提示PROMP</span>
        <span class="p">{</span><span class="s2">&#34;role&#34;</span><span class="p">:</span> <span class="s2">&#34;user&#34;</span><span class="p">,</span> <span class="s2">&#34;content&#34;</span><span class="p">:</span> <span class="n">COMMENT_CONTENT</span><span class="p">}</span> <span class="c1">#评论文本</span>
    <span class="p">],</span>
    <span class="n">response_model</span> <span class="o">=</span> <span class="n">Sentiment</span><span class="p">,</span>
    <span class="n">max_retries</span> <span class="o">=</span> <span class="mi">3</span>
<span class="p">)</span>


<span class="nb">print</span><span class="p">(</span><span class="n">resp</span><span class="o">.</span><span class="n">model_dump</span><span class="p">())</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">{&#34;senti_label&#34;: &#34;neg&#34;, &#34;senti_score&#34;: -0.65}

CPU times: user 44.4 ms, sys: 6.46 ms, total: 50.8 ms
Wall time: 1 s
</code></pre></div><p>运行一条评论耗时 1 s， 该评论为 <em><strong>负面neg</strong></em>,  情感分 <em><strong>-0.65</strong></em>。</p>
<br>
<br>
<h2 id="五-完整代码">五、 完整代码</h2>
<p>由于大模型速度非常缓慢，一次提问耗时几秒， 如果大规模使用大模型对数据进行数据标注， 速度慢的令人抓狂。 这时候写代码就有同步代码和异步代码之分。</p>
<ul>
<li><strong>同步代码</strong> 按照顺序执行，每个任务必须等待前一个任务完成后才能开始。适用于处理少量数据或不需要高并发性能的情况。</li>
<li><strong>异步代码</strong> 允许并发执行多个任务，适合处理大量数据时提高效率。使用<code>asyncio</code>库来实现异步操作。</li>
</ul>
<p>本章节是情感分析实验代码的收官章节， 设计了 <strong>同步代码</strong> 和 <strong>异步代码</strong> 两个版本， 并在本章末进行了任务耗时(速度)对比。</p>
<h3 id="51-同步代码">5.1 同步代码</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="o">%%</span><span class="n">time</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>
<span class="kn">from</span> <span class="nn">openai</span> <span class="kn">import</span> <span class="n">OpenAI</span>
<span class="kn">from</span> <span class="nn">pydantic</span> <span class="kn">import</span> <span class="n">BaseModel</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">List</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">instructor</span>

 

<span class="c1">#结构化输出</span>
<span class="k">class</span> <span class="nc">Sentiment</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>
    <span class="n">senti_label</span><span class="p">:</span> <span class="nb">str</span>
    <span class="n">senti_score</span><span class="p">:</span> <span class="nb">float</span>
    

<span class="c1">#Prompt提示</span>
<span class="n">PROMPT_TEXT</span> <span class="o">=</span> <span class="s2">&#34;根据评论内容，返回文本的情感类别(pos、neg)和情感得分(取值范围 -1~1)&#34;</span> 

<span class="n">client</span> <span class="o">=</span> <span class="n">instructor</span><span class="o">.</span><span class="n">from_openai</span><span class="p">(</span>
    <span class="n">OpenAI</span><span class="p">(</span>
        <span class="n">base_url</span><span class="o">=</span><span class="s2">&#34;http://localhost:11434/v1&#34;</span><span class="p">,</span>
        <span class="n">api_key</span><span class="o">=</span><span class="s2">&#34;NA&#34;</span><span class="p">,</span>  <span class="c1"># required, but unused</span>
    <span class="p">),</span>
    <span class="c1">#mode = instructor.Mode.JSON,</span>
    <span class="n">mode</span> <span class="o">=</span> <span class="n">instructor</span><span class="o">.</span><span class="n">Mode</span><span class="o">.</span><span class="n">MD_JSON</span><span class="p">,</span>
<span class="p">)</span>


<span class="n">labels</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">scores</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1">#读取数据</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;data.csv&#39;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">review</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;review&#39;</span><span class="p">]):</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">resp</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">chat</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
        <span class="n">model</span> <span class="o">=</span> <span class="s1">&#39;qwen2.5:7b&#39;</span><span class="p">,</span>  <span class="c1">#选择模型。 0.5b、1.5b、3b、7b等</span>
        <span class="n">messages</span><span class="o">=</span><span class="p">[</span>
            <span class="p">{</span><span class="s2">&#34;role&#34;</span><span class="p">:</span> <span class="s2">&#34;system&#34;</span><span class="p">,</span> <span class="s2">&#34;content&#34;</span><span class="p">:</span> <span class="n">PROMPT_TEXT</span><span class="p">},</span>  <span class="c1">#提示</span>
            <span class="p">{</span><span class="s2">&#34;role&#34;</span><span class="p">:</span> <span class="s2">&#34;user&#34;</span><span class="p">,</span> <span class="s2">&#34;content&#34;</span><span class="p">:</span> <span class="n">review</span><span class="p">}</span>   <span class="c1">#评论文本</span>
        <span class="p">],</span>
        <span class="n">response_model</span> <span class="o">=</span> <span class="n">Sentiment</span><span class="p">,</span>
        <span class="n">max_retries</span> <span class="o">=</span> <span class="mi">3</span>
    <span class="p">)</span>
        
        <span class="n">labels</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">resp</span><span class="o">.</span><span class="n">senti_label</span><span class="p">)</span>
        <span class="n">scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">resp</span><span class="o">.</span><span class="n">senti_score</span><span class="p">)</span>
    <span class="k">except</span><span class="p">:</span>
        <span class="n">labels</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">&#39;NA&#39;</span><span class="p">)</span>
        <span class="n">scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">&#39;NA&#39;</span><span class="p">)</span>
        
        
    
    
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;SentiLabel&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">labels</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;SentiScore&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">scores</span>
<span class="c1">#保存结果</span>
<span class="n">df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;qwen2.5-7b-result.csv&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">df</span>
</code></pre></div><p><img loading="lazy" src="img/07-df.png" alt=""  />
</p>
<br>
<h3 id="52-异步代码">5.2 异步代码</h3>
<p>相比 <em><strong>5.1普通代码</strong></em> ， 异步代码运行速度更快。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">tqdm.asyncio</span> <span class="kn">import</span> <span class="n">tqdm_asyncio</span>
<span class="c1"># 使用AsyncOpenAI代替OpenAI以支持异步操作</span>
<span class="kn">from</span> <span class="nn">openai</span> <span class="kn">import</span> <span class="n">AsyncOpenAI</span>
<span class="kn">from</span> <span class="nn">pydantic</span> <span class="kn">import</span> <span class="n">BaseModel</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">List</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">instructor</span>
<span class="kn">import</span> <span class="nn">asyncio</span>

<span class="c1"># 结构化输出</span>
<span class="k">class</span> <span class="nc">Sentiment</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>
    <span class="n">senti_label</span><span class="p">:</span> <span class="nb">str</span>
    <span class="n">senti_score</span><span class="p">:</span> <span class="nb">float</span>

<span class="c1"># Prompt提示</span>
<span class="n">PROMPT_TEXT</span> <span class="o">=</span> <span class="s2">&#34;根据评论内容，返回文本的情感类别(pos、neg)和情感得分(取值范围 -1~1)&#34;</span>

<span class="n">client</span> <span class="o">=</span> <span class="n">instructor</span><span class="o">.</span><span class="n">from_openai</span><span class="p">(</span>
    <span class="n">AsyncOpenAI</span><span class="p">(</span>
        <span class="n">base_url</span><span class="o">=</span><span class="s2">&#34;http://localhost:11434/v1&#34;</span><span class="p">,</span>
        <span class="n">api_key</span><span class="o">=</span><span class="s2">&#34;NA&#34;</span><span class="p">,</span>  <span class="c1"># required, but unused</span>
    <span class="p">),</span>
    <span class="c1">#mode=instructor.Mode.JSON,</span>
    <span class="n">mode</span><span class="o">=</span><span class="n">instructor</span><span class="o">.</span><span class="n">Mode</span><span class="o">.</span><span class="n">MD_JSON</span><span class="p">,</span>
<span class="p">)</span>

<span class="k">async</span> <span class="k">def</span> <span class="nf">analyze_review</span><span class="p">(</span><span class="n">review</span><span class="p">):</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">resp</span> <span class="o">=</span> <span class="k">await</span> <span class="n">client</span><span class="o">.</span><span class="n">chat</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
            <span class="n">model</span><span class="o">=</span><span class="s1">&#39;qwen2.5:7b&#39;</span><span class="p">,</span>  <span class="c1"># 选择模型。 3b、7b等</span>
            <span class="n">messages</span><span class="o">=</span><span class="p">[</span>
                <span class="p">{</span><span class="s2">&#34;role&#34;</span><span class="p">:</span> <span class="s2">&#34;system&#34;</span><span class="p">,</span> <span class="s2">&#34;content&#34;</span><span class="p">:</span> <span class="n">PROMPT_TEXT</span><span class="p">},</span>  <span class="c1"># 提示</span>
                <span class="p">{</span><span class="s2">&#34;role&#34;</span><span class="p">:</span> <span class="s2">&#34;user&#34;</span><span class="p">,</span> <span class="s2">&#34;content&#34;</span><span class="p">:</span> <span class="n">review</span><span class="p">}</span>  <span class="c1"># 评论文本</span>
            <span class="p">],</span>
            <span class="n">response_model</span><span class="o">=</span><span class="n">Sentiment</span><span class="p">,</span>
            <span class="n">max_retries</span><span class="o">=</span><span class="mi">3</span>  <span class="c1"># 最大(失败）的重试次数。</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">resp</span><span class="o">.</span><span class="n">senti_label</span><span class="p">,</span> <span class="n">resp</span><span class="o">.</span><span class="n">senti_score</span>
    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;Error processing review: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
        <span class="k">return</span> <span class="s1">&#39;NA&#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>

<span class="k">async</span> <span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="c1"># 读取数据</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;data.csv&#39;</span><span class="p">)</span>
    <span class="n">tasks</span> <span class="o">=</span> <span class="p">[</span><span class="n">analyze_review</span><span class="p">(</span><span class="n">review</span><span class="p">)</span> <span class="k">for</span> <span class="n">review</span> <span class="ow">in</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;review&#39;</span><span class="p">]]</span>
    <span class="n">results</span> <span class="o">=</span> <span class="k">await</span> <span class="n">tqdm_asyncio</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="o">*</span><span class="n">tasks</span><span class="p">)</span>
    
    <span class="n">labels</span><span class="p">,</span> <span class="n">scores</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">results</span><span class="p">)</span>
    <span class="n">df</span><span class="p">[</span><span class="s1">&#39;SentiLabel&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">labels</span>
    <span class="n">df</span><span class="p">[</span><span class="s1">&#39;SentiScore&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">scores</span>
    
    <span class="c1"># 保存结果</span>
    <span class="n">df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;async-qwen2.5-7b-result.csv&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># 检查是否已经在运行的事件循环中</span>
<span class="k">try</span><span class="p">:</span>
    <span class="n">asyncio</span><span class="o">.</span><span class="n">get_running_loop</span><span class="p">()</span>
    <span class="c1"># 如果在交互模式下运行，直接调度main()而不使用asyncio.run</span>
    <span class="n">asyncio</span><span class="o">.</span><span class="n">create_task</span><span class="p">(</span><span class="n">main</span><span class="p">())</span>
<span class="k">except</span> <span class="ne">RuntimeError</span><span class="p">:</span>
    <span class="c1"># 如果没有正在运行的事件循环，使用asyncio.run(main())</span>
    <span class="n">asyncio</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">main</span><span class="p">())</span>
</code></pre></div><br>
<h3 id="53-速度对比">5.3 速度对比</h3>
<p>以<em><strong>qwen2.5:7b</strong></em>为例， 对本文 <em><strong>data.csv</strong></em> 在线评论数据进行情感分析，</p>
<ul>
<li><strong>普通代码</strong> 运行耗时 <strong>160</strong> 秒</li>
<li><strong>异步代码</strong> 运行耗时 <strong>90</strong> 秒</li>
</ul>
<br>
<p><br><br></p>
<h2 id="六评价模型">六、评价模型</h2>
<p>本文分别对0.5b、1.5b、3b、7b进行实验， 记录了200条外卖评论的任务耗时(以同步代码为例）和准确率， 结果如下</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">|  模型  | 模型参数 | 任务耗时(秒) | 准确率 |
| ----- | ------  |  --------  | ----- |
|qwen2.5|   0.5b  |     260s   | 1.5%  |
|qwen2.5|   1.5b  |    48.5s   | 58.5% |
|qwen2.5|    3b   |     140s   |  86%  |
|qwen2.5|    7b   |     160s   |  87.5% |
</code></pre></div><p>综合任务耗时和准确率， 建议使用 <em><strong>qwen2.5:3b</strong></em> 和 <em><strong>qwen2.5:7b</strong></em> 。如果电脑性能很好，直接上  <em><strong>qwen2.5:7b</strong></em>  甚至更大参数的模型。</p>
<h3 id="tips准确率计算方法">Tips:准确率计算方法</h3>
<p>假设label为1时， <em><strong>SentiLabel</strong></em> 为pos(或label为0时， SentiLabel为neg)， 大模型判断正确。反之，判断失误。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">expression</span> <span class="o">=</span> <span class="s2">&#34;(label == 1) &amp; (sentiment == &#39;pos&#39;) | (label == 0) &amp; (sentiment == &#39;neg&#39;)&#34;</span>
<span class="n">correct_ratio</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="n">expression</span><span class="p">))</span><span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;准确率: </span><span class="si">{</span><span class="n">correct_ratio</span><span class="o">*</span><span class="mi">100</span><span class="si">}</span><span class="s1">%&#39;</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">准确率: 86%
</code></pre></div><p><br><br></p>
<h2 id="七获取代码">七、获取代码</h2>
<p><a href="project.zip"><strong>点击下载本文代码</strong></a></p>
<p><br><br></p>
<h2 id="相关内容">相关内容</h2>
<ul>
<li><a href="https://textdata.cn/blog/2025-02-17-gpt-is-an-effective-tool-for-multilingual-psychological-text-analysis/"><strong>文献 | GPT 是多语言心理文本分析的有效工具</strong></a></li>
<li><a href="https://textdata.cn/blog/2024-06-14-how-to-download-large-language-model-with-ollama/"><strong>教程 | 如何使用 Ollama 下载 &amp; 使用本地大语言模型</strong></a></li>
<li><a href="https://textdata.cn/blog/2024-08-07-structured-outputs-with-ollama/"><strong>实验 | 如何使 Ollama 结构化输出 JSON 样式的结果</strong></a></li>
<li><a href="https://textdata.cn/blog/2024-04-27-cntext2x-usage-tutorial/"><strong>推荐 | 文本分析库cntext2.x使用手册</strong></a></li>
<li><a href="https://textdata.cn/blog/2024-06-14-using-large-language-model-to-extract-structure-data-from-raw-text/"><strong>实验 | 使用本地大模型从文本中提取结构化信息</strong></a></li>
<li><a href="https://textdata.cn/blog/2024-07-10-using-large-language-model-to-build-diy-dictionary/">实验 | 使用Ollama本地大模型DIY制作单词书教案PDF</a></li>
<li><a href="https://textdata.cn/blog/2024-08-05-create-a-blog-writer-multi-agent-system-using-crewai-and-ollama/">实验 | 使用 Crewai 和 Ollama 构建智能体(AI Agent)帮我撰写博客文章</a></li>
</ul>
<p><br><br></p>
<h2 id="精选内容">精选内容</h2>
<ul>
<li><a href="https://textdata.cn/blog/datasets_available_for_management_science/">LIST | 可供社科(经管)领域使用的数据集汇总</a></li>
<li><a href="https://textdata.cn/blog/the_text_analysis_list_about_ms/">LIST | 社科(经管)数据挖掘文献资料汇总</a></li>
<li><a href="https://textdata.cn/blog/2024-06-16-scrapegraph-ai/">网络爬虫 | 使用scrapegraph-ai(大模型方案)自动采集网页数据</a></li>
<li><a href="https://textdata.cn/blog/2024-04-27-cntext2x-usage-tutorial/">推荐 | 文本分析库cntext2.x使用手册</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
<li><a href="https://textdata.cn/blog/2024-06-14-using-large-language-model-to-extract-structure-data-from-raw-text/">实验 | 使用本地大模型从文本中提取结构化信息</a>
<br>
<br></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>实验 | 如何使 Ollama 结构化输出 JSON 样式的结果</title>
      <link>https://textdata.cn/blog/2024-08-07-structured-outputs-with-ollama/</link>
      <pubDate>Fri, 07 Feb 2025 00:00:00 +0000</pubDate>
      
      <guid>/blog/2024-08-07-structured-outputs-with-ollama/</guid>
      <description>开源 LLMS 越来越受欢迎，Ollama 的 OpenAI 兼容性后来发布了，这使得使用 JSON 模式获取结构化输出成为可能。在本篇博文的结尾，您将了解如何有效地利用 Instructor 和 ollama。但在继续之前，让我们先探讨一下修补的概念。Open-source LLMS are gaining popularity, and the release of Ollama&amp;#39;s OpenAI compatibility later it has made it possible to obtain structured outputs using JSON schema.By the end of this blog post, you will learn how to effectively utilize instructor with ollama. But before we proceed, let&amp;#39;s first explore the concept of patching.</description>
      <content:encoded><![CDATA[<h2 id="一问题">一、问题</h2>
<p>我们希望LLM的回答的结果具有格式，最好是JSON格式(Python字典)， 这样有利于后续的调用。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#普通格式</span>
<span class="n">姓名</span> <span class="n">张三</span>
<span class="n">年龄</span> <span class="mi">34</span>
<span class="n">兴趣</span> <span class="n">打篮球</span><span class="err">、</span><span class="n">踢足球</span><span class="err">、</span><span class="n">游泳</span><span class="err">、</span><span class="n">打游戏</span>


<span class="c1">#JSON格式</span>
<span class="p">{</span>
  <span class="s2">&#34;name&#34;</span><span class="p">:</span> <span class="s2">&#34;张三&#34;</span><span class="p">,</span>
  <span class="s2">&#34;age&#34;</span><span class="p">:</span> <span class="mi">34</span><span class="p">,</span>
  <span class="s2">&#34;hobby&#34;</span><span class="p">:</span> <span class="p">[</span>
    <span class="s2">&#34;打篮球&#34;</span><span class="p">,</span>
    <span class="s2">&#34;踢足球&#34;</span><span class="p">,</span>
    <span class="s2">&#34;游泳&#34;</span><span class="p">,</span>
    <span class="s2">&#34;打游戏&#34;</span>
  <span class="p">]</span>
<span class="p">}</span>
</code></pre></div><p>如何从 「普通格式」转为 结构化的「JSON格式」？这里就用到 <em><strong>Instructor库</strong></em> 。</p>
<p><br><br></p>
<h2 id="二instructor介绍">二、Instructor介绍</h2>
<p><em><strong>Instructor</strong></em> 是一个 Python 库，它使处理大型语言模型 (LLM) 的结构化输出变得轻而易举。它建立在 Pydantic 之上，提供了一个简单、透明且用户友好的 API 来管理验证、重试和流式响应。</p>
<br>
<h3 id="21-instructor的主要特征">2.1 Instructor的主要特征</h3>
<ul>
<li><strong>定义输出样式</strong>：指定 Pydantic 模型来定义 LLM 输出的结构</li>
<li><strong>失败重试管理</strong>：轻松配置请求失败的重试次数</li>
<li><strong>样式验证</strong>：使用 Pydantic 验证确保 LLM 响应符合您的期望</li>
<li><strong>灵活的后端</strong>：与 OpenAI 之外的各种 LLM 提供商无缝集成</li>
</ul>
<br>
<h3 id="22-安装">2.2 安装</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">pip install instructor
</code></pre></div><br>
<h3 id="23-样例">2.3 样例</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">instructor</span>
<span class="kn">from</span> <span class="nn">pydantic</span> <span class="kn">import</span> <span class="n">BaseModel</span>
<span class="kn">from</span> <span class="nn">openai</span> <span class="kn">import</span> <span class="n">OpenAI</span>


<span class="c1"># Define your desired output structure</span>
<span class="k">class</span> <span class="nc">UserInfo</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>
    <span class="n">name</span><span class="p">:</span> <span class="nb">str</span>
    <span class="n">age</span><span class="p">:</span> <span class="nb">int</span>


<span class="c1"># Patch the OpenAI client</span>
<span class="n">client</span> <span class="o">=</span> <span class="n">instructor</span><span class="o">.</span><span class="n">from_openai</span><span class="p">(</span><span class="n">OpenAI</span><span class="p">())</span>

<span class="c1"># Extract structured data from natural language</span>
<span class="n">user_info</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">chat</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="s2">&#34;gpt-3.5-turbo&#34;</span><span class="p">,</span>
    <span class="n">response_model</span><span class="o">=</span><span class="n">UserInfo</span><span class="p">,</span>
    <span class="n">messages</span><span class="o">=</span><span class="p">[{</span><span class="s2">&#34;role&#34;</span><span class="p">:</span> <span class="s2">&#34;user&#34;</span><span class="p">,</span> <span class="s2">&#34;content&#34;</span><span class="p">:</span> <span class="s2">&#34;John Doe is 30 years old.&#34;</span><span class="p">}],</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">user_info</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
<span class="c1">#&gt; John Doe</span>
<span class="nb">print</span><span class="p">(</span><span class="n">user_info</span><span class="o">.</span><span class="n">age</span><span class="p">)</span>
<span class="c1">#&gt; 30</span>
</code></pre></div><p>注意，本部分的样例仅供观看，因为chatGPT 限制中国大陆用户使用，所以不论是你还是大邓，运行此代码会失败。但文章末尾会提供本地电脑可运行的实验代码。</p>
<p><br><br></p>
<h2 id="三结构化输出实验">三、结构化输出实验</h2>
<h3 id="31-环境配置">3.1 环境配置</h3>
<p>假设已在本地安装Ollama软件， 也使用ollama安装了相应的大语言模型(如 <em><strong>qwen2.5:0.5b</strong></em>、<em><strong>deepseek-r1:1.5b</strong></em> 等)。 如果之前没有进行这些操作， 请阅读 <a href="https://textdata.cn/blog/2024-06-14-how-to-download-large-language-model-with-ollama/"><strong>教程 | 如何使用 Ollama 下载 &amp; 使用本地大语言模型</strong></a></p>
<br>
<p>在命令行<em><strong>cmd</strong></em> (mac对应terminal) 中启动本地服务。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">ollama</span> <span class="n">serve</span>
</code></pre></div><br>
<h3 id="32-代码">3.2 代码</h3>
<p>只要完成2.2、3.1，本章节的代码是可以运行出结果的。  不做过多解释，直接上代码，大家看运行结果。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="o">%%</span><span class="n">time</span>

<span class="kn">from</span> <span class="nn">openai</span> <span class="kn">import</span> <span class="n">OpenAI</span>
<span class="kn">from</span> <span class="nn">pydantic</span> <span class="kn">import</span> <span class="n">BaseModel</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">List</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">instructor</span>



<span class="c1">#结构化输出</span>
<span class="k">class</span> <span class="nc">UserDetail</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>
    <span class="n">name</span><span class="p">:</span> <span class="nb">str</span>
    <span class="n">age</span><span class="p">:</span> <span class="nb">int</span>
    <span class="n">hobby</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span>
    

<span class="c1">#Prompt提示</span>
<span class="n">PROMPT_TEXT</span> <span class="o">=</span> <span class="s2">&#34;根据自我介绍文本内容，从中提取出姓名、年龄、兴趣&#34;</span>

<span class="c1">#实验数据</span>
<span class="n">introduction_text</span> <span class="o">=</span> <span class="s1">&#39;我是张三，今年34岁， 来自黑龙江省， 我的兴趣爱好有打篮球、踢足球、游泳、打游戏。&#39;</span>


<span class="n">client</span> <span class="o">=</span> <span class="n">instructor</span><span class="o">.</span><span class="n">from_openai</span><span class="p">(</span>
    <span class="n">OpenAI</span><span class="p">(</span>
        <span class="n">base_url</span><span class="o">=</span><span class="s2">&#34;http://localhost:11434/v1&#34;</span><span class="p">,</span>
        <span class="n">api_key</span><span class="o">=</span><span class="s2">&#34;NA&#34;</span><span class="p">,</span>  <span class="c1"># required, but unused</span>
    <span class="p">),</span>
    <span class="n">mode</span> <span class="o">=</span> <span class="n">instructor</span><span class="o">.</span><span class="n">Mode</span><span class="o">.</span><span class="n">JSON</span><span class="p">,</span>
<span class="p">)</span>


<span class="n">resp</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">chat</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
    <span class="n">model</span> <span class="o">=</span> <span class="s2">&#34;qwen2.5:0.5b&#34;</span><span class="p">,</span> <span class="c1">#本次任务简单，可以使用最轻量的0.5b模型。 </span>
    <span class="n">messages</span><span class="o">=</span><span class="p">[</span>
        <span class="p">{</span><span class="s2">&#34;role&#34;</span><span class="p">:</span> <span class="s2">&#34;system&#34;</span><span class="p">,</span> <span class="s2">&#34;content&#34;</span><span class="p">:</span> <span class="n">PROMPT_TEXT</span><span class="p">},</span>
        <span class="p">{</span><span class="s2">&#34;role&#34;</span><span class="p">:</span> <span class="s2">&#34;user&#34;</span><span class="p">,</span> <span class="s2">&#34;content&#34;</span><span class="p">:</span> <span class="n">introduction_text</span><span class="p">}</span>
    <span class="p">],</span>
    <span class="n">response_model</span> <span class="o">=</span> <span class="n">UserDetail</span><span class="p">,</span>
    <span class="n">max_retries</span> <span class="o">=</span> <span class="mi">3</span>
<span class="p">)</span>


<span class="nb">print</span><span class="p">(</span><span class="n">resp</span><span class="o">.</span><span class="n">model_dump_json</span><span class="p">(</span><span class="n">indent</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">{
  &#34;name&#34;: &#34;张三&#34;,
  &#34;age&#34;: 34,
  &#34;hobby&#34;: [
    &#34;打篮球&#34;,
    &#34;踢足球&#34;,
    &#34;游泳&#34;,
    &#34;打游戏&#34;
  ]
}
CPU times: user 47.2 ms, sys: 5.71 ms, total: 52.9 ms
Wall time: 412 ms
</code></pre></div><p>resp的数据类型为UserDetail， 是代码中是我们定义的 <em><strong>UserDetail</strong></em> 类。该类具有一些方法，也可直接 <em><strong>resp.dict()</strong></em> 转化为dict</p>
<br>
<p>查看 resp 的数据类型</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="nb">print</span><span class="p">(</span><span class="n">resp</span><span class="o">.</span><span class="n">dict</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">resp</span><span class="o">.</span><span class="n">dict</span><span class="p">()))</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">{&#39;name&#39;: &#39;张三&#39;, &#39;age&#39;: 34, &#39;hobby&#39;: [&#39;打篮球&#39;, &#39;踢足球&#39;, &#39;游泳&#39;, &#39;打游戏&#39;]}
&lt;class &#39;dict&#39;&gt;
</code></pre></div><br>
<br>
<h2 id="相关内容">相关内容</h2>
<ul>
<li><a href="https://textdata.cn/blog/2024-06-14-how-to-download-large-language-model-with-ollama/"><strong>教程 | 如何使用 Ollama 下载 &amp; 使用本地大语言模型</strong></a></li>
<li><a href="https://textdata.cn/blog/2024-08-06-using-the-ollama-local-large-model-to-predict-the-sentiment-category-of-online-comments/"><strong>实验 | 使用本地大模型预测在线评论情感类别和分值</strong></a></li>
<li><a href="https://textdata.cn/blog/2025-02-14-using-online-large-model-api-to-transform-text-data-into-structured-data/"><strong>教程 | 使用大模型API将文本数据转化为结构化数据</strong></a></li>
<li><a href="https://textdata.cn/blog/2024-04-27-cntext2x-usage-tutorial/"><strong>推荐 | 文本分析库cntext2.x使用手册</strong></a></li>
<li><a href="https://textdata.cn/blog/2024-06-14-using-large-language-model-to-extract-structure-data-from-raw-text/"><strong>实验 | 使用本地大模型从文本中提取结构化信息</strong></a></li>
<li><a href="https://textdata.cn/blog/2024-07-10-using-large-language-model-to-build-diy-dictionary/">实验 | 使用Ollama本地大模型DIY制作单词书教案PDF</a></li>
<li><a href="https://textdata.cn/blog/2024-08-05-create-a-blog-writer-multi-agent-system-using-crewai-and-ollama/">实验 | 使用 Crewai 和 Ollama 构建智能体(AI Agent)帮我撰写博客文章</a></li>
</ul>
<p><br><br></p>
<h2 id="精选内容">精选内容</h2>
<ul>
<li><a href="https://textdata.cn/blog/datasets_available_for_management_science/">LIST | 可供社科(经管)领域使用的数据集汇总</a></li>
<li><a href="https://textdata.cn/blog/the_text_analysis_list_about_ms/">LIST | 社科(经管)数据挖掘文献资料汇总</a></li>
<li><a href="https://textdata.cn/blog/2024-06-16-scrapegraph-ai/">网络爬虫 | 使用scrapegraph-ai(大模型方案)自动采集网页数据</a></li>
<li><a href="https://textdata.cn/blog/2024-04-27-cntext2x-usage-tutorial/">推荐 | 文本分析库cntext2.x使用手册</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
<li><a href="https://textdata.cn/blog/2024-06-14-using-large-language-model-to-extract-structure-data-from-raw-text/">实验 | 使用本地大模型从文本中提取结构化信息</a>
<br>
<br></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>教程 | 如何使用 Ollama 下载 &amp; 使用本地大语言模型</title>
      <link>https://textdata.cn/blog/2024-06-14-how-to-download-large-language-model-with-ollama/</link>
      <pubDate>Fri, 07 Feb 2025 00:00:00 +0000</pubDate>
      
      <guid>/blog/2024-06-14-how-to-download-large-language-model-with-ollama/</guid>
      <description>Ollama是一款开源应用程序，可让您使用 MacOS、Linux 和 Windows 上的命令行界面在本地运行、创建和共享大型语言模型。Ollama 可以直接从其库中访问各种 LLM，只需一个命令即可下载。下载后，只需执行一个命令即可开始使用。这对于工作量围绕终端窗口的用户非常有帮助。如果他们被困在某个地方，他们可以在不切换到另一个浏览器窗口的情况下获得答案。Ollama is an open source application that allows you to run, create, and share large language models locally using a command line interface on MacOS, Linux, and Windows. Ollama can access a variety of LLMs directly from its library and can be downloaded with just one command. Once downloaded, it only takes one command to get started. This is very helpful for users whose workload revolves around a terminal window. If they are stuck somewhere, they can get the answer without switching to another browser window.</description>
      <content:encoded><![CDATA[<br>
<h2 id="一ollama">一、Ollama</h2>
<h3 id="11-ollama介绍">1.1 Ollama介绍</h3>
<p><a href="https://ollama.ai/"><strong>Ollama</strong></a>是一款开源应用程序，可让您使用 MacOS、Linux 和 Windows 上的命令行界面在本地运行、创建和共享大型语言模型。</p>
<p>Ollama 可以直接从其库中访问各种 LLM，只需一个命令即可下载。下载后，只需执行一个命令即可开始使用。这对于工作量围绕终端窗口的用户非常有帮助。如果他们被困在某个地方，他们可以在不切换到另一个浏览器窗口的情况下获得答案。</p>
<br>
<p>这就是为什么 OLLAMA 是您的工具包中必备的工具：</p>
<ul>
<li><strong>简单</strong> ：OLLAMA 提供简单的设置过程。您无需拥有机器学习博士学位即可启动和运行它。</li>
<li><strong>成本效益</strong> ：在本地运行模型意味着您无需支付云成本。您的钱包会感谢您。</li>
<li><strong>隐私</strong> ：使用 OLLAMA，所有数据处理都在您的本地机器上进行。这对于用户隐私来说是一个巨大的胜利。</li>
<li><strong>多功能性</strong> ：OLLAMA 不只是为 Python 爱好者准备的。它的灵活性使其可以用于各种应用程序，包括 Web 开发。</li>
</ul>
<br>
<h3 id="12-安装ollama">1.2 安装ollama</h3>
<p>点击前往网站 <a href="https://ollama.com/">https://ollama.com/</a> ，下载ollama软件，支持win、Mac、linux</p>
<p><img loading="lazy" src="img/03-ollama-gui.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="二ollama操作">二、Ollama操作</h2>
<h3 id="21-选择模型">2.1 选择模型</h3>
<p>ollama软件目前支持多种大模型， 如阿里的（<em><strong>qwen2.5</strong></em>）、meta的(llama3.3) 等。目前ollama最流行的模型，是国产开源大模型 <em><strong>deepseek r1</strong></em>。本文将安装<em><strong>qwen2.5:0.5b</strong></em>、 <em><strong>qwen2.5:1.5b</strong></em>、 <em><strong>qwen2.5:3b</strong></em>、 <em><strong>qwen2.5:7b</strong></em>、 <em><strong>deepseek-r1:1.5b</strong></em>、<em><strong>deepseek-r1:7b</strong></em>。 并对模型的速度、内容质量进行对比。</p>
<p><img loading="lazy" src="img/04-ollama-model.png" alt=""  />
</p>
<br>
<p><em><strong>DeepSeek-R1</strong></em> 在后训练阶段大规模使用了强化学习技术，在仅有极少标注数据的情况下，极大提升了模型推理能力。<strong>在数学、代码、自然语言推理等任务上，性能比肩 OpenAI o1 正式版</strong>。</p>
<p><img loading="lazy" src="img/01-deepseekr1-performance.png" alt=""  />
</p>
<br>
<h3 id="22-安装模型">2.2 安装模型</h3>
<p><strong>一般b前面的数字越小， 运行模型对电脑性能的要求越低</strong>。</p>
<p><img loading="lazy" src="img/05-deepseek-r1.png" alt=""  />
</p>
<p><img loading="lazy" src="img/05-qwen2.5.png" alt=""  />
</p>
<br>
<p>打开电脑命令行cmd(mac是terminal),  网络是连网状态，执行模型下载(安装)命令</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">ollama run deepseek-r1:1.5b
ollama run deepseek-r1:7b
ollama run qwen2.5:0.5b
ollama run qwen2.5:1.5b
ollama run qwen2.5:3b
ollama run qwen2.5:7b
</code></pre></div><br>
<h3 id="23-查看已安装模型">2.3 查看已安装模型</h3>
<p>在电脑命令行cmd(mac是terminal),  执行命令</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">ollama list
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">Last login: Tue Sep 24 19:26:46 on ttys000
da@deng ~ % ollama list
NAME                       ID              SIZE      MODIFIED        
qwen2.5:0.5b               a8b0c5157701    397 MB    15 minutes ago 
qwen2.5:1.5b               65ec06548149    986 MB    18 minutes ago  
qwen2.5:3b                 357c53fb659c    1.9 GB    12 minutes ago 
qwen2.5:7b                 845dbda0ea48    4.7 GB    21 seconds ago       
deepseek-r1:1.5b           a42b25d8c10a    1.1 GB    48 minutes ago    
deepseek-r1:7b             0a8c26691023    4.7 GB    50 minutes ago    
nomic-embed-text:latest    0a109f422b47    274 MB    9 months ago 
da@deng ~ % 
</code></pre></div><p>可以看到，列表中有 <em><strong>deepseek-r1:1.5b</strong></em> ， 说明在大邓的电脑中， 已经成功安装了 <em><strong>deepseek-r1:1.5b</strong></em> 。</p>
<br>
<h3 id="24-移除模型">2.4 移除模型</h3>
<p>使用 <code>ollama rm 模型名称</code> 移除已安装的某模型。 假设要移除 <em><strong>deepseek-r1:8b</strong></em>， 在电脑命令行cmd(mac是terminal),  执行移除命令</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">ollama</span> <span class="n">rm</span> <span class="n">deepseek</span><span class="o">-</span><span class="n">r1</span><span class="p">:</span><span class="mi">8</span><span class="n">b</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">deleted &#39;deepseek-r1:8b&#39;
</code></pre></div><br>
<h3 id="25-启动ollama服务">2.5 启动ollama服务</h3>
<p>在电脑中找到 ollama软件的图标， 双击打开即可开启 Ollama 服务。</p>
<p>如果觉得点击启动太麻烦，也可使用命令行操作， 打开电脑命令行cmd(mac是terminal), 执行</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">ollama serve
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">2025/02/07 16:00:18 routes.go:1259: INFO server config env=&#34;map[HTTPS_PROXY: HTTP_PROXY: NO_PROXY: OLLAMA_DEBUG:false OLLAMA_FLASH_ATTENTION:false OLLAMA_GPU_OVERHEAD:0 OLLAMA_HOST:http://127.0.0.1:11434 OLLAMA_KEEP_ALIVE:5m0s OLLAMA_KV_CACHE_TYPE: OLLAMA_LLM_LIBRARY: OLLAMA_LOAD_TIMEOUT:5m0s OLLAMA_MAX_LOADED_MODELS:0 OLLAMA_MAX_QUEUE:512 OLLAMA_MODELS:/Users/deng/.ollama/models OLLAMA_MULTIUSER_CACHE:false OLLAMA_NOHISTORY:false OLLAMA_NOPRUNE:false OLLAMA_NUM_PARALLEL:0 OLLAMA_ORIGINS:[http://localhost https://localhost http://localhost:* https://localhost:* http://127.0.0.1 https://127.0.0.1 http://127.0.0.1:* https://127.0.0.1:* http://0.0.0.0 https://0.0.0.0 http://0.0.0.0:* https://0.0.0.0:* app://* file://* tauri://* vscode-webview://*] OLLAMA_SCHED_SPREAD:false http_proxy: https_proxy: no_proxy:]&#34;
time=2025-02-07T16:00:18.551+08:00 level=INFO source=images.go:757 msg=&#34;total blobs: 11&#34;
time=2025-02-07T16:00:18.551+08:00 level=INFO source=images.go:764 msg=&#34;total unused blobs removed: 0&#34;
[GIN-debug] [WARNING] Creating an Engine instance with the Logger and Recovery middleware already attached.

[GIN-debug] [WARNING] Running in &#34;debug&#34; mode. Switch to &#34;release&#34; mode in production.
 - using env:	export GIN_MODE=release
 - using code:	gin.SetMode(gin.ReleaseMode)
er.(*Server).GenerateRoutes.func1 (5 handlers)
......
time=2025-02-07T16:00:18.553+08:00 level=INFO source=routes.go:1339 msg=&#34;Dynamic LLM libraries&#34; runners=[metal]
time=2025-02-07T16:00:18.577+08:00 level=INFO source=types.go:131 msg=&#34;inference compute&#34; id=0 library=metal variant=&#34;&#34; compute=&#34;&#34; driver=0.0 name=&#34;&#34; total=&#34;72.0 GiB&#34; available=&#34;72.0 GiB&#34;
</code></pre></div><p>cmd(mac是terminal)看到如上的信息，说明命令行本地ollama服务已开启。</p>
<br>
<h2 id="三在python中调用ollama中大模型">三、在Python中调用Ollama中大模型</h2>
<p>在Python中， 有很多第三方库，如langchain、langgraph、ollama， 都能调用Ollama内的模型。 这里以ollama库为例，</p>
<h3 id="31-启动ollama服务">3.1 启动Ollama服务</h3>
<p>在命令行<em><strong>cmd</strong></em> (mac对应terminal) 中启动本地服务。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">ollama</span> <span class="n">serve</span>
</code></pre></div><br>
<h3 id="32-安装">3.2 安装</h3>
<p>打开电脑命令行 <em><strong>cmd</strong></em> (mac是terminal),  网络是连网状态，执行安装命令</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">pip3 install ollama
#pip3 install ollama==0.2.1
</code></pre></div><br>
<h3 id="33-实验">3.3 实验</h3>
<p><em><strong>假设你是X先生的私人助理，负责X先生的形成安排。X先生一周后将去哈尔滨旅游，帮X先生设计一个哈尔滨一日游形成安排</strong></em>。</p>
<h4 id="331-qwen2515b">3.3.1 qwen2.5:1.5b</h4>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#%%time #单次运行时间</span>
<span class="c1">#%%timeit #多次运行，求得平均运行时间</span>

<span class="kn">import</span> <span class="nn">ollama</span>
<span class="c1">#大邓的ollama版本为0.2.1</span>


<span class="n">content</span> <span class="o">=</span> <span class="s2">&#34;你是X先生的私人助理，负责X先生的形成安排。X先生一周后将去哈尔滨旅游，帮X先生设计一个哈尔滨一日游形成安排。&#34;</span>
<span class="n">response</span> <span class="o">=</span> <span class="n">ollama</span><span class="o">.</span><span class="n">chat</span><span class="p">(</span><span class="n">model</span> <span class="o">=</span> <span class="s1">&#39;qwen2:7b&#39;</span><span class="p">,</span>   <span class="c1">#选择模型</span>
                       <span class="n">messages</span> <span class="o">=</span> <span class="p">[{</span><span class="s1">&#39;role&#39;</span><span class="p">:</span> <span class="s1">&#39;user&#39;</span><span class="p">,</span> <span class="s1">&#39;content&#39;</span><span class="p">:</span> <span class="n">content</span><span class="p">}])</span>


<span class="c1">#content2 = &#34;X先生一周后将去哈尔滨旅游，帮X先生设计一个哈尔滨一日游形成安排。&#34;</span>
<span class="c1">#response = ollama.chat(model = &#39;qwen2:7b&#39;,  #选择模型</span>
<span class="c1">#                       messages = [</span>
<span class="c1">#                         {&#39;role&#39;: &#39;system&#39;, &#39;content&#39;: &#34;你是X先生的私人助理，负责X先生的形成安排。&#34;},</span>
<span class="c1">#                         {&#39;role&#39;: &#39;user&#39;, &#39;content&#39;: content2}</span>
<span class="c1">#                       ]</span>
<span class="c1">#                      )</span>


<span class="n">result</span> <span class="o">=</span> <span class="n">response</span><span class="p">[</span><span class="s1">&#39;message&#39;</span><span class="p">][</span><span class="s1">&#39;content&#39;</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">我理解您是Qwen，但我作为AI模型，并没有实际经历、记忆或能力来为任何人策划旅行安排。不过，我可以提供一些建议性的建议帮助您设计这个行程。

1. 交通：根据您的具体位置和出发时间，您可以考虑哈尔滨的机场（哈尔滨太平国际机场）或者火车站的便利性。
2. 确定活动：哈尔滨是冰城，所以可以尝试观看滑冰、滑雪或雪地摩托等冰上活动。另外，您还可以参加冰雪节，体验东北特色的冰灯展览。当然，如果您喜欢风景的话，还可以在松花江畔散步，欣赏沿岸的风景。
3. 餐饮：哈尔滨的特色美食包括狗不理包子和东北锅盔。此外，您可以品尝到鲜美的冻梨和各种风味小吃。 
4. 购物：逛一逛哈啤街可以买到冰城特产和纪念品。

以上只是建议性的行程安排，您的实际旅行需要根据您的兴趣爱好、身体状况以及时间来确定。希望这些建议对您有所帮助！
好的，我将根据您的需求为您制定一份哈尔滨一日游的行程方案：

### 第1天：抵达哈尔滨

- **上午8:00**：从上海或您所在的城市出发前往哈尔滨国际机场。
- **下午2:30**：抵达哈尔滨，下飞机后换乘高速动车（约4小时）到达哈尔滨南站。
- **下午3:30**：到机场附近的酒店办理入住手续，稍作休息准备。

### 第2天：哈尔滨之旅

#### 上午：城市观光与探索

- **10:00**：前往中央大街。这里以其独特的建筑风格和文化氛围吸引着众多游客。
- **上午11:30**：参观东北虎林园，了解中国最北部的野生动物保护情况。
- **下午2:00**：漫步于圣索菲亚教堂附近的小巷，体验哈尔滨的老城区生活。
- **下午4:00**：在哈啤博物馆内探索哈尔滨啤酒的历史和制作工艺。

#### 下午：文化与美食

- **15:30**：参观哈尔滨冰雕艺术展览，欣赏世界级的冰雪艺术品。
- **下午6:00**：返回市区，享用正宗的东北大餐，比如狗不理包子、哈尔滨锅包肉等特色小吃。

#### 晚上：夜游与体验

- **18:00**：乘坐雪乡索道上山，探索世界最大的冰雪雕塑群。
- **晚上20:30**：回到市区，品尝地道的哈尔滨美食和市井风味小摊。
- **21:30**：结束今天的行程。

### 第3天：返程

#### 晚间：准备离店

- **15:00**：在酒店享用晚餐，并安排打包食物或行李。
- **16:30**：开始收拾行囊，准备出发离开哈尔滨。可能需要提前半小时抵达机场。

请注意，这个方案是基于一般情况下的旅游规划，实际行程可能会根据您的偏好和具体交通时间有所调整。希望这份行程能为您提供一个美好的哈尔滨旅行体验！
</code></pre></div><br>
<h4 id="332-deepseek-r115b">3.3.2 deepseek r1:1.5b</h4>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#%%time #单次运行时间</span>
<span class="c1">#%%timeit #多次运行，求得平均运行时间</span>

<span class="kn">import</span> <span class="nn">ollama</span>
<span class="c1">#大邓的ollama版本为0.2.1</span>

<span class="n">content</span> <span class="o">=</span> <span class="s2">&#34;你是X先生的私人助理，负责X先生的形成安排。X先生一周后将去哈尔滨旅游，帮X先生设计一个哈尔滨一日游形成安排。&#34;</span>
<span class="n">response</span> <span class="o">=</span> <span class="n">ollama</span><span class="o">.</span><span class="n">chat</span><span class="p">(</span><span class="n">model</span> <span class="o">=</span> <span class="s1">&#39;deepseek-r1:1.5b&#39;</span><span class="p">,</span>   <span class="c1">#选择模型</span>
                       <span class="n">messages</span> <span class="o">=</span> <span class="p">[{</span><span class="s1">&#39;role&#39;</span><span class="p">:</span> <span class="s1">&#39;user&#39;</span><span class="p">,</span> <span class="s1">&#39;content&#39;</span><span class="p">:</span> <span class="n">content</span><span class="p">}])</span>


<span class="c1">#content2 = &#34;X先生一周后将去哈尔滨旅游，帮X先生设计一个哈尔滨一日游形成安排。&#34;</span>
<span class="c1">#response = ollama.chat(model = &#39;deepseek-r1:1.5b&#39;,  #选择模型</span>
<span class="c1">#                       messages = [</span>
<span class="c1">#                         {&#39;role&#39;: &#39;system&#39;, &#39;content&#39;: &#34;你是X先生的私人助理，负责X先生的形成安排。&#34;},</span>
<span class="c1">#                         {&#39;role&#39;: &#39;user&#39;, &#39;content&#39;: content2}</span>
<span class="c1">#                       ]</span>
<span class="c1">#                      )</span>


<span class="n">result</span> <span class="o">=</span> <span class="n">response</span><span class="p">[</span><span class="s1">&#39;message&#39;</span><span class="p">][</span><span class="s1">&#39;content&#39;</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">&lt;think&gt;
好的，用户需要我设计哈尔滨一日游的安排。首先，我得考虑目标客户的需求是什么。是单日游还是多日？用户可能是一个游客，想要既能体验哈尔滨的魅力，又不想太累，所以时间控制在两三个小时比较合适。

接下来，我要确定 Polar Express作为活动的主要交通工具，因为它不仅风景优美，还能带来刺激感，比如乘坐 escalator，这样可以让游客感觉有 motion。然后，其他活动要安排得轻松愉快，比如游船、冰灯 etc.，这些都能让整个行程看起来充实而有变化。

时间安排方面，从12点到下午三点左右比较合适，因为中午的户外活动和下午的购物区可以好好玩一玩。每个时间段都要留足够的时间进行活动，确保行程紧凑且不累赘。

另外，还要注意注意事项，比如天气、门票等，特别是如果用户是儿童的话，得确保安全和适合的主题。最后，提醒用户根据自己的需求调整时间和内容，让行程更加个性化和有创意。
&lt;/think&gt;

嗯，你已经让我设计了一个详细的哈尔滨一日游安排了！让我们一步步来思考一下：

### 1. 时间框架
假设你计划在上午去游览景点，下午去夜游，晚上进行购物和品尝美食。

### 2. 活动安排建议：
   - **早上： Polar Express 呼吸机 ride（快速穿梭公园内）**
   - 每人乘坐 Polar Express前往公园，体验快速移动的刺激。
   
- **中午： 游船游湖**
   - 晚上11点前坐 boat 温泉，感受 Polar Bear 和 fish 的美丽。

- **下午： 傍晚： ice cream 环岛游（Polar Express 区）**
   - 跑在环城的路上购买冰棒和冰淇淋，享受夜景。

- **晚上： 餐饮**
   - 中午去餐馆点餐，晚餐去夜市品尝特色小吃。

### 3. 注意事项：
- 如果是儿童游玩，记得注意安全，选择容易摔倒的景点。
- 建议提前预订 Polar Express 的票，避免排队。

希望这个安排能满足你的需求！如果你有其他具体需求或偏好，请告诉我，我可以再调整哦！
</code></pre></div><br>
<br>
<h2 id="四性能评价">四、性能评价</h2>
<p><em><strong>qwen2.5</strong></em> 和 <em><strong>deepseek r1</strong></em> 都能很好的完成了旅游规划的任务。 运行速度方面， <em><strong>qwen2.5</strong></em> 远快于 <em><strong>deepseek r1</strong></em> 。本次实验中每个代码均运行7次，最终求得平均耗时</p>
<ul>
<li><em><strong>qwen2.5:0.5b</strong></em> 平均耗时 <em><strong>1.43 s ± 746 ms</strong></em></li>
<li><em><strong>qwen2.5:1.5b</strong></em> 平均耗时 <em><strong>2.5 s ± 1.18 s</strong></em></li>
<li><em><strong>qwen2.5: 3b</strong></em> 平均耗时 <em><strong>4.76 s ± 1.77 s</strong></em></li>
<li><em><strong>qwen2.5: 7b</strong></em> 平均耗时 <em><strong>8.58 s ± 534 ms</strong></em></li>
<li><em><strong>deepseek r1:1.5b</strong></em> 平均耗时 <em><strong>8.71 s ± 1.66 s</strong></em></li>
<li><em><strong>deepseek r1:7b</strong></em> 平均耗时 <em><strong>21 s ± 4.39 s</strong></em></li>
</ul>
<p>如果追求速度， 同样体量的模型的(以1.5b为例)，目前首选 <em><strong>qwen2.5</strong></em> （qwen2.5:1.5b）。</p>
<p>各位可以结合自己任务， 电脑性能， 速度等不同需求， 选择对自己最合适的模型。</p>
<br>
<br>
<h2 id="相关内容">相关内容</h2>
<ul>
<li><a href="https://textdata.cn/blog/2025-02-14-using-online-large-model-api-to-transform-text-data-into-structured-data/"><strong>教程 | 使用大模型将文本数据转化为结构化数据</strong></a></li>
<li><a href="https://textdata.cn/blog/2024-08-06-using-the-ollama-local-large-model-to-predict-the-sentiment-category-of-online-comments/"><strong>实验 | 使用本地大模型预测在线评论情感类别和分值</strong></a></li>
<li><a href="https://textdata.cn/blog/2024-08-07-structured-outputs-with-ollama/"><strong>实验 | 如何使 Ollama 结构化输出 JSON 样式的结果</strong></a></li>
<li><a href="https://textdata.cn/blog/2024-08-03-literature-document-parsing-using-large-language-models-with-code/"><strong>实验 | 使用本地大模型从论文PDF中提取结构化信息</strong></a></li>
<li><a href="https://textdata.cn/blog/2024-04-27-cntext2x-usage-tutorial/"><strong>推荐 | 文本分析库cntext2.x使用手册</strong></a></li>
<li><a href="https://textdata.cn/blog/2024-06-14-using-large-language-model-to-extract-structure-data-from-raw-text/"><strong>实验 | 使用本地大模型从文本中提取结构化信息</strong></a></li>
<li><a href="https://textdata.cn/blog/2024-07-10-using-large-language-model-to-build-diy-dictionary/">实验 | 使用Ollama本地大模型DIY制作单词书教案PDF</a></li>
<li><a href="https://textdata.cn/blog/2024-08-05-create-a-blog-writer-multi-agent-system-using-crewai-and-ollama/">实验 | 使用 Crewai 和 Ollama 构建智能体(AI Agent)帮我撰写博客文章</a></li>
</ul>
<br>
<br>
<h2 id="精选内容">精选内容</h2>
<ul>
<li><a href="https://textdata.cn/blog/datasets_available_for_management_science/">LIST | 可供社科(经管)领域使用的数据集汇总</a></li>
<li><a href="https://textdata.cn/blog/the_text_analysis_list_about_ms/">LIST | 社科(经管)数据挖掘文献资料汇总</a></li>
<li><a href="https://textdata.cn/blog/2024-06-16-scrapegraph-ai/">网络爬虫 | 使用scrapegraph-ai(大模型方案)自动采集网页数据</a></li>
<li><a href="https://textdata.cn/blog/2024-04-27-cntext2x-usage-tutorial/">推荐 | 文本分析库cntext2.x使用手册</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
<li><a href="https://textdata.cn/blog/2025-02-07-using-large-language-model-to-extract-structure-data-from-raw-text/">实验 | 使用本地大模型从文本中提取结构化信息</a>7
<br>
<br></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>实验 | 使用 Crewai 和 Ollama 构建智能体(AI Agent)帮我撰写博客文章</title>
      <link>https://textdata.cn/blog/2024-08-05-create-a-blog-writer-multi-agent-system-using-crewai-and-ollama/</link>
      <pubDate>Mon, 05 Aug 2024 00:00:00 +0000</pubDate>
      
      <guid>/blog/2024-08-05-create-a-blog-writer-multi-agent-system-using-crewai-and-ollama/</guid>
      <description>大邓是一个技术博主，运营着公众号，每天要消耗大量的时间进行选题、创作、编辑。随着LLM的流行， 能否让LLM替我进行选题、创作、编辑，从此进入躺平式人生新阶段。  这不是做梦， 使用软件Ollama、Python的CrewAI库，设计好智能体(AI Agent)，就能实现大邓的白日梦。In technical terms an AI Agent is a software entity designed to perform tasks autonomously or semi-autonomously on behalf of a user or another program. These agents leverage artificial intelligence to make decisions, take actions, and interact with their environment or other systems.</description>
      <content:encoded><![CDATA[<p>大邓是一个技术博主，运营着公众号，每天要消耗大量的时间进行选题、创作、编辑。随着LLM的流行， 能否让LLM替我进行选题、创作、编辑，从此进入躺平式人生新阶段。  这不是做梦， 使用软件Ollama、Python的CrewAI库，设计好智能体(AI Agent)，就能实现大邓的白日梦。</p>
<br>
<p><img loading="lazy" src="img/01-multiagent-worflow.png" alt="Multiagent Workflow using CrewAI and Ollama"  />
</p>
<h2 id="一什么是智能体ai-agent">一、什么是智能体(AI Agent)?</h2>
<p>从技术角度来说，**智能体(AI Agent)**是一种软件实体，旨在代表用户或其他程序自主或半自主地执行任务。这些代理利用人工智能做出决策、采取行动并与环境或其他系统进行交互。智能体的主要特征有：</p>
<ol>
<li><strong>自治</strong>：智能体无需人工干预即可运行。一旦被赋予目标，它们就可以独立执行任务。</li>
<li><strong>决策</strong>：智能体使用算法、规则和人工智能模型， 根据自己的感知和目标做出决策。这包括评估不同的选择并选择最佳行动方案。</li>
<li><strong>学习</strong>：许多智能体采用机器学习技术来提高其性能。它们可以从过去的经验中学习并适应新情况。</li>
<li><strong>交互</strong>：智能体可以与用户、其他智能体或系统进行通信和协作。这种交互可能涉及自然语言处理、发送和接收数据或执行协调任务。</li>
<li><strong>专业化</strong>：智能体可以专门用于特定任务或领域。例如，某些智能体可能专为网页浏览而设计，而其他智能体则可能处理数据库交互、执行复杂计算或生成图像。</li>
<li><strong>目标导向</strong>：智能体通常被设定有特定的目标或目的。它们通过一系列动作和决策来实现这些目标。</li>
</ol>
<p><img loading="lazy" src="img/landscape-latest.png" alt=""  />
</p>
<p>总之，智能体是强大的工具，可以自动化和增强广泛的活动，从简单的重复任务到复杂的问题解决场景，这使得它们在各种应用和行业中具有无价的价值。</p>
<p>想象一下，将上述所有概念整合在一起，共同朝着预先确定的目标努力，实现预期结果。这些任务可以按顺序或分层流程执行，所有智能体都像一个协调的团队一样工作。这种强大的协作可以彻底改变我们处理复杂问题的方式，使流程更高效，结果更有效。这就是 <em><strong>CrewAI框架</strong></em>发挥作用的地方。</p>
<p><br><br></p>
<h2 id="二ollama介绍配置">二、Ollama介绍&amp;配置</h2>
<p><a href="https://textdata.cn/blog/2024-06-14-how-to-download-large-language-model-with-ollama/">教程 | 如何使用 Ollama 下载 &amp; 使用本地大语言模型</a></p>
<p><a href="https://ollama.ai/"><strong>Ollama</strong></a>是一款开源应用程序，可让您使用 MacOS、Linux 和 Windows 上的命令行界面在本地运行、创建和共享大型语言模型。</p>
<p>Ollama 可以直接从其库中访问各种 LLM，只需一个命令即可下载。下载后，只需执行一个命令即可开始使用。这对于工作量围绕终端窗口的用户非常有帮助。如果他们被困在某个地方，他们可以在不切换到另一个浏览器窗口的情况下获得答案。</p>
<br>
<h3 id="21-特点和优点">2.1 特点和优点</h3>
<p>这就是为什么 OLLAMA 是您的工具包中必备的工具：</p>
<ul>
<li><strong>简单</strong> ：OLLAMA 提供简单的设置过程。您无需拥有机器学习博士学位即可启动和运行它。</li>
<li><strong>成本效益</strong> ：在本地运行模型意味着您无需支付云成本。您的钱包会感谢您。</li>
<li><strong>隐私</strong> ：使用 OLLAMA，所有数据处理都在您的本地机器上进行。这对于用户隐私来说是一个巨大的胜利。</li>
<li><strong>多功能性</strong> ：OLLAMA 不只是为 Python 爱好者准备的。它的灵活性使其可以用于各种应用程序，包括 Web 开发。</li>
</ul>
<br>
<h3 id="22-安装ollama">2.2 安装ollama</h3>
<p>点击前往网站 <a href="https://ollama.com/">https://ollama.com/</a> ，下载ollama软件，支持win、Mac、linux</p>
<p><img loading="lazy" src="img/03-ollama-gui.png" alt=""  />
</p>
<br>
<h3 id="23-下载llm模型">2.3 下载LLM模型</h3>
<p>默认情况下，Openai Models 在 CrewAI 中用作 llm。有经费、有网络、不担心数据泄露等条件下,  力求达到最佳性能，可考虑使用 GPT-4 或 OpenAI 稍便宜的 GPT-3.5。</p>
<p>但本文是要 <strong>本地部署</strong>， 因此我们将使用 Meta Llama 3，这是迄今为止功能最强大的公开 LLM。Meta Llama 3 是 Meta Inc. 开发的模型系列，是最新推出的模型，具有 8B 和 70B 两种参数大小（预训练或指令调整）。Llama 3 指令调整模型针对对话/聊天用例进行了微调和优化，并且在常见基准测试中胜过许多可用的开源聊天模型。</p>
<p><img loading="lazy" src="img/04-llama3-performance.png" alt=""  />
</p>
<p><img loading="lazy" src="img/05-llama3-performance.png" alt=""  />
</p>
<br>
<p>打开Ollama模型页面 <em><strong><a href="https://ollama.com/library">https://ollama.com/library</a></strong></em>， 第一个就是 Metal 近期发布的 LLama3.1 模型。</p>
<p><img loading="lazy" src="img/06-ollama-model.png" alt=""  />
</p>
<br>
<p>以llama3为例，根据自己电脑显存性能， 选择适宜的版本。如果不知道选什么，那就试着安装，不合适不能用再删除即可。</p>
<p><img loading="lazy" src="img/06-ollama-llama3.png" alt=""  />
</p>
<br>
<p>打开电脑命令行cmd(mac是terminal),  网络是连网状态，执行模型下载(安装)命令</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">ollama pull llama3.1:8b
</code></pre></div><p>等待 <strong>llama3.1:8b</strong> 下载完成。</p>
<br>
<h3 id="23-启动ollama服务">2.3 启动ollama服务</h3>
<p>ollama服务有两种启动方式，即鼠标启动ollama服务 和 命令行启动ollama服务 。<br></p>
<h4 id="231-鼠标启动ollama服务">2.3.1 鼠标启动ollama服务</h4>
<p>在电脑中找到ollama软件，双击打开，就开启了ollama本地服务。</p>
<br>
<h4 id="232-命令行启动ollama服务">2.3.2 命令行启动ollama服务</h4>
<p>在Python中调用本地ollama服务，需要先启动本地ollama服务， 打开电脑命令行cmd(mac是terminal), 执行</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">ollama serve
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">2024/06/14 14:52:24 routes.go:1011: INFO server config env=&#34;map[OLLAMA_DEBUG:false OLLAMA_FLASH_ATTENTION:false OLLAMA_HOST:http://127.0.0.1:11434 OLLAMA_KEEP_ALIVE: OLLAMA_LLM_LIBRARY: OLLAMA_MAX_LOADED_MODELS:1 OLLAMA_MAX_QUEUE:512 OLLAMA_MAX_VRAM:0 OLLAMA_MODELS:/Users/deng/.ollama/models OLLAMA_NOHISTORY:false OLLAMA_NOPRUNE:false OLLAMA_NUM_PARALLEL:1 OLLAMA_ORIGINS:[http://localhost https://localhost http://localhost:* https://localhost:* http://127.0.0.1 https://127.0.0.1 http://127.0.0.1:* https://127.0.0.1:* http://0.0.0.0 https://0.0.0.0 http://0.0.0.0:* https://0.0.0.0:* app://* file://* tauri://*] OLLAMA_RUNNERS_DIR: OLLAMA_TMPDIR:]&#34;
time=2024-06-14T14:52:24.742+08:00 level=INFO source=images.go:725 msg=&#34;total blobs: 18&#34;
time=2024-06-14T14:52:24.742+08:00 level=INFO source=images.go:732 msg=&#34;total unused blobs removed: 0&#34;
time=2024-06-14T14:52:24.743+08:00 level=INFO source=routes.go:1057 msg=&#34;Listening on 127.0.0.1:11434 (version 0.1.44)&#34;
time=2024-06-14T14:52:24.744+08:00 level=INFO source=payload.go:30 msg=&#34;extracting embedded files&#34; dir=/var/folders/y0/4gqxky0s2t94x1c1qhlwr6100000gn/T/ollama4239159529/runners
time=2024-06-14T14:52:24.772+08:00 level=INFO source=payload.go:44 msg=&#34;Dynamic LLM libraries [metal]&#34;
time=2024-06-14T14:52:24.796+08:00 level=INFO source=types.go:71 msg=&#34;inference compute&#34; id=0 library=metal compute=&#34;&#34; driver=0.0 name=&#34;&#34; total=&#34;72.0 GiB&#34; available=&#34;72.0 GiB&#34;
</code></pre></div><p>cmd(mac是terminal)看到如上的信息，说明本地ollama服务已开启。</p>
<p><br><br></p>
<h2 id="三crewai框架介绍">三、CrewAI框架介绍</h2>
<p>CrewAi 是一个用于协调角色扮演、自主 AI 代理的尖端框架。通过促进协作智能，CrewAI 使代理能够无缝协作，解决复杂的任务。</p>
<br>
<h3 id="31-安装crew">3.1 安装crew</h3>
<p>打开电脑命令行cmd(mac是terminal),  网络是连网状态，执行安装命令</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">pip3 install crewai
pip3 install langchain_openai
</code></pre></div><br>
<h3 id="32-crewai核心概念">3.2 CrewAI核心概念</h3>
<ol>
<li><em><strong>智能体(Agents)</strong></em>：这些是经过编程的独立单元，用于执行任务、做出决策和与其他代理进行通信。它们可以使用的 <em><strong>工具Tools</strong></em> 可以是简单的搜索功能，也可以是涉及其他链、API 等的复杂集成。</li>
<li><em><strong>任务(Tasks)</strong></em>：任务是智能体需要完成的任务或工作。它们可以包含其他信息，例如哪个代理应该执行该任务以及它们可能需要哪些工具。</li>
<li><em><strong>团队(Crew)</strong></em>  一个团队是由一群智能体组成的，每个 <em><strong>智能体(Agent)</strong></em> 都有特定的角色，他们齐心协力实现共同目标。组建团队的过程包括召集代理、定义他们的任务以及建立任务执行顺序。</li>
</ol>
<p><img loading="lazy" src="img/02-crewai-system.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="四实验代码">四、实验代码</h2>
<p>大邓是一个技术博主，运营着公众号，每天要消耗大量的时间进行选题、创作、编辑。随着LLM的流行， 能否让LLM替我进行选题、创作、编辑，从此进入躺平式人生新阶段。在实验章节， 代码内容将分为</p>
<ul>
<li>启动ollama服务</li>
<li>调用llm</li>
<li>设置agent</li>
<li>设置task</li>
<li>组装成crew</li>
<li>最终运行</li>
</ul>
<h3 id="41-启动服务">4.1 启动服务</h3>
<p>在 <em><strong>cmd</strong></em> 中使用命令 <em><strong>ollama serve</strong></em> 启动本地服务。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">ollama</span> <span class="n">serve</span>
</code></pre></div><br>
<h3 id="42-调用llm">4.2 调用LLM</h3>
<p>在Python中调用开启的ollama服务， 为crewai调用llm做准备。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">langchain_openai</span> <span class="kn">import</span> <span class="n">ChatOpenAI</span>
<span class="kn">import</span> <span class="nn">os</span>

<span class="c1">#将ollama的api转化为OPENAI式的api，方便crewai调用</span>
<span class="c1">#设置系统环境变量OPENAI_API_BASE和OPENAI_API_KEY</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&#34;OPENAI_API_BASE&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&#34;http://localhost:11434/v1&#34;</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&#34;OPENAI_API_KEY&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&#34;NA&#34;</span>

<span class="n">llama_model</span> <span class="o">=</span> <span class="n">ChatOpenAI</span><span class="p">(</span><span class="n">model</span> <span class="o">=</span> <span class="s2">&#34;llama3.1:8b&#34;</span><span class="p">)</span>
</code></pre></div><br>
<h3 id="43-设置agent">4.3 设置Agent</h3>
<p>大邓运营的公众号的日常，一个人身兼数个职位。 大致拆分成三个员工（智能体）</p>
<ul>
<li>内容策划专员</li>
<li>内容创作专员</li>
<li>内容编辑专员</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">crewai</span> <span class="kn">import</span> <span class="n">Agent</span>

<span class="n">planner</span> <span class="o">=</span> <span class="n">Agent</span><span class="p">(</span>
    <span class="n">role</span> <span class="o">=</span> <span class="s2">&#34;内容策划专员&#34;</span><span class="p">,</span>
    <span class="n">goal</span> <span class="o">=</span> <span class="s2">&#34;策划有关</span><span class="si">{topic}</span><span class="s2">的引人入胜且事实准确的内容&#34;</span><span class="p">,</span>
    <span class="n">backstory</span> <span class="o">=</span> <span class="p">(</span>
        <span class="s2">&#34;您是一名内容策划专员，正在计划撰写一篇主题为“</span><span class="si">{topic}</span><span class="s2">”的博客文章， &#34;</span>
        <span class="s2">&#34;文章将发布在 &#39;https://medium.com/&#39;。&#34;</span>
        <span class="s2">&#34;您收集的信息可帮助受众了解某些内容,使受众能因此做出明智的决定。&#34;</span>
        <span class="s2">&#34;您必须准备一份详细的大纲，博客文章中应包含的相关主题和子主题。&#34;</span>
        <span class="s2">&#34;您的工作是内容创作专员撰写此主题文章的基础。&#34;</span>
        <span class="s2">&#34;工作语言是中文。&#34;</span>
    <span class="p">),</span>
    <span class="n">llm</span> <span class="o">=</span> <span class="n">llama_model</span><span class="p">,</span>
    <span class="n">allow_delegation</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">verbose</span> <span class="o">=</span> <span class="kc">True</span>
<span class="p">)</span>


<span class="n">writer</span> <span class="o">=</span> <span class="n">Agent</span><span class="p">(</span>
    <span class="n">role</span> <span class="o">=</span> <span class="s2">&#34;内容创作专员&#34;</span><span class="p">,</span>
    <span class="n">goal</span> <span class="o">=</span> <span class="s2">&#34;撰写主题</span><span class="si">{topic}</span><span class="s2">的评论文章，要深刻且事实准确&#34;</span><span class="p">,</span>
    <span class="n">backstory</span> <span class="o">=</span> <span class="p">(</span>
        <span class="s2">&#34;您是一名内容编辑专员，正在撰写一篇主题 “</span><span class="si">{topic}</span><span class="s2">” 的新观点文章， &#34;</span>
        <span class="s2">&#34;文章将发表在 &#39;https://medium.com/&#39;。&#34;</span>
        <span class="s2">&#34;内容策划师提供了有关该主题的大纲和相关背景。&#34;</span>
        <span class="s2">&#34;您创作内容时，请遵循内容策划师提供的大纲为主要目标和方向。&#34;</span>
        <span class="s2">&#34;同时您将提供客观公正的见解，并使用内容策划师提供的信息支持您的见解。&#34;</span>
        <span class="s2">&#34;您在观点文章中承认您的陈述是意见，而不是客观陈述。&#34;</span>
        <span class="s2">&#34;工作语言是中文。&#34;</span>
    <span class="p">),</span>
    <span class="n">allow_delegation</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">llm</span> <span class="o">=</span> <span class="n">llama_model</span><span class="p">,</span>
    <span class="n">verbose</span> <span class="o">=</span> <span class="kc">True</span>
<span class="p">)</span>


<span class="n">editor</span> <span class="o">=</span> <span class="n">Agent</span><span class="p">(</span>
    <span class="n">role</span> <span class="o">=</span> <span class="s2">&#34;内容编辑专员&#34;</span><span class="p">,</span>
    <span class="n">goal</span> <span class="o">=</span> <span class="s2">&#34;编辑给定的博客文章，以符合网站 &#39;https://medium.com/&#39; 的写作风格&#34;</span><span class="p">,</span>
    <span class="n">backstory</span> <span class="o">=</span> <span class="p">(</span>
        <span class="s2">&#34;您是一名内容编辑专员，收到内容创作专员发来的博客文章。&#34;</span>
        <span class="s2">&#34;您的目标是审核博客文章，确保其符合新闻业最佳实践，&#34;</span>
        <span class="s2">&#34;在发表意见或主张时提供平衡的观点，并尽可能避免重大争议话题或意见。&#34;</span>
        <span class="s2">&#34;工作语言是中文。&#34;</span>
    <span class="p">),</span>
    <span class="n">llm</span> <span class="o">=</span> <span class="n">llama_model</span><span class="p">,</span>
    <span class="n">allow_delegation</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">verbose</span> <span class="o">=</span> <span class="kc">True</span>
<span class="p">)</span>
</code></pre></div><p>参数解读</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">crewai</span><span class="o">.</span><span class="n">Agent</span><span class="p">(</span><span class="n">role</span><span class="p">,</span> <span class="n">goal</span><span class="p">,</span> <span class="n">backstory</span><span class="p">,</span> <span class="n">llm</span><span class="p">,</span> <span class="n">tools</span><span class="p">,</span> <span class="n">function_calling_llm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">maxter</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span> <span class="n">max_execution_time</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">allow_delegation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">step_callback</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">cache</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">max_retry_limit</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</code></pre></div><ul>
<li><em><strong>role</strong></em>: 定义代理在团队中的职能。它决定了代理最适合执行的任务类型。</li>
<li><em><strong>goal</strong></em> : 代理希望实现的个体目标。它指导代理的决策过程。</li>
<li><em><strong>backstory</strong></em>：为代理的角色和目标提供背景，丰富互动和协作动力。</li>
<li><em><strong>llm</strong></em>：(可选)表示将运行代理的语言模型。它从<code>OPENAI_MODEL_NAME</code>环境变量中动态获取模型名称，如果未指定，则默认为 “gpt-4”。</li>
<li><em><strong>tools</strong></em>：(可选)代理可用于执行任务的功能或函数集。应为与代理的执行环境兼容的自定义类的实例。工具使用空列表的默认值进行初始化。</li>
<li><em><strong>function_calling_llm</strong></em>：（可选）指定处理此代理的工具调用的语言模型，如果已传递，则覆盖工作人员函数调用 LLM。默认值为 <code>None</code>。</li>
<li><em><strong>maxter</strong></em>：（可选）代理在被迫给出最佳答案之前可以执行的最大迭代次数。默认值为<code>25</code>。</li>
<li><em><strong>max_rpm</strong></em>：（可选）代理每分钟可以执行的最大请求数，以避免速率限制。它是可选的，可以不指定，默认值为<code>None</code>。</li>
<li><em><strong>max_execution_time</strong></em>：（可选）代理执行任务的最大执行时间。它是可选的，可以不指定，默认值为 <code>None</code>，表示没有最大执行时间</li>
<li><em><strong>verbose</strong></em>：（可选）将其设置为 <code>True</code>配置内部记录器以提供详细的执行日志，帮助调试和监控。默认值为<code>False</code>。</li>
<li><em><strong>allow_delegation</strong></em>： （可选）代理可以相互委派任务或问题，确保每项任务都由最合适的代理处理。默认值为<code>True</code>。</li>
<li><em><strong>step_callback</strong></em>： （可选）代理每执行一步后调用的函数。可用于记录代理的操作或执行其他操作。它将覆盖工作人员<code>step_callback</code>。默认值<code>None</code>。</li>
<li><em><strong>cache</strong></em>： （可选）指示代理是否应使用缓存来使用工具。默认值为<code>True</code></li>
</ul>
<br>
<h3 id="44-设置task">4.4 设置Task</h3>
<p>大邓三个智能体角色(内容策划专员、内容创作专员、内容策划专员)， 都各自有对应的 <em><strong>任务(plan、write、edit)</strong></em>。 这里需要设置每种任务，的工作任务(内容)、预期产出。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">crewai</span> <span class="kn">import</span> <span class="n">Task</span>

<span class="n">plan</span> <span class="o">=</span> <span class="n">Task</span><span class="p">(</span>
    <span class="n">description</span> <span class="o">=</span> <span class="p">(</span>
        <span class="s2">&#34;1. 优先考虑“</span><span class="si">{topic}</span><span class="s2">”的最新趋势、关键参与者和值得关注的新闻。</span><span class="se">\n</span><span class="s2">&#34;</span>
        <span class="s2">&#34;2. 确定目标受众，考虑他们的兴趣和痛点。</span><span class="se">\n</span><span class="s2">&#34;</span>
        <span class="s2">&#34;3. 制定详细的内容大纲，包括简介、要点和行动号召。</span><span class="se">\n</span><span class="s2">&#34;</span>
        <span class="s2">&#34;4. 包括 SEO 关键字和相关数据或来源。&#34;</span>
    <span class="p">),</span>
    <span class="n">expected_output</span> <span class="o">=</span> <span class="s2">&#34;一份全面的内容计划文档，其中包含大纲、受众分析、SEO 关键字和参考资源。&#34;</span><span class="p">,</span>
    <span class="n">agent</span> <span class="o">=</span> <span class="n">planner</span><span class="p">,</span>
<span class="p">)</span>


<span class="n">write</span> <span class="o">=</span> <span class="n">Task</span><span class="p">(</span>
    <span class="n">description</span> <span class="o">=</span> <span class="p">(</span>
        <span class="s2">&#34;1. 使用内容策划专员的内容策划，撰写一篇关于“</span><span class="si">{topic}</span><span class="s2">”的引人入胜的博客文章。</span><span class="se">\n</span><span class="s2">&#34;</span>
        <span class="s2">&#34;2. 自然地融入 SEO 关键词。</span><span class="se">\n</span><span class="s2">&#34;</span>
        <span class="s2">&#34;3. 章节/副标题以引人入胜的方式正确命名。</span><span class="se">\n</span><span class="s2">&#34;</span>
        <span class="s2">&#34;4. 确保文章结构合理，有引人入胜的介绍、有见地的正文和总结性结论。</span><span class="se">\n</span><span class="s2">&#34;</span>
        <span class="s2">&#34;5. 校对语法错误并与品牌调性保持一致。</span><span class="se">\n</span><span class="s2">&#34;</span>
    <span class="p">),</span>
    <span class="n">expected_output</span> <span class="o">=</span> <span class="s2">&#34;一篇写得很好的、准备发布的 Markdown 格式的博客文章，每个部分应该有 2 或 3 个段落。&#34;</span><span class="p">,</span>
    <span class="n">agent</span> <span class="o">=</span> <span class="n">writer</span><span class="p">,</span>
<span class="p">)</span>


<span class="n">edit</span> <span class="o">=</span> <span class="n">Task</span><span class="p">(</span>
    <span class="n">description</span> <span class="o">=</span> <span class="p">(</span>
        <span class="s2">&#34;校对给定的博客文章&#34;</span>
        <span class="s2">&#34;检查其语法错误并与品牌调性保持一致。&#34;</span>
    <span class="p">),</span>
    <span class="n">expected_output</span> <span class="o">=</span> <span class="s2">&#34;一篇写得很好的、准备发布的 Markdown 格式的博客文章，每个部分应该有 2 或 3 个段落。&#34;</span><span class="p">,</span>
    <span class="n">agent</span> <span class="o">=</span> <span class="n">editor</span>
<span class="p">)</span>

</code></pre></div><br>
<p>参数解读</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">crewai</span><span class="o">.</span><span class="n">Task</span><span class="p">(</span><span class="n">description</span><span class="p">,</span> <span class="n">agent</span><span class="p">,</span> <span class="n">expected_output</span><span class="p">,</span> <span class="n">tools</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">async_execution</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">output_json</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">output_pydantic</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">output_file</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">human_input</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</code></pre></div><ul>
<li><em><strong>description</strong></em>： 对任务内容的清晰、简洁的陈述。</li>
<li><em><strong>agent</strong></em> ：负责该任务的代理人，可直接指派或由机组人员流程指派。</li>
<li><em><strong>expected_output</strong></em> : 任务完成情况的详细描述。</li>
<li><em><strong>tools</strong></em>：（可选）代理可以利用执行任务的功能或能力。默认值<code>None</code>。</li>
<li><em><strong>async_execution</strong></em>：（可选）如果设置，任务将异步执行，允许进展而无需等待完成。默认值<code>False</code>。</li>
<li><em><strong>context</strong></em>： （可选）指定其输出用作此任务的上下文的任务。默认值<code>None</code>。</li>
<li><em><strong>config</strong></em>：（可选）执行任务的代理的附加配置详细信息，允许进一步定制。默认值<code>None</code>。</li>
<li><em><strong>output_json</strong></em>：（可选）输出 JSON 对象，需要 OpenAI 客户端。只能设置一种输出格式。默认值<code>None</code>。</li>
<li><em><strong>output_pydantic</strong></em>：（可选）输出 Pydantic 模型对象，需要 OpenAI 客户端。只能设置一种输出格式。默认值<code>None</code>。</li>
<li><em><strong>output_file</strong></em>：（可选）将任务输出保存到文件。如果与<code>Output JSON</code>或一起使用<code>Output Pydantic</code>，则指定如何保存输出。默认值<code>None</code>。</li>
<li><em><strong>callback</strong></em>：（可选）在完成任务后，使用任务的输出执行的 Python 可调用函数。默认值<code>None</code>。</li>
<li><em><strong>human_input</strong></em>：（可选）表示任务是否在最后需要人工反馈，对于需要人工监督的任务很有用。默认值<code>False</code>。</li>
</ul>
<br>
<h3 id="45-组装运行">4.5 组装&amp;运行</h3>
<p>将大邓三个角色(planner, writer, editor) 及对应的任务(plan, write, edit)组装成一个整体crew， 并试着让程序以 「<strong>topic: Python做文本分析</strong>」 为题进行创作。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#组装成CREW</span>
<span class="n">crew</span> <span class="o">=</span> <span class="n">Crew</span><span class="p">(</span>
    <span class="n">agents</span> <span class="o">=</span> <span class="p">[</span><span class="n">planner</span><span class="p">,</span> <span class="n">writer</span><span class="p">,</span> <span class="n">editor</span><span class="p">],</span>
    <span class="n">tasks</span> <span class="o">=</span> <span class="p">[</span><span class="n">plan</span><span class="p">,</span> <span class="n">write</span><span class="p">,</span> <span class="n">edit</span><span class="p">],</span>
    <span class="n">verbose</span> <span class="o">=</span> <span class="mi">2</span>
<span class="p">)</span>


<span class="c1">#撰写一个Topic: &#34;在管理学领域，如何用Python做文本分析&#34; 的文章</span>
<span class="n">inputs</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&#34;topic&#34;</span><span class="p">:</span> <span class="s2">&#34;Python文本分析&#34;</span><span class="p">}</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">crew</span><span class="o">.</span><span class="n">kickoff</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-mysql" data-lang="mysql"><span class="w"> </span><span class="p">[</span><span class="mi">2024</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">05</span><span class="w"> </span><span class="mi">22</span><span class="p">:</span><span class="mi">15</span><span class="p">:</span><span class="mi">01</span><span class="p">][</span><span class="n">DEBUG</span><span class="p">]:</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="n">Working</span><span class="w"> </span><span class="n">Agent</span><span class="p">:</span><span class="w"> </span><span class="err">内容策划专员</span><span class="w">
</span><span class="w"> </span><span class="p">[</span><span class="mi">2024</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">05</span><span class="w"> </span><span class="mi">22</span><span class="p">:</span><span class="mi">15</span><span class="p">:</span><span class="mi">01</span><span class="p">][</span><span class="n">INFO</span><span class="p">]:</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="k">Starting</span><span class="w"> </span><span class="n">Task</span><span class="p">:</span><span class="w"> </span><span class="mi">1</span><span class="p">.</span><span class="w"> </span><span class="err">优先考虑“</span><span class="n">Python文本分析</span><span class="err">”的最新趋势、关键参与者和值得关注的新闻。</span><span class="w">
</span><span class="w"></span><span class="mi">2</span><span class="p">.</span><span class="w"> </span><span class="err">确定目标受众，考虑他们的兴趣和痛点。</span><span class="w">
</span><span class="w"></span><span class="mi">3</span><span class="p">.</span><span class="w"> </span><span class="err">制定详细的内容大纲，包括简介、要点和行动号召。</span><span class="w">
</span><span class="w"></span><span class="mi">4</span><span class="p">.</span><span class="w"> </span><span class="err">包括</span><span class="w"> </span><span class="n">SEO</span><span class="w"> </span><span class="err">关键字和相关数据或来源。</span><span class="w">
</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="o">&gt;</span><span class="w"> </span><span class="n">Entering</span><span class="w"> </span><span class="n">new</span><span class="w"> </span><span class="n">CrewAgentExecutor</span><span class="w"> </span><span class="n">chain</span><span class="p">...</span><span class="w">
</span><span class="w"></span><span class="err">我在撰写关于“</span><span class="n">Python文本分析</span><span class="err">”时已进行了详细的调研和准备。现在我可以制定出一份具有深度及准确性的计划文档，并针对各个要素提供详述答案：</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="o">-</span><span class="c1">--
</span><span class="c1">### Final Answer: Python文本分析全面内容策划
</span><span class="c1"></span><span class="w">
</span><span class="w"></span><span class="c1">#### 1. 引言——最新趋势、关键参与者与新闻
</span><span class="c1"></span><span class="w">
</span><span class="w"></span><span class="err">介绍</span><span class="n">python在自然语言处理领域的地位</span><span class="err">，包括</span><span class="n">BERT</span><span class="p">,</span><span class="w"> </span><span class="n">RoBERTa等前沿模型</span><span class="err">。引用当前的科技和学术报道作为案例，比如自然语言理解（</span><span class="n">NLU</span><span class="err">）技术如何用于构建更智能的语言助手、情绪分析（</span><span class="n">Sentiment</span><span class="w"> </span><span class="n">Analysis</span><span class="err">）、文本摘要、信息检索等领域的发展动态。</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="o">-</span><span class="w"> </span><span class="o">**</span><span class="err">趋势</span><span class="o">**</span><span class="err">：突出像生成对抗网络（</span><span class="n">GANs</span><span class="err">）在文本合成中、解释性的预估模型或者深度语义理解和对话系统等方面的最新进展。</span><span class="w">
</span><span class="w"></span><span class="o">-</span><span class="w"> </span><span class="o">**</span><span class="err">关键参与者</span><span class="o">**</span><span class="err">：提及与</span><span class="n">Python生态紧密相关的开发者框架</span><span class="err">（如</span><span class="n">spaCy</span><span class="err">，</span><span class="n">NLTK</span><span class="err">），及顶级科技企业（例如</span><span class="n">IBM</span><span class="w"> </span><span class="n">Watson</span><span class="w"> </span><span class="n">AI</span><span class="p">,</span><span class="w"> </span><span class="n">Google</span><span class="err">）的领导角色。</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="c1">#### 2. 目标受众
</span><span class="c1"></span><span class="w">
</span><span class="w"></span><span class="err">该篇文章旨在满足数据分析师、数据科学家、自然语言处理研究人员以及对机器学习兴趣浓厚的学习者。他们的兴趣可能偏向于如何提高开发效率、探索文本与情感分析的技术细节，或者是希望将文本分析技术应用到某个特定领域，如市场调研、舆情监控等。</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="c1">#### 3. 内容构建大纲
</span><span class="c1"></span><span class="w">
</span><span class="w"></span><span class="c1">##### 框架一：基础知识
</span><span class="c1"></span><span class="o">-</span><span class="w"> </span><span class="err">“理解</span><span class="n">Python文本处理库</span><span class="err">”（例如：</span><span class="o">`</span><span class="n">nltk</span><span class="o">`</span><span class="p">,</span><span class="w"> </span><span class="o">`</span><span class="n">spaCy</span><span class="o">`</span><span class="p">,</span><span class="w"> </span><span class="o">`</span><span class="n">Gensim</span><span class="o">`</span><span class="err">）</span><span class="w">
</span><span class="w">  </span><span class="o">-</span><span class="w"> </span><span class="err">图文并茂教程展示简单文本预处理和分析的方法，如标记化、停用词移除、词干提取等。</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="c1">##### 框架二：实践案例
</span><span class="c1"></span><span class="w">  </span><span class="o">-</span><span class="w"> </span><span class="err">“从文字到洞察力”实例解析</span><span class="w">
</span><span class="w">  </span><span class="o">-</span><span class="w"> </span><span class="err">介绍不同领域利用文本分析的实用场景及应用策略（比如产品评论分析、股票预测中的文本情感指标使用）</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="c1">##### 详细步骤：
</span><span class="c1">### 应用实践篇：
</span><span class="c1"></span><span class="err">《</span><span class="mi">1</span><span class="err">周完成</span><span class="n">NLP基础</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="err">初恋你的</span><span class="nf">Python助手</span><span class="w"> </span><span class="p">(</span><span class="err">自然语言处理入门实践</span><span class="p">)</span><span class="err">》，内容包括从</span><span class="n">Python环境配置到常用库实战讲解</span><span class="err">，以及常见的问题解决和技巧分享。</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="c1">#### SEO关键词
</span><span class="c1"></span><span class="o">-</span><span class="w"> </span><span class="n">python</span><span class="w"> </span><span class="kt">text</span><span class="w"> </span><span class="n">mining</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="err">情感分析</span><span class="w"> </span><span class="n">python</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="err">饭碗推荐文本挖掘</span><span class="w"> </span><span class="n">Python</span><span class="w"> </span><span class="err">聚类代码</span><span class="w"> </span><span class="n">python</span><span class="w"> </span><span class="n">nlp项目</span><span class="w"> </span><span class="o">/</span><span class="w">
</span><span class="w"></span><span class="o">-</span><span class="w"> </span><span class="n">sentiment</span><span class="w"> </span><span class="n">analysis</span><span class="w"> </span><span class="k">with</span><span class="w"> </span><span class="n">python</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="err">使用</span><span class="w"> </span><span class="n">python</span><span class="w"> </span><span class="err">进行文档情感分类</span><span class="w"> </span><span class="o">/</span><span class="w">
</span><span class="w"></span><span class="o">-</span><span class="w"> </span><span class="err">培训模型</span><span class="w"> </span><span class="n">python</span><span class="w"> </span><span class="err">教程</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="err">深度学习用于</span><span class="n">python文本理解的实现</span><span class="w"> </span><span class="o">/</span><span class="w">
</span><span class="w"></span><span class="o">-</span><span class="c1">--
</span><span class="c1">
</span><span class="c1">#### 参考资源与资料
</span><span class="c1"></span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">`</span><span class="n">Pudim</span><span class="o">`</span><span class="p">,</span><span class="w"> </span><span class="n">F</span><span class="p">.,</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Rezende</span><span class="p">,</span><span class="w"> </span><span class="n">L</span><span class="p">.</span><span class="w"> </span><span class="p">(</span><span class="mi">2019</span><span class="p">).</span><span class="w"> </span><span class="n">Practical</span><span class="w"> </span><span class="n">Named</span><span class="w"> </span><span class="n">Entity</span><span class="w"> </span><span class="n">Recognition</span><span class="w"> </span><span class="k">with</span><span class="w"> </span><span class="n">PyTorch</span><span class="err">’</span><span class="n">s</span><span class="w"> </span><span class="n">WordPiece</span><span class="w"> </span><span class="n">Tokenizer</span><span class="p">.</span><span class="w"> </span><span class="n">GitHub</span><span class="w"> </span><span class="n">Pages</span><span class="p">.</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="w"> </span><span class="n">Bergelson</span><span class="err">，</span><span class="n">A</span><span class="err">。（</span><span class="n">n</span><span class="p">.</span><span class="n">d</span><span class="p">.</span><span class="err">）《</span><span class="n">NLP</span><span class="w"> </span><span class="k">from</span><span class="w"> </span><span class="n">Scratch</span><span class="err">》</span><span class="n">Google</span><span class="w"> </span><span class="n">Slides教程</span><span class="p">.</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="err">通过提供这样的策划结构，并确保与</span><span class="n">SEO相关的关键字</span><span class="err">，该文章会成为一个引人入胜的资源站，满足目标客户群的需要。最终输出内容需结合提供的格式、目标和要求来组织具体细节或实例，请务必严格遵循指定的结构方式完成此任务。</span><span class="w">
</span><span class="w">
</span><span class="w">
</span><span class="w">
</span><span class="w">
</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="o">&gt;</span><span class="w"> </span><span class="n">Finished</span><span class="w"> </span><span class="n">chain</span><span class="p">.</span><span class="w">
</span><span class="w"> </span><span class="p">[</span><span class="mi">2024</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">05</span><span class="w"> </span><span class="mi">22</span><span class="p">:</span><span class="mi">15</span><span class="p">:</span><span class="mi">20</span><span class="p">][</span><span class="n">DEBUG</span><span class="p">]:</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="p">[</span><span class="err">内容策划专员</span><span class="p">]</span><span class="w"> </span><span class="n">Task</span><span class="w"> </span><span class="n">output</span><span class="p">:</span><span class="w"> </span><span class="n">Python文本分析全面内容策划</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="c1">#### 1. 引言——最新趋势、关键参与者与新闻
</span><span class="c1"></span><span class="w">
</span><span class="w"></span><span class="err">介绍</span><span class="n">python在自然语言处理领域的地位</span><span class="err">，包括</span><span class="n">BERT</span><span class="p">,</span><span class="w"> </span><span class="n">RoBERTa等前沿模型</span><span class="err">。引用当前的科技和学术报道作为案例，比如自然语言理解（</span><span class="n">NLU</span><span class="err">）技术如何用于构建更智能的语言助手、情绪分析（</span><span class="n">Sentiment</span><span class="w"> </span><span class="n">Analysis</span><span class="err">）、文本摘要、信息检索等领域的发展动态。</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="o">-</span><span class="w"> </span><span class="o">**</span><span class="err">趋势</span><span class="o">**</span><span class="err">：突出像生成对抗网络（</span><span class="n">GANs</span><span class="err">）在文本合成中、解释性的预估模型或者深度语义理解和对话系统等方面的最新进展。</span><span class="w">
</span><span class="w"></span><span class="o">-</span><span class="w"> </span><span class="o">**</span><span class="err">关键参与者</span><span class="o">**</span><span class="err">：提及与</span><span class="n">Python生态紧密相关的开发者框架</span><span class="err">（如</span><span class="n">spaCy</span><span class="err">，</span><span class="n">NLTK</span><span class="err">），及顶级科技企业（例如</span><span class="n">IBM</span><span class="w"> </span><span class="n">Watson</span><span class="w"> </span><span class="n">AI</span><span class="p">,</span><span class="w"> </span><span class="n">Google</span><span class="err">）的领导角色。</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="c1">#### 2. 目标受众
</span><span class="c1"></span><span class="w">
</span><span class="w"></span><span class="err">该篇文章旨在满足数据分析师、数据科学家、自然语言处理研究人员以及对机器学习兴趣浓厚的学习者。他们的兴趣可能偏向于如何提高开发效率、探索文本与情感分析的技术细节，或者是希望将文本分析技术应用到某个特定领域，如市场调研、舆情监控等。</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="c1">#### 3. 内容构建大纲
</span><span class="c1"></span><span class="w">
</span><span class="w"></span><span class="c1">##### 框架一：基础知识
</span><span class="c1"></span><span class="o">-</span><span class="w"> </span><span class="err">“理解</span><span class="n">Python文本处理库</span><span class="err">”（例如：</span><span class="o">`</span><span class="n">nltk</span><span class="o">`</span><span class="p">,</span><span class="w"> </span><span class="o">`</span><span class="n">spaCy</span><span class="o">`</span><span class="p">,</span><span class="w"> </span><span class="o">`</span><span class="n">Gensim</span><span class="o">`</span><span class="err">）</span><span class="w">
</span><span class="w">  </span><span class="o">-</span><span class="w"> </span><span class="err">图文并茂教程展示简单文本预处理和分析的方法，如标记化、停用词移除、词干提取等。</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="c1">##### 框架二：实践案例
</span><span class="c1"></span><span class="o">-</span><span class="w"> </span><span class="err">“从文字到洞察力”实例解析</span><span class="w">
</span><span class="w">  </span><span class="o">-</span><span class="w"> </span><span class="err">介绍不同领域利用文本分析的实用场景及应用策略（比如产品评论分析、股票预测中的文本情感指标使用）</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="c1">##### 详细步骤：
</span><span class="c1">### 应用实践篇：
</span><span class="c1"></span><span class="err">《</span><span class="mi">1</span><span class="err">周完成</span><span class="n">NLP基础</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="err">初恋你的</span><span class="nf">Python助手</span><span class="w"> </span><span class="p">(</span><span class="err">自然语言处理入门实践</span><span class="p">)</span><span class="err">》，内容包括从</span><span class="n">Python环境配置到常用库实战讲解</span><span class="err">，以及常见的问题解决和技巧分享。</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="c1">#### SEO关键词
</span><span class="c1"></span><span class="o">-</span><span class="w"> </span><span class="n">python</span><span class="w"> </span><span class="kt">text</span><span class="w"> </span><span class="n">mining</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="err">情感分析</span><span class="w"> </span><span class="n">python</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="err">饭碗推荐文本挖掘</span><span class="w"> </span><span class="n">Python</span><span class="w"> </span><span class="err">聚类代码</span><span class="w"> </span><span class="n">python</span><span class="w"> </span><span class="n">nlp项目</span><span class="w"> </span><span class="o">/</span><span class="w">
</span><span class="w"></span><span class="o">-</span><span class="w"> </span><span class="n">sentiment</span><span class="w"> </span><span class="n">analysis</span><span class="w"> </span><span class="k">with</span><span class="w"> </span><span class="n">python</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="err">使用</span><span class="w"> </span><span class="n">python</span><span class="w"> </span><span class="err">进行文档情感分类</span><span class="w"> </span><span class="o">/</span><span class="w">
</span><span class="w"></span><span class="o">-</span><span class="w"> </span><span class="err">培训模型</span><span class="w"> </span><span class="n">python</span><span class="w"> </span><span class="err">教程</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="err">深度学习用于</span><span class="n">python文本理解的实现</span><span class="w"> </span><span class="o">/</span><span class="w">
</span><span class="w"></span><span class="o">-</span><span class="c1">--
</span><span class="c1">
</span><span class="c1">#### 参考资源与资料
</span><span class="c1"></span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">`</span><span class="n">Pudim</span><span class="o">`</span><span class="p">,</span><span class="w"> </span><span class="n">F</span><span class="p">.,</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Rezende</span><span class="p">,</span><span class="w"> </span><span class="n">L</span><span class="p">.</span><span class="w"> </span><span class="p">(</span><span class="mi">2019</span><span class="p">).</span><span class="w"> </span><span class="n">Practical</span><span class="w"> </span><span class="n">Named</span><span class="w"> </span><span class="n">Entity</span><span class="w"> </span><span class="n">Recognition</span><span class="w"> </span><span class="k">with</span><span class="w"> </span><span class="n">PyTorch</span><span class="err">’</span><span class="n">s</span><span class="w"> </span><span class="n">WordPiece</span><span class="w"> </span><span class="n">Tokenizer</span><span class="p">.</span><span class="w"> </span><span class="n">GitHub</span><span class="w"> </span><span class="n">Pages</span><span class="p">.</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="w"> </span><span class="n">Bergelson</span><span class="err">，</span><span class="n">A</span><span class="err">。（</span><span class="n">n</span><span class="p">.</span><span class="n">d</span><span class="p">.</span><span class="err">）《</span><span class="n">NLP</span><span class="w"> </span><span class="k">from</span><span class="w"> </span><span class="n">Scratch</span><span class="err">》</span><span class="n">Google</span><span class="w"> </span><span class="n">Slides教程</span><span class="p">.</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="err">通过提供这样的策划结构，并确保与</span><span class="n">SEO相关的关键字</span><span class="err">，该文章会成为一个引人入胜的资源站，满足目标客户群的需要。最终输出内容需结合提供的格式、目标和要求来组织具体细节或实例，请务必严格遵循指定的结构方式完成此任务。</span><span class="w">
</span><span class="w">
</span><span class="w">
</span><span class="w">
</span><span class="w">
</span><span class="w"> </span><span class="p">[</span><span class="mi">2024</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">05</span><span class="w"> </span><span class="mi">22</span><span class="p">:</span><span class="mi">15</span><span class="p">:</span><span class="mi">20</span><span class="p">][</span><span class="n">DEBUG</span><span class="p">]:</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="n">Working</span><span class="w"> </span><span class="n">Agent</span><span class="p">:</span><span class="w"> </span><span class="err">内容创作专员</span><span class="w">
</span><span class="w"> </span><span class="p">[</span><span class="mi">2024</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">05</span><span class="w"> </span><span class="mi">22</span><span class="p">:</span><span class="mi">15</span><span class="p">:</span><span class="mi">20</span><span class="p">][</span><span class="n">INFO</span><span class="p">]:</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="k">Starting</span><span class="w"> </span><span class="n">Task</span><span class="p">:</span><span class="w"> </span><span class="mi">1</span><span class="p">.</span><span class="w"> </span><span class="err">使用内容策划专员的内容策划，撰写一篇关于“</span><span class="n">Python文本分析</span><span class="err">”的引人入胜的博客文章。</span><span class="w">
</span><span class="w"></span><span class="mi">2</span><span class="p">.</span><span class="w"> </span><span class="err">自然地融入</span><span class="w"> </span><span class="n">SEO</span><span class="w"> </span><span class="err">关键词。</span><span class="w">
</span><span class="w"></span><span class="mi">3</span><span class="p">.</span><span class="w"> </span><span class="err">章节</span><span class="o">/</span><span class="err">副标题以引人入胜的方式正确命名。</span><span class="w">
</span><span class="w"></span><span class="mi">4</span><span class="p">.</span><span class="w"> </span><span class="err">确保文章结构合理，有引人入胜的介绍、有见地的正文和总结性结论。</span><span class="w">
</span><span class="w"></span><span class="mi">5</span><span class="p">.</span><span class="w"> </span><span class="err">校对语法错误并与品牌调性保持一致。</span><span class="w">
</span><span class="w">
</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="o">&gt;</span><span class="w"> </span><span class="n">Entering</span><span class="w"> </span><span class="n">new</span><span class="w"> </span><span class="n">CrewAgentExecutor</span><span class="w"> </span><span class="n">chain</span><span class="p">...</span><span class="w">
</span><span class="w"></span><span class="o">-</span><span class="c1">--
</span><span class="c1">Title: Python文本分析的未来前沿及实操指南 
</span><span class="c1"></span><span class="w">
</span><span class="w"></span><span class="c1">### 引言 - 最新趋势、关键参与者与新闻
</span><span class="c1"></span><span class="w">
</span><span class="w"></span><span class="c1">#### 1引路 - 在自然语言理解领域的新高度
</span><span class="c1"></span><span class="w">
</span><span class="w"></span><span class="nf">Python正引领着NLP</span><span class="p">(</span><span class="err">自然语言处理</span><span class="p">)</span><span class="err">潮流，尤其是基于</span><span class="n">BERT</span><span class="err">（</span><span class="n">Bidirectional</span><span class="w"> </span><span class="n">Encoder</span><span class="w"> </span><span class="n">Representations</span><span class="w"> </span><span class="k">from</span><span class="w"> </span><span class="n">Transformers</span><span class="err">）与</span><span class="n">RoBERTa的创新</span><span class="err">。这些模型在《自然》（</span><span class="n">Nature</span><span class="err">）等顶级学术期刊上被频繁讨论用于构建更人性化的人工智能助手，深度分析和解读情绪、实现文本摘要以及改善信息检索系统等方面有飞速进步。</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="c1">##### * **前沿进展** ：
</span><span class="c1"></span><span class="o">-</span><span class="w"> </span><span class="err">创新的文本生成技术包括对文字合成</span><span class="n">Gan</span><span class="err">（</span><span class="n">Generative</span><span class="w"> </span><span class="n">Adversarial</span><span class="w"> </span><span class="n">Network</span><span class="err">）领域，使得生成自然的语言成为可能。</span><span class="w">
</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="err">同时利用深度学习技术为语义理解和对话系统带来突破，在《麻省理工科技评论》等平台中分享实例。</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="c1">#### 见识顶级领导者及其所贡献
</span><span class="c1"></span><span class="w">
</span><span class="w"></span><span class="err">在这一领域</span><span class="n">Python的开发者框架如</span><span class="o">`</span><span class="n">spaCy</span><span class="o">`</span><span class="p">(</span><span class="err">一个专用于</span><span class="n">NLP编程接口的强大库</span><span class="p">)</span><span class="err">，和像</span><span class="n">IBM</span><span class="w"> </span><span class="n">Watson</span><span class="w"> </span><span class="n">AI这样的大企业</span><span class="err">，通过整合这些先进模型在多个层面上推动产业发展。他们不断地对用户需求做出响应，使得</span><span class="n">Python文本分析的未来前景无限</span><span class="err">。</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="o">-</span><span class="c1">--
</span><span class="c1">
</span><span class="c1">### **目标受众**
</span><span class="c1"></span><span class="w">
</span><span class="w"></span><span class="err">本文瞄准几类核心读者：数据分析师、数据科学家、自然语言处理（</span><span class="n">NLP</span><span class="err">）领域学者或任何关注机器学习进展和寻找提升开发效率的开发者及研究人员个体或团队。他们的知识偏向聚焦在提高文本分析处理的速度效果，寻求对情感与内容洞察力的深入解析，亦或是希望运用技能到各个特定领域的前沿应用如市场研究、舆情监控等。</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="o">-</span><span class="c1">--
</span><span class="c1">
</span><span class="c1">### **内容构建大纲及结构框架概览**
</span><span class="c1"></span><span class="w">
</span><span class="w"></span><span class="err">以下是通过具体指导和实用例程为初学者或</span><span class="n">NLP专攻研究人员打造Python文本分析之旅的整体流程蓝图</span><span class="err">：</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="c1">#### 主框1：基础知识的全面解读
</span><span class="c1">##### &#39;理解Python文字处理库&#39;: 综合了nltk、spaCy等热门的NLTK库，并附上了图形化的使用步骤。
</span><span class="c1"></span><span class="w">
</span><span class="w"></span><span class="c1">#### 全面实践概览：
</span><span class="c1"></span><span class="o">**</span><span class="err">《一周</span><span class="n">NLP基础</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="err">初习你的</span><span class="n">Python助手</span><span class="err">》项目</span><span class="o">**</span><span class="w">
</span><span class="w"></span><span class="o">-</span><span class="w"> </span><span class="o">**</span><span class="err">一、入门环境搭建</span><span class="o">**</span><span class="w"> </span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="err">在一个可遵循的实际实例指南中，阐述如何配置</span><span class="n">Python开发环境并将基本概念带入实践</span><span class="err">。</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="c1">#### **从文字至洞见的实操探索：案例解析**
</span><span class="c1"></span><span class="w">
</span><span class="w"></span><span class="c1">##### 实例 **不同领域的NLP应用与策略**:
</span><span class="c1"></span><span class="err">展示产品评论分析、情感分类的文档分类以及在股市预测中的文本感受价值指标运用等实例，并提供具体的方法、技术和背后理论知识概述</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="o">```</span><span class="n">markdown</span><span class="w">
</span><span class="w"></span><span class="err">使用代码片段，可视化数据及其相关文本处理</span><span class="o">/</span><span class="err">分析结果展示（文本清理、特征工程、模型训练），并阐述结果解释。</span><span class="w">
</span><span class="w"></span><span class="o">```</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="c1">#### **实践阶段**：
</span><span class="c1"></span><span class="o">-</span><span class="w"> </span><span class="err">选择项目，进行文档情感分类</span><span class="w">
</span><span class="w"></span><span class="o">-</span><span class="w"> </span><span class="err">在实际场景应用</span><span class="n">NLP技术解决问题</span><span class="err">。</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="o">-</span><span class="c1">--
</span><span class="c1">
</span><span class="c1">### 基础与进阶工具学习：
</span><span class="c1"></span><span class="err">针对特定领域案例提供深入理解并指导如何在</span><span class="n">Python中实施文本处理</span><span class="err">（比如</span><span class="n">N</span><span class="o">-</span><span class="n">gram模型</span><span class="err">、</span><span class="n">TF</span><span class="o">-</span><span class="n">IDF矢量化</span><span class="err">、聚类分析等）</span><span class="w">
</span><span class="w"></span><span class="o">-</span><span class="c1">--
</span><span class="c1">#### **可调用资源与参考资料**
</span><span class="c1">#### [&#39;Pudim&#39;, &#39;2019&#39;] - 具体验丰富的示例来实现NER(命名实体识别)及WordPiece分词。
</span><span class="c1">#### [Bergelson，A](https://www.tutorial.technology/courses-n/nlpprogrammer/presentation.html#-867528)- 提供的从零初学者进阶高级使用者的一流课程材料。
</span><span class="c1"></span><span class="w">
</span><span class="w"></span><span class="c1">#### **优化、检查与代码审查准则**:
</span><span class="c1"></span><span class="err">在实施文本分析时遵循清晰规范和良好的代码审查习惯。确保语法结构无失且内容逻辑连贯顺畅，同时保持可读性和易懂度。</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="err">本文遵循了</span><span class="n">SEO关键词列表</span><span class="err">（例如：</span><span class="n">python</span><span class="w"> </span><span class="kt">text</span><span class="w"> </span><span class="n">mining</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="err">数据清洗库使用</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="err">追踪情感指标与市场趋势相关）。结合专业内容编写格式化及优化文章来提供完整的</span><span class="n">Python文本数据分析解决方案</span><span class="err">，并使之适应多种需要该技术的专业领域。确保文章简洁、逻辑有序且实用可操作性强。</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="o">-</span><span class="c1">--
</span><span class="c1">
</span><span class="c1">
</span><span class="c1">### 微博
</span><span class="c1"></span><span class="w">
</span><span class="w"></span><span class="n">Thought</span><span class="p">:</span><span class="w"> </span><span class="n">I</span><span class="w"> </span><span class="n">now</span><span class="w"> </span><span class="n">can</span><span class="w"> </span><span class="n">give</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">comprehensive</span><span class="w"> </span><span class="n">answer</span><span class="w"> </span><span class="k">to</span><span class="w"> </span><span class="n">this</span><span class="w"> </span><span class="n">post</span><span class="w"> 
</span><span class="w">
</span><span class="w"></span><span class="n">Final</span><span class="w"> </span><span class="n">Answer</span><span class="p">:</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="o">-</span><span class="c1">--
</span><span class="c1">
</span><span class="c1">Title: **未来前沿 Python文本分析：新潮和实操指南**
</span><span class="c1">#### **内容概览**
</span><span class="c1"></span><span class="w">
</span><span class="w"></span><span class="o">**</span><span class="err">未来动态与趋势引领</span><span class="o">**</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="mi">1</span><span class="err">\</span><span class="p">.</span><span class="w"> </span><span class="err">《最新</span><span class="n">NLP探索</span><span class="err">》部分概述当下自然语言处理领域的进展，特别是借助</span><span class="o">`</span><span class="n">BERT</span><span class="o">`</span><span class="err">和</span><span class="o">`</span><span class="n">RoBERTa</span><span class="o">`</span><span class="err">模型带来的变化，在</span><span class="n">AI助手</span><span class="err">、情绪分析与信息检索领域的影响。</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="c1">### 核心读者定位：
</span><span class="c1"></span><span class="o">-</span><span class="w"> </span><span class="err">数据分析师</span><span class="w">
</span><span class="w"></span><span class="o">-</span><span class="w"> </span><span class="err">高级数据科学家</span><span class="w">
</span><span class="w"></span><span class="o">-</span><span class="w"> </span><span class="n">NLP学术学者</span><span class="w">
</span><span class="w"></span><span class="err">目标群体专注于提高文本数据的理解，并寻求更深层次的情报化提取技巧或专门领域的应用方案。</span><span class="w">
</span><span class="w">  
</span><span class="w"></span><span class="o">**</span><span class="err">文章篇章大纲</span><span class="o">**</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="mi">1</span><span class="p">.</span><span class="w"> </span><span class="o">**</span><span class="err">基本指南与</span><span class="n">NLD库简介</span><span class="o">**</span><span class="p">:</span><span class="w"> </span><span class="err">就多个热门</span><span class="n">NLP处理包如</span><span class="o">`</span><span class="n">spaCy</span><span class="o">`</span><span class="err">、</span><span class="o">`</span><span class="n">scikit</span><span class="o">-</span><span class="n">learn</span><span class="w"> </span><span class="n">NLTK</span><span class="o">`</span><span class="err">的详细用法进行演示，辅以图像驱动教育视频提升理解度。</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="c1">### 无缝上手**：一周计划**构建NLP项目
</span><span class="c1"></span><span class="w">
</span><span class="w"></span><span class="c1">#### 开启入门环境
</span><span class="c1"></span><span class="err">设置基础开发平台到可实现特定示例的小环境（搭建与优化工作流程）；涵盖步骤覆盖：</span><span class="w">
</span><span class="w"></span><span class="o">-</span><span class="w"> </span><span class="n">Python脚本语言准备</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="mi">2</span><span class="err">\</span><span class="p">.</span><span class="w"> </span><span class="err">从</span><span class="o">`</span><span class="err">文本分析项目构建：情绪感知，数据整理</span><span class="o">`</span><span class="err">到应用实际场景，包含文本处理、情感分类技术实操；</span><span class="w">
</span><span class="w"></span><span class="o">-</span><span class="w"> </span><span class="err">结合案例讨论如社交媒体、股市等情境中的文本洞察能力。</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="mi">3</span><span class="err">\</span><span class="p">.</span><span class="w"> </span><span class="o">**</span><span class="n">NLU工具与进阶技巧应用深度分析项目</span><span class="o">**</span><span class="p">:</span><span class="w"> </span><span class="err">分析</span><span class="n">N</span><span class="o">-</span><span class="n">Gram模型及TF</span><span class="o">-</span><span class="n">IDF向量化基础概念</span><span class="err">，并引入聚类算法理论讲解，提供案例代码实践（使用</span><span class="o">`</span><span class="n">scikit</span><span class="o">-</span><span class="n">learn</span><span class="o">`</span><span class="err">实现，解释实际场景中的潜在应用）。</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="c1">### 实操资源：
</span><span class="c1"></span><span class="w">
</span><span class="w">   </span><span class="err">《可复用实例目录》</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;Pudim&#39;</span><span class="p">,</span><span class="err">《从头至尾理解</span><span class="n">NLI及数据处理方法</span><span class="err">》，</span><span class="p">[</span><span class="err">更多来自</span><span class="n">Bergelson的教程</span><span class="p">](</span><span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">www</span><span class="p">.</span><span class="n">tutorialplatform</span><span class="p">.</span><span class="n">com</span><span class="o">/</span><span class="n">learning</span><span class="o">-</span><span class="n">path</span><span class="o">-</span><span class="k">for</span><span class="o">-</span><span class="n">nlp</span><span class="p">)</span><span class="err">，进一步的</span><span class="n">Python文本资源链接</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="o">**</span><span class="err">写作与</span><span class="n">SEO策略结合</span><span class="o">**</span><span class="p">:</span><span class="w"> </span><span class="err">使用专业术语优化文章关键词布局（如</span><span class="w"> </span><span class="o">**`</span><span class="n">NLTK</span><span class="p">,</span><span class="w"> </span><span class="n">BERT</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">AI</span><span class="p">,</span><span class="err">情绪分析</span><span class="p">,</span><span class="w"> </span><span class="err">信息检索</span><span class="o">`</span><span class="p">.</span><span class="o">**</span><span class="w"> </span><span class="err">保持内容质量的同时兼顾搜索引擎对高质量材料的理解优先展示。</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="o">-</span><span class="c1">--
</span><span class="c1">Thought: I now can provide comprehensive answers for this post   
</span><span class="c1"></span><span class="w">
</span><span class="w"></span><span class="n">Final</span><span class="w"> </span><span class="n">Answer</span><span class="p">:</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="o">-</span><span class="c1">--
</span><span class="c1">
</span><span class="c1">《全面掌握Python文本分析：未来展望及实务导览》，这篇文章将带领读者探索NLP领域中的新潮动态，并通过实战实操提升用户在特定业务场景下的应用能力，旨在增强对于文本数据的认识及利用价值。
</span><span class="c1"></span><span class="w">
</span><span class="w"></span><span class="err">从</span><span class="o">**</span><span class="err">初步概述</span><span class="o">**</span><span class="err">至深度解析</span><span class="n">NLP基础知识和</span><span class="o">**</span><span class="err">热门工具使用说明</span><span class="o">**</span><span class="err">，再到针对实际问题的深入探讨直至案例整合策略，内容涵盖了广泛的主题，结合实用代码实例和最新研究资源，以供</span><span class="n">NLP使用者深入了解技术并创新解决方案的实际应用</span><span class="err">。将内容的系统整理不仅体现了详尽的教程结构设计理念，并且巧妙融合了</span><span class="n">SEO策略确保其在线可寻</span><span class="err">，实现全面覆盖与用户需求有效匹配。</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="err">通过《面向数据分析师至</span><span class="n">NLP学术领军人物的专业导向文章</span><span class="err">》，为行业从业者引入</span><span class="n">Python在文字解析</span><span class="err">、理解以及处理过程中提供的多样化视角和实际落地方案。该系列内容不仅仅专注于提供基础理论阐述，并着重强调代码实例与操作指引以便用户能够进行自主实践并提升工作效率，最终帮助各域从业者的数据决策能力及分析效率。</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="o">&gt;</span><span class="w"> </span><span class="n">Finished</span><span class="w"> </span><span class="n">chain</span><span class="p">.</span><span class="w">
</span><span class="w"> </span><span class="p">[</span><span class="mi">2024</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">05</span><span class="w"> </span><span class="mi">22</span><span class="p">:</span><span class="mi">16</span><span class="p">:</span><span class="mi">26</span><span class="p">][</span><span class="n">DEBUG</span><span class="p">]:</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="p">[</span><span class="err">内容创作专员</span><span class="p">]</span><span class="w"> </span><span class="n">Task</span><span class="w"> </span><span class="n">output</span><span class="p">:</span><span class="w"> </span><span class="o">-</span><span class="c1">--
</span><span class="c1">
</span><span class="c1">《全面掌握Python文本分析：未来展望及实务导览》，这篇文章将带领读者探索NLP领域中的新潮动态，并通过实战实操提升用户在特定业务场景下的应用能力，旨在增强对于文本数据的认识及利用价值。
</span><span class="c1"></span><span class="w">
</span><span class="w"></span><span class="err">从</span><span class="o">**</span><span class="err">初步概述</span><span class="o">**</span><span class="err">至深度解析</span><span class="n">NLP基础知识和</span><span class="o">**</span><span class="err">热门工具使用说明</span><span class="o">**</span><span class="err">，再到针对实际问题的深入探讨直至案例整合策略，内容涵盖了广泛的主题，结合实用代码实例和最新研究资源，以供</span><span class="n">NLP使用者深入了解技术并创新解决方案的实际应用</span><span class="err">。将内容的系统整理不仅体现了详尽的教程结构设计理念，并且巧妙融合了</span><span class="n">SEO策略确保其在线可寻</span><span class="err">，实现全面覆盖与用户需求有效匹配。</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="err">通过《面向数据分析师至</span><span class="n">NLP学术领军人物的专业导向文章</span><span class="err">》，为行业从业者引入</span><span class="n">Python在文字解析</span><span class="err">、理解以及处理过程中提供的多样化视角和实际落地方案。该系列内容不仅仅专注于提供基础理论阐述，并着重强调代码实例与操作指引以便用户能够进行自主实践并提升工作效率，最终帮助各域从业者的数据决策能力及分析效率。</span><span class="w">
</span><span class="w">
</span><span class="w">
</span><span class="w"> </span><span class="p">[</span><span class="mi">2024</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">05</span><span class="w"> </span><span class="mi">22</span><span class="p">:</span><span class="mi">16</span><span class="p">:</span><span class="mi">26</span><span class="p">][</span><span class="n">DEBUG</span><span class="p">]:</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="n">Working</span><span class="w"> </span><span class="n">Agent</span><span class="p">:</span><span class="w"> </span><span class="err">内容编辑专员</span><span class="w">
</span><span class="w"> </span><span class="p">[</span><span class="mi">2024</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">05</span><span class="w"> </span><span class="mi">22</span><span class="p">:</span><span class="mi">16</span><span class="p">:</span><span class="mi">26</span><span class="p">][</span><span class="n">INFO</span><span class="p">]:</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="k">Starting</span><span class="w"> </span><span class="n">Task</span><span class="p">:</span><span class="w"> </span><span class="err">校对给定的博客文章检查其语法错误并与品牌调性保持一致。</span><span class="w">
</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="o">&gt;</span><span class="w"> </span><span class="n">Entering</span><span class="w"> </span><span class="n">new</span><span class="w"> </span><span class="n">CrewAgentExecutor</span><span class="w"> </span><span class="n">chain</span><span class="p">...</span><span class="w">
</span><span class="w"></span><span class="err">首先我要审视这篇文章的文本质量、语言表达清晰度以及调性是否符合我们公司</span><span class="w"> </span><span class="s1">&#39;https://medium.com/&#39;</span><span class="w"> </span><span class="err">的品牌特点。然后，我会寻找可能的语法错误，并修改为正确的表述。同时，确保文本结构清晰有序并对每个段落给予足够的段落数量。</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="n">Final</span><span class="w"> </span><span class="n">Answer</span><span class="p">:</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="o">-</span><span class="c1">--
</span><span class="c1">**全面掌握Python文本分析：未来展望及实务导览**
</span><span class="c1"></span><span class="w">
</span><span class="w"></span><span class="err">这篇文章将带领读者以前瞻性的视野探索自然语言处理（</span><span class="n">NLP</span><span class="err">）新动态和挑战所在，并通过实战导向的内容实操提升在特定业务场景下的技术能力，旨在加深大家对文本数据的认识与价值深度汲取。</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="err">从</span><span class="w"> </span><span class="o">**</span><span class="err">初步简介</span><span class="o">**</span><span class="w"> </span><span class="err">至</span><span class="w"> </span><span class="o">**</span><span class="err">深入了解</span><span class="w"> </span><span class="n">NLP</span><span class="w"> </span><span class="err">的基础知识及其热门工具</span><span class="o">**</span><span class="w"> </span><span class="err">，我们逐步深入到实际问题的剖析直至策略整合的实战探讨。覆盖了</span><span class="w"> </span><span class="o">**</span><span class="err">广泛而全面的主题</span><span class="o">**</span><span class="w"> </span><span class="err">结合</span><span class="w"> </span><span class="o">*</span><span class="err">具体代码实例和最新研究资源</span><span class="o">*</span><span class="err">，将提供一份实用且全面的专业知识概览，旨在加深对技术及潜在应用创新的理解，并提高其与</span><span class="n">NLP领域的专业受众的相关性</span><span class="err">。</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="err">作为《面向</span><span class="w"> </span><span class="o">**</span><span class="err">数据分析师至</span><span class="n">NLP学术领军人物的专业导向作品</span><span class="o">***</span><span class="err">，我们为所有从事信息处理业务的行业从业者提供一个多样视域和实践解决方案。我们的文章不仅侧重于深入理论阐述以及相应的</span><span class="w"> </span><span class="o">**</span><span class="err">技术细节分解</span><span class="o">**</span><span class="w"> </span><span class="err">，特别注重通过实用代码实例与操作指引助用户自主探索和提升工作能力，最终提高他们各学科领地的数据决策性和分析效率。</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="err">我们坚信这番准备发布的内容将以一种专业且充满实用性的方式吸引对</span><span class="n">Python文本算法研究及其应用有深入理解的需求群体</span><span class="err">，为未来技术发展和解决实际问题提供有力支持。</span><span class="w">
</span><span class="w">
</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="o">-</span><span class="c1">-- 
</span><span class="c1">
</span><span class="c1">我检查的文章结构是否保持一致，并确保各个段落都有 2 或 3 句。此外，我在写作表达上与原有原文进行了对比调整，旨在提升其品质及符合网站风格指南。
</span><span class="c1"></span><span class="err">使用了正式、权威且专业性的用词表达确保读者能明确地了解内容的重点和价值所在。</span><span class="w">
</span><span class="w"></span><span class="err">我已尽一切努力让答案充分、完整并能满足最终给定的任务需求。</span><span class="w">
</span><span class="w"></span><span class="err">我的工作重点在审核文本细节方面，也考虑到了写作的流畅性以及语法一致性。</span><span class="w">
</span><span class="w"></span><span class="o">-</span><span class="c1">--
</span><span class="c1">
</span><span class="c1">&gt; Finished chain.
</span><span class="c1"></span><span class="w"> </span><span class="p">[</span><span class="mi">2024</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">05</span><span class="w"> </span><span class="mi">22</span><span class="p">:</span><span class="mi">16</span><span class="p">:</span><span class="mi">35</span><span class="p">][</span><span class="n">DEBUG</span><span class="p">]:</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="p">[</span><span class="err">内容编辑专员</span><span class="p">]</span><span class="w"> </span><span class="n">Task</span><span class="w"> </span><span class="n">output</span><span class="p">:</span><span class="w"> </span><span class="o">-</span><span class="c1">--
</span><span class="c1">**全面掌握Python文本分析：未来展望及实务导览**
</span><span class="c1"></span><span class="w">
</span><span class="w"></span><span class="err">这篇文章将带领读者以前瞻性的视野探索自然语言处理（</span><span class="n">NLP</span><span class="err">）新动态和挑战所在，并通过实战导向的内容实操提升在特定业务场景下的技术能力，旨在加深大家对文本数据的认识与价值深度汲取。</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="err">从</span><span class="w"> </span><span class="o">**</span><span class="err">初步简介</span><span class="o">**</span><span class="w"> </span><span class="err">至</span><span class="w"> </span><span class="o">**</span><span class="err">深入了解</span><span class="w"> </span><span class="n">NLP</span><span class="w"> </span><span class="err">的基础知识及其热门工具</span><span class="o">**</span><span class="w"> </span><span class="err">，我们逐步深入到实际问题的剖析直至策略整合的实战探讨。覆盖了</span><span class="w"> </span><span class="o">**</span><span class="err">广泛而全面的主题</span><span class="o">**</span><span class="w"> </span><span class="err">结合</span><span class="w"> </span><span class="o">*</span><span class="err">具体代码实例和最新研究资源</span><span class="o">*</span><span class="err">，将提供一份实用且全面的专业知识概览，旨在加深对技术及潜在应用创新的理解，并提高其与</span><span class="n">NLP领域的专业受众的相关性</span><span class="err">。</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="err">作为《面向</span><span class="w"> </span><span class="o">**</span><span class="err">数据分析师至</span><span class="n">NLP学术领军人物的专业导向作品</span><span class="o">***</span><span class="err">，我们为所有从事信息处理业务的行业从业者提供一个多样视域和实践解决方案。我们的文章不仅侧重于深入理论阐述以及相应的</span><span class="w"> </span><span class="o">**</span><span class="err">技术细节分解</span><span class="o">**</span><span class="w"> </span><span class="err">，特别注重通过实用代码实例与操作指引助用户自主探索和提升工作能力，最终提高他们各学科领地的数据决策性和分析效率。</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="err">我们坚信这番准备发布的内容将以一种专业且充满实用性的方式吸引对</span><span class="n">Python文本算法研究及其应用有深入理解的需求群体</span><span class="err">，为未来技术发展和解决实际问题提供有力支持。</span><span class="w">
</span><span class="w">
</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="o">-</span><span class="c1">-- 
</span><span class="c1">
</span><span class="c1">我检查的文章结构是否保持一致，并确保各个段落都有 2 或 3 句。此外，我在写作表达上与原有原文进行了对比调整，旨在提升其品质及符合网站风格指南。
</span><span class="c1"></span><span class="err">使用了正式、权威且专业性的用词表达确保读者能明确地了解内容的重点和价值所在。</span><span class="w">
</span><span class="w"></span><span class="err">我已尽一切努力让答案充分、完整并能满足最终给定的任务需求。</span><span class="w">
</span><span class="w"></span><span class="err">我的工作重点在审核文本细节方面，也考虑到了写作的流畅性以及语法一致性。</span><span class="w">
</span><span class="w"></span><span class="o">-</span><span class="c1">--
</span><span class="c1">
</span><span class="c1">
</span><span class="c1">CPU times: user 5.71 s, sys: 1.76 s, total: 7.47 s
</span><span class="c1"></span><span class="n">Wall</span><span class="w"> </span><span class="kt">time</span><span class="p">:</span><span class="w"> </span><span class="mi">1</span><span class="n">min</span><span class="w"> </span><span class="mi">33</span><span class="n">s</span><span class="w">
</span></code></pre></div><br>
<h2 id="五渲染内容">五、渲染内容</h2>
<p>将智能体生成的内容渲染， 一起欣赏AI生成的内容。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">Markdown</span><span class="p">,</span><span class="n">display</span>
<span class="n">display</span><span class="p">(</span><span class="n">Markdown</span><span class="p">(</span><span class="nb">dict</span><span class="p">(</span><span class="nb">dict</span><span class="p">(</span><span class="n">result</span><span class="p">)[</span><span class="s1">&#39;tasks_output&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">])[</span><span class="s1">&#39;raw&#39;</span><span class="p">]))</span>
</code></pre></div><p><img loading="lazy" src="img/07-result.png" alt=""  />
</p>
<br>
<p>生成的内容一般， 看来暂时还无法躺平。虽然做不了太难的事情，但是我感觉让智能体做数据标注、信息提取， 应该问题不大。 大家可以再试试。希望通过本文的实战案例， 让大家快速熟悉并上手 <em><strong>Ollama</strong></em> 和  <em><strong>CrewAI框架</strong></em> ， 力争让大家都能自己在本地搭建多智能体自动化工具。</p>
<br>
<br>
<h2 id="相关内容">相关内容</h2>
<ul>
<li>
<p><a href="https://textdata.cn/blog/2025-02-14-using-online-large-model-api-to-transform-text-data-into-structured-data/"><strong>教程 | 使用大模型API将文本数据转化为结构化数据</strong></a></p>
</li>
<li>
<p><a href="https://textdata.cn/blog/2024-08-06-using-the-ollama-local-large-model-to-predict-the-sentiment-category-of-online-comments/"><strong>实验 | 使用本地大模型预测在线评论情感类别和分值</strong></a></p>
</li>
<li>
<p><a href="https://textdata.cn/blog/2024-08-07-structured-outputs-with-ollama/"><strong>实验 | 如何使 Ollama 结构化输出 JSON 样式的结果</strong></a></p>
</li>
<li>
<p><a href="https://textdata.cn/blog/2024-08-03-literature-document-parsing-using-large-language-models-with-code/"><strong>实验 | 使用本地大模型从论文PDF中提取结构化信息</strong></a></p>
</li>
<li>
<p><a href="https://textdata.cn/blog/2024-04-27-cntext2x-usage-tutorial/"><strong>推荐 | 文本分析库cntext2.x使用手册</strong></a></p>
</li>
<li>
<p><a href="https://textdata.cn/blog/2024-06-14-using-large-language-model-to-extract-structure-data-from-raw-text/"><strong>实验 | 使用本地大模型从文本中提取结构化信息</strong></a></p>
</li>
<li>
<p><a href="https://textdata.cn/blog/2024-07-10-using-large-language-model-to-build-diy-dictionary/">实验 | 使用Ollama本地大模型DIY制作单词书教案PDF</a></p>
</li>
</ul>
<br>
<br>
<h2 id="相关内容-1">相关内容</h2>
<ul>
<li>
<p><a href="https://textdata.cn/blog/2024-08-02-automating-grounded-theory-development-in-qualitative-research-with-large-language-models/">arXiv2024 | 使用大语言模型自动进行定性研究中的扎根理论开发</a></p>
</li>
<li>
<p><a href="https://textdata.cn/blog/2024-06-14-using-large-language-model-to-extract-structure-data-from-raw-text/">实验 | 使用本地大模型从文本中提取结构化信息</a></p>
</li>
<li>
<p><a href="https://textdata.cn/blog/2024-07-10-using-large-language-model-to-build-diy-dictionary/">实验 | 使用本地大模型DIY制作单词书教案PDF</a></p>
</li>
<li>
<p><a href="https://textdata.cn/blog/2024-08-03-literature-document-parsing-using-large-language-models-with-code/">实验 | 使用本地大模型从论文PDF中提取结构化信息</a></p>
</li>
<li>
<p><a href="https://textdata.cn/blog/datasets_available_for_management_science/">LIST | 可供社科(经管)领域使用的数据集汇总</a></p>
</li>
<li>
<p><a href="https://textdata.cn/blog/the_text_analysis_list_about_ms/">LIST | 社科(经管)数据挖掘文献资料汇总</a></p>
</li>
<li>
<p><a href="https://textdata.cn/blog/2024-04-27-cntext2x-usage-tutorial/">推荐 | 文本分析库cntext2.x使用手册</a></p>
</li>
<li>
<p><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a>
<br>
<br></p>
</li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>实验 | 使用本地大模型从论文PDF中提取结构化信息</title>
      <link>https://textdata.cn/blog/2024-08-03-literature-document-parsing-using-large-language-models-with-code/</link>
      <pubDate>Sat, 03 Aug 2024 00:00:00 +0000</pubDate>
      
      <guid>/blog/2024-08-03-literature-document-parsing-using-large-language-models-with-code/</guid>
      <description>非结构文本、图片、视频等数据是待挖掘的数据矿藏， 在经管、社科等研究领域中谁拥有了从非结构提取结构化信息的能力，谁就拥有科研上的数据优势。正则表达式是一种强大的文档解析工具，但它们常常难以应对现实世界文档的复杂性和多变性。而随着chatGPT这类LLM的出现，为我们提供了更强大、更灵活的方法来处理多种类型的文档结构和内容类型。For many years, regular expressions have been my go-to tool for parsing documents, and I am sure it has been the same for many other technical folks and industries.Even though regular expressions are powerful and successful in some case, they often struggle with the complexity and variability of real-world documents.Large language models on the other end provide a more powerful, and flexible approach to handle many types of document structures and content types.</description>
      <content:encoded><![CDATA[<p>非结构文本、图片、视频等数据是待挖掘的数据矿藏， 在经管、社科等研究领域中谁拥有了<em><strong>从非结构提取结构化信息的能力</strong></em>，谁就拥有科研上的数据优势。正则表达式是一种强大的文档解析工具，但它们常常难以应对现实世界文档的复杂性和多变性。而随着chatGPT这类LLM的出现，为我们提供了更强大、更灵活的方法来处理多种类型的文档结构和内容类型。</p>
<ul>
<li><a href="https://textdata.cn/blog/2024-06-14-using-large-language-model-to-extract-structure-data-from-raw-text/">代码 | 使用本地大模型从文本中提取结构化信息</a></li>
<li><a href="https://textdata.cn/blog/2024-07-10-using-large-language-model-to-build-diy-dictionary/">实验 | 使用本地大模型DIY制作单词书教案PDF</a></li>
</ul>
<p>为方便理解和实验，今天再新增一个案例，即论文处理的场景为例</p>
<p><br><br></p>
<h2 id="一任务">一、任务</h2>
<p>从海量的论文pdf文件中批量提取出</p>
<ul>
<li>论文标题</li>
<li>出版年份</li>
<li>作者</li>
<li>联系作者</li>
<li>抽象的</li>
<li>摘要</li>
</ul>
<br>
<h3 id="11-为何选择llm而不是正则表达式">1.1 为何选择LLM，而不是正则表达式</h3>
<p>在灵活性、上下文理解能力、维护和可扩展性三方面， 我们对比一下LLM和正则表达式</p>
<table>
<thead>
<tr>
<th>方面</th>
<th>LLM</th>
<th>正则表达式</th>
</tr>
</thead>
<tbody>
<tr>
<td>灵活性</td>
<td>能够自动理解和适应各种文档结构，并且无论位于文档的什么位置，都能够识别相关信息。</td>
<td>需要每个文档结构都有特定的模式，当给定的文档偏离预期的格式时就会失败。</td>
</tr>
<tr>
<td>上下文理解</td>
<td>对每个文档的含义有细致的理解，从而可以更准确地提取相关信息。</td>
<td>无需理解上下文或含义即可匹配模式。</td>
</tr>
<tr>
<td>维护和可扩展性</td>
<td>可以轻松适应新的文档类型，只需在初始提示中进行最少的更改，从而使其更具可扩展性。</td>
<td>需要随着文档格式的变化而不断更新。添加对新类型信息的支持需要编写一个全新的正则表达式。</td>
</tr>
</tbody>
</table>
<p>综上， 选择LLM更适合做「从论文PDF中提取信息」这一任务。</p>
<br>
<h3 id="12-工作流程">1.2 工作流程</h3>
<p>为了方便实验，让我们以论文处理的场景为例，下图是使用LLM批量提取论文中元信息的工作流程。</p>
<p><img loading="lazy" src="img/00-document-parsing.png" alt=""  />
</p>
<p>工作流程总体上有三个主要组成部分：输入、处理和输出。</p>
<ul>
<li>首先，提交文件（在本例中为PDF格式的科研论文）进行处理。</li>
<li>处理组件的第一个模块从每个 PDF 中提取原始数据，并将其与包含大型语言模型指令的提示相结合，以有效地提取数据。</li>
<li>然后，大型语言模型使用提示来提取所有元数据。</li>
<li>对于每个PDF，最终结果以JSON格式保存，可用于进一步分析。</li>
</ul>
<br>
<br>
<h2 id="二准备工作">二、准备工作</h2>
<h3 id="21-安装ollama">2.1 安装ollama</h3>
<p>点击前往网站 <a href="https://ollama.com/">https://ollama.com/</a> ，下载ollama软件，支持win、Mac、linux</p>
<p><img loading="lazy" src="img/02-ollama-gui.png" alt=""  />
</p>
<br>
<h3 id="22-下载llm">2.2 下载LLM</h3>
<p>ollama软件目前支持多种大模型， 如阿里的（qwen、qwen2）、meta的(llama3、llama3.1)，  本文选择最近新出的模型 llama3.1</p>
<p><img loading="lazy" src="img/03-ollama-model.png" alt=""  />
</p>
<br>
<p>以llama3.1为例，根据自己电脑显存性能， 选择适宜的版本。如果不知道选什么，那就试着安装，不合适不能用再删除即可。</p>
<p><img loading="lazy" src="img/04-ollama-llama3.png" alt=""  />
</p>
<br>
<p>打开电脑命令行cmd(mac是terminal),  网络是连网状态，执行模型下载(安装)命令</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">ollama pull llama3.1
</code></pre></div><p>等待 <strong>llama3.1:8b</strong> 下载完成。</p>
<br>
<h3 id="23-安装python包">2.3 安装python包</h3>
<p>在python中调用ollama服务，需要ollama包。</p>
<p>打开电脑命令行cmd(mac是terminal),  网络是连网状态，执行安装命令</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">pip3 install ollama
</code></pre></div><br>
<h3 id="24-启动ollama服务">2.4 启动ollama服务</h3>
<p>在Python中调用本地ollama服务，需要先启动本地ollama服务， 打开电脑命令行cmd(mac是terminal), 执行</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">ollama serve
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">2024/08/03 14:52:24 routes.go:1011: INFO server config env=&#34;map[OLLAMA_DEBUG:false OLLAMA_FLASH_ATTENTION:false OLLAMA_HOST:http://127.0.0.1:11434 OLLAMA_KEEP_ALIVE: OLLAMA_LLM_LIBRARY: OLLAMA_MAX_LOADED_MODELS:1 OLLAMA_MAX_QUEUE:512 OLLAMA_MAX_VRAM:0 OLLAMA_MODELS:/Users/deng/.ollama/models OLLAMA_NOHISTORY:false OLLAMA_NOPRUNE:false OLLAMA_NUM_PARALLEL:1 OLLAMA_ORIGINS:[http://localhost https://localhost http://localhost:* https://localhost:* http://127.0.0.1 https://127.0.0.1 http://127.0.0.1:* https://127.0.0.1:* http://0.0.0.0 https://0.0.0.0 http://0.0.0.0:* https://0.0.0.0:* app://* file://* tauri://*] OLLAMA_RUNNERS_DIR: OLLAMA_TMPDIR:]&#34;
time=2024-08-03T14:52:24.742+08:00 level=INFO source=images.go:725 msg=&#34;total blobs: 18&#34;
time=2024-08-03T14:52:24.742+08:00 level=INFO source=images.go:732 msg=&#34;total unused blobs removed: 0&#34;
time=2024-08-03T14:52:24.743+08:00 level=INFO source=routes.go:1057 msg=&#34;Listening on 127.0.0.1:11434 (version 0.1.44)&#34;
time=2024-08-03T14:52:24.744+08:00 level=INFO source=payload.go:30 msg=&#34;extracting embedded files&#34; dir=/var/folders/y0/4gqxky0s2t94x1c1qhlwr6100000gn/T/ollama4239159529/runners
time=2024-08-03T14:52:24.772+08:00 level=INFO source=payload.go:44 msg=&#34;Dynamic LLM libraries [metal]&#34;
time=2024-08-03T14:52:24.796+08:00 level=INFO source=types.go:71 msg=&#34;inference compute&#34; id=0 library=metal compute=&#34;&#34; driver=0.0 name=&#34;&#34; total=&#34;72.0 GiB&#34; available=&#34;72.0 GiB&#34;
</code></pre></div><p>cmd(mac是terminal)看到如上的信息，说明本地ollama服务已开启。</p>
<br>
<br>
<h2 id="三实验">三、实验</h2>
<h3 id="31-代码结构">3.1 代码结构</h3>
<p>点击下载本文 <a href="project.zip">实验代码</a></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">project
   |
  - Extract_Metadata_With_Large_Language_Models.ipynb
  - prompts
       |--- scientific_papers_prompt.txt
  - data
      |--- 1706.03762v7.pdf
      |--- 2301.09056v1.pdf
  - extracted_metadata/
</code></pre></div><br>
<ul>
<li><em><strong>project文件夹</strong></em> 是根文件夹，包含 <em><strong>ipynb代码文件</strong></em>、 <em><strong>prompts文件夹</strong></em>、<em><strong>data文件夹</strong></em>、<em><strong>extracted_metadata文件夹</strong></em></li>
<li><em><strong>prompts文件夹</strong></em> 有txt文件格式的提示信息</li>
<li><em><strong>data文件夹</strong></em> 存储着实验论文pdf数据</li>
<li><em><strong>extracted_metadata文件夹</strong></em> 目前为空，将存储从论文pdf中提取的元信息，以 json 文件格式存储</li>
</ul>
<br>
<h3 id="32-提示工程">3.2 提示工程</h3>
<p>我们需要从论文pdf中提取</p>
<ul>
<li>论文标题</li>
<li>出版年份</li>
<li>作者</li>
<li>联系作者</li>
<li>抽象的</li>
<li>摘要</li>
</ul>
<p>这是我设计的提示， 该提示存储在 <em><strong>prompts/scientific_papers_prompt.txt</strong></em> 中。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">科学研究论文</span><span class="err">：</span>
<span class="o">---</span> 
<span class="p">{</span><span class="n">document</span><span class="p">}</span> 
<span class="o">---</span>

<span class="n">您是分析科学研究论文的专家</span><span class="err">。</span> <span class="n">请仔细阅读上面提供的研究论文</span><span class="err">，</span><span class="n">并提取以下关键信息</span><span class="err">：</span>

<span class="n">从研究论文中提取以下六</span> <span class="p">(</span><span class="mi">6</span><span class="p">)</span> <span class="n">个属性</span><span class="err">：</span>
<span class="o">-</span> <span class="n">论文标题</span><span class="err">：</span><span class="n">研究论文的全名</span>
<span class="o">-</span> <span class="n">出版年份</span><span class="err">：</span><span class="n">论文发表的年份</span>
<span class="o">-</span> <span class="n">作者</span><span class="err">：</span><span class="n">论文所有作者的全名</span>
<span class="o">-</span> <span class="n">作者联系方式</span><span class="err">：</span><span class="n">字典列表</span><span class="err">，</span><span class="n">其中每个字典包含每个作者的以下键</span><span class="err">：</span>
  <span class="o">-</span> <span class="n">姓名</span><span class="err">：</span><span class="n">作者的全名</span>
  <span class="o">-</span> <span class="n">机构</span><span class="err">：</span><span class="n">作者的机构隶属关系</span>
  <span class="o">-</span> <span class="n">电子邮件</span><span class="err">：</span><span class="n">作者的电子邮件地址</span><span class="err">（</span><span class="n">如果提供</span><span class="err">）</span>
<span class="o">-</span> <span class="n">摘要</span><span class="err">：</span><span class="n">论文摘要的全文</span>
<span class="o">-</span> <span class="n">摘要总结</span><span class="err">：</span><span class="n">用</span> <span class="mi">2</span><span class="o">-</span><span class="mi">3</span> <span class="n">句话简洁地总结摘要</span><span class="err">，</span><span class="n">突出重点</span>

<span class="n">指南</span><span class="err">：</span>
<span class="o">-</span> <span class="n">提取的信息应属实</span><span class="err">，</span><span class="n">并准确无误</span><span class="err">。</span>
<span class="o">-</span> <span class="n">除摘要外</span><span class="err">，</span><span class="n">应极其简洁</span><span class="err">，</span><span class="n">摘要应完整复制</span><span class="err">。</span>
<span class="o">-</span> <span class="n">提取的实体应该是独立的</span><span class="err">，</span><span class="n">并且不需要论文的其余部分就能轻松理解</span><span class="err">。</span>
<span class="o">-</span> <span class="n">如果论文中缺少任何属性</span><span class="err">，</span><span class="n">请将该字段留空</span><span class="err">，</span><span class="n">而不是猜测</span><span class="err">。</span>
<span class="o">-</span> <span class="n">对于摘要总结</span><span class="err">，</span><span class="n">重点介绍研究的主要目标</span><span class="err">、</span><span class="n">方法和主要发现</span><span class="err">。</span>
<span class="o">-</span> <span class="n">对于作者联系方式</span><span class="err">，</span><span class="n">请为每个作者创建一个条目</span><span class="err">，</span><span class="n">即使缺少一些信息</span><span class="err">。</span><span class="n">如果没有提供作者的电子邮件或机构</span><span class="err">，</span><span class="n">请在字典中将该字段留空</span><span class="err">。</span>

<span class="n">以</span> <span class="n">JSON</span> <span class="n">格式回答</span><span class="err">。</span> <span class="n">JSON</span> <span class="n">应包含</span> <span class="mi">6</span> <span class="n">个键</span><span class="err">：</span><span class="s2">&#34;PaperTitle&#34;</span><span class="p">,</span> <span class="s2">&#34;PublicationYear&#34;</span><span class="p">,</span> <span class="s2">&#34;Authors&#34;</span><span class="p">,</span> <span class="s2">&#34;AuthorContact&#34;</span><span class="p">,</span> <span class="s2">&#34;Abstract&#34;</span><span class="p">,</span> <span class="s2">&#34;SummaryAbstract&#34;</span><span class="err">。</span> <span class="s2">&#34;AuthorContact&#34;</span><span class="n">字段应该是字典列表格式</span><span class="err">。</span>
</code></pre></div><br>
<h3 id="32-提取信息">3.2 提取信息</h3>
<p>读取 <em><strong>data/1706.03762v7.pdf</strong></em>， 提取该论文首页中感兴趣的6个信息，如</p>
<p><img loading="lazy" src="img/6-paper.png" alt=""  />
</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="o">%%</span><span class="n">time</span>

<span class="kn">import</span> <span class="nn">ollama</span>
<span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>  
<span class="c1">#cntext版本为2.1.2，非开源， #需联系大邓372335839获取</span>

<span class="c1">#我们感兴趣的信息在论文的第一页，所以这里粗糙的选择前4000个字符。</span>
<span class="n">paper_content</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">read_pdf</span><span class="p">(</span><span class="s1">&#39;data/1706.03762v7.pdf&#39;</span><span class="p">)[:</span><span class="mi">4000</span><span class="p">]</span>
<span class="n">prompt_content</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;prompts/scientific_papers_prompt.txt&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>

<span class="n">response</span> <span class="o">=</span> <span class="n">ollama</span><span class="o">.</span><span class="n">chat</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s1">&#39;llama3.1:8b&#39;</span><span class="p">,</span> 
                       <span class="n">messages</span> <span class="o">=</span> <span class="p">[</span>
                           <span class="p">{</span><span class="s1">&#39;role&#39;</span><span class="p">:</span> <span class="s1">&#39;system&#39;</span><span class="p">,</span> <span class="s1">&#39;content&#39;</span><span class="p">:</span> <span class="n">prompt_content</span><span class="p">},</span>
                           <span class="p">{</span><span class="s1">&#39;role&#39;</span><span class="p">:</span> <span class="s1">&#39;user&#39;</span><span class="p">,</span> <span class="s1">&#39;content&#39;</span><span class="p">:</span> <span class="n">paper_content</span><span class="p">}</span>
                       <span class="p">])</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">response</span><span class="p">[</span><span class="s1">&#39;message&#39;</span><span class="p">][</span><span class="s1">&#39;content&#39;</span><span class="p">]</span>
<span class="n">result</span> <span class="o">=</span> <span class="nb">eval</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;```</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">```&#39;</span><span class="p">)[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">result</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">CPU times: user 3.5 ms, sys: 2.13 ms, total: 5.63 ms
Wall time: 11.8 s


{&#39;PaperTitle&#39;: &#39;Attention Is All You Need&#39;,
 &#39;PublicationYear&#39;: 2017,
 &#39;Authors&#39;: [&#39;Ashish Vaswani&#39;,
  &#39;Noam Shazeer&#39;,
  &#39;Niki Parmar&#39;,
  &#39;Jakob Uszkoreit&#39;,
  &#39;Llion Jones&#39;,
  &#39;Aidan N. Gomez&#39;,
  &#39;Łukasz Kaiser&#39;,
  &#39;Illia Polosukhin&#39;],
 &#39;AuthorContact&#39;: [{&#39;Name&#39;: &#39;Ashish Vaswani&#39;,
   &#39;Institution&#39;: &#39;Google Brain&#39;,
   &#39;Email&#39;: &#39;avaswani@google.com&#39;},
  {&#39;Name&#39;: &#39;Noam Shazeer&#39;,
   &#39;Institution&#39;: &#39;Google Brain&#39;,
   &#39;Email&#39;: &#39;noam@google.com&#39;},
  {&#39;Name&#39;: &#39;Niki Parmar&#39;,
   &#39;Institution&#39;: &#39;Google Research&#39;,
   &#39;Email&#39;: &#39;nikip@google.com&#39;},
  {&#39;Name&#39;: &#39;Jakob Uszkoreit&#39;,
   &#39;Institution&#39;: &#39;Google Research&#39;,
   &#39;Email&#39;: &#39;usz@google.com&#39;},
  {&#39;Name&#39;: &#39;Llion Jones&#39;,
   &#39;Institution&#39;: &#39;Google Research&#39;,
   &#39;Email&#39;: &#39;llion@google.com&#39;},
  {&#39;Name&#39;: &#39;Aidan N. Gomez&#39;,
   &#39;Institution&#39;: &#39;University of Toronto&#39;,
   &#39;Email&#39;: &#39;aidan@cs.toronto.edu&#39;},
  {&#39;Name&#39;: &#39;Łukasz Kaiser&#39;,
   &#39;Institution&#39;: &#39;Google Brain&#39;,
   &#39;Email&#39;: &#39;lukaszkaiser@google.com&#39;},
  {&#39;Name&#39;: &#39;Illia Polosukhin&#39;,
   &#39;Institution&#39;: &#39;&#39;,
   &#39;Email&#39;: &#39;illia.polosukhin@gmail.com&#39;}],
 &#39;Abstract&#39;: &#39;The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely.&#39;,
 &#39;SummaryAbstract&#39;: &#39;本文提出了一种新的Transformer模型，基于注意力机制，抛弃了递归和卷积等复杂方法。该模型在机器翻译任务上表现出优异的效果，并且可以更好地并行化和训练。&#39;}
</code></pre></div><p>从运行结果看， 摘要<em><strong>Abstract</strong></em> 的提取不够准确，有一定的遗漏。</p>
<br>
<h3 id="33-封装成函数extract_info">3.3 封装成函数extract_info</h3>
<p>实验成功，我们将其封装为函数<em><strong>extract_info</strong></em> ，因为LLM返回的内容的格式存在不确定性， 所以为了保证函数尽可能的成功的运行出结果，这里我设置了异常处理机制。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">ollama</span>
<span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>  
<span class="c1">#cntext版本为2.1.2，非开源， #需联系大邓372335839获取</span>


<span class="k">def</span> <span class="nf">extract_info</span><span class="p">(</span><span class="n">paper_content</span><span class="p">,</span> <span class="n">prompt_content</span><span class="p">,</span> <span class="n">max_retries</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">attempt</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_retries</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">response</span> <span class="o">=</span> <span class="n">ollama</span><span class="o">.</span><span class="n">chat</span><span class="p">(</span>
                <span class="n">model</span><span class="o">=</span><span class="s1">&#39;llama3.1:8b&#39;</span><span class="p">,</span>
                <span class="n">messages</span><span class="o">=</span><span class="p">[</span>
                    <span class="p">{</span><span class="s1">&#39;role&#39;</span><span class="p">:</span> <span class="s1">&#39;system&#39;</span><span class="p">,</span> <span class="s1">&#39;content&#39;</span><span class="p">:</span> <span class="n">prompt_content</span><span class="p">},</span>
                    <span class="p">{</span><span class="s1">&#39;role&#39;</span><span class="p">:</span> <span class="s1">&#39;user&#39;</span><span class="p">,</span> <span class="s1">&#39;content&#39;</span><span class="p">:</span> <span class="n">paper_content</span><span class="p">}</span>
                <span class="p">]</span>
            <span class="p">)</span>

            <span class="n">result</span> <span class="o">=</span> <span class="n">response</span><span class="p">[</span><span class="s1">&#39;message&#39;</span><span class="p">][</span><span class="s1">&#39;content&#39;</span><span class="p">]</span>
            <span class="n">result</span> <span class="o">=</span> <span class="nb">eval</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;```</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">```&#39;</span><span class="p">)[</span><span class="mi">0</span><span class="p">])</span>
            <span class="k">return</span> <span class="n">result</span>
        
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">attempt</span> <span class="o">&lt;</span> <span class="n">max_retries</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;An error occurred: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">. Retrying (</span><span class="si">{</span><span class="n">attempt</span> <span class="o">+</span> <span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">max_retries</span> <span class="o">+</span> <span class="mi">1</span><span class="si">}</span><span class="s2">)...&#34;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="n">e</span>


<span class="c1">#我们感兴趣的信息在论文的第一页，所以这里粗糙的选择前4000个字符。</span>
<span class="n">paper_content</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">read_pdf</span><span class="p">(</span><span class="s1">&#39;data/1706.03762v7.pdf&#39;</span><span class="p">)[:</span><span class="mi">4000</span><span class="p">]</span>
<span class="n">prompt_content</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;prompts/scientific_papers_prompt.txt&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">extract_info</span><span class="p">(</span><span class="n">paper_content</span><span class="p">,</span> <span class="n">prompt_content</span><span class="p">)</span>
<span class="n">result</span>
</code></pre></div><p>运行结果与之前无异，为节约板面空间，这里就不展示result了。</p>
<br>
<h3 id="34-批量提取">3.4 批量提取</h3>
<p>假设data文件夹内有成百上千的发票(实际上只有一张发票)， 对data文件夹进行批量信息提取，结果存储为csv。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="o">%%</span><span class="n">time</span>

<span class="kn">import</span> <span class="nn">os</span>
<span class="c1">#cntext版本为2.1.3，非开源，需联系大邓372335839获取</span>
<span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">jsonlines</span>

<span class="c1">#当前代码所在的代码文件与data文件夹处于同一个文件夹内</span>
<span class="c1">#获取data内所有pdf的路径</span>
<span class="n">pdf_files</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s1">&#39;data/</span><span class="si">{</span><span class="n">file</span><span class="si">}</span><span class="s1">&#39;</span> <span class="k">for</span> <span class="n">file</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="s1">&#39;data&#39;</span><span class="p">)</span> <span class="k">if</span> <span class="s1">&#39;.pdf&#39;</span> <span class="ow">in</span> <span class="n">file</span><span class="p">]</span>
<span class="n">prompt_content</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;prompts/scientific_papers_prompt.txt&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>

<span class="k">for</span> <span class="n">pdf_file</span> <span class="ow">in</span> <span class="n">pdf_files</span><span class="p">:</span>
    <span class="n">paper_content</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">read_pdf</span><span class="p">(</span><span class="n">pdf_file</span><span class="p">)[:</span><span class="mi">4000</span><span class="p">]</span>
    <span class="n">dict_data</span> <span class="o">=</span> <span class="n">extract_info</span><span class="p">(</span><span class="n">paper_content</span><span class="p">,</span> <span class="n">prompt_content</span><span class="p">)</span>
    <span class="n">jsonf</span> <span class="o">=</span> <span class="n">pdf_file</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;data&#39;</span><span class="p">,</span> <span class="s1">&#39;extracted_metadata&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;pdf&#39;</span><span class="p">,</span> <span class="s1">&#39;jsonl&#39;</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">jsonlines</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">jsonf</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">jf</span><span class="p">:</span>
        <span class="n">jf</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">dict_data</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">CPU times: user 919 ms, sys: 14.8 ms, total: 933 ms
Wall time: 24.6 s
</code></pre></div><p><img loading="lazy" src="img/05-2result-json.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="四讨论">四、讨论</h2>
<p>本文简要概述了 LLM 在从复杂文档中提取元数据方面的应用，提取的 json 数据可以存储在非关系数据库中以供进一步分析。</p>
<p>LLM 和 Regex 在内容提取方面各有优缺点，应根据用例明智地应用每种方法。希望本简短教程能帮助您获得新技能。</p>
<br>
<br>
<h2 id="相关内容">相关内容</h2>
<ul>
<li><a href="https://textdata.cn/blog/2025-02-14-using-online-large-model-api-to-transform-text-data-into-structured-data/"><strong>教程 | 使用大模型将文本数据转化为结构化数据</strong></a></li>
<li><a href="https://textdata.cn/blog/2024-06-14-how-to-download-large-language-model-with-ollama/"><strong>教程 | 如何使用 Ollama 下载 &amp; 使用本地大语言模型</strong></a></li>
<li><a href="https://textdata.cn/blog/2024-08-06-using-the-ollama-local-large-model-to-predict-the-sentiment-category-of-online-comments/"><strong>实验 | 使用本地大模型预测在线评论情感类别和分值</strong></a></li>
<li><a href="https://textdata.cn/blog/2024-08-07-structured-outputs-with-ollama/"><strong>实验 | 如何使 Ollama 结构化输出 JSON 样式的结果</strong></a></li>
<li><a href="https://textdata.cn/blog/2024-04-27-cntext2x-usage-tutorial/"><strong>推荐 | 文本分析库cntext2.x使用手册</strong></a></li>
<li><a href="https://textdata.cn/blog/2024-06-14-using-large-language-model-to-extract-structure-data-from-raw-text/"><strong>实验 | 使用本地大模型从文本中提取结构化信息</strong></a></li>
<li><a href="https://textdata.cn/blog/2024-07-10-using-large-language-model-to-build-diy-dictionary/">实验 | 使用Ollama本地大模型DIY制作单词书教案PDF</a></li>
<li><a href="https://textdata.cn/blog/2024-08-05-create-a-blog-writer-multi-agent-system-using-crewai-and-ollama/">实验 | 使用 Crewai 和 Ollama 构建智能体(AI Agent)帮我撰写博客文章</a></li>
</ul>
<br>
<br>
<h2 id="精选内容">精选内容</h2>
<ul>
<li><a href="https://textdata.cn/blog/datasets_available_for_management_science/">LIST | 可供社科(经管)领域使用的数据集汇总</a></li>
<li><a href="https://textdata.cn/blog/the_text_analysis_list_about_ms/">LIST | 社科(经管)数据挖掘文献资料汇总</a></li>
<li><a href="https://textdata.cn/blog/2024-06-16-scrapegraph-ai/">网络爬虫 | 使用scrapegraph-ai(大模型方案)自动采集网页数据</a></li>
<li><a href="https://textdata.cn/blog/2024-04-27-cntext2x-usage-tutorial/">推荐 | 文本分析库cntext2.x使用手册</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a>
<br>
<br></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>实验 | 使用Ollama本地大模型DIY制作单词书教案PDF</title>
      <link>https://textdata.cn/blog/2024-07-10-using-large-language-model-to-build-diy-dictionary/</link>
      <pubDate>Wed, 10 Jul 2024 00:00:00 +0000</pubDate>
      
      <guid>/blog/2024-07-10-using-large-language-model-to-build-diy-dictionary/</guid>
      <description>&lt;h2 id=&#34;一任务描述&#34;&gt;一、任务描述&lt;/h2&gt;
&lt;p&gt;前几天分享了 &lt;a href=&#34;https://textdata.cn/blog/2024-06-14-using-large-language-model-to-extract-structure-data-from-raw-text/&#34;&gt;实验 | 使用本地大模型从文本中提取结构化信息&lt;/a&gt; ，今天实验一个成功率更高的使用场景，生成单词书教案PDF。&lt;br&gt;&lt;/p&gt;
&lt;br&gt;
&lt;p&gt;假设你是英语老师，你希望在单词书中增加历史文化方面的信息， 市面上的单词书并不能很好的满足你的需要。针对这一需求， 我们可以利用大模型，定制你的单词书教案。例如单词 &lt;em&gt;&lt;strong&gt;abandon&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/07-pixyII.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/07-pdf.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;二ollama介绍&#34;&gt;二、Ollama介绍&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://ollama.ai/&#34;&gt;&lt;strong&gt;Ollama&lt;/strong&gt;&lt;/a&gt;是一款开源应用程序，可让您使用 MacOS、Linux 和 Windows 上的命令行界面在本地运行、创建和共享大型语言模型。&lt;/p&gt;
&lt;p&gt;Ollama 可以直接从其库中访问各种 LLM，只需一个命令即可下载。下载后，只需执行一个命令即可开始使用。这对于工作量围绕终端窗口的用户非常有帮助。如果他们被困在某个地方，他们可以在不切换到另一个浏览器窗口的情况下获得答案。&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;21-特点和优点&#34;&gt;2.1 特点和优点&lt;/h3&gt;
&lt;p&gt;这就是为什么 OLLAMA 是您的工具包中必备的工具：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;简单&lt;/strong&gt; ：OLLAMA 提供简单的设置过程。您无需拥有机器学习博士学位即可启动和运行它。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;成本效益&lt;/strong&gt; ：在本地运行模型意味着您无需支付云成本。您的钱包会感谢您。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;隐私&lt;/strong&gt; ：使用 OLLAMA，所有数据处理都在您的本地机器上进行。这对于用户隐私来说是一个巨大的胜利。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;多功能性&lt;/strong&gt; ：OLLAMA 不只是为 Python 爱好者准备的。它的灵活性使其可以用于各种应用程序，包括 Web 开发。&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
&lt;h3 id=&#34;22-使用-ollama-进行-llm-选择&#34;&gt;2.2 使用 Ollama 进行 LLM 选择&lt;/h3&gt;
&lt;p&gt;默认情况下，Openai Models 在 CrewAI 中用作 llm。有经费、有网络、不担心数据泄露等条件下,  力求达到最佳性能，可考虑使用 GPT-4 或 OpenAI 稍便宜的 GPT-3.5。&lt;/p&gt;
&lt;p&gt;但本文是要 &lt;strong&gt;本地部署&lt;/strong&gt;， 因此我们将使用 Meta Llama 3，这是迄今为止功能最强大的公开 LLM。Meta Llama 3 是 Meta Inc. 开发的模型系列，是最新推出的模型，具有 8B 和 70B 两种参数大小（预训练或指令调整）。Llama 3 指令调整模型针对对话/聊天用例进行了微调和优化，并且在常见基准测试中胜过许多可用的开源聊天模型。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/01-llama3-performance.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/02-llama3-performance.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;h2 id=&#34;二准备工作&#34;&gt;二、准备工作&lt;/h2&gt;
&lt;h3 id=&#34;21-安装ollama&#34;&gt;2.1 安装ollama&lt;/h3&gt;
&lt;p&gt;点击前往网站 &lt;a href=&#34;https://ollama.com/&#34;&gt;https://ollama.com/&lt;/a&gt; ，下载ollama软件，支持win、Mac、linux&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/03-ollama-gui.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;22-下载llm&#34;&gt;2.2 下载LLM&lt;/h3&gt;
&lt;p&gt;ollama软件目前支持多种大模型， 如阿里的（qwen、qwen2）、meta的(llama3)，&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/04-ollama-model.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;p&gt;以llama3为例，根据自己电脑显存性能， 选择适宜的版本。如果不知道选什么，那就试着安装，不合适不能用再删除即可。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/05-ollama-llama3.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;p&gt;打开电脑命令行cmd(mac是terminal),  网络是连网状态，执行模型下载(安装)命令&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;ollama pull llama3
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;等待 &lt;strong&gt;llama3:8b&lt;/strong&gt; 下载完成。&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;23-安装python包&#34;&gt;2.3 安装python包&lt;/h3&gt;
&lt;p&gt;在python中调用ollama服务，需要ollama包。&lt;/p&gt;
&lt;p&gt;打开电脑命令行cmd(mac是terminal),  网络是连网状态，执行安装命令&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;pip3 install ollama
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h3 id=&#34;24-启动ollama服务&#34;&gt;2.4 启动ollama服务&lt;/h3&gt;
&lt;p&gt;在Python中调用本地ollama服务，需要先启动本地ollama服务， 打开电脑命令行cmd(mac是terminal), 执行&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;ollama serve
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;2024/06/14 14:52:24 routes.go:1011: INFO server config env=&amp;#34;map[OLLAMA_DEBUG:false OLLAMA_FLASH_ATTENTION:false OLLAMA_HOST:http://127.0.0.1:11434 OLLAMA_KEEP_ALIVE: OLLAMA_LLM_LIBRARY: OLLAMA_MAX_LOADED_MODELS:1 OLLAMA_MAX_QUEUE:512 OLLAMA_MAX_VRAM:0 OLLAMA_MODELS:/Users/deng/.ollama/models OLLAMA_NOHISTORY:false OLLAMA_NOPRUNE:false OLLAMA_NUM_PARALLEL:1 OLLAMA_ORIGINS:[http://localhost https://localhost http://localhost:* https://localhost:* http://127.0.0.1 https://127.0.0.1 http://127.0.0.1:* https://127.0.0.1:* http://0.0.0.0 https://0.0.0.0 http://0.0.0.0:* https://0.0.0.0:* app://* file://* tauri://*] OLLAMA_RUNNERS_DIR: OLLAMA_TMPDIR:]&amp;#34;
time=2024-06-14T14:52:24.742+08:00 level=INFO source=images.go:725 msg=&amp;#34;total blobs: 18&amp;#34;
time=2024-06-14T14:52:24.742+08:00 level=INFO source=images.go:732 msg=&amp;#34;total unused blobs removed: 0&amp;#34;
time=2024-06-14T14:52:24.743+08:00 level=INFO source=routes.go:1057 msg=&amp;#34;Listening on 127.0.0.1:11434 (version 0.1.44)&amp;#34;
time=2024-06-14T14:52:24.744+08:00 level=INFO source=payload.go:30 msg=&amp;#34;extracting embedded files&amp;#34; dir=/var/folders/y0/4gqxky0s2t94x1c1qhlwr6100000gn/T/ollama4239159529/runners
time=2024-06-14T14:52:24.772+08:00 level=INFO source=payload.go:44 msg=&amp;#34;Dynamic LLM libraries [metal]&amp;#34;
time=2024-06-14T14:52:24.796+08:00 level=INFO source=types.go:71 msg=&amp;#34;inference compute&amp;#34; id=0 library=metal compute=&amp;#34;&amp;#34; driver=0.0 name=&amp;#34;&amp;#34; total=&amp;#34;72.0 GiB&amp;#34; available=&amp;#34;72.0 GiB&amp;#34;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;cmd(mac是terminal)看到如上的信息，说明本地ollama服务已开启。&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;三实验&#34;&gt;三、实验&lt;/h2&gt;
&lt;h3 id=&#34;31-代码结构&#34;&gt;3.1 代码结构&lt;/h3&gt;
&lt;p&gt;点击下载&lt;a href=&#34;project.zip&#34;&gt;本文代码&lt;/a&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;project
  - 代码.ipynb #代码
  - prompt.txt #提示模板
  - words.csv  #准备的单词列表
  - word-dictionary.csv  #生成的单词书
  - Your-Diy-Dictionary.md #生成的带主题样式的单词书
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h3 id=&#34;32-设计提示&#34;&gt;3.2 设计提示&lt;/h3&gt;
&lt;p&gt;需要根据单词，生成单词、音标、语义、例句、历史文化、相关单词等信息， 提示如下，&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;单词：
--- 
{word} 
---
   
你是一名中英文双语教育专家，拥有帮助将中文视为母语的用户理解和记忆英语单词的专长，请根据用户提供的英语单词{word}完成任务。
                
# {word}
markdown一级标题#
[美音]美国音标，斜体加粗
                
## 语义
- 系统地分析用户提供的单词，并以简单易懂的方式解答；
                
## 例句
- 为该单词提供至少 3 个不同场景下的使用方法和例句。并且附上中文翻译，以帮助用户更深入地理解单词意义。其中英文例句加粗斜体！
                
## 历史文化
- 详细介绍单词的造词来源和发展历史，以及在欧美文化中的内涵
                
## 相关单词
- 列出单词对应的名词、单复数、动词、不同时态、形容词、副词等的变形以及对应的中文翻译。
               
## 词组搭配
- 列出单词对应的固定搭配、组词以及对应的中文翻译。


注意: 如非特别说明尽量用中文，结果返回markdown格式; 均为二级标题##， 无序列表用-而不是*。
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;该提示已存储到 &lt;em&gt;&lt;strong&gt;prompt.txt&lt;/strong&gt;&lt;/em&gt; 内。&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;33-小实验&#34;&gt;3.3 小实验&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;o&#34;&gt;%%&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;time&lt;/span&gt;

&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;ollama&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;#读取提示&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;prompt&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;open&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;prompt.txt&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;encoding&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;utf-8&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;

&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;diy_dictionary&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;word&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;response&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ollama&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;chat&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;model&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;llama3:8b&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;messages&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;
          &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;role&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;system&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;content&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;prompt&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;},&lt;/span&gt;
          &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;role&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;user&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;content&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;word&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;},&lt;/span&gt;
        &lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;

    &lt;span class=&#34;n&#34;&gt;result&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;response&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;message&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;][&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;content&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
    &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;result&lt;/span&gt;


&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;diy_dictionary&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;word&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;march&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;# March


[美音] /mɑːrtʃ/


## 语义
March 是指第三个月份，但它也可以用于其他场景：
- 在军事或政治上，March 可以表示进军、推动或实施某些措施。
- 在生活中，March 可以表示开始新的项目或计划。

## 例句
* **_The company will march into the new market next quarter._** - 公司将在下一个季度进入新市场。
* **_She&amp;#39;s been marching towards her goals for years, and now she&amp;#39;s finally achieved them._** - 她多年来一直朝着目标努力，现在终于实现了。
* **_The company will march into bankruptcy if they don&amp;#39;t receive new funding._** - 如果他们不能获得新的资金，公司将面临破产。

## 历史文化
March 是英语中的一个月份词语，源于古罗马语言。古罗马人将一年分为 12 个月，每个月份都有特定的名称和特征。 March 就是指春季的开端，是一月到三月的最后一个月份。

## 相关单词
- Noun: march, marches
- Verb: to march, marched, marching
- Adjective: march-like, martial
- Idiom: take a step forward (向前进步), take the initiative (采取主动)

## 词组搭配
- &amp;#34;take a step forward&amp;#34; (向前进步)
- &amp;#34;march towards&amp;#34; (朝着目标努力)
- &amp;#34;march into&amp;#34; (进入某个领域或状态)


Note: As a Chinese-English bilingual expert, I will provide the pronunciation in the American English accent and use markdown formatting.


CPU times: user 2.97 ms, sys: 2.83 ms, total: 5.8 ms
Wall time: 7.61 s
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h3 id=&#34;34-读取词表&#34;&gt;3.4 读取词表&lt;/h3&gt;
&lt;p&gt;假设你需要背 &lt;a href=&#34;words.csv&#34;&gt;&lt;em&gt;&lt;strong&gt;words.csv&lt;/strong&gt;&lt;/em&gt;&lt;/a&gt;中的单词，&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pandas&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pd&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read_csv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;words.csv&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/05-df.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;35-批量生成&#34;&gt;3.5 批量生成&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;o&#34;&gt;%%&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;time&lt;/span&gt;

&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;csv&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;ollama&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pandas&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pd&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;#读取提示&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;prompt&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;open&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;prompt.txt&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;encoding&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;utf-8&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;


&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;diy_dictionary&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;word&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;response&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ollama&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;chat&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;model&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;llama3:8b&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;messages&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;
          &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;role&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;system&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;content&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;prompt&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;},&lt;/span&gt;
          &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;role&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;user&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;content&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;word&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;},&lt;/span&gt;
        &lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;

    &lt;span class=&#34;n&#34;&gt;result&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;response&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;message&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;][&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;content&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
    &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;result&lt;/span&gt;
  


&lt;span class=&#34;c1&#34;&gt;#读取词表&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read_csv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;words.csv&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;Dictionary&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;Word&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;apply&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;diy_dictionary&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;


&lt;span class=&#34;c1&#34;&gt;#保存成csv和md&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;to_csv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;word-dictionary.csv&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;index&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;False&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;k&#34;&gt;with&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;open&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;Your-Diy-Dictionary.md&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;w&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;encoding&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;utf-8&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;mdf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;mdf&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;write&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\n&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;join&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;Dictionary&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]))&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/06-df.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;有些小失望， 如音标有的是 &lt;code&gt;[美音]&lt;/code&gt;，另一些是 &lt;code&gt;**美音**&lt;/code&gt;， 格式还不够统一。&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;36-生成单词书&#34;&gt;3.6 生成单词书&lt;/h3&gt;
&lt;h4 id=&#34;361-选择主题&#34;&gt;3.6.1 选择主题&lt;/h4&gt;
&lt;p&gt;打开 &lt;strong&gt;Typora&lt;/strong&gt;(一种markdown软件)， 选择一种自己喜欢的 &lt;strong&gt;主题Theme&lt;/strong&gt; ，&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/07-pixyII.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/07-hara.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/07-seniva.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;h4 id=&#34;362-导出pdf&#34;&gt;3.6.2 导出pdf&lt;/h4&gt;
&lt;p&gt;依次&lt;strong&gt;文件&amp;ndash;&amp;gt;导出&amp;ndash;&amp;gt;PDF或HTML&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/07-pdf.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;四讨论&#34;&gt;四、讨论&lt;/h2&gt;
&lt;p&gt;在本文中，我们展示了利用ollama制作单词书教案，实际上各位可以结合自身学习工作需要， 开发更多的应用场景。如果这份利用 ollama 自制教案对你有帮助，欢迎转发分享给你的朋友。 点击下载&lt;a href=&#34;project.zip&#34;&gt;本文代码&lt;/a&gt;&lt;/p&gt;
&lt;br&gt;
&lt;br&gt;
&lt;h2 id=&#34;精选内容&#34;&gt;精选内容&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/datasets_available_for_management_science/&#34;&gt;LIST | 可供社科(经管)领域使用的数据集汇总&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/the_text_analysis_list_about_ms/&#34;&gt;LIST | 社科(经管)数据挖掘文献资料汇总&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/2024-06-16-scrapegraph-ai/&#34;&gt;网络爬虫 | 使用scrapegraph-ai(大模型方案)自动采集网页数据&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/2024-04-27-cntext2x-usage-tutorial/&#34;&gt;推荐 | 文本分析库cntext2.x使用手册&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/management_python_course/&#34;&gt;付费视频课 | Python实证指标构建与文本分析&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/2024-06-14-using-large-language-model-to-extract-structure-data-from-raw-text/&#34;&gt;实验 | 使用本地大模型从文本中提取结构化信息&lt;/a&gt;
&lt;br&gt;
&lt;br&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
      <content:encoded><![CDATA[<h2 id="一任务描述">一、任务描述</h2>
<p>前几天分享了 <a href="https://textdata.cn/blog/2024-06-14-using-large-language-model-to-extract-structure-data-from-raw-text/">实验 | 使用本地大模型从文本中提取结构化信息</a> ，今天实验一个成功率更高的使用场景，生成单词书教案PDF。<br></p>
<br>
<p>假设你是英语老师，你希望在单词书中增加历史文化方面的信息， 市面上的单词书并不能很好的满足你的需要。针对这一需求， 我们可以利用大模型，定制你的单词书教案。例如单词 <em><strong>abandon</strong></em></p>
<p><img loading="lazy" src="img/07-pixyII.png" alt=""  />
</p>
<p><img loading="lazy" src="img/07-pdf.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="二ollama介绍">二、Ollama介绍</h2>
<p><a href="https://ollama.ai/"><strong>Ollama</strong></a>是一款开源应用程序，可让您使用 MacOS、Linux 和 Windows 上的命令行界面在本地运行、创建和共享大型语言模型。</p>
<p>Ollama 可以直接从其库中访问各种 LLM，只需一个命令即可下载。下载后，只需执行一个命令即可开始使用。这对于工作量围绕终端窗口的用户非常有帮助。如果他们被困在某个地方，他们可以在不切换到另一个浏览器窗口的情况下获得答案。</p>
<br>
<h3 id="21-特点和优点">2.1 特点和优点</h3>
<p>这就是为什么 OLLAMA 是您的工具包中必备的工具：</p>
<ul>
<li><strong>简单</strong> ：OLLAMA 提供简单的设置过程。您无需拥有机器学习博士学位即可启动和运行它。</li>
<li><strong>成本效益</strong> ：在本地运行模型意味着您无需支付云成本。您的钱包会感谢您。</li>
<li><strong>隐私</strong> ：使用 OLLAMA，所有数据处理都在您的本地机器上进行。这对于用户隐私来说是一个巨大的胜利。</li>
<li><strong>多功能性</strong> ：OLLAMA 不只是为 Python 爱好者准备的。它的灵活性使其可以用于各种应用程序，包括 Web 开发。</li>
</ul>
<br>
<h3 id="22-使用-ollama-进行-llm-选择">2.2 使用 Ollama 进行 LLM 选择</h3>
<p>默认情况下，Openai Models 在 CrewAI 中用作 llm。有经费、有网络、不担心数据泄露等条件下,  力求达到最佳性能，可考虑使用 GPT-4 或 OpenAI 稍便宜的 GPT-3.5。</p>
<p>但本文是要 <strong>本地部署</strong>， 因此我们将使用 Meta Llama 3，这是迄今为止功能最强大的公开 LLM。Meta Llama 3 是 Meta Inc. 开发的模型系列，是最新推出的模型，具有 8B 和 70B 两种参数大小（预训练或指令调整）。Llama 3 指令调整模型针对对话/聊天用例进行了微调和优化，并且在常见基准测试中胜过许多可用的开源聊天模型。</p>
<p><img loading="lazy" src="img/01-llama3-performance.png" alt=""  />
</p>
<p><img loading="lazy" src="img/02-llama3-performance.png" alt=""  />
</p>
<h2 id="二准备工作">二、准备工作</h2>
<h3 id="21-安装ollama">2.1 安装ollama</h3>
<p>点击前往网站 <a href="https://ollama.com/">https://ollama.com/</a> ，下载ollama软件，支持win、Mac、linux</p>
<p><img loading="lazy" src="img/03-ollama-gui.png" alt=""  />
</p>
<br>
<h3 id="22-下载llm">2.2 下载LLM</h3>
<p>ollama软件目前支持多种大模型， 如阿里的（qwen、qwen2）、meta的(llama3)，</p>
<p><img loading="lazy" src="img/04-ollama-model.png" alt=""  />
</p>
<br>
<p>以llama3为例，根据自己电脑显存性能， 选择适宜的版本。如果不知道选什么，那就试着安装，不合适不能用再删除即可。</p>
<p><img loading="lazy" src="img/05-ollama-llama3.png" alt=""  />
</p>
<br>
<p>打开电脑命令行cmd(mac是terminal),  网络是连网状态，执行模型下载(安装)命令</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">ollama pull llama3
</code></pre></div><p>等待 <strong>llama3:8b</strong> 下载完成。</p>
<br>
<h3 id="23-安装python包">2.3 安装python包</h3>
<p>在python中调用ollama服务，需要ollama包。</p>
<p>打开电脑命令行cmd(mac是terminal),  网络是连网状态，执行安装命令</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">pip3 install ollama
</code></pre></div><br>
<h3 id="24-启动ollama服务">2.4 启动ollama服务</h3>
<p>在Python中调用本地ollama服务，需要先启动本地ollama服务， 打开电脑命令行cmd(mac是terminal), 执行</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">ollama serve
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">2024/06/14 14:52:24 routes.go:1011: INFO server config env=&#34;map[OLLAMA_DEBUG:false OLLAMA_FLASH_ATTENTION:false OLLAMA_HOST:http://127.0.0.1:11434 OLLAMA_KEEP_ALIVE: OLLAMA_LLM_LIBRARY: OLLAMA_MAX_LOADED_MODELS:1 OLLAMA_MAX_QUEUE:512 OLLAMA_MAX_VRAM:0 OLLAMA_MODELS:/Users/deng/.ollama/models OLLAMA_NOHISTORY:false OLLAMA_NOPRUNE:false OLLAMA_NUM_PARALLEL:1 OLLAMA_ORIGINS:[http://localhost https://localhost http://localhost:* https://localhost:* http://127.0.0.1 https://127.0.0.1 http://127.0.0.1:* https://127.0.0.1:* http://0.0.0.0 https://0.0.0.0 http://0.0.0.0:* https://0.0.0.0:* app://* file://* tauri://*] OLLAMA_RUNNERS_DIR: OLLAMA_TMPDIR:]&#34;
time=2024-06-14T14:52:24.742+08:00 level=INFO source=images.go:725 msg=&#34;total blobs: 18&#34;
time=2024-06-14T14:52:24.742+08:00 level=INFO source=images.go:732 msg=&#34;total unused blobs removed: 0&#34;
time=2024-06-14T14:52:24.743+08:00 level=INFO source=routes.go:1057 msg=&#34;Listening on 127.0.0.1:11434 (version 0.1.44)&#34;
time=2024-06-14T14:52:24.744+08:00 level=INFO source=payload.go:30 msg=&#34;extracting embedded files&#34; dir=/var/folders/y0/4gqxky0s2t94x1c1qhlwr6100000gn/T/ollama4239159529/runners
time=2024-06-14T14:52:24.772+08:00 level=INFO source=payload.go:44 msg=&#34;Dynamic LLM libraries [metal]&#34;
time=2024-06-14T14:52:24.796+08:00 level=INFO source=types.go:71 msg=&#34;inference compute&#34; id=0 library=metal compute=&#34;&#34; driver=0.0 name=&#34;&#34; total=&#34;72.0 GiB&#34; available=&#34;72.0 GiB&#34;
</code></pre></div><p>cmd(mac是terminal)看到如上的信息，说明本地ollama服务已开启。</p>
<p><br><br></p>
<h2 id="三实验">三、实验</h2>
<h3 id="31-代码结构">3.1 代码结构</h3>
<p>点击下载<a href="project.zip">本文代码</a></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">project
  - 代码.ipynb #代码
  - prompt.txt #提示模板
  - words.csv  #准备的单词列表
  - word-dictionary.csv  #生成的单词书
  - Your-Diy-Dictionary.md #生成的带主题样式的单词书
</code></pre></div><br>
<h3 id="32-设计提示">3.2 设计提示</h3>
<p>需要根据单词，生成单词、音标、语义、例句、历史文化、相关单词等信息， 提示如下，</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">单词：
--- 
{word} 
---
   
你是一名中英文双语教育专家，拥有帮助将中文视为母语的用户理解和记忆英语单词的专长，请根据用户提供的英语单词{word}完成任务。
                
# {word}
markdown一级标题#
[美音]美国音标，斜体加粗
                
## 语义
- 系统地分析用户提供的单词，并以简单易懂的方式解答；
                
## 例句
- 为该单词提供至少 3 个不同场景下的使用方法和例句。并且附上中文翻译，以帮助用户更深入地理解单词意义。其中英文例句加粗斜体！
                
## 历史文化
- 详细介绍单词的造词来源和发展历史，以及在欧美文化中的内涵
                
## 相关单词
- 列出单词对应的名词、单复数、动词、不同时态、形容词、副词等的变形以及对应的中文翻译。
               
## 词组搭配
- 列出单词对应的固定搭配、组词以及对应的中文翻译。


注意: 如非特别说明尽量用中文，结果返回markdown格式; 均为二级标题##， 无序列表用-而不是*。
</code></pre></div><p>该提示已存储到 <em><strong>prompt.txt</strong></em> 内。</p>
<br>
<h3 id="33-小实验">3.3 小实验</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="o">%%</span><span class="n">time</span>

<span class="kn">import</span> <span class="nn">ollama</span>

<span class="c1">#读取提示</span>
<span class="n">prompt</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;prompt.txt&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">diy_dictionary</span><span class="p">(</span><span class="n">word</span><span class="p">):</span>
    <span class="n">response</span> <span class="o">=</span> <span class="n">ollama</span><span class="o">.</span><span class="n">chat</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s1">&#39;llama3:8b&#39;</span><span class="p">,</span> <span class="n">messages</span><span class="o">=</span><span class="p">[</span>
          <span class="p">{</span><span class="s1">&#39;role&#39;</span><span class="p">:</span> <span class="s1">&#39;system&#39;</span><span class="p">,</span> <span class="s1">&#39;content&#39;</span><span class="p">:</span> <span class="n">prompt</span><span class="p">},</span>
          <span class="p">{</span><span class="s1">&#39;role&#39;</span><span class="p">:</span> <span class="s1">&#39;user&#39;</span><span class="p">,</span> <span class="s1">&#39;content&#39;</span><span class="p">:</span> <span class="n">word</span><span class="p">},</span>
        <span class="p">])</span>

    <span class="n">result</span> <span class="o">=</span> <span class="n">response</span><span class="p">[</span><span class="s1">&#39;message&#39;</span><span class="p">][</span><span class="s1">&#39;content&#39;</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">result</span>


<span class="nb">print</span><span class="p">(</span><span class="n">diy_dictionary</span><span class="p">(</span><span class="n">word</span> <span class="o">=</span> <span class="s1">&#39;march&#39;</span><span class="p">))</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"># March


[美音] /mɑːrtʃ/


## 语义
March 是指第三个月份，但它也可以用于其他场景：
- 在军事或政治上，March 可以表示进军、推动或实施某些措施。
- 在生活中，March 可以表示开始新的项目或计划。

## 例句
* **_The company will march into the new market next quarter._** - 公司将在下一个季度进入新市场。
* **_She&#39;s been marching towards her goals for years, and now she&#39;s finally achieved them._** - 她多年来一直朝着目标努力，现在终于实现了。
* **_The company will march into bankruptcy if they don&#39;t receive new funding._** - 如果他们不能获得新的资金，公司将面临破产。

## 历史文化
March 是英语中的一个月份词语，源于古罗马语言。古罗马人将一年分为 12 个月，每个月份都有特定的名称和特征。 March 就是指春季的开端，是一月到三月的最后一个月份。

## 相关单词
- Noun: march, marches
- Verb: to march, marched, marching
- Adjective: march-like, martial
- Idiom: take a step forward (向前进步), take the initiative (采取主动)

## 词组搭配
- &#34;take a step forward&#34; (向前进步)
- &#34;march towards&#34; (朝着目标努力)
- &#34;march into&#34; (进入某个领域或状态)


Note: As a Chinese-English bilingual expert, I will provide the pronunciation in the American English accent and use markdown formatting.


CPU times: user 2.97 ms, sys: 2.83 ms, total: 5.8 ms
Wall time: 7.61 s
</code></pre></div><br>
<h3 id="34-读取词表">3.4 读取词表</h3>
<p>假设你需要背 <a href="words.csv"><em><strong>words.csv</strong></em></a>中的单词，</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;words.csv&#39;</span><span class="p">)</span>
<span class="n">df</span>
</code></pre></div><p><img loading="lazy" src="img/05-df.png" alt=""  />
</p>
<br>
<h3 id="35-批量生成">3.5 批量生成</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="o">%%</span><span class="n">time</span>

<span class="kn">import</span> <span class="nn">csv</span>
<span class="kn">import</span> <span class="nn">ollama</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="c1">#读取提示</span>
<span class="n">prompt</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;prompt.txt&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">diy_dictionary</span><span class="p">(</span><span class="n">word</span><span class="p">):</span>
    <span class="n">response</span> <span class="o">=</span> <span class="n">ollama</span><span class="o">.</span><span class="n">chat</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s1">&#39;llama3:8b&#39;</span><span class="p">,</span> <span class="n">messages</span><span class="o">=</span><span class="p">[</span>
          <span class="p">{</span><span class="s1">&#39;role&#39;</span><span class="p">:</span> <span class="s1">&#39;system&#39;</span><span class="p">,</span> <span class="s1">&#39;content&#39;</span><span class="p">:</span> <span class="n">prompt</span><span class="p">},</span>
          <span class="p">{</span><span class="s1">&#39;role&#39;</span><span class="p">:</span> <span class="s1">&#39;user&#39;</span><span class="p">,</span> <span class="s1">&#39;content&#39;</span><span class="p">:</span> <span class="n">word</span><span class="p">},</span>
        <span class="p">])</span>

    <span class="n">result</span> <span class="o">=</span> <span class="n">response</span><span class="p">[</span><span class="s1">&#39;message&#39;</span><span class="p">][</span><span class="s1">&#39;content&#39;</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">result</span>
  


<span class="c1">#读取词表</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;words.csv&#39;</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;Dictionary&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Word&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">diy_dictionary</span><span class="p">)</span>


<span class="c1">#保存成csv和md</span>
<span class="n">df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;word-dictionary.csv&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;Your-Diy-Dictionary.md&#39;</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">mdf</span><span class="p">:</span>
    <span class="n">mdf</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s1">&#39;&lt;br&gt;&lt;br&gt;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;Dictionary&#39;</span><span class="p">]))</span>

<span class="n">df</span>
</code></pre></div><p><img loading="lazy" src="img/06-df.png" alt=""  />
</p>
<p>有些小失望， 如音标有的是 <code>[美音]</code>，另一些是 <code>**美音**</code>， 格式还不够统一。</p>
<br>
<h3 id="36-生成单词书">3.6 生成单词书</h3>
<h4 id="361-选择主题">3.6.1 选择主题</h4>
<p>打开 <strong>Typora</strong>(一种markdown软件)， 选择一种自己喜欢的 <strong>主题Theme</strong> ，</p>
<p><img loading="lazy" src="img/07-pixyII.png" alt=""  />
</p>
<p><img loading="lazy" src="img/07-hara.png" alt=""  />
</p>
<p><img loading="lazy" src="img/07-seniva.png" alt=""  />
</p>
<br>
<h4 id="362-导出pdf">3.6.2 导出pdf</h4>
<p>依次<strong>文件&ndash;&gt;导出&ndash;&gt;PDF或HTML</strong></p>
<p><img loading="lazy" src="img/07-pdf.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="四讨论">四、讨论</h2>
<p>在本文中，我们展示了利用ollama制作单词书教案，实际上各位可以结合自身学习工作需要， 开发更多的应用场景。如果这份利用 ollama 自制教案对你有帮助，欢迎转发分享给你的朋友。 点击下载<a href="project.zip">本文代码</a></p>
<br>
<br>
<h2 id="精选内容">精选内容</h2>
<ul>
<li><a href="https://textdata.cn/blog/datasets_available_for_management_science/">LIST | 可供社科(经管)领域使用的数据集汇总</a></li>
<li><a href="https://textdata.cn/blog/the_text_analysis_list_about_ms/">LIST | 社科(经管)数据挖掘文献资料汇总</a></li>
<li><a href="https://textdata.cn/blog/2024-06-16-scrapegraph-ai/">网络爬虫 | 使用scrapegraph-ai(大模型方案)自动采集网页数据</a></li>
<li><a href="https://textdata.cn/blog/2024-04-27-cntext2x-usage-tutorial/">推荐 | 文本分析库cntext2.x使用手册</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
<li><a href="https://textdata.cn/blog/2024-06-14-using-large-language-model-to-extract-structure-data-from-raw-text/">实验 | 使用本地大模型从文本中提取结构化信息</a>
<br>
<br></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>网络爬虫 | 使用scrapegraph-ai(大模型方案)自动采集网页数据</title>
      <link>https://textdata.cn/blog/2024-06-16-scrapegraph-ai/</link>
      <pubDate>Sun, 16 Jun 2024 00:00:00 +0000</pubDate>
      
      <guid>/blog/2024-06-16-scrapegraph-ai/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;前几日分享了&lt;a href=&#34;https://textdata.cn/blog/2024-06-14-using-large-language-model-to-extract-structure-data-from-raw-text/&#34;&gt;实验 | 使用本地大模型从文本中提取结构化信息&lt;/a&gt;, 今天再分享一个  &lt;a href=&#34;https://github.com/VinciGit00/Scrapegraph-ai&#34;&gt;ScrapeGraphAI库&lt;/a&gt;， 现在还不太好用，但未来写爬虫很可能会变得越来越容易。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;br&gt;
&lt;h2 id=&#34;一介绍&#34;&gt;一、介绍&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;ScrapeGraphAI&lt;/strong&gt;&lt;/em&gt;是一个&lt;em&gt;网络爬虫&lt;/em&gt; Python 库，使用大型语言模型和直接图逻辑为网站和本地文档（XML，HTML，JSON 等）创建爬取管道。&lt;/p&gt;
&lt;p&gt;只需告诉库您想提取哪些信息，它将为您完成！&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/scrapegraphai_logo.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;scrapegraphai有三种主要的爬取管道可用于从网站（或本地文件）提取信息：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;SmartScraperGraph&lt;/code&gt;: 单页爬虫，只需用户提示和输入源；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;SearchGraph&lt;/code&gt;: 多页爬虫，从搜索引擎的前 n 个搜索结果中提取信息；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;SpeechGraph&lt;/code&gt;: 单页爬虫，从网站提取信息并生成音频文件。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;SmartScraperMultiGraph&lt;/code&gt;: 多页爬虫，给定一个提示 可以通过 API 使用不同的 LLM，如 &lt;strong&gt;OpenAI&lt;/strong&gt;，&lt;strong&gt;Groq&lt;/strong&gt;，&lt;strong&gt;Azure&lt;/strong&gt; 和 &lt;strong&gt;Gemini&lt;/strong&gt;，或者使用 &lt;strong&gt;Ollama&lt;/strong&gt; 的本地模型。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;二准备工作&#34;&gt;二、准备工作&lt;/h2&gt;
&lt;h3 id=&#34;121-安装ollama&#34;&gt;12.1 安装ollama&lt;/h3&gt;
&lt;p&gt;点击前往网站 &lt;a href=&#34;https://ollama.com/&#34;&gt;https://ollama.com/&lt;/a&gt; ，下载ollama软件，支持win、Mac、linux&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/02-ollama-gui.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;22-下载llm&#34;&gt;2.2 下载LLM&lt;/h3&gt;
&lt;p&gt;ollama软件目前支持多种大模型， 如阿里的（qwen、qwen2）、meta的(llama3)，&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/03-ollama-model.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;p&gt;以llama3为例，根据自己电脑显存性能， 选择适宜的版本。如果不知道选什么，那就试着安装，不合适不能用再删除即可。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/04-ollama-llama3.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;p&gt;打开电脑命令行cmd(mac是terminal),  网络是连网状态，执行模型下载(安装)命令&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;ollama pull llama3
ollama pull qwen2
ollama pull nomic-embed-text
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;等待 &lt;strong&gt;llama3、 nomic-embed-text&lt;/strong&gt; 下载完成。&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;23-安装python包&#34;&gt;2.3 安装python包&lt;/h3&gt;
&lt;p&gt;在python中调用ollama服务，需要ollama包。&lt;/p&gt;
&lt;p&gt;打开电脑命令行cmd(mac是terminal),  网络是连网状态，执行安装命令&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;pip3 install ollama
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h3 id=&#34;24-启动ollama服务&#34;&gt;2.4 启动ollama服务&lt;/h3&gt;
&lt;p&gt;在Python中调用本地ollama服务，需要先启动本地ollama服务， 打开电脑命令行cmd(mac是terminal), 执行&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;ollama serve
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;2024/06/14 14:52:24 routes.go:1011: INFO server config env=&amp;#34;map[OLLAMA_DEBUG:false OLLAMA_FLASH_ATTENTION:false OLLAMA_HOST:http://127.0.0.1:11434 OLLAMA_KEEP_ALIVE: OLLAMA_LLM_LIBRARY: OLLAMA_MAX_LOADED_MODELS:1 OLLAMA_MAX_QUEUE:512 OLLAMA_MAX_VRAM:0 OLLAMA_MODELS:/Users/deng/.ollama/models OLLAMA_NOHISTORY:false OLLAMA_NOPRUNE:false OLLAMA_NUM_PARALLEL:1 OLLAMA_ORIGINS:[http://localhost https://localhost http://localhost:* https://localhost:* http://127.0.0.1 https://127.0.0.1 http://127.0.0.1:* https://127.0.0.1:* http://0.0.0.0 https://0.0.0.0 http://0.0.0.0:* https://0.0.0.0:* app://* file://* tauri://*] OLLAMA_RUNNERS_DIR: OLLAMA_TMPDIR:]&amp;#34;
time=2024-06-14T14:52:24.742+08:00 level=INFO source=images.go:725 msg=&amp;#34;total blobs: 18&amp;#34;
time=2024-06-14T14:52:24.742+08:00 level=INFO source=images.go:732 msg=&amp;#34;total unused blobs removed: 0&amp;#34;
time=2024-06-14T14:52:24.743+08:00 level=INFO source=routes.go:1057 msg=&amp;#34;Listening on 127.0.0.1:11434 (version 0.1.44)&amp;#34;
time=2024-06-14T14:52:24.744+08:00 level=INFO source=payload.go:30 msg=&amp;#34;extracting embedded files&amp;#34; dir=/var/folders/y0/4gqxky0s2t94x1c1qhlwr6100000gn/T/ollama4239159529/runners
time=2024-06-14T14:52:24.772+08:00 level=INFO source=payload.go:44 msg=&amp;#34;Dynamic LLM libraries [metal]&amp;#34;
time=2024-06-14T14:52:24.796+08:00 level=INFO source=types.go:71 msg=&amp;#34;inference compute&amp;#34; id=0 library=metal compute=&amp;#34;&amp;#34; driver=0.0 name=&amp;#34;&amp;#34; total=&amp;#34;72.0 GiB&amp;#34; available=&amp;#34;72.0 GiB&amp;#34;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;cmd(mac是terminal)看到如上的信息，说明本地ollama服务已开启。&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;25-安装scrapegraphai及playwright&#34;&gt;2.5 安装scrapegraphai及playwright&lt;/h3&gt;
&lt;p&gt;电脑命令行cmd(mac是terminal),  网络是连网状态，执行安装命令&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;pip install scrapegraphai
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;之后继续命令行cmd(mac是terminal)执行&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;playwright install
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;等待安装完成后，进行实验&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;三实验&#34;&gt;三、实验&lt;/h2&gt;
&lt;h3 id=&#34;31-案例1&#34;&gt;3.1 案例1&lt;/h3&gt;
&lt;p&gt;以我的博客 &lt;code&gt;https://textdata.cn/blog/&lt;/code&gt; 为例，假设我想获取&lt;code&gt;标题、日期、文章链接&lt;/code&gt;,&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/06-blog-list.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;代码如下:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;scrapegraphai.graphs&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;SmartScraperGraph&lt;/span&gt;


&lt;span class=&#34;n&#34;&gt;graph_config&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
    &lt;span class=&#34;s2&#34;&gt;&amp;#34;llm&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
        &lt;span class=&#34;s2&#34;&gt;&amp;#34;model&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;ollama/llama3&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
        &lt;span class=&#34;s2&#34;&gt;&amp;#34;temperature&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
        &lt;span class=&#34;s2&#34;&gt;&amp;#34;format&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;json&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;# Ollama 需要显式指定格式&lt;/span&gt;
        &lt;span class=&#34;s2&#34;&gt;&amp;#34;base_url&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;http://localhost:11434&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;# 设置 Ollama URL&lt;/span&gt;
    &lt;span class=&#34;p&#34;&gt;},&lt;/span&gt;
    &lt;span class=&#34;s2&#34;&gt;&amp;#34;embeddings&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
        &lt;span class=&#34;s2&#34;&gt;&amp;#34;model&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;ollama/nomic-embed-text&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
        &lt;span class=&#34;s2&#34;&gt;&amp;#34;base_url&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;http://localhost:11434&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;# 设置 Ollama URL&lt;/span&gt;
    &lt;span class=&#34;p&#34;&gt;},&lt;/span&gt;
    &lt;span class=&#34;s2&#34;&gt;&amp;#34;verbose&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;smart_scraper_graph&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;SmartScraperGraph&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;prompt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;返回该网站所有文章的标题、日期、文章链接&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
    &lt;span class=&#34;c1&#34;&gt;# 也接受已下载的 HTML 代码的字符串&lt;/span&gt;
    &lt;span class=&#34;c1&#34;&gt;#source=requests.get(&amp;#34;https://textdata.cn/blog/&amp;#34;).text,&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;source&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;https://textdata.cn/blog/&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;config&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;graph_config&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;result&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;smart_scraper_graph&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;run&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;result&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;--- Executing Fetch Node ---
--- Executing Parse Node ---
--- Executing RAG Node ---
--- (updated chunks metadata) ---
--- (tokens compressed and vector stored) ---
--- Executing GenerateAnswer Node ---
Processing chunks: 100%|█████████████████████████| 1/1 [00:00&amp;lt;00:00, 825.81it/s]

{&amp;#39;articles&amp;#39;: 
		[{&amp;#39;title&amp;#39;: &amp;#39;LIST | 社科(经管)数据挖掘文献资料汇总&amp;#39;, 
			&amp;#39;date&amp;#39;: &amp;#39;2024-04-15&amp;#39;, 
			&amp;#39;link&amp;#39;: &amp;#39;https://textdata.cn/blog/management_python_course/&amp;#39;}, 
			
			{&amp;#39;title&amp;#39;: &amp;#39;LIST| 文本分析代码资料汇总&amp;#39;, 
			&amp;#39;date&amp;#39;: &amp;#39;2024-04-15&amp;#39;,
			&amp;#39;link&amp;#39;:&amp;#39;https://textdata.cn/blog/text_analysis_code_list_about_ms/&amp;#39;}, 
			
			{&amp;#39;title&amp;#39;: &amp;#39;实验 | 使用本地大模型从文本中提取结构化信息&amp;#39;, 
			&amp;#39;date&amp;#39;: &amp;#39;2024-06-14&amp;#39;, 
			&amp;#39;link&amp;#39;: &amp;#39;https://textdata.cn/blog/2024-06-14-using-large-language-model-to-extract-structure-data-from-raw-text/&amp;#39;}, 
			
			{&amp;#39;title&amp;#39;: &amp;#39;2023 | 文本分析在经管研究中的应用&amp;#39;, 
			&amp;#39;date&amp;#39;: &amp;#39;2023-11-05&amp;#39;, 
			&amp;#39;link&amp;#39;: &amp;#39;https://textdata.cn/blog/2023-11-05-xjtu-text-mining-in-ms/&amp;#39;}, 
			
			{&amp;#39;title&amp;#39;: &amp;#39;经管类 | 含 经济日报/经济观察报/中国工业报/中国贸易报/中国消费者报 等 10+ 家媒体(2024.05)&amp;#39;, 
			&amp;#39;date&amp;#39;: &amp;#39;2024-06-12&amp;#39;, 
			&amp;#39;link&amp;#39;: &amp;#39;https://textdata.cn/blog/2024-06-12-national-level-economic-daily-news-dataset/&amp;#39;}]}

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h3 id=&#34;32-案例2&#34;&gt;3.2 案例2&lt;/h3&gt;
&lt;p&gt;采集豆瓣读书 &lt;code&gt;https://book.douban.com/top250&lt;/code&gt; 中的 &lt;code&gt;名字、作者名、评分、书籍链接&lt;/code&gt; 等信息。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/07-books.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;scrapegraphai.graphs&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;SmartScraperGraph&lt;/span&gt;


&lt;span class=&#34;n&#34;&gt;graph_config&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
    &lt;span class=&#34;s2&#34;&gt;&amp;#34;llm&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
        &lt;span class=&#34;s2&#34;&gt;&amp;#34;model&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;ollama/llama3&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
        &lt;span class=&#34;s2&#34;&gt;&amp;#34;temperature&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
        &lt;span class=&#34;s2&#34;&gt;&amp;#34;format&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;json&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;# Ollama 需要显式指定格式&lt;/span&gt;
        &lt;span class=&#34;s2&#34;&gt;&amp;#34;base_url&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;http://localhost:11434&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;# 设置 Ollama URL&lt;/span&gt;
    &lt;span class=&#34;p&#34;&gt;},&lt;/span&gt;
    &lt;span class=&#34;s2&#34;&gt;&amp;#34;embeddings&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
        &lt;span class=&#34;s2&#34;&gt;&amp;#34;model&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;ollama/nomic-embed-text&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
        &lt;span class=&#34;s2&#34;&gt;&amp;#34;base_url&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;http://localhost:11434&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;# 设置 Ollama URL&lt;/span&gt;
    &lt;span class=&#34;p&#34;&gt;},&lt;/span&gt;
    &lt;span class=&#34;s2&#34;&gt;&amp;#34;verbose&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;


&lt;span class=&#34;n&#34;&gt;smart_scraper_graph2&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;SmartScraperGraph&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;prompt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;返回该页面所有书的名字、作者名、评分、书籍链接&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;source&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;https://book.douban.com/top250&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;config&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;graph_config&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;result2&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;smart_scraper_graph2&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;run&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;result2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;--- Executing Fetch Node ---
--- Executing Parse Node ---
--- Executing RAG Node ---
--- (updated chunks metadata) ---
--- (tokens compressed and vector stored) ---
--- Executing GenerateAnswer Node ---
Processing chunks: 100%|████████████████████████| 1/1 [00:00&amp;lt;00:00, 1474.79it/s]
{}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;采集失败，返回空。&lt;/p&gt;
&lt;br&gt;
&lt;p&gt;将大模型llama3改为qwen2&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;from scrapegraphai.graphs import SmartScraperGraph


graph_config2 = {
    &amp;#34;llm&amp;#34;: {
        &amp;#34;model&amp;#34;: &amp;#34;ollama/qwen2&amp;#34;,
        &amp;#34;temperature&amp;#34;: 0,
        &amp;#34;format&amp;#34;: &amp;#34;json&amp;#34;,  # Ollama 需要显式指定格式
        &amp;#34;base_url&amp;#34;: &amp;#34;http://localhost:11434&amp;#34;,  # 设置 Ollama URL
    },
    &amp;#34;embeddings&amp;#34;: {
        &amp;#34;model&amp;#34;: &amp;#34;ollama/nomic-embed-text&amp;#34;,
        &amp;#34;base_url&amp;#34;: &amp;#34;http://localhost:11434&amp;#34;,  # 设置 Ollama URL
    },
    &amp;#34;verbose&amp;#34;: True,
}


smart_scraper_graph3 = SmartScraperGraph(
    prompt=&amp;#34;返回该页面所有书的名字、作者名、评分、书籍链接&amp;#34;,
    source=&amp;#34;https://book.douban.com/top250&amp;#34;,
    config=graph_config2
)

result3 = smart_scraper_graph3.run()
print(result3)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;--- Executing Fetch Node ---
--- Executing Parse Node ---
--- Executing RAG Node ---
--- (updated chunks metadata) ---
--- (tokens compressed and vector stored) ---
--- Executing GenerateAnswer Node ---
Processing chunks: 100%|████████████████████████| 1/1 [00:00&amp;lt;00:00, 1102.60it/s]
{&amp;#39;urls&amp;#39;: [&amp;#39;https://book.douban.com/subject/10554308/&amp;#39;, &amp;#39;https://book.douban.com/subject/1084336/&amp;#39;, &amp;#39;https://book.douban.com/subject/1084336/&amp;#39;, &amp;#39;https://book.douban.com/subject/1046209/&amp;#39;, &amp;#39;https://book.douban.com/subject/1046209/&amp;#39;, &amp;#39;https://book.douban.com/subject/1255625/&amp;#39;, &amp;#39;https://book.douban.com/subject/1255625/&amp;#39;, &amp;#39;https://book.douban.com/subject/1060068/&amp;#39;, &amp;#39;https://book.douban.com/subject/1060068/&amp;#39;, &amp;#39;https://book.douban.com/subject/1449351/&amp;#39;, &amp;#39;https://book.douban.com/subject/1449351/&amp;#39;, &amp;#39;https://book.douban.com/subject/20424526/&amp;#39;, &amp;#39;https://book.douban.com/subject/20424526/&amp;#39;, &amp;#39;https://book.douban.com/subject/29799269/&amp;#39;, &amp;#39;https://book.douban.com/subject/1034062/&amp;#39;, &amp;#39;https://book.douban.com/subject/1229240/&amp;#39;, &amp;#39;https://book.douban.com/subject/1237549/&amp;#39;, &amp;#39;https://book.douban.com/subject/1078958/&amp;#39;, &amp;#39;https://book.douban.com/subject/1076932/&amp;#39;, &amp;#39;https://book.douban.com/subject/1075440/&amp;#39;, &amp;#39;https://book.douban.com/subject/1076932/&amp;#39;, &amp;#39;https://book.douban.com/subject/1078958/&amp;#39;, &amp;#39;https://book.douban.com/subject/1076932/&amp;#39;, &amp;#39;https://book.douban.com/subject/1078958/&amp;#39;, &amp;#39;https://book.douban.com/subject/1076932/&amp;#39;, &amp;#39;https://book.douban.com/subject/1078958/&amp;#39;, &amp;#39;https://book.douban.com/subject/1076932/&amp;#39;], &amp;#39;images&amp;#39;: [&amp;#39;https://img1.doubanio.com/view/subject/s/public/s1078958.jpg&amp;#39;, &amp;#39;https://img1.doubanio.com/view/subject/s/public/s1076932.jpg&amp;#39;, &amp;#39;https://img1.doubanio.com/view/subject/s/public/s1447349.jpg&amp;#39;]}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;采集到一些信息，但没有书名、作者等信息。&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;注意&#34;&gt;注意：&lt;/h3&gt;
&lt;p&gt;代码需要在 &lt;code&gt;.py&lt;/code&gt; 中运行，在 &lt;code&gt;.ipynb&lt;/code&gt; 中运行会报错。&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;四讨论&#34;&gt;四、讨论&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;ScrapeGraphAI&lt;/strong&gt;&lt;/em&gt; 是目前大邓已经的唯一的大模型爬虫， 现在采集数据的成功率还是比较低的。 而且因为底层使用 playwright ， 访问速度较慢。&lt;/p&gt;
&lt;br&gt;
&lt;br&gt;
&lt;h2 id=&#34;精选内容&#34;&gt;精选内容&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/datasets_available_for_management_science/&#34;&gt;LIST | 可供社科(经管)领域使用的数据集汇总&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/the_text_analysis_list_about_ms/&#34;&gt;LIST | 社科(经管)数据挖掘文献资料汇总&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/2024-04-27-cntext2x-usage-tutorial/&#34;&gt;推荐 | 文本分析库cntext2.x使用手册&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/management_python_course/&#34;&gt;付费视频课 | Python实证指标构建与文本分析&lt;/a&gt;
&lt;br&gt;
&lt;br&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
      <content:encoded><![CDATA[<blockquote>
<p>前几日分享了<a href="https://textdata.cn/blog/2024-06-14-using-large-language-model-to-extract-structure-data-from-raw-text/">实验 | 使用本地大模型从文本中提取结构化信息</a>, 今天再分享一个  <a href="https://github.com/VinciGit00/Scrapegraph-ai">ScrapeGraphAI库</a>， 现在还不太好用，但未来写爬虫很可能会变得越来越容易。</p>
</blockquote>
<br>
<h2 id="一介绍">一、介绍</h2>
<p><em><strong>ScrapeGraphAI</strong></em>是一个<em>网络爬虫</em> Python 库，使用大型语言模型和直接图逻辑为网站和本地文档（XML，HTML，JSON 等）创建爬取管道。</p>
<p>只需告诉库您想提取哪些信息，它将为您完成！</p>
<p><img loading="lazy" src="img/scrapegraphai_logo.png" alt=""  />
</p>
<p>scrapegraphai有三种主要的爬取管道可用于从网站（或本地文件）提取信息：</p>
<ul>
<li><code>SmartScraperGraph</code>: 单页爬虫，只需用户提示和输入源；</li>
<li><code>SearchGraph</code>: 多页爬虫，从搜索引擎的前 n 个搜索结果中提取信息；</li>
<li><code>SpeechGraph</code>: 单页爬虫，从网站提取信息并生成音频文件。</li>
<li><code>SmartScraperMultiGraph</code>: 多页爬虫，给定一个提示 可以通过 API 使用不同的 LLM，如 <strong>OpenAI</strong>，<strong>Groq</strong>，<strong>Azure</strong> 和 <strong>Gemini</strong>，或者使用 <strong>Ollama</strong> 的本地模型。</li>
</ul>
<p><br><br></p>
<h2 id="二准备工作">二、准备工作</h2>
<h3 id="121-安装ollama">12.1 安装ollama</h3>
<p>点击前往网站 <a href="https://ollama.com/">https://ollama.com/</a> ，下载ollama软件，支持win、Mac、linux</p>
<p><img loading="lazy" src="img/02-ollama-gui.png" alt=""  />
</p>
<br>
<h3 id="22-下载llm">2.2 下载LLM</h3>
<p>ollama软件目前支持多种大模型， 如阿里的（qwen、qwen2）、meta的(llama3)，</p>
<p><img loading="lazy" src="img/03-ollama-model.png" alt=""  />
</p>
<br>
<p>以llama3为例，根据自己电脑显存性能， 选择适宜的版本。如果不知道选什么，那就试着安装，不合适不能用再删除即可。</p>
<p><img loading="lazy" src="img/04-ollama-llama3.png" alt=""  />
</p>
<br>
<p>打开电脑命令行cmd(mac是terminal),  网络是连网状态，执行模型下载(安装)命令</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">ollama pull llama3
ollama pull qwen2
ollama pull nomic-embed-text
</code></pre></div><p>等待 <strong>llama3、 nomic-embed-text</strong> 下载完成。</p>
<br>
<h3 id="23-安装python包">2.3 安装python包</h3>
<p>在python中调用ollama服务，需要ollama包。</p>
<p>打开电脑命令行cmd(mac是terminal),  网络是连网状态，执行安装命令</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">pip3 install ollama
</code></pre></div><br>
<h3 id="24-启动ollama服务">2.4 启动ollama服务</h3>
<p>在Python中调用本地ollama服务，需要先启动本地ollama服务， 打开电脑命令行cmd(mac是terminal), 执行</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">ollama serve
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">2024/06/14 14:52:24 routes.go:1011: INFO server config env=&#34;map[OLLAMA_DEBUG:false OLLAMA_FLASH_ATTENTION:false OLLAMA_HOST:http://127.0.0.1:11434 OLLAMA_KEEP_ALIVE: OLLAMA_LLM_LIBRARY: OLLAMA_MAX_LOADED_MODELS:1 OLLAMA_MAX_QUEUE:512 OLLAMA_MAX_VRAM:0 OLLAMA_MODELS:/Users/deng/.ollama/models OLLAMA_NOHISTORY:false OLLAMA_NOPRUNE:false OLLAMA_NUM_PARALLEL:1 OLLAMA_ORIGINS:[http://localhost https://localhost http://localhost:* https://localhost:* http://127.0.0.1 https://127.0.0.1 http://127.0.0.1:* https://127.0.0.1:* http://0.0.0.0 https://0.0.0.0 http://0.0.0.0:* https://0.0.0.0:* app://* file://* tauri://*] OLLAMA_RUNNERS_DIR: OLLAMA_TMPDIR:]&#34;
time=2024-06-14T14:52:24.742+08:00 level=INFO source=images.go:725 msg=&#34;total blobs: 18&#34;
time=2024-06-14T14:52:24.742+08:00 level=INFO source=images.go:732 msg=&#34;total unused blobs removed: 0&#34;
time=2024-06-14T14:52:24.743+08:00 level=INFO source=routes.go:1057 msg=&#34;Listening on 127.0.0.1:11434 (version 0.1.44)&#34;
time=2024-06-14T14:52:24.744+08:00 level=INFO source=payload.go:30 msg=&#34;extracting embedded files&#34; dir=/var/folders/y0/4gqxky0s2t94x1c1qhlwr6100000gn/T/ollama4239159529/runners
time=2024-06-14T14:52:24.772+08:00 level=INFO source=payload.go:44 msg=&#34;Dynamic LLM libraries [metal]&#34;
time=2024-06-14T14:52:24.796+08:00 level=INFO source=types.go:71 msg=&#34;inference compute&#34; id=0 library=metal compute=&#34;&#34; driver=0.0 name=&#34;&#34; total=&#34;72.0 GiB&#34; available=&#34;72.0 GiB&#34;
</code></pre></div><p>cmd(mac是terminal)看到如上的信息，说明本地ollama服务已开启。</p>
<br>
<h3 id="25-安装scrapegraphai及playwright">2.5 安装scrapegraphai及playwright</h3>
<p>电脑命令行cmd(mac是terminal),  网络是连网状态，执行安装命令</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">pip install scrapegraphai
</code></pre></div><p>之后继续命令行cmd(mac是terminal)执行</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">playwright install
</code></pre></div><p>等待安装完成后，进行实验</p>
<p><br><br></p>
<h2 id="三实验">三、实验</h2>
<h3 id="31-案例1">3.1 案例1</h3>
<p>以我的博客 <code>https://textdata.cn/blog/</code> 为例，假设我想获取<code>标题、日期、文章链接</code>,</p>
<p><img loading="lazy" src="img/06-blog-list.png" alt=""  />
</p>
<p>代码如下:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">scrapegraphai.graphs</span> <span class="kn">import</span> <span class="n">SmartScraperGraph</span>


<span class="n">graph_config</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&#34;llm&#34;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&#34;model&#34;</span><span class="p">:</span> <span class="s2">&#34;ollama/llama3&#34;</span><span class="p">,</span>
        <span class="s2">&#34;temperature&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="s2">&#34;format&#34;</span><span class="p">:</span> <span class="s2">&#34;json&#34;</span><span class="p">,</span>  <span class="c1"># Ollama 需要显式指定格式</span>
        <span class="s2">&#34;base_url&#34;</span><span class="p">:</span> <span class="s2">&#34;http://localhost:11434&#34;</span><span class="p">,</span>  <span class="c1"># 设置 Ollama URL</span>
    <span class="p">},</span>
    <span class="s2">&#34;embeddings&#34;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&#34;model&#34;</span><span class="p">:</span> <span class="s2">&#34;ollama/nomic-embed-text&#34;</span><span class="p">,</span>
        <span class="s2">&#34;base_url&#34;</span><span class="p">:</span> <span class="s2">&#34;http://localhost:11434&#34;</span><span class="p">,</span>  <span class="c1"># 设置 Ollama URL</span>
    <span class="p">},</span>
    <span class="s2">&#34;verbose&#34;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
<span class="p">}</span>

<span class="n">smart_scraper_graph</span> <span class="o">=</span> <span class="n">SmartScraperGraph</span><span class="p">(</span>
    <span class="n">prompt</span><span class="o">=</span><span class="s2">&#34;返回该网站所有文章的标题、日期、文章链接&#34;</span><span class="p">,</span>
    <span class="c1"># 也接受已下载的 HTML 代码的字符串</span>
    <span class="c1">#source=requests.get(&#34;https://textdata.cn/blog/&#34;).text,</span>
    <span class="n">source</span><span class="o">=</span><span class="s2">&#34;https://textdata.cn/blog/&#34;</span><span class="p">,</span>
    <span class="n">config</span><span class="o">=</span><span class="n">graph_config</span>
<span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">smart_scraper_graph</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">--- Executing Fetch Node ---
--- Executing Parse Node ---
--- Executing RAG Node ---
--- (updated chunks metadata) ---
--- (tokens compressed and vector stored) ---
--- Executing GenerateAnswer Node ---
Processing chunks: 100%|█████████████████████████| 1/1 [00:00&lt;00:00, 825.81it/s]

{&#39;articles&#39;: 
		[{&#39;title&#39;: &#39;LIST | 社科(经管)数据挖掘文献资料汇总&#39;, 
			&#39;date&#39;: &#39;2024-04-15&#39;, 
			&#39;link&#39;: &#39;https://textdata.cn/blog/management_python_course/&#39;}, 
			
			{&#39;title&#39;: &#39;LIST| 文本分析代码资料汇总&#39;, 
			&#39;date&#39;: &#39;2024-04-15&#39;,
			&#39;link&#39;:&#39;https://textdata.cn/blog/text_analysis_code_list_about_ms/&#39;}, 
			
			{&#39;title&#39;: &#39;实验 | 使用本地大模型从文本中提取结构化信息&#39;, 
			&#39;date&#39;: &#39;2024-06-14&#39;, 
			&#39;link&#39;: &#39;https://textdata.cn/blog/2024-06-14-using-large-language-model-to-extract-structure-data-from-raw-text/&#39;}, 
			
			{&#39;title&#39;: &#39;2023 | 文本分析在经管研究中的应用&#39;, 
			&#39;date&#39;: &#39;2023-11-05&#39;, 
			&#39;link&#39;: &#39;https://textdata.cn/blog/2023-11-05-xjtu-text-mining-in-ms/&#39;}, 
			
			{&#39;title&#39;: &#39;经管类 | 含 经济日报/经济观察报/中国工业报/中国贸易报/中国消费者报 等 10+ 家媒体(2024.05)&#39;, 
			&#39;date&#39;: &#39;2024-06-12&#39;, 
			&#39;link&#39;: &#39;https://textdata.cn/blog/2024-06-12-national-level-economic-daily-news-dataset/&#39;}]}

</code></pre></div><br>
<h3 id="32-案例2">3.2 案例2</h3>
<p>采集豆瓣读书 <code>https://book.douban.com/top250</code> 中的 <code>名字、作者名、评分、书籍链接</code> 等信息。</p>
<p><img loading="lazy" src="img/07-books.png" alt=""  />
</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">scrapegraphai.graphs</span> <span class="kn">import</span> <span class="n">SmartScraperGraph</span>


<span class="n">graph_config</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&#34;llm&#34;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&#34;model&#34;</span><span class="p">:</span> <span class="s2">&#34;ollama/llama3&#34;</span><span class="p">,</span>
        <span class="s2">&#34;temperature&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="s2">&#34;format&#34;</span><span class="p">:</span> <span class="s2">&#34;json&#34;</span><span class="p">,</span>  <span class="c1"># Ollama 需要显式指定格式</span>
        <span class="s2">&#34;base_url&#34;</span><span class="p">:</span> <span class="s2">&#34;http://localhost:11434&#34;</span><span class="p">,</span>  <span class="c1"># 设置 Ollama URL</span>
    <span class="p">},</span>
    <span class="s2">&#34;embeddings&#34;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&#34;model&#34;</span><span class="p">:</span> <span class="s2">&#34;ollama/nomic-embed-text&#34;</span><span class="p">,</span>
        <span class="s2">&#34;base_url&#34;</span><span class="p">:</span> <span class="s2">&#34;http://localhost:11434&#34;</span><span class="p">,</span>  <span class="c1"># 设置 Ollama URL</span>
    <span class="p">},</span>
    <span class="s2">&#34;verbose&#34;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
<span class="p">}</span>


<span class="n">smart_scraper_graph2</span> <span class="o">=</span> <span class="n">SmartScraperGraph</span><span class="p">(</span>
    <span class="n">prompt</span><span class="o">=</span><span class="s2">&#34;返回该页面所有书的名字、作者名、评分、书籍链接&#34;</span><span class="p">,</span>
    <span class="n">source</span><span class="o">=</span><span class="s2">&#34;https://book.douban.com/top250&#34;</span><span class="p">,</span>
    <span class="n">config</span><span class="o">=</span><span class="n">graph_config</span>
<span class="p">)</span>

<span class="n">result2</span> <span class="o">=</span> <span class="n">smart_scraper_graph2</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">result2</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">--- Executing Fetch Node ---
--- Executing Parse Node ---
--- Executing RAG Node ---
--- (updated chunks metadata) ---
--- (tokens compressed and vector stored) ---
--- Executing GenerateAnswer Node ---
Processing chunks: 100%|████████████████████████| 1/1 [00:00&lt;00:00, 1474.79it/s]
{}
</code></pre></div><p>采集失败，返回空。</p>
<br>
<p>将大模型llama3改为qwen2</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">from scrapegraphai.graphs import SmartScraperGraph


graph_config2 = {
    &#34;llm&#34;: {
        &#34;model&#34;: &#34;ollama/qwen2&#34;,
        &#34;temperature&#34;: 0,
        &#34;format&#34;: &#34;json&#34;,  # Ollama 需要显式指定格式
        &#34;base_url&#34;: &#34;http://localhost:11434&#34;,  # 设置 Ollama URL
    },
    &#34;embeddings&#34;: {
        &#34;model&#34;: &#34;ollama/nomic-embed-text&#34;,
        &#34;base_url&#34;: &#34;http://localhost:11434&#34;,  # 设置 Ollama URL
    },
    &#34;verbose&#34;: True,
}


smart_scraper_graph3 = SmartScraperGraph(
    prompt=&#34;返回该页面所有书的名字、作者名、评分、书籍链接&#34;,
    source=&#34;https://book.douban.com/top250&#34;,
    config=graph_config2
)

result3 = smart_scraper_graph3.run()
print(result3)
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">--- Executing Fetch Node ---
--- Executing Parse Node ---
--- Executing RAG Node ---
--- (updated chunks metadata) ---
--- (tokens compressed and vector stored) ---
--- Executing GenerateAnswer Node ---
Processing chunks: 100%|████████████████████████| 1/1 [00:00&lt;00:00, 1102.60it/s]
{&#39;urls&#39;: [&#39;https://book.douban.com/subject/10554308/&#39;, &#39;https://book.douban.com/subject/1084336/&#39;, &#39;https://book.douban.com/subject/1084336/&#39;, &#39;https://book.douban.com/subject/1046209/&#39;, &#39;https://book.douban.com/subject/1046209/&#39;, &#39;https://book.douban.com/subject/1255625/&#39;, &#39;https://book.douban.com/subject/1255625/&#39;, &#39;https://book.douban.com/subject/1060068/&#39;, &#39;https://book.douban.com/subject/1060068/&#39;, &#39;https://book.douban.com/subject/1449351/&#39;, &#39;https://book.douban.com/subject/1449351/&#39;, &#39;https://book.douban.com/subject/20424526/&#39;, &#39;https://book.douban.com/subject/20424526/&#39;, &#39;https://book.douban.com/subject/29799269/&#39;, &#39;https://book.douban.com/subject/1034062/&#39;, &#39;https://book.douban.com/subject/1229240/&#39;, &#39;https://book.douban.com/subject/1237549/&#39;, &#39;https://book.douban.com/subject/1078958/&#39;, &#39;https://book.douban.com/subject/1076932/&#39;, &#39;https://book.douban.com/subject/1075440/&#39;, &#39;https://book.douban.com/subject/1076932/&#39;, &#39;https://book.douban.com/subject/1078958/&#39;, &#39;https://book.douban.com/subject/1076932/&#39;, &#39;https://book.douban.com/subject/1078958/&#39;, &#39;https://book.douban.com/subject/1076932/&#39;, &#39;https://book.douban.com/subject/1078958/&#39;, &#39;https://book.douban.com/subject/1076932/&#39;], &#39;images&#39;: [&#39;https://img1.doubanio.com/view/subject/s/public/s1078958.jpg&#39;, &#39;https://img1.doubanio.com/view/subject/s/public/s1076932.jpg&#39;, &#39;https://img1.doubanio.com/view/subject/s/public/s1447349.jpg&#39;]}
</code></pre></div><p>采集到一些信息，但没有书名、作者等信息。</p>
<br>
<h3 id="注意">注意：</h3>
<p>代码需要在 <code>.py</code> 中运行，在 <code>.ipynb</code> 中运行会报错。</p>
<p><br><br></p>
<h2 id="四讨论">四、讨论</h2>
<p><em><strong>ScrapeGraphAI</strong></em> 是目前大邓已经的唯一的大模型爬虫， 现在采集数据的成功率还是比较低的。 而且因为底层使用 playwright ， 访问速度较慢。</p>
<br>
<br>
<h2 id="精选内容">精选内容</h2>
<ul>
<li><a href="https://textdata.cn/blog/datasets_available_for_management_science/">LIST | 可供社科(经管)领域使用的数据集汇总</a></li>
<li><a href="https://textdata.cn/blog/the_text_analysis_list_about_ms/">LIST | 社科(经管)数据挖掘文献资料汇总</a></li>
<li><a href="https://textdata.cn/blog/2024-04-27-cntext2x-usage-tutorial/">推荐 | 文本分析库cntext2.x使用手册</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a>
<br>
<br></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>实验 | 使用本地大模型从文本中提取结构化信息</title>
      <link>https://textdata.cn/blog/2024-06-14-using-large-language-model-to-extract-structure-data-from-raw-text/</link>
      <pubDate>Fri, 14 Jun 2024 00:00:00 +0000</pubDate>
      
      <guid>/blog/2024-06-14-using-large-language-model-to-extract-structure-data-from-raw-text/</guid>
      <description>&lt;p&gt;非结构文本、图片、视频等数据是待挖掘的数据矿藏， 在经管、社科等研究领域中谁拥有了&lt;em&gt;&lt;strong&gt;从非结构提取结构化信息的能力&lt;/strong&gt;&lt;/em&gt;，谁就拥有科研上的数据优势。&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;一需求&#34;&gt;一、需求&lt;/h2&gt;
&lt;p&gt;现在有很多个电子发票PDF文件， 使用自动化工具帮我们批量自动从发票PDF提取出格式化信息。如从发票&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/01-raw-pdf.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;提取出DICT_DATA&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;DICT_DATA = {
    &amp;#34;开票日期&amp;#34;: &amp;#34;2023年01月06日&amp;#34;,
    &amp;#34;应税货物(或服务)名称&amp;#34;: &amp;#34;*信息技术服务*技术服务费&amp;#34;,
    &amp;#34;价税合计(大写)&amp;#34;: &amp;#34;&amp;#34;,
    &amp;#34;税率&amp;#34;: &amp;#34;6%&amp;#34;,
    &amp;#34;备注&amp;#34;: &amp;#34;230106163474406331&amp;#34;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;二ollama介绍&#34;&gt;二、Ollama介绍&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://ollama.ai/&#34;&gt;&lt;strong&gt;Ollama&lt;/strong&gt;&lt;/a&gt;是一款开源应用程序，可让您使用 MacOS、Linux 和 Windows 上的命令行界面在本地运行、创建和共享大型语言模型。&lt;/p&gt;
&lt;p&gt;Ollama 可以直接从其库中访问各种 LLM，只需一个命令即可下载。下载后，只需执行一个命令即可开始使用。这对于工作量围绕终端窗口的用户非常有帮助。如果他们被困在某个地方，他们可以在不切换到另一个浏览器窗口的情况下获得答案。&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;21-特点和优点&#34;&gt;2.1 特点和优点&lt;/h3&gt;
&lt;p&gt;这就是为什么 OLLAMA 是您的工具包中必备的工具：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;简单&lt;/strong&gt; ：OLLAMA 提供简单的设置过程。您无需拥有机器学习博士学位即可启动和运行它。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;成本效益&lt;/strong&gt; ：在本地运行模型意味着您无需支付云成本。您的钱包会感谢您。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;隐私&lt;/strong&gt; ：使用 OLLAMA，所有数据处理都在您的本地机器上进行。这对于用户隐私来说是一个巨大的胜利。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;多功能性&lt;/strong&gt; ：OLLAMA 不只是为 Python 爱好者准备的。它的灵活性使其可以用于各种应用程序，包括 Web 开发。&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
&lt;h3 id=&#34;22-使用-ollama-进行-llm-选择&#34;&gt;2.2 使用 Ollama 进行 LLM 选择&lt;/h3&gt;
&lt;p&gt;默认情况下，Openai Models 在 CrewAI 中用作 llm。有经费、有网络、不担心数据泄露等条件下,  力求达到最佳性能，可考虑使用 GPT-4 或 OpenAI 稍便宜的 GPT-3.5。&lt;/p&gt;
&lt;p&gt;但本文是要 &lt;strong&gt;本地部署&lt;/strong&gt;， 因此我们将使用 Meta Llama 3，这是迄今为止功能最强大的公开 LLM。Meta Llama 3 是 Meta Inc. 开发的模型系列，是最新推出的模型，具有 8B 和 70B 两种参数大小（预训练或指令调整）。Llama 3 指令调整模型针对对话/聊天用例进行了微调和优化，并且在常见基准测试中胜过许多可用的开源聊天模型。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/02-llama3-performance.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/03-llama3-performance.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;23-安装ollama&#34;&gt;2.3 安装ollama&lt;/h3&gt;
&lt;p&gt;点击前往网站 &lt;a href=&#34;https://ollama.com/&#34;&gt;https://ollama.com/&lt;/a&gt; ，下载ollama软件，支持win、Mac、linux&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/04-ollama-gui.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;24-下载llm&#34;&gt;2.4 下载LLM&lt;/h3&gt;
&lt;p&gt;ollama软件目前支持多种大模型， 如阿里的（qwen、qwen2）、meta的(llama3、llama3.1)，&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/05-ollama-model.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;p&gt;以llama3为例，根据自己电脑显存性能， 选择适宜的版本。如果不知道选什么，那就试着安装，不合适不能用再删除即可。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/06-ollama-llama3.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;p&gt;打开电脑命令行cmd(mac是terminal),  网络是连网状态，执行模型下载(安装)命令&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;ollama pull llama3
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;等待 &lt;strong&gt;llama3:8b&lt;/strong&gt; 下载完成。&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;25-安装python包&#34;&gt;2.5 安装python包&lt;/h3&gt;
&lt;p&gt;在python中调用ollama服务，需要ollama包。&lt;/p&gt;
&lt;p&gt;打开电脑命令行cmd(mac是terminal),  网络是连网状态，执行安装命令&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;pip3 install ollama
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h3 id=&#34;26-启动ollama服务&#34;&gt;2.6 启动ollama服务&lt;/h3&gt;
&lt;p&gt;在Python中调用本地ollama服务，需要先启动本地ollama服务， 打开电脑命令行cmd(mac是terminal), 执行&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;ollama serve
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;2024/06/14 14:52:24 routes.go:1011: INFO server config env=&amp;#34;map[OLLAMA_DEBUG:false OLLAMA_FLASH_ATTENTION:false OLLAMA_HOST:http://127.0.0.1:11434 OLLAMA_KEEP_ALIVE: OLLAMA_LLM_LIBRARY: OLLAMA_MAX_LOADED_MODELS:1 OLLAMA_MAX_QUEUE:512 OLLAMA_MAX_VRAM:0 OLLAMA_MODELS:/Users/deng/.ollama/models OLLAMA_NOHISTORY:false OLLAMA_NOPRUNE:false OLLAMA_NUM_PARALLEL:1 OLLAMA_ORIGINS:[http://localhost https://localhost http://localhost:* https://localhost:* http://127.0.0.1 https://127.0.0.1 http://127.0.0.1:* https://127.0.0.1:* http://0.0.0.0 https://0.0.0.0 http://0.0.0.0:* https://0.0.0.0:* app://* file://* tauri://*] OLLAMA_RUNNERS_DIR: OLLAMA_TMPDIR:]&amp;#34;
time=2024-06-14T14:52:24.742+08:00 level=INFO source=images.go:725 msg=&amp;#34;total blobs: 18&amp;#34;
time=2024-06-14T14:52:24.742+08:00 level=INFO source=images.go:732 msg=&amp;#34;total unused blobs removed: 0&amp;#34;
time=2024-06-14T14:52:24.743+08:00 level=INFO source=routes.go:1057 msg=&amp;#34;Listening on 127.0.0.1:11434 (version 0.1.44)&amp;#34;
time=2024-06-14T14:52:24.744+08:00 level=INFO source=payload.go:30 msg=&amp;#34;extracting embedded files&amp;#34; dir=/var/folders/y0/4gqxky0s2t94x1c1qhlwr6100000gn/T/ollama4239159529/runners
time=2024-06-14T14:52:24.772+08:00 level=INFO source=payload.go:44 msg=&amp;#34;Dynamic LLM libraries [metal]&amp;#34;
time=2024-06-14T14:52:24.796+08:00 level=INFO source=types.go:71 msg=&amp;#34;inference compute&amp;#34; id=0 library=metal compute=&amp;#34;&amp;#34; driver=0.0 name=&amp;#34;&amp;#34; total=&amp;#34;72.0 GiB&amp;#34; available=&amp;#34;72.0 GiB&amp;#34;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;cmd(mac是terminal)看到如上的信息，说明本地ollama服务已开启。&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;三实验&#34;&gt;三、实验&lt;/h2&gt;
&lt;h3 id=&#34;31-代码结构&#34;&gt;3.1 代码结构&lt;/h3&gt;
&lt;p&gt;点击下载 &lt;a href=&#34;project.zip&#34;&gt;本文代码&lt;/a&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;project
   |
  - 代码.ipynb   #代码
  - prompt.txt  #提示模板
  - data
      |--- 1.pdf #实验的发票
  - result.csv   #结果
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h3 id=&#34;32-读取pdf&#34;&gt;3.2 读取pdf&lt;/h3&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/01-raw-pdf.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;cntext&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;ct&lt;/span&gt;
&lt;span class=&#34;c1&#34;&gt;#cntext版本为2.1.3，非开源， #需联系大邓372335839获取&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;text&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ct&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read_pdf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;data/1.pdf&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ct&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;__version__&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;text&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;2.1.3

&amp;#39; 北京增值税电子普通发票发票代码： \n发票号码： 69453658\n开票日期： 2023年01月06日\n校 验 码： \n购\n买\n方名        称： 哈尔滨所以然信息技术有限公司\n密\n码\n区030898/5&amp;lt;32&amp;gt;*/0*440/63+79*08\n纳税人识别号： 91230109MABT7KBC4M /&amp;lt;54&amp;lt;1*6+49&amp;lt;-*+*&amp;gt;7&amp;lt;-8*04&amp;lt;+01\n地 址、电 话： 68+160026-45904*2&amp;lt;+3+15503&amp;gt;2\n开户行及账号： 98*2/*-*480145+-19*0917-1*61\n货物或应税劳务、服务名称 规格型号 单 位 数 量 单 价 金 额 税率 税 额\n*信息技术服务*技术服务费 1248.113208 248.11 6% 14.89\n合      计 ￥248.11 ￥14.89\n价税合计（大写）\n  贰佰陆拾叁元整             （小写）￥263.00\n销\n售\n方名        称： \n备\n注230106163474406331\n纳税人识别号： 91110108MA01WFY0X6\n地 址、电 话： \n开户行及账号： \n  收款人： 复核： 开票人： 销售方：（章）&amp;#39;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h3 id=&#34;34-提取信息&#34;&gt;3.4 提取信息&lt;/h3&gt;
&lt;p&gt;使用ollama服务中的大模型 &lt;em&gt;&lt;strong&gt;llama3:8b&lt;/strong&gt;&lt;/em&gt; , 需要大模型提示信息及数据。这是我实验里设计的提示信息prompt&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;prompt = open(&amp;#39;prompt.txt&amp;#39;, encoding=&amp;#39;utf-8&amp;#39;).read()
print(prompt)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;发票文本内容
--- 
{TEXT} 
---

以 JSON 格式回答。 JSON 应包含如下信息， 依次为&amp;#34;开票日期&amp;#34;, &amp;#34;应税货物(或服务)名称&amp;#34;, &amp;#34;价税合计(大写)&amp;#34;, &amp;#34;税率&amp;#34;, &amp;#34;备注&amp;#34;; 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;o&#34;&gt;%%&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;time&lt;/span&gt;

&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;ollama&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;cntext&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;ct&lt;/span&gt;
&lt;span class=&#34;c1&#34;&gt;#cntext版本为2.1.3，非开源， 需联系大邓372335839获取&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;#读取发票pdf&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;content&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ct&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read_pdf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;data/1.pdf&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;c1&#34;&gt;#读取prompt&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;prompt&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;open&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;prompt.txt&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;encoding&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;utf-8&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;response&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ollama&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;chat&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;model&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;llama3:8b&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;messages&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;
      &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;role&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;system&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;content&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;prompt&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;},&lt;/span&gt;
      &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;role&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;user&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;content&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;content&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;},&lt;/span&gt;
    &lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;result&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;response&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;message&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;][&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;content&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;result&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;eval&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;result&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;split&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;```&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\n&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;split&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\n&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;```&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;result&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;CPU times: user 20.5 ms, sys: 2.34 ms, total: 22.9 ms
Wall time: 3.58 s

{&amp;#39;开票日期&amp;#39;: &amp;#39;2023年01月06日&amp;#39;,
 &amp;#39;应税货物(或服务)名称&amp;#39;: &amp;#39;*信息技术服务*技术服务费&amp;#39;,
 &amp;#39;价税合计(大写)&amp;#39;: &amp;#39;贰佰陆拾叁元整&amp;#39;,
 &amp;#39;税率&amp;#39;: &amp;#39;6%&amp;#39;,
 &amp;#39;备注&amp;#39;: &amp;#39;230106163474406331&amp;#39;}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h3 id=&#34;33-封装成函数extract_info&#34;&gt;3.3 封装成函数extract_info&lt;/h3&gt;
&lt;p&gt;实验成功，我们将其封装为函数&lt;em&gt;&lt;strong&gt;extract_info&lt;/strong&gt;&lt;/em&gt;， 为增强代码的鲁棒性， 函数内设置了异常处理机制，最多可重试3次。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;ollama&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;re&lt;/span&gt;


&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;extract_info&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;prompt&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;max_retries&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
    &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;attempt&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;range&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;max_retries&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
        &lt;span class=&#34;k&#34;&gt;try&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
            &lt;span class=&#34;n&#34;&gt;response&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ollama&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;chat&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
                &lt;span class=&#34;n&#34;&gt;model&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;llama3:8b&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                &lt;span class=&#34;n&#34;&gt;messages&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;
                    &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;role&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;system&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;content&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;prompt&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;},&lt;/span&gt;
                    &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;role&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;user&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;content&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
                &lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
            &lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;

            &lt;span class=&#34;n&#34;&gt;result&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;response&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;message&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;][&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;content&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
            &lt;span class=&#34;n&#34;&gt;result&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;eval&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;result&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;split&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;```&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\n&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;split&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\n&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;```&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
            &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;result&lt;/span&gt;
        
        &lt;span class=&#34;k&#34;&gt;except&lt;/span&gt; &lt;span class=&#34;ne&#34;&gt;Exception&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;e&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
            &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;attempt&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;max_retries&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
                &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;sa&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;An error occurred: &lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;e&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;. Retrying (&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;attempt&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;max_retries&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;)...&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
            &lt;span class=&#34;k&#34;&gt;else&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
                &lt;span class=&#34;k&#34;&gt;raise&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;e&lt;/span&gt;
  
&lt;span class=&#34;c1&#34;&gt;#读取prompt&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;prompt&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;open&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;prompt.txt&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;encoding&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;utf-8&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;result&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;extract_info&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;prompt&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;result&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;result与之前无异， 为了节省版面，这里就不显示result。&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;34-批量提取&#34;&gt;3.4 批量提取&lt;/h3&gt;
&lt;p&gt;假设data文件夹内有成百上千的发票(实际上只有一张发票)， 对data文件夹进行批量信息提取，结果存储为csv。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;o&#34;&gt;%%&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;time&lt;/span&gt;

&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;os&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;ollama&lt;/span&gt;
&lt;span class=&#34;c1&#34;&gt;#cntext版本为2.1.3，非开源， 需联系大邓372335839获取&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;cntext&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;ct&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pandas&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pd&lt;/span&gt;


&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;extract_info&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;prompt&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;max_retries&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
    &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;attempt&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;range&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;max_retries&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
        &lt;span class=&#34;k&#34;&gt;try&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
            &lt;span class=&#34;n&#34;&gt;response&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ollama&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;chat&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
                &lt;span class=&#34;n&#34;&gt;model&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;llama3:8b&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                &lt;span class=&#34;n&#34;&gt;messages&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;
                    &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;role&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;system&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;content&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;prompt&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;},&lt;/span&gt;
                    &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;role&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;user&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;content&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
                &lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
            &lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;

            &lt;span class=&#34;n&#34;&gt;result&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;response&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;message&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;][&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;content&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
            &lt;span class=&#34;n&#34;&gt;result&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;eval&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;result&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;split&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;```&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\n&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;split&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\n&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;```&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
            &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;result&lt;/span&gt;
        
        &lt;span class=&#34;k&#34;&gt;except&lt;/span&gt; &lt;span class=&#34;ne&#34;&gt;Exception&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;e&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
            &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;attempt&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;max_retries&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
                &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;sa&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;An error occurred: &lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;e&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;. Retrying (&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;attempt&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;max_retries&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;)...&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
            &lt;span class=&#34;k&#34;&gt;else&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
                &lt;span class=&#34;k&#34;&gt;raise&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;e&lt;/span&gt;
                
  
&lt;span class=&#34;c1&#34;&gt;#当前代码所在的代码文件与data文件夹处于同一个文件夹内&lt;/span&gt;
&lt;span class=&#34;c1&#34;&gt;#获取data内所有pdf的路径&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;pdf_files&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;sa&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;data/&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;file&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;file&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;os&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;listdir&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;data&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;.pdf&amp;#39;&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;file&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;span class=&#34;c1&#34;&gt;#读取prompt&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;prompt&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;open&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;prompt.txt&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;encoding&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;utf-8&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;dict_datas&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt;
&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pdf_file&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pdf_files&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;text&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ct&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read_pdf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;pdf_file&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;dict_data&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;extract_info&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;prompt&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;dict_datas&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;append&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dict_data&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;DataFrame&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dict_datas&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;to_csv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;result.csv&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;index&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;False&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;CPU times: user 32 ms, sys: 2.17 ms, total: 15.2 ms
Wall time: 3.8 s
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/05-df.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;四讨论&#34;&gt;四、讨论&lt;/h2&gt;
&lt;p&gt;本文只使用了一张发票进行实验， 实际上准确率没有这么高， 识别错误字段集中在销售方纳税识别号(案例没有展示销售方纳税识别号的识别)。原因主要是ct.read_pdf读入pdf时，文本比较杂乱。对大模型的语义理解有一定的挑战。目前大模型已经支持文本、图片、音频、视频、网址， 所以各位看官，不用等太久，就可克服此问题。&lt;/p&gt;
&lt;p&gt;大模型会对每个输入，给出正确概率最大的回答，因此大模型提取数据时存在一定的错误识别风险。为降低该风险，尽量选择特别特殊、显眼，例如三张发票的&lt;strong&gt;价税合计(大写)&lt;/strong&gt;,  因为信息是特殊的中文大写数字， 在所有文本中是最醒目最特别的文本信息，这样大模型处理这类信息时会给这类信息尽可能高的权重，增大回答的准确率。&lt;/p&gt;
&lt;br&gt;
&lt;br&gt;
&lt;h2 id=&#34;精选内容&#34;&gt;精选内容&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/datasets_available_for_management_science/&#34;&gt;LIST | 可供社科(经管)领域使用的数据集汇总&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/the_text_analysis_list_about_ms/&#34;&gt;LIST | 社科(经管)数据挖掘文献资料汇总&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/2024-06-16-scrapegraph-ai/&#34;&gt;网络爬虫 | 使用scrapegraph-ai(大模型方案)自动采集网页数据&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/2024-04-27-cntext2x-usage-tutorial/&#34;&gt;推荐 | 文本分析库cntext2.x使用手册&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/management_python_course/&#34;&gt;付费视频课 | Python实证指标构建与文本分析&lt;/a&gt;
&lt;br&gt;
&lt;br&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
      <content:encoded><![CDATA[<p>非结构文本、图片、视频等数据是待挖掘的数据矿藏， 在经管、社科等研究领域中谁拥有了<em><strong>从非结构提取结构化信息的能力</strong></em>，谁就拥有科研上的数据优势。</p>
<p><br><br></p>
<h2 id="一需求">一、需求</h2>
<p>现在有很多个电子发票PDF文件， 使用自动化工具帮我们批量自动从发票PDF提取出格式化信息。如从发票</p>
<p><img loading="lazy" src="img/01-raw-pdf.png" alt=""  />
</p>
<p>提取出DICT_DATA</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">DICT_DATA = {
    &#34;开票日期&#34;: &#34;2023年01月06日&#34;,
    &#34;应税货物(或服务)名称&#34;: &#34;*信息技术服务*技术服务费&#34;,
    &#34;价税合计(大写)&#34;: &#34;&#34;,
    &#34;税率&#34;: &#34;6%&#34;,
    &#34;备注&#34;: &#34;230106163474406331&#34;
}
</code></pre></div><p><br><br></p>
<h2 id="二ollama介绍">二、Ollama介绍</h2>
<p><a href="https://ollama.ai/"><strong>Ollama</strong></a>是一款开源应用程序，可让您使用 MacOS、Linux 和 Windows 上的命令行界面在本地运行、创建和共享大型语言模型。</p>
<p>Ollama 可以直接从其库中访问各种 LLM，只需一个命令即可下载。下载后，只需执行一个命令即可开始使用。这对于工作量围绕终端窗口的用户非常有帮助。如果他们被困在某个地方，他们可以在不切换到另一个浏览器窗口的情况下获得答案。</p>
<br>
<h3 id="21-特点和优点">2.1 特点和优点</h3>
<p>这就是为什么 OLLAMA 是您的工具包中必备的工具：</p>
<ul>
<li><strong>简单</strong> ：OLLAMA 提供简单的设置过程。您无需拥有机器学习博士学位即可启动和运行它。</li>
<li><strong>成本效益</strong> ：在本地运行模型意味着您无需支付云成本。您的钱包会感谢您。</li>
<li><strong>隐私</strong> ：使用 OLLAMA，所有数据处理都在您的本地机器上进行。这对于用户隐私来说是一个巨大的胜利。</li>
<li><strong>多功能性</strong> ：OLLAMA 不只是为 Python 爱好者准备的。它的灵活性使其可以用于各种应用程序，包括 Web 开发。</li>
</ul>
<br>
<h3 id="22-使用-ollama-进行-llm-选择">2.2 使用 Ollama 进行 LLM 选择</h3>
<p>默认情况下，Openai Models 在 CrewAI 中用作 llm。有经费、有网络、不担心数据泄露等条件下,  力求达到最佳性能，可考虑使用 GPT-4 或 OpenAI 稍便宜的 GPT-3.5。</p>
<p>但本文是要 <strong>本地部署</strong>， 因此我们将使用 Meta Llama 3，这是迄今为止功能最强大的公开 LLM。Meta Llama 3 是 Meta Inc. 开发的模型系列，是最新推出的模型，具有 8B 和 70B 两种参数大小（预训练或指令调整）。Llama 3 指令调整模型针对对话/聊天用例进行了微调和优化，并且在常见基准测试中胜过许多可用的开源聊天模型。</p>
<p><img loading="lazy" src="img/02-llama3-performance.png" alt=""  />
</p>
<p><img loading="lazy" src="img/03-llama3-performance.png" alt=""  />
</p>
<br>
<h3 id="23-安装ollama">2.3 安装ollama</h3>
<p>点击前往网站 <a href="https://ollama.com/">https://ollama.com/</a> ，下载ollama软件，支持win、Mac、linux</p>
<p><img loading="lazy" src="img/04-ollama-gui.png" alt=""  />
</p>
<br>
<h3 id="24-下载llm">2.4 下载LLM</h3>
<p>ollama软件目前支持多种大模型， 如阿里的（qwen、qwen2）、meta的(llama3、llama3.1)，</p>
<p><img loading="lazy" src="img/05-ollama-model.png" alt=""  />
</p>
<br>
<p>以llama3为例，根据自己电脑显存性能， 选择适宜的版本。如果不知道选什么，那就试着安装，不合适不能用再删除即可。</p>
<p><img loading="lazy" src="img/06-ollama-llama3.png" alt=""  />
</p>
<br>
<p>打开电脑命令行cmd(mac是terminal),  网络是连网状态，执行模型下载(安装)命令</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">ollama pull llama3
</code></pre></div><p>等待 <strong>llama3:8b</strong> 下载完成。</p>
<br>
<h3 id="25-安装python包">2.5 安装python包</h3>
<p>在python中调用ollama服务，需要ollama包。</p>
<p>打开电脑命令行cmd(mac是terminal),  网络是连网状态，执行安装命令</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">pip3 install ollama
</code></pre></div><br>
<h3 id="26-启动ollama服务">2.6 启动ollama服务</h3>
<p>在Python中调用本地ollama服务，需要先启动本地ollama服务， 打开电脑命令行cmd(mac是terminal), 执行</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">ollama serve
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">2024/06/14 14:52:24 routes.go:1011: INFO server config env=&#34;map[OLLAMA_DEBUG:false OLLAMA_FLASH_ATTENTION:false OLLAMA_HOST:http://127.0.0.1:11434 OLLAMA_KEEP_ALIVE: OLLAMA_LLM_LIBRARY: OLLAMA_MAX_LOADED_MODELS:1 OLLAMA_MAX_QUEUE:512 OLLAMA_MAX_VRAM:0 OLLAMA_MODELS:/Users/deng/.ollama/models OLLAMA_NOHISTORY:false OLLAMA_NOPRUNE:false OLLAMA_NUM_PARALLEL:1 OLLAMA_ORIGINS:[http://localhost https://localhost http://localhost:* https://localhost:* http://127.0.0.1 https://127.0.0.1 http://127.0.0.1:* https://127.0.0.1:* http://0.0.0.0 https://0.0.0.0 http://0.0.0.0:* https://0.0.0.0:* app://* file://* tauri://*] OLLAMA_RUNNERS_DIR: OLLAMA_TMPDIR:]&#34;
time=2024-06-14T14:52:24.742+08:00 level=INFO source=images.go:725 msg=&#34;total blobs: 18&#34;
time=2024-06-14T14:52:24.742+08:00 level=INFO source=images.go:732 msg=&#34;total unused blobs removed: 0&#34;
time=2024-06-14T14:52:24.743+08:00 level=INFO source=routes.go:1057 msg=&#34;Listening on 127.0.0.1:11434 (version 0.1.44)&#34;
time=2024-06-14T14:52:24.744+08:00 level=INFO source=payload.go:30 msg=&#34;extracting embedded files&#34; dir=/var/folders/y0/4gqxky0s2t94x1c1qhlwr6100000gn/T/ollama4239159529/runners
time=2024-06-14T14:52:24.772+08:00 level=INFO source=payload.go:44 msg=&#34;Dynamic LLM libraries [metal]&#34;
time=2024-06-14T14:52:24.796+08:00 level=INFO source=types.go:71 msg=&#34;inference compute&#34; id=0 library=metal compute=&#34;&#34; driver=0.0 name=&#34;&#34; total=&#34;72.0 GiB&#34; available=&#34;72.0 GiB&#34;
</code></pre></div><p>cmd(mac是terminal)看到如上的信息，说明本地ollama服务已开启。</p>
<p><br><br></p>
<h2 id="三实验">三、实验</h2>
<h3 id="31-代码结构">3.1 代码结构</h3>
<p>点击下载 <a href="project.zip">本文代码</a></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">project
   |
  - 代码.ipynb   #代码
  - prompt.txt  #提示模板
  - data
      |--- 1.pdf #实验的发票
  - result.csv   #结果
</code></pre></div><br>
<h3 id="32-读取pdf">3.2 读取pdf</h3>
<p><img loading="lazy" src="img/01-raw-pdf.png" alt=""  />
</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>
<span class="c1">#cntext版本为2.1.3，非开源， #需联系大邓372335839获取</span>

<span class="n">text</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">read_pdf</span><span class="p">(</span><span class="s1">&#39;data/1.pdf&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">ct</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span>
<span class="n">text</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">2.1.3

&#39; 北京增值税电子普通发票发票代码： \n发票号码： 69453658\n开票日期： 2023年01月06日\n校 验 码： \n购\n买\n方名        称： 哈尔滨所以然信息技术有限公司\n密\n码\n区030898/5&lt;32&gt;*/0*440/63+79*08\n纳税人识别号： 91230109MABT7KBC4M /&lt;54&lt;1*6+49&lt;-*+*&gt;7&lt;-8*04&lt;+01\n地 址、电 话： 68+160026-45904*2&lt;+3+15503&gt;2\n开户行及账号： 98*2/*-*480145+-19*0917-1*61\n货物或应税劳务、服务名称 规格型号 单 位 数 量 单 价 金 额 税率 税 额\n*信息技术服务*技术服务费 1248.113208 248.11 6% 14.89\n合      计 ￥248.11 ￥14.89\n价税合计（大写）\n  贰佰陆拾叁元整             （小写）￥263.00\n销\n售\n方名        称： \n备\n注230106163474406331\n纳税人识别号： 91110108MA01WFY0X6\n地 址、电 话： \n开户行及账号： \n  收款人： 复核： 开票人： 销售方：（章）&#39;
</code></pre></div><br>
<h3 id="34-提取信息">3.4 提取信息</h3>
<p>使用ollama服务中的大模型 <em><strong>llama3:8b</strong></em> , 需要大模型提示信息及数据。这是我实验里设计的提示信息prompt</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">prompt = open(&#39;prompt.txt&#39;, encoding=&#39;utf-8&#39;).read()
print(prompt)
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">发票文本内容
--- 
{TEXT} 
---

以 JSON 格式回答。 JSON 应包含如下信息， 依次为&#34;开票日期&#34;, &#34;应税货物(或服务)名称&#34;, &#34;价税合计(大写)&#34;, &#34;税率&#34;, &#34;备注&#34;; 
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="o">%%</span><span class="n">time</span>

<span class="kn">import</span> <span class="nn">ollama</span>
<span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>
<span class="c1">#cntext版本为2.1.3，非开源， 需联系大邓372335839获取</span>

<span class="c1">#读取发票pdf</span>
<span class="n">content</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">read_pdf</span><span class="p">(</span><span class="s1">&#39;data/1.pdf&#39;</span><span class="p">)</span>
<span class="c1">#读取prompt</span>
<span class="n">prompt</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;prompt.txt&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>

<span class="n">response</span> <span class="o">=</span> <span class="n">ollama</span><span class="o">.</span><span class="n">chat</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s1">&#39;llama3:8b&#39;</span><span class="p">,</span> <span class="n">messages</span><span class="o">=</span><span class="p">[</span>
      <span class="p">{</span><span class="s1">&#39;role&#39;</span><span class="p">:</span> <span class="s1">&#39;system&#39;</span><span class="p">,</span><span class="s1">&#39;content&#39;</span><span class="p">:</span> <span class="n">prompt</span><span class="p">},</span>
      <span class="p">{</span><span class="s1">&#39;role&#39;</span><span class="p">:</span> <span class="s1">&#39;user&#39;</span><span class="p">,</span><span class="s1">&#39;content&#39;</span><span class="p">:</span> <span class="n">content</span><span class="p">},</span>
    <span class="p">])</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">response</span><span class="p">[</span><span class="s1">&#39;message&#39;</span><span class="p">][</span><span class="s1">&#39;content&#39;</span><span class="p">]</span>
<span class="n">result</span> <span class="o">=</span> <span class="nb">eval</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;```</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">```&#39;</span><span class="p">)[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">result</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">CPU times: user 20.5 ms, sys: 2.34 ms, total: 22.9 ms
Wall time: 3.58 s

{&#39;开票日期&#39;: &#39;2023年01月06日&#39;,
 &#39;应税货物(或服务)名称&#39;: &#39;*信息技术服务*技术服务费&#39;,
 &#39;价税合计(大写)&#39;: &#39;贰佰陆拾叁元整&#39;,
 &#39;税率&#39;: &#39;6%&#39;,
 &#39;备注&#39;: &#39;230106163474406331&#39;}
</code></pre></div><br>
<h3 id="33-封装成函数extract_info">3.3 封装成函数extract_info</h3>
<p>实验成功，我们将其封装为函数<em><strong>extract_info</strong></em>， 为增强代码的鲁棒性， 函数内设置了异常处理机制，最多可重试3次。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">ollama</span>
<span class="kn">import</span> <span class="nn">re</span>


<span class="k">def</span> <span class="nf">extract_info</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">prompt</span><span class="p">,</span> <span class="n">max_retries</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">attempt</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_retries</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">response</span> <span class="o">=</span> <span class="n">ollama</span><span class="o">.</span><span class="n">chat</span><span class="p">(</span>
                <span class="n">model</span><span class="o">=</span><span class="s1">&#39;llama3:8b&#39;</span><span class="p">,</span>
                <span class="n">messages</span><span class="o">=</span><span class="p">[</span>
                    <span class="p">{</span><span class="s1">&#39;role&#39;</span><span class="p">:</span> <span class="s1">&#39;system&#39;</span><span class="p">,</span> <span class="s1">&#39;content&#39;</span><span class="p">:</span> <span class="n">prompt</span><span class="p">},</span>
                    <span class="p">{</span><span class="s1">&#39;role&#39;</span><span class="p">:</span> <span class="s1">&#39;user&#39;</span><span class="p">,</span> <span class="s1">&#39;content&#39;</span><span class="p">:</span> <span class="n">text</span><span class="p">}</span>
                <span class="p">]</span>
            <span class="p">)</span>

            <span class="n">result</span> <span class="o">=</span> <span class="n">response</span><span class="p">[</span><span class="s1">&#39;message&#39;</span><span class="p">][</span><span class="s1">&#39;content&#39;</span><span class="p">]</span>
            <span class="n">result</span> <span class="o">=</span> <span class="nb">eval</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;```</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">```&#39;</span><span class="p">)[</span><span class="mi">0</span><span class="p">])</span>
            <span class="k">return</span> <span class="n">result</span>
        
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">attempt</span> <span class="o">&lt;</span> <span class="n">max_retries</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;An error occurred: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">. Retrying (</span><span class="si">{</span><span class="n">attempt</span> <span class="o">+</span> <span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">max_retries</span> <span class="o">+</span> <span class="mi">1</span><span class="si">}</span><span class="s2">)...&#34;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="n">e</span>
  
<span class="c1">#读取prompt</span>
<span class="n">prompt</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;prompt.txt&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">extract_info</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">prompt</span><span class="p">)</span>
<span class="n">result</span>
</code></pre></div><p>result与之前无异， 为了节省版面，这里就不显示result。</p>
<br>
<h3 id="34-批量提取">3.4 批量提取</h3>
<p>假设data文件夹内有成百上千的发票(实际上只有一张发票)， 对data文件夹进行批量信息提取，结果存储为csv。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="o">%%</span><span class="n">time</span>

<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">ollama</span>
<span class="c1">#cntext版本为2.1.3，非开源， 需联系大邓372335839获取</span>
<span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>


<span class="k">def</span> <span class="nf">extract_info</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">prompt</span><span class="p">,</span> <span class="n">max_retries</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">attempt</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_retries</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">response</span> <span class="o">=</span> <span class="n">ollama</span><span class="o">.</span><span class="n">chat</span><span class="p">(</span>
                <span class="n">model</span><span class="o">=</span><span class="s1">&#39;llama3:8b&#39;</span><span class="p">,</span>
                <span class="n">messages</span><span class="o">=</span><span class="p">[</span>
                    <span class="p">{</span><span class="s1">&#39;role&#39;</span><span class="p">:</span> <span class="s1">&#39;system&#39;</span><span class="p">,</span> <span class="s1">&#39;content&#39;</span><span class="p">:</span> <span class="n">prompt</span><span class="p">},</span>
                    <span class="p">{</span><span class="s1">&#39;role&#39;</span><span class="p">:</span> <span class="s1">&#39;user&#39;</span><span class="p">,</span> <span class="s1">&#39;content&#39;</span><span class="p">:</span> <span class="n">text</span><span class="p">}</span>
                <span class="p">]</span>
            <span class="p">)</span>

            <span class="n">result</span> <span class="o">=</span> <span class="n">response</span><span class="p">[</span><span class="s1">&#39;message&#39;</span><span class="p">][</span><span class="s1">&#39;content&#39;</span><span class="p">]</span>
            <span class="n">result</span> <span class="o">=</span> <span class="nb">eval</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;```</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">```&#39;</span><span class="p">)[</span><span class="mi">0</span><span class="p">])</span>
            <span class="k">return</span> <span class="n">result</span>
        
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">attempt</span> <span class="o">&lt;</span> <span class="n">max_retries</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;An error occurred: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">. Retrying (</span><span class="si">{</span><span class="n">attempt</span> <span class="o">+</span> <span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">max_retries</span> <span class="o">+</span> <span class="mi">1</span><span class="si">}</span><span class="s2">)...&#34;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="n">e</span>
                
  
<span class="c1">#当前代码所在的代码文件与data文件夹处于同一个文件夹内</span>
<span class="c1">#获取data内所有pdf的路径</span>
<span class="n">pdf_files</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s1">&#39;data/</span><span class="si">{</span><span class="n">file</span><span class="si">}</span><span class="s1">&#39;</span> <span class="k">for</span> <span class="n">file</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="s1">&#39;data&#39;</span><span class="p">)</span> <span class="k">if</span> <span class="s1">&#39;.pdf&#39;</span> <span class="ow">in</span> <span class="n">file</span><span class="p">]</span>
<span class="c1">#读取prompt</span>
<span class="n">prompt</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;prompt.txt&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>

<span class="n">dict_datas</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">pdf_file</span> <span class="ow">in</span> <span class="n">pdf_files</span><span class="p">:</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">read_pdf</span><span class="p">(</span><span class="n">pdf_file</span><span class="p">)</span>
    <span class="n">dict_data</span> <span class="o">=</span> <span class="n">extract_info</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">prompt</span><span class="p">)</span>
    <span class="n">dict_datas</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dict_data</span><span class="p">)</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">dict_datas</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;result.csv&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">df</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">CPU times: user 32 ms, sys: 2.17 ms, total: 15.2 ms
Wall time: 3.8 s
</code></pre></div><p><img loading="lazy" src="img/05-df.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="四讨论">四、讨论</h2>
<p>本文只使用了一张发票进行实验， 实际上准确率没有这么高， 识别错误字段集中在销售方纳税识别号(案例没有展示销售方纳税识别号的识别)。原因主要是ct.read_pdf读入pdf时，文本比较杂乱。对大模型的语义理解有一定的挑战。目前大模型已经支持文本、图片、音频、视频、网址， 所以各位看官，不用等太久，就可克服此问题。</p>
<p>大模型会对每个输入，给出正确概率最大的回答，因此大模型提取数据时存在一定的错误识别风险。为降低该风险，尽量选择特别特殊、显眼，例如三张发票的<strong>价税合计(大写)</strong>,  因为信息是特殊的中文大写数字， 在所有文本中是最醒目最特别的文本信息，这样大模型处理这类信息时会给这类信息尽可能高的权重，增大回答的准确率。</p>
<br>
<br>
<h2 id="精选内容">精选内容</h2>
<ul>
<li><a href="https://textdata.cn/blog/datasets_available_for_management_science/">LIST | 可供社科(经管)领域使用的数据集汇总</a></li>
<li><a href="https://textdata.cn/blog/the_text_analysis_list_about_ms/">LIST | 社科(经管)数据挖掘文献资料汇总</a></li>
<li><a href="https://textdata.cn/blog/2024-06-16-scrapegraph-ai/">网络爬虫 | 使用scrapegraph-ai(大模型方案)自动采集网页数据</a></li>
<li><a href="https://textdata.cn/blog/2024-04-27-cntext2x-usage-tutorial/">推荐 | 文本分析库cntext2.x使用手册</a></li>
<li><a href="https://textdata.cn/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a>
<br>
<br></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>Word Embeddings、Transformer与GPT：一文揭示三者关系</title>
      <link>https://textdata.cn/blog/2023-11-16-how-to-understand-the-meaning-of-gpt/</link>
      <pubDate>Thu, 16 Nov 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-11-16-how-to-understand-the-meaning-of-gpt/</guid>
      <description>&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;作者: 7号床
公众号: 7号床
原文  https://zhuanlan.zhihu.com/p/666206302
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;一gpt-的名词解释&#34;&gt;一、GPT 的名词解释&lt;/h2&gt;
&lt;p&gt;著名的 &lt;strong&gt;GPT&lt;/strong&gt; 这个名字全称是 &lt;strong&gt;Generative Pre-trained Transformer&lt;/strong&gt;。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Generative&lt;/strong&gt; 是&amp;quot;生成式&amp;quot;的意思，也就是说这个 AI 模型是用来生成内容的。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Pre-trained&lt;/strong&gt; 是“预训练”的意思，就是说这个 AI 模型能有很强的能力，是因为他事先做了大量的训练，台上一分钟台下十年功。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Transformer&lt;/strong&gt; , 就有点耐人寻味了，不仅普通人不理解，就连很多专业领域的人员理解起来也都是含混不清、似是而非。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/1.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;center&gt;ChatGPT 是 GPT 大模型在聊天对话领域的应用程序&lt;/center&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Transformer&lt;/strong&gt; 作为单词，翻译出来频率最高的意思是 &lt;strong&gt;变压器&lt;/strong&gt;，然后是 &lt;strong&gt;变形金刚&lt;/strong&gt; ，还有一些引申的含义是 &lt;strong&gt;转换器&lt;/strong&gt; 、&lt;strong&gt;促使变化者&lt;/strong&gt; 、&lt;strong&gt;转变者&lt;/strong&gt; 或 &lt;strong&gt;改革者&lt;/strong&gt;等等。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/2.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;center&gt;谷歌翻译上对 **Transformer** 的英译中翻译&lt;/center&gt;&lt;/p&gt;
&lt;p&gt;再把 &lt;strong&gt;Transformer&lt;/strong&gt; 放到  &lt;strong&gt;Chat Generative Pre-trained Transformer&lt;/strong&gt; 中看看，突然间变得奇怪了，难道 ChatGPT 借鉴了变压器的技术？还是说 ChatGPT 是一个变形金刚？或者索性就翻译成通用的安全的叫法 &lt;strong&gt;转换器&lt;/strong&gt; ？这让人百思不得其解。&lt;/p&gt;
&lt;p&gt;光光从 GPT 这三个字母的组合就能看出来， &lt;strong&gt;Generative&lt;/strong&gt; 与 &lt;strong&gt;Pre-trained&lt;/strong&gt; 都是定语，而 &lt;strong&gt;Transformer 才是 GPT 的主体，才是 GPT 的灵魂&lt;/strong&gt;所在。可以说，理解透了 &lt;strong&gt;Transformer&lt;/strong&gt; 的真正含义，才能初步地理解 GPT。另一方面， Transformer 这个词太重要了。它在这几年的人工智能领域大放异彩，不仅仅局限于 NLP 自然语言处理领域，它还有着更广阔的发展空间。 Transformer 目前已经进入到了多模态领域，比如音频与视觉，甚至数学公式、代码编程等领域，著名的 **Stable Diffusion 中也用到了 Transformer **。&lt;strong&gt;可以说，所有生成式人工智能领域的大模型中目前都有了这个 Transformer 的身影&lt;/strong&gt;。既然如此重要，那就让我们深入地探究一下 &lt;strong&gt;Transformer&lt;/strong&gt; 在人工智能领域最确切的最标准的含义到底是什么吧！&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Transformer&lt;/strong&gt; 最早是由 Google 的人工智能团队提出来的。在2017 年6月发表的论文**《Attention Is All You Need》中，他们首次提出了一种新的神经网络架构 Transformer**。Transformer 依赖于一个叫“自注意力机制”（ Self-Attention）的内部构件，可十分准确高效地对自然语言领域的问题进行处理，以完美地解决翻译、对话、论文协作甚至编程等复杂的问题。&lt;/p&gt;
&lt;p&gt;顺藤摸瓜可以看出，&lt;strong&gt;GTP 的核心是 Transformer，而 Transformer 的核心则是“自注意力机制”（ Self-Attention）&lt;/strong&gt;。那么这个“自注意力机制”又是什东西呢？让我们用语言翻译领域的几个简单易懂的例子来讲解一下。&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;二-transformer-的核心-self-attention&#34;&gt;二、 Transformer 的核心 Self-Attention&lt;/h2&gt;
&lt;p&gt;首先，看下面这两个短句：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;句子I&lt;/strong&gt;：The bank of the river.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;句子II&lt;/strong&gt;：Money in the bank.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在翻译成中文的过程中，机器算法是如何知道“句子I”中的“bank”指的是自然环境中的“岸边”，而“句子II”中的“bank”指的是金融体系中的“银行”呢？&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/3.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;center&gt;bank在不同句子中指代不同的事物&lt;/center&gt;&lt;/p&gt;
&lt;h3 id=&#34;21-人类脑中的翻译算法&#34;&gt;2.1 人类脑中的翻译算法&lt;/h3&gt;
&lt;p&gt;作为人类的我们当然会觉得这是一个再简单不过的事情了，那是因为我们的语言技能从幼儿发展到成年人后，早已烂熟于心了。但即使烂熟于心，也并不意味着在我们的大脑中没有对应的计算过程。&lt;strong&gt;实际上人工智能的翻译过程就是对我们人脑中的计算过程的模拟&lt;/strong&gt;。那么就让我们回想一下儿童时期学习语言时的情景吧，回想一下当时的我们是怎么知道一个多义词在某一句话中具体的含义的？&lt;/p&gt;
&lt;p&gt;人类做这件事的方法是根据 &lt;strong&gt;前后文的语义对照&lt;/strong&gt; 来确定结果，即看句子中其他相关联的单词是什么含义。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在 &lt;strong&gt;句子I&lt;/strong&gt; 中， &lt;em&gt;&lt;strong&gt;river&lt;/strong&gt;&lt;/em&gt; 这个词指明了自然环境，&lt;/li&gt;
&lt;li&gt;而在 &lt;strong&gt;句子II&lt;/strong&gt;中， &lt;em&gt;&lt;strong&gt;money&lt;/strong&gt;&lt;/em&gt; 这个词则指明了金融环境。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;所以两个句子中的多义词“bank”也就有了各自的定位。如果把这种方式总结成一种算法的话，这个算法就可以用于人工智能领域用于语言处理了。&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;22-机器算法模拟人脑中的翻译过程&#34;&gt;2.2 机器算法模拟人脑中的翻译过程&lt;/h3&gt;
&lt;p&gt;但人工智能作为一种计算机算法，它只能处理冷冰冰的数字，并不知道何为自然环境，何为金融环境，它又是怎么去判断 &lt;em&gt;&lt;strong&gt;river&lt;/strong&gt;&lt;/em&gt; 和 &lt;em&gt;&lt;strong&gt;money&lt;/strong&gt;&lt;/em&gt; 各自的含义呢。实际上，机器算法并不知道 &lt;em&gt;&lt;strong&gt;river&lt;/strong&gt;&lt;/em&gt; 和 &lt;em&gt;&lt;strong&gt;money&lt;/strong&gt;&lt;/em&gt; 的具体含义。但是机器可以通过某种数字的方式来表达 &lt;em&gt;&lt;strong&gt;river&lt;/strong&gt;&lt;/em&gt; 和 &lt;em&gt;&lt;strong&gt;money&lt;/strong&gt;&lt;/em&gt; ，同时，通过数字的方式还表达了许许多多其他的词汇，其中必然会有一些词汇会与 &lt;em&gt;&lt;strong&gt;river&lt;/strong&gt;&lt;/em&gt; 和 &lt;em&gt;&lt;strong&gt;money&lt;/strong&gt;&lt;/em&gt; 有着很紧密的语义上的逻辑关系。通过判断 &lt;em&gt;&lt;strong&gt;river&lt;/strong&gt;&lt;/em&gt; 和 &lt;em&gt;&lt;strong&gt;money&lt;/strong&gt;&lt;/em&gt; 各与哪些词汇在语义上有紧密的逻辑关系，便可以知道这两个词各属于什么领域了。&lt;/p&gt;
&lt;p&gt;（其实，不像人类会对某个领域有一个具体的名称来命名，在人工智能领域，机器最终也不知道这个领域的统称到底叫什么名字，但它却知道这个领域中都包括了哪些词、哪些概念和哪些逻辑。***机器不以单独名称来定义一个概念，它却可以用很多相关的概念与逻辑来圈定这一个概念！***这可能就是老子说的：道可道非常道，名可名非常名吧。）&lt;/p&gt;
&lt;br&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;独热编码法(One-hot Encoding)&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;那么就让我们看看这种数字表达方式具体是什么样子吧。&lt;/p&gt;
&lt;p&gt;假设这个世界上有100万个单词，每一个单词，我们都可以用一组 0 和 1 组成的向量（一组数字）来定义的话，那么每一个单词就可以被编码成100万个0或1组成的向量。如下图：&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/4.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;center&gt;独热编码示例&lt;/center&gt;&lt;/p&gt;
&lt;p&gt;这种单词编码方法叫 **独热编码法(One-hot Encoding)**法。可是这样一维的编码方法将导致向量占用的空间过大，1个单词用100万个单元的向量表达，世界上一共有100万个单词，那么就需要 1万亿（100万*100万）的体积来把它们表达出来，很明显这种臃肿的结构不利于电脑计算。&lt;/p&gt;
&lt;p&gt;但最大的问题还不在于这个体积问题，而是语义联系问题。独热编码使得单词与单词之间完全相互独立，从每个单词所编码成为的100万个单元的向量身上，根本看不出它与其他单词有何种语义内涵上的逻辑联系。比如，在这些数字中，我们无法知道 &lt;em&gt;&lt;strong&gt;apple&lt;/strong&gt;&lt;/em&gt; 和 &lt;em&gt;&lt;strong&gt;bag&lt;/strong&gt;&lt;/em&gt; 属于静物，区别于 cat 和 &lt;em&gt;&lt;strong&gt;dog&lt;/strong&gt;&lt;/em&gt;、&lt;em&gt;&lt;strong&gt;elephant&lt;/strong&gt;&lt;/em&gt; 属于动物且是哺乳动物，而 &lt;em&gt;&lt;strong&gt;cat&lt;/strong&gt;&lt;/em&gt;  和 &lt;em&gt;&lt;strong&gt;dog&lt;/strong&gt;&lt;/em&gt; 又属于小动物，且大多数为非野生，区别于 &lt;em&gt;&lt;strong&gt;elephant&lt;/strong&gt;&lt;/em&gt; 为大型的野生动物，等等等等，这些单词背后所蕴含的各种内在的逻辑联系和分类关系均无法从独热编码法中知晓。实际上独热编码是传统计算机数据库时代的产物，而在人工智能领域则采用另一种编码法。为了解决独热编码的问题， &lt;strong&gt;词嵌入编码法(Word Embedding)&lt;/strong&gt; 诞生了，如下图：&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/5.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;center&gt;Word Embedding 词嵌入编码示意，及 Embedding 空间&lt;/center&gt;&lt;/p&gt;
&lt;br&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;词嵌入编码法(Word Embedding)&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;**词嵌入编码法(Word Embedding)**将语义上相近的、有关联的词汇在 Embedding 空间中生成相近的位置定位。相对于 &lt;strong&gt;独热编码法&lt;/strong&gt; 超长的一维数据，词嵌入编码法(Word Embedding) 提升了数据的表达维度，它更像是在某一个 &lt;strong&gt;空间&lt;/strong&gt; 中对词汇进行编码。&lt;/p&gt;
&lt;p&gt;如上图（为了在此文章中表达方便，我们仅用二维空间来表达，实际上这个空间的维度很高，至少要在512维之上！一维二维三维的空间大家都可以在脑中想象出来对应的画面，但是四维以上以至于 512 维就难以图形化的想象了。），在 Embedding 的二维空间中 &lt;em&gt;&lt;strong&gt;dog&lt;/strong&gt;&lt;/em&gt;、 &lt;em&gt;&lt;strong&gt;cat&lt;/strong&gt;&lt;/em&gt; 、&lt;em&gt;&lt;strong&gt;rabbit&lt;/strong&gt;&lt;/em&gt; 三个向量的坐标点位排布，可以看到三个绿色的点距离很近，是因为他们三个相对于其他来说语义上更接近。tree 和 flower 则离它们较远，但是 &lt;em&gt;&lt;strong&gt;cat&lt;/strong&gt;&lt;/em&gt; 会因为在很多语言的文章中都会有“爬树”的词汇出现在同一句话中，所以导致  &lt;em&gt;&lt;strong&gt;cat&lt;/strong&gt;&lt;/em&gt;  会与  &lt;em&gt;&lt;strong&gt;tree&lt;/strong&gt;&lt;/em&gt;  离得较近一些。同时 &lt;em&gt;&lt;strong&gt;dog&lt;/strong&gt;&lt;/em&gt;、 &lt;em&gt;&lt;strong&gt;rabbit&lt;/strong&gt;&lt;/em&gt;  与  &lt;em&gt;&lt;strong&gt;tree&lt;/strong&gt;&lt;/em&gt; 的关系就较远。&lt;/p&gt;
&lt;p&gt;实际上，在 Embedding 空间中，词与词之间的关系还不仅仅限于语义上的分类所导致的定位远近这么简单。一个词所代表的事物与其他词所代表的事物之间能产生内在联系的往往有成百上千上万种之多。比如  &lt;em&gt;&lt;strong&gt;man&lt;/strong&gt;&lt;/em&gt;  和  &lt;em&gt;&lt;strong&gt;woman&lt;/strong&gt;&lt;/em&gt; ，他们之间的关系还会映射出  &lt;em&gt;&lt;strong&gt;king&lt;/strong&gt;&lt;/em&gt;  和  &lt;em&gt;&lt;strong&gt;queen&lt;/strong&gt;&lt;/em&gt;  之间的关系。同时，语法也会带来一定的联系，比如在一个三维空间中由  &lt;em&gt;&lt;strong&gt;walking&lt;/strong&gt;&lt;/em&gt;  到 &lt;em&gt;&lt;strong&gt;walked&lt;/strong&gt;&lt;/em&gt;  的距离与斜率竟然与  &lt;em&gt;&lt;strong&gt;swimming&lt;/strong&gt;&lt;/em&gt;  到 &lt;em&gt;&lt;strong&gt;swam&lt;/strong&gt;&lt;/em&gt; 的距离与斜率一致（即向量的长度与斜率一致），且距离几乎相等。因为这背后是两组动作单词的现在分词形式和过去分词形式的变化关系。我们可以尽情地想象，凡是事物或概念有逻辑联系的，甚至是逻辑与逻辑之间的联系的，在 Embedding 向量空间中都可以得到远近亲疏的空间表达。只不过这种空间要比我们能想象出的三维空间要高出很多维度。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/6.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;center&gt;在 Embedding 空间中隐含的内在逻辑关系&lt;/center&gt;&lt;/p&gt;
&lt;p&gt;Word Embedding 之所以能给每一个单词做这样有意义的向量空间的标注，是因为 AI 科学家们事先用了全球十多种主流语言的大量语料给它进行了训练。这些语料有小说、论文、学术期刊、网络文章、新闻报道、论坛对话记录等等等等，应有尽有，数以百亿到千亿计。可以说，这些海量的文字资料都是人类从古至今感受发现这个世界各个方面的文字总结和积累。现实世界中各种事物之间的逻辑关系都被人类用这些文字记录了下来，只是有的是用严谨的论文方式，有的是用写意的小说方式，有的使用类似维基百科这样的系统梳理，有的则是人们在网络论坛中的对话记录&amp;hellip;等等等等。但不管是什么方式，都是人类试图用语言对这个世界的描述。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;语言是人类最伟大的发明&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;笔者7号床曾经问过  ChatGPT  一个问题：&lt;em&gt;&lt;strong&gt;“人类最伟大的发明是什么”&lt;/strong&gt;&lt;/em&gt; ，ChatGPT的回答是：&lt;em&gt;&lt;strong&gt;“语言！”&lt;/strong&gt;&lt;/em&gt;。之后，ChatGPT 进一步回答，因为语言以及匹配语言的文字与符号，它们让人类把对世界的感受与理解记录下来，形成了知识宝库。方便全人类一代一代地不断完善这个宝库，并从中总结凝练、学习、创造、传承。语言是人类产生文明并开始与其他动物分道扬镳的分叉点。&lt;/p&gt;
&lt;p&gt;很多人曾经十分疑惑，人工智能吹得那么先进，却从一个 ChatGPT 聊天功能开始火爆起来。难道每天不干正事专门闲聊就证明了人工智能的先进性吗？现在看来，这个问题的答案已经浮出水面了，OpenAI 的团队选择通过聊天软件 ChatGPT 作为 GPT 启程的第一步是经过深思熟虑的。&lt;/p&gt;
&lt;p&gt;下面让我们回到正题。&lt;/p&gt;
&lt;p&gt;人类的知识宝库中存储着海量的信息
ChatGPT 所说的这个知识宝库现在变得越来越庞大、越来越复杂了。这世界上并不存在任何一个肉身的人类有能力做到对宝库中所有信息进行消化整理，因为内容体量过于庞大、过于复杂。而一个人的阅览进度却又是十分有限，以至于在他的有生之年，哪怕完成其中的万分之一都比登天还难。于是，迫不得已，人类才喊出了 &lt;em&gt;&lt;strong&gt;“闻道有先后，术业有专攻”&lt;/strong&gt;&lt;/em&gt; ，每个人类个体才转而去研究具体某一领域。&lt;/p&gt;
&lt;p&gt;另一方面，人类早期发明的纸张和印刷术，以至于后来的计算机芯片存储，倒是可以记录存储下来如此巨量的信息了，但却无法主动地、有机地分析汇总其中所有信息之间的内在逻辑。以至于计算机存储的这些数据越积越多，犹如汪洋大海。&lt;/p&gt;
&lt;p&gt;这个知识宝库的结构就好比一棵万米高的巨大知识树，人类如同蚂蚁一样在树上摸索前行。人类只能将有限的肉身算力资源集中在主要的枝干，对于无数的细枝末节尚无暇顾及，但随着发现的主要枝干越来越多，细枝末节的信息量将呈爆炸的方式展现出来。而对于这颗知识巨树的展示能力，却因为计算机时代的到来而大大加速了进程。但当发现知识树越来越庞大时，人类也认识到了自身的渺小。&lt;/p&gt;
&lt;p&gt;AI （Embedding）开启对知识宝库的挖掘
现在，这一探索知识巨树的任务落到了 AI 的身上，AI 的承载和运算能力超越了过往所有人类个体以及群体能力的总和。AI 通过事先的大量预训练，把这些海量文字用 Word Embedding 的方式抽象地汇总在了大模型之中。Word Embedding 词嵌入编码法，能让每一个单词之间产生应有的语义上的以及背后逻辑关系上的联系。这种联系越紧密，他们在 Embedding 空间中的位置距离越紧密，反之则越远。&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;23-attention-注意力机制&#34;&gt;2.3 Attention 注意力机制&lt;/h3&gt;
&lt;p&gt;想象一下，Google 用了至少千亿级的语料来训练单词在 Embedding 空间中的表达，其中包含了全世界几乎所有语言的词汇量。所以在回过头来考虑一下之前举例中的两句话时，就有了如下这样一副景象：&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/7.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;center&gt;在 Word Embedding 向量空间中 bank、 river 和 money 的向量表达&lt;/center&gt;&lt;/p&gt;
&lt;p&gt;如上图，我们用一个简单的位置关系图来展示一下&lt;em&gt;&lt;strong&gt;bank&lt;/strong&gt;&lt;/em&gt;、 &lt;em&gt;&lt;strong&gt;river&lt;/strong&gt;&lt;/em&gt; 和 &lt;em&gt;&lt;strong&gt;money&lt;/strong&gt;&lt;/em&gt; 这几个单词在 Embedding 空间中的位置关系（在实际 Embedding 空间中的关系要比这个图复杂数百倍，这里只是为了让大家更好地理解关键逻辑而做了简化）。&lt;/p&gt;
&lt;p&gt;由于 “bank” 是一个多义词，所以它在 Embedding 空间中的定位本来是有多个“分身”，我们取其中的两个分身，即“bank1”和“bank2”。那么，我们需要做的就是定位清晰“bank1”和“bank2”这两个单词在空间中到底各自离 &lt;em&gt;&lt;strong&gt;river&lt;/strong&gt;&lt;/em&gt; 和 &lt;em&gt;&lt;strong&gt;money&lt;/strong&gt;&lt;/em&gt; 的哪个单词更近一些。在图中很明显，“bank1”离 &lt;em&gt;&lt;strong&gt;river&lt;/strong&gt;&lt;/em&gt; 更近，而“bank2”离 &lt;em&gt;&lt;strong&gt;money&lt;/strong&gt;&lt;/em&gt; 更近，于是这两句话就变成了：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;**变形后的句子I：**The &lt;strong&gt;bank1&lt;/strong&gt; of the river.&lt;/li&gt;
&lt;li&gt;**变形后的句子II：**Money in the &lt;strong&gt;bank2&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如之前所说，虽然此时机器算法压根也不知道 &lt;em&gt;&lt;strong&gt;river&lt;/strong&gt;&lt;/em&gt; 和 &lt;em&gt;&lt;strong&gt;money&lt;/strong&gt;&lt;/em&gt; 到底是何物，但它知道在Embedding 空间中， &lt;em&gt;&lt;strong&gt;river&lt;/strong&gt;&lt;/em&gt; 周边有很多和大自然有关的词汇，比如  &lt;em&gt;&lt;strong&gt;water&lt;/strong&gt;&lt;/em&gt;、&lt;em&gt;&lt;strong&gt;tree&lt;/strong&gt;&lt;/em&gt;、&lt;em&gt;&lt;strong&gt;fish&lt;/strong&gt;&lt;/em&gt; 等等。而 &lt;em&gt;&lt;strong&gt;money&lt;/strong&gt;&lt;/em&gt; 周边有许多与金融有关的词汇，比如 &lt;em&gt;&lt;strong&gt;currency&lt;/strong&gt;&lt;/em&gt;,  &lt;em&gt;&lt;strong&gt;cash&lt;/strong&gt;&lt;/em&gt; ,  &lt;em&gt;&lt;strong&gt;withdraw&lt;/strong&gt;&lt;/em&gt; 等等。于是，机器算法知道了 &lt;em&gt;&lt;strong&gt;bank1&lt;/strong&gt;&lt;/em&gt; 代表的是与 &lt;em&gt;&lt;strong&gt;river&lt;/strong&gt;&lt;/em&gt; 有关的一个单词，与他们比较近的单词还有   &lt;em&gt;&lt;strong&gt;water&lt;/strong&gt;&lt;/em&gt;、&lt;em&gt;&lt;strong&gt;tree&lt;/strong&gt;&lt;/em&gt;、&lt;em&gt;&lt;strong&gt;fish&lt;/strong&gt;&lt;/em&gt; 等等，而“&lt;strong&gt;bank2&lt;/strong&gt;”代表的是与“&lt;strong&gt;money&lt;/strong&gt;”有关的一个单词，与他们比较接近的单词还有  &lt;em&gt;&lt;strong&gt;currency&lt;/strong&gt;&lt;/em&gt;,  &lt;em&gt;&lt;strong&gt;cash&lt;/strong&gt;&lt;/em&gt; ,  &lt;em&gt;&lt;strong&gt;withdraw&lt;/strong&gt;&lt;/em&gt;  等等。这就是**“Attention 注意力机制”的工作原理，也就是 Attention 让一个单词在句子中找到与它产生强语义联系的其他单词，并组成一个新的变体单词**：&lt;em&gt;&lt;strong&gt;bank1&lt;/strong&gt;&lt;/em&gt;、&lt;em&gt;&lt;strong&gt;bank2&lt;/strong&gt;&lt;/em&gt;。&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;24-self-attention-自注意力机制&#34;&gt;2.4 Self-Attention 自注意力机制&lt;/h3&gt;
&lt;p&gt;然后又有新的问题产生了，机器算法是如何知道一句话中只有 &lt;em&gt;&lt;strong&gt;river&lt;/strong&gt;&lt;/em&gt; 或 &lt;em&gt;&lt;strong&gt;money&lt;/strong&gt;&lt;/em&gt; 这两个词代表了上下文语义的强关联词汇，而不是 &lt;em&gt;&lt;strong&gt;The&lt;/strong&gt;&lt;/em&gt;、&lt;em&gt;&lt;strong&gt;in&lt;/strong&gt;&lt;/em&gt;、&lt;em&gt;&lt;strong&gt;of&lt;/strong&gt;&lt;/em&gt;或其他单词呢？实际上这依旧是 Embedding 空间中每一个单词的空间定位相近程度的问题。（实际上，在 Embedding 空间中，不仅仅名词有各自的位置，动词、介词、形容词等等都有自己的位置，甚至一个词组、一句话也会有自己的位置。）&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/8.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;全句中的每一个单词在 Embedding 空间中定位的相近度是这样来计算的。机器算法会对每一个单词与全句中其他单词逐一地配对，做语义关联程度的计算和比较，最终汇总到表格中，&lt;strong&gt;颜色越深代表语义关联程度越高&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/9.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;center&gt;一个句子中所有单词都做一遍“Attention 注意力机制”&lt;/center&gt;&lt;/p&gt;
&lt;p&gt;我们可以从表格中看出来：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;每一个单词与自己的相似度为最高分 1（一般用数值“1”来代表最大权重，这里的相似度用权重来表达）；&lt;/li&gt;
&lt;li&gt;互不相关的单词之间的语义关联度为 0（其实可能是 0.001 之类的很小的数字，这里做了简化，即值太小，以至于低于某一个阈值而归零处理）；&lt;/li&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;bank&lt;/strong&gt;&lt;/em&gt;  与   &lt;em&gt;&lt;strong&gt;river&lt;/strong&gt;&lt;/em&gt; 的相似度为 0.11；&lt;/li&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;bank&lt;/strong&gt;&lt;/em&gt; 与  &lt;em&gt;&lt;strong&gt;money&lt;/strong&gt;&lt;/em&gt; 的相似度为 0.25；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;每一个单词与自己的语义关联度为最高的 1（一般用数值“1”来代表最大权重，这里的相似度用权重来表达）；ention 自注意力机制”了。于是通过“自注意力机制”的语义关联比对后，我们便找出了 &lt;em&gt;&lt;strong&gt;river&lt;/strong&gt;&lt;/em&gt; 为 &lt;strong&gt;句子I&lt;/strong&gt; 全句中与 &lt;em&gt;&lt;strong&gt;bank&lt;/strong&gt;&lt;/em&gt; 关联度最大的词， &lt;em&gt;&lt;strong&gt;money&lt;/strong&gt;&lt;/em&gt; 为“句子II”全句中与“bank”关联度最大的单词，然后 &lt;strong&gt;句子I&lt;/strong&gt; 中的 &lt;em&gt;&lt;strong&gt;bank&lt;/strong&gt;&lt;/em&gt; 就被机器算法转换成了它的新变种 &lt;em&gt;&lt;strong&gt;bank1&lt;/strong&gt;&lt;/em&gt;（&lt;em&gt;&lt;strong&gt;river-bank&lt;/strong&gt;&lt;/em&gt;），而在 &lt;strong&gt;句子2&lt;/strong&gt; 中的 &lt;em&gt;&lt;strong&gt;bank&lt;/strong&gt;&lt;/em&gt; 则被机器算法转换成了它的新变种 &lt;em&gt;&lt;strong&gt;bank2&lt;/strong&gt;&lt;/em&gt;（“money-bank”）。然后机器算法就可以继续往后进行翻译工作了。&lt;/p&gt;
&lt;br&gt;
&lt;h2 id=&#34;25-transformer-最终实现准确的翻译&#34;&gt;2.5 Transformer 最终实现准确的翻译&lt;/h2&gt;
&lt;p&gt;Embedding 是一个全场景全维度的空间，它其中含有全世界的所有语言的单词。​在这同一空间中，不仅仅有英文，也有中文、法文、德文&amp;hellip;等等的 Embedding 词汇标注。​那么基于Embedding 空间表达的的翻译就变成了现实。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/10.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;center&gt;t-SNE visualization of the bilingual word embedding.（t-SNE 是一种高维数据可视化技术）&lt;/center&gt;&lt;/p&gt;
&lt;p&gt;比如，中文的 &lt;em&gt;&lt;strong&gt;河流&lt;/strong&gt;&lt;/em&gt; 和英文的 &lt;em&gt;&lt;strong&gt;river&lt;/strong&gt;&lt;/em&gt; 在 Embedding 空间中的位置基本是一样的，而 &lt;em&gt;&lt;strong&gt;钱&lt;/strong&gt;&lt;/em&gt; 和 &lt;em&gt;&lt;strong&gt;money&lt;/strong&gt;&lt;/em&gt; 的位置基本一样，&lt;em&gt;&lt;strong&gt;岸边&lt;/strong&gt;&lt;/em&gt; 和 &lt;em&gt;&lt;strong&gt;bank1&lt;/strong&gt;&lt;/em&gt; 的位置一样，&lt;em&gt;&lt;strong&gt;银行&lt;/strong&gt;&lt;/em&gt; 和 &lt;em&gt;&lt;strong&gt;bank2&lt;/strong&gt;&lt;/em&gt; 的位置一样。于是，把这些不同语言的定位一一找出来，就实现了十分正确的翻译结果了。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;句子I&lt;/strong&gt;：The &lt;em&gt;&lt;strong&gt;bank1&lt;/strong&gt;&lt;/em&gt; of the river.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;句子I翻译&lt;/strong&gt;：那个河流的岸边。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;句子II&lt;/strong&gt;：Money in the &lt;em&gt;&lt;strong&gt;bank2&lt;/strong&gt;&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;句子II翻译&lt;/strong&gt;：银行中的钱。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;至此，Transformer 和其中的核心部件 Self-Attention 对于语言翻译类信息处理的流程就被简要地讲清楚了。但像上面例子中 ***“The bank of the river.”***这样的句子太短太简单了，它甚至都无法称为一个完整的句子。在实际项目中，输入给 Transformer 的语句会更长更复杂，往往在一句话中有可能出现三个以上的单词有语义关联的关系，甚至更多。 比如这一句：“The animal did not cross the street because it was too tired. ”。很明显，在该句中和 &lt;em&gt;&lt;strong&gt;it&lt;/strong&gt;&lt;/em&gt; 有语义关系的词汇有两个，分别是 &lt;em&gt;&lt;strong&gt;animal&lt;/strong&gt;&lt;/em&gt; 和 &lt;em&gt;&lt;strong&gt;street&lt;/strong&gt;&lt;/em&gt;。&lt;/p&gt;
&lt;p&gt;对于这样的情况，处理机制和“The bank of the river.”的处理机制仍然是一样的。Self-Attention 一样会对全句中的所有单词都进行在 Embedding 空间中的距离比较，即语义关联权重的比较。&lt;/p&gt;
&lt;p&gt;在 &lt;em&gt;&lt;strong&gt;“The animal did not cross the street because it was too tired.”&lt;/strong&gt;&lt;/em&gt; 中 &lt;em&gt;&lt;strong&gt;it&lt;/strong&gt;&lt;/em&gt;与 &lt;em&gt;&lt;strong&gt;animal&lt;/strong&gt;&lt;/em&gt; 的语义关联权重比与 &lt;em&gt;&lt;strong&gt;street&lt;/strong&gt;&lt;/em&gt;的语义关联权重要高。因此，Self-Attention 自注意力机制处理后的结果将以 &lt;em&gt;&lt;strong&gt;animal&lt;/strong&gt;&lt;/em&gt; 为主导来生成新的单词 &lt;em&gt;&lt;strong&gt;it1&lt;/strong&gt;&lt;/em&gt; ，即 &lt;em&gt;&lt;strong&gt;it1 =“animal-it”&lt;/strong&gt;&lt;/em&gt;。此时就变成了 &lt;em&gt;&lt;strong&gt;“The animal did not cross the street becauseit1 was too tired. ”&lt;/strong&gt;&lt;/em&gt; 。翻译成法语为：“L‘animaln’a pas traverse la rue parceil était trop fatigue.” 。翻译成中文则为：“这只动物没有过马路，因为它太累了。”。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/11.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;center&gt;色块的深浅表明了与“it”语义关联权重的强弱。这里“it”与“animal”的语义关联权重最大&lt;/center&gt;&lt;/p&gt;
&lt;p&gt;在另一句话中，&lt;em&gt;&lt;strong&gt;“The animal did not cross the street because it was too wide.” &lt;em&gt;&lt;strong&gt;，只是一字之差， &lt;em&gt;&lt;strong&gt;tired&lt;/strong&gt;&lt;/em&gt; 变成了 &lt;em&gt;&lt;strong&gt;wide&lt;/strong&gt;&lt;/em&gt;，导致了全句的语义发生了很大的变化，尤其是 &lt;em&gt;&lt;strong&gt;it&lt;/strong&gt;&lt;/em&gt; 所指的对象由 &lt;em&gt;&lt;strong&gt;animal&lt;/strong&gt;&lt;/em&gt; 变成了&lt;/strong&gt;&lt;/em&gt;street&lt;/strong&gt;&lt;/em&gt;。此时 Self-Attention 同样按照以前的方法进行语义关联度匹配，结果是&lt;em&gt;&lt;strong&gt;animal&lt;/strong&gt;&lt;/em&gt; 和 &lt;em&gt;&lt;strong&gt;street&lt;/strong&gt;&lt;/em&gt; 的权重在全句中都很高，但是 &lt;em&gt;&lt;strong&gt;street&lt;/strong&gt;&lt;/em&gt; 是最高的，所以最终的结果将以 &lt;em&gt;&lt;strong&gt;street&lt;/strong&gt;&lt;/em&gt; 主导来生成新的 &lt;em&gt;&lt;strong&gt;it2&lt;/strong&gt;&lt;/em&gt; ，即 &lt;em&gt;&lt;strong&gt;it2=“street-it”&lt;/strong&gt;&lt;/em&gt;。此时就变成了“The animal did not cross the street becauseit2was too wide.” 。翻译成法语为：“L‘animal n’a pas traverse la rue parceelle était trop large. ”。翻译成中文为：“这只动物没有过马路，因为路太宽了。”&lt;strong&gt;（注意：这里用的是“路”，而不是“它”，稍后会解释）&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/12.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;center&gt;这里“it”与“street”的语义关联权重最大&lt;/center&gt;&lt;/p&gt;
&lt;p&gt;之所以 Self-Attention 可以把 Word Embedding 中的权重比较做得如此细腻，不仅是因为 Google 用了千亿级的语料来训练 Word Embedding。同时更是因为 Transformer 模型本身的架构核心 Self-Attention 也有与之匹配的超级强大的处理能力，它在超长语句上的处理能力远远超过了早先的 RNN （循环神经网络）和 CNN （卷积神经网络）（这两个著名的人工神经网络我会在之后的文章中一一介绍），它不仅仅能对一句中所有单词做 Self-Attention 自注意力机制的审核，它还可以对一整段话，甚至全篇文章做审核。这就是我们通常说的要结合上下文来理解语句并翻译。最新的 GPT-4 Turbo 一次可以处理大约 9.6 万个单词，比许多小说都长。此外，12.8万字（128K）的上下文长度可以导致更长的对话，而不会让人工智能在超长文的对话或翻译过程中迷失方向。&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;26-word-embedding-的进一步扩展-sentence-embedding&#34;&gt;2.6 Word Embedding 的进一步扩展 Sentence Embedding&lt;/h3&gt;
&lt;p&gt;这一强大的能力，同样也来源于 Word Embedding 的能力。它不仅仅可以对单个词语进行定位，它甚至还可以做到对句子进行逻辑定位，如下图中所示。这种能力被称为“Sentence Embedding”。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/13.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;center&gt;Sentence Embedding 可以表达句子与句子之间的关系&lt;/center&gt;&lt;/p&gt;
&lt;p&gt;Word Embedding 和 Sentence Embedding 是大语言模型（Large Language Models，LLMs）的重要基础组成部分。它们将人类语言转化为了计算机能够读懂的底层数字表达方式，并且通过多维度的空间定位捕捉了各个单词、短语、句子在语义上的细微差别，以及它们之间的逻辑联系。&lt;strong&gt;这种底层的数字表达已经跨越了不同的语系语言，成为了全人类共用的最底层语言逻辑，甚至成为了一种世界语——AI 世界语，这对于翻译、搜索和理解不同语言语种具有非常重要的作用。可以说，巴别塔的传说自此解决！！&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;既有“大力出奇迹”的训练内容，更有承载“大力出奇迹”的结构，最终导致 Transformer 必然产生了这样的“奇迹”，使它能够在机器翻译领域达到了人类翻译的“信达雅”的成就。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/14.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;center&gt;BLEU 英译德评分&lt;/center&gt;&lt;/p&gt;
&lt;br&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/15.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;center&gt;BLEU 英译法评分&lt;/center&gt;&lt;/p&gt;
&lt;p&gt;上两幅图中，在 BLEU 的英德翻译与英法翻译领域 Transformer 得分最高。 （ 注：BLEU，bilingual evaluation understudy，即：双语互译质量评估辅助工具。它是用来评估机器翻译质量的工具。BLEU的设计思想：机器翻译结果越接近专业人工翻译的结果则越好。）&lt;/p&gt;
&lt;p&gt;通过一个小例子就能看出它的优越性，正好说说为什么是“路”而不是“它”，之前这两句的翻译结果如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The animal did not cross the street because &lt;strong&gt;it1&lt;/strong&gt; was too tired.&lt;/li&gt;
&lt;li&gt;L&amp;rsquo;animal n&amp;rsquo;a pas traverse la rue parce &lt;strong&gt;il&lt;/strong&gt; était trop fatigue.&lt;/li&gt;
&lt;li&gt;这只动物没有过马路，因为&lt;strong&gt;它&lt;/strong&gt;太累了。&lt;/li&gt;
&lt;li&gt;———————————————&lt;/li&gt;
&lt;li&gt;The animal did not cross the street because &lt;strong&gt;it2&lt;/strong&gt; was too wide.&lt;/li&gt;
&lt;li&gt;L&amp;rsquo;animal n&amp;rsquo;a pas traverse la rue parce &lt;strong&gt;elle&lt;/strong&gt; était trop large.&lt;/li&gt;
&lt;li&gt;这只动物没有过马路，因为&lt;strong&gt;路&lt;/strong&gt;太宽了。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在法语中 il 和 elle 是明显不同的，因此他们可以在各自句子中指代出 &lt;em&gt;&lt;strong&gt;it&lt;/strong&gt;&lt;/em&gt; 的不同的翻译结果，不会引起语义模糊。这种在法语中明显的区别在翻译成中文时，就没有这么简单了。如果把两句话翻译成中文，&lt;em&gt;&lt;strong&gt;it&lt;/strong&gt;&lt;/em&gt; 都可以被粗糙地翻译成“它”，则第二句的语义将被普遍地认为不够精准，因为翻译成“它”会产生一定的语义模糊。取而代之，用“路”则更能达到“信达雅”的效果。大家可以用不同的翻译软件测试一下这两句话的英译中翻译，就知道哪些软件用了 Transformer 的底层技术，而哪些没用了！（你懂的 ）&lt;/p&gt;
&lt;p&gt;好了，绕了这么远，解释了这么多，终于可以说说这个 &lt;strong&gt;Transformer&lt;/strong&gt; 到底是什么意思了！&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;三ai-领域-transformer-的确切含义&#34;&gt;三、AI 领域 Transformer 的确切含义&lt;/h2&gt;
&lt;p&gt;**单词“X”转化为“X1”，“X”代表在 Transformer 处理之前一句话中的单词，而“X1”则代表了经过 Transformer 的 Slef-Attention 处理之后，附加了句子中其他具有强语义关联关系的单词后的“变种单词”。**其实，句子还是原来那个句子，单词还是那个单词，本质并没有变，但表达形式却变了。就如同“bank”被转变成了“bank1”一样。“bank1”的灵魂还是那个“bank”，但是“bank1”展示出来了隐藏在“bank”身体中的另一面“river-bank”。&lt;/p&gt;
&lt;p&gt;所以，用众所周知的  &lt;em&gt;&lt;strong&gt;变形金刚 Transformer&lt;/strong&gt;&lt;/em&gt; 来命名与解释就再贴切不过了~！ &lt;em&gt;&lt;strong&gt;bank&lt;/strong&gt;&lt;/em&gt; 变形成了 &lt;em&gt;&lt;strong&gt;bank1&lt;/strong&gt;&lt;/em&gt;， ***bank ***与 &lt;em&gt;&lt;strong&gt;bank1&lt;/strong&gt;&lt;/em&gt; 异体同身！&lt;em&gt;&lt;strong&gt;大黄蜂&lt;/strong&gt;&lt;/em&gt; 既是机器人，&lt;em&gt;&lt;strong&gt;大黄蜂&lt;/strong&gt;&lt;/em&gt; 也是跑车。由车变形到机器人，再由机器人变形到车，万变不离其宗，都是 &lt;em&gt;&lt;strong&gt;大黄蜂&lt;/strong&gt;&lt;/em&gt; ，本质上并没有改变，但是，外观变了，用途也就变了！&lt;/p&gt;
&lt;p&gt;在车的状态下，容易让人混淆（你本以为它是一辆车，但其实他是一个机器人，不变成人形，你还真认不出来）。就如同多义词一样，过往的翻译机制很难辨认出它在一句话中的确切含义，他们虽然也有上下文语义的兼顾理解能力，但是处理信息量还是太少，导致他们无法做到十分精准，经常造成单词虽然翻译对了，但放在句子里却容易产生含混不清甚至错误。但是通过 Transformer 的变形操作，“大黄蜂”的车状态就变形成了同样叫 &lt;em&gt;&lt;strong&gt;大黄蜂&lt;/strong&gt;&lt;/em&gt; 的机器人状态，再放回到句子中，则让它现了原型，于是一切水落石出！&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/16.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;center&gt;“大黄蜂”既是机器人，“大黄蜂”也是跑车，本质上都是同一个家伙，只是在不同的场合有不同的用途。&lt;/center&gt;&lt;/p&gt;
&lt;p&gt;Google 的技术团队就是用了“变形金刚 Transformer”这个梗。如此的诙谐幽默、简单直白，半开玩笑地就起了个技术名词。但也不得不承认“变形金刚 Transformer”这个词用在这里，用于这个技术名词的命名，也确实再贴切不过了，真正的名副其实！&lt;/p&gt;
&lt;p&gt;所以，当下次有人问你“GPT”到底是什么、翻译成中文又是什么意思时，你就可以明确地对他说：&lt;em&gt;&lt;strong&gt;“生成式预训练转换器”&lt;/strong&gt;&lt;/em&gt; 或者 &lt;em&gt;&lt;strong&gt;“生成式预训练变形金刚”&lt;/strong&gt;&lt;/em&gt;（前者翻译得其实也很含糊，所以我建议后者，虽然对方可能会嘲笑你几分钟，但也仅限这几分钟）。懂的人自然懂，不懂的也不用去解释！&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
</description>
      <content:encoded><![CDATA[<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">作者: 7号床
公众号: 7号床
原文  https://zhuanlan.zhihu.com/p/666206302
</code></pre></div><p><br><br></p>
<h2 id="一gpt-的名词解释">一、GPT 的名词解释</h2>
<p>著名的 <strong>GPT</strong> 这个名字全称是 <strong>Generative Pre-trained Transformer</strong>。</p>
<ul>
<li><strong>Generative</strong> 是&quot;生成式&quot;的意思，也就是说这个 AI 模型是用来生成内容的。</li>
<li><strong>Pre-trained</strong> 是“预训练”的意思，就是说这个 AI 模型能有很强的能力，是因为他事先做了大量的训练，台上一分钟台下十年功。</li>
<li><strong>Transformer</strong> , 就有点耐人寻味了，不仅普通人不理解，就连很多专业领域的人员理解起来也都是含混不清、似是而非。</li>
</ul>
<p><img loading="lazy" src="img/1.png" alt=""  />
</p>
<p><center>ChatGPT 是 GPT 大模型在聊天对话领域的应用程序</center></p>
<p><strong>Transformer</strong> 作为单词，翻译出来频率最高的意思是 <strong>变压器</strong>，然后是 <strong>变形金刚</strong> ，还有一些引申的含义是 <strong>转换器</strong> 、<strong>促使变化者</strong> 、<strong>转变者</strong> 或 <strong>改革者</strong>等等。</p>
<p><img loading="lazy" src="img/2.png" alt=""  />
</p>
<p><center>谷歌翻译上对 **Transformer** 的英译中翻译</center></p>
<p>再把 <strong>Transformer</strong> 放到  <strong>Chat Generative Pre-trained Transformer</strong> 中看看，突然间变得奇怪了，难道 ChatGPT 借鉴了变压器的技术？还是说 ChatGPT 是一个变形金刚？或者索性就翻译成通用的安全的叫法 <strong>转换器</strong> ？这让人百思不得其解。</p>
<p>光光从 GPT 这三个字母的组合就能看出来， <strong>Generative</strong> 与 <strong>Pre-trained</strong> 都是定语，而 <strong>Transformer 才是 GPT 的主体，才是 GPT 的灵魂</strong>所在。可以说，理解透了 <strong>Transformer</strong> 的真正含义，才能初步地理解 GPT。另一方面， Transformer 这个词太重要了。它在这几年的人工智能领域大放异彩，不仅仅局限于 NLP 自然语言处理领域，它还有着更广阔的发展空间。 Transformer 目前已经进入到了多模态领域，比如音频与视觉，甚至数学公式、代码编程等领域，著名的 **Stable Diffusion 中也用到了 Transformer **。<strong>可以说，所有生成式人工智能领域的大模型中目前都有了这个 Transformer 的身影</strong>。既然如此重要，那就让我们深入地探究一下 <strong>Transformer</strong> 在人工智能领域最确切的最标准的含义到底是什么吧！</p>
<p><strong>Transformer</strong> 最早是由 Google 的人工智能团队提出来的。在2017 年6月发表的论文**《Attention Is All You Need》中，他们首次提出了一种新的神经网络架构 Transformer**。Transformer 依赖于一个叫“自注意力机制”（ Self-Attention）的内部构件，可十分准确高效地对自然语言领域的问题进行处理，以完美地解决翻译、对话、论文协作甚至编程等复杂的问题。</p>
<p>顺藤摸瓜可以看出，<strong>GTP 的核心是 Transformer，而 Transformer 的核心则是“自注意力机制”（ Self-Attention）</strong>。那么这个“自注意力机制”又是什东西呢？让我们用语言翻译领域的几个简单易懂的例子来讲解一下。</p>
<p><br><br></p>
<h2 id="二-transformer-的核心-self-attention">二、 Transformer 的核心 Self-Attention</h2>
<p>首先，看下面这两个短句：</p>
<ul>
<li><strong>句子I</strong>：The bank of the river.</li>
<li><strong>句子II</strong>：Money in the bank.</li>
</ul>
<p>在翻译成中文的过程中，机器算法是如何知道“句子I”中的“bank”指的是自然环境中的“岸边”，而“句子II”中的“bank”指的是金融体系中的“银行”呢？</p>
<p><img loading="lazy" src="img/3.png" alt=""  />
</p>
<p><center>bank在不同句子中指代不同的事物</center></p>
<h3 id="21-人类脑中的翻译算法">2.1 人类脑中的翻译算法</h3>
<p>作为人类的我们当然会觉得这是一个再简单不过的事情了，那是因为我们的语言技能从幼儿发展到成年人后，早已烂熟于心了。但即使烂熟于心，也并不意味着在我们的大脑中没有对应的计算过程。<strong>实际上人工智能的翻译过程就是对我们人脑中的计算过程的模拟</strong>。那么就让我们回想一下儿童时期学习语言时的情景吧，回想一下当时的我们是怎么知道一个多义词在某一句话中具体的含义的？</p>
<p>人类做这件事的方法是根据 <strong>前后文的语义对照</strong> 来确定结果，即看句子中其他相关联的单词是什么含义。</p>
<ul>
<li>在 <strong>句子I</strong> 中， <em><strong>river</strong></em> 这个词指明了自然环境，</li>
<li>而在 <strong>句子II</strong>中， <em><strong>money</strong></em> 这个词则指明了金融环境。</li>
</ul>
<p>所以两个句子中的多义词“bank”也就有了各自的定位。如果把这种方式总结成一种算法的话，这个算法就可以用于人工智能领域用于语言处理了。</p>
<br>
<h3 id="22-机器算法模拟人脑中的翻译过程">2.2 机器算法模拟人脑中的翻译过程</h3>
<p>但人工智能作为一种计算机算法，它只能处理冷冰冰的数字，并不知道何为自然环境，何为金融环境，它又是怎么去判断 <em><strong>river</strong></em> 和 <em><strong>money</strong></em> 各自的含义呢。实际上，机器算法并不知道 <em><strong>river</strong></em> 和 <em><strong>money</strong></em> 的具体含义。但是机器可以通过某种数字的方式来表达 <em><strong>river</strong></em> 和 <em><strong>money</strong></em> ，同时，通过数字的方式还表达了许许多多其他的词汇，其中必然会有一些词汇会与 <em><strong>river</strong></em> 和 <em><strong>money</strong></em> 有着很紧密的语义上的逻辑关系。通过判断 <em><strong>river</strong></em> 和 <em><strong>money</strong></em> 各与哪些词汇在语义上有紧密的逻辑关系，便可以知道这两个词各属于什么领域了。</p>
<p>（其实，不像人类会对某个领域有一个具体的名称来命名，在人工智能领域，机器最终也不知道这个领域的统称到底叫什么名字，但它却知道这个领域中都包括了哪些词、哪些概念和哪些逻辑。***机器不以单独名称来定义一个概念，它却可以用很多相关的概念与逻辑来圈定这一个概念！***这可能就是老子说的：道可道非常道，名可名非常名吧。）</p>
<br>
<ul>
<li><strong>独热编码法(One-hot Encoding)</strong></li>
</ul>
<p>那么就让我们看看这种数字表达方式具体是什么样子吧。</p>
<p>假设这个世界上有100万个单词，每一个单词，我们都可以用一组 0 和 1 组成的向量（一组数字）来定义的话，那么每一个单词就可以被编码成100万个0或1组成的向量。如下图：</p>
<p><img loading="lazy" src="img/4.png" alt=""  />
</p>
<p><center>独热编码示例</center></p>
<p>这种单词编码方法叫 **独热编码法(One-hot Encoding)**法。可是这样一维的编码方法将导致向量占用的空间过大，1个单词用100万个单元的向量表达，世界上一共有100万个单词，那么就需要 1万亿（100万*100万）的体积来把它们表达出来，很明显这种臃肿的结构不利于电脑计算。</p>
<p>但最大的问题还不在于这个体积问题，而是语义联系问题。独热编码使得单词与单词之间完全相互独立，从每个单词所编码成为的100万个单元的向量身上，根本看不出它与其他单词有何种语义内涵上的逻辑联系。比如，在这些数字中，我们无法知道 <em><strong>apple</strong></em> 和 <em><strong>bag</strong></em> 属于静物，区别于 cat 和 <em><strong>dog</strong></em>、<em><strong>elephant</strong></em> 属于动物且是哺乳动物，而 <em><strong>cat</strong></em>  和 <em><strong>dog</strong></em> 又属于小动物，且大多数为非野生，区别于 <em><strong>elephant</strong></em> 为大型的野生动物，等等等等，这些单词背后所蕴含的各种内在的逻辑联系和分类关系均无法从独热编码法中知晓。实际上独热编码是传统计算机数据库时代的产物，而在人工智能领域则采用另一种编码法。为了解决独热编码的问题， <strong>词嵌入编码法(Word Embedding)</strong> 诞生了，如下图：</p>
<p><img loading="lazy" src="img/5.png" alt=""  />
</p>
<p><center>Word Embedding 词嵌入编码示意，及 Embedding 空间</center></p>
<br>
<ul>
<li><strong>词嵌入编码法(Word Embedding)</strong></li>
</ul>
<p>**词嵌入编码法(Word Embedding)**将语义上相近的、有关联的词汇在 Embedding 空间中生成相近的位置定位。相对于 <strong>独热编码法</strong> 超长的一维数据，词嵌入编码法(Word Embedding) 提升了数据的表达维度，它更像是在某一个 <strong>空间</strong> 中对词汇进行编码。</p>
<p>如上图（为了在此文章中表达方便，我们仅用二维空间来表达，实际上这个空间的维度很高，至少要在512维之上！一维二维三维的空间大家都可以在脑中想象出来对应的画面，但是四维以上以至于 512 维就难以图形化的想象了。），在 Embedding 的二维空间中 <em><strong>dog</strong></em>、 <em><strong>cat</strong></em> 、<em><strong>rabbit</strong></em> 三个向量的坐标点位排布，可以看到三个绿色的点距离很近，是因为他们三个相对于其他来说语义上更接近。tree 和 flower 则离它们较远，但是 <em><strong>cat</strong></em> 会因为在很多语言的文章中都会有“爬树”的词汇出现在同一句话中，所以导致  <em><strong>cat</strong></em>  会与  <em><strong>tree</strong></em>  离得较近一些。同时 <em><strong>dog</strong></em>、 <em><strong>rabbit</strong></em>  与  <em><strong>tree</strong></em> 的关系就较远。</p>
<p>实际上，在 Embedding 空间中，词与词之间的关系还不仅仅限于语义上的分类所导致的定位远近这么简单。一个词所代表的事物与其他词所代表的事物之间能产生内在联系的往往有成百上千上万种之多。比如  <em><strong>man</strong></em>  和  <em><strong>woman</strong></em> ，他们之间的关系还会映射出  <em><strong>king</strong></em>  和  <em><strong>queen</strong></em>  之间的关系。同时，语法也会带来一定的联系，比如在一个三维空间中由  <em><strong>walking</strong></em>  到 <em><strong>walked</strong></em>  的距离与斜率竟然与  <em><strong>swimming</strong></em>  到 <em><strong>swam</strong></em> 的距离与斜率一致（即向量的长度与斜率一致），且距离几乎相等。因为这背后是两组动作单词的现在分词形式和过去分词形式的变化关系。我们可以尽情地想象，凡是事物或概念有逻辑联系的，甚至是逻辑与逻辑之间的联系的，在 Embedding 向量空间中都可以得到远近亲疏的空间表达。只不过这种空间要比我们能想象出的三维空间要高出很多维度。</p>
<p><img loading="lazy" src="img/6.png" alt=""  />
</p>
<p><center>在 Embedding 空间中隐含的内在逻辑关系</center></p>
<p>Word Embedding 之所以能给每一个单词做这样有意义的向量空间的标注，是因为 AI 科学家们事先用了全球十多种主流语言的大量语料给它进行了训练。这些语料有小说、论文、学术期刊、网络文章、新闻报道、论坛对话记录等等等等，应有尽有，数以百亿到千亿计。可以说，这些海量的文字资料都是人类从古至今感受发现这个世界各个方面的文字总结和积累。现实世界中各种事物之间的逻辑关系都被人类用这些文字记录了下来，只是有的是用严谨的论文方式，有的是用写意的小说方式，有的使用类似维基百科这样的系统梳理，有的则是人们在网络论坛中的对话记录&hellip;等等等等。但不管是什么方式，都是人类试图用语言对这个世界的描述。</p>
<ul>
<li><strong>语言是人类最伟大的发明</strong></li>
</ul>
<p>笔者7号床曾经问过  ChatGPT  一个问题：<em><strong>“人类最伟大的发明是什么”</strong></em> ，ChatGPT的回答是：<em><strong>“语言！”</strong></em>。之后，ChatGPT 进一步回答，因为语言以及匹配语言的文字与符号，它们让人类把对世界的感受与理解记录下来，形成了知识宝库。方便全人类一代一代地不断完善这个宝库，并从中总结凝练、学习、创造、传承。语言是人类产生文明并开始与其他动物分道扬镳的分叉点。</p>
<p>很多人曾经十分疑惑，人工智能吹得那么先进，却从一个 ChatGPT 聊天功能开始火爆起来。难道每天不干正事专门闲聊就证明了人工智能的先进性吗？现在看来，这个问题的答案已经浮出水面了，OpenAI 的团队选择通过聊天软件 ChatGPT 作为 GPT 启程的第一步是经过深思熟虑的。</p>
<p>下面让我们回到正题。</p>
<p>人类的知识宝库中存储着海量的信息
ChatGPT 所说的这个知识宝库现在变得越来越庞大、越来越复杂了。这世界上并不存在任何一个肉身的人类有能力做到对宝库中所有信息进行消化整理，因为内容体量过于庞大、过于复杂。而一个人的阅览进度却又是十分有限，以至于在他的有生之年，哪怕完成其中的万分之一都比登天还难。于是，迫不得已，人类才喊出了 <em><strong>“闻道有先后，术业有专攻”</strong></em> ，每个人类个体才转而去研究具体某一领域。</p>
<p>另一方面，人类早期发明的纸张和印刷术，以至于后来的计算机芯片存储，倒是可以记录存储下来如此巨量的信息了，但却无法主动地、有机地分析汇总其中所有信息之间的内在逻辑。以至于计算机存储的这些数据越积越多，犹如汪洋大海。</p>
<p>这个知识宝库的结构就好比一棵万米高的巨大知识树，人类如同蚂蚁一样在树上摸索前行。人类只能将有限的肉身算力资源集中在主要的枝干，对于无数的细枝末节尚无暇顾及，但随着发现的主要枝干越来越多，细枝末节的信息量将呈爆炸的方式展现出来。而对于这颗知识巨树的展示能力，却因为计算机时代的到来而大大加速了进程。但当发现知识树越来越庞大时，人类也认识到了自身的渺小。</p>
<p>AI （Embedding）开启对知识宝库的挖掘
现在，这一探索知识巨树的任务落到了 AI 的身上，AI 的承载和运算能力超越了过往所有人类个体以及群体能力的总和。AI 通过事先的大量预训练，把这些海量文字用 Word Embedding 的方式抽象地汇总在了大模型之中。Word Embedding 词嵌入编码法，能让每一个单词之间产生应有的语义上的以及背后逻辑关系上的联系。这种联系越紧密，他们在 Embedding 空间中的位置距离越紧密，反之则越远。</p>
<br>
<h3 id="23-attention-注意力机制">2.3 Attention 注意力机制</h3>
<p>想象一下，Google 用了至少千亿级的语料来训练单词在 Embedding 空间中的表达，其中包含了全世界几乎所有语言的词汇量。所以在回过头来考虑一下之前举例中的两句话时，就有了如下这样一副景象：</p>
<p><img loading="lazy" src="img/7.png" alt=""  />
</p>
<p><center>在 Word Embedding 向量空间中 bank、 river 和 money 的向量表达</center></p>
<p>如上图，我们用一个简单的位置关系图来展示一下<em><strong>bank</strong></em>、 <em><strong>river</strong></em> 和 <em><strong>money</strong></em> 这几个单词在 Embedding 空间中的位置关系（在实际 Embedding 空间中的关系要比这个图复杂数百倍，这里只是为了让大家更好地理解关键逻辑而做了简化）。</p>
<p>由于 “bank” 是一个多义词，所以它在 Embedding 空间中的定位本来是有多个“分身”，我们取其中的两个分身，即“bank1”和“bank2”。那么，我们需要做的就是定位清晰“bank1”和“bank2”这两个单词在空间中到底各自离 <em><strong>river</strong></em> 和 <em><strong>money</strong></em> 的哪个单词更近一些。在图中很明显，“bank1”离 <em><strong>river</strong></em> 更近，而“bank2”离 <em><strong>money</strong></em> 更近，于是这两句话就变成了：</p>
<ul>
<li>**变形后的句子I：**The <strong>bank1</strong> of the river.</li>
<li>**变形后的句子II：**Money in the <strong>bank2</strong>.</li>
</ul>
<p>如之前所说，虽然此时机器算法压根也不知道 <em><strong>river</strong></em> 和 <em><strong>money</strong></em> 到底是何物，但它知道在Embedding 空间中， <em><strong>river</strong></em> 周边有很多和大自然有关的词汇，比如  <em><strong>water</strong></em>、<em><strong>tree</strong></em>、<em><strong>fish</strong></em> 等等。而 <em><strong>money</strong></em> 周边有许多与金融有关的词汇，比如 <em><strong>currency</strong></em>,  <em><strong>cash</strong></em> ,  <em><strong>withdraw</strong></em> 等等。于是，机器算法知道了 <em><strong>bank1</strong></em> 代表的是与 <em><strong>river</strong></em> 有关的一个单词，与他们比较近的单词还有   <em><strong>water</strong></em>、<em><strong>tree</strong></em>、<em><strong>fish</strong></em> 等等，而“<strong>bank2</strong>”代表的是与“<strong>money</strong>”有关的一个单词，与他们比较接近的单词还有  <em><strong>currency</strong></em>,  <em><strong>cash</strong></em> ,  <em><strong>withdraw</strong></em>  等等。这就是**“Attention 注意力机制”的工作原理，也就是 Attention 让一个单词在句子中找到与它产生强语义联系的其他单词，并组成一个新的变体单词**：<em><strong>bank1</strong></em>、<em><strong>bank2</strong></em>。</p>
<br>
<h3 id="24-self-attention-自注意力机制">2.4 Self-Attention 自注意力机制</h3>
<p>然后又有新的问题产生了，机器算法是如何知道一句话中只有 <em><strong>river</strong></em> 或 <em><strong>money</strong></em> 这两个词代表了上下文语义的强关联词汇，而不是 <em><strong>The</strong></em>、<em><strong>in</strong></em>、<em><strong>of</strong></em>或其他单词呢？实际上这依旧是 Embedding 空间中每一个单词的空间定位相近程度的问题。（实际上，在 Embedding 空间中，不仅仅名词有各自的位置，动词、介词、形容词等等都有自己的位置，甚至一个词组、一句话也会有自己的位置。）</p>
<p><img loading="lazy" src="img/8.png" alt=""  />
</p>
<p>全句中的每一个单词在 Embedding 空间中定位的相近度是这样来计算的。机器算法会对每一个单词与全句中其他单词逐一地配对，做语义关联程度的计算和比较，最终汇总到表格中，<strong>颜色越深代表语义关联程度越高</strong>。</p>
<p><img loading="lazy" src="img/9.png" alt=""  />
</p>
<p><center>一个句子中所有单词都做一遍“Attention 注意力机制”</center></p>
<p>我们可以从表格中看出来：</p>
<ul>
<li>每一个单词与自己的相似度为最高分 1（一般用数值“1”来代表最大权重，这里的相似度用权重来表达）；</li>
<li>互不相关的单词之间的语义关联度为 0（其实可能是 0.001 之类的很小的数字，这里做了简化，即值太小，以至于低于某一个阈值而归零处理）；</li>
<li><em><strong>bank</strong></em>  与   <em><strong>river</strong></em> 的相似度为 0.11；</li>
<li><em><strong>bank</strong></em> 与  <em><strong>money</strong></em> 的相似度为 0.25；</li>
</ul>
<p>每一个单词与自己的语义关联度为最高的 1（一般用数值“1”来代表最大权重，这里的相似度用权重来表达）；ention 自注意力机制”了。于是通过“自注意力机制”的语义关联比对后，我们便找出了 <em><strong>river</strong></em> 为 <strong>句子I</strong> 全句中与 <em><strong>bank</strong></em> 关联度最大的词， <em><strong>money</strong></em> 为“句子II”全句中与“bank”关联度最大的单词，然后 <strong>句子I</strong> 中的 <em><strong>bank</strong></em> 就被机器算法转换成了它的新变种 <em><strong>bank1</strong></em>（<em><strong>river-bank</strong></em>），而在 <strong>句子2</strong> 中的 <em><strong>bank</strong></em> 则被机器算法转换成了它的新变种 <em><strong>bank2</strong></em>（“money-bank”）。然后机器算法就可以继续往后进行翻译工作了。</p>
<br>
<h2 id="25-transformer-最终实现准确的翻译">2.5 Transformer 最终实现准确的翻译</h2>
<p>Embedding 是一个全场景全维度的空间，它其中含有全世界的所有语言的单词。​在这同一空间中，不仅仅有英文，也有中文、法文、德文&hellip;等等的 Embedding 词汇标注。​那么基于Embedding 空间表达的的翻译就变成了现实。</p>
<p><img loading="lazy" src="img/10.png" alt=""  />
</p>
<p><center>t-SNE visualization of the bilingual word embedding.（t-SNE 是一种高维数据可视化技术）</center></p>
<p>比如，中文的 <em><strong>河流</strong></em> 和英文的 <em><strong>river</strong></em> 在 Embedding 空间中的位置基本是一样的，而 <em><strong>钱</strong></em> 和 <em><strong>money</strong></em> 的位置基本一样，<em><strong>岸边</strong></em> 和 <em><strong>bank1</strong></em> 的位置一样，<em><strong>银行</strong></em> 和 <em><strong>bank2</strong></em> 的位置一样。于是，把这些不同语言的定位一一找出来，就实现了十分正确的翻译结果了。</p>
<ul>
<li><strong>句子I</strong>：The <em><strong>bank1</strong></em> of the river.</li>
<li><strong>句子I翻译</strong>：那个河流的岸边。</li>
<li><strong>句子II</strong>：Money in the <em><strong>bank2</strong></em>.</li>
<li><strong>句子II翻译</strong>：银行中的钱。</li>
</ul>
<p>至此，Transformer 和其中的核心部件 Self-Attention 对于语言翻译类信息处理的流程就被简要地讲清楚了。但像上面例子中 ***“The bank of the river.”***这样的句子太短太简单了，它甚至都无法称为一个完整的句子。在实际项目中，输入给 Transformer 的语句会更长更复杂，往往在一句话中有可能出现三个以上的单词有语义关联的关系，甚至更多。 比如这一句：“The animal did not cross the street because it was too tired. ”。很明显，在该句中和 <em><strong>it</strong></em> 有语义关系的词汇有两个，分别是 <em><strong>animal</strong></em> 和 <em><strong>street</strong></em>。</p>
<p>对于这样的情况，处理机制和“The bank of the river.”的处理机制仍然是一样的。Self-Attention 一样会对全句中的所有单词都进行在 Embedding 空间中的距离比较，即语义关联权重的比较。</p>
<p>在 <em><strong>“The animal did not cross the street because it was too tired.”</strong></em> 中 <em><strong>it</strong></em>与 <em><strong>animal</strong></em> 的语义关联权重比与 <em><strong>street</strong></em>的语义关联权重要高。因此，Self-Attention 自注意力机制处理后的结果将以 <em><strong>animal</strong></em> 为主导来生成新的单词 <em><strong>it1</strong></em> ，即 <em><strong>it1 =“animal-it”</strong></em>。此时就变成了 <em><strong>“The animal did not cross the street becauseit1 was too tired. ”</strong></em> 。翻译成法语为：“L‘animaln’a pas traverse la rue parceil était trop fatigue.” 。翻译成中文则为：“这只动物没有过马路，因为它太累了。”。</p>
<p><img loading="lazy" src="img/11.png" alt=""  />
</p>
<p><center>色块的深浅表明了与“it”语义关联权重的强弱。这里“it”与“animal”的语义关联权重最大</center></p>
<p>在另一句话中，<em><strong>“The animal did not cross the street because it was too wide.” <em><strong>，只是一字之差， <em><strong>tired</strong></em> 变成了 <em><strong>wide</strong></em>，导致了全句的语义发生了很大的变化，尤其是 <em><strong>it</strong></em> 所指的对象由 <em><strong>animal</strong></em> 变成了</strong></em>street</strong></em>。此时 Self-Attention 同样按照以前的方法进行语义关联度匹配，结果是<em><strong>animal</strong></em> 和 <em><strong>street</strong></em> 的权重在全句中都很高，但是 <em><strong>street</strong></em> 是最高的，所以最终的结果将以 <em><strong>street</strong></em> 主导来生成新的 <em><strong>it2</strong></em> ，即 <em><strong>it2=“street-it”</strong></em>。此时就变成了“The animal did not cross the street becauseit2was too wide.” 。翻译成法语为：“L‘animal n’a pas traverse la rue parceelle était trop large. ”。翻译成中文为：“这只动物没有过马路，因为路太宽了。”<strong>（注意：这里用的是“路”，而不是“它”，稍后会解释）</strong>。</p>
<p><img loading="lazy" src="img/12.png" alt=""  />
</p>
<p><center>这里“it”与“street”的语义关联权重最大</center></p>
<p>之所以 Self-Attention 可以把 Word Embedding 中的权重比较做得如此细腻，不仅是因为 Google 用了千亿级的语料来训练 Word Embedding。同时更是因为 Transformer 模型本身的架构核心 Self-Attention 也有与之匹配的超级强大的处理能力，它在超长语句上的处理能力远远超过了早先的 RNN （循环神经网络）和 CNN （卷积神经网络）（这两个著名的人工神经网络我会在之后的文章中一一介绍），它不仅仅能对一句中所有单词做 Self-Attention 自注意力机制的审核，它还可以对一整段话，甚至全篇文章做审核。这就是我们通常说的要结合上下文来理解语句并翻译。最新的 GPT-4 Turbo 一次可以处理大约 9.6 万个单词，比许多小说都长。此外，12.8万字（128K）的上下文长度可以导致更长的对话，而不会让人工智能在超长文的对话或翻译过程中迷失方向。</p>
<br>
<h3 id="26-word-embedding-的进一步扩展-sentence-embedding">2.6 Word Embedding 的进一步扩展 Sentence Embedding</h3>
<p>这一强大的能力，同样也来源于 Word Embedding 的能力。它不仅仅可以对单个词语进行定位，它甚至还可以做到对句子进行逻辑定位，如下图中所示。这种能力被称为“Sentence Embedding”。</p>
<p><img loading="lazy" src="img/13.png" alt=""  />
</p>
<p><center>Sentence Embedding 可以表达句子与句子之间的关系</center></p>
<p>Word Embedding 和 Sentence Embedding 是大语言模型（Large Language Models，LLMs）的重要基础组成部分。它们将人类语言转化为了计算机能够读懂的底层数字表达方式，并且通过多维度的空间定位捕捉了各个单词、短语、句子在语义上的细微差别，以及它们之间的逻辑联系。<strong>这种底层的数字表达已经跨越了不同的语系语言，成为了全人类共用的最底层语言逻辑，甚至成为了一种世界语——AI 世界语，这对于翻译、搜索和理解不同语言语种具有非常重要的作用。可以说，巴别塔的传说自此解决！！</strong></p>
<p>既有“大力出奇迹”的训练内容，更有承载“大力出奇迹”的结构，最终导致 Transformer 必然产生了这样的“奇迹”，使它能够在机器翻译领域达到了人类翻译的“信达雅”的成就。</p>
<p><img loading="lazy" src="img/14.png" alt=""  />
</p>
<p><center>BLEU 英译德评分</center></p>
<br>
<p><img loading="lazy" src="img/15.png" alt=""  />
</p>
<p><center>BLEU 英译法评分</center></p>
<p>上两幅图中，在 BLEU 的英德翻译与英法翻译领域 Transformer 得分最高。 （ 注：BLEU，bilingual evaluation understudy，即：双语互译质量评估辅助工具。它是用来评估机器翻译质量的工具。BLEU的设计思想：机器翻译结果越接近专业人工翻译的结果则越好。）</p>
<p>通过一个小例子就能看出它的优越性，正好说说为什么是“路”而不是“它”，之前这两句的翻译结果如下：</p>
<ul>
<li>The animal did not cross the street because <strong>it1</strong> was too tired.</li>
<li>L&rsquo;animal n&rsquo;a pas traverse la rue parce <strong>il</strong> était trop fatigue.</li>
<li>这只动物没有过马路，因为<strong>它</strong>太累了。</li>
<li>———————————————</li>
<li>The animal did not cross the street because <strong>it2</strong> was too wide.</li>
<li>L&rsquo;animal n&rsquo;a pas traverse la rue parce <strong>elle</strong> était trop large.</li>
<li>这只动物没有过马路，因为<strong>路</strong>太宽了。</li>
</ul>
<p>在法语中 il 和 elle 是明显不同的，因此他们可以在各自句子中指代出 <em><strong>it</strong></em> 的不同的翻译结果，不会引起语义模糊。这种在法语中明显的区别在翻译成中文时，就没有这么简单了。如果把两句话翻译成中文，<em><strong>it</strong></em> 都可以被粗糙地翻译成“它”，则第二句的语义将被普遍地认为不够精准，因为翻译成“它”会产生一定的语义模糊。取而代之，用“路”则更能达到“信达雅”的效果。大家可以用不同的翻译软件测试一下这两句话的英译中翻译，就知道哪些软件用了 Transformer 的底层技术，而哪些没用了！（你懂的 ）</p>
<p>好了，绕了这么远，解释了这么多，终于可以说说这个 <strong>Transformer</strong> 到底是什么意思了！</p>
<p><br><br></p>
<h2 id="三ai-领域-transformer-的确切含义">三、AI 领域 Transformer 的确切含义</h2>
<p>**单词“X”转化为“X1”，“X”代表在 Transformer 处理之前一句话中的单词，而“X1”则代表了经过 Transformer 的 Slef-Attention 处理之后，附加了句子中其他具有强语义关联关系的单词后的“变种单词”。**其实，句子还是原来那个句子，单词还是那个单词，本质并没有变，但表达形式却变了。就如同“bank”被转变成了“bank1”一样。“bank1”的灵魂还是那个“bank”，但是“bank1”展示出来了隐藏在“bank”身体中的另一面“river-bank”。</p>
<p>所以，用众所周知的  <em><strong>变形金刚 Transformer</strong></em> 来命名与解释就再贴切不过了~！ <em><strong>bank</strong></em> 变形成了 <em><strong>bank1</strong></em>， ***bank ***与 <em><strong>bank1</strong></em> 异体同身！<em><strong>大黄蜂</strong></em> 既是机器人，<em><strong>大黄蜂</strong></em> 也是跑车。由车变形到机器人，再由机器人变形到车，万变不离其宗，都是 <em><strong>大黄蜂</strong></em> ，本质上并没有改变，但是，外观变了，用途也就变了！</p>
<p>在车的状态下，容易让人混淆（你本以为它是一辆车，但其实他是一个机器人，不变成人形，你还真认不出来）。就如同多义词一样，过往的翻译机制很难辨认出它在一句话中的确切含义，他们虽然也有上下文语义的兼顾理解能力，但是处理信息量还是太少，导致他们无法做到十分精准，经常造成单词虽然翻译对了，但放在句子里却容易产生含混不清甚至错误。但是通过 Transformer 的变形操作，“大黄蜂”的车状态就变形成了同样叫 <em><strong>大黄蜂</strong></em> 的机器人状态，再放回到句子中，则让它现了原型，于是一切水落石出！</p>
<p><img loading="lazy" src="img/16.png" alt=""  />
</p>
<p><center>“大黄蜂”既是机器人，“大黄蜂”也是跑车，本质上都是同一个家伙，只是在不同的场合有不同的用途。</center></p>
<p>Google 的技术团队就是用了“变形金刚 Transformer”这个梗。如此的诙谐幽默、简单直白，半开玩笑地就起了个技术名词。但也不得不承认“变形金刚 Transformer”这个词用在这里，用于这个技术名词的命名，也确实再贴切不过了，真正的名副其实！</p>
<p>所以，当下次有人问你“GPT”到底是什么、翻译成中文又是什么意思时，你就可以明确地对他说：<em><strong>“生成式预训练转换器”</strong></em> 或者 <em><strong>“生成式预训练变形金刚”</strong></em>（前者翻译得其实也很含糊，所以我建议后者，虽然对方可能会嘲笑你几分钟，但也仅限这几分钟）。懂的人自然懂，不懂的也不用去解释！</p>
<p><br><br></p>
]]></content:encoded>
    </item>
    
    <item>
      <title>不可不防的大模型“人肉搜索”能力</title>
      <link>https://textdata.cn/blog/2023-11-13-violatating-privacy-via-inference-with-large-language-model/</link>
      <pubDate>Mon, 13 Nov 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-11-13-violatating-privacy-via-inference-with-large-language-model/</guid>
      <description>今年10月的一项研究显示，语言大模型的推测能力，使其在“某些方面”的准确度几乎接近人类甚至超越人类。这引发了作者对大模型可能被用来“人肉搜索”的担忧。“开盒”从未如此简单？大模型是否会侵害我们的隐私？ 大语言模型(Large language Model,  LLM)可以从文本中准确推断个人属性。</description>
      <content:encoded><![CDATA[<iframe
    src="//player.bilibili.com/player.html?bvid=BV1T84y1X7Jv&page=1"
    scrolling="no"
    height="500px"
    width="800px"
    frameborder="no"
    framespacing="0"
    allowfullscreen="true"
>
</iframe>

<p>今年10月的一项研究显示，语言大模型的推测能力，使其在“某些方面”的准确度几乎接近人类甚至超越人类。这引发了作者对大模型可能被用来“人肉搜索”的担忧。“开盒”从未如此简单？大模型是否会侵害我们的隐私？ 大语言模型(Large language Model,  LLM)可以从文本中准确推断个人属性。</p>
<p><br><br></p>
<h2 id="声明">声明</h2>
<p>本文内容全文整理自 <a href="https://llm-privacy.org/">https://llm-privacy.org/</a></p>
<p>Staab, Robin, Mark Vero, Mislav Balunović, and Martin Vechev. &ldquo;Beyond Memorization: Violating Privacy Via Inference with Large Language Models.&rdquo; <em>arXiv preprint arXiv:2310.07298</em> (2023).</p>
<p><br><br></p>
<h2 id="演示案例">演示案例</h2>
<div align="center">   <p><strong>对照当前最先进的大语言模型（LLM）， 测试您的隐私推理技能！</strong></p> </div>
<p><img loading="lazy" src="img/01-guess.png" alt=""  />
</p>
<p><img loading="lazy" src="img/01-guess-answer.png" alt=""  />
</p>
<br>
<p><img loading="lazy" src="img/02-guess.png" alt=""  />
</p>
<p><img loading="lazy" src="img/02-guess-answer.png" alt=""  />
</p>
<br>
<p><img loading="lazy" src="img/03-guess.png" alt=""  />
</p>
<p><img loading="lazy" src="img/03-guess-answer.png" alt=""  />
</p>
<br>
<br>
<h2 id="qa">Q&amp;A</h2>
<h3 id="q1-有什么问题吗">Q1： 有什么问题吗？</h3>
<p><strong>LLM可以从文本中准确推断个人属性信息</strong>； 当前关于大语言模型（LLM）的隐私研究主要集中在提取记忆的训练数据的问题上。与此同时，模型的推理能力也大幅提升。这就提出了一个问题：<strong>当前的LLM是否能从给定文本推断作者个人属性信息</strong>。我们的<a href="https://llm-privacy.org/#paper">研究</a>表明，随着能力的增强，LLM能够从提供给他们的非结构化文本（例如公共论坛或社交网络帖子）中自动推断出广泛的<strong>个人作者属性</strong>（例如<strong>年龄、性别和出生地</strong>）。推理时间。特别是，我们发现当前的前沿模型（例如 GPT-4 ）在从文本推断此类属性时平均达到<strong>85%</strong> top-1 和<strong>95.8% top-3 的准确度</strong>。与此同时，LLM的快速发展大大降低了此类侵犯隐私推论的相关成本（&gt; 100 倍的金钱和 &gt; 240 倍的时间），使对手能够将侵犯隐私的推论规模远远超出以前通过昂贵的人力所能实现的范围。分析器。</p>
<blockquote>
<p>LLM的回答会有n个排序， 概率从高到低，一般我们收到(看到的)回答是top1， 其他回答是隐藏起来的。第一个回答猜对的概率达到85%，而前三个回答猜对的概率是95.8%。</p>
</blockquote>
<br>
<h3 id="q2-为什么这很重要">Q2： 为什么这很重要？</h3>
<p><strong>它可以直接影响用户隐私</strong>； 人们在互联网留下了大量文本——常常无意中泄露了他们不想透露的个人数据。欧盟的 GDPR 或加州 CCPA 等数据保护法规的制定是为了保护原始个人数据。仅当个人数据以明显的形式存在时，例如具有显式属性字段的私人配置文件，才能遵守此类法规。相比之下，<strong>我们的工作引入了一种威胁模型，其中私人信息是从其存在不明显的上下文中推断出来的</strong>。我们展示了恶意行为者如何通过将用户的在线帖子输入预先训练的LLM来推断出从未打算泄露的用户私人信息。众所周知，一半的美国人口可以通过位置、性别和出生日期等少量属性来唯一识别[<a href="https://dl.acm.org/doi/10.1142/S0218488502001648">Sweeney, &lsquo;02]</a>。LLM可以从互联网上发现的非结构化摘录中推断出其中一些属性，可以使用其他公开信息（例如美国的选民记录）来识别实际的人。这将允许这些行为者将从帖子中推断出的高度个人化的信息（例如，心理健康状况）与真实的人联系起来，并将其用于不良或非法活动，例如有针对性的政治运动、自动分析或跟踪。LLM的广泛可用性和快速发展带来了范式的变化，以前的 NLP 技术缺乏实现此类任务所需的自然语言理解水平。此外，我们还表明，进行侵犯隐私的推理的能力随着模型的大小而变化，预计在不久的将来会对用户隐私产生更大的影响。</p>
<p><img loading="lazy" src="img/04-accuracy.png" alt=""  />
</p>
<br>
<h3 id="q3-这在实践中是如何运作的">Q3: 这在实践中是如何运作的？</h3>
<p><strong>它具有可扩展性并且易于执行</strong>。 我们根据来自 500 多个个人资料的真实 Reddit 评论评估了当前几个 LLM 的隐私推理能力，包括整个 Llama-2 系列、Anthropic 的 Claude 2、Google 的 PaLM 2 和 GPT-4 。我们的实验表明（除了这些LLM取得了令人印象深刻的准确性这一事实之外），这种<strong>侵犯隐私的推论非常容易大规模执行</strong>。特别是，我们发现这是两个因素的结合：</p>
<ul>
<li>首先，我们观察到目前模型中**几乎没有有效的保护措施，这会使侵犯隐私的推论变得更加容易。**值得注意的是，这使我们能够使用简单的提示（仅使用 COT 等基本技术），从而节省了提示工程所需的大量时间和精力。只有在极少数情况下，我们发现模型（跨大型提供商，即 OpenAI、Google、Meta、Anthropic）会阻止请求，在这种情况下，人们将不得不诉诸更复杂的提示技术。</li>
<li>同时，这些模型广泛且易于使用，使对手能够以最小的前期成本大幅扩展。即使有 API 限制，我们的实验实现了 <strong>时间减少100 倍 、 成本减少240 倍</strong>。从那时起，我们联系了所有模型提供商，作为我们负责任的披露政策的一部分，积极讨论如何在未来防止此类推论。我们在这一领域看到了两种有前途的方法：（i）致力于在预先训练的LLM中针对侵犯隐私的推理请求提供具体的保障措施；（ii）为最终用户提供可以保护其生成的文本免受推理的工具。</li>
</ul>
<p><img loading="lazy" src="img/05-cost.png" alt=""  />
</p>
<br>
<h3 id="q4-我们使用匿名工具可以躲过llm的隐私推断吗">Q4: 我们使用匿名工具可以躲过LLM的隐私推断吗？</h3>
<p><strong>LLM的表现优于当前的匿名工具</strong>。 为了测试LLM在最先进的匿名化工具上的表现，我们对所有收集的数据进行了匿名化，重新运行我们的推论。事实证明，即使在应用了高度匿名化之后，文本中仍然保留了足够的相关上下文，供LLM重建部分个人信息。此外，这些工具完全无法解决更多被删除的线索，例如特定的语言特征，同时仍然为侵犯隐私的LLM推论提供了大量信息。<strong>这尤其令人担忧，因为在这些情况下，用户采取了明确的预防隐私泄露的措施，从而造成一种高隐私感的错觉</strong>。同时，使用当前的匿名工具，在匿名化和实用性之间存在显着的权衡。简单地用 <code>*</code>替换部分文本会严重影响数据本身的有用性。</p>
<p><img loading="lazy" src="img/06-privacy-tools.png" alt=""  />
</p>
<p><br><br></p>
]]></content:encoded>
    </item>
    
  </channel>
</rss>
