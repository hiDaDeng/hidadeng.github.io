<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>语言模型 on 大邓和他的PYTHON</title>
    <link>/tags/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/</link>
    <description>Recent content in 语言模型 on 大邓和他的PYTHON</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh</language>
    <lastBuildDate>Tue, 14 Feb 2023 00:00:00 +0000</lastBuildDate><atom:link href="/tags/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>如何注册chatGPT账号</title>
      <link>https://hidadeng.github.io/blog/2023-02-15-how-to-sign-up-the-chatgpt-accout-and-upgrade-to-plus/</link>
      <pubDate>Tue, 14 Feb 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-02-15-how-to-sign-up-the-chatgpt-accout-and-upgrade-to-plus/</guid>
      <description>如何注册chatGPT，如何升级为PLUS用户</description>
      <content:encoded><![CDATA[<h2 id="一拦路虎">一、拦路虎</h2>
<p>使用chatGPT PLUS前，我们将面临有几个拦路虎</p>
<ol>
<li>如何科学上网</li>
<li>海外手机号</li>
<li>国外的信用卡</li>
</ol>
<p>搞定了这些问题， 我们就可以愉悦的使用chatGPT</p>
<p><img loading="lazy" src="img/chatgpt-is-a-joke.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="二注册chatgpt">二、注册chatGPT</h2>
<p>注册 chatGPT，需要先科学上网， 教程之前分享过 <a href="https://hidadeng.github.io/blog/2023-02-01-v2net-science-network/">科学上网v2net</a> ，需要注意， 代理节点推荐选用美国、日本，全局模式访问外网。</p>
<h3 id="21-自己注册">2.1 自己注册</h3>
<p>搞定了 chatGPT 页面的访问后，需要使用国外可用的手机号， 才能注册chatGPT， 这时候可以用<a href="https://sms-activate.org/">接码平台https://sms-activate.org/</a>，</p>
<h3 id="22-找代理注册账号">2.2 找代理注册账号</h3>
<p>或者花钱 <a href="https://shop.terobox.com/?from=1059">找代理网https://shop.terobox.com/</a> 注册chatGPT账号。对了， 大邓自己的账号就是找代理注册的。</p>
<p><img loading="lazy" src="img/chatgpt-register-page.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="三chatgpt-plus">三、chatGPT PLUS</h2>
<p>chatGPT短短一个月，注册用户狂涨至 一亿用户， 是目前发展最迅猛的 网络应用。这就导致短时间大规模的访问让chatGPT服务有点绷不住了， 出现网络连接不稳定、响应速度变慢。 而且chatGPT的功能也被阉割， 不像最初那么智能。解决办法只有一个&mdash;使用超能力，20美金将账号提升至PLUS。有两种PLUS升级方式</p>
<h3 id="21-虚拟信用卡">2.1 虚拟信用卡</h3>
<p>升级chatGPT PLUS的难点在于你的信用卡是否可用。比如大邓，即使是VISA卡， 升级PLUS也不支持。解决办法是使用<a href="https://hidadeng.github.io/blog/2023-02-11-credit_card_for_chatgpt-plus/">虚拟信用卡</a> ， PLUS最终使用成本大概 <strong>150元（21美元/月） ， 大邓个人推荐自己搭建虚拟信用卡</strong>，</p>
<h3 id="32-找代理升级账号">3.2 找代理升级账号</h3>
<p>如果觉得操作起来比较繁琐复杂，如果你经济状况还okay， 可以使用 <a href="https://shop.terobox.com/?from=1059">代理网https://shop.terobox.com/</a> ，但就是有些小贵， 要300元啊，两倍于自己搞。</p>
<p><img loading="lazy" src="img/chatgpt-register-page.png" alt=""  />
</p>
<br>
<br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://hidadeng.github.io/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://hidadeng.github.io/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://hidadeng.github.io/blog/management_python_course/">支持开票 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>转载 | 大数据时代的「计算文化心理学」</title>
      <link>https://hidadeng.github.io/blog/2023-02-13-computing-cultural-psychology-with-big-data/</link>
      <pubDate>Mon, 13 Feb 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-02-13-computing-cultural-psychology-with-big-data/</guid>
      <description>随着大数据技术与文化心理学的融合发展, 计算文化心理学作为一门新兴交叉学科逐渐兴起, 大尺 度、近乎全样本的文化心理分析真正得以实现。计算文化心理学关注的文化变量主要围绕个人主义/集体主义 这一文化心理学使用最为广泛的维度展开, 分析方法包括特征词典、机器学习、社会网络分析、仿真模拟等, 分 析思路包括时间维度上的文化变迁效应以及空间维度上的文化地理效应。 当然, 计算文化心理学在为传统文 化心理研究提供新方法、新范式的同时, 也存在解码失真、样本偏差、词语多义性、隐私风险等局限, 未来研 究应重视变量理论解释、文化动态演化分析、学科深度整合、生态效度等问题。</description>
      <content:encoded><![CDATA[<h2 id="推荐理由">推荐理由</h2>
<p><a href="https://hidadeng.github.io/blog/management_python_course/"><strong>「课程 | Python实证指标构建与文本分析」</strong></a> 一直是面向经管、心理学、社会学等计算社会科学的一门综合性课程。 希望能学技术的同时，也多了解技术应用背后的方法论、认识论，大数据导向的研究必能事半功倍。</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">吴胜涛,茅云云,吴舒涵,冯健仁,张庆鹏,谢天,陈浩,朱廷劭.基于大数据的文化心理分析[J].心理科学进展:1-13.
</code></pre></div><p><strong>摘要</strong>: 随着大数据技术与文化心理学的融合发展, 计算文化心理学作为一门新兴交叉学科逐渐兴起, 大尺度、近乎全样本的文化心理分析真正得以实现。计算文化心理学关注的文化变量主要围绕个人主义/集体主义这一文化心理学使用最为广泛的维度展开, 分析方法包括特征词典、机器学习、社会网络分析、仿真模拟等, 分析思路包括时间维度上的文化变迁效应以及空间维度上的文化地理效应。 当然, 计算文化心理学在为传统文 化心理研究提供新方法、新范式的同时, 也存在解码失真、样本偏差、词语多义性、隐私风险等局限, 未来研 究应重视变量理论解释、文化动态演化分析、学科深度整合、生态效度等问题。</p>
<p><strong>关键词: 大数据, 文化, 计算文化心理学, 文化变迁, 文化地理</strong></p>
<p><br><br></p>
<h2 id="一大数据文化心理学">一、大数据文化心理学</h2>
<p>近 10 年的大量文献来看, <strong>大数据技术已经成为当前哲学、自然科学和 社会科学共同关注的重要问题,  为人文与社会科学提供了继实验、理论、仿真之后的第四种研究范式,  并催生了计算社会科学</strong>的诞生(Gray, 2009; Lazer et al., 2009)。</p>
<p>随着大数据时代的到来, 传统文化心理学面临诸多挑战, 但也迎来了范式变革的机遇。</p>
<p>首先, 互联网将人与人之间的距离拉近, 使得不同文化背景的人主动或被动地汇聚在一个时空压缩的“地球村”里, 全球范围的文化互动、变迁成为常态, 但由于研究资料受限、分析方法滞后, <strong>传统文化心理学在进行大尺度时间、空间分析时费时费力。幸运的是, 信息技术的发展使得不同时间、空间的文化符号及其互动过程留下了海量的数据印记, 这为研究者分析不同时间、不同空间下的文化心理特征提供了无可比拟的大规模生态数据库。</strong> 进而, 大数据技术赋能研究者们方便地抓取网络生态数据, 研究文化动态演化及节点事件效应(Park, Baek et al., 2014; Wu, Zhou et al., 2018), 使得时间趋势和空间地理上的大尺度分析真正成为可能, 文化心理学的研究问题也得以拓展。</p>
<p>其次, 大数据时代文化符号生产快速增长, 但是基于纸笔测验和行为实验的传统文化心理学 研究往往是滞后的, 且样本量较小、代表性不够, 远远不能满足研究者和决策者的需要。 而<strong>基于大数据的文化心理学研究能够以相对较低的时间、 人力成本实现近乎全样本的数据进行自动抓取、 实时分析乃至实验操控, 并从海量数据中迅速锁定、预测某一群体的行为特征, 进而实现宏观群 体水平的文化心理分析、预测和改变。</strong></p>
<p><strong>再者, 大数据时代的文化互动日趋个体化和复杂化, 而传统的文化心理学容易忽视文化成员在个体水平及复杂情景中的差异, 仅通过抽样追 求简单因果关系, 却难以把握文化心理、行为间的复杂相关性</strong>。也就是说, 在没有搞清楚“是什么” 的情况下就去分析“为什么” (顾肃, 2021)。 巨大、 连续的数据存储和模型分析, 以一种细粒度和大规模乃至全球范围的方式实时研究个体行为, 能够根据个体和情景变异进行适应性的调整和持续、实时的纠正;  同时, 庞大数据量补偿了精确性上的损失, 这有助于分辨出最合适的相关关系, 捕捉小数据测量时没有的新价值(Lazer et al., 2009)。尽管基于大数据技术的词频、预测模型或社会网络分析并非新鲜事物, 但将其应用于文化心理学研究能够从整体上把握对象, 促进从因果思维向相关性思维转变, 进而有利于全面、客观地揭示隐藏在数据背后的文化意涵和规律(陈云松, 2015)。</p>
<p><strong>最后, 更为重要的是, 大数据时代的文化形态也发生了深刻变化。</strong> 随着互联网的快速发展与网民的大量增加, 基于网络的独特文化现象层出 不穷, 一些经典的文化行为特征在网络上的表现也有所不同, 但传统文化心理学对此知之甚少。 例如, 研究发现相对于其他社会环境, 网络环境 下人们的情绪表达会更极端, 而且网络使用的时间越长, 极端情绪越明显(King, 2001)。 此外, 由于线上与线下任务的认知加工过程不同, 人们在 一些经典的文化认知表现上也存在差异。 例如, 相对于认知负荷较大的线下记忆任务, 低认知负荷的线上浏览任务中被试有更多的认知资源来处理外部信息, 因此在社会行为推理上会表现出较小的对应偏差, 基于国别的文化差异被基于线上 和线下的文化差异所代替(Miyamoto &amp; Kitayama, 2002)。 尤其值得注意的是, 移动互联网本身就是一种带有偏差的文化产品, 例如具有相应文化倾向(如高个人主义、低不确定性回避)的用户也更能 体验到技术−文化匹配后的愉悦感和效用感(Lee et al., 2007)。 因此我们不能仅满足于将研究线下文化现象的思维来简单套用到线上行为的文化心理研究中。 总之, 随着计算机和大数据技术的深入发展, 人类社会及其文化形态正经历着深刻的变革。 <strong>文化符号的生产和互动日趋复杂, 文化成员及其社 会网络更是留下了海量的文本与行为足迹。 这使得文化必须被快速地描述、预测甚至改变, “可计算”的文化符号及其互动过程也逐渐成为文化心理学的研究对象。 接下来, 我们将主要对计算文化心理学的产生过程、主要变量和分析技术进行回顾, 并介绍该技术在相关文化变迁、文化地理效应的应用。</strong></p>
<p><br><br></p>
<h2 id="二计算文化心理学">二、计算文化心理学</h2>
<p>在计算文化心理学正式产生以前, 文化学者就受到计算机技术的启发, 提出了**「文化计算」**概 念, 强调要发挥计算机的独特优势, 以便多维度 展现文化及其与人的互动(Tosa et al., 2005)。通过 <strong>文化计算</strong>, 研究者首先在艺术领域实现了文化的数据化呈现和翻译(Tosa et al., 2019)。 进而, <strong>文化计算把计算及相关技术应用到越来越多的文化领域, 探索其发展规律、提示其内在联系并对其进行量化分析与展示的科学</strong>(赵海英 等, 2016)。 如 Michel 等人(2011)通过对谷歌图书项目的数据进行分析, 发现了特定关键词使用频率的时间变化规律, 并由此推导出人类文化发展的趋势, 如语法演变、集体记忆和流行病学的变化趋势等; 吴育锋等人(2018)通过“文心” (中文心理分析系统) 对小说《平凡的世界》中的对话文本进行文学智能分析, 发现其计算出的小说人物性格与以往文艺研究结果一致, 并发现了不同时代人物呈现出性格变迁的趋势(如新时代青年的性格更加开放、 外向);</p>
<p>Neuman 等人(2012)在 <strong>「文化计算」</strong> 的基础上正式提出了**「计算文化心理学」**”的概念, 即通过计算工具和大数据资料库来研究文化符号及其互动过程的心理学分支。 值得注意的是, 虽然文化计算和基于计算的文化心理学有很多相似之处, 但是二者也有区别：</p>
<ul>
<li>前者侧重文化载体的呈现, 以及 文化基因的提取;</li>
<li>后者除了一般意义上的文化计算, 还注重分析人与文化环境的交互关系, 并且文化载体不仅是传统艺术文化, 也包含网络社交 媒体等。</li>
</ul>
<p><br><br></p>
<h2 id="三文化心理变量的提取">三、文化心理变量的提取</h2>
<p>为了理解文化现象, 心理学者需要首先提取文化心理变量, 进而理解影响其成员思维的符号系统和互动机制。<strong>语言是被分享的文化系统(王斌, 2012), 因此我们可以把语言看做是理解文化的窗口以及提取文化心理变量的来源(罗伯特·怀尔 等, 2017)。 语言的本质是思想、话语的直接现实和展示(吴美川, 2020), 其在计算文化心理学领域的语言载体主要包括书籍、社会媒体数据、档案数据、网络音频等</strong>。</p>
<p>针对语言文化载体, 研究者主要提取的文化心理变量包括<strong>个人主义/集体主义、个性解放/自我表达、文化松紧度</strong>等, 详见表 1。</p>
<p><img loading="lazy" src="img/%e6%96%87%e5%8c%96%e5%bf%83%e7%90%86%e5%8f%98%e9%87%8f%e7%a0%94%e7%a9%b6%e8%b7%9d%e7%a6%bb.png" alt=""  />
</p>
<p>第一, 这些变量本身具有重要研究价值, 如个人主义/集体 主义是文化心理学中使用最为广泛的文化维度, 尤其对社会文化变迁和跨文化比较研究具有重要 意义; 第二, 社会现实的需求, 如新冠疫情的全球大流行显著增加了规范遵从的强度, 这需要研 究者及时分析其文化适应后果及政策干预策略; 第三, 此类文化变量的可操作性强, 便于用大数 据方法来进行抓取和计算。</p>
<p>此外, 计算文化心理学研究也对一些文化变量进行了操作化和创造性的发展。 首先, 考虑到大数据的语料库特点, 选用一些便于操作的语言 特征作为经典文化心理学变量的指标, 例如用第一人称单数的使用频率作为个人主义的指标(Twenge et al., 2013); 其次, 将个体的行为印记(如@他人、 成组人群比例)作为文化心理变量的指标, 是对以往基于主观报告的文化心理测量的重要发展(Wu, Li et al., 2018); 此外, 根据新媒体的特点, 采用表情包等作为文化相关情绪表达规范的指标也是一种有益的创新(Koda &amp; Ishida, 2006)。</p>
<p><br><br></p>
<h2 id="四文化心理变量的计算方法">四、文化心理变量的计算方法</h2>
<p>目前采用大数据技术进行文化心理分析主要 有 4 种方法：</p>
<ol>
<li>
<p>基于<strong>特征词典的频次分析</strong>, 如通过对数字、表情和语言等方面的关键特征分析, 研究个体或群体的文化价值观, 这是一种简单有效但相对粗糙的分析(李国杰, 程学旗, 2012)。</p>
</li>
<li>
<p>基于<strong>机器学习的模型预测或词嵌入联想测验</strong>, 如通过机器学习模型对用户的个性、价值观和意识 形态进行识别, 这种方法更精确, 对心理特征的 把握也更全面(Kosinski et al., 2015); 词嵌入联想 测验以词嵌入向量特征代替传统的词频特征, 将 靶词和属性词向量的余弦相似度作为语义关联度的指标, 是社会态度与价值观研究的新方法 (Caliskan et al., 2017; Hamamura et al., 2021)。</p>
</li>
<li>
<p><strong>社会网络分析</strong>, 如通过对网络搜索、网友互粉 等数据的分析, 研究不同文化群体的行为和决策风格, 这种方法目前在文化心理学领域还相对较 少, 但具有重要的社会实践价值(Wu, Li et al., 2018);</p>
</li>
<li>
<p><strong>社会仿真模型</strong>, 因为很多社会事 件是无法在现实中进行实验的, 所以采用仿真模拟的办法来研究某一特定的系统和策略, 从而达到分析社会事件的目的(刘婷婷 等, 2016)。 当然, 这 4 种技术并不是孤立的, 研究者也会根据研究 问题采取一种或多种技术。</p>
</li>
</ol>
<blockquote>
<p>特征词典的频次分析、机器学习的模型预测或词嵌入联想测验等技术方法在课程<a href="https://hidadeng.github.io/blog/management_python_course/"><strong>「课程 | Python实证指标构建与文本分析」</strong></a> 中均有丰富的案例、代码、实战。</p>
</blockquote>
<br>
<p>总之, 计算文化心理学致力于应用大数据思维、大数据资源和计算工具来研究文化系统背后的意义制造与互动过程, 它不仅为文化心理分析 提供了新的工具, 也为理解人类思维本质和文化 形态提供了新的学科范式(Neuman, 2014)。<strong>围绕着“集体主义/个人主义”这一被最广泛讨论的文化心理变量, 「计算文化心理学」可以在时间、空间两个维度方面有如下应用</strong>：</p>
<ul>
<li>在时间维度上, 分别从长时程的宏观历史发展和短时程的经济波动转型两个角度介绍计算文化心理学的应用;</li>
<li>在空间维度上, 主要进行生态地理分析, 如文化在特定政治和经济框架内的地区差异, 不同地区生态或户籍制度造成的个人−环境匹配与价值失调。 分析框架见图 1。</li>
</ul>
<p><img loading="lazy" src="img/%e8%ae%a1%e7%ae%97%e6%96%87%e5%8c%96%e5%bf%83%e7%90%86%e5%ad%a6%e7%9a%84%e5%88%86%e6%9e%90%e6%a1%86%e6%9e%b6.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="五不足展望">五、不足&amp;展望</h2>
<p>虽然计算文化心理学已经崭露头角, 相对于 传统文化心理学研究方法和范式具有无法比拟的优势, 但利用大数据进行文化心理分析仍然存在一些局限。</p>
<h3 id="51-技术自身带来的局限">5.1 技术自身带来的局限</h3>
<p><strong>首先, 很多研究者忽视了同一变量在不同时代、不同国家的意义分歧, 造成解码失真</strong>。 心理学者检验文化变迁的常用方法是寻找作者认为对 文化敏感的词汇并探索其使用频率的时间变化, 比如通过追踪第一人称单、复数代词的使用频率 来分析集体主义、个人主义的时间变迁效应 (Twenge et al., 2013; Yu et al., 2016)。 然而, 语言 总是随着时间演变, 同一个词义并不具有稳定性, 其不可避免地受到经济、政治或者文化因素的影响。</p>
<p><strong>假定大数据背后的文化成员能代表整个文化, 容易将带有偏差的文化成员样本视为研究整体</strong>。 例如, 很多研究者使用当下非常流行的语料库——Google Ngram Viewer 来研究集体主义/个人主 义, 并把结论推广至整个国家层面(Twenge et al., 2013)。 但实际上, 该语料库并不能代表无差别的文化整体, 相反, 它仅仅是突出了特定子群体的文化, 如 Google Ngram Viewer 仅代表书面文化的使用者, 社交媒体数据只包含社交媒体用户, 而 忽视了没有机会接触书籍和社交媒体的文化成员 (Pettit, 2016)。 所以, <strong>研究者要特别注意, 诸如图书语料库、社交媒体分析等并不是基于无偏样本, 因此在使用该类分析材料时要考虑结论的可推广 性和普遍适用性问题。</strong></p>
<p>第三, 研究者对量表或题项进行赋值、使得变量可计量, 进而将文化心理与行为转换为一种符号系统, 但是<strong>大数据分析中的频次分析提取的 关键词往往具有多义性, 如果研究者只是摘取了某个含义并将其纳入特定理论范畴, 则难免会出 现选择性谬误</strong>。 同时, 用于处理数据的软件还会 进一步固化这一测量误差。例如在 LIWC 软件中, 因 为 “great” 属 于积极情感范畴 , 所 以 “a great amount of rain”这一无关表达将被归类为积极情 感表达。 这意味着, 即便大数据分析技术的飞速发展, 但其得出的结果仍不够精确。</p>
<p>第四, 存在文化被监控和被操纵、以及侵犯个人隐私的风险。 大数据以其海量存储和智能计算优势来提取个人和特定群体的文化和性格数据, 进而实施与文化−性格相匹配的精准操纵, 甚至攻击。 这些做法明显的弊端就是数据隐私性和国 家区域安全难以保证, 容易被不法分子利用。 因 此, 为了避免个体数据及其分析结果被滥用, 全球研究者应该将研究伦理置于大数据分析的首位, 共同谋求相应的解决措施和共通的数据法律来解 决个人信息及国家或地区文化心理分析的不当使 用问题 (Kosinski et al., 2015)。</p>
<br>
<h3 id="52-技术带来的机会">5.2 技术带来的机会</h3>
<p><strong>我们不能忽视它在未来的巨大发展空间， 应从理论高度对大数据测量指标进行准确定义和解释</strong>。 大数据时代, 出现了重视数据驱动、而轻视理论的现象(维克托 • 迈尔-舍恩伯格, 肯尼斯 • 库克耶, 2013)。 但实际上大数据只是在数据采集中提供了一个发现或检验科学理论的新方法, 不能在知识生产环节中取代理论知识的地位。 理论在大数据研究中是重要的, 一方面大数据分析的算法模型以及对数据的解释需要理论的支撑(彭理强, 2019), 另一方面我们需要运用数据的意向性并由此对数据进行分类, 而不同的意向性和不同的分类体系是由理论概念决定的(齐磊磊, 2015)。 因此, <strong>在未来的研究中, 研究者的设计和经验数据的使用应在理论指引下进行, 尤其在指标维度的构建上要重视理论术语的指称和实体之间的关系</strong>(贾向桐, 2019)。</p>
<p><strong>其次, 利用多种大数据语料库, 进行更广泛的文化动态演化分析</strong>。 过往的研究容易把文化看做静态的单一实体, 并且将不同文化之间的异同 归因于其背后的国家/民族中根深蒂固的特质, 即轻易对群体进行本质化。 然而, 我们需要意识到文化知识是动态发展的过程, 文化的相关潜质或 因果连结存在于特定共享文化知识的激活, 并且 共享文化会随着社会政治和其他类型的社会变化 不断地产生和演化(康萤仪 等, 2010)。 传统的文 化心理学研究受制于小样本并容易忽视微弱的相 关关系, 因此在条件允许的情况下, 未来需要依 赖多种大数据语料库开展更广泛的纵向大尺度研 究, 探索文化符号串联及其背后机制的研究线 索。例如, 研究者可以使用历史档案数据库, 来研 究共享文化从何而来、其分布与使用的频率如何、 共享的边界是什么、共享文化被激活后产生了什么后果等, 进而促进共同的和个体的经验。</p>
<p><strong>第三, 推动文化心理学与计算机、传播学、 历史学等学科的深度整合</strong>。 文化心理学的力量在于其方法论上的多元化和多学科基础(余霞, 钟年, 2019; Cohen, 2019)。 但是, 跨学科也使得学科互补的同时充满文化冲突, 例如不同学科会由于不同范式而在考虑问题的优先级等方面存在根本性 差异, 一旦学科之间产生冲突, 问题或许就会贯穿任何主题和学科的边界(Popper, 1963)。 然而, <strong>当计算思维、数据资源和计算工具被采用后, 就可以从方法论层面加速对研究问题的解决</strong>。 在未来研究中, 研究者可以充分利用计算文化心理学固有的学科多样性和数据多源化, 尝试通过“计 算”去更好地整合文化心理学背后的多个学科视 角及其变量维度, 使大家共同聚焦某个问题。 比如, 为了描绘复杂的文化现象共同将目光聚焦于 背后多源数据的处理、共享数据库的建成、理论与数据的结合等学科问题, 不断推进计算文化心理学的整体发展。</p>
<p><strong>最后, 利用大数据的“场景功能”, 提升文化心理学研究的生态效度。</strong> 一直以来, 由于实验情境缺乏生态效度, 心理学赖以成为“科学”的实验研究备受质疑; 而在大数据背景下, 研究者对已有数据的挖掘完全能够在自然情境下生成实验变量, 在大数据中挑选情境便是实验方式(喻丰 等, 2015)。 在未来研究中, 研究者不仅可以聚焦小场景, 研究个人经验与近端影响源之间的关系, 而且可以探索大场景中更远端影响源与个人经验之间的相互作用, 从而分析不同时间、空间的文化 差异。值得注意的是, 当场景被扩大和拉长, 这些真实的场景可能体现了个人行为与动机的绝大部 分变异, 这体现了自然情境研究的“深度背景化”, 有助于提升文化等背景特征的解释水平。</p>
<p><br><br></p>
<h2 id="六总结">六、总结</h2>
<p>总之, 计算机和大数据技术深刻影响了文化符号的生产、互动方式以及文化形态本身, 并促成了计算文化心理学的产生和发展。 通过回顾计 算文化心理学的产生过程, 以及将大数据分析方法应用到文化变迁、文化地理效应等多个领域的实证研究, 有助于我们理解计算文化心理学的学 科优势、局限及未来发展方向, 并对文化心理研 究的思路拓展和方法革新具有启发意义。</p>
<p>尤为重要的是, 大数据为大尺度的文化分析提供了可能。 文化作为一种宏观且多变的现象, 任何一种文化理论都需要从越大规模的时间和空 间维度来进行检验和评判, 基于大数据的计算文化心理学能够为研究者提供数以亿计的数据以及 强有力的分析工具; 同时, 大数据改变了传统文 化心理学的研究范式, 更产生了诸多新的文化现 象, 这蕴含了整个学科思维方式和学科体系的变 革(喻丰 等, 2015)。当然, 在看到大数据为传统文 化心理研究提供新方法、新范式的同时, 我们也不能忽视其研究局限, 以及潜在的伦理和安全风险。</p>
<br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://hidadeng.github.io/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://hidadeng.github.io/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://hidadeng.github.io/blog/management_python_course/">支持开票 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>数据清洗 | 借助 chatGPT 设计正则表达式</title>
      <link>https://hidadeng.github.io/blog/2023-02-12-regex-expression-generated-by-chatgpt/</link>
      <pubDate>Sun, 12 Feb 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-02-12-regex-expression-generated-by-chatgpt/</guid>
      <description>使用 chatGPT 做正则表达式做数据清洗。</description>
      <content:encoded><![CDATA[<p>正则表达式可以帮我们，对给定输入的数据input_data，设定一定的规律pattern，输出干净结果output_data的工具。</p>
<p>但对于小白而言，很多时候，我们知道 input_data 和 output_data， 但不知道如何设计 表达式pattern，毕竟即使是计算机专业的学生，如果不系统钻研，都不一定会快速上手，更遑论我们文科生小白。<strong>chatGPT 是一种具有极强学习和推理能力的工具， 我们需要先研究数据中的规律，抽象出能实现目的的 input_data 和 output_data， 丢给chatGPT帮我们设计</strong>。</p>
<p>接下来的人机对话中，input_data 和 output 为视频课程《Python实证指标构建与文本分析》正则表达式章节的实验数据。实验下来， 比通过谷歌百度搜效率高多了，准确率也不错。</p>
<br>
<h2 id="问题1-提取个人信息">问题1-提取个人信息</h2>
<h3 id="deng">deng:</h3>
<p>我正在学习Python正则表达式，将给出实验文本数据input_data，以及我想从中抽取出的内容output_data。请帮我设计对应的正则表达式。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">input_text</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;大家好，我叫张三,来自河北，今年30岁。&#39;</span><span class="p">,</span>                      
              <span class="s1">&#39;大家好，我叫李四,来自山东，今年25岁。&#39;</span><span class="p">,</span>                     
              <span class="s1">&#39;大家好，我叫王五,来自内蒙古，今年22岁。&#39;</span><span class="p">]</span> 


<span class="n">output</span> <span class="o">=</span> <span class="p">[(</span><span class="s1">&#39;张三&#39;</span><span class="p">,</span> <span class="s1">&#39;河北&#39;</span><span class="p">,</span> <span class="s1">&#39;30&#39;</span><span class="p">),</span> 
          <span class="p">(</span><span class="s1">&#39;李四&#39;</span><span class="p">,</span> <span class="s1">&#39;山东&#39;</span><span class="p">,</span> <span class="s1">&#39;25&#39;</span><span class="p">),</span> 
          <span class="p">(</span><span class="s1">&#39;王五&#39;</span><span class="p">,</span> <span class="s1">&#39;内蒙古&#39;</span><span class="p">,</span> <span class="s1">&#39;22&#39;</span><span class="p">)]</span> 
</code></pre></div><h3 id="chatgpt">chatGPT:</h3>
<p>下面是匹配上述input_data和output_data的正则表达式：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">re</span>

<span class="n">input_data</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;大家好，我叫张三,来自河北，今年30岁。&#39;</span><span class="p">,</span> 
              <span class="s1">&#39;大家好，我叫李四,来自山东，今年25岁。&#39;</span><span class="p">,</span>
              <span class="s1">&#39;大家好，我叫王五,来自内蒙古，今年22岁。&#39;</span><span class="p">]</span>

<span class="n">output_data</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">text</span> <span class="ow">in</span> <span class="n">input_text</span><span class="p">:</span>
    
    <span class="n">res</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">findall</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;我叫(.*),来自(.*)，今年(.*)岁&#39;</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>
    <span class="n">output_data</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">tuple</span><span class="p">(</span><span class="n">res</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
    
<span class="nb">print</span><span class="p">(</span><span class="n">output_data</span><span class="p">)</span>
</code></pre></div><p>这段代码将使用正则表达式 <code>r&quot;我叫(.*),来自(.*),今年(\d+)岁&quot;</code> 匹配 <code>input_data</code> 中的内容，并将每一行的匹配结果存储在 <code>output_data</code> 列表中。</p>
<br>
<h2 id="问题2-提取出数据中的年份">问题2-提取出数据中的年份。</h2>
<h3 id="deng-1">deng:</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">intput_data = &#34;&#34;&#34;Python是一门面向对象的编程语言，诞生于1991年22。目前以广泛应用在网站开发、游戏软件开发、数据采集、机器学习等多个领域。一般情况下Python是Java的20%，所以说人生苦短，我用Python。&#34;&#34;&#34;

output_data = [&#39;1991&#39;]
</code></pre></div><h3 id="chatgpt-1">chatGPT：</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">re</span> 
<span class="n">intput_data</span> <span class="o">=</span> <span class="s2">&#34;&#34;&#34;Python是一门面向对象的编程语言，诞生于1991年22。目前以广泛应用在网站开发、游戏软件开发、数据采集、机器学习等多个领域。一般情况下Python是Java的20%，所以说人生苦短，我用Python。&#34;&#34;&#34;</span> 
<span class="n">output_data</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">findall</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;\b\d</span><span class="si">{4}</span><span class="s1">\b&#39;</span><span class="p">,</span> <span class="n">intput_data</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">output_data</span><span class="p">)</span>
</code></pre></div><br>
<h2 id="问题3-resplit分割句子">问题3-re.split分割句子</h2>
<h3 id="deng-2">deng:</h3>
<p>用re.split 分割 input_data ，生成output_data， 设计刚刚的正则表达式。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">intput_data</span> <span class="o">=</span> <span class="s2">&#34;&#34;&#34;Python是一门面向对象的编程语言，诞生于1991年22。目前以广泛应用在网站开发、游戏软件开发、数据采集、机器学习等多个领域。一般情况下Python是Java的20%，所以说人生苦短，我用Python。&#34;&#34;&#34;</span>

<span class="n">output_data</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Python是一门面向对象的编程语言&#39;</span><span class="p">,</span> 
               <span class="s1">&#39;诞生于1991年&#39;</span><span class="p">,</span> 
               <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">目前以广泛应用在网站开发、游戏软件开发、数据采集、机器学习等多个领域&#39;</span><span class="p">,</span> 
               <span class="s1">&#39;一般情况下Python是Java的20%&#39;</span><span class="p">]</span>

</code></pre></div><h3 id="chatgpt-2">chatGPT：</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">re</span>

<span class="n">input_data</span> <span class="o">=</span> <span class="s2">&#34;&#34;&#34;Python是一门面向对象的编程语言，诞生于1991年22。目前以广泛应用在网站开发、游戏软件开发、数据采集、机器学习等多个领域。一般情况下Python是Java的20%，所以说人生苦短，我用Python。&#34;&#34;&#34;</span>

<span class="n">output_data</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;[。,]&#39;</span><span class="p">,</span> <span class="n">input_data</span><span class="p">)</span>
<span class="n">output_data</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="s1">&#39;。&#39;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">output_data</span> <span class="k">if</span> <span class="n">i</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="n">output_data</span><span class="p">)</span>
</code></pre></div><br>
<h2 id="问题4-resub替换数字为num">问题4-re.sub替换数字为NUM</h2>
<h3 id="deng-3">deng:</h3>
<p>使用正则表达式 re.sub 实现从input_data到output_data的转换。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">input_data</span> <span class="o">=</span> <span class="s2">&#34;&#34;&#34;Python是一门面向对象的编程语言，诞生于1991年。</span><span class="se">\
</span><span class="se"></span><span class="s2">一般情况下Python代码量是Java的20%，所以说人生苦短，我用Python。&#34;&#34;&#34;</span>

<span class="n">output_data</span> <span class="o">=</span> <span class="s1">&#39;Python是一门面向对象的编程语言，诞生于NUM年。一般情况下Python代码量是Java的NUM%，所以说人生苦短，我用Python。&#39;</span>
</code></pre></div><h3 id="chatgpt-3">chatGPT</h3>
<p>您可以使用正则表达式 re.sub 来实现将所有数字替换为 &lsquo;NUM&rsquo; 的转换：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">re</span>

<span class="n">input_data</span> <span class="o">=</span> <span class="s2">&#34;&#34;&#34;Python是一门面向对象的编程语言，诞生于1991年。</span><span class="se">\
</span><span class="se"></span><span class="s2">一般情况下Python代码量是Java的20%，所以说人生苦短，我用Python。&#34;&#34;&#34;</span>

<span class="n">output_data</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;\d+&#39;</span><span class="p">,</span> <span class="s1">&#39;NUM&#39;</span><span class="p">,</span> <span class="n">input_data</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">output_data</span><span class="p">)</span>
</code></pre></div><br>
<br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://hidadeng.github.io/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://hidadeng.github.io/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://hidadeng.github.io/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>使用 chatGPT 做词频统计&amp;词云图</title>
      <link>https://hidadeng.github.io/blog/2023-02-11-chatgpt-plus-for-text-mining/</link>
      <pubDate>Thu, 09 Feb 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-02-11-chatgpt-plus-for-text-mining/</guid>
      <description>使用 chatGPT 做词频统计&amp;amp;词云图，过程使用pandas、pyecharts、jieba等库。</description>
      <content:encoded><![CDATA[<h2 id="任务描述">任务描述</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">请用Python撰写一个中文文本分析的代码，进行词频统计、绘制词云图。

分析的数据是csv文件，过程使用pandas、pyecharts、jieba等库。

代码生成后，按照数据导入、数据清洗、数据分析、结果展示四个章节部分对代码进行中文讲解，格式为markdown。
</code></pre></div><br>
<h2 id="需要注意">需要注意</h2>
<ul>
<li>chatGPT需要科学上网才能使用， 推荐 <a href="https://hidadeng.github.io/blog/2023-02-01-v2net-science-network/"><strong>科学上网工具v2net</strong></a>。</li>
<li>如果想升级为chatGPT Plus，需要使用国外的虚拟信用卡，推荐阅读[<strong>使用虚拟信用卡，国内用户升级为chatGPT plus会员</strong>]https://hidadeng.github.io/blog/2023-02-11-credit_card_for_chatgpt-plus)</li>
</ul>
<br>
<h2 id="说明">说明</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">- 以下内容，80%左右内容为chatGPT生成，大邓工作主要是准备实验数据，调试代码，编辑章节。
- 实验环境chatGPT PLUS，今天刚刚花了20美元，使用全局网络模式下，chatGPT响应更稳定快速。
- chatGPT PLUS虽然很强，结果依然有问题，最初生成的词云图是基于wordcloud库，
  该库不支持中文，绘制的图片是乱码的。这里指导ta改为pyecharts制作词云图。
</code></pre></div><p>如需了解升级 <strong>chatGPT plus</strong> 教程(国内信用卡不支持，绑定需要国外的信用卡)， 可以私信大邓 <strong>37233583</strong>9， 备注【<strong>姓名-学校-专业</strong>】</p>
<br>
<h2 id="下载本文codezip"><a href="code.zip">下载本文</a></h2>
<p><a href="code.zip">点击下载本文代码&amp;数据</a></p>
<br>
<h2 id="一数据导入">一、数据导入</h2>
<p>首先需要导入需要的库：pandas、jieba、pyecharts等。如果电脑没有相应的库，可以命令行中执行以下安装命令</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">pip3 install pyecharts
pip3 install jieba
</code></pre></div><p>读取csv文件，使用pandas库的read_csv函数：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">jieba</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">pyecharts</span> <span class="kn">import</span> <span class="n">options</span> <span class="k">as</span> <span class="n">opts</span>
<span class="kn">from</span> <span class="nn">pyecharts.charts</span> <span class="kn">import</span> <span class="n">Bar</span><span class="p">,</span> <span class="n">WordCloud</span>


<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;data.csv&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<p><img loading="lazy" src="img/df.png" alt=""  />
</p>
<br>
<h2 id="二数据清洗">二、数据清洗</h2>
<p>清洗数据是文本分析的第一步，这里需要对数据进行去重、去除空值、去除停用词等操作。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1"># 去重</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop_duplicates</span><span class="p">()</span>

<span class="c1"># 去除空值</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">dropna</span><span class="p">()</span>

<span class="c1"># 加载停用词表</span>
<span class="n">stopwords</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;stopwords.txt&#39;</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">stopwords</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">line</span><span class="o">.</span><span class="n">strip</span><span class="p">())</span>

<span class="c1"># 分词，并去除停用词</span>
<span class="n">text</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>
<span class="k">for</span> <span class="n">content</span> <span class="ow">in</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;desc&#39;</span><span class="p">]:</span>
    <span class="n">seg_list</span> <span class="o">=</span> <span class="n">jieba</span><span class="o">.</span><span class="n">cut</span><span class="p">(</span><span class="n">content</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">seg_list</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">word</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">stopwords</span><span class="p">:</span>
            <span class="n">text</span> <span class="o">+=</span> <span class="n">word</span> <span class="o">+</span> <span class="s1">&#39; &#39;</span>

<span class="c1">#查看text部分内容</span>
<span class="n">text</span><span class="p">[:</span><span class="mi">200</span><span class="p">]</span>
</code></pre></div><pre><code>Building prefix dict from the default dictionary ...
Dumping model to file cache /var/folders/y0/4gqxky0s2t94x1c1qhlwr6100000gn/T/jieba.cache
Loading model cost 0.460 seconds.
Prefix dict has been built successfully.
</code></pre>
<p>Run</p>
<pre><code>'唐天宝 十四年 长安城 小吏 李善德 突然 接到 一个 任务 贵妃 诞日 之前 岭南 运来 新鲜 荔枝 荔枝 “ 一日 色变 两日 香变 三日 味变 ” 岭南 长安 五千余里 山水 迢 ... ◆ 编辑 推荐   ★ 〇 一年 国际 布克奖 美国 国家图书奖 短 名单 作品   ★ 入选 〇 二一 年度 纽约时报 书评 周刊 十大 好书   ★ 入选 奥巴马 〇 一年 夏季 阅读 书单   ★ .'
</code></pre>
<br>
<h2 id="三数据分析">三、数据分析</h2>
<p>使用jieba库对文本进行分词处理，然后<strong>统计每个词语的出现频率</strong>。这里使用Python的字典数据结构进行计数。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1"># 分词</span>
<span class="n">seg_list</span> <span class="o">=</span> <span class="n">jieba</span><span class="o">.</span><span class="n">cut</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>

<span class="c1"># 统计词频</span>
<span class="n">word_count</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">seg_list</span><span class="p">:</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">word</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">2</span><span class="p">:</span>  <span class="c1"># 只统计长度大于等于2的词语</span>
        <span class="k">if</span> <span class="n">word</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">word_count</span><span class="p">:</span>
            <span class="n">word_count</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">word_count</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>

<span class="n">word_count</span>
</code></pre></div><p>Run</p>
<pre><code>{'唐天宝': 4,
 '十四年': 2,
 '长安城': 4,
 '小吏': 2,
 '李善德': 2,
 '突然': 5,
 '接到': 2,
 ......
 '文笔': 1,
 '行云流水': 1,
 '医学': 1,
 '研究生': 1,
 '大为': 1,
 '空怀': 1,
 '壮志': 1,
 '无职无权': 1,
 '时来运转': 1,
 '有名': 2,
 '有利': 1,
 '真切': 1,
 '旅程': 1,
 '困扰': 1,
 '傅真': 1,
 '暌违': 1,
 '七年': 1,
 ...}
</code></pre>
<br>
<h2 id="四结果展现">四、结果展现</h2>
<p>接下来，根据统计结果绘制词云图和柱状图。</p>
<h3 id="41-词云图">4.1 词云图</h3>
<p>绘制词云图，使用pyecharts的WordCloud库：
<img loading="lazy" src="img/wordcloud.png" alt=""  />
</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pyecharts.options</span> <span class="k">as</span> <span class="nn">opts</span>
<span class="kn">from</span> <span class="nn">pyecharts.charts</span> <span class="kn">import</span> <span class="n">WordCloud</span>


<span class="n">wordfreqs</span> <span class="o">=</span> <span class="p">[(</span><span class="n">w</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">f</span><span class="p">))</span> <span class="k">for</span> <span class="n">w</span><span class="p">,</span><span class="n">f</span> <span class="ow">in</span> <span class="n">word_count</span><span class="o">.</span><span class="n">items</span><span class="p">()]</span>


<span class="p">(</span>
    <span class="n">WordCloud</span><span class="p">()</span>
    <span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">series_name</span><span class="o">=</span><span class="s2">&#34;&#34;</span><span class="p">,</span> <span class="n">data_pair</span><span class="o">=</span><span class="n">wordfreqs</span><span class="p">,</span> <span class="n">word_size_range</span><span class="o">=</span><span class="p">[</span><span class="mi">20</span><span class="p">,</span> <span class="mi">100</span><span class="p">])</span>
    <span class="o">.</span><span class="n">set_global_opts</span><span class="p">(</span>
        <span class="n">title_opts</span><span class="o">=</span><span class="n">opts</span><span class="o">.</span><span class="n">TitleOpts</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s2">&#34;词频分析&#34;</span><span class="p">,</span> <span class="n">title_textstyle_opts</span><span class="o">=</span><span class="n">opts</span><span class="o">.</span><span class="n">TextStyleOpts</span><span class="p">(</span><span class="n">font_size</span><span class="o">=</span><span class="mi">23</span><span class="p">)</span>
        <span class="p">),</span>
        <span class="n">tooltip_opts</span><span class="o">=</span><span class="n">opts</span><span class="o">.</span><span class="n">TooltipOpts</span><span class="p">(</span><span class="n">is_show</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
    <span class="p">)</span>
    <span class="o">.</span><span class="n">render</span><span class="p">(</span><span class="s2">&#34;词云图.html&#34;</span><span class="p">)</span>  <span class="c1">#存储位置</span>
<span class="p">)</span>
</code></pre></div><h3 id="42-柱状图">4.2 柱状图</h3>
<p>绘制柱状图</p>
<p><img loading="lazy" src="img/bar.png" alt=""  />
</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python">
<span class="c1"># </span>
<span class="n">top_n</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">word_count_sorted</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">word_count</span><span class="o">.</span><span class="n">items</span><span class="p">(),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">word_top_n</span> <span class="o">=</span> <span class="n">word_count_sorted</span><span class="p">[:</span><span class="n">top_n</span><span class="p">]</span>

<span class="n">bar</span> <span class="o">=</span> <span class="n">Bar</span><span class="p">()</span>
<span class="n">bar</span><span class="o">.</span><span class="n">add_xaxis</span><span class="p">([</span><span class="n">w</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">word_top_n</span><span class="p">])</span>
<span class="n">bar</span><span class="o">.</span><span class="n">add_yaxis</span><span class="p">(</span><span class="s2">&#34;词频&#34;</span><span class="p">,</span> <span class="p">[</span><span class="n">w</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">word_top_n</span><span class="p">])</span>
<span class="n">bar</span><span class="o">.</span><span class="n">set_global_opts</span><span class="p">(</span><span class="n">title_opts</span><span class="o">=</span><span class="n">opts</span><span class="o">.</span><span class="n">TitleOpts</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s2">&#34;词频统计&#34;</span><span class="p">),</span> <span class="n">xaxis_opts</span><span class="o">=</span><span class="n">opts</span><span class="o">.</span><span class="n">AxisOpts</span><span class="p">(</span><span class="n">axislabel_opts</span><span class="o">=</span><span class="n">opts</span><span class="o">.</span><span class="n">LabelOpts</span><span class="p">(</span><span class="n">rotate</span><span class="o">=-</span><span class="mi">15</span><span class="p">)))</span>
<span class="n">bar</span><span class="o">.</span><span class="n">render</span><span class="p">(</span><span class="s2">&#34;word_count.html&#34;</span><span class="p">)</span>

</code></pre></div><br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://hidadeng.github.io/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://hidadeng.github.io/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://hidadeng.github.io/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>使用虚拟信用卡，国内用户升级为chatGPT plus会员</title>
      <link>https://hidadeng.github.io/blog/2023-02-11-credit_card_for_chatgpt-plus/</link>
      <pubDate>Thu, 09 Feb 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-02-11-credit_card_for_chatgpt-plus/</guid>
      <description>使用虚拟信用卡，国内用户升级为chatGPT plus会员</description>
      <content:encoded><![CDATA[<h2 id="如何chatgpt-plus升级">如何chatGPT plus升级</h2>
<p>可能周围很多朋友已经注册了 chatGPT， 想体验更稳定快速的plus版， 结果升级 chatGPT plus 时发现openAI不支持国内的信用卡。大邓的信用卡是 <strong>中国银行VISA卡</strong>，也不支持。参考了一些网上的教程，可以使用 <strong>虚拟信用卡</strong> 来搞定升级chatGPT plus的任务，耗时10min左右。</p>
<blockquote>
<p>Note:</p>
<p>虚拟信用卡是一种创新的支付工具，为消费者提供更安全、更便捷的网上支付体验。与传统信用卡不同，虚拟信用卡能够提供更多的安全性和便利性，同时还具有更广泛的使用范围。</p>
</blockquote>
<p>大邓用的 <strong>诺贝nobepay</strong> 的虚拟信用卡服务商，我已经充值并开通了一张卡，效果不错。</p>
<br>
<h2 id="诺贝nobepay">诺贝nobepay</h2>
<p>诺贝nobepay的特点如下：</p>
<ul>
<li>支持自定义姓名和地址信息，也可以<strong>一键生成虚拟地址</strong>；</li>
<li>无限开卡，随用随开，不用的卡可以删除，剩余余额将自动返还到账户，可以在下次使用；</li>
<li>费用透明，仅收取开卡费和充值手续费，没有其他隐藏费用；</li>
<li>多功能使用，可以用于日常购物消费，支持绑定美国PayPal，支持阿里云国际绑定，支持Google Play等；</li>
<li>支持人民币充值，只能使用绑定的微信充值，充值速度很快；</li>
<li>支持派安盈、万里汇、空中云汇、银行电汇、ach美元充值；</li>
</ul>
<br>
<h2 id="注册地址">注册地址</h2>
<p><strong>注册地址：<a href="https://nobepay.com/app/login?type=azmzep&amp;code=514DF0">https://nobepay.com</a>，邀请码： 514DF0</strong></p>
<br>
<p><img loading="lazy" src="img/nobe.png" alt=""  />
</p>
<p>注册后，充值前需要进行实名验证，根据提示，使用手机内的浏览器，扫码人脸验证即可。</p>
<br>
<p><strong>注册地址：<a href="https://nobepay.com/app/login?type=azmzep&amp;code=514DF0">https://nobepay.com</a>，邀请码： 514DF0</strong></p>
<br>
<h2 id="充值操作">充值操作</h2>
<p>需要注意，诺贝nobepay 有在线充值、客服充值、USDT充值等几种方式，</p>
<p><img loading="lazy" src="img/money_in.png" alt=""  />
</p>
<p>大邓选的 <strong>在线充值</strong>，最低充值门槛 <strong>500</strong> 元，高于990元，需要找客服代充。</p>
<p><img loading="lazy" src="img/account_cash.png" alt=""  />
</p>
<br>
<h2 id="注意">注意</h2>
<p><strong>nobepay 对于薅羊毛和拒付等不当行为非常重视，一旦发现，立即封号</strong>，不会通知您并退还任何资金。因此，请您在使用诺贝nobepay时遵守相关规则，以确保您的账户安全。</p>
<br>
<h2 id="开卡">开卡</h2>
<p>充值完成后，您就可以开始使用诺贝nobepay的虚拟信用卡了。该平台支持多种虚拟信用卡类型，如果您不确定哪种卡适合您，可以咨询在线客服。</p>
<p>注意，开卡是需要收费的，费用根据所选卡片不同而异，一般在1-5美元之间。充值的最低限额为10美元，部分卡片的最低限额要求为30美元，并需要支付3%的服务费。因此，费用的组成为：开卡费（1-5美元）+充值（最低10美元）+服务费（充值费用的3%）。</p>
<p>开卡时，点击<strong>随机地址</strong> 可以选择生成随机地址，构造出虚拟的姓名和地址。</p>
<p><img loading="lazy" src="img/creadit_card.png" alt=""  />
</p>
<br>
<h2 id="总结">总结</h2>
<p>请注意，</p>
<ul>
<li>
<p>注册诺贝nobepay需要邀请码，并且需要先进行实名认证才能使用该服务。</p>
</li>
<li>
<p>在线充值仅支持微信支付，微信号和实名认证需要保持一致，最低充值金额为500元。</p>
</li>
<li>
<p>诺贝nobepay适合没有实体信用卡但需要进行海淘的用户，或者担心实体信用卡信息泄露的用户。</p>
</li>
<li>
<p>在删除卡片之前，请先解绑该卡片与所有服务商的关联，以避免出现拒付情况。</p>
</li>
</ul>
<p>诺贝nobepay存在一些不足，例如，开通的虚拟卡仅有1年的有效期，并且存在开卡费和服务费。因此，请您在使用诺贝nobepay之前仔细考虑您的需求和消费情况。</p>
<p><strong>注册地址：<a href="https://nobepay.com/app/login?type=azmzep&amp;code=514DF0">https://nobepay.com</a>，邀请码： 514DF0</strong></p>
<br>
<br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://hidadeng.github.io/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://hidadeng.github.io/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://hidadeng.github.io/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>在巨型语言模型时代竞争：OpenAI vs 谷歌</title>
      <link>https://hidadeng.github.io/blog/2023-02-09-openai-vs-google/</link>
      <pubDate>Thu, 09 Feb 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-02-09-openai-vs-google/</guid>
      <description>在未来，巨型语言模型将继续发挥重要作用，并不断推动人工智能的发展。随着技术的不断提高，它们将越来越智能，更加逼近人类语言的表达能力，从而改变人类的生活和工作方式。</description>
      <content:encoded><![CDATA[<h2 id="目录">目录</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">1. 巨型语言模型的诞生
   - OpenAI 和谷歌的研究历史
   - 巨型语言模型的定义与特征
2. OpenAI 与谷歌的研究方向对比
   - OpenAI：强调人工智能的社会责任
   - 谷歌：注重语言模型的应用前景
3. OpenAI 与谷歌的研究成果对比
   - OpenAI 的 GPT 系列模型
   - 谷歌的 Transformer 系列模型
4. 语言模型的应用前景
   - OpenAI 和谷歌的观点对比
   - 语言模型的未来发展趋势
5. 结语
   - 巨型语言模型的影响与未来展望
</code></pre></div><p><br><br></p>
<h2 id="一巨型语言模型的诞生">一、巨型语言模型的诞生</h2>
<h3 id="11-openai-和谷歌的研究历史">1.1 OpenAI 和谷歌的研究历史</h3>
<p>OpenAI 成立于 2015 年，是一家致力于开展人工智能研究并将其应用于改善人类生活的非盈利机构。自成立以来，OpenAI 一直致力于大语言模型的研究与开发。</p>
<p>谷歌的语言模型研究始于 2012 年，当时谷歌的研究团队开始探索使用神经网络进行语言处理的方法。在随后的几年中，谷歌不断完善和提升其语言模型的性能，并成功应用于许多实际场景中。</p>
<p>OpenAI 和谷歌都是语言模型研究的先驱者，它们在巨型语言模型的研究与应用方面都取得了显著的成绩。</p>
<br>
<h3 id="12-巨型语言模型的定义与特征">1.2 巨型语言模型的定义与特征</h3>
<p>巨型语言模型 (GPT) 是一种基于深度学习的语言处理模型，通过训练大量的文本数据，使得模型具备了对人类语言进行理解和生成的能力。</p>
<p>巨型语言模型具有以下特征：</p>
<ul>
<li>能够掌握大量语言知识，如词汇、语法、语义等</li>
<li>具有语言生成能力，能够根据上下文生成合理的语言输出</li>
<li>具有语言理解能力，能够根据输入文本进行语义理解</li>
</ul>
<p>巨型语言模型在各种语言任务上的表现都很优秀，如文本生成、问答、机器翻译等。它们已经成为语言技术领域的一个重要研究方向。</p>
<p><br><br></p>
<h2 id="二-openai-与谷歌的研究方向对比">二、 OpenAI 与谷歌的研究方向对比</h2>
<h3 id="21-openai强调人工智能的社会责任">2.1 OpenAI：强调人工智能的社会责任</h3>
<p>OpenAI 是一家由 Elon Musk, Sam Altman, Greg Brockman, Ilya Sutskever, Wojciech Zaremba, John Schulman 等人创立的人工智能研究机构，总部位于美国加州。OpenAI 强调人工智能的社会责任，致力于研究人工智能领域的前沿技术，同时也关注人工智能的社会影响和道德责任。</p>
<p>OpenAI 关注的领域包括：</p>
<ul>
<li>巨型语言模型</li>
<li>强化学习</li>
<li>机器人</li>
<li>生物信息学</li>
<li>生成对抗网络等</li>
</ul>
<p>OpenAI 发布了多项重要研究成果，如 GPT 系列语言模型、OpenAI Five 强化学习系统等。OpenAI 的研究工作一直得到了全球学术界和业界的高度关注。</p>
<p>OpenAI 的使命是创造安全、有益的人工智能，帮助人类实现更美好的未来。</p>
<br>
<h3 id="22-谷歌注重语言模型的应用前景">2.2 谷歌：注重语言模型的应用前景</h3>
<p>谷歌是全球科技巨头，总部位于美国加州。谷歌在人工智能领域有着丰富的研究经验，并在语言模型方面有着卓越的表现。谷歌强调语言模型的应用前景，致力于将语言模型技术应用到实际生活中，提高人们的工作效率和生活质量。</p>
<p>谷歌在语言模型方面的主要研究内容包括：</p>
<ul>
<li>语音识别</li>
<li>语音合成</li>
<li>智能问答系统</li>
<li>机器翻译等</li>
</ul>
<p>谷歌发布的 BERT 语言模型引领了语言模型的发展，并在多项 NLP 任务中取得了显著的成绩。谷歌还推出了 Google Assistant、Google Translate 等应用，为人们的生活和工作带来了便利。</p>
<p>谷歌致力于通过人工智能技术，帮助人们更好地了解世界，提高工作效率，改善生活质量。</p>
<p><br><br></p>
<h2 id="三openai-与谷歌的研究成果对比">三、OpenAI 与谷歌的研究成果对比</h2>
<h3 id="31-openai-的-gpt-系列模型">3.1 OpenAI 的 GPT 系列模型</h3>
<p>&ldquo;OpenAI 的 GPT 系列模型&rdquo; 包括了 OpenAI 在巨型语言模型领域的研究成果。GPT 指的是 Generative Pretrained Transformer，是一系列基于 Transformer 架构的语言生成模型。</p>
<p>第一代 GPT 模型于 2018 年发布，并在 NLP 研究领域引起了很大的关注。GPT 模型采用了预训练 + 微调的策略，在大量文本数据上预先训练出语言表示，再在特定任务上微调模型以提高其准确性。</p>
<p>后续，OpenAI 不断推出了更高版本的 GPT 模型，如 GPT-2 和 GPT-3，并不断提升了模型的语言生成能力和多样性。GPT-3 是目前世界上最大的语言生成模型，具有卓越的语言理解能力和生成能力，能够完成各种 NLP 任务，如文本生成、翻译等。</p>
<p>总的来说，OpenAI 的 GPT 系列模型为巨型语言模型的研究和应用提供了重要的贡献，也为人工智能的发展提供了新的思路。</p>
<br>
<h3 id="32-谷歌的-transformer-系列模型">3.2 谷歌的 Transformer 系列模型</h3>
<p>谷歌的 Transformer 系列模型是谷歌研究院在语言模型领域的代表性成果。Transformer 模型首次在 2017 年提出，其独特的结构使得其能够解决语言模型中的长依赖问题，从而提高了模型的效果。</p>
<p>随着 Transformer 模型的不断改进，谷歌在这一领域取得了显著的成绩，例如其在 2018 年推出的 BERT 模型，它在 NLP 领域产生了深远的影响，并被广泛应用在文本分类、问答等任务中。此外，谷歌还推出了其他多种 Transformer 模型，如 GPT-3、T5 等，进一步提高了语言模型的效果。</p>
<p>总的来说，谷歌的 Transformer 系列模型是语言模型领域的先驱，其研究成果为 NLP 领域的发展奠定了基础，同时也为谷歌在语言模型领域的竞争力增强奠定了基础。</p>
<p><br><br></p>
<h2 id="四语言模型的应用前景">四、语言模型的应用前景</h2>
<h3 id="41-openai-和谷歌的观点对比">4.1 OpenAI 和谷歌的观点对比</h3>
<p>OpenAI 和谷歌对巨型语言模型的看法有所不同。OpenAI 更注重人工智能技术的社会责任，强调技术应该在促进人类福祉的同时进行研究和开发。因此，OpenAI 一直以来都在努力提高人工智能技术的透明度和可靠性，并对技术的滥用和危害进行监测。</p>
<p>相比之下，谷歌更注重语言模型的应用前景。谷歌认为，巨型语言模型有巨大的商业潜力，可以应用于自然语言处理、机器翻译、搜索引擎优化等领域。因此，谷歌一直以来都在努力提高语言模型的准确性和效率，以便在商业应用中获得更高的竞争力。</p>
<p>总的来说，OpenAI 和谷歌的差异体现在对巨型语言模型的重点不同。OpenAI 更关注人工智能技术的社会责任，而谷歌更关注语言模型的商业应用。</p>
<br>
<h3 id="42-语言模型的未来发展趋势">4.2 语言模型的未来发展趋势</h3>
<p>随着人工智能的快速发展，巨型语言模型的未来发展趋势预计将具有以下几个方面：</p>
<p>多语种支持：巨型语言模型将不再仅仅局限于英语，而是能够支持更多的语言。</p>
<p>更高效的计算：巨型语言模型需要大量的计算资源，但是随着硬件和软件的发展，这些模型将变得更加高效。</p>
<p>更多的应用场景：巨型语言模型的应用将不仅限于聊天机器人，将会扩展到更多领域，如文本生成、翻译、摘要等。</p>
<p>更加逼真的人工智能：巨型语言模型将不断提高，使得人工智能更加逼真，从而带来更加流畅的人机交互体验。</p>
<p>更多的开放数据：随着政府和公司的重视，将有更多的开放数据可供研究者使用，从而提高语言模型的准确性和复杂性。</p>
<p>这些趋势将为巨型语言模型的未来发展带来更多的机会和挑战，并为人工智能的整体发展提供更多的推动力。</p>
<p><br><br></p>
<h2 id="五巨型语言模型的影响与未来展望">五、巨型语言模型的影响与未来展望</h2>
<p>巨型语言模型已经成为人工智能领域最受关注的研究方向之一。它们在语言生成、翻译、问答等方面有着广泛的应用。巨型语言模型对当前社会和未来产生了深远的影响，也激发了新的研究和应用前景。</p>
<p>首先，巨型语言模型的出现改变了人工智能的发展趋势。它们的出色表现使得许多以往难以实现的应用变得可行。此外，巨型语言模型的大规模数据训练和高效推理机制，使得它们在实际应用中有着广泛的前景。</p>
<p>其次，巨型语言模型的出现也引发了关于人工智能的伦理和道德问题的讨论。例如，巨型语言模型可能会模仿人类的语言和行为，对社会和个人造成影响；巨型语言模型的数据来源也存在隐私和安全问题。因此，关于巨型语言模型的研究和应用应该遵循相关的伦理和道德准则。</p>
<p>最后，巨型语言模型的未来发展仍将是人工智能领域的热巨型语言模型已经对人工智能领域产生了巨大的影响，它们已经被用于各种应用场景，如文本生成、机器翻译、对话系统、问答系统等。</p>
<p>然而，随着技术的不断发展，巨型语言模型仍有很多的潜力未能实现。它们的应用范围可以扩展到更多的领域，如医学、法律等。同时，巨型语言模型也需要继续提高它们的准确性和可靠性，避免生成不适当的内容。</p>
<p>在未来，巨型语言模型将继续发挥重要作用，并不断推动人工智能的发展。随着技术的不断提高，它们将越来越智能，更加逼近人类语言的表达能力，从而改变人类的生活和工作方式。</p>
<br>
<br>
<h2 id="广而告之">广而告之</h2>
<ul>
<li><a href="https://hidadeng.github.io/blog/call_for_paper/">长期征稿</a></li>
<li><a href="https://hidadeng.github.io/blog/we_need_you/">长期招募小伙伴</a></li>
<li><a href="https://hidadeng.github.io/blog/management_python_course/">付费视频课 | Python实证指标构建与文本分析</a></li>
</ul>
]]></content:encoded>
    </item>
    
  </channel>
</rss>
