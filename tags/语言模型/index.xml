<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>语言模型 on 大邓和他的PYTHON</title>
    <link>/tags/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/</link>
    <description>Recent content in 语言模型 on 大邓和他的PYTHON</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Fri, 28 Mar 2025 00:00:00 +0000</lastBuildDate><atom:link href="/tags/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>实验 | 使用Stanford Glove代码训练中文语料的Glove模型</title>
      <link>https://textdata.cn/blog/2025-03-28-train_a_glove_model_on_chinese_corpus_using_stanfordnlp/</link>
      <pubDate>Fri, 28 Mar 2025 00:00:00 +0000</pubDate>
      
      <guid>/blog/2025-03-28-train_a_glove_model_on_chinese_corpus_using_stanfordnlp/</guid>
      <description>&lt;h2 id=&#34;一简介&#34;&gt;一、简介&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://nlp.stanford.edu/projects/glove/&#34;&gt;Stanford GloVe&lt;/a&gt;（Global Vectors for Word Representation）算法作为一种融合全局统计信息与局部上下文窗口的词嵌入模型，相较于Word2Vec仅依赖局部上下文，GloVe利用全局统计信息，能更精准地反映词频分布特征。例如，在高维词向量（如200D）中，GloVe在词语类比任务中准确率达75%，并在命名实体识别任务中优于其他词嵌入模型。因其高效的语义表征能力，在社会学、管理学等领域展现出广泛的应用价值。 相关词嵌入文献资料可阅读&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/2023-11-03-organization-science-with-word-embeddings/&#34;&gt;OS2022 | 概念空间 | 词嵌入模型如何为组织科学中的测量和理论提供信息&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/2022-04-07-word-embeddings-in-social-science/&#34;&gt;转载|大数据时代下社会科学研究方法的拓展——基于词嵌入技术的文本分析的应用&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/2023-03-15-39faq-about-word-embeddings-for-social-science/&#34;&gt;词嵌入技术在社会科学领域进行数据挖掘常见39个FAQ汇总&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/2022-04-09-literature-about-embeddings/&#34;&gt;文献汇总 | 词嵌入 与 社会科学中的偏见(态度)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/2022-04-01-embeddings-and-attitude/&#34;&gt;词嵌入测量不同群体对某概念的态度(偏见)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;二环境准备&#34;&gt;二、环境准备&lt;/h2&gt;
&lt;p&gt;cntext2.x 内置了 GloVe 训练所需的环境，支持 win 和 mac。&lt;/p&gt;
&lt;p&gt;获取&lt;a href=&#34;https://textdata.cn/blog/2024-04-27-cntext2x-usage-tutorial/&#34;&gt;cntext2.x&lt;/a&gt; 的安装文件 &lt;em&gt;&lt;strong&gt;cntext-2.1.5-py3-none-any.whl&lt;/strong&gt;&lt;/em&gt;，并将该whl文件放置于桌面。执行以下安装命令&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;cd desktop
pip install cntext-2.1.5-py3-none-any.whl
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;ct&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;GloVe&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;corpus_file&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;lang&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;chinese&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;dict_file&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;None&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;stopwords_file&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;None&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;vector_size&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;100&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;window_size&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;15&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;min_count&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;max_memory&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;4.0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;max_iter&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;15&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x_max&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;corpus_file&lt;/strong&gt;&lt;/em&gt;: 输入语料文件路径（文本格式）。该文件为分词后的语料文件。&lt;/li&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;lang&lt;/strong&gt;&lt;/em&gt;: 语料文件的语言类型，默认为 &amp;lsquo;chinese&amp;rsquo;。&lt;/li&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;dict_file&lt;/strong&gt;&lt;/em&gt;: 自定义词典txt文件路径，默认为None。utf-8编码。&lt;/li&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;stopwords_file&lt;/strong&gt;&lt;/em&gt;: 停用词文件路径，默认为 None。utf-8编码。&lt;/li&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;vector_size&lt;/strong&gt;&lt;/em&gt;: 词向量维度，默认 100。&lt;/li&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;window_size&lt;/strong&gt;&lt;/em&gt;: 上下文窗口大小，默认 15。&lt;/li&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;min_count&lt;/strong&gt;&lt;/em&gt;: 忽略出现次数低于此值的单词，默认 5。&lt;/li&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;max_memory&lt;/strong&gt;&lt;/em&gt;: 可供使用的最大内存大小，单位为GB，默认 4;  该参数越大，训练越快。&lt;/li&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;max_iter&lt;/strong&gt;&lt;/em&gt;: 训练的最大迭代次数，默认 15。&lt;/li&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;x_max&lt;/strong&gt;&lt;/em&gt;: 共现矩阵中元素的最大计数值，默认 10。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;三训练中文glove&#34;&gt;三、训练中文GloVe&lt;/h2&gt;
&lt;p&gt;我们其实只需要设置 &lt;em&gt;&lt;strong&gt;corpus_file&lt;/strong&gt;&lt;/em&gt; 和 &lt;em&gt;&lt;strong&gt;lang&lt;/strong&gt;&lt;/em&gt;， 但为了让大家知道&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;上下文的窗口大小 &lt;em&gt;&lt;strong&gt;window_size&lt;/strong&gt;&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;训练出模型词语的维度数 &lt;em&gt;&lt;strong&gt;vector_size&lt;/strong&gt;&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;cntext&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;ct&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;# 简化版调用。训练window_size=100维， vector_size=15&lt;/span&gt;
&lt;span class=&#34;c1&#34;&gt;# glove_wv = ct.GloVe(corpus_file=&amp;#39;data/三体.txt&amp;#39;, lang=&amp;#39;chinese&amp;#39;)&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;# 正常调用。训练window_size=15维， vector_size=50&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;glove_wv&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ct&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;GloVe&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;corpus_file&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;data/三体.txt&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
                    &lt;span class=&#34;n&#34;&gt;lang&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;chinese&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                    &lt;span class=&#34;n&#34;&gt;vector_size&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;50&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                    &lt;span class=&#34;n&#34;&gt;window_size&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;15&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                    &lt;span class=&#34;n&#34;&gt;only_binary&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;False&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# 同时保存txt和bin两种格式的模型文件&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;glove_wv&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;Mac(Linux) System, Enable Parallel Processing
Cache output/三体_cache.txt Not Found or Empty, Preprocessing Corpus
Start Training GloVe
BUILDING VOCABULARY
Using vocabulary of size 6975.

COUNTING COOCCURRENCES
Merging cooccurrence files: processed 2106999 lines.

Using random seed 1743474106
SHUFFLING COOCCURRENCES
Merging temp files: processed 2106999 lines.

TRAINING MODEL
Read 2106999 lines.
Using random seed 1743474106
04/01/25 - 10:21.46AM, iter: 001, cost: 0.055981
04/01/25 - 10:21.46AM, iter: 002, cost: 0.050632
......
04/01/25 - 10:21.48AM, iter: 014, cost: 0.030047
04/01/25 - 10:21.48AM, iter: 015, cost: 0.029100

GloVe Training Cost 9 s. 
Output Saved To: output/三体-GloVe.50.15.txt
Output Saved To: output/三体-GloVe.50.15.bin
&amp;lt;gensim.models.keyedvectors.KeyedVectors at 0x331517440&amp;gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;img/05-glove.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;h2 id=&#34;四使用中文glove模型&#34;&gt;四、使用中文GloVe模型&lt;/h2&gt;
&lt;h3 id=&#34;41-加载模型&#34;&gt;4.1 加载模型&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;cntext&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;ct&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;# 加载word2vec模型.txt文件&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;wv_model&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ct&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;load_w2v&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;output/三体-GloVe.50.15.bin&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;wv_model&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&amp;lt;gensim.models.keyedvectors.KeyedVectors at 0x336ff8dd0&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h3 id=&#34;42-keyedvectors的操作方法或属性&#34;&gt;4.2 KeyedVectors的操作方法(或属性)&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;方法&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;KeyedVectors.index_to_key&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;获取词汇表中的所有单词。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;KeyedVectors.key_to_index&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;获取单词到索引的映射。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;KeyedVectors.vector_size&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;获取GloVe模型中任意词向量的维度。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;KeyedVectors.get_vector(word)&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;获取给定单词的词向量。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;KeyedVectors.similar_by_word(word, topn=10)&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;获取某词语最相似的10个近义词。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;&lt;strong&gt;KeyedVectors.similar_by_vector(vector, topn=10)&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;获取词向量最相似的10个近义词。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&amp;hellip;&lt;/td&gt;
&lt;td&gt;&amp;hellip;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;421-词表&#34;&gt;4.2.1 词表&lt;/h3&gt;
&lt;br&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;wv_model&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;index_to_key&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;[&amp;#39;的&amp;#39;,
 &amp;#39;了&amp;#39;,
 &amp;#39;在&amp;#39;,
...
 &amp;#39;引力&amp;#39;,
 &amp;#39;所说&amp;#39;,
 &amp;#39;星际&amp;#39;,
 ...]

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h3 id=&#34;422-词表映射&#34;&gt;4.2.2 词表映射&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;wv_model&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;key_to_index&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;{&amp;#39;的&amp;#39;: 0,
 &amp;#39;了&amp;#39;: 1,
 &amp;#39;在&amp;#39;: 2,
...
 &amp;#39;引力&amp;#39;: 997,
 &amp;#39;所说&amp;#39;: 998,
 &amp;#39;星际&amp;#39;: 999,
 ...}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h3 id=&#34;423-向量维度数&#34;&gt;4.2.3 向量维度数&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;sa&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;词表有 &lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv_model&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;key_to_index&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt; 个词&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;sa&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;向量是 &lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv_model&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;vector_size&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt; 维&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;词表有 4365 个词
向量是 50 维
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h3 id=&#34;424-获取词向量&#34;&gt;4.2.4 获取词向量&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 查看「降临」的词向量&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;get_vector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;降临&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;array([ 0.672314,  0.020081,  0.653733,  0.598732, -0.680517, -0.049689,
       -0.16845 , -0.06759 , -0.147955,  0.024006,  0.264551, -0.050127,
        0.252063, -0.475633,  0.103722, -0.012481,  0.040755,  1.154912,
        0.742695,  0.048619, -0.514424, -1.184054,  0.515892, -0.1034  ,
        0.368755, -0.690357, -0.784287, -0.505814,  0.035807, -0.166354,
       -0.26149 ,  0.015089,  0.10626 , -0.215666, -0.374001, -0.123558,
        0.422617, -0.075277, -0.316387, -0.484295,  0.059687,  0.132621,
        0.192094, -0.591919,  0.236281,  0.164198, -0.058724,  1.285457,
        0.905606, -0.52032 ], dtype=float32)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h3 id=&#34;425-近义词&#34;&gt;4.2.5 近义词&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;similar_by_word&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;三体&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;topn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;[(&amp;#39;叛军&amp;#39;, 0.7699569463729858),
 (&amp;#39;更新&amp;#39;, 0.7687217593193054),
 (&amp;#39;地球&amp;#39;, 0.760529100894928),
 (&amp;#39;全集&amp;#39;, 0.7575182914733887),
 (&amp;#39;最快&amp;#39;, 0.7426372170448303),
 (&amp;#39;世界&amp;#39;, 0.7262137532234192),
 (&amp;#39;最新&amp;#39;, 0.7219281792640686),
 (&amp;#39;游戏&amp;#39;, 0.7180070877075195),
 (&amp;#39;危机&amp;#39;, 0.7020451426506042),
 (&amp;#39;教&amp;#39;, 0.7012627720832825)]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;h3 id=&#34;426-计算多个词的中心向量&#34;&gt;4.2.6 计算多个词的中心向量&lt;/h3&gt;
&lt;p&gt;我们可以计算「三体」、「降临」、「组织」、「拯救」的中心向量eto_vector。 并试图寻找中心向量eto_vector的最相似的10个词。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;eto_vector&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ct&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;semantic_centroid&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;words&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;三体&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;降临&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;组织&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;拯救&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;

&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;eto_vector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;c1&#34;&gt;# 寻找 eto_vector 语义最相似的10个词&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;wv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;similar_by_vector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;eto_vector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;topn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;[ 0.6267875   0.08975425  0.48438451  0.405128   -0.49928901  0.11347825
 -0.90057975  0.11877625 -0.27053049  0.344603    0.4368495  -0.3839495
  0.02633176 -0.138534    0.2531555  -0.0060905  -0.48776849  0.75548999
  0.72575876 -0.446079   -0.30361701 -1.039792    0.457687   -0.4286315
  0.44577325 -0.39119426 -0.4783935  -0.2596135  -0.32513325 -0.10315975
 -0.42880575 -0.48328425  0.129438   -0.17085625 -0.13454625 -0.070053
  0.68060375  0.16736924 -0.15664874 -0.20528575  0.385481    0.206432
  0.18913225 -0.93453825  0.58597099  0.60727924  0.009064    0.87661726
  0.65814423 -0.356567  ]

[(&amp;#39;降临&amp;#39;, 0.8707027435302734),
 (&amp;#39;组织&amp;#39;, 0.8625670671463013),
 (&amp;#39;三体&amp;#39;, 0.8621653914451599),
 (&amp;#39;派&amp;#39;, 0.8343338966369629),
 (&amp;#39;拯救&amp;#39;, 0.8301094174385071),
 (&amp;#39;叛军&amp;#39;, 0.784512460231781),
 (&amp;#39;地球&amp;#39;, 0.7536635398864746),
 (&amp;#39;世界&amp;#39;, 0.7245718836784363),
 (&amp;#39;外部&amp;#39;, 0.7078365087509155),
 (&amp;#39;入侵&amp;#39;, 0.6962169408798218)]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br&gt;
&lt;p&gt;熟悉三体的朋友应该能联想到背叛人类的ETO(地球三体组织)有两个派别，分别是拯救派和降临派。&lt;/p&gt;
&lt;p&gt;ETO开发了一款虚拟现实游戏，它向参与者展示了三体世界的真实情况，包括其恶劣的自然条件、三体文明的历史及其科技水平等。通过参与这个游戏，玩家们能够逐渐了解三体世界的真相，并最终决定是否要加入到支持三体文明入侵地球的行列中来。&lt;/p&gt;
&lt;p&gt;这个游戏不仅充当了信息传递的媒介，也是甄别志同道合者的工具，让那些对人类社会现状不满、渴望变革的人们找到了组织，进而成为了背叛人类的叛军一员。在这个过程中，“三体游戏”起到了关键的作用，是连接地球人与三体世界的重要桥梁。&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;相关内容&#34;&gt;相关内容&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://cntext.readthedocs.io/&#34;&gt;文本分析库cntext使用手册 https://cntext.readthedocs.io/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/2023-12-28-train-word2vec-using-renmin-gov-leader-board-dataset/&#34;&gt;词向量 | 使用人民网领导留言板语料训练Word2Vec模型&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/2023-11-20-word2vec-by-year-by-province/&#34;&gt;使用 5000w 专利申请数据集按年份(按省份)训练词向量&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/2024-04-16-douban-movie-1000w-ratings-comments-dataset/&#34;&gt;使用 1000w 条豆瓣影评训练 Word2Vec&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/2023-03-15-39faq-about-word-embeddings-for-social-science/&#34;&gt;词嵌入技术在社会科学领域进行数据挖掘常见39个FAQ汇总&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/2022-04-07-word-embeddings-in-social-science/&#34;&gt;转载|大数据时代下社会科学研究方法的拓展——基于词嵌入技术的文本分析的应用&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://textdata.cn/blog/2023-11-03-organization-science-with-word-embeddings/&#34;&gt;OS2022 | 概念空间 | 词嵌入模型如何为组织科学中的测量和理论提供信息&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
      <content:encoded><![CDATA[<h2 id="一简介">一、简介</h2>
<p><a href="https://nlp.stanford.edu/projects/glove/">Stanford GloVe</a>（Global Vectors for Word Representation）算法作为一种融合全局统计信息与局部上下文窗口的词嵌入模型，相较于Word2Vec仅依赖局部上下文，GloVe利用全局统计信息，能更精准地反映词频分布特征。例如，在高维词向量（如200D）中，GloVe在词语类比任务中准确率达75%，并在命名实体识别任务中优于其他词嵌入模型。因其高效的语义表征能力，在社会学、管理学等领域展现出广泛的应用价值。 相关词嵌入文献资料可阅读</p>
<ul>
<li><a href="https://textdata.cn/blog/2023-11-03-organization-science-with-word-embeddings/">OS2022 | 概念空间 | 词嵌入模型如何为组织科学中的测量和理论提供信息</a></li>
<li><a href="https://textdata.cn/blog/2022-04-07-word-embeddings-in-social-science/">转载|大数据时代下社会科学研究方法的拓展——基于词嵌入技术的文本分析的应用</a></li>
<li><a href="https://textdata.cn/blog/2023-03-15-39faq-about-word-embeddings-for-social-science/">词嵌入技术在社会科学领域进行数据挖掘常见39个FAQ汇总</a></li>
<li><a href="https://textdata.cn/blog/2022-04-09-literature-about-embeddings/">文献汇总 | 词嵌入 与 社会科学中的偏见(态度)</a></li>
<li><a href="https://textdata.cn/blog/2022-04-01-embeddings-and-attitude/">词嵌入测量不同群体对某概念的态度(偏见)</a></li>
</ul>
<p><br><br></p>
<h2 id="二环境准备">二、环境准备</h2>
<p>cntext2.x 内置了 GloVe 训练所需的环境，支持 win 和 mac。</p>
<p>获取<a href="https://textdata.cn/blog/2024-04-27-cntext2x-usage-tutorial/">cntext2.x</a> 的安装文件 <em><strong>cntext-2.1.5-py3-none-any.whl</strong></em>，并将该whl文件放置于桌面。执行以下安装命令</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">cd desktop
pip install cntext-2.1.5-py3-none-any.whl
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">ct</span><span class="o">.</span><span class="n">GloVe</span><span class="p">(</span><span class="n">corpus_file</span><span class="p">,</span> <span class="n">lang</span><span class="o">=</span><span class="s1">&#39;chinese&#39;</span><span class="p">,</span> <span class="n">dict_file</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">stopwords_file</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vector_size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">window_size</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">min_count</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">max_memory</span><span class="o">=</span><span class="mf">4.0</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">x_max</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</code></pre></div><ul>
<li><em><strong>corpus_file</strong></em>: 输入语料文件路径（文本格式）。该文件为分词后的语料文件。</li>
<li><em><strong>lang</strong></em>: 语料文件的语言类型，默认为 &lsquo;chinese&rsquo;。</li>
<li><em><strong>dict_file</strong></em>: 自定义词典txt文件路径，默认为None。utf-8编码。</li>
<li><em><strong>stopwords_file</strong></em>: 停用词文件路径，默认为 None。utf-8编码。</li>
<li><em><strong>vector_size</strong></em>: 词向量维度，默认 100。</li>
<li><em><strong>window_size</strong></em>: 上下文窗口大小，默认 15。</li>
<li><em><strong>min_count</strong></em>: 忽略出现次数低于此值的单词，默认 5。</li>
<li><em><strong>max_memory</strong></em>: 可供使用的最大内存大小，单位为GB，默认 4;  该参数越大，训练越快。</li>
<li><em><strong>max_iter</strong></em>: 训练的最大迭代次数，默认 15。</li>
<li><em><strong>x_max</strong></em>: 共现矩阵中元素的最大计数值，默认 10。</li>
</ul>
<p><br><br></p>
<h2 id="三训练中文glove">三、训练中文GloVe</h2>
<p>我们其实只需要设置 <em><strong>corpus_file</strong></em> 和 <em><strong>lang</strong></em>， 但为了让大家知道</p>
<ul>
<li>上下文的窗口大小 <em><strong>window_size</strong></em></li>
<li>训练出模型词语的维度数 <em><strong>vector_size</strong></em></li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>

<span class="c1"># 简化版调用。训练window_size=100维， vector_size=15</span>
<span class="c1"># glove_wv = ct.GloVe(corpus_file=&#39;data/三体.txt&#39;, lang=&#39;chinese&#39;)</span>

<span class="c1"># 正常调用。训练window_size=15维， vector_size=50</span>
<span class="n">glove_wv</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">GloVe</span><span class="p">(</span><span class="n">corpus_file</span><span class="o">=</span><span class="s1">&#39;data/三体.txt&#39;</span><span class="p">,</span> 
                    <span class="n">lang</span><span class="o">=</span><span class="s1">&#39;chinese&#39;</span><span class="p">,</span>
                    <span class="n">vector_size</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
                    <span class="n">window_size</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span>
                    <span class="n">only_binary</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="c1"># 同时保存txt和bin两种格式的模型文件</span>

<span class="n">glove_wv</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">Mac(Linux) System, Enable Parallel Processing
Cache output/三体_cache.txt Not Found or Empty, Preprocessing Corpus
Start Training GloVe
BUILDING VOCABULARY
Using vocabulary of size 6975.

COUNTING COOCCURRENCES
Merging cooccurrence files: processed 2106999 lines.

Using random seed 1743474106
SHUFFLING COOCCURRENCES
Merging temp files: processed 2106999 lines.

TRAINING MODEL
Read 2106999 lines.
Using random seed 1743474106
04/01/25 - 10:21.46AM, iter: 001, cost: 0.055981
04/01/25 - 10:21.46AM, iter: 002, cost: 0.050632
......
04/01/25 - 10:21.48AM, iter: 014, cost: 0.030047
04/01/25 - 10:21.48AM, iter: 015, cost: 0.029100

GloVe Training Cost 9 s. 
Output Saved To: output/三体-GloVe.50.15.txt
Output Saved To: output/三体-GloVe.50.15.bin
&lt;gensim.models.keyedvectors.KeyedVectors at 0x331517440&gt;

</code></pre></div><p><img loading="lazy" src="img/05-glove.png" alt=""  />
</p>
<br>
<h2 id="四使用中文glove模型">四、使用中文GloVe模型</h2>
<h3 id="41-加载模型">4.1 加载模型</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cntext</span> <span class="k">as</span> <span class="nn">ct</span>

<span class="c1"># 加载word2vec模型.txt文件</span>
<span class="n">wv_model</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">load_w2v</span><span class="p">(</span><span class="s1">&#39;output/三体-GloVe.50.15.bin&#39;</span><span class="p">)</span>
<span class="n">wv_model</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">&lt;gensim.models.keyedvectors.KeyedVectors at 0x336ff8dd0&gt;
</code></pre></div><br>
<h3 id="42-keyedvectors的操作方法或属性">4.2 KeyedVectors的操作方法(或属性)</h3>
<table>
<thead>
<tr>
<th>方法</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td><em><strong>KeyedVectors.index_to_key</strong></em></td>
<td>获取词汇表中的所有单词。</td>
</tr>
<tr>
<td><em><strong>KeyedVectors.key_to_index</strong></em></td>
<td>获取单词到索引的映射。</td>
</tr>
<tr>
<td><em><strong>KeyedVectors.vector_size</strong></em></td>
<td>获取GloVe模型中任意词向量的维度。</td>
</tr>
<tr>
<td><em><strong>KeyedVectors.get_vector(word)</strong></em></td>
<td>获取给定单词的词向量。</td>
</tr>
<tr>
<td><em><strong>KeyedVectors.similar_by_word(word, topn=10)</strong></em></td>
<td>获取某词语最相似的10个近义词。</td>
</tr>
<tr>
<td><em><strong>KeyedVectors.similar_by_vector(vector, topn=10)</strong></em></td>
<td>获取词向量最相似的10个近义词。</td>
</tr>
<tr>
<td>&hellip;</td>
<td>&hellip;</td>
</tr>
</tbody>
</table>
<h3 id="421-词表">4.2.1 词表</h3>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">wv_model</span><span class="o">.</span><span class="n">index_to_key</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">[&#39;的&#39;,
 &#39;了&#39;,
 &#39;在&#39;,
...
 &#39;引力&#39;,
 &#39;所说&#39;,
 &#39;星际&#39;,
 ...]

</code></pre></div><br>
<h3 id="422-词表映射">4.2.2 词表映射</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">wv_model</span><span class="o">.</span><span class="n">key_to_index</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">{&#39;的&#39;: 0,
 &#39;了&#39;: 1,
 &#39;在&#39;: 2,
...
 &#39;引力&#39;: 997,
 &#39;所说&#39;: 998,
 &#39;星际&#39;: 999,
 ...}
</code></pre></div><br>
<h3 id="423-向量维度数">4.2.3 向量维度数</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;词表有 </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">wv_model</span><span class="o">.</span><span class="n">key_to_index</span><span class="p">)</span><span class="si">}</span><span class="s1"> 个词&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;向量是 </span><span class="si">{</span><span class="n">wv_model</span><span class="o">.</span><span class="n">vector_size</span><span class="si">}</span><span class="s1"> 维&#39;</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">词表有 4365 个词
向量是 50 维
</code></pre></div><br>
<h3 id="424-获取词向量">4.2.4 获取词向量</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1"># 查看「降临」的词向量</span>
<span class="n">wv</span><span class="o">.</span><span class="n">get_vector</span><span class="p">(</span><span class="s1">&#39;降临&#39;</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">array([ 0.672314,  0.020081,  0.653733,  0.598732, -0.680517, -0.049689,
       -0.16845 , -0.06759 , -0.147955,  0.024006,  0.264551, -0.050127,
        0.252063, -0.475633,  0.103722, -0.012481,  0.040755,  1.154912,
        0.742695,  0.048619, -0.514424, -1.184054,  0.515892, -0.1034  ,
        0.368755, -0.690357, -0.784287, -0.505814,  0.035807, -0.166354,
       -0.26149 ,  0.015089,  0.10626 , -0.215666, -0.374001, -0.123558,
        0.422617, -0.075277, -0.316387, -0.484295,  0.059687,  0.132621,
        0.192094, -0.591919,  0.236281,  0.164198, -0.058724,  1.285457,
        0.905606, -0.52032 ], dtype=float32)
</code></pre></div><br>
<h3 id="425-近义词">4.2.5 近义词</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">wv</span><span class="o">.</span><span class="n">similar_by_word</span><span class="p">(</span><span class="s1">&#39;三体&#39;</span><span class="p">,</span> <span class="n">topn</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">[(&#39;叛军&#39;, 0.7699569463729858),
 (&#39;更新&#39;, 0.7687217593193054),
 (&#39;地球&#39;, 0.760529100894928),
 (&#39;全集&#39;, 0.7575182914733887),
 (&#39;最快&#39;, 0.7426372170448303),
 (&#39;世界&#39;, 0.7262137532234192),
 (&#39;最新&#39;, 0.7219281792640686),
 (&#39;游戏&#39;, 0.7180070877075195),
 (&#39;危机&#39;, 0.7020451426506042),
 (&#39;教&#39;, 0.7012627720832825)]
</code></pre></div><br>
<h3 id="426-计算多个词的中心向量">4.2.6 计算多个词的中心向量</h3>
<p>我们可以计算「三体」、「降临」、「组织」、「拯救」的中心向量eto_vector。 并试图寻找中心向量eto_vector的最相似的10个词。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">eto_vector</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">semantic_centroid</span><span class="p">(</span><span class="n">wv</span><span class="o">=</span><span class="n">wv</span><span class="p">,</span> <span class="n">words</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;三体&#39;</span><span class="p">,</span> <span class="s1">&#39;降临&#39;</span><span class="p">,</span> <span class="s1">&#39;组织&#39;</span><span class="p">,</span> <span class="s1">&#39;拯救&#39;</span><span class="p">])</span>

<span class="nb">print</span><span class="p">(</span><span class="n">eto_vector</span><span class="p">)</span>
<span class="c1"># 寻找 eto_vector 语义最相似的10个词</span>
<span class="n">wv</span><span class="o">.</span><span class="n">similar_by_vector</span><span class="p">(</span><span class="n">eto_vector</span><span class="p">,</span> <span class="n">topn</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">[ 0.6267875   0.08975425  0.48438451  0.405128   -0.49928901  0.11347825
 -0.90057975  0.11877625 -0.27053049  0.344603    0.4368495  -0.3839495
  0.02633176 -0.138534    0.2531555  -0.0060905  -0.48776849  0.75548999
  0.72575876 -0.446079   -0.30361701 -1.039792    0.457687   -0.4286315
  0.44577325 -0.39119426 -0.4783935  -0.2596135  -0.32513325 -0.10315975
 -0.42880575 -0.48328425  0.129438   -0.17085625 -0.13454625 -0.070053
  0.68060375  0.16736924 -0.15664874 -0.20528575  0.385481    0.206432
  0.18913225 -0.93453825  0.58597099  0.60727924  0.009064    0.87661726
  0.65814423 -0.356567  ]

[(&#39;降临&#39;, 0.8707027435302734),
 (&#39;组织&#39;, 0.8625670671463013),
 (&#39;三体&#39;, 0.8621653914451599),
 (&#39;派&#39;, 0.8343338966369629),
 (&#39;拯救&#39;, 0.8301094174385071),
 (&#39;叛军&#39;, 0.784512460231781),
 (&#39;地球&#39;, 0.7536635398864746),
 (&#39;世界&#39;, 0.7245718836784363),
 (&#39;外部&#39;, 0.7078365087509155),
 (&#39;入侵&#39;, 0.6962169408798218)]
</code></pre></div><br>
<p>熟悉三体的朋友应该能联想到背叛人类的ETO(地球三体组织)有两个派别，分别是拯救派和降临派。</p>
<p>ETO开发了一款虚拟现实游戏，它向参与者展示了三体世界的真实情况，包括其恶劣的自然条件、三体文明的历史及其科技水平等。通过参与这个游戏，玩家们能够逐渐了解三体世界的真相，并最终决定是否要加入到支持三体文明入侵地球的行列中来。</p>
<p>这个游戏不仅充当了信息传递的媒介，也是甄别志同道合者的工具，让那些对人类社会现状不满、渴望变革的人们找到了组织，进而成为了背叛人类的叛军一员。在这个过程中，“三体游戏”起到了关键的作用，是连接地球人与三体世界的重要桥梁。</p>
<p><br><br></p>
<h2 id="相关内容">相关内容</h2>
<ul>
<li><a href="https://cntext.readthedocs.io/">文本分析库cntext使用手册 https://cntext.readthedocs.io/</a></li>
<li><a href="https://textdata.cn/blog/2023-12-28-train-word2vec-using-renmin-gov-leader-board-dataset/">词向量 | 使用人民网领导留言板语料训练Word2Vec模型</a></li>
<li><a href="https://textdata.cn/blog/2023-11-20-word2vec-by-year-by-province/">使用 5000w 专利申请数据集按年份(按省份)训练词向量</a></li>
<li><a href="https://textdata.cn/blog/2024-04-16-douban-movie-1000w-ratings-comments-dataset/">使用 1000w 条豆瓣影评训练 Word2Vec</a></li>
<li><a href="https://textdata.cn/blog/2023-03-15-39faq-about-word-embeddings-for-social-science/">词嵌入技术在社会科学领域进行数据挖掘常见39个FAQ汇总</a></li>
<li><a href="https://textdata.cn/blog/2022-04-07-word-embeddings-in-social-science/">转载|大数据时代下社会科学研究方法的拓展——基于词嵌入技术的文本分析的应用</a></li>
<li><a href="https://textdata.cn/blog/2023-11-03-organization-science-with-word-embeddings/">OS2022 | 概念空间 | 词嵌入模型如何为组织科学中的测量和理论提供信息</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>可视化 | 词嵌入模型用于计算社科领域刻板印象等信息（含代码）</title>
      <link>https://textdata.cn/blog/2023-03-03-extracts-cognitive-information-and-visualization-with-embedings/</link>
      <pubDate>Fri, 03 Mar 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-03-03-extracts-cognitive-information-and-visualization-with-embedings/</guid>
      <description>语言的文字反映了人类思想的结构，使我们能够在个人之间传递思想， 而使用大规模语料训练得来的词嵌入模型蕴含着这类信息。 英文的词嵌入在社会科学中的应用教程较多，大家可以谷歌查询，我主要想丰富中文数据的教程。The words of language reflect the structure of human thought, allowing us to transfer thoughts between individuals, and word embedding models trained using large-scale corpora contain this information. There are many application tutorials of English word embedding in social science. You can search it on Google. I mainly want to enrich the tutorials of Chinese data.</description>
      <content:encoded><![CDATA[<iframe
    src="//player.bilibili.com/player.html?bvid=BV1CY4y11712&page=1"
    scrolling="no"
    height="500px"
    width="800px"
    frameborder="no"
    framespacing="0"
    allowfullscreen="true"
>
</iframe>

<br>
<p>语言的文字反映了人类思想的结构，使我们能够在个人之间传递思想， 而使用大规模语料训练得来的词嵌入模型往往蕴含着这类信息。</p>
<br>
<h3 id="11-国内外社科方面的应用">1.1 国内外社科方面的应用</h3>
<p><strong>在国内社科领域， 应用词嵌入 主要用来做情感分析</strong>，大致的算法(思路)是</p>
<ol>
<li>训练词向量模型</li>
<li>根据词向量cosine或欧几里得距离，度量词语的相似性，进而扩展某种概念词典</li>
<li>检查扩充的概念词典，剔除无效词后。</li>
<li>使用整理好的概念词典，统计文本中出现该概念的词频，当做该概念的代理指标。</li>
</ol>
<p>但词嵌入在国外社科领域， 不用传统方法，使用文本数据，也能做出 **刻板印象、性别种族歧视、词语百年来语义变迁、女性高管就职后公司内性别观念变化、测量创新力(发散思维)**等议题的实证研究。</p>
<p>下图是「阶级财富性别与运动」，摘自2019年文化几何学这篇论文。</p>
<p><img loading="lazy" src="img/sport_class_fortune.png" alt=""  />
</p>
<blockquote>
<p>Kozlowski, Austin C., Matt Taddy, and James A. Evans. &ldquo;The geometry of culture: Analyzing the meanings of class through word embeddings.&rdquo; American Sociological Review 84, no. 5 (2019): 905-949.</p>
</blockquote>
<p>本文主要内容是实现这类文化几何学图的中文可视化。</p>
<br>
<h3 id="12-之前分享过的资料">1.2 之前分享过的资料</h3>
<p>之前大邓分享过的词嵌入稍有涉及，感兴趣的可以阅读我之前分享的文章</p>
<ul>
<li><a href="https://textdata.cn/blog/douban_w2v/">豆瓣影评 | 探索词向量妙处</a></li>
<li><a href="https://textdata.cn/blog/2022-10-16-python-word-mover-s-distance/">Python | 词移距离(Word Mover’s Distance)</a></li>
<li><a href="https://textdata.cn/blog/wordbias/">WordBias库 | 发现偏见(刻板印象)的交互式工具</a></li>
<li><a href="https://textdata.cn/blog/embeddingsandattitude/">词嵌入测量不同群体对某概念的态度(偏见)</a></li>
<li><a href="https://textdata.cn/blog/whatlies_word2vec/">whatlies库 | 可视化词向量</a></li>
<li><a href="https://textdata.cn/blog//2022-11-14-pnas_naming_unrelated_words_predicts_creativity/">PNAS | 使用语义距离测量一个人的创新力(发散思维)得分</a></li>
<li><a href="https://textdata.cn/blog/embeddings_resource_usage_method/">中文词向量资源汇总 &amp; 使用方法</a></li>
<li><a href="https://textdata.cn/blog/2023-03-15-39faq-about-word-embeddings-for-social-science/">词嵌入技术在社会科学领域进行数据挖掘常见39个FAQ汇总</a></li>
<li><a href="https://textdata.cn/blog/wordembeddingsinsocialscience/">转载 | 大数据时代下社会科学研究方法的拓展——基于词嵌入技术的文本分析的应用</a></li>
</ul>
<br>
<p>但可视化分享的不多，<strong>本文将用公开的中文预训练模型，验证可视化中文圈的群体记忆、刻板印象、偏见等信息</strong>。在此先放一张论文中两个截图， <strong>语义概念向量</strong> 一般是由语义相反的两组词构成。</p>
<p><img loading="lazy" src="img/size.png" alt=""  />

<img loading="lazy" src="img/%e4%ba%8c%e5%85%83%e6%a6%82%e5%bf%b5%e7%bb%84.png" alt=""  />
</p>
<blockquote>
<p>Grand, G., Blank, I.A., Pereira, F. and Fedorenko, E., 2022. <strong>Semantic projection recovers rich human knowledge of multiple object features from word embeddings</strong>. <em>Nature Human Behaviour</em>, pp.1-13.</p>
</blockquote>
<br>
<h3 id="概念向量的计算方法">概念向量的计算方法</h3>
<ul>
<li>二维坐标系下，点和向量都可以用二维数组(m, n)表示。同理，在n维空间中，点和向量都是n维数组。</li>
<li>将多个近义的词向量， 通过平均法创建出一个 <strong>均值端点</strong>。</li>
<li>语义完全相反的两个<strong>均值端点</strong>， 通过减法操作， 得到 <strong>概念向量</strong></li>
</ul>
<br>
<h3 id="为啥每个端点向量用多个词计算">为啥每个端点向量用多个词计算？</h3>
<p>单个词变动较大， 为了保证语义的稳定性，最好是找一组词构成概念的一个端点。</p>
<p><br><br></p>
<h2 id="二准备工作">二、准备工作</h2>
<p>下载预训练模型，可以查看这篇文章获取</p>
<p><a href="https://textdata.cn/blog/embeddings_resource_usage_method/">中文词向量资源汇总 &amp; 使用方法</a></p>
<p>之后安装好本节需要的python包</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="err">!</span><span class="n">pip3</span> <span class="n">install</span> <span class="n">whatlies</span><span class="o">==</span><span class="mf">0.7.0</span>
<span class="err">!</span><span class="n">pip3</span> <span class="n">install</span> <span class="n">matplotlib_inline</span>
<span class="err">!</span><span class="n">pip3</span> <span class="n">install</span> <span class="n">gensim</span><span class="o">==</span><span class="mf">4.2.0</span>
</code></pre></div><p><br><br></p>
<h2 id="三导入预训练模型">三、导入预训练模型</h2>
<p>使用 gensim 库导入预训练模型，这里我本地保留的是预训练模型是word2vec中的sgns算法训练出来的。 导入后的数据是 KeyedVectors 类型的数据。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">gensim.models.keyedvectors</span> <span class="kn">import</span> <span class="n">KeyedVectors</span>

<span class="c1"># 微博 sgns.weibo.word.bz2 为例  </span>
<span class="n">weibo_wv</span> <span class="o">=</span> <span class="n">KeyedVectors</span><span class="o">.</span><span class="n">load_word2vec_format</span><span class="p">(</span><span class="s1">&#39;embeddings/sgns.weibo.word.bz2&#39;</span><span class="p">,</span> 
                                             <span class="n">binary</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> 
                                             <span class="n">unicode_errors</span><span class="o">=</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>

<span class="c1"># 知乎 sgns.renmin.word.bz2</span>
<span class="n">zhihu_wv</span> <span class="o">=</span> <span class="n">KeyedVectors</span><span class="o">.</span><span class="n">load_word2vec_format</span><span class="p">(</span><span class="s1">&#39;embeddings/sgns.zhihu.word.bz2&#39;</span><span class="p">,</span> 
                                              <span class="n">binary</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> 
                                              <span class="n">unicode_errors</span><span class="o">=</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>

<span class="c1"># 中文维基 </span>
<span class="n">wiki_wv</span> <span class="o">=</span> <span class="n">KeyedVectors</span><span class="o">.</span><span class="n">load_word2vec_format</span><span class="p">(</span><span class="s1">&#39;embeddings/sgns.wiki.word.bz2&#39;</span><span class="p">,</span> 
                                              <span class="n">binary</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> 
                                              <span class="n">unicode_errors</span><span class="o">=</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>
</code></pre></div><br>
<h3 id="31-预训练模型的词汇量">3.1 预训练模型的词汇量</h3>
<p>weibo_wv、zhihu_wv、wiki_wv是KeyedVectors类型的数据，可以直接查看词汇量</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;预训练模型词汇量&#39;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;微博: &#39;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">weibo_wv</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;知乎: &#39;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">zhihu_wv</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;中文维基: &#39;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">wiki_wv</span><span class="p">))</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">预训练模型词汇量

微博:  195202
知乎:  259949
中文维基:  352277
</code></pre></div><br>
<h3 id="32-通用词">3.2 通用词</h3>
<p>使用不同数据集训练，得到的语言模型所含词语会有差异。这里我们查看通用词一共有多少</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">wiki_vocab</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">wiki_wv</span><span class="o">.</span><span class="n">index_to_key</span><span class="p">)</span>
<span class="n">zhihu_vocab</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">zhihu_wv</span><span class="o">.</span><span class="n">index_to_key</span><span class="p">)</span>
<span class="n">weibo_vocab</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">weibo_wv</span><span class="o">.</span><span class="n">index_to_key</span><span class="p">)</span>

<span class="c1">#交集</span>
<span class="n">common_vocab</span> <span class="o">=</span> <span class="n">wiki_vocab</span> <span class="o">&amp;</span> <span class="n">zhihu_vocab</span> <span class="o">&amp;</span>  <span class="n">weibo_vocab</span><span class="c1"># intersection</span>

<span class="nb">len</span><span class="p">(</span><span class="n">common_vocab</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">118539
</code></pre></div><br>
<h3 id="33-提取某个词的向量">3.3 提取某个词的向量</h3>
<p>以维基百科为例， 查看「幸福」的词向量</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#只显示向量的前20个数字</span>
<span class="n">wiki_wv</span><span class="p">[</span><span class="s1">&#39;幸福&#39;</span><span class="p">][:</span><span class="mi">20</span><span class="p">]</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">array([ 0.159344,  0.280468, -0.236876, -0.198076, -0.170838,  0.027264,
           -0.349646,  0.289169, -0.421038, -0.470539,  0.247534,  0.112968,
            0.355498,  0.479956,  0.093291,  0.081054, -0.046995, -0.624586,
            0.568242,  0.16665 ], dtype=float32)
</code></pre></div><br>
<h3 id="34-查看词向量的维度">3.4 查看词向量的维度</h3>
<p>查看向量的长度（维度），以「幸福」为例</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;预训练模型维度数&#39;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;微博: &#39;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">weibo_wv</span><span class="p">[</span><span class="s2">&#34;幸福&#34;</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;知乎: &#39;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">zhihu_wv</span><span class="p">[</span><span class="s2">&#34;幸福&#34;</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;中文维基: &#39;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">wiki_wv</span><span class="p">[</span><span class="s2">&#34;幸福&#34;</span><span class="p">]))</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">预训练模型维度数
微博:  300
知乎:  300
中文维基:  300
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#单个词向量的尺寸</span>
<span class="n">wiki_wv</span><span class="p">[</span><span class="s1">&#39;幸福&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">(300,)
</code></pre></div><br>
<h3 id="35-计算多个词向量的均值向量">3.5 计算多个词向量的均值向量</h3>
<p>先看一下多个词提取后得到的数据形状</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">wiki_wv</span><span class="p">[[</span><span class="s1">&#39;男&#39;</span><span class="p">,</span> <span class="s1">&#39;男孩&#39;</span><span class="p">,</span> <span class="s1">&#39;父亲&#39;</span><span class="p">,</span> <span class="s1">&#39;爷爷&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">shape</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">(4, 300)
</code></pre></div><br>
<p>4个词，每个词都是300维的词向量。如果计算4个词向量的均值向量，返回的尺寸应该是 (300,)</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">male_vector</span> <span class="o">=</span> <span class="n">wiki_wv</span><span class="p">[[</span><span class="s1">&#39;男&#39;</span><span class="p">,</span> <span class="s1">&#39;男孩&#39;</span><span class="p">,</span> <span class="s1">&#39;父亲&#39;</span><span class="p">,</span> <span class="s1">&#39;爷爷&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">male_vector</span><span class="o">.</span><span class="n">shape</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">(300,)
</code></pre></div><br>
<h3 id="36-最相似的词">3.6 最相似的词</h3>
<p>网上的教程经常分享最相似的词，这里我们也实验一下。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">wiki_wv</span><span class="o">.</span><span class="n">most_similar</span><span class="p">(</span><span class="s2">&#34;社会&#34;</span><span class="p">,</span> <span class="n">topn</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">[(&#39;于社会&#39;, 0.6210986971855164),
(&#39;社会上&#39;, 0.5995474457740784),
(&#39;社会关系&#39;, 0.5894029140472412),
(&#39;各阶层&#39;, 0.5799717903137207),
(&#39;社会制度&#39;, 0.5777087211608887),
(&#39;社会变迁&#39;, 0.5756841897964478),
(&#39;令社会&#39;, 0.575627326965332),
(&#39;社会变革&#39;, 0.5755838751792908),
(&#39;思想观念&#39;, 0.5752044916152954),
(&#39;社会存在&#39;, 0.573627769947052)]
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">weibo_wv</span><span class="o">.</span><span class="n">most_similar</span><span class="p">(</span><span class="s2">&#34;社会&#34;</span><span class="p">,</span> <span class="n">topn</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">[(&#39;金钱至上&#39;, 0.5815222859382629),
(&#39;各阶层&#39;, 0.5668456554412842),
(&#39;福利制度&#39;, 0.5532322525978088),
(&#39;官与民&#39;, 0.5526734590530396),
(&#39;高考制度&#39;, 0.5515810251235962),
(&#39;资源分配&#39;, 0.5500271916389465),
(&#39;功利主义&#39;, 0.5484314560890198),
(&#39;分级制&#39;, 0.5450907349586487),
(&#39;功利化&#39;, 0.5432640910148621),
(&#39;法制建设&#39;, 0.5420899391174316)]
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">zhihu_wv</span><span class="o">.</span><span class="n">most_similar</span><span class="p">(</span><span class="s2">&#34;社会&#34;</span><span class="p">,</span> <span class="n">topn</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">[(&#39;社会存在&#39;, 0.6277482509613037),
 (&#39;社会生活&#39;, 0.613935649394989),
(&#39;社会群体&#39;, 0.6123108863830566),
(&#39;社会意识&#39;, 0.6055717468261719),
(&#39;物欲横流&#39;, 0.6041101217269897),
(&#39;民主决策&#39;, 0.602908194065094),
(&#39;阶级分化&#39;, 0.59609454870224),
(&#39;社会上&#39;, 0.5932644605636597),
(&#39;于社会&#39;, 0.5919737219810486),
(&#39;法制化&#39;, 0.5820874571800232)]
</code></pre></div><p><br><br></p>
<h2 id="四-可视化">四、 可视化</h2>
<p>为了让中文可以在matplotlib正常显示， 需要先运行下方代码</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">matplotlib</span>
<span class="kn">import</span> <span class="nn">platform</span>
<span class="kn">import</span> <span class="nn">matplotlib_inline</span>
<span class="n">matplotlib_inline</span><span class="o">.</span><span class="n">backend_inline</span><span class="o">.</span><span class="n">set_matplotlib_formats</span><span class="p">(</span><span class="s1">&#39;png&#39;</span><span class="p">,</span> <span class="s1">&#39;svg&#39;</span><span class="p">)</span>

<span class="n">system</span> <span class="o">=</span> <span class="n">platform</span><span class="o">.</span><span class="n">system</span><span class="p">()</span>  <span class="c1"># 获取操作系统类型</span>

<span class="k">if</span> <span class="n">system</span> <span class="o">==</span> <span class="s1">&#39;Windows&#39;</span><span class="p">:</span>
    <span class="n">font</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;family&#39;</span><span class="p">:</span> <span class="s1">&#39;SimHei&#39;</span><span class="p">}</span>
<span class="k">elif</span> <span class="n">system</span> <span class="o">==</span> <span class="s1">&#39;Darwin&#39;</span><span class="p">:</span>
    <span class="n">font</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;family&#39;</span><span class="p">:</span> <span class="s1">&#39;Arial Unicode MS&#39;</span><span class="p">}</span>
<span class="k">else</span><span class="p">:</span>
    <span class="c1"># 如果是其他系统，可以使用系统默认字体</span>
    <span class="n">font</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;family&#39;</span><span class="p">:</span> <span class="s1">&#39;sans-serif&#39;</span><span class="p">}</span>
<span class="n">matplotlib</span><span class="o">.</span><span class="n">rc</span><span class="p">(</span><span class="s1">&#39;font&#39;</span><span class="p">,</span> <span class="o">**</span><span class="n">font</span><span class="p">)</span>  <span class="c1"># 设置全局字体</span>
</code></pre></div><br>
<h3 id="41-运动的贫富和性别属性">4.1 运动的贫富和性别属性</h3>
<p>先看一个最难的例子， 后面的例子都是围绕ta展开的。</p>
<ul>
<li><strong>性别向量</strong> 由 <strong>男性均值端点向量</strong> 和 <strong>女性均值端点向量</strong> 计算得来</li>
<li><strong>贫富向量</strong> 由 <strong>富裕均值端点向量</strong> 和 <strong>贫穷均值端点向量</strong> 计算得来</li>
</ul>
<p>需要注意， 不论是 <strong>性别向量</strong>、<strong>贫富向量</strong> 还是运动词的词向量，都是 300维的向量。 如果在低维空间，例如2维坐标轴中可视化，需要做投影操作。这里需要一点大学线性代数的点乘知识。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="c1"># 获取需要绘制的单词列表</span>
<span class="n">words</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;足球&#39;</span><span class="p">,</span> <span class="s1">&#39;拳击&#39;</span><span class="p">,</span> <span class="s1">&#39;高尔夫&#39;</span><span class="p">,</span> <span class="s1">&#39;棒球&#39;</span><span class="p">,</span> <span class="s1">&#39;芭蕾&#39;</span><span class="p">]</span>

<span class="c1"># 获取词向量，并转换为 NumPy 数组</span>
<span class="n">vectors</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">wiki_wv</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">words</span><span class="p">])</span>

<span class="c1"># 选择两个词向量作为新坐标系的 x 轴和 y 轴</span>
<span class="n">x_axis</span> <span class="o">=</span> <span class="n">wiki_wv</span><span class="p">[[</span><span class="s1">&#39;女&#39;</span><span class="p">,</span> <span class="s1">&#39;女孩&#39;</span><span class="p">,</span> <span class="s1">&#39;母亲&#39;</span><span class="p">,</span> <span class="s1">&#39;奶奶&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">-</span>  <span class="n">wiki_wv</span><span class="p">[[</span><span class="s1">&#39;男&#39;</span><span class="p">,</span> <span class="s1">&#39;男孩&#39;</span><span class="p">,</span> <span class="s1">&#39;父亲&#39;</span><span class="p">,</span> <span class="s1">&#39;爷爷&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">y_axis</span> <span class="o">=</span> <span class="n">wiki_wv</span><span class="p">[[</span><span class="s1">&#39;贫穷&#39;</span><span class="p">,</span> <span class="s1">&#39;拮据&#39;</span><span class="p">,</span> <span class="s1">&#39;囊中羞涩&#39;</span><span class="p">,</span> <span class="s1">&#39;困难&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">-</span> <span class="n">wiki_wv</span><span class="p">[[</span><span class="s1">&#39;富裕&#39;</span><span class="p">,</span> <span class="s1">&#39;富有&#39;</span><span class="p">,</span> <span class="s1">&#39;贵气&#39;</span><span class="p">,</span> <span class="s1">&#39;财富&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># 计算每个词向量在新坐标系中的投影</span>
<span class="n">x_coords</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">vectors</span><span class="p">,</span> <span class="n">x_axis</span><span class="p">)</span>
<span class="n">y_coords</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">vectors</span><span class="p">,</span> <span class="n">y_axis</span><span class="p">)</span>

<span class="c1"># 绘制图形</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x_coords</span><span class="p">,</span> <span class="n">y_coords</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">word</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">words</span><span class="p">):</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="p">(</span><span class="n">x_coords</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">y_coords</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>

<span class="c1"># 绘制 x 轴和 y 轴的十字线</span>
<span class="n">ax</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="o">-</span><span class="mf">1.5</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="o">-</span><span class="mf">1.5</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;性别(男左女右)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;贫富(贫下富上)&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;运动的贫富和性别属性&#39;</span><span class="p">)</span>
<span class="c1">#plt.show()</span>


<span class="c1">#保存</span>
<span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">fname</span><span class="o">=</span><span class="s2">&#34;img/运动的贫富和性别属性.png&#34;</span><span class="p">,</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">300</span><span class="p">)</span>
</code></pre></div><p><img loading="lazy" src="img/output_25_0.png" alt="svg"  />
</p>
<br>
<h3 id="42-使用whatlies处理数据">4.2 使用whatlies处理数据</h3>
<p>上面的可视化代码太长了，使用whatlies可以简化代码量。我们把 KeyedVectors类 转为 EmbeddingSet类，这里就可以更容易的把点显示为带箭头的向量。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">whatlies</span> <span class="kn">import</span> <span class="n">Embedding</span><span class="p">,</span> <span class="n">EmbeddingSet</span>

<span class="c1"># load vectors as whatlies EmbeddingSet</span>
<span class="n">wiki_emb</span> <span class="o">=</span> <span class="n">EmbeddingSet</span><span class="o">.</span><span class="n">from_names_X</span><span class="p">(</span><span class="n">names</span><span class="o">=</span><span class="n">wiki_wv</span><span class="o">.</span><span class="n">index_to_key</span><span class="p">,</span> 
                                     <span class="n">X</span><span class="o">=</span><span class="n">wiki_wv</span><span class="o">.</span><span class="n">vectors</span><span class="p">)</span>

<span class="n">weibo_emb</span> <span class="o">=</span> <span class="n">EmbeddingSet</span><span class="o">.</span><span class="n">from_names_X</span><span class="p">(</span><span class="n">names</span><span class="o">=</span><span class="n">weibo_wv</span><span class="o">.</span><span class="n">index_to_key</span><span class="p">,</span>
                                      <span class="n">X</span> <span class="o">=</span> <span class="n">weibo_wv</span><span class="o">.</span><span class="n">vectors</span><span class="p">)</span>

<span class="n">zhihu_emb</span> <span class="o">=</span> <span class="n">EmbeddingSet</span><span class="o">.</span><span class="n">from_names_X</span><span class="p">(</span><span class="n">names</span><span class="o">=</span><span class="n">zhihu_wv</span><span class="o">.</span><span class="n">index_to_key</span><span class="p">,</span> 
                                      <span class="n">X</span><span class="o">=</span><span class="n">zhihu_wv</span><span class="o">.</span><span class="n">vectors</span><span class="p">)</span>

</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1"># list similar words, n=10</span>
<span class="n">wiki_emb</span><span class="o">.</span><span class="n">score_similar</span><span class="p">(</span><span class="s2">&#34;社会&#34;</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">[(Emb[社会], 5.960464477539063e-08),
(Emb[于社会], 0.3789013624191284),
(Emb[社会上], 0.4004524350166321),
(Emb[社会关系], 0.410597026348114),
(Emb[各阶层], 0.42002809047698975),
(Emb[社会制度], 0.4222911596298218),
(Emb[社会变迁], 0.42431581020355225),
(Emb[令社会], 0.42437267303466797),
(Emb[社会变革], 0.424416184425354),
(Emb[思想观念], 0.4247954487800598)]
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">weibo_emb</span><span class="o">.</span><span class="n">score_similar</span><span class="p">(</span><span class="s2">&#34;社会&#34;</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">[(Emb[社会], 0.0),
(Emb[金钱至上], 0.41847753524780273),
(Emb[各阶层], 0.43315428495407104),
(Emb[福利制度], 0.4467676877975464),
(Emb[官与民], 0.4473266005516052),
(Emb[高考制度], 0.4484187364578247),
(Emb[资源分配], 0.44997286796569824),
(Emb[功利主义], 0.4515683650970459),
(Emb[分级制], 0.45490920543670654),
(Emb[功利化], 0.4567357897758484)]
</code></pre></div><br>
<h3 id="43-whatlies默认可视化">4.3 whatlies默认可视化</h3>
<p>使用whatlies默认的效果绘制如下，但需要注意， 这里的Dimension0和Dimension1的含义是未知的。所以除了可视化， 含义解读起来比较困难。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1"># the default X and Y axes are the first two dimensions of the embedding vectors</span>
<span class="n">wiki_emb</span><span class="p">[</span><span class="s2">&#34;马&#34;</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s2">&#34;arrow&#34;</span><span class="p">,</span> 
                   <span class="n">color</span><span class="o">=</span><span class="s2">&#34;purple&#34;</span><span class="p">)</span>

<span class="n">wiki_emb</span><span class="p">[</span><span class="s2">&#34;鲨鱼&#34;</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s2">&#34;arrow&#34;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&#34;blue&#34;</span><span class="p">)</span>

<span class="n">wiki_emb</span><span class="p">[</span><span class="s2">&#34;鸟类&#34;</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s2">&#34;arrow&#34;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&#34;green&#34;</span><span class="p">)</span>
<span class="n">wiki_emb</span><span class="p">[</span><span class="s2">&#34;人&#34;</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s2">&#34;arrow&#34;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&#34;red&#34;</span><span class="p">)</span>
<span class="n">wiki_emb</span><span class="p">[</span><span class="s2">&#34;蛇&#34;</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s2">&#34;arrow&#34;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&#34;black&#34;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/output_30_0.svg" alt="svg"  />
</p>
<br>
<h3 id="44-使用端点向量当基向量">4.4 使用端点向量当基向量</h3>
<p>使用端点向量当基向量，</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">vecs</span> <span class="o">=</span> <span class="n">wiki_emb</span><span class="p">[</span><span class="s2">&#34;美国&#34;</span><span class="p">,</span> <span class="s2">&#34;中国&#34;</span><span class="p">,</span> <span class="s2">&#34;俄罗斯&#34;</span><span class="p">,</span> <span class="s2">&#34;韩国&#34;</span><span class="p">]</span>

<span class="n">vecs</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_axis</span><span class="o">=</span><span class="n">wiki_emb</span><span class="p">[</span><span class="s2">&#34;弱小&#34;</span><span class="p">],</span> 
          <span class="n">y_axis</span><span class="o">=</span><span class="n">wiki_emb</span><span class="p">[</span><span class="s2">&#34;强大&#34;</span><span class="p">],</span> 
          <span class="n">color</span><span class="o">=</span><span class="p">[</span><span class="s2">&#34;purple&#34;</span><span class="p">,</span> <span class="s2">&#34;green&#34;</span><span class="p">,</span> <span class="s2">&#34;blue&#34;</span><span class="p">,</span> <span class="s2">&#34;red&#34;</span><span class="p">])</span>

<span class="c1">#plt.show()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;国家强弱&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">fname</span><span class="o">=</span><span class="s2">&#34;img/国家强弱.png&#34;</span><span class="p">,</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">300</span><span class="p">)</span>
</code></pre></div><p><img loading="lazy" src="img/output_32_0.svg" alt="svg"  />
</p>
<br>
<p>按照我们的理解， 强大与弱小是方向相反的。但是如果将这两个词分别做基向量。如图所示，就体现不出方向。</p>
<p>同时，因为给定有意义的基向量作为坐标轴向量， 坐标轴含有了意义，可视化的结果可以看出语义信息的亲疏远近。</p>
<p>可以看到， 中美俄是大国强国，韩国是小国军事弱国。</p>
<br>
<h3 id="45-使用概念向量当做基向量">4.5 使用概念向量当做基向量</h3>
<p>当使用概念向量做基向量， 我们就能保留住词语之间的正反方向。避免 4.4 反义词之间无法体现方向性信息。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#待考察词</span>
<span class="n">vecs</span> <span class="o">=</span> <span class="n">wiki_emb</span><span class="p">[</span><span class="s1">&#39;足球&#39;</span><span class="p">,</span> <span class="s2">&#34;斗殴&#34;</span><span class="p">,</span> <span class="s1">&#39;高尔夫&#39;</span><span class="p">,</span> <span class="s1">&#39;篮球&#39;</span><span class="p">,</span> <span class="s1">&#39;芭蕾&#39;</span><span class="p">,</span> <span class="s1">&#39;男&#39;</span><span class="p">,</span> <span class="s1">&#39;女&#39;</span><span class="p">,</span> <span class="s1">&#39;富裕&#39;</span><span class="p">,</span> <span class="s1">&#39;贫穷&#39;</span><span class="p">,</span> <span class="s1">&#39;乒乓球&#39;</span><span class="p">,</span> <span class="s1">&#39;举重&#39;</span><span class="p">]</span>

<span class="c1">#性别概念向量</span>
<span class="n">sex_vector</span> <span class="o">=</span> <span class="n">wiki_emb</span><span class="p">[[</span><span class="s1">&#39;女&#39;</span><span class="p">,</span> <span class="s1">&#39;女孩&#39;</span><span class="p">,</span> <span class="s1">&#39;母亲&#39;</span><span class="p">,</span> <span class="s1">&#39;奶奶&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">average</span><span class="p">()</span> <span class="o">-</span> <span class="n">wiki_emb</span><span class="p">[[</span><span class="s1">&#39;男&#39;</span><span class="p">,</span> <span class="s1">&#39;男孩&#39;</span><span class="p">,</span> <span class="s1">&#39;父亲&#39;</span><span class="p">,</span> <span class="s1">&#39;爷爷&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">average</span><span class="p">()</span>
<span class="c1">#贫富概念向量</span>
<span class="n">disparity_vector</span> <span class="o">=</span> <span class="n">wiki_emb</span><span class="p">[[</span><span class="s1">&#39;富裕&#39;</span><span class="p">,</span> <span class="s1">&#39;富有&#39;</span><span class="p">,</span> <span class="s1">&#39;贵气&#39;</span><span class="p">,</span> <span class="s1">&#39;财富&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">average</span><span class="p">()</span> <span class="o">-</span> <span class="n">wiki_emb</span><span class="p">[[</span><span class="s1">&#39;贫穷&#39;</span><span class="p">,</span> <span class="s1">&#39;拮据&#39;</span><span class="p">,</span> <span class="s1">&#39;囊中羞涩&#39;</span><span class="p">,</span> <span class="s1">&#39;困难&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">average</span><span class="p">()</span> 

<span class="c1">#概念向量 做 基向量</span>
<span class="n">vecs</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_axis</span><span class="o">=</span> <span class="n">sex_vector</span><span class="p">,</span> 
          <span class="n">y_axis</span><span class="o">=</span> <span class="n">disparity_vector</span><span class="p">,</span> 
          <span class="n">color</span><span class="o">=</span><span class="p">[</span><span class="s2">&#34;purple&#34;</span><span class="p">,</span> <span class="s2">&#34;green&#34;</span><span class="p">,</span> <span class="s2">&#34;blue&#34;</span><span class="p">,</span> <span class="s2">&#34;red&#34;</span><span class="p">])</span>


<span class="c1">#plt.show()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;运动中体现的贫富与性别信息&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;性别(男左女右)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;贫富(贫下富上)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">fname</span><span class="o">=</span><span class="s2">&#34;img/运动中体现的贫富与性别信息.png&#34;</span><span class="p">,</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">300</span><span class="p">)</span>
</code></pre></div><p><img loading="lazy" src="img/output_34_0.svg" alt="svg"  />
</p>
<br>
<p>刚刚的图中加入了<code>男、女、贫穷、富裕</code>四个词，是为了帮助我们识别出方向来的，判断横纵坐标的含义和方向性。现在我们可以去掉这四个词，绘制更美观的图。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">vecs</span> <span class="o">=</span> <span class="n">wiki_emb</span><span class="p">[</span><span class="s1">&#39;足球&#39;</span><span class="p">,</span> <span class="s1">&#39;高尔夫&#39;</span><span class="p">,</span> <span class="s1">&#39;篮球&#39;</span><span class="p">,</span> <span class="s1">&#39;芭蕾&#39;</span><span class="p">,</span> <span class="s1">&#39;乒乓球&#39;</span><span class="p">,</span> <span class="s1">&#39;举重&#39;</span><span class="p">,</span> <span class="s1">&#39;徒步&#39;</span><span class="p">]</span>

<span class="n">sex_vector</span> <span class="o">=</span> <span class="n">wiki_emb</span><span class="p">[[</span><span class="s1">&#39;女&#39;</span><span class="p">,</span> <span class="s1">&#39;女孩&#39;</span><span class="p">,</span> <span class="s1">&#39;母亲&#39;</span><span class="p">,</span> <span class="s1">&#39;奶奶&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">average</span><span class="p">()</span> <span class="o">-</span> <span class="n">wiki_emb</span><span class="p">[[</span><span class="s1">&#39;男&#39;</span><span class="p">,</span> <span class="s1">&#39;男孩&#39;</span><span class="p">,</span> <span class="s1">&#39;父亲&#39;</span><span class="p">,</span> <span class="s1">&#39;爷爷&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">average</span><span class="p">()</span> 
<span class="n">disparity_vector</span> <span class="o">=</span> <span class="n">wiki_emb</span><span class="p">[[</span><span class="s1">&#39;富裕&#39;</span><span class="p">,</span> <span class="s1">&#39;富有&#39;</span><span class="p">,</span> <span class="s1">&#39;贵气&#39;</span><span class="p">,</span> <span class="s1">&#39;财富&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">average</span><span class="p">()</span> <span class="o">-</span> <span class="n">wiki_emb</span><span class="p">[[</span><span class="s1">&#39;贫穷&#39;</span><span class="p">,</span> <span class="s1">&#39;拮据&#39;</span><span class="p">,</span> <span class="s1">&#39;囊中羞涩&#39;</span><span class="p">,</span> <span class="s1">&#39;困难&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">average</span><span class="p">()</span> 

<span class="n">vecs</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_axis</span><span class="o">=</span> <span class="n">sex_vector</span><span class="p">,</span> 
          <span class="n">y_axis</span><span class="o">=</span> <span class="n">disparity_vector</span><span class="p">,</span> 
          <span class="n">color</span><span class="o">=</span><span class="p">[</span><span class="s2">&#34;purple&#34;</span><span class="p">,</span> <span class="s2">&#34;green&#34;</span><span class="p">,</span> <span class="s2">&#34;blue&#34;</span><span class="p">,</span> <span class="s2">&#34;red&#34;</span><span class="p">])</span>

<span class="c1">#plt.show()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;运动中体现的贫富与性别信息&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">)</span>


<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="o">-</span><span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="o">-</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">)</span>

<span class="c1">#plt.axis(&#39;off&#39;)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;性别(男左女右)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;贫富(贫下富上)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">fname</span><span class="o">=</span><span class="s2">&#34;img/运动中体现的贫富与性别信息.png&#34;</span><span class="p">,</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">300</span><span class="p">)</span>
</code></pre></div><p><img loading="lazy" src="img/output_36_0.png" alt="svg"  />
</p>
<br>
<p>从上图可以看出， 在wiki百科中记录下的， 我们对不同运动是存在贫富、性别化的信息。这些信息根据研究场景，解读为<strong>刻板印象、态度偏好、文化记忆</strong>等。 我们再看一个例子， 把中国动物(含神兽)分别在性别维度和尺寸维度可视化。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">vecs</span> <span class="o">=</span> <span class="n">wiki_emb</span><span class="p">[</span><span class="s1">&#39;虎&#39;</span><span class="p">,</span> <span class="s1">&#39;龙&#39;</span><span class="p">,</span> <span class="s1">&#39;猫&#39;</span><span class="p">,</span> <span class="s1">&#39;燕子&#39;</span><span class="p">,</span> <span class="s1">&#39;蝴蝶&#39;</span><span class="p">]</span>

<span class="n">sex_vector</span> <span class="o">=</span> <span class="n">wiki_emb</span><span class="p">[[</span><span class="s1">&#39;女&#39;</span><span class="p">,</span> <span class="s1">&#39;女孩&#39;</span><span class="p">,</span> <span class="s1">&#39;母亲&#39;</span><span class="p">,</span> <span class="s1">&#39;奶奶&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">average</span><span class="p">()</span><span class="o">-</span><span class="n">wiki_emb</span><span class="p">[[</span><span class="s1">&#39;男&#39;</span><span class="p">,</span> <span class="s1">&#39;男孩&#39;</span><span class="p">,</span> <span class="s1">&#39;父亲&#39;</span><span class="p">,</span> <span class="s1">&#39;爷爷&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">average</span><span class="p">()</span>
<span class="n">size_vector</span> <span class="o">=</span> <span class="n">wiki_emb</span><span class="p">[[</span><span class="s1">&#39;大&#39;</span><span class="p">,</span> <span class="s1">&#39;庞&#39;</span><span class="p">,</span> <span class="s1">&#39;巨&#39;</span><span class="p">,</span> <span class="s1">&#39;高&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">average</span><span class="p">()</span> <span class="o">-</span> <span class="n">wiki_emb</span><span class="p">[[</span><span class="s1">&#39;矮&#39;</span><span class="p">,</span> <span class="s1">&#39;小&#39;</span><span class="p">,</span> <span class="s1">&#39;微&#39;</span><span class="p">,</span> <span class="s1">&#39;毫&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">average</span><span class="p">()</span>


<span class="n">vecs</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_axis</span><span class="o">=</span> <span class="n">sex_vector</span><span class="p">,</span> 
          <span class="n">y_axis</span><span class="o">=</span> <span class="n">size_vector</span><span class="p">,</span> 
          <span class="n">color</span><span class="o">=</span><span class="p">[</span><span class="s2">&#34;purple&#34;</span><span class="p">,</span> <span class="s2">&#34;green&#34;</span><span class="p">,</span> <span class="s2">&#34;blue&#34;</span><span class="p">,</span> <span class="s2">&#34;red&#34;</span><span class="p">,</span> <span class="s2">&#34;yellow&#34;</span><span class="p">,</span> <span class="s2">&#34;grey&#34;</span><span class="p">])</span>

<span class="c1">#plt.show()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;文化中动物词蕴含的性别化和尺寸信息&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">)</span>


<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="o">-</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">)</span>

<span class="c1">#plt.axis(&#39;off&#39;)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;性别(男左女右)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;尺寸(下小上大)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">fname</span><span class="o">=</span><span class="s2">&#34;img/文化中动物词蕴含的性别化和尺寸信息.png&#34;</span><span class="p">,</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">300</span><span class="p">)</span>
</code></pre></div><p><img loading="lazy" src="img/output_38_0.svg" alt="svg"  />
</p>
<p><br><br></p>
<h2 id="代码获取">代码获取</h2>
<p>公众号:  大邓和他的Python， 同日期推文， 付费阅读获取全文教程、数据、代码~</p>
<p><br><br></p>
]]></content:encoded>
    </item>
    
    <item>
      <title>simpleT5 库 | 根据英文摘要内容生成标题</title>
      <link>https://textdata.cn/blog/2023-02-23-simplet5-one-line-summary/</link>
      <pubDate>Thu, 23 Feb 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-02-23-simplet5-one-line-summary/</guid>
      <description>T5（Text-to-Text Transfer Transformer）是一种基于 Transformer 架构的自然语言处理模型，由 Google Brain 团队开发。T5 模型采用了 encoder-decoder 架构，其中 encoder 将输入文本编码为向量，decoder 则从该向量生成目标文本。T5 模型的特点是将所有自然语言处理任务都视为“从输入文本到输出文本”的转换问题，它可以通过在任务之间共享模型参数和预训练模型来轻松地应用于各种 NLP 任务，如**文本分类、命名实体识别、文本摘要、问答系统**等。 与其他 NLP 模型不同的是，T5 模型使用了一种称为“text-to-text”方法的统一输入输出架构，使得所有 NLP 任务都能转化为文本转换问题，从而使得模型训练更加高效。</description>
      <content:encoded><![CDATA[<p>simpleT5 是基于 PyTorch 实现的 T5 模型库，旨在为用户提供一种简单、易用、可定制的 T5 模型工具。T5（Text-to-Text Transfer Transformer）是一种基于 Transformer 架构的自然语言处理模型，由 Google Brain 团队开发。T5 模型采用了 encoder-decoder 架构，其中 encoder 将输入文本编码为向量，decoder 则从该向量生成目标文本。</p>
<p><img loading="lazy" src="img/new_text_to_text.jpg" alt=""  />
</p>
<p>simpleT5 的设计目标是尽可能地减少 T5 模型的使用门槛，以方便用户在自然语言处理任务中快速应用 T5 模型，从而节省大量的模型开发时间和成本。</p>
<p>simpleT5 提供了一个简单的 API 接口，用户只需要提供输入文本和模型参数，即可轻松地使用 T5 模型进行文本转换任务，如<strong>文本摘要、机器翻译、对话系统</strong>等。simpleT5 还提供了一些预训练模型，包括 T5-small、T5-base 和 T5-large 等不同规模的模型，用户可以根据任务需求选择合适的模型。</p>
<p>除此之外，simpleT5 还提供了一些有用的工具和功能，如文本预处理、数据集加载、训练日志记录等，以帮助用户更轻松地进行模型训练和调试。simpleT5 的开发者们还提供了详细的文档和示例代码，以帮助用户更快地上手使用该库。</p>
<p>总之，simpleT5 为用户提供了一种快速、方便、可定制的 T5 模型工具，可以帮助用户在自然语言处理任务中更加高效地应用 T5 模型，节省大量的开发时间和成本。</p>
<p><br><br></p>
<h2 id="安装">安装</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="err">!</span><span class="n">pip3</span> <span class="n">install</span> <span class="o">--</span><span class="n">upgrade</span> <span class="n">simplet5</span>
</code></pre></div><p><br><br></p>
<h2 id="快速上手">快速上手</h2>
<p>t5模型有很多，如下图，今天以huggingface中公开的模型 <strong>snrspeaks/t5-one-line-summary为例， 展示 「根据传入的摘要内容生成对应的标题」。</strong></p>
<p><img loading="lazy" src="img/t5-models.png" alt=""  />
</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1"># pip install --upgrade simplet5</span>
<span class="kn">from</span> <span class="nn">simplet5</span> <span class="kn">import</span> <span class="n">SimpleT5</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">SimpleT5</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="s2">&#34;t5&#34;</span><span class="p">,</span><span class="s2">&#34;snrspeaks/t5-one-line-summary&#34;</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">    Global seed set to 42
    Downloading:   100%|          | 0.00/1.36k [00:00&lt;?, ?B/s]
    Downloading:   100%|          | 0.00/850M [00:00&lt;?, ?B/s]
    Downloading:   100%|          | 0.00/1.84k [00:00&lt;?, ?B/s]
    Downloading:   100%|          | 0.00/773k [00:00&lt;?, ?B/s]
    Downloading:   100%|          | 0.00/1.32M [00:00&lt;?, ?B/s]
    Downloading:   100%|          | 0.00/1.74k [00:00&lt;?, ?B/s]
</code></pre></div><br>
<p>根据英文摘要生成标题</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">abstract</span> <span class="o">=</span> <span class="s2">&#34;&#34;&#34;We describe a system called Overton, whose main design goal is to support engineers in building, monitoring, and improving production 
</span><span class="s2">machine learning systems. Key challenges engineers face are monitoring fine-grained quality, diagnosing errors in sophisticated applications, and 
</span><span class="s2">handling contradictory or incomplete supervision data. Overton automates the life cycle of model construction, deployment, and monitoring by providing a 
</span><span class="s2">set of novel high-level, declarative abstractions. Overton&#39;s vision is to shift developers to these higher-level tasks instead of lower-level machine learning tasks. 
</span><span class="s2">In fact, using Overton, engineers can build deep-learning-based applications without writing any code in frameworks like TensorFlow. For over a year, 
</span><span class="s2">Overton has been used in production to support multiple applications in both near-real-time applications and back-of-house processing. In that time, 
</span><span class="s2">Overton-based applications have answered billions of queries in multiple languages and processed trillions of records reducing errors 1.7-2.9 times versus production systems.
</span><span class="s2">&#34;&#34;&#34;</span>

<span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">abstract</span><span class="p">)</span>
</code></pre></div><p>Run</p>
<pre><code>['Overton: Building, Deploying, and Monitoring Deep Machine Learning Systems']
</code></pre>
<br>
<p>根据摘要生成多个标题</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">abstract</span> <span class="o">=</span> <span class="s2">&#34;&#34;&#34;We describe a system called Overton, whose main design goal is to support engineers in building, monitoring, and improving production 
</span><span class="s2">machine learning systems. Key challenges engineers face are monitoring fine-grained quality, diagnosing errors in sophisticated applications, and 
</span><span class="s2">handling contradictory or incomplete supervision data. Overton automates the life cycle of model construction, deployment, and monitoring by providing a 
</span><span class="s2">set of novel high-level, declarative abstractions. Overton&#39;s vision is to shift developers to these higher-level tasks instead of lower-level machine learning tasks. 
</span><span class="s2">In fact, using Overton, engineers can build deep-learning-based applications without writing any code in frameworks like TensorFlow. For over a year, 
</span><span class="s2">Overton has been used in production to support multiple applications in both near-real-time applications and back-of-house processing. In that time, 
</span><span class="s2">Overton-based applications have answered billions of queries in multiple languages and processed trillions of records reducing errors 1.7-2.9 times versus production systems.
</span><span class="s2">&#34;&#34;&#34;</span>

<span class="c1">#根据摘要生成5个标题</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">abstract</span><span class="p">,</span> 
              <span class="n">num_return_sequences</span><span class="o">=</span><span class="n">n</span><span class="p">,</span> 
              <span class="n">num_beams</span><span class="o">=</span><span class="n">n</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>

</code></pre></div><p>Run</p>
<pre><code>['Overton: Building, Deploying, and Monitoring Deep Machine Learning Systems',
 'Overton: Building, Deployment, and Improving Production Machine Learning Systems',
 'Overton: Building, Deploying, and Monitoring Machine Learning Systems for Engineers',
 'Overton: Building, Deploying, and Monitoring Machine Learning Systems',
 'Overton: Building, Deployment, and Monitoring Deep Machine Learning Systems']
</code></pre>
<p><br><br></p>
<h2 id="simplet5微调">simpleT5微调</h2>
<p>在 T5 模型的预训练阶段，它使用了巨大的文本语料库进行无监督的训练，以学习将输入文本转换为输出文本的能力。</p>
<p>预训练阶段结束后，T5 模型可以通过微调或迁移学习的方式用于各种下游 NLP 任务中，以实现最先进的性能表现。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="n">path</span> <span class="o">=</span> <span class="s2">&#34;https://raw.githubusercontent.com/Shivanandroy/T5-Finetuning-PyTorch/main/data/news_summary.csv&#34;</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p><img loading="lazy" src="img/df1.png" alt=""  />
</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1"># simple5库传入的数据是DataFrames，必须含 &#34;source_text&#34; 和 &#34;target_text&#34;这两个字段。</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s2">&#34;headlines&#34;</span><span class="p">:</span><span class="s2">&#34;target_text&#34;</span><span class="p">,</span> <span class="s2">&#34;text&#34;</span><span class="p">:</span><span class="s2">&#34;source_text&#34;</span><span class="p">})</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="s1">&#39;source_text&#39;</span><span class="p">,</span> <span class="s1">&#39;target_text&#39;</span><span class="p">]]</span>

<span class="c1"># T5 模型微调时候，source_text 数据都加入了前缀关键词summarise， 告诉 T5模型要做总结类任务的微调。</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;source_text&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&#34;summarize: &#34;</span> <span class="o">+</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;source_text&#39;</span><span class="p">]</span>
<span class="n">df</span>
</code></pre></div><p><img loading="lazy" src="img/df2.png" alt=""  />
</p>
<br>
<p>查看数据的形状</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">train_df</span><span class="p">,</span> <span class="n">test_df</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="n">train_df</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">test_df</span><span class="o">.</span><span class="n">shape</span>
</code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">((78720, 2), (19681, 2))
</code></pre></div><br>
<p>开始进行 T5 模型的微调</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">simplet5</span> <span class="kn">import</span> <span class="n">SimpleT5</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">SimpleT5</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_type</span><span class="o">=</span><span class="s2">&#34;t5&#34;</span><span class="p">,</span> <span class="n">model_name</span><span class="o">=</span><span class="s2">&#34;t5-base&#34;</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">train_df</span><span class="o">=</span><span class="n">train_df</span><span class="p">[:</span><span class="mi">5000</span><span class="p">],</span>
            <span class="n">eval_df</span><span class="o">=</span><span class="n">test_df</span><span class="p">[:</span><span class="mi">100</span><span class="p">],</span> 
            <span class="n">source_max_token_len</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> 
            <span class="n">target_max_token_len</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> 
            <span class="n">batch_size</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">max_epochs</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">use_gpu</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">Downloading: 100%
792k/792k [00:36&lt;00:00, 21.6kB/s]

Downloading: 100%
1.39M/1.39M [00:02&lt;00:00, 641kB/s]

Downloading: 100%
1.20k/1.20k [00:00&lt;00:00, 3.50kB/s]

Downloading: 100%
892M/892M [00:32&lt;00:00, 27.4MB/s]

GPU available: True, used: True
TPU available: False, using: 0 TPU cores
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name  | Type                       | Params
-----------------------------------------------------
0 | model | T5ForConditionalGeneration | 222 M 
-----------------------------------------------------
222 M     Trainable params
0         Non-trainable params
222 M     Total params
891.614   Total estimated model params size (MB)
Validation sanity check: 0%
0/2 [22:52&lt;?, ?it/s]
Global seed set to 42
Epoch 2: 100%
638/638 [04:07&lt;00:00, 2.57it/s, loss=1.02, v_num=0, val_loss=1.200, train_loss=1.130]
Validating: 100%
13/13 [00:01&lt;00:00, 7.43it/s]
Validating: 100%
13/13 [00:01&lt;00:00, 7.29it/s]
Validating: 100%
13/13 [00:01&lt;00:00, 7.30it/s]
</code></pre></div><br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1"># let&#39;s load the trained model for inferencing:</span>
<span class="n">model</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="s2">&#34;t5&#34;</span><span class="p">,</span><span class="s2">&#34;outputs/SimpleT5-epoch-2-train-loss-0.9478&#34;</span><span class="p">,</span> <span class="n">use_gpu</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">text_to_summarize</span><span class="o">=</span><span class="s2">&#34;&#34;&#34;summarize: Rahul Gandhi has replied to Goa CM Manohar Parrikar&#39;s letter, 
</span><span class="s2">which accused the Congress President of using his &#34;visit to an ailing man for political gains&#34;. 
</span><span class="s2">&#34;He&#39;s under immense pressure from the PM after our meeting and needs to demonstrate his loyalty by attacking me,&#34; 
</span><span class="s2">Gandhi wrote in his letter. Parrikar had clarified he didn&#39;t discuss Rafale deal with Rahul.
</span><span class="s2">&#34;&#34;&#34;</span>
<span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">text_to_summarize</span><span class="p">)</span>
</code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">[&#39;Rahul responds to Goa CM accusing him of using visit for political gain&#39;]
</code></pre></div><p><br><br></p>
]]></content:encoded>
    </item>
    
    <item>
      <title>如何注册chatGPT账号</title>
      <link>https://textdata.cn/blog/2023-02-15-how-to-sign-up-the-chatgpt-accout-and-upgrade-to-plus/</link>
      <pubDate>Tue, 14 Feb 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-02-15-how-to-sign-up-the-chatgpt-accout-and-upgrade-to-plus/</guid>
      <description>如何注册chatGPT，如何升级为PLUS用户</description>
      <content:encoded><![CDATA[<h2 id="一拦路虎">一、拦路虎</h2>
<p>使用chatGPT PLUS前，我们将面临有几个拦路虎</p>
<ol>
<li>如何科学上网</li>
<li>海外手机号</li>
<li>国外的信用卡</li>
</ol>
<p>搞定了这些问题， 我们就可以愉悦的使用chatGPT</p>
<p><img loading="lazy" src="img/chatgpt-is-a-joke.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="二注册chatgpt">二、注册chatGPT</h2>
<p>注册 chatGPT，需要先科学上网， 教程之前分享过 <a href="https://textdata.cn/blog/2023-02-01-v2net-science-network/">科学上网v2net</a> ，需要注意， 代理节点推荐选用美国、日本，全局模式访问外网。</p>
<h3 id="21-自己注册">2.1 自己注册</h3>
<p>搞定了 chatGPT 页面的访问后，需要使用国外可用的手机号， 才能注册chatGPT， 这时候可以用<a href="https://sms-activate.org/">接码平台https://sms-activate.org/</a>，</p>
<h3 id="22-找代理注册账号">2.2 找代理注册账号</h3>
<p>或者花钱 <a href="https://shop.terobox.com/?from=1059">找代理网https://shop.terobox.com/</a> 注册chatGPT账号。对了， 大邓自己的账号就是找代理注册的。</p>
<p><img loading="lazy" src="img/chatgpt-register-page.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="三chatgpt-plus">三、chatGPT PLUS</h2>
<p>chatGPT短短一个月，注册用户狂涨至 一亿用户， 是目前发展最迅猛的 网络应用。这就导致短时间大规模的访问让chatGPT服务有点绷不住了， 出现网络连接不稳定、响应速度变慢。 而且chatGPT的功能也被阉割， 不像最初那么智能。解决办法只有一个&mdash;使用超能力，20美金将账号提升至PLUS。有两种PLUS升级方式</p>
<h3 id="21-虚拟信用卡">2.1 虚拟信用卡</h3>
<p>升级chatGPT PLUS的难点在于你的信用卡是否可用。比如大邓，即使是VISA卡， 升级PLUS也不支持。解决办法是看大邓写的<a href="https://textdata.cn/blog/2023-02-11-credit_card_for_chatgpt-plus/">虚拟信用卡使用教程</a> ， PLUS最终使用成本大概 <strong>150元（21美元/月） ， 大邓个人推荐自己搭建虚拟信用卡</strong>。确保在**「全局VPN+浏览器无痕模式」下进行注册及升级PLUS的操作**</p>
<h3 id="32-找代理升级账号">3.2 找代理升级账号</h3>
<p>如果觉得操作起来比较繁琐复杂，如果你经济状况还okay， 可以使用 <a href="https://shop.terobox.com/?from=1059">代理网https://shop.terobox.com/</a> ，但就是有些小贵， 要300元啊，两倍于自己搞。</p>
<p><img loading="lazy" src="img/chatgpt-register-page.png" alt=""  />
</p>
<br>
<br>
]]></content:encoded>
    </item>
    
    <item>
      <title>转载 | 大数据时代的「计算文化心理学」</title>
      <link>https://textdata.cn/blog/2023-02-13-computing-cultural-psychology-with-big-data/</link>
      <pubDate>Mon, 13 Feb 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-02-13-computing-cultural-psychology-with-big-data/</guid>
      <description>随着大数据技术与文化心理学的融合发展, 计算文化心理学作为一门新兴交叉学科逐渐兴起, 大尺 度、近乎全样本的文化心理分析真正得以实现。计算文化心理学关注的文化变量主要围绕个人主义/集体主义 这一文化心理学使用最为广泛的维度展开, 分析方法包括特征词典、机器学习、社会网络分析、仿真模拟等, 分 析思路包括时间维度上的文化变迁效应以及空间维度上的文化地理效应。 当然, 计算文化心理学在为传统文 化心理研究提供新方法、新范式的同时, 也存在解码失真、样本偏差、词语多义性、隐私风险等局限, 未来研 究应重视变量理论解释、文化动态演化分析、学科深度整合、生态效度等问题。</description>
      <content:encoded><![CDATA[<h2 id="推荐理由">推荐理由</h2>
<p><a href="https://textdata.cn/blog/management_python_course/"><strong>「课程 | Python实证指标构建与文本分析」</strong></a> 一直是面向经管、心理学、社会学等计算社会科学的一门综合性课程。 希望能学技术的同时，也多了解技术应用背后的方法论、认识论，大数据导向的研究必能事半功倍。</p>
<br>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">吴胜涛,茅云云,吴舒涵,冯健仁,张庆鹏,谢天,陈浩,朱廷劭.基于大数据的文化心理分析[J].心理科学进展:1-13.
</code></pre></div><p><strong>摘要</strong>: 随着大数据技术与文化心理学的融合发展, 计算文化心理学作为一门新兴交叉学科逐渐兴起, 大尺度、近乎全样本的文化心理分析真正得以实现。计算文化心理学关注的文化变量主要围绕个人主义/集体主义这一文化心理学使用最为广泛的维度展开, 分析方法包括特征词典、机器学习、社会网络分析、仿真模拟等, 分析思路包括时间维度上的文化变迁效应以及空间维度上的文化地理效应。 当然, 计算文化心理学在为传统文 化心理研究提供新方法、新范式的同时, 也存在解码失真、样本偏差、词语多义性、隐私风险等局限, 未来研 究应重视变量理论解释、文化动态演化分析、学科深度整合、生态效度等问题。</p>
<p><strong>关键词: 大数据, 文化, 计算文化心理学, 文化变迁, 文化地理</strong></p>
<p><br><br></p>
<h2 id="一大数据文化心理学">一、大数据文化心理学</h2>
<p>近 10 年的大量文献来看, <strong>大数据技术已经成为当前哲学、自然科学和 社会科学共同关注的重要问题,  为人文与社会科学提供了继实验、理论、仿真之后的第四种研究范式,  并催生了计算社会科学</strong>的诞生(Gray, 2009; Lazer et al., 2009)。</p>
<p>随着大数据时代的到来, 传统文化心理学面临诸多挑战, 但也迎来了范式变革的机遇。</p>
<p>首先, 互联网将人与人之间的距离拉近, 使得不同文化背景的人主动或被动地汇聚在一个时空压缩的“地球村”里, 全球范围的文化互动、变迁成为常态, 但由于研究资料受限、分析方法滞后, <strong>传统文化心理学在进行大尺度时间、空间分析时费时费力。幸运的是, 信息技术的发展使得不同时间、空间的文化符号及其互动过程留下了海量的数据印记, 这为研究者分析不同时间、不同空间下的文化心理特征提供了无可比拟的大规模生态数据库。</strong> 进而, 大数据技术赋能研究者们方便地抓取网络生态数据, 研究文化动态演化及节点事件效应(Park, Baek et al., 2014; Wu, Zhou et al., 2018), 使得时间趋势和空间地理上的大尺度分析真正成为可能, 文化心理学的研究问题也得以拓展。</p>
<p>其次, 大数据时代文化符号生产快速增长, 但是基于纸笔测验和行为实验的传统文化心理学 研究往往是滞后的, 且样本量较小、代表性不够, 远远不能满足研究者和决策者的需要。 而<strong>基于大数据的文化心理学研究能够以相对较低的时间、 人力成本实现近乎全样本的数据进行自动抓取、 实时分析乃至实验操控, 并从海量数据中迅速锁定、预测某一群体的行为特征, 进而实现宏观群 体水平的文化心理分析、预测和改变。</strong></p>
<p><strong>再者, 大数据时代的文化互动日趋个体化和复杂化, 而传统的文化心理学容易忽视文化成员在个体水平及复杂情景中的差异, 仅通过抽样追 求简单因果关系, 却难以把握文化心理、行为间的复杂相关性</strong>。也就是说, 在没有搞清楚“是什么” 的情况下就去分析“为什么” (顾肃, 2021)。 巨大、 连续的数据存储和模型分析, 以一种细粒度和大规模乃至全球范围的方式实时研究个体行为, 能够根据个体和情景变异进行适应性的调整和持续、实时的纠正;  同时, 庞大数据量补偿了精确性上的损失, 这有助于分辨出最合适的相关关系, 捕捉小数据测量时没有的新价值(Lazer et al., 2009)。尽管基于大数据技术的词频、预测模型或社会网络分析并非新鲜事物, 但将其应用于文化心理学研究能够从整体上把握对象, 促进从因果思维向相关性思维转变, 进而有利于全面、客观地揭示隐藏在数据背后的文化意涵和规律(陈云松, 2015)。</p>
<p><strong>最后, 更为重要的是, 大数据时代的文化形态也发生了深刻变化。</strong> 随着互联网的快速发展与网民的大量增加, 基于网络的独特文化现象层出 不穷, 一些经典的文化行为特征在网络上的表现也有所不同, 但传统文化心理学对此知之甚少。 例如, 研究发现相对于其他社会环境, 网络环境 下人们的情绪表达会更极端, 而且网络使用的时间越长, 极端情绪越明显(King, 2001)。 此外, 由于线上与线下任务的认知加工过程不同, 人们在 一些经典的文化认知表现上也存在差异。 例如, 相对于认知负荷较大的线下记忆任务, 低认知负荷的线上浏览任务中被试有更多的认知资源来处理外部信息, 因此在社会行为推理上会表现出较小的对应偏差, 基于国别的文化差异被基于线上 和线下的文化差异所代替(Miyamoto &amp; Kitayama, 2002)。 尤其值得注意的是, 移动互联网本身就是一种带有偏差的文化产品, 例如具有相应文化倾向(如高个人主义、低不确定性回避)的用户也更能 体验到技术−文化匹配后的愉悦感和效用感(Lee et al., 2007)。 因此我们不能仅满足于将研究线下文化现象的思维来简单套用到线上行为的文化心理研究中。 总之, 随着计算机和大数据技术的深入发展, 人类社会及其文化形态正经历着深刻的变革。 <strong>文化符号的生产和互动日趋复杂, 文化成员及其社 会网络更是留下了海量的文本与行为足迹。 这使得文化必须被快速地描述、预测甚至改变, “可计算”的文化符号及其互动过程也逐渐成为文化心理学的研究对象。 接下来, 我们将主要对计算文化心理学的产生过程、主要变量和分析技术进行回顾, 并介绍该技术在相关文化变迁、文化地理效应的应用。</strong></p>
<p><br><br></p>
<h2 id="二计算文化心理学">二、计算文化心理学</h2>
<p>在计算文化心理学正式产生以前, 文化学者就受到计算机技术的启发, 提出了**「文化计算」**概 念, 强调要发挥计算机的独特优势, 以便多维度 展现文化及其与人的互动(Tosa et al., 2005)。通过 <strong>文化计算</strong>, 研究者首先在艺术领域实现了文化的数据化呈现和翻译(Tosa et al., 2019)。 进而, <strong>文化计算把计算及相关技术应用到越来越多的文化领域, 探索其发展规律、提示其内在联系并对其进行量化分析与展示的科学</strong>(赵海英 等, 2016)。 如 Michel 等人(2011)通过对谷歌图书项目的数据进行分析, 发现了特定关键词使用频率的时间变化规律, 并由此推导出人类文化发展的趋势, 如语法演变、集体记忆和流行病学的变化趋势等; 吴育锋等人(2018)通过“文心” (中文心理分析系统) 对小说《平凡的世界》中的对话文本进行文学智能分析, 发现其计算出的小说人物性格与以往文艺研究结果一致, 并发现了不同时代人物呈现出性格变迁的趋势(如新时代青年的性格更加开放、 外向);</p>
<p>Neuman 等人(2012)在 <strong>「文化计算」</strong> 的基础上正式提出了**「计算文化心理学」**”的概念, 即通过计算工具和大数据资料库来研究文化符号及其互动过程的心理学分支。 值得注意的是, 虽然文化计算和基于计算的文化心理学有很多相似之处, 但是二者也有区别：</p>
<ul>
<li>前者侧重文化载体的呈现, 以及 文化基因的提取;</li>
<li>后者除了一般意义上的文化计算, 还注重分析人与文化环境的交互关系, 并且文化载体不仅是传统艺术文化, 也包含网络社交 媒体等。</li>
</ul>
<p><br><br></p>
<h2 id="三文化心理变量的提取">三、文化心理变量的提取</h2>
<p>为了理解文化现象, 心理学者需要首先提取文化心理变量, 进而理解影响其成员思维的符号系统和互动机制。<strong>语言是被分享的文化系统(王斌, 2012), 因此我们可以把语言看做是理解文化的窗口以及提取文化心理变量的来源(罗伯特·怀尔 等, 2017)。 语言的本质是思想、话语的直接现实和展示(吴美川, 2020), 其在计算文化心理学领域的语言载体主要包括书籍、社会媒体数据、档案数据、网络音频等</strong>。</p>
<p>针对语言文化载体, 研究者主要提取的文化心理变量包括<strong>个人主义/集体主义、个性解放/自我表达、文化松紧度</strong>等, 详见表 1。</p>
<p><img loading="lazy" src="img/%e6%96%87%e5%8c%96%e5%bf%83%e7%90%86%e5%8f%98%e9%87%8f%e7%a0%94%e7%a9%b6%e8%b7%9d%e7%a6%bb.png" alt=""  />
</p>
<p>第一, 这些变量本身具有重要研究价值, 如个人主义/集体 主义是文化心理学中使用最为广泛的文化维度, 尤其对社会文化变迁和跨文化比较研究具有重要 意义; 第二, 社会现实的需求, 如新冠疫情的全球大流行显著增加了规范遵从的强度, 这需要研 究者及时分析其文化适应后果及政策干预策略; 第三, 此类文化变量的可操作性强, 便于用大数 据方法来进行抓取和计算。</p>
<p>此外, 计算文化心理学研究也对一些文化变量进行了操作化和创造性的发展。 首先, 考虑到大数据的语料库特点, 选用一些便于操作的语言 特征作为经典文化心理学变量的指标, 例如用第一人称单数的使用频率作为个人主义的指标(Twenge et al., 2013); 其次, 将个体的行为印记(如@他人、 成组人群比例)作为文化心理变量的指标, 是对以往基于主观报告的文化心理测量的重要发展(Wu, Li et al., 2018); 此外, 根据新媒体的特点, 采用表情包等作为文化相关情绪表达规范的指标也是一种有益的创新(Koda &amp; Ishida, 2006)。</p>
<p><br><br></p>
<h2 id="四文化心理变量的计算方法">四、文化心理变量的计算方法</h2>
<p>目前采用大数据技术进行文化心理分析主要 有 4 种方法：</p>
<ol>
<li>
<p>基于<strong>特征词典的频次分析</strong>, 如通过对数字、表情和语言等方面的关键特征分析, 研究个体或群体的文化价值观, 这是一种简单有效但相对粗糙的分析(李国杰, 程学旗, 2012)。</p>
</li>
<li>
<p>基于<strong>机器学习的模型预测或词嵌入联想测验</strong>, 如通过机器学习模型对用户的个性、价值观和意识 形态进行识别, 这种方法更精确, 对心理特征的 把握也更全面(Kosinski et al., 2015); 词嵌入联想 测验以词嵌入向量特征代替传统的词频特征, 将 靶词和属性词向量的余弦相似度作为语义关联度的指标, 是社会态度与价值观研究的新方法 (Caliskan et al., 2017; Hamamura et al., 2021)。</p>
</li>
<li>
<p><strong>社会网络分析</strong>, 如通过对网络搜索、网友互粉 等数据的分析, 研究不同文化群体的行为和决策风格, 这种方法目前在文化心理学领域还相对较 少, 但具有重要的社会实践价值(Wu, Li et al., 2018);</p>
</li>
<li>
<p><strong>社会仿真模型</strong>, 因为很多社会事 件是无法在现实中进行实验的, 所以采用仿真模拟的办法来研究某一特定的系统和策略, 从而达到分析社会事件的目的(刘婷婷 等, 2016)。 当然, 这 4 种技术并不是孤立的, 研究者也会根据研究 问题采取一种或多种技术。</p>
</li>
</ol>
<blockquote>
<p>特征词典的频次分析、机器学习的模型预测或词嵌入联想测验等技术方法在课程<a href="https://textdata.cn/blog/management_python_course/"><strong>「课程 | Python实证指标构建与文本分析」</strong></a> 中均有丰富的案例、代码、实战。</p>
</blockquote>
<br>
<p>总之, 计算文化心理学致力于应用大数据思维、大数据资源和计算工具来研究文化系统背后的意义制造与互动过程, 它不仅为文化心理分析 提供了新的工具, 也为理解人类思维本质和文化 形态提供了新的学科范式(Neuman, 2014)。<strong>围绕着“集体主义/个人主义”这一被最广泛讨论的文化心理变量, 「计算文化心理学」可以在时间、空间两个维度方面有如下应用</strong>：</p>
<ul>
<li>在时间维度上, 分别从长时程的宏观历史发展和短时程的经济波动转型两个角度介绍计算文化心理学的应用;</li>
<li>在空间维度上, 主要进行生态地理分析, 如文化在特定政治和经济框架内的地区差异, 不同地区生态或户籍制度造成的个人−环境匹配与价值失调。 分析框架见图 1。</li>
</ul>
<p><img loading="lazy" src="img/%e8%ae%a1%e7%ae%97%e6%96%87%e5%8c%96%e5%bf%83%e7%90%86%e5%ad%a6%e7%9a%84%e5%88%86%e6%9e%90%e6%a1%86%e6%9e%b6.png" alt=""  />
</p>
<p><br><br></p>
<h2 id="五不足展望">五、不足&amp;展望</h2>
<p>虽然计算文化心理学已经崭露头角, 相对于 传统文化心理学研究方法和范式具有无法比拟的优势, 但利用大数据进行文化心理分析仍然存在一些局限。</p>
<h3 id="51-技术自身带来的局限">5.1 技术自身带来的局限</h3>
<p><strong>首先, 很多研究者忽视了同一变量在不同时代、不同国家的意义分歧, 造成解码失真</strong>。 心理学者检验文化变迁的常用方法是寻找作者认为对 文化敏感的词汇并探索其使用频率的时间变化, 比如通过追踪第一人称单、复数代词的使用频率 来分析集体主义、个人主义的时间变迁效应 (Twenge et al., 2013; Yu et al., 2016)。 然而, 语言 总是随着时间演变, 同一个词义并不具有稳定性, 其不可避免地受到经济、政治或者文化因素的影响。</p>
<p><strong>假定大数据背后的文化成员能代表整个文化, 容易将带有偏差的文化成员样本视为研究整体</strong>。 例如, 很多研究者使用当下非常流行的语料库——Google Ngram Viewer 来研究集体主义/个人主 义, 并把结论推广至整个国家层面(Twenge et al., 2013)。 但实际上, 该语料库并不能代表无差别的文化整体, 相反, 它仅仅是突出了特定子群体的文化, 如 Google Ngram Viewer 仅代表书面文化的使用者, 社交媒体数据只包含社交媒体用户, 而 忽视了没有机会接触书籍和社交媒体的文化成员 (Pettit, 2016)。 所以, <strong>研究者要特别注意, 诸如图书语料库、社交媒体分析等并不是基于无偏样本, 因此在使用该类分析材料时要考虑结论的可推广 性和普遍适用性问题。</strong></p>
<p>第三, 研究者对量表或题项进行赋值、使得变量可计量, 进而将文化心理与行为转换为一种符号系统, 但是<strong>大数据分析中的频次分析提取的 关键词往往具有多义性, 如果研究者只是摘取了某个含义并将其纳入特定理论范畴, 则难免会出 现选择性谬误</strong>。 同时, 用于处理数据的软件还会 进一步固化这一测量误差。例如在 LIWC 软件中, 因 为 “great” 属 于积极情感范畴 , 所 以 “a great amount of rain”这一无关表达将被归类为积极情 感表达。 这意味着, 即便大数据分析技术的飞速发展, 但其得出的结果仍不够精确。</p>
<p>第四, 存在文化被监控和被操纵、以及侵犯个人隐私的风险。 大数据以其海量存储和智能计算优势来提取个人和特定群体的文化和性格数据, 进而实施与文化−性格相匹配的精准操纵, 甚至攻击。 这些做法明显的弊端就是数据隐私性和国 家区域安全难以保证, 容易被不法分子利用。 因 此, 为了避免个体数据及其分析结果被滥用, 全球研究者应该将研究伦理置于大数据分析的首位, 共同谋求相应的解决措施和共通的数据法律来解 决个人信息及国家或地区文化心理分析的不当使 用问题 (Kosinski et al., 2015)。</p>
<br>
<h3 id="52-技术带来的机会">5.2 技术带来的机会</h3>
<p><strong>我们不能忽视它在未来的巨大发展空间， 应从理论高度对大数据测量指标进行准确定义和解释</strong>。 大数据时代, 出现了重视数据驱动、而轻视理论的现象(维克托 • 迈尔-舍恩伯格, 肯尼斯 • 库克耶, 2013)。 但实际上大数据只是在数据采集中提供了一个发现或检验科学理论的新方法, 不能在知识生产环节中取代理论知识的地位。 理论在大数据研究中是重要的, 一方面大数据分析的算法模型以及对数据的解释需要理论的支撑(彭理强, 2019), 另一方面我们需要运用数据的意向性并由此对数据进行分类, 而不同的意向性和不同的分类体系是由理论概念决定的(齐磊磊, 2015)。 因此, <strong>在未来的研究中, 研究者的设计和经验数据的使用应在理论指引下进行, 尤其在指标维度的构建上要重视理论术语的指称和实体之间的关系</strong>(贾向桐, 2019)。</p>
<p><strong>其次, 利用多种大数据语料库, 进行更广泛的文化动态演化分析</strong>。 过往的研究容易把文化看做静态的单一实体, 并且将不同文化之间的异同 归因于其背后的国家/民族中根深蒂固的特质, 即轻易对群体进行本质化。 然而, 我们需要意识到文化知识是动态发展的过程, 文化的相关潜质或 因果连结存在于特定共享文化知识的激活, 并且 共享文化会随着社会政治和其他类型的社会变化 不断地产生和演化(康萤仪 等, 2010)。 传统的文 化心理学研究受制于小样本并容易忽视微弱的相 关关系, 因此在条件允许的情况下, 未来需要依 赖多种大数据语料库开展更广泛的纵向大尺度研 究, 探索文化符号串联及其背后机制的研究线 索。例如, 研究者可以使用历史档案数据库, 来研 究共享文化从何而来、其分布与使用的频率如何、 共享的边界是什么、共享文化被激活后产生了什么后果等, 进而促进共同的和个体的经验。</p>
<p><strong>第三, 推动文化心理学与计算机、传播学、 历史学等学科的深度整合</strong>。 文化心理学的力量在于其方法论上的多元化和多学科基础(余霞, 钟年, 2019; Cohen, 2019)。 但是, 跨学科也使得学科互补的同时充满文化冲突, 例如不同学科会由于不同范式而在考虑问题的优先级等方面存在根本性 差异, 一旦学科之间产生冲突, 问题或许就会贯穿任何主题和学科的边界(Popper, 1963)。 然而, <strong>当计算思维、数据资源和计算工具被采用后, 就可以从方法论层面加速对研究问题的解决</strong>。 在未来研究中, 研究者可以充分利用计算文化心理学固有的学科多样性和数据多源化, 尝试通过“计 算”去更好地整合文化心理学背后的多个学科视 角及其变量维度, 使大家共同聚焦某个问题。 比如, 为了描绘复杂的文化现象共同将目光聚焦于 背后多源数据的处理、共享数据库的建成、理论与数据的结合等学科问题, 不断推进计算文化心理学的整体发展。</p>
<p><strong>最后, 利用大数据的“场景功能”, 提升文化心理学研究的生态效度。</strong> 一直以来, 由于实验情境缺乏生态效度, 心理学赖以成为“科学”的实验研究备受质疑; 而在大数据背景下, 研究者对已有数据的挖掘完全能够在自然情境下生成实验变量, 在大数据中挑选情境便是实验方式(喻丰 等, 2015)。 在未来研究中, 研究者不仅可以聚焦小场景, 研究个人经验与近端影响源之间的关系, 而且可以探索大场景中更远端影响源与个人经验之间的相互作用, 从而分析不同时间、空间的文化 差异。值得注意的是, 当场景被扩大和拉长, 这些真实的场景可能体现了个人行为与动机的绝大部 分变异, 这体现了自然情境研究的“深度背景化”, 有助于提升文化等背景特征的解释水平。</p>
<p><br><br></p>
<h2 id="六总结">六、总结</h2>
<p>总之, 计算机和大数据技术深刻影响了文化符号的生产、互动方式以及文化形态本身, 并促成了计算文化心理学的产生和发展。 通过回顾计 算文化心理学的产生过程, 以及将大数据分析方法应用到文化变迁、文化地理效应等多个领域的实证研究, 有助于我们理解计算文化心理学的学 科优势、局限及未来发展方向, 并对文化心理研 究的思路拓展和方法革新具有启发意义。</p>
<p>尤为重要的是, 大数据为大尺度的文化分析提供了可能。 文化作为一种宏观且多变的现象, 任何一种文化理论都需要从越大规模的时间和空 间维度来进行检验和评判, 基于大数据的计算文化心理学能够为研究者提供数以亿计的数据以及 强有力的分析工具; 同时, 大数据改变了传统文 化心理学的研究范式, 更产生了诸多新的文化现 象, 这蕴含了整个学科思维方式和学科体系的变 革(喻丰 等, 2015)。当然, 在看到大数据为传统文 化心理研究提供新方法、新范式的同时, 我们也不能忽视其研究局限, 以及潜在的伦理和安全风险。</p>
<br>
]]></content:encoded>
    </item>
    
    <item>
      <title>数据清洗 | 借助 chatGPT 设计正则表达式</title>
      <link>https://textdata.cn/blog/2023-02-12-regex-expression-generated-by-chatgpt/</link>
      <pubDate>Sun, 12 Feb 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-02-12-regex-expression-generated-by-chatgpt/</guid>
      <description>使用 chatGPT 做正则表达式做数据清洗。</description>
      <content:encoded><![CDATA[<p>正则表达式可以帮我们，对给定输入的数据input_data，设定一定的规律pattern，输出干净结果output_data的工具。</p>
<p>但对于小白而言，很多时候，我们知道 input_data 和 output_data， 但不知道如何设计 表达式pattern，毕竟即使是计算机专业的学生，如果不系统钻研，都不一定会快速上手，更遑论我们文科生小白。<strong>chatGPT 是一种具有极强学习和推理能力的工具， 我们需要先研究数据中的规律，抽象出能实现目的的 input_data 和 output_data， 丢给chatGPT帮我们设计</strong>。</p>
<p>接下来的人机对话中，input_data 和 output 为视频课程《Python实证指标构建与文本分析》正则表达式章节的实验数据。实验下来， 比通过谷歌百度搜效率高多了，准确率也不错。</p>
<br>
<h2 id="问题1-提取个人信息">问题1-提取个人信息</h2>
<h3 id="deng">deng:</h3>
<p>我正在学习Python正则表达式，将给出实验文本数据input_data，以及我想从中抽取出的内容output_data。请帮我设计对应的正则表达式。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">input_text</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;大家好，我叫张三,来自河北，今年30岁。&#39;</span><span class="p">,</span>                      
              <span class="s1">&#39;大家好，我叫李四,来自山东，今年25岁。&#39;</span><span class="p">,</span>                     
              <span class="s1">&#39;大家好，我叫王五,来自内蒙古，今年22岁。&#39;</span><span class="p">]</span> 


<span class="n">output</span> <span class="o">=</span> <span class="p">[(</span><span class="s1">&#39;张三&#39;</span><span class="p">,</span> <span class="s1">&#39;河北&#39;</span><span class="p">,</span> <span class="s1">&#39;30&#39;</span><span class="p">),</span> 
          <span class="p">(</span><span class="s1">&#39;李四&#39;</span><span class="p">,</span> <span class="s1">&#39;山东&#39;</span><span class="p">,</span> <span class="s1">&#39;25&#39;</span><span class="p">),</span> 
          <span class="p">(</span><span class="s1">&#39;王五&#39;</span><span class="p">,</span> <span class="s1">&#39;内蒙古&#39;</span><span class="p">,</span> <span class="s1">&#39;22&#39;</span><span class="p">)]</span> 
</code></pre></div><h3 id="chatgpt">chatGPT:</h3>
<p>下面是匹配上述input_data和output_data的正则表达式：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">re</span>

<span class="n">input_data</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;大家好，我叫张三,来自河北，今年30岁。&#39;</span><span class="p">,</span> 
              <span class="s1">&#39;大家好，我叫李四,来自山东，今年25岁。&#39;</span><span class="p">,</span>
              <span class="s1">&#39;大家好，我叫王五,来自内蒙古，今年22岁。&#39;</span><span class="p">]</span>

<span class="n">output_data</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">text</span> <span class="ow">in</span> <span class="n">input_text</span><span class="p">:</span>
    
    <span class="n">res</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">findall</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;我叫(.*),来自(.*)，今年(.*)岁&#39;</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>
    <span class="n">output_data</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">tuple</span><span class="p">(</span><span class="n">res</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
    
<span class="nb">print</span><span class="p">(</span><span class="n">output_data</span><span class="p">)</span>
</code></pre></div><p>这段代码将使用正则表达式 <code>r&quot;我叫(.*),来自(.*),今年(\d+)岁&quot;</code> 匹配 <code>input_data</code> 中的内容，并将每一行的匹配结果存储在 <code>output_data</code> 列表中。</p>
<br>
<h2 id="问题2-提取出数据中的年份">问题2-提取出数据中的年份。</h2>
<h3 id="deng-1">deng:</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">intput_data = &#34;&#34;&#34;Python是一门面向对象的编程语言，诞生于1991年22。目前以广泛应用在网站开发、游戏软件开发、数据采集、机器学习等多个领域。一般情况下Python是Java的20%，所以说人生苦短，我用Python。&#34;&#34;&#34;

output_data = [&#39;1991&#39;]
</code></pre></div><h3 id="chatgpt-1">chatGPT：</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">re</span> 
<span class="n">intput_data</span> <span class="o">=</span> <span class="s2">&#34;&#34;&#34;Python是一门面向对象的编程语言，诞生于1991年22。目前以广泛应用在网站开发、游戏软件开发、数据采集、机器学习等多个领域。一般情况下Python是Java的20%，所以说人生苦短，我用Python。&#34;&#34;&#34;</span> 
<span class="n">output_data</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">findall</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;\b\d</span><span class="si">{4}</span><span class="s1">\b&#39;</span><span class="p">,</span> <span class="n">intput_data</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">output_data</span><span class="p">)</span>
</code></pre></div><br>
<h2 id="问题3-resplit分割句子">问题3-re.split分割句子</h2>
<h3 id="deng-2">deng:</h3>
<p>用re.split 分割 input_data ，生成output_data， 设计刚刚的正则表达式。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">intput_data</span> <span class="o">=</span> <span class="s2">&#34;&#34;&#34;Python是一门面向对象的编程语言，诞生于1991年22。目前以广泛应用在网站开发、游戏软件开发、数据采集、机器学习等多个领域。一般情况下Python是Java的20%，所以说人生苦短，我用Python。&#34;&#34;&#34;</span>

<span class="n">output_data</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Python是一门面向对象的编程语言&#39;</span><span class="p">,</span> 
               <span class="s1">&#39;诞生于1991年&#39;</span><span class="p">,</span> 
               <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">目前以广泛应用在网站开发、游戏软件开发、数据采集、机器学习等多个领域&#39;</span><span class="p">,</span> 
               <span class="s1">&#39;一般情况下Python是Java的20%&#39;</span><span class="p">]</span>

</code></pre></div><h3 id="chatgpt-2">chatGPT：</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">re</span>

<span class="n">input_data</span> <span class="o">=</span> <span class="s2">&#34;&#34;&#34;Python是一门面向对象的编程语言，诞生于1991年22。目前以广泛应用在网站开发、游戏软件开发、数据采集、机器学习等多个领域。一般情况下Python是Java的20%，所以说人生苦短，我用Python。&#34;&#34;&#34;</span>

<span class="n">output_data</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;[。,]&#39;</span><span class="p">,</span> <span class="n">input_data</span><span class="p">)</span>
<span class="n">output_data</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="s1">&#39;。&#39;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">output_data</span> <span class="k">if</span> <span class="n">i</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="n">output_data</span><span class="p">)</span>
</code></pre></div><br>
<h2 id="问题4-resub替换数字为num">问题4-re.sub替换数字为NUM</h2>
<h3 id="deng-3">deng:</h3>
<p>使用正则表达式 re.sub 实现从input_data到output_data的转换。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">input_data</span> <span class="o">=</span> <span class="s2">&#34;&#34;&#34;Python是一门面向对象的编程语言，诞生于1991年。</span><span class="se">\
</span><span class="se"></span><span class="s2">一般情况下Python代码量是Java的20%，所以说人生苦短，我用Python。&#34;&#34;&#34;</span>

<span class="n">output_data</span> <span class="o">=</span> <span class="s1">&#39;Python是一门面向对象的编程语言，诞生于NUM年。一般情况下Python代码量是Java的NUM%，所以说人生苦短，我用Python。&#39;</span>
</code></pre></div><h3 id="chatgpt-3">chatGPT</h3>
<p>您可以使用正则表达式 re.sub 来实现将所有数字替换为 &lsquo;NUM&rsquo; 的转换：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">re</span>

<span class="n">input_data</span> <span class="o">=</span> <span class="s2">&#34;&#34;&#34;Python是一门面向对象的编程语言，诞生于1991年。</span><span class="se">\
</span><span class="se"></span><span class="s2">一般情况下Python代码量是Java的20%，所以说人生苦短，我用Python。&#34;&#34;&#34;</span>

<span class="n">output_data</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;\d+&#39;</span><span class="p">,</span> <span class="s1">&#39;NUM&#39;</span><span class="p">,</span> <span class="n">input_data</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">output_data</span><span class="p">)</span>
</code></pre></div><br>
<br>
]]></content:encoded>
    </item>
    
    <item>
      <title>使用 chatGPT 做词频统计&amp;词云图</title>
      <link>https://textdata.cn/blog/2023-02-11-chatgpt-plus-for-text-mining/</link>
      <pubDate>Thu, 09 Feb 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-02-11-chatgpt-plus-for-text-mining/</guid>
      <description>使用 chatGPT 做词频统计&amp;amp;词云图，过程使用pandas、pyecharts、jieba等库。</description>
      <content:encoded><![CDATA[<h2 id="任务描述">任务描述</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">请用Python撰写一个中文文本分析的代码，进行词频统计、绘制词云图。

分析的数据是csv文件，过程使用pandas、pyecharts、jieba等库。

代码生成后，按照数据导入、数据清洗、数据分析、结果展示四个章节部分对代码进行中文讲解，格式为markdown。
</code></pre></div><br>
<h2 id="需要注意">需要注意</h2>
<ul>
<li>chatGPT需要科学上网才能使用， 推荐 <a href="https://textdata.cn/blog/2023-02-01-v2net-science-network/"><strong>科学上网工具v2net</strong></a>。</li>
<li>如果想升级为chatGPT Plus，需要使用国外的虚拟信用卡，推荐阅读[<strong>使用虚拟信用卡，国内用户升级为chatGPT plus会员</strong>]https://textdata.cn/blog/2023-02-11-credit_card_for_chatgpt-plus)</li>
</ul>
<br>
<h2 id="说明">说明</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">- 以下内容，80%左右内容为chatGPT生成，大邓工作主要是准备实验数据，调试代码，编辑章节。
- 实验环境chatGPT PLUS，今天刚刚花了20美元，使用全局网络模式下，chatGPT响应更稳定快速。
- chatGPT PLUS虽然很强，结果依然有问题，最初生成的词云图是基于wordcloud库，
  该库不支持中文，绘制的图片是乱码的。这里指导ta改为pyecharts制作词云图。
</code></pre></div><p>如需了解升级 <strong>chatGPT plus</strong> 教程(国内信用卡不支持，绑定需要国外的信用卡)， 可以私信大邓 <strong>37233583</strong>9， 备注【<strong>姓名-学校-专业</strong>】</p>
<br>
<h2 id="下载本文codezip"><a href="code.zip">下载本文</a></h2>
<p><a href="code.zip">点击下载本文代码&amp;数据</a></p>
<br>
<h2 id="一数据导入">一、数据导入</h2>
<p>首先需要导入需要的库：pandas、jieba、pyecharts等。如果电脑没有相应的库，可以命令行中执行以下安装命令</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">pip3 install pyecharts
pip3 install jieba
</code></pre></div><p>读取csv文件，使用pandas库的read_csv函数：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">jieba</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">pyecharts</span> <span class="kn">import</span> <span class="n">options</span> <span class="k">as</span> <span class="n">opts</span>
<span class="kn">from</span> <span class="nn">pyecharts.charts</span> <span class="kn">import</span> <span class="n">Bar</span><span class="p">,</span> <span class="n">WordCloud</span>


<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;data.csv&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><p>Run</p>
<p><img loading="lazy" src="img/df.png" alt=""  />
</p>
<br>
<h2 id="二数据清洗">二、数据清洗</h2>
<p>清洗数据是文本分析的第一步，这里需要对数据进行去重、去除空值、去除停用词等操作。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1"># 去重</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop_duplicates</span><span class="p">()</span>

<span class="c1"># 去除空值</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">dropna</span><span class="p">()</span>

<span class="c1"># 加载停用词表</span>
<span class="n">stopwords</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;stopwords.txt&#39;</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">stopwords</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">line</span><span class="o">.</span><span class="n">strip</span><span class="p">())</span>

<span class="c1"># 分词，并去除停用词</span>
<span class="n">text</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>
<span class="k">for</span> <span class="n">content</span> <span class="ow">in</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;desc&#39;</span><span class="p">]:</span>
    <span class="n">seg_list</span> <span class="o">=</span> <span class="n">jieba</span><span class="o">.</span><span class="n">cut</span><span class="p">(</span><span class="n">content</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">seg_list</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">word</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">stopwords</span><span class="p">:</span>
            <span class="n">text</span> <span class="o">+=</span> <span class="n">word</span> <span class="o">+</span> <span class="s1">&#39; &#39;</span>

<span class="c1">#查看text部分内容</span>
<span class="n">text</span><span class="p">[:</span><span class="mi">200</span><span class="p">]</span>
</code></pre></div><pre><code>Building prefix dict from the default dictionary ...
Dumping model to file cache /var/folders/y0/4gqxky0s2t94x1c1qhlwr6100000gn/T/jieba.cache
Loading model cost 0.460 seconds.
Prefix dict has been built successfully.
</code></pre>
<p>Run</p>
<pre><code>'唐天宝 十四年 长安城 小吏 李善德 突然 接到 一个 任务 贵妃 诞日 之前 岭南 运来 新鲜 荔枝 荔枝 “ 一日 色变 两日 香变 三日 味变 ” 岭南 长安 五千余里 山水 迢 ... ◆ 编辑 推荐   ★ 〇 一年 国际 布克奖 美国 国家图书奖 短 名单 作品   ★ 入选 〇 二一 年度 纽约时报 书评 周刊 十大 好书   ★ 入选 奥巴马 〇 一年 夏季 阅读 书单   ★ .'
</code></pre>
<br>
<h2 id="三数据分析">三、数据分析</h2>
<p>使用jieba库对文本进行分词处理，然后<strong>统计每个词语的出现频率</strong>。这里使用Python的字典数据结构进行计数。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1"># 分词</span>
<span class="n">seg_list</span> <span class="o">=</span> <span class="n">jieba</span><span class="o">.</span><span class="n">cut</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>

<span class="c1"># 统计词频</span>
<span class="n">word_count</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">seg_list</span><span class="p">:</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">word</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">2</span><span class="p">:</span>  <span class="c1"># 只统计长度大于等于2的词语</span>
        <span class="k">if</span> <span class="n">word</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">word_count</span><span class="p">:</span>
            <span class="n">word_count</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">word_count</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>

<span class="n">word_count</span>
</code></pre></div><p>Run</p>
<pre><code>{'唐天宝': 4,
 '十四年': 2,
 '长安城': 4,
 '小吏': 2,
 '李善德': 2,
 '突然': 5,
 '接到': 2,
 ......
 '文笔': 1,
 '行云流水': 1,
 '医学': 1,
 '研究生': 1,
 '大为': 1,
 '空怀': 1,
 '壮志': 1,
 '无职无权': 1,
 '时来运转': 1,
 '有名': 2,
 '有利': 1,
 '真切': 1,
 '旅程': 1,
 '困扰': 1,
 '傅真': 1,
 '暌违': 1,
 '七年': 1,
 ...}
</code></pre>
<br>
<h2 id="四结果展现">四、结果展现</h2>
<p>接下来，根据统计结果绘制词云图和柱状图。</p>
<h3 id="41-词云图">4.1 词云图</h3>
<p>绘制词云图，使用pyecharts的WordCloud库：
<img loading="lazy" src="img/wordcloud.png" alt=""  />
</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pyecharts.options</span> <span class="k">as</span> <span class="nn">opts</span>
<span class="kn">from</span> <span class="nn">pyecharts.charts</span> <span class="kn">import</span> <span class="n">WordCloud</span>


<span class="n">wordfreqs</span> <span class="o">=</span> <span class="p">[(</span><span class="n">w</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">f</span><span class="p">))</span> <span class="k">for</span> <span class="n">w</span><span class="p">,</span><span class="n">f</span> <span class="ow">in</span> <span class="n">word_count</span><span class="o">.</span><span class="n">items</span><span class="p">()]</span>


<span class="p">(</span>
    <span class="n">WordCloud</span><span class="p">()</span>
    <span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">series_name</span><span class="o">=</span><span class="s2">&#34;&#34;</span><span class="p">,</span> <span class="n">data_pair</span><span class="o">=</span><span class="n">wordfreqs</span><span class="p">,</span> <span class="n">word_size_range</span><span class="o">=</span><span class="p">[</span><span class="mi">20</span><span class="p">,</span> <span class="mi">100</span><span class="p">])</span>
    <span class="o">.</span><span class="n">set_global_opts</span><span class="p">(</span>
        <span class="n">title_opts</span><span class="o">=</span><span class="n">opts</span><span class="o">.</span><span class="n">TitleOpts</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s2">&#34;词频分析&#34;</span><span class="p">,</span> <span class="n">title_textstyle_opts</span><span class="o">=</span><span class="n">opts</span><span class="o">.</span><span class="n">TextStyleOpts</span><span class="p">(</span><span class="n">font_size</span><span class="o">=</span><span class="mi">23</span><span class="p">)</span>
        <span class="p">),</span>
        <span class="n">tooltip_opts</span><span class="o">=</span><span class="n">opts</span><span class="o">.</span><span class="n">TooltipOpts</span><span class="p">(</span><span class="n">is_show</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
    <span class="p">)</span>
    <span class="o">.</span><span class="n">render</span><span class="p">(</span><span class="s2">&#34;词云图.html&#34;</span><span class="p">)</span>  <span class="c1">#存储位置</span>
<span class="p">)</span>
</code></pre></div><h3 id="42-柱状图">4.2 柱状图</h3>
<p>绘制柱状图</p>
<p><img loading="lazy" src="img/bar.png" alt=""  />
</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python">
<span class="c1"># </span>
<span class="n">top_n</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">word_count_sorted</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">word_count</span><span class="o">.</span><span class="n">items</span><span class="p">(),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">word_top_n</span> <span class="o">=</span> <span class="n">word_count_sorted</span><span class="p">[:</span><span class="n">top_n</span><span class="p">]</span>

<span class="n">bar</span> <span class="o">=</span> <span class="n">Bar</span><span class="p">()</span>
<span class="n">bar</span><span class="o">.</span><span class="n">add_xaxis</span><span class="p">([</span><span class="n">w</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">word_top_n</span><span class="p">])</span>
<span class="n">bar</span><span class="o">.</span><span class="n">add_yaxis</span><span class="p">(</span><span class="s2">&#34;词频&#34;</span><span class="p">,</span> <span class="p">[</span><span class="n">w</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">word_top_n</span><span class="p">])</span>
<span class="n">bar</span><span class="o">.</span><span class="n">set_global_opts</span><span class="p">(</span><span class="n">title_opts</span><span class="o">=</span><span class="n">opts</span><span class="o">.</span><span class="n">TitleOpts</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s2">&#34;词频统计&#34;</span><span class="p">),</span> <span class="n">xaxis_opts</span><span class="o">=</span><span class="n">opts</span><span class="o">.</span><span class="n">AxisOpts</span><span class="p">(</span><span class="n">axislabel_opts</span><span class="o">=</span><span class="n">opts</span><span class="o">.</span><span class="n">LabelOpts</span><span class="p">(</span><span class="n">rotate</span><span class="o">=-</span><span class="mi">15</span><span class="p">)))</span>
<span class="n">bar</span><span class="o">.</span><span class="n">render</span><span class="p">(</span><span class="s2">&#34;word_count.html&#34;</span><span class="p">)</span>

</code></pre></div><br>
]]></content:encoded>
    </item>
    
    <item>
      <title>使用虚拟信用卡，国内用户升级为chatGPT plus会员</title>
      <link>https://textdata.cn/blog/2023-02-11-credit_card_for_chatgpt-plus/</link>
      <pubDate>Thu, 09 Feb 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-02-11-credit_card_for_chatgpt-plus/</guid>
      <description>可能周围很多朋友已经注册了 chatGPT， 想体验更稳定快速的plus版， 结果升级 chatGPT plus 时发现openAI不支持国内的信用卡。大邓的信用卡是 **中国银行VISA卡**，也不支持。参考了一些网上的教程，可以使用 **虚拟信用卡** 来搞定升级chatGPT plus的任务，耗时10min左右。使用虚拟信用卡，国内用户升级为chatGPT plus会员</description>
      <content:encoded><![CDATA[<h2 id="如何chatgpt-plus升级">如何chatGPT plus升级</h2>
<p>可能周围很多朋友已经注册了 chatGPT， 想体验更稳定快速的plus版， 结果升级 chatGPT plus 时发现openAI不支持国内的信用卡。大邓的信用卡是 <strong>中国银行VISA卡</strong>，也不支持。参考了一些网上的教程，可以使用 <strong>虚拟信用卡</strong> 来搞定升级chatGPT plus的任务，耗时10min左右。确保在**「全局VPN+浏览器无痕模式」下进行注册及升级PLUS的操作**</p>
<blockquote>
<p>Note:</p>
<p>虚拟信用卡是一种创新的支付工具，为消费者提供更安全、更便捷的网上支付体验。与传统信用卡不同，虚拟信用卡能够提供更多的安全性和便利性，同时还具有更广泛的使用范围。</p>
</blockquote>
<p>大邓用的 <strong>诺贝nobepay</strong> 的虚拟信用卡服务商，我已经充值并开通了一张卡，效果不错。</p>
<br>
<h2 id="诺贝nobepay">诺贝nobepay</h2>
<p>诺贝nobepay的特点如下：</p>
<ul>
<li>支持自定义姓名和地址信息，也可以<strong>一键生成虚拟地址</strong>；</li>
<li>无限开卡，随用随开，不用的卡可以删除，剩余余额将自动返还到账户，可以在下次使用；</li>
<li>费用透明，仅收取开卡费和充值手续费，没有其他隐藏费用；</li>
<li>多功能使用，可以用于日常购物消费，支持绑定美国PayPal，支持阿里云国际绑定，支持Google Play等；</li>
<li>支持人民币充值，只能使用绑定的微信充值，充值速度很快；</li>
<li>支持派安盈、万里汇、空中云汇、银行电汇、ach美元充值；</li>
</ul>
<br>
<h2 id="注册地址">注册地址</h2>
<p><strong>注册地址：<a href="https://nobepay.com/app/login?type=azmzep&amp;code=514DF0">https://nobepay.com</a>，邀请码： 514DF0</strong></p>
<br>
<p><img loading="lazy" src="img/nobe.png" alt=""  />
</p>
<p>注册后，充值前需要进行实名验证，根据提示，使用手机内的浏览器，扫码人脸验证即可。</p>
<br>
<p><strong>注册地址：<a href="https://nobepay.com/app/login?type=azmzep&amp;code=514DF0">https://nobepay.com</a>，邀请码： 514DF0</strong></p>
<br>
<h2 id="充值操作">充值操作</h2>
<p>需要注意，诺贝nobepay 有在线充值、客服充值、USDT充值等几种方式，</p>
<p><img loading="lazy" src="img/money_in.png" alt=""  />
</p>
<p>大邓选的 <strong>在线充值</strong>，最低充值门槛 <strong>500</strong> 元，高于990元，需要找客服代充。</p>
<p><img loading="lazy" src="img/account_cash.png" alt=""  />
</p>
<br>
<h2 id="注意">注意</h2>
<p><strong>nobepay 对于薅羊毛和拒付等不当行为非常重视，一旦发现，立即封号</strong>，不会通知您并退还任何资金。因此，请您在使用诺贝nobepay时遵守相关规则，以确保您的账户安全。</p>
<br>
<h2 id="开卡">开卡</h2>
<p>充值完成后，您就可以开始使用诺贝nobepay的虚拟信用卡了。该平台支持多种虚拟信用卡类型，如果您不确定哪种卡适合您，可以咨询在线客服。</p>
<p>注意，开卡是需要收费的，费用根据所选卡片不同而异，一般在1-5美元之间。充值的最低限额为10美元，部分卡片的最低限额要求为30美元，并需要支付3%的服务费。因此，费用的组成为：开卡费（1-5美元）+充值（最低10美元）+服务费（充值费用的3%）。</p>
<p>开卡时，点击<strong>随机地址</strong> 可以选择生成随机地址，构造出虚拟的姓名和地址(<strong>不要直接写我截图的个人信息，因为我已经用了，你们再用会有冲突</strong>)。</p>
<p><img loading="lazy" src="img/creadit_card.png" alt=""  />
</p>
<br>
<p>点击<strong>开卡</strong>，大概1min左右就在<strong>卡片列表</strong>中看到激活的卡片。</p>
<h2 id="总结">总结</h2>
<p>请注意，</p>
<ul>
<li>
<p>注册诺贝nobepay需要邀请码，并且需要先进行实名认证才能使用该服务。</p>
</li>
<li>
<p>在线充值仅支持微信支付，微信号和实名认证需要保持一致，最低充值金额为500元。</p>
</li>
<li>
<p>诺贝nobepay适合没有实体信用卡但需要进行海淘的用户，或者担心实体信用卡信息泄露的用户。</p>
</li>
<li>
<p>在删除卡片之前，请先解绑该卡片与所有服务商的关联，以避免出现拒付情况。</p>
</li>
</ul>
<p>诺贝nobepay存在一些不足，例如，开通的虚拟卡仅有1年的有效期，并且存在开卡费和服务费。因此，请您在使用诺贝nobepay之前仔细考虑您的需求和消费情况。</p>
<p><strong>注册地址：<a href="https://nobepay.com/app/login?type=azmzep&amp;code=514DF0">https://nobepay.com</a>，邀请码： 514DF0</strong></p>
<br>
<br>
]]></content:encoded>
    </item>
    
    <item>
      <title>在巨型语言模型时代竞争：OpenAI vs 谷歌</title>
      <link>https://textdata.cn/blog/2023-02-09-openai-vs-google/</link>
      <pubDate>Thu, 09 Feb 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/2023-02-09-openai-vs-google/</guid>
      <description>在未来，巨型语言模型将继续发挥重要作用，并不断推动人工智能的发展。随着技术的不断提高，它们将越来越智能，更加逼近人类语言的表达能力，从而改变人类的生活和工作方式。</description>
      <content:encoded><![CDATA[<h2 id="目录">目录</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">1. 巨型语言模型的诞生
   - OpenAI 和谷歌的研究历史
   - 巨型语言模型的定义与特征
2. OpenAI 与谷歌的研究方向对比
   - OpenAI：强调人工智能的社会责任
   - 谷歌：注重语言模型的应用前景
3. OpenAI 与谷歌的研究成果对比
   - OpenAI 的 GPT 系列模型
   - 谷歌的 Transformer 系列模型
4. 语言模型的应用前景
   - OpenAI 和谷歌的观点对比
   - 语言模型的未来发展趋势
5. 结语
   - 巨型语言模型的影响与未来展望
</code></pre></div><p><br><br></p>
<h2 id="一巨型语言模型的诞生">一、巨型语言模型的诞生</h2>
<h3 id="11-openai-和谷歌的研究历史">1.1 OpenAI 和谷歌的研究历史</h3>
<p>OpenAI 成立于 2015 年，是一家致力于开展人工智能研究并将其应用于改善人类生活的非盈利机构。自成立以来，OpenAI 一直致力于大语言模型的研究与开发。</p>
<p>谷歌的语言模型研究始于 2012 年，当时谷歌的研究团队开始探索使用神经网络进行语言处理的方法。在随后的几年中，谷歌不断完善和提升其语言模型的性能，并成功应用于许多实际场景中。</p>
<p>OpenAI 和谷歌都是语言模型研究的先驱者，它们在巨型语言模型的研究与应用方面都取得了显著的成绩。</p>
<br>
<h3 id="12-巨型语言模型的定义与特征">1.2 巨型语言模型的定义与特征</h3>
<p>巨型语言模型 (GPT) 是一种基于深度学习的语言处理模型，通过训练大量的文本数据，使得模型具备了对人类语言进行理解和生成的能力。</p>
<p>巨型语言模型具有以下特征：</p>
<ul>
<li>能够掌握大量语言知识，如词汇、语法、语义等</li>
<li>具有语言生成能力，能够根据上下文生成合理的语言输出</li>
<li>具有语言理解能力，能够根据输入文本进行语义理解</li>
</ul>
<p>巨型语言模型在各种语言任务上的表现都很优秀，如文本生成、问答、机器翻译等。它们已经成为语言技术领域的一个重要研究方向。</p>
<p><br><br></p>
<h2 id="二-openai-与谷歌的研究方向对比">二、 OpenAI 与谷歌的研究方向对比</h2>
<h3 id="21-openai强调人工智能的社会责任">2.1 OpenAI：强调人工智能的社会责任</h3>
<p>OpenAI 是一家由 Elon Musk, Sam Altman, Greg Brockman, Ilya Sutskever, Wojciech Zaremba, John Schulman 等人创立的人工智能研究机构，总部位于美国加州。OpenAI 强调人工智能的社会责任，致力于研究人工智能领域的前沿技术，同时也关注人工智能的社会影响和道德责任。</p>
<p>OpenAI 关注的领域包括：</p>
<ul>
<li>巨型语言模型</li>
<li>强化学习</li>
<li>机器人</li>
<li>生物信息学</li>
<li>生成对抗网络等</li>
</ul>
<p>OpenAI 发布了多项重要研究成果，如 GPT 系列语言模型、OpenAI Five 强化学习系统等。OpenAI 的研究工作一直得到了全球学术界和业界的高度关注。</p>
<p>OpenAI 的使命是创造安全、有益的人工智能，帮助人类实现更美好的未来。</p>
<br>
<h3 id="22-谷歌注重语言模型的应用前景">2.2 谷歌：注重语言模型的应用前景</h3>
<p>谷歌是全球科技巨头，总部位于美国加州。谷歌在人工智能领域有着丰富的研究经验，并在语言模型方面有着卓越的表现。谷歌强调语言模型的应用前景，致力于将语言模型技术应用到实际生活中，提高人们的工作效率和生活质量。</p>
<p>谷歌在语言模型方面的主要研究内容包括：</p>
<ul>
<li>语音识别</li>
<li>语音合成</li>
<li>智能问答系统</li>
<li>机器翻译等</li>
</ul>
<p>谷歌发布的 BERT 语言模型引领了语言模型的发展，并在多项 NLP 任务中取得了显著的成绩。谷歌还推出了 Google Assistant、Google Translate 等应用，为人们的生活和工作带来了便利。</p>
<p>谷歌致力于通过人工智能技术，帮助人们更好地了解世界，提高工作效率，改善生活质量。</p>
<p><br><br></p>
<h2 id="三openai-与谷歌的研究成果对比">三、OpenAI 与谷歌的研究成果对比</h2>
<h3 id="31-openai-的-gpt-系列模型">3.1 OpenAI 的 GPT 系列模型</h3>
<p>&ldquo;OpenAI 的 GPT 系列模型&rdquo; 包括了 OpenAI 在巨型语言模型领域的研究成果。GPT 指的是 Generative Pretrained Transformer，是一系列基于 Transformer 架构的语言生成模型。</p>
<p>第一代 GPT 模型于 2018 年发布，并在 NLP 研究领域引起了很大的关注。GPT 模型采用了预训练 + 微调的策略，在大量文本数据上预先训练出语言表示，再在特定任务上微调模型以提高其准确性。</p>
<p>后续，OpenAI 不断推出了更高版本的 GPT 模型，如 GPT-2 和 GPT-3，并不断提升了模型的语言生成能力和多样性。GPT-3 是目前世界上最大的语言生成模型，具有卓越的语言理解能力和生成能力，能够完成各种 NLP 任务，如文本生成、翻译等。</p>
<p>总的来说，OpenAI 的 GPT 系列模型为巨型语言模型的研究和应用提供了重要的贡献，也为人工智能的发展提供了新的思路。</p>
<br>
<h3 id="32-谷歌的-transformer-系列模型">3.2 谷歌的 Transformer 系列模型</h3>
<p>谷歌的 Transformer 系列模型是谷歌研究院在语言模型领域的代表性成果。Transformer 模型首次在 2017 年提出，其独特的结构使得其能够解决语言模型中的长依赖问题，从而提高了模型的效果。</p>
<p>随着 Transformer 模型的不断改进，谷歌在这一领域取得了显著的成绩，例如其在 2018 年推出的 BERT 模型，它在 NLP 领域产生了深远的影响，并被广泛应用在文本分类、问答等任务中。此外，谷歌还推出了其他多种 Transformer 模型，如 GPT-3、T5 等，进一步提高了语言模型的效果。</p>
<p>总的来说，谷歌的 Transformer 系列模型是语言模型领域的先驱，其研究成果为 NLP 领域的发展奠定了基础，同时也为谷歌在语言模型领域的竞争力增强奠定了基础。</p>
<p><br><br></p>
<h2 id="四语言模型的应用前景">四、语言模型的应用前景</h2>
<h3 id="41-openai-和谷歌的观点对比">4.1 OpenAI 和谷歌的观点对比</h3>
<p>OpenAI 和谷歌对巨型语言模型的看法有所不同。OpenAI 更注重人工智能技术的社会责任，强调技术应该在促进人类福祉的同时进行研究和开发。因此，OpenAI 一直以来都在努力提高人工智能技术的透明度和可靠性，并对技术的滥用和危害进行监测。</p>
<p>相比之下，谷歌更注重语言模型的应用前景。谷歌认为，巨型语言模型有巨大的商业潜力，可以应用于自然语言处理、机器翻译、搜索引擎优化等领域。因此，谷歌一直以来都在努力提高语言模型的准确性和效率，以便在商业应用中获得更高的竞争力。</p>
<p>总的来说，OpenAI 和谷歌的差异体现在对巨型语言模型的重点不同。OpenAI 更关注人工智能技术的社会责任，而谷歌更关注语言模型的商业应用。</p>
<br>
<h3 id="42-语言模型的未来发展趋势">4.2 语言模型的未来发展趋势</h3>
<p>随着人工智能的快速发展，巨型语言模型的未来发展趋势预计将具有以下几个方面：</p>
<p>多语种支持：巨型语言模型将不再仅仅局限于英语，而是能够支持更多的语言。</p>
<p>更高效的计算：巨型语言模型需要大量的计算资源，但是随着硬件和软件的发展，这些模型将变得更加高效。</p>
<p>更多的应用场景：巨型语言模型的应用将不仅限于聊天机器人，将会扩展到更多领域，如文本生成、翻译、摘要等。</p>
<p>更加逼真的人工智能：巨型语言模型将不断提高，使得人工智能更加逼真，从而带来更加流畅的人机交互体验。</p>
<p>更多的开放数据：随着政府和公司的重视，将有更多的开放数据可供研究者使用，从而提高语言模型的准确性和复杂性。</p>
<p>这些趋势将为巨型语言模型的未来发展带来更多的机会和挑战，并为人工智能的整体发展提供更多的推动力。</p>
<p><br><br></p>
<h2 id="五巨型语言模型的影响与未来展望">五、巨型语言模型的影响与未来展望</h2>
<p>巨型语言模型已经成为人工智能领域最受关注的研究方向之一。它们在语言生成、翻译、问答等方面有着广泛的应用。巨型语言模型对当前社会和未来产生了深远的影响，也激发了新的研究和应用前景。</p>
<p>首先，巨型语言模型的出现改变了人工智能的发展趋势。它们的出色表现使得许多以往难以实现的应用变得可行。此外，巨型语言模型的大规模数据训练和高效推理机制，使得它们在实际应用中有着广泛的前景。</p>
<p>其次，巨型语言模型的出现也引发了关于人工智能的伦理和道德问题的讨论。例如，巨型语言模型可能会模仿人类的语言和行为，对社会和个人造成影响；巨型语言模型的数据来源也存在隐私和安全问题。因此，关于巨型语言模型的研究和应用应该遵循相关的伦理和道德准则。</p>
<p>最后，巨型语言模型的未来发展仍将是人工智能领域的热巨型语言模型已经对人工智能领域产生了巨大的影响，它们已经被用于各种应用场景，如文本生成、机器翻译、对话系统、问答系统等。</p>
<p>然而，随着技术的不断发展，巨型语言模型仍有很多的潜力未能实现。它们的应用范围可以扩展到更多的领域，如医学、法律等。同时，巨型语言模型也需要继续提高它们的准确性和可靠性，避免生成不适当的内容。</p>
<p>在未来，巨型语言模型将继续发挥重要作用，并不断推动人工智能的发展。随着技术的不断提高，它们将越来越智能，更加逼近人类语言的表达能力，从而改变人类的生活和工作方式。</p>
<br>
<br>
]]></content:encoded>
    </item>
    
  </channel>
</rss>
